{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Resource Persons</b> - <b>AICTE Sponsored Three Two week Online</b> FDP", "url": "https://fdp.spit.ac.in/resource-persons/", "isFamilyFriendly": true, "displayUrl": "https://fdp.spit.ac.in/<b>resource-persons</b>", "snippet": "<b>Long short-term memory</b> is an artificial recurrent neural network architecture used in the field of deep learning. Unlike standard feedforward neural networks, <b>LSTM</b> has feedback connections. It can not only process single data points, but also entire sequences of data. Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, introduced in 2014 by Kyunghyun Cho et al. The GRU <b>is like</b> a <b>long short-term memory</b> (<b>LSTM</b>) with a forget gate, but has fewer parameters than <b>LSTM</b> ...", "dateLastCrawled": "2022-01-28T16:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Hierarchical Model for Text Autosummarization", "url": "https://cs224d.stanford.edu/reports/zhenpeng.pdf", "isFamilyFriendly": true, "displayUrl": "https://cs224d.stanford.edu/reports/zhenpeng.pdf", "snippet": "3.1 <b>Long-Short Term Memory</b> (<b>LSTM</b>) <b>Long Short Term Memory</b> networks, usually just called \u201dLSTMs\u201d, are a special kind of RNN, which is capable of learning <b>long</b>-term dependencies. They were introduced by Hochreiter &amp; Schmidhuber [19]. They work tremendously well on a large variety of problems, and are now widely used.", "dateLastCrawled": "2021-10-31T22:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Short-term</b> stock market price trend prediction using a comprehensive ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7467129/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7467129", "snippet": "Fischer and Krauss in applied <b>long short-term memory</b> (<b>LSTM</b>) on financial market prediction. The dataset they used is S&amp;P 500 index constituents from Thomson Reuters. They obtained all month-end constituent lists for the S&amp;P 500 from Dec 1989 to Sep 2015, then consolidated the lists into a binary matrix to eliminate survivor bias. The authors also used RMSprop as an optimizer, which is a mini-batch version of rprop. The primary strength of this work is that the authors used the latest deep ...", "dateLastCrawled": "2021-12-22T09:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Artificial Intelligence in Pathology", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6344799/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6344799", "snippet": "<b>Long shortterm memory</b> (<b>LSTM</b>) ... AI has been tried in other areas, for example, an intelligent assistant named <b>Secretary</b>-Mimicking Artificial Intelligence that helps in the execution of a pathology workflow was presented by Ye . Treatment decision is another important factor in patient healthcare, from both prognostic and financial perspectives. Markov decision analysis is an effective tool in such situations, which was used to solve the cardiological decision problem in the work presented ...", "dateLastCrawled": "2022-01-28T19:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Multivariate Time Series Forecasting <b>Lstm</b> and Similar Products and ...", "url": "https://www.listalternatives.com/multivariate-time-series-forecasting-lstm", "isFamilyFriendly": true, "displayUrl": "https://www.listalternatives.com/multivariate-time-series-forecasting-<b>lstm</b>", "snippet": "Neural networks <b>like</b> <b>Long Short-Term Memory</b> (<b>LSTM</b>) recurrent neural networks are able to almost seamlessly model problems with multiple input variables. This is a great benefit in time series forecasting, where classical linear methods can be difficult to adapt to multivariate or multiple input forecasting problems. Get Certified for Only $299.", "dateLastCrawled": "2022-01-20T22:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Machine learning-based approach to GPS antijamming", "url": "https://link.springer.com/article/10.1007/s10291-021-01154-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10291-021-01154-7", "snippet": "<b>Long short-term memory</b> networks. <b>LSTM</b> networks are a class of unique RNNs, first introduced in 1997 to solve the gradient exploding and vanishing problem (Hochreiter and Schmidhuber 1997). The training of <b>LSTM</b> networks is typically accomplished with the conventional backpropagation through time.", "dateLastCrawled": "2021-12-24T09:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Bidirectional <b>long short-term memory</b> for surgical skill classification ...", "url": "https://link.springer.com/article/10.1007/s11548-020-02269-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11548-020-02269-x", "snippet": "<b>Long short-term memory</b> networks ... The hypothesis of this work is that experts do not behave in an expert-<b>like</b> manner throughout the entirety of a task, and likewise for novices, but instead that the main factor in deciding upon a surgeon\u2019s overall technical skill is the number of expert-<b>like</b> to novice-<b>like</b> segments in footage of a surgical task, and that bidirectional LSTMs have the ability to learn this information from kinematic tool motion data. Methods. Dataset. This study used the ...", "dateLastCrawled": "2021-12-29T12:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Building thermal load prediction</b> through shallow machine learning and ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306261920301951", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306261920301951", "snippet": "It was found that Extreme Gradient Boosting (XGBoost) and <b>Long Short Term Memory</b> (<b>LSTM</b>) are the most accurate shallow and deep learning model, respectively. The CVRMSE of load prediction on the test dataset is 21.1% for XGBoost and 20.2% for <b>LSTM</b>. Both XGBoost and <b>LSTM</b> outperform the best baseline model, which has a CVRMSE of 29.9%. Compared with results in the existing literature, XGBoost is also among the best for building load prediction.", "dateLastCrawled": "2022-01-14T19:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep learning for named entity recognition on Chinese electronic ...", "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0216046&type=printable", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0216046&amp;type=...", "snippet": "Entity Recognition (NER) [11] from EMR. Recurrent Neural Network (RNN) such as <b>Long Short-Term Memory</b> (<b>LSTM</b>) is taking prominent place in NER due to its ability of depen-dency building in neighboring words. Wang et al. [12] studied bi-directional <b>LSTM</b> architec-ture and concluded that this model is very effective for predicting sequential data ...", "dateLastCrawled": "2021-12-13T10:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Applications of Artificial Intelligence in Fire &amp; Safety</b> | by Vedant ...", "url": "https://towardsdatascience.com/applications-of-artificial-intelligence-in-fire-safety-20f66f19bdf9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>applications-of-artificial-intelligence-in-fire-safety</b>...", "snippet": "Again, classification models <b>like</b> the random forest can be used to detect forest fires. An advanced application of the same concept would be to predict the occurrence of the next forest fires. This is a time series problem and can be solved using deep learning models <b>like</b> <b>Long Short-Term Memory</b> (<b>LSTM</b>) or recurrent neural network (RNN). Conclusion", "dateLastCrawled": "2022-01-28T19:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Hierarchical Model for Text Autosummarization", "url": "https://cs224d.stanford.edu/reports/zhenpeng.pdf", "isFamilyFriendly": true, "displayUrl": "https://cs224d.stanford.edu/reports/zhenpeng.pdf", "snippet": "3.1 <b>Long-Short Term Memory</b> (<b>LSTM</b>) <b>Long Short Term Memory</b> networks, usually just called \u201dLSTMs\u201d, are a special kind of RNN, which is capable of learning <b>long</b>-term dependencies. They were introduced by Hochreiter &amp; Schmidhuber [19]. They work tremendously well on a large variety of problems, and are now widely used.", "dateLastCrawled": "2021-10-31T22:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Multivariate Time Series Forecasting <b>Lstm</b> and <b>Similar</b> Products and ...", "url": "https://www.listalternatives.com/multivariate-time-series-forecasting-lstm", "isFamilyFriendly": true, "displayUrl": "https://www.listalternatives.com/multivariate-time-series-forecasting-<b>lstm</b>", "snippet": "Neural networks like <b>Long Short-Term Memory</b> (<b>LSTM</b>) recurrent neural networks are able to almost seamlessly model problems with multiple input variables. This is a great benefit in time series forecasting, where classical linear methods can be difficult to adapt to multivariate or multiple input forecasting problems. Get Certified for Only $299.", "dateLastCrawled": "2022-01-20T22:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Short-term</b> stock market price trend prediction using a comprehensive ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7467129/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7467129", "snippet": "Fischer and Krauss in applied <b>long short-term memory</b> (<b>LSTM</b>) on financial market prediction. The dataset they used is S&amp;P 500 index constituents from Thomson Reuters. They obtained all month-end constituent lists for the S&amp;P 500 from Dec 1989 to Sep 2015, then consolidated the lists into a binary matrix to eliminate survivor bias. The authors also used RMSprop as an optimizer, which is a mini-batch version of rprop. The primary strength of this work is that the authors used the latest deep ...", "dateLastCrawled": "2021-12-22T09:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Artificial Intelligence in Pathology", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6344799/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6344799", "snippet": "<b>Long shortterm memory</b> (<b>LSTM</b>) ... <b>Long short-term memory</b>: <b>LSTM</b>: Recurrent neuron suitable for learning <b>long</b>-term dependency: Support vector machine: SVM: ML method that separates with regard to the trained hyperplane: k-nearest neighbor (search) k-NN: ML method that classifies based on the classes of k <b>similar</b> training data: Conditional random field: CRF: ML method suitable for data with spatial/temporal dependency: Markov decision process: MDP: Modeling framework for a series of decisions ...", "dateLastCrawled": "2022-01-28T19:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Robust Human Action Recognition via <b>Long Short-Term Memory</b>", "url": "http://www.overcomplete.net/papers/ijcnn2013.pdf", "isFamilyFriendly": true, "displayUrl": "www.overcomplete.net/papers/ijcnn2013.pdf", "snippet": "Abstract\u2014The <b>long short-term memory</b> (<b>LSTM</b>) neural network utilizes specialized modulation mechanisms to store information for extended periods of time. It is thus potentially well-suited for complex visual processing, where the current video frame must be considered in the context of past frames. Recent studies have indeed shown that <b>LSTM</b> can effectively recognize and classify human actions (e.g., running, hand waving) in video data; however, these results were achieved under somewhat ...", "dateLastCrawled": "2022-02-03T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Lstm</b> Text Classification - Gain Important Knowledge", "url": "https://coursesoffers.com/lstm-text-classification", "isFamilyFriendly": true, "displayUrl": "https://coursesoffers.com/<b>lstm</b>-text-classification", "snippet": "Open Live Script. This example shows how to classify text data using a deep learning <b>long short-term memory</b> (<b>LSTM</b>) network. Text data is naturally sequential. A piece of text is a sequence of words, which might have dependencies between them. To learn and use <b>long</b>-term dependencies to classify sequence data, use an <b>LSTM</b> ...", "dateLastCrawled": "2022-01-04T16:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Daily natural gas load forecasting based on the combination of <b>long</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1875510021003760", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1875510021003760", "snippet": "To that end, this paper proposes a novel combined model that integrates local mean decomposition (LMD), wavelet threshold denoising (WTD), and <b>long short term memory</b> (<b>LSTM</b>) methods to predict <b>short-term</b> gas consumption, or \u201cLMD-WTD-<b>LSTM</b>\u201d. To begin with, based on the above three basic methods, this paper adopts two different combination schemes, scheme\u2160and scheme\u2161, to predict the gas consumption of London city. The results show that scheme\u2161 is better than scheme\u2160. Further, this ...", "dateLastCrawled": "2022-01-26T22:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Building thermal load prediction</b> through shallow machine learning and ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306261920301951", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306261920301951", "snippet": "It was found that Extreme Gradient Boosting (XGBoost) and <b>Long Short Term Memory</b> (<b>LSTM</b>) are the most accurate shallow and deep learning model, respectively. The CVRMSE of load prediction on the test dataset is 21.1% for XGBoost and 20.2% for <b>LSTM</b>. Both XGBoost and <b>LSTM</b> outperform the best baseline model, which has a CVRMSE of 29.9%. Compared with results in the existing literature, XGBoost is also among the best for building load prediction.", "dateLastCrawled": "2022-01-14T19:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Applications of Artificial Intelligence in Fire &amp; Safety</b> | by Vedant ...", "url": "https://towardsdatascience.com/applications-of-artificial-intelligence-in-fire-safety-20f66f19bdf9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>applications-of-artificial-intelligence-in-fire-safety</b>...", "snippet": "Again, classification models like the random forest can be used to detect forest fires. An advanced application of the same concept would be to predict the occurrence of the next forest fires. This is a time series problem and can be solved using deep learning models like <b>Long Short-Term Memory</b> (<b>LSTM</b>) or recurrent neural network (RNN). Conclusion", "dateLastCrawled": "2022-01-28T19:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A Deep Ensemble <b>Framework for Fake News Detection and Classification</b> ...", "url": "https://deepai.org/publication/a-deep-ensemble-framework-for-fake-news-detection-and-classification", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-deep-ensemble-<b>framework-for-fake-news-detection</b>-and...", "snippet": "dataset and observed that classifiers based on Gated Recurrent Unit (GRU), <b>Long Short Term Memory</b> (<b>LSTM</b>), Bi-directional <b>Long Short Term Memory</b> (Bi-<b>LSTM</b>) performed better than the classifiers based on CNN. Natali Ruchansky et al. used social media dataset (which is also used in for Rumor Detection) and developed a hybrid deep learning model which showed the accuracies of 0.892 on Twitter data and 0.953 on Weibo data. They showed that both, capturing the temporal behavior of the articles as ...", "dateLastCrawled": "2022-01-29T03:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Text generation with <b>LSTM</b>", "url": "https://juliabieniewska.github.io/Text-creation.html", "isFamilyFriendly": true, "displayUrl": "https://juliabieniewska.github.io/Text-creation.html", "snippet": "To generate the text I used an <b>LSTM</b> (<b>long-short term memory</b>) neural network on a dataset created and hosted by Evan Odell (Odell, Evan. (2019). \u201cHansard Speeches V2.6.0 [Dataset].\u201d 10.5281/zenodo.2537227). The dataset contains texts and details of UK Parliament Speeches between 1979-2018, with additional information about speeches like the political affiliation and gender of the speaker. Seeing the additional data I also decided to train a machine learning model which given a speech ...", "dateLastCrawled": "2021-09-17T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "BDCC | Free Full-Text | Prediction of Cloud Fractional Cover Using ...", "url": "https://www.mdpi.com/2504-2289/5/4/62/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2504-2289/5/4/62/htm", "snippet": "We evaluated the potential of two different methods, a convolutional <b>long short-term memory</b> model (ConvLSTM) and a multiple regression equation, to predict CFC from other environmental variables. The predictions were associated with much uncertainty indicating that there might not be much information in the environmental variables used in the study to predict CFC. Overall the regression equation performed the best, but the ConvLSTM was the better performing model along some coastal and ...", "dateLastCrawled": "2021-11-22T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Sentiment analysis through recurrent variants latterly on convolutional ...", "url": "https://www.sciencedirect.com/science/article/pii/S0167739X18324944", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167739X18324944", "snippet": "However, researchers found that greater improvement in the recurrent neural network <b>can</b> be refined by presenting <b>LSTM</b> (<b>Long\u2013Short-Term Memory</b> Network) Bi-<b>LSTM</b> (Bi-directional <b>LSTM</b>). 3.3. <b>Long\u2013short term memory</b>. It is usually known as \u201cLSTMs\u201d and designed to deal with the <b>long</b>-term dependency problems. <b>Long\u2013short term memory</b> network ...", "dateLastCrawled": "2022-01-25T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Machine learning methods <b>for cyber security intrusion detection</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1389128621000141", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1389128621000141", "snippet": "Zhang et al. proposed a unified method combining Multiscale Convolutional Neural Network (MSCNN) with <b>Long Short-Term Memory</b> (<b>LSTM</b>). In the first stage of the method, MSCNN was used to analyze the spatial properties of the data set. In the second stage of the method, <b>LSTM</b> network was used to process temporary features. UNSW-NB15 dataset was used for the training and testing of the model. The method has better accuracy, false alarm rate and false negative speed than models based on ...", "dateLastCrawled": "2022-01-27T05:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Fake News Detection with Different Models</b>", "url": "https://www.researchgate.net/publication/339873192_Fake_News_Detection_with_Different_Models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339873192_<b>Fake_News_Detection_with_Different</b>...", "snippet": "2.6.2 <b>Long Short T erm Memory</b> networks (LSTMs) <b>Long Short Term Memory</b> netw orks (LSTMs) is a special recurrent neural network (RNN) introduced by Hochreiter &amp; Schmidhuber (1997) 8 .", "dateLastCrawled": "2022-01-20T17:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>mind-builder&#39;s blog</b> \u2013 Page 2 \u2013 Clues to how the brain works", "url": "https://thoughtbuilderblog.com/page/2/", "isFamilyFriendly": true, "displayUrl": "https://<b>thought</b>builderblog.com/page/2", "snippet": "Before I talk about how the problem has been tackled, I should mention an improvement to standard recurrent nets, which was called by its authors (Jurgen Shmidhuber and Sepp Hochreiter) <b>LSTM</b> (<b>Long Short Term Memory</b>). The inventors of this net realized that backpropagation isn\u2019t limited to training a relation between two patterns, it <b>can</b> also be used to train gates that control the learning by the other gates. One such gate is a \u2018forget gate\u2019. It uses a \u2018sigmoid function\u2019 on the ...", "dateLastCrawled": "2021-12-06T12:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Nomics ML strategy \u2014 nur wenn die strategie stimmt, w\u00e4chst ihr ...", "url": "https://situacion-rodinu.com/2018/05/loading-oecd-data-with-python7w3q8245jdait.html", "isFamilyFriendly": true, "displayUrl": "https://situacion-rodinu.com/2018/05/loading-oecd-data-with-python7w3q8245jdait.html", "snippet": "The Nomics ML strategy uses a <b>long short-term memory</b> (<b>LSTM</b>) machine learning model to predict the 7-day price movement of each asset. <b>LSTM</b> is used in the field of deep learning to process, classify, and make predictions based on time series data. Learn more about <b>long short-term memory</b>. Methodology The Nomics ML Strategy leverages the 7-day price predictions generated by the Nomics ML engine. These price predictions are then used to determine which assets should be placed into our portfolio ...", "dateLastCrawled": "2021-12-25T19:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>TopicRNN: A Recurrent Neural Network</b> with <b>Long</b>-Range Semantic ...", "url": "https://www.arxiv-vanity.com/papers/1611.01702/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1611.01702", "snippet": "While in principle \\oldtextsc rnn-based models <b>can</b> \u201cremember\u201d arbitrarily <b>long</b> histories if provided enough capacity, in practice such large-scale neural networks <b>can</b> easily encounter difficulties during optimization (Bengio et al., 1994; Pascanu et al., 2013; Sutskever, 2013) or overfitting issues (Srivastava et al., 2014).Finding better ways to model <b>long</b>-range dependencies in language modeling is therefore an open research challenge. As motivated in the introduction, much of the <b>long</b> ...", "dateLastCrawled": "2022-02-03T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>speech recognition</b> IEEE PAPER, IEEE PROJECT", "url": "https://www.engpaper.com/cse/speech-recognition.html", "isFamilyFriendly": true, "displayUrl": "https://www.engpaper.com/cse/<b>speech-recognition</b>.html", "snippet": "help express <b>thought</b> or to emphasize speech. The act of moving the limbs or body as an expression of <b>thought</b> or emphasis. An act or a remark made as a. Voicebrook to Exhibit at APF Pathology Coding HubSpot free download 2015 Seminar. Voicebrook to demonstrate accurate reporting tools that is the industry leader in Pathology <b>speech recognition</b> and reporting. Optical Character Recognition Norsk Regnesentral free download In systems for <b>speech recognition</b>, spoken input from a predefined library ...", "dateLastCrawled": "2022-01-16T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Harry Potter chapters re-written by AI computers with confusing results", "url": "https://www.dailymail.co.uk/sciencetech/article-3691791/amp/Don-t-worry-JK-Rowling-job-safe-New-chapter-Harry-Potter-books-written-AI-COMPUTER-makes-no-sense.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.dailymail.co.uk</b>/sciencetech/article-3691791/amp", "snippet": "He trained a <b>Long Short Term Memory</b> computer with the first four books ; However the computer&#39;s version lacks plot and structure and adds characters on top of each other, such as: &#39;Harry grinned ...", "dateLastCrawled": "2022-01-06T11:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Is Classical <b>LSTM</b> more Efficient than Modern GCN Approaches in ...", "url": "https://www.researchgate.net/publication/355898645_Is_Classical_LSTM_more_Efficient_than_Modern_GCN_Approaches_in_the_Context_of_Traffic_Forecasting", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/355898645_Is_Classical_<b>LSTM</b>_more_Efficient...", "snippet": "The proposed SRCNs inherit the advantages of deep convolutional neural networks (DCNNs) and <b>long short-term memory</b> (<b>LSTM</b>) neural networks. The spatial dependencies of network-wide traffic <b>can</b> be ...", "dateLastCrawled": "2022-01-10T10:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Application of machine learning in the prediction of COVID-19 daily new ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8503968/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8503968", "snippet": "3.4. <b>Long short-term memory</b> (<b>LSTM</b>) <b>LSTM</b> is an artificial recurrent neural network (RNN) method utilized as a deep learning strategy. In contrast to standard feedforward neural networks, this model ensures feedback connection. In addition to processing single data points, <b>LSTM</b> <b>can</b> process complete sequences of data .", "dateLastCrawled": "2022-01-13T00:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Hierarchical Model for Text Autosummarization", "url": "https://cs224d.stanford.edu/reports/zhenpeng.pdf", "isFamilyFriendly": true, "displayUrl": "https://cs224d.stanford.edu/reports/zhenpeng.pdf", "snippet": "3.1 <b>Long-Short Term Memory</b> (<b>LSTM</b>) <b>Long Short Term Memory</b> networks, usually just called \u201dLSTMs\u201d, are a special kind of RNN, which is capable of learning <b>long</b>-term dependencies. They were introduced by Hochreiter &amp; Schmidhuber [19]. They work tremendously well on a large variety of problems, and are now widely used.", "dateLastCrawled": "2021-10-31T22:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Long short-term memory</b>-based Malware classification method for ...", "url": "https://www.sciencedirect.com/science/article/pii/S0045790618328167", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0045790618328167", "snippet": "It <b>can</b> then be classified into families using a <b>long short-term memory</b> (<b>LSTM</b>) network. Vectorizing opcodes and application programming interface (API) function names using one-hot encoding results in high-dimensional vectors because each case is represented using one dimension. Therefore, this paper proposes a word2vec-based <b>LSTM</b> method to analyze opcodes and API function names using fewer dimensions. The results of opcode and API function name classification using the proposed method and ...", "dateLastCrawled": "2022-01-11T06:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Long short-term memory</b>-based Malware classification method for ...", "url": "https://www.sciencedirect.com/science/article/abs/pii/S0045790618328167", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/abs/pii/S0045790618328167", "snippet": "The effects of malware <b>can</b> be estimated by analyzing the opcodes in its executable files. It <b>can</b> then be classified into families using a <b>long short-term memory</b> (<b>LSTM</b>) network. Vectorizing opcodes and application programming interface (API) function names using one-hot encoding results in high-dimensional vectors because each case is represented using one dimension. Therefore, this paper proposes a word2vec-based <b>LSTM</b> method to analyze opcodes and API function names using fewer dimensions ...", "dateLastCrawled": "2021-10-21T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Improved vehicle detection systems with double-layer <b>LSTM</b> modules ...", "url": "https://asp-eurasipjournals.springeropen.com/articles/10.1186/s13634-022-00839-6", "isFamilyFriendly": true, "displayUrl": "https://asp-eurasipjournals.springeropen.com/articles/10.1186/s13634-022-00839-6", "snippet": "In order to track the multiple vehicles better, we adopt a modified version of <b>long short-term memory</b> (<b>LSTM</b>) module with a dual-layer and multi-stage structure. Instead of inner layers, which have larger feature maps, we suggested that the <b>LSTM</b> modules to directly track the object detection outputs to simplify the computation. It is noted that the proposed <b>LSTM</b> modules <b>can</b> be applied to any of the latest detection methods. Without loss of generality, we choose the YOLOv2 as the initial ...", "dateLastCrawled": "2022-02-02T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Short-term</b> stock market price trend prediction using a comprehensive ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7467129/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7467129", "snippet": "Fischer and Krauss in applied <b>long short-term memory</b> (<b>LSTM</b>) on financial market prediction. The dataset they used is S&amp;P 500 index constituents from Thomson Reuters. They obtained all month-end constituent lists for the S&amp;P 500 from Dec 1989 to Sep 2015, then consolidated the lists into a binary matrix to eliminate survivor bias. The authors also used RMSprop as an optimizer, which is a mini-batch version of rprop. The primary strength of this work is that the authors used the latest deep ...", "dateLastCrawled": "2021-12-22T09:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Machine learning-based approach to GPS antijamming", "url": "https://link.springer.com/article/10.1007/s10291-021-01154-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10291-021-01154-7", "snippet": "To mitigate jamming, we study three types of machine learning methods: reservoir computing (echo state network), multi-layer perceptron, and <b>long short-term memory</b> networks (RNNs). A machine <b>can</b> be trained to learn and predict the signal directly or learn and predict jamming where the real signal <b>can</b> be obtained by removing the jammed component from the total received signal. For a high-frequency carrier (e.g., the standard 1575.42 MHz L1 carrier), learning and prediction <b>can</b> be made ...", "dateLastCrawled": "2021-12-24T09:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Modeling and Prediction of Stock Price with Convolutional Neural ...", "url": "https://www.hindawi.com/journals/wcmc/2020/6686181/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/wcmc/2020/6686181", "snippet": "Second, a stock prediction model based on the <b>long short-term memory</b> (<b>LSTM</b>) method is established. This incorporates investor sentiment characteristics guided by official information into the proposed model and explores the depth and breadth of the influence of emotional factors. Experiment results reveal that the accuracy of the model incorporating the emotional characteristics of the intervention has been improved, thus proving that market information requires effective intervention and ...", "dateLastCrawled": "2022-01-30T20:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Utilizing Gated Recurrent Units to Retain <b>Long</b> Term Dependencies ...", "url": "https://www.academia.edu/68028711/Utilizing_Gated_Recurrent_Units_to_Retain_Long_Term_Dependencies_with_Recurrent_Neural_Network_in_Text_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/68028711/Utilizing_Gated_Recurrent_Units_to_Retain_<b>Long</b>_Term...", "snippet": "GRU and <b>Long Short-Term Memory</b> [9] <b>can</b> store information about a longer data sequence that has been processed. One of the powerful techniques that have emerged in Figure 9: Training and Validation loss the recent past is Deep learning [34] which does its learning by using multiple layers of representations or data features and helps to produce state-of-the-art prediction results. There are manyfold challenges associated with traditional neural network techniques like gradient 100 Chandra ...", "dateLastCrawled": "2022-01-24T11:45:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>Learning</b> : Intro to <b>LSTM</b> (<b>Long Short Term Memory</b>) | by HIMANSHU ...", "url": "https://medium.com/@himanshunpatel01/deep-learning-intro-to-lstm-long-short-term-memory-ce504dc6e585", "isFamilyFriendly": true, "displayUrl": "https://medium.com/.../deep-<b>learning</b>-intro-to-<b>lstm</b>-<b>long-short-term-memory</b>-ce504dc6e585", "snippet": "A simple <b>machine</b> <b>learning</b> model or an Artificial Neural Network may learn to predict the stock prices based on a number of features: the volume of the stock, the opening value etc. While the price ...", "dateLastCrawled": "2022-01-27T16:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Long Short Term Memory</b>(<b>LSTM</b>) and <b>Gated Recurrent</b> Units(GRU) | by ...", "url": "https://prvnk10.medium.com/long-short-term-memory-lstm-and-gated-recurrent-units-gru-240d8a62db9", "isFamilyFriendly": true, "displayUrl": "https://prvnk10.medium.com/<b>long-short-term-memory</b>-<b>lstm</b>-and-<b>gated-recurrent</b>-units-gru...", "snippet": "<b>Long Short Term Memory</b> (<b>LSTM</b>) and <b>Gated Recurrent</b> Units (GRU) This article covers the content discussed in the LSTMs and GRU module of the Deep <b>Learning</b> course offered on the website: https://padhai.onefourthlabs.in. The problem with the RNN is that we want the output at every time step to b e dependent on the previous input and the way we do ...", "dateLastCrawled": "2022-01-30T07:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Gentle Introduction to <b>Long Short-Term Memory</b> Networks by the Experts", "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>long-short-term-memory</b>-networks...", "snippet": "<b>Long Short-Term Memory</b> (<b>LSTM</b>) networks are a type of recurrent neural network capable of <b>learning</b> order dependence in sequence prediction problems. This is a behavior required in complex problem domains like <b>machine</b> translation, speech recognition, and more. LSTMs are a complex area of deep <b>learning</b>. It can be hard to get your hands around what LSTMs are, and how terms like bidirectional", "dateLastCrawled": "2022-01-31T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "9.2. <b>Long Short-Term Memory</b> (<b>LSTM</b>) \u2014 Dive into Deep <b>Learning</b> 0.17.2 ...", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_recurrent-modern/<b>lstm</b>.html", "snippet": "The challenge to address <b>long</b>-term information preservation and <b>short-term</b> input skipping in latent variable models has existed for a <b>long</b> time. One of the earliest approaches to address this was the <b>long short-term memory</b> (<b>LSTM</b>) [Hochreiter &amp; Schmidhuber, 1997]. It shares many of the properties of the GRU. Interestingly, LSTMs have a slightly more complex design than GRUs but predates GRUs by almost two decades. 9.2.1. Gated <b>Memory</b> Cell\u00b6 Arguably <b>LSTM</b>\u2019s design is inspired by logic gates ...", "dateLastCrawled": "2022-02-02T23:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>CPSC 540: Machine Learning</b>", "url": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W20/L32.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W20/L32.pdf", "snippet": "<b>CPSC 540: Machine Learning</b> <b>Long Short Term Memory</b> Winter 2020. Previously: Sequence-to-Sequence \u2022Sequence-to-sequence: \u2013Recurrent neural network for sequences of different lengths. \u2022 ^Encoding phase that takes an input at each time. \u2022 ^Decoding phase that makes an output at each time. \u2013Encoding ends with BOS, decoding ends with EOS. x 1 z 1 x 2 z 2 x 3 z 0 z 3 z 4 z 5 y 1 y 2. Variations on Recurrent Neural Networks \u2022Bi-directional RNNs: feedforward from past and future ...", "dateLastCrawled": "2021-11-08T22:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Model Reduction with Memory and</b> <b>the Machine Learning of Dynamical</b> ...", "url": "https://deepai.org/publication/model-reduction-with-memory-and-the-machine-learning-of-dynamical-systems", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>model-reduction-with-memory-and</b>-the-<b>machine</b>-<b>learning</b>-of...", "snippet": "2.2 <b>Long short-term memory</b> networks. Theoretically, RNNs is capable of <b>learning</b> <b>long</b>-term <b>memory</b> effects in the time series. However, in practice it is hard for RNN to catch such dependencies, because of the exploding or shrinking gradient effects , . The <b>Long Short-Term Memory</b> (<b>LSTM</b>) network is designed to solve this problem. Proposed by Hochreiter et al. , the <b>LSTM</b> introduces a new group of hidden units called states, and uses gates to control the information flow through the states. Since ...", "dateLastCrawled": "2022-01-17T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning: Text Generation, A Summary</b> \u2013 Alan&#39;s Blog", "url": "https://achungweb.wordpress.com/2017/04/14/machine-learning-text-generation-a-summary/", "isFamilyFriendly": true, "displayUrl": "https://achungweb.wordpress.com/2017/04/14/<b>machine-learning-text-generation-a-summary</b>", "snippet": "Math, <b>Machine</b> <b>Learning</b>, and other Life Thoughts. <b>Machine Learning: Text Generation, A Summary</b>. Posted on April 14, 2017 by achungweb. I while back I performed an exercise on text generation using the concept of Recurrent Neural Networks, and more specifically, <b>LSTM</b>\u2019s (<b>Long Short-Term Memory</b> Units) in order to generate coherent text based on the book Sherlock Holmes by Conan Doyle. The whole project was a fascinating one, and I wanted to share my results and a brief summary on how <b>LSTM</b>\u2019s ...", "dateLastCrawled": "2022-01-20T17:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "NPTEL :: Computer Science and Engineering - NOC:Deep <b>Learning</b>- Part 1", "url": "https://www.nptel.ac.in/courses/106/106/106106184/", "isFamilyFriendly": true, "displayUrl": "https://www.nptel.ac.in/courses/106/106/106106184", "snippet": "Selective Read, Selective Write, Selective Forget - The Whiteboard <b>Analogy</b>: Download: 109: <b>Long Short Term Memory</b>(<b>LSTM</b>) and Gated Recurrent Units(GRUs) Download: 110: How LSTMs avoid the problem of vanishing gradients: Download: 111: How LSTMs avoid the problem of vanishing gradients (Contd.) Download: 112: Introduction to Encoder Decoder ...", "dateLastCrawled": "2022-01-25T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Multistep Time Series Forecasting with</b> LSTMs in Python", "url": "https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>multi-step-time-series-forecasting</b>-<b>long</b>-<b>short-term</b>...", "snippet": "The <b>Long Short-Term Memory</b> network or <b>LSTM</b> is a recurrent neural network that can learn and forecast <b>long</b> sequences. A benefit of LSTMs in addition to <b>learning</b> <b>long</b> sequences is that they can learn to make a one-shot multi-step forecast which may be useful for <b>time series forecasting</b>. A difficulty with LSTMs is that they can be tricky to configure and it", "dateLastCrawled": "2022-02-02T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Alan&#39;s Blog \u2013 Math, <b>Machine</b> <b>Learning</b>, and other Life Thoughts", "url": "https://achungweb.wordpress.com/", "isFamilyFriendly": true, "displayUrl": "https://achungweb.wordpress.com", "snippet": "<b>Long Short-Term Memory</b> Units (<b>LSTM</b>\u2019s) The concept behind <b>LSTM</b>\u2019s is not extremely complicated, but it\u2019s a fascinating technique with which to retain old information without destroying it through repeated multiplication. As an <b>analogy</b>, imagine a conveyor belt carrying an unfinished product, moving to different processing cells. In each cell ...", "dateLastCrawled": "2022-01-19T07:52:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>learning</b> hybrid model with Boruta-Random forest optimiser ...", "url": "https://www.sciencedirect.com/science/article/pii/S0022169421003978", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0022169421003978", "snippet": "The <b>long short-term memory (LSTM) is like</b> the recurrent neural network (RNN), popularly used in the deep <b>learning</b> field. Likewise, the RNN architecture, LSTM, has a feedback connection with the layers, which can establish the complete sequences of the inputs. The description of LSTM networks can be found different from researches Britz, 2015, Chollet, 2016, Ghimire et al., 2019c, Graves, 2012, Olah, 2015). The LSTM networks are introduced to solve the problems associated with conventional ...", "dateLastCrawled": "2022-01-26T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep <b>Learning</b> Approach for Aggressive Driving Behaviour Detection", "url": "https://arxiv.org/pdf/2111.04794v1", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/2111.04794v1", "snippet": "ML = <b>Machine</b> <b>Learning</b> DL = Deep <b>Learning</b> RNN = Recurrent Neural Network GRU = Gated Recurrent Unit LSTM = Long Short-Term Memory Introduction With the number of automobile accidents, fuel economy, and determining the level of driving talent, the DBA (Driving Behaviour Analysis) becomes a critical subject to be calculated. Depending on the types of car sensors, the inputs . and outputs can then be examined to establish if the DBC (Driving Behaviour Classification) is normal or deviant ...", "dateLastCrawled": "2021-12-09T07:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>Learning</b> Methods Cancer Diagnosis", "url": "https://www.linkedin.com/pulse/deep-learning-methods-cancer-diagnosis-jims-vasant-kunj-ii", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/deep-<b>learning</b>-methods-cancer-diagnosis-jims-vasant-kunj-ii", "snippet": "Classifiers in <b>Machine</b> <b>Learning</b> and its Application: ... <b>Long Short-Term Memory (LSTM) is similar</b> to RNN. It is used for <b>learning</b> order dependence in sequential prediction problems. Conclusion ...", "dateLastCrawled": "2022-01-13T06:31:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(long short-term memory (lstm))  is like +(a secretary)", "+(long short-term memory (lstm)) is similar to +(a secretary)", "+(long short-term memory (lstm)) can be thought of as +(a secretary)", "+(long short-term memory (lstm)) can be compared to +(a secretary)", "machine learning +(long short-term memory (lstm) AND analogy)", "machine learning +(\"long short-term memory (lstm) is like\")", "machine learning +(\"long short-term memory (lstm) is similar\")", "machine learning +(\"just as long short-term memory (lstm)\")", "machine learning +(\"long short-term memory (lstm) can be thought of as\")", "machine learning +(\"long short-term memory (lstm) can be compared to\")"]}