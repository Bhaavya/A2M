{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>The Gambler\u2019s Fallacy</b>: What It Is and How to Avoid It - Effectiviology", "url": "https://effectiviology.com/gamblers-fallacy/", "isFamilyFriendly": true, "displayUrl": "https://effectiviology.com/<b>gamblers-fallacy</b>", "snippet": "For example, imagine Rachel <b>repeatedly</b> <b>flipping</b> <b>a (fair</b>) <b>coin</b> and guessing the outcome before it lands. If she believes in the hot hand, then after observing three correct guesses in a row her subjective probability of guessing correctly on the next flip is higher than 50%. Thus she believes that she is \u2018hot\u2019 and more likely than chance to guess correctly.", "dateLastCrawled": "2022-02-03T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "probability - <b>Stochastic processes and coin flip</b> - Mathematics Stack ...", "url": "https://math.stackexchange.com/questions/1993177/stochastic-processes-and-coin-flip", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/1993177/<b>stochastic-processes-and-coin-flip</b>", "snippet": "<b>Mathematics Stack Exchange</b> is a question and answer site for people studying math at any level and professionals in related fields. It only takes a minute to sign up.", "dateLastCrawled": "2022-01-10T10:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Chapter 9 Limit Theorems and <b>Conditional Expectation</b> | bookdown-demo.knit", "url": "https://bookdown.org/probability/beta/limit-theorems-and-conditional-expectation.html", "isFamilyFriendly": true, "displayUrl": "https://bookdown.org/probability/beta/limit-theorems-and-<b>conditional-expectation</b>.html", "snippet": "This is an intuitive result. Imagine if we were <b>flipping</b> <b>a fair</b> <b>coin</b> over and over and keeping track of the \u2018running mean\u2019 of the number of heads (i.e., the average number of heads from the first two flips, then the average number of heads from the first three flips, etc.).", "dateLastCrawled": "2022-01-31T10:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Learning as conditional inference</b> - probmods.org", "url": "https://probmods.org/chapters/learning-as-conditional-inference.html", "isFamilyFriendly": true, "displayUrl": "https://probmods.org/chapters/<b>learning-as-conditional-inference</b>.html", "snippet": "What does a random sequence look <b>like</b>? Is 00101 more random than 00000? Is the former a better example of a sequence coming from <b>a fair</b> <b>coin</b> than the latter? Most people say so, but notice that if you flip <b>a fair</b> <b>coin</b>, these two sequences are equally probable. Yet these intuitions about randomness are pervasive and often misunderstood: In 1936 ...", "dateLastCrawled": "2022-02-01T04:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Solutions to Exercises Marked with from the book Introduction to ...", "url": "https://projects.iq.harvard.edu/files/stat110/files/selected_solutions_blitzstein_hwang_probability_01.pdf", "isFamilyFriendly": true, "displayUrl": "https://projects.iq.harvard.edu/files/stat110/files/selected_solutions_blitzstein...", "snippet": "(a) (<b>probability</b> that the total after rolling 4 <b>fair</b> dice is 21) (<b>probability</b> that the total after rolling 4 <b>fair</b> dice is 22) (b) (<b>probability</b> that a random 2-letter word is a palindrome1) (<b>probability</b> that a random 3-letter word is a palindrome) Solution: (a) &gt;. All ordered outcomes are equally likely here. So for example with two dice,", "dateLastCrawled": "2022-01-30T21:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "SectionSlides_W3.pdf - Econ 113 Week 3 Section The Normal Distribution ...", "url": "https://www.coursehero.com/file/128091911/SectionSlides-W3pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/128091911/SectionSlides-W3pdf", "snippet": "This is important! Let\u2019s show it using a counter example: Consider the <b>coin</b> <b>flipping</b> example from earlier, where, <b>flipping</b> <b>a fair</b> <b>coin</b> gives you 1 for heads and 0 for tails: X = (1 if heads w/ probability p = 0. 5 0 if tails w/ probability (1 \u2212 p) = 0. 5 What is the expected value of X? E [X] = 0. 5 \u00d7 (1) + 0. 5 \u00d7 (0) = 0. 5 E [X] 2...", "dateLastCrawled": "2022-02-01T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Discrete random variables", "url": "https://probability.oer.math.uconn.edu/wp-content/uploads/sites/2187/2018/01/prob3160ch5.pdf", "isFamilyFriendly": true, "displayUrl": "https://probability.oer.math.uconn.edu/wp-content/uploads/sites/2187/2018/01/prob3160...", "snippet": "If we toss a <b>coin</b> and Xis 1 if we have heads and 0 if we have tails, what is the expectation of X? Solution : p X(x) = 8 &gt;&lt; &gt;: 1 2; x= 1 1 2; x= 0 0; all other aluesv of x. Hence EX= (1)(1 2) + (0)(1 2) = 1 2. Example 5.6. Suppose X= 0 with probability 1 2, 1 with probability 1 4, 2 with probability 1 8, and more generally nwith probability 1=2n+1. This is an example where X can take in nitely many aluesv (although still countably many alues).v What is the expectation of X? Solution : Here p ...", "dateLastCrawled": "2022-01-30T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Chapter 9 Simulation by Markov Chain Monte</b> Carlo | Probability and ...", "url": "https://bayesball.github.io/BOOK/simulation-by-markov-chain-monte-carlo.html", "isFamilyFriendly": true, "displayUrl": "https://bayesball.github.io/BOOK/<b>simulation-by-markov-chain-monte</b>-carlo.html", "snippet": "To decide where to visit next, <b>a fair</b> <b>coin</b> is flipped. If the <b>coin</b> lands heads, we think about visiting the location one value to the left, and if <b>coin</b> lands tails, we consider visiting the location one value to right. We call this location the \u201ccandidate\u201d location.", "dateLastCrawled": "2022-02-02T20:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(McGraw) Schaum&#39;s Outlines of <b>Probability</b>, Random Variables &amp; Random ...", "url": "https://fliphtml5.com/zuef/iyqz/basic/51-100", "isFamilyFriendly": true, "displayUrl": "https://fliphtml5.com/zuef/iyqz/basic/51-100", "snippet": "Let the r.v. X denote the number of heads occurring when ia <b>fair</b> <b>coin</b> is flipped 10 times. Then X is a 4).binomial r.v. with parameters (n, p) = (10, Thus, by Eq. (2.36),2.39. Let X be a binomial r.v. with parameters (n, p), where 0 &lt;: p &lt; 1. Show that as k goes from 0 to n, the pmf p,(k) of X first increases monotonically and then decreases monotonically, reaching its +largest value when k is the largest integer less than or equal to (n 1)p. By Eq. (2.36),we have+ +Hence, px(k) 2 px(k - 1 ...", "dateLastCrawled": "2022-02-02T16:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Conditional Probability</b> Questions and Answers | Study.com", "url": "https://study.com/learn/conditional-probability-questions-and-answers.html", "isFamilyFriendly": true, "displayUrl": "https://study.com/learn/<b>conditional-probability</b>-questions-and-answers.html", "snippet": "A <b>coin</b> is tossed <b>repeatedly</b>; on each toss a head is shown with probability p, satisfying 0 less than p less than 1, and a tail with probability 1 - p. All tosses are mutually independent. Let E den...", "dateLastCrawled": "2022-01-30T18:32:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Learning as conditional inference</b> - probmods.org", "url": "https://probmods.org/chapters/learning-as-conditional-inference.html", "isFamilyFriendly": true, "displayUrl": "https://probmods.org/chapters/<b>learning-as-conditional-inference</b>.html", "snippet": "Suppose instead of simply <b>flipping</b> a <b>coin</b> to determine which of two <b>coin</b> weights to use, we can choose any <b>coin</b> weight between 0 and 1. The following program computes conditional inferences about the weight of a <b>coin</b> drawn from a prior distribution described by the Uniform function, conditioned on a set of observed flips.", "dateLastCrawled": "2022-02-01T04:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Bayesian social aggregation with accumulating evidence - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0022053121002167", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0022053121002167", "snippet": "If one of these <b>i.i.d</b>. processes has nonzero mass in the mixture ... is a <b>coin</b>-<b>flipping</b> process, and we are interested in whether we will first see six \u201cheads\u201d in a row, or six \u201ctails\u201d in a row. Let x, y \u2208 X, and define \u03b1: S N X as follows: for any s \u2208 S N, \u03b1 (s) = x if the block (H, H, H, H, H, H) appears in s earlier in time than the block (T, T, T, T, T, T), whereas \u03b1 (s) = y otherwise. For a random s, the time until the first appearance of (H, H, H, H, H, H) or (T, T, T, T ...", "dateLastCrawled": "2021-12-12T15:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "CSE525: Randomized Algorithms and Probabilistic Analysis June 4, 2013 ...", "url": "https://courses.cs.washington.edu/courses/cse525/13sp/scribe/lec17.pdf", "isFamilyFriendly": true, "displayUrl": "https://courses.cs.washington.edu/courses/cse525/13sp/scribe/lec17.pdf", "snippet": "2.1 Motivating Example: <b>Coin</b>-<b>Flipping</b> One problem for which martingales are especially relevant is computing the expected number of ips of <b>a fair</b> <b>coin</b> until a given sequence is observed. For instance, how many ips would it take on average to observe HHor HTH? These values can be computed directly, but martingales provide a more elegant and general solution. This section demonstrates the use of martingales in order to provide direction before we give de nitions. Consider the sequence S= HTH ...", "dateLastCrawled": "2021-10-31T19:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 9 Limit Theorems and <b>Conditional Expectation</b> | bookdown-demo.knit", "url": "https://bookdown.org/probability/beta/limit-theorems-and-conditional-expectation.html", "isFamilyFriendly": true, "displayUrl": "https://bookdown.org/probability/beta/limit-theorems-and-<b>conditional-expectation</b>.html", "snippet": "This is an intuitive result. Imagine if we were <b>flipping</b> <b>a fair</b> <b>coin</b> over and over and keeping track of the \u2018running mean\u2019 of the number of heads (i.e., the average number of heads from the first two flips, then the average number of heads from the first three flips, etc.).", "dateLastCrawled": "2022-01-31T10:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "EECS 70 Discrete Mathematics and Probability Theory Fall 2014 Anant ...", "url": "https://hkn.eecs.berkeley.edu/examfiles/cs70_fa14_f_sol.pdf", "isFamilyFriendly": true, "displayUrl": "https://hkn.eecs.berkeley.edu/examfiles/cs70_fa14_f_sol.pdf", "snippet": "We have n <b>i.i.d</b>. Bernoulli-p random variables. Let A be the average of these random variables. The following plots are on log-scale and show various bounds and approximations for the probability of the average being more than 1:1 times the mean of A as a function of n (depicted in linear scale). The scatter points represent the actual probability of the deviation. (a)In this set of plots, p = 0:4. Label which one corresponds to Markov\u2019s Inequality, to Chebyshev\u2019s Inequality, and to a ...", "dateLastCrawled": "2022-01-29T19:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Discrete random variables", "url": "https://probability.oer.math.uconn.edu/wp-content/uploads/sites/2187/2018/01/prob3160ch5.pdf", "isFamilyFriendly": true, "displayUrl": "https://probability.oer.math.uconn.edu/wp-content/uploads/sites/2187/2018/01/prob3160...", "snippet": "If we toss a <b>coin</b> and Xis 1 if we have heads and 0 if we have tails, what is the expectation of X? Solution : p X(x) = 8 &gt;&lt; &gt;: 1 2; x= 1 1 2; x= 0 0; all other aluesv of x. Hence EX= (1)(1 2) + (0)(1 2) = 1 2. Example 5.6. Suppose X= 0 with probability 1 2 , 1 with probability 1 4, 2 with probability 1 8, and more generally nwith probability 1=2n+1. This is an example where X can take in nitely many aluesv (although still countably many alues).v What is the expectation of X? Solution : Here ...", "dateLastCrawled": "2022-01-30T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Chapter 3 Random Variables | Foundations of Statistics with R", "url": "https://mathstat.slu.edu/~speegle/_book/randomvariables.html", "isFamilyFriendly": true, "displayUrl": "https://mathstat.slu.edu/~speegle/_book/<b>randomvariable</b>s.html", "snippet": "Consider the <b>random variable</b> \\(X\\) which counts the number of tails observed before the first head when <b>a fair</b> <b>coin</b> is <b>repeatedly</b> tossed. The pmf of \\(X\\) is \\(p(x) = 0.5^{x + 1}\\) for \\(x = 0, 1, 2, \\ldots\\). Finding the expected value requires summing an infinite series, which we leave as an exercise. Instead, we proceed by simulation. We assume (see the next paragraph for a justification) that the infrequent results of \\(x \\ge 100\\) do not impact the expected value much. This assumption ...", "dateLastCrawled": "2022-02-03T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "SectionSlides_W3.pdf - Econ 113 Week 3 Section The Normal Distribution ...", "url": "https://www.coursehero.com/file/128091911/SectionSlides-W3pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/128091911/SectionSlides-W3pdf", "snippet": "The Law of Large Numbers (LLN) Let X 1, X 2, \u00b7 \u00b7 \u00b7, X n \u223c <b>i. i. d</b>. random variables with E [X i] = \u00b5 X and var (X i) &lt; \u221e, then: plim n \u2192\u221e \u00af X = \u00b5 X Translation: As n gets very large, the sample average converges to the population average with increasing probability Implication: As long as the sample was randomly drawn and there are unlikely large outliers, we can get close to the population mean by having a sufficiently large sample! 34 / 46", "dateLastCrawled": "2022-02-01T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(McGraw) Schaum&#39;s Outlines of <b>Probability</b>, Random Variables &amp; Random ...", "url": "https://fliphtml5.com/zuef/iyqz/basic/51-100", "isFamilyFriendly": true, "displayUrl": "https://fliphtml5.com/zuef/iyqz/basic/51-100", "snippet": "Let the r.v. X denote the number of heads occurring when ia <b>fair</b> <b>coin</b> is flipped 10 times. Then X is a 4).binomial r.v. with parameters (n, p) = (10, Thus, by Eq. (2.36),2.39. Let X be a binomial r.v. with parameters (n, p), where 0 &lt;: p &lt; 1. Show that as k goes from 0 to n, the pmf p,(k) of X first increases monotonically and then decreases monotonically, reaching its +largest value when k is the largest integer less than or equal to (n 1)p. By Eq. (2.36),we have+ +Hence, px(k) 2 px(k - 1 ...", "dateLastCrawled": "2022-02-02T16:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>The Gambler\u2019s Fallacy</b>: What It Is and How to Avoid It - Effectiviology", "url": "https://effectiviology.com/gamblers-fallacy/", "isFamilyFriendly": true, "displayUrl": "https://effectiviology.com/<b>gamblers-fallacy</b>", "snippet": "A <b>similar</b> example of <b>the gambler\u2019s fallacy</b> is the mistaken belief that if a die landed on the same number (e.g. 6) multiple times in a row, then it\u2019s less likely to land on that same number the next time. In general, as its name suggests, <b>the gambler\u2019s fallacy</b> is most commonly associated with how people think when they gamble. Beyond the previous examples of this, with coins and dice, another example of this is the incorrect belief that if a certain number was recently drawn in a ...", "dateLastCrawled": "2022-02-03T03:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Polynomially Bounded | Theoretical Computer Science with Chris", "url": "https://polynomiallybounded.wordpress.com/", "isFamilyFriendly": true, "displayUrl": "https://polynomiallybounded.wordpress.com", "snippet": "The proof <b>can</b> <b>be thought</b> of as \u201cmaking recursive calls until termination\u201d. Say we want to know what value we should assign to . ... where the are <b>i.i.d</b> Gaussian random variables with the same mean and variance as the , . This <b>can</b> <b>be thought</b> of as an \u201cinvariance principle\u201d or \u201creplacement lemma\u201d (and this is the viewpoint taken by Lindeburg in his proof of the CLT). The invariance principle is now a tool used in Boolean fourier analysis. Crucial remark: Unfortunately, the equality ...", "dateLastCrawled": "2022-01-24T11:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "probability - <b>Stochastic processes and coin flip</b> - Mathematics Stack ...", "url": "https://math.stackexchange.com/questions/1993177/stochastic-processes-and-coin-flip", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/1993177/<b>stochastic-processes-and-coin-flip</b>", "snippet": "Stack Exchange network consists of 178 Q&amp;A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers.. Visit Stack Exchange", "dateLastCrawled": "2022-01-10T10:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning as conditional inference</b> - probmods.org", "url": "https://probmods.org/chapters/learning-as-conditional-inference.html", "isFamilyFriendly": true, "displayUrl": "https://probmods.org/chapters/<b>learning-as-conditional-inference</b>.html", "snippet": "Suppose instead of simply <b>flipping</b> a <b>coin</b> to determine which of two <b>coin</b> weights to use, we <b>can</b> choose any <b>coin</b> weight between 0 and 1. The following program computes conditional inferences about the weight of a <b>coin</b> drawn from a prior distribution described by the Uniform function, conditioned on a set of observed flips.", "dateLastCrawled": "2022-02-01T04:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 9 Limit Theorems and <b>Conditional Expectation</b> | bookdown-demo.knit", "url": "https://bookdown.org/probability/beta/limit-theorems-and-conditional-expectation.html", "isFamilyFriendly": true, "displayUrl": "https://bookdown.org/probability/beta/limit-theorems-and-<b>conditional-expectation</b>.html", "snippet": "This is an intuitive result. Imagine if we were <b>flipping</b> <b>a fair</b> <b>coin</b> over and over and keeping track of the \u2018running mean\u2019 of the number of heads (i.e., the average number of heads from the first two flips, then the average number of heads from the first three flips, etc.).", "dateLastCrawled": "2022-01-31T10:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bernoulli trials</b> - <b>Columbia University</b>", "url": "http://www.columbia.edu/~kr2248/4109/chapter5.pdf", "isFamilyFriendly": true, "displayUrl": "<b>www.columbia.edu</b>/~kr2248/4109/chapter5.pdf", "snippet": "Ex. Flip <b>a fair</b> <b>coin</b>. Let X = number of heads. Then X is a Bernoulli random variable with p=1/2. E(X) = 1/2 Var(X) = 1/4 . Binomial random variables Consider that n independent <b>Bernoulli trials</b> are performed. Each of these trials has probability p of success and probability (1-p) of failure. Let X = number of successes in the n trials. p(0) = P(0 successes in n trials) = (1-p)n {FFFFFFF} p(1) = P(1 success in n trials) = (n 1)p(1-p)n-1 {FSFFFFF} p(2) = P(2 successes in n trials) = (n 2)p2(1 ...", "dateLastCrawled": "2022-02-02T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Chapter 3 Random Variables | Foundations of Statistics with R", "url": "https://mathstat.slu.edu/~speegle/_book/randomvariables.html", "isFamilyFriendly": true, "displayUrl": "https://mathstat.slu.edu/~speegle/_book/<b>randomvariable</b>s.html", "snippet": "Suppose you <b>repeatedly</b> roll <b>a fair</b> die. What is the probability of getting exactly 14 non-sixes before getting your second 6? As you <b>can</b> see, this is an example of repeated Bernoulli trials with \\(p = 1/6\\), but it isn\u2019t exactly geometric because we are waiting for the second success. This is an example of a negative binomial <b>random variable</b>.", "dateLastCrawled": "2022-02-03T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Chapter 2 <b>Probability</b> | <b>Probability</b>, Statistics, and Data", "url": "https://mathstat.slu.edu/~speegle/_book/probchapter.html", "isFamilyFriendly": true, "displayUrl": "https://mathstat.slu.edu/~speegle/_book/probchapter.html", "snippet": "<b>A fair</b> <b>coin</b> is <b>repeatedly</b> tossed. 9 Estimate the <b>probability</b> that you observe heads for the third time on the 10th toss. In this example, an outcome of the experiment is ten tosses of the <b>coin</b>. The event \u201cyou observe heads for the third time on the 10th toss\u201d is complicated, and most of the work involves testing whether that event occurred. As before, we build this up in stages. Begin by simulating an outcome, a sample of ten tosses of a <b>coin</b>: coinToss &lt;-sample (c (&quot;H&quot;, &quot;T&quot;), 10, replace ...", "dateLastCrawled": "2022-01-29T08:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A <b>couple of thoughts regarding the hot hand fallacy</b> fallacy ...", "url": "https://statmodeling.stat.columbia.edu/2018/12/14/couple-thoughts-regarding-hot-hand-fallacy-argument/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2018/12/14/couple-<b>thoughts</b>-regarding-hot-hand...", "snippet": "Just like <b>flipping</b> a <b>coin</b>, basketball shots <b>can</b> <b>be thought</b> of from a frequentist perspective: the probability of making the shot is the long run frequency of all shots taken that have the same characteristic that we <b>can</b> observe about the shot at hand (player identity, previous shot outcome, distance from hoop, etc). This logic <b>can</b> equally be applied to elections: the probability of trump winning is the long-run frequency of elections with the same characteristics as the one we currently ...", "dateLastCrawled": "2022-02-03T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Introduction to Probability, Second Edition</b> [2&amp;nbsp;ed.] 1138369918 ...", "url": "https://dokumen.pub/introduction-to-probability-second-edition-2nbsped-1138369918-9781138369917.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>introduction-to-probability-second-edition</b>-2nbsped-1138369918...", "snippet": "As another example, consider <b>flipping</b> <b>a fair</b> <b>coin</b> once. Let X be the indicator of Heads and Y = 1 \u2212 X be the indicator of Tails. Both X and Y have the Bern(1/2) distribution, but the event X = Y is impossible. The PMFs of X and Y are the same function, but X and Y are different mappings from the sample space to the real numbers. If Z is the indicator of Heads in a second flip (independent of the first flip), then Z is also Bern(1/2), but Z is not the same r.v. as X. Here P (Z = X) = P (HH ...", "dateLastCrawled": "2022-02-03T14:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>The Extra Half Boy</b> at Steven Landsburg | The Big ... - The Big Questions", "url": "http://www.thebigquestions.com/2011/01/07/the-extra-half-boy/", "isFamilyFriendly": true, "displayUrl": "www.thebigquestions.com/2011/01/07/<b>the-extra-half-boy</b>", "snippet": "The point is the probabilities of the different subsequences are determined exactly as you would get by <b>flipping</b> <b>a fair</b> <b>coin</b>. If that was all there was to it, Lubos would be right, the expected girl proportion is exactly equal to 50%\u2014but there is also the boy on the decision <b>coin</b>, which is why Steve is right, it is less than 50%. (Note that we\u2019re still only talking about the single-generation case only here, however.) If we want to talk about all possible completed countries, the fixed-N ...", "dateLastCrawled": "2021-11-26T02:24:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Law of large numbers</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Law_of_large_numbers", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Law_of_large_numbers</b>", "snippet": "When <b>a fair</b> <b>coin</b> is flipped once, ... As mentioned earlier, the weak law applies in the case of <b>i.i.d</b>. random variables, but it also applies in some other cases. For example, the variance may be different for each random variable in the series, keeping the expected value constant. If the variances are bounded, then the law applies, as shown by Chebyshev as early as 1867. (If the expected values change during the series, then we <b>can</b> simply apply the law to the average deviation from the ...", "dateLastCrawled": "2022-02-07T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "CSE525: Randomized Algorithms and Probabilistic Analysis June 4, 2013 ...", "url": "https://courses.cs.washington.edu/courses/cse525/13sp/scribe/lec17.pdf", "isFamilyFriendly": true, "displayUrl": "https://courses.cs.washington.edu/courses/cse525/13sp/scribe/lec17.pdf", "snippet": "2.1 Motivating Example: <b>Coin</b>-<b>Flipping</b> One problem for which martingales are especially relevant is computing the expected number of ips of <b>a fair</b> <b>coin</b> until a given sequence is observed. For instance, how many ips would it take on average to observe HHor HTH? These values <b>can</b> be computed directly, but martingales provide a more elegant and", "dateLastCrawled": "2021-10-31T19:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bernoulli trials</b> - <b>Columbia University</b>", "url": "http://www.columbia.edu/~kr2248/4109/chapter5.pdf", "isFamilyFriendly": true, "displayUrl": "<b>www.columbia.edu</b>/~kr2248/4109/chapter5.pdf", "snippet": "Ex. Flip <b>a fair</b> <b>coin</b>. Let X = number of heads. Then X is a Bernoulli random variable with p=1/2. E(X) = 1/2 Var(X) = 1/4 . Binomial random variables Consider that n independent <b>Bernoulli trials</b> are performed. Each of these trials has probability p of success and probability (1-p) of failure. Let X = number of successes in the n trials. p(0) = P(0 successes in n trials) = (1-p)n {FFFFFFF} p(1) = P(1 success in n trials) = (n 1)p(1-p)n-1 {FSFFFFF} p(2) = P(2 successes in n trials) = (n 2)p2(1 ...", "dateLastCrawled": "2022-02-02T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Chapter 9 Simulation by Markov Chain Monte</b> Carlo | Probability and ...", "url": "https://bayesball.github.io/BOOK/simulation-by-markov-chain-monte-carlo.html", "isFamilyFriendly": true, "displayUrl": "https://bayesball.github.io/BOOK/<b>simulation-by-markov-chain-monte</b>-carlo.html", "snippet": "One <b>can</b> demonstrate this result empirically for our example. Using a loop, we take the transition matrix \\(P\\) to the 100th power by <b>repeatedly</b> multiplying the transition matrix by itself. From this calculation below, note that the rows of the matrix ```Pm} appear to be approaching a constant vector. Specifically, it appears the constant vector", "dateLastCrawled": "2022-02-02T20:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>The Gambler\u2019s Fallacy</b>: What It Is and How to Avoid It \u2013 Effectiviology", "url": "https://effectiviology.com/gamblers-fallacy/", "isFamilyFriendly": true, "displayUrl": "https://effectiviology.com/<b>gamblers-fallacy</b>", "snippet": "<b>The gambler\u2019s fallacy</b> is the mistaken belief that if an event occurred more frequently than expected in the past then it\u2019s less likely to occur in the future (and vice versa), in a situation where these occurrences are independent of one another. For example, <b>the gambler\u2019s fallacy</b> <b>can</b> cause someone to mistakenly assume that if a <b>coin</b> that they tossed landed on heads twice in a row, then it\u2019s likely to land on tails next.", "dateLastCrawled": "2022-02-03T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>couple of thoughts regarding the hot hand fallacy</b> fallacy ...", "url": "https://statmodeling.stat.columbia.edu/2018/12/14/couple-thoughts-regarding-hot-hand-fallacy-argument/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2018/12/14/couple-thoughts-regarding-hot-hand...", "snippet": "Just like <b>flipping</b> a <b>coin</b>, basketball shots <b>can</b> be thought of from a frequentist perspective: the probability of making the shot is the long run frequency of all shots taken that have the same characteristic that we <b>can</b> observe about the shot at hand (player identity, previous shot outcome, distance from hoop, etc). This logic <b>can</b> equally be applied to elections: the probability of trump winning is the long-run frequency of elections with the same characteristics as the one we currently ...", "dateLastCrawled": "2022-02-03T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Chapter 3 Random Variables | Foundations of Statistics with R", "url": "https://mathstat.slu.edu/~speegle/_book/randomvariables.html", "isFamilyFriendly": true, "displayUrl": "https://mathstat.slu.edu/~speegle/_book/<b>randomvariable</b>s.html", "snippet": "Suppose you <b>repeatedly</b> roll <b>a fair</b> die. What is the probability of getting exactly 14 non-sixes before getting your second 6? As you <b>can</b> see, this is an example of repeated Bernoulli trials with \\(p = 1/6\\), but it isn\u2019t exactly geometric because we are waiting for the second success. This is an example of a negative binomial <b>random variable</b>.", "dateLastCrawled": "2022-02-03T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Conditionals and Loops - Princeton University", "url": "https://introcs.cs.princeton.edu/java/13flow/", "isFamilyFriendly": true, "displayUrl": "https://introcs.cs.princeton.edu/<b>java</b>/13flow", "snippet": "Modify Binary.<b>java</b> to get a program Modify Kary.<b>java</b> that takes a second command-line argument K and converts the first argument to base K.Assume the base is between 2 and 16. For bases greater than 10, use the letters A through F to represent the 11th through 16th digits, respectively.; Write a program code fragment that puts the binary representation of a positive integer n into a String variable s. Creative Exercises. Ramanujan&#39;s taxi. S. Ramanujan was an Indian mathematician who became ...", "dateLastCrawled": "2022-02-03T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Conditional Probability</b> Questions and Answers | Study.com", "url": "https://study.com/learn/conditional-probability-questions-and-answers.html", "isFamilyFriendly": true, "displayUrl": "https://study.com/learn/<b>conditional-probability</b>-questions-and-answers.html", "snippet": "A <b>coin</b> is tossed <b>repeatedly</b>; on each toss a head is shown with probability p, satisfying 0 less than p less than 1, and a tail with probability 1 - p. All tosses are mutually independent. Let E den...", "dateLastCrawled": "2022-01-30T18:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Introduction to Probability, Second Edition</b> [2&amp;nbsp;ed.] 1138369918 ...", "url": "https://dokumen.pub/introduction-to-probability-second-edition-2nbsped-1138369918-9781138369917.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>introduction-to-probability-second-edition</b>-2nbsped-1138369918...", "snippet": "As another example, consider <b>flipping</b> <b>a fair</b> <b>coin</b> once. Let X be the indicator of Heads and Y = 1 \u2212 X be the indicator of Tails. Both X and Y have the Bern(1/2) distribution, but the event X = Y is impossible. The PMFs of X and Y are the same function, but X and Y are different mappings from the sample space to the real numbers. If Z is the indicator of Heads in a second flip (independent of the first flip), then Z is also Bern(1/2), but Z is not the same r.v. as X. Here P (Z = X) = P (HH ...", "dateLastCrawled": "2022-02-03T14:52:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~bgibson/cs540/handouts/learning_intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~bgibson/cs540/handouts/<b>learning</b>_intro.pdf", "snippet": "<b>learning</b> process \u2022x i = (x i1, . . . , x iD) \u2022Assume these instances are sampled independently from an unknown (population) distribution, P(x) \u2022We denote this by x i \u223c P(x), where <b>i.i.d</b>. stands for independent and identically distributed <b>i.i.d</b>. Training Sample \u2022A training sample is the \u201cexperience\u201d given to a <b>learning</b> algorithm", "dateLastCrawled": "2021-08-25T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Learning</b>? <b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "<b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b> Chapter 18.1, 18.2, 18.8.1 and \u201cIntroduction to Statistical <b>Machine</b> <b>Learning</b>\u201d 1 What is <b>Learning</b>? \u2022\u201c<b>Learning</b> is making useful changes in our minds\u201d \u2013Marvin Minsky \u2022\u201c<b>Learning</b> is constructing or modifying representations of what is being experienced\u201c \u2013RyszardMichalski \u2022\u201c<b>Learning</b> denotes changes in a system that ... enable a system to do the same task more efficiently the next time\u201d \u2013Herbert Simon 3 Why do Mach", "dateLastCrawled": "2022-02-03T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> for Drug <b>Discovery</b> in a Nutshell \u2014 Part I | by Stefan ...", "url": "https://medium.com/atomwise/machine-learning-for-drug-discovery-in-a-nutshell-part-i-24ae3f65c135", "isFamilyFriendly": true, "displayUrl": "https://medium.com/atomwise/<b>machine</b>-<b>learning</b>-for-drug-<b>discovery</b>-in-a-nutshell-part-i...", "snippet": "Classical <b>machine</b> <b>learning</b> literature spends little attention to this aspect. Most often, the underlying assumption is that training and test examples are drawn <b>i.i.d</b>. from the same distribution ...", "dateLastCrawled": "2022-01-26T14:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Shortcut <b>learning</b> in deep neural networks | Nature <b>Machine</b> Intelligence", "url": "https://www.nature.com/articles/s42256-020-00257-z", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42256-020-00257-z", "snippet": "In <b>analogy</b> to <b>machine</b> <b>learning</b>, we have a striking discrepancy between intended and actual <b>learning</b> outcome. Shortcut <b>learning</b> in education (surface <b>learning</b>) Alice loves history\u2014but at this ...", "dateLastCrawled": "2022-02-03T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning for Market Microstructure and</b> High Frequency Trading", "url": "https://www.cis.upenn.edu/~mkearns/papers/KearnsNevmyvakaHFTRiskBooks.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cis.upenn.edu/~mkearns/papers/KearnsNevmyvakaHFTRiskBooks.pdf", "snippet": "<b>Machine</b> <b>learning</b> is a vibrant sub\ufb01eld of computer science that draws on models and methods from statistics, algorithms, computational complexity, arti\ufb01cial intelli- gence, control theory, and a variety of other disciplines. Its primary focus is on computationally and informationally ef\ufb01cient algorithms for inferring good predictive models from large data sets, and thus is a natural candidate for application to problems arising in HFT, both for trade execution and the generation of ...", "dateLastCrawled": "2022-02-01T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning Foundations</b> hx\u00d2", "url": "https://www.csie.ntu.edu.tw/~htlin/course/ml20fall/doc/04_handout.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.csie.ntu.edu.tw/~htlin/course/ml20fall/doc/04_handout.pdf", "snippet": "Hsuan-Tien Lin (NTU CSIE) <b>Machine Learning Foundations</b> 12/26. Feasibility of <b>Learning</b> Probability to the Rescue Fun Time Let = 0:4. Use Hoeffding\u2019s Inequality P &gt; 2exp 2 2N to bound the probability that a sample of 10 marbles will have 0:1. What bound do you get? 1 0:67 2 0:40 3 0:33 4 0:05 Reference Answer: 3 Set N = 10 and = 0:3 and you get the answer. BTW, 4 is the actual probability and Hoeffding gives only an upper bound to that. Hsuan-Tien Lin (NTU CSIE) <b>Machine Learning Foundations</b> ...", "dateLastCrawled": "2022-02-02T14:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Distributed Machine Learning for Big</b> Data and Streaming - Guavus - Go ...", "url": "https://www.guavus.com/technical-blog/distributed-machine-learning-for-big-data-and-streaming/", "isFamilyFriendly": true, "displayUrl": "https://www.guavus.com/technical-blog/<b>distributed-machine-learning-for-big</b>-data-and...", "snippet": "In this era of informed decision-making industry, demand for <b>Machine</b> <b>Learning</b> (ML) and Artificial Intelligence (AI) based analytical solutions has increased exponentially. As data processing technologies are becoming more mature and with new technologies in Big Data, streaming and IoT space, data is now available in abundance and at high speeds. Therefore, the way data is processed by analytical systems calls for a transformation. A new form of ML namely the Distributed ML can prove to be a ...", "dateLastCrawled": "2022-01-21T14:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Overcoming Forgetting in Federated <b>Learning</b> on Non-<b>IID</b> Data - <b>NASA/ADS</b>", "url": "https://ui.adsabs.harvard.edu/abs/2019arXiv191007796S/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2019arXiv191007796S/abstract", "snippet": "We tackle the problem of Federated <b>Learning</b> in the non <b>i.i.d</b>. case, in which local models drift apart, inhibiting <b>learning</b>. Building on an <b>analogy</b> with Lifelong <b>Learning</b>, we adapt a solution for catastrophic forgetting to Federated <b>Learning</b>. We add a penalty term to the loss function, compelling all local models to converge to a shared optimum. We show that this can be done efficiently for communication (adding no further privacy risks), scaling with the number of nodes in the distributed ...", "dateLastCrawled": "2022-01-03T20:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[1910.07796] Overcoming Forgetting in <b>Federated Learning</b> on Non-<b>IID</b> Data", "url": "https://arxiv.org/abs/1910.07796", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1910.07796", "snippet": "We tackle the problem of <b>Federated Learning</b> in the non <b>i.i.d</b>. case, in which local models drift apart, inhibiting <b>learning</b>. Building on an <b>analogy</b> with Lifelong <b>Learning</b>, we adapt a solution for catastrophic forgetting to <b>Federated Learning</b>. We add a penalty term to the loss function, compelling all local models to converge to a shared optimum. We show that this can be done efficiently for communication (adding no further privacy risks), scaling with the number of nodes in the distributed ...", "dateLastCrawled": "2022-01-28T12:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Connection between denoising and unsupervised learning</b>", "url": "https://www.inference.vc/denoising-as-unsupervised-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.inference.vc/denoising-as-unsupervised-<b>learning</b>", "snippet": "posts on <b>machine</b> <b>learning</b>, statistics, opinions on things I&#39;m reading in the space. About me Blog <b>Connection between denoising and unsupervised learning</b> . This is just a note showing the connection between <b>learning</b> to remove additive Gaussian noise and <b>learning</b> a probability distribution. I think this connection highlights why <b>learning</b> to denoise is, in fact, a form of unsupervised <b>learning</b>. This is despite the fact that the training procedure is more similar to supervised <b>learning</b> and is ...", "dateLastCrawled": "2022-01-22T15:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Pearson\u2019s Correlation, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black-swans-in-your-market-neutral-portfolios-part-1-e17fc18a42a7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum ...", "dateLastCrawled": "2021-05-27T10:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Pearson\u2019s <b>Correlation</b>, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part-i-7521683a7317", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum-entropy problem , which aims at finding among all probability distributions that are consistent with observed empirical evidence, the one the is the most ignorant about everything else.", "dateLastCrawled": "2022-02-02T09:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(i.i.d.)  is like +(flipping a fair coin repeatedly)", "+(i.i.d.) is similar to +(flipping a fair coin repeatedly)", "+(i.i.d.) can be thought of as +(flipping a fair coin repeatedly)", "+(i.i.d.) can be compared to +(flipping a fair coin repeatedly)", "machine learning +(i.i.d. AND analogy)", "machine learning +(\"i.i.d. is like\")", "machine learning +(\"i.i.d. is similar\")", "machine learning +(\"just as i.i.d.\")", "machine learning +(\"i.i.d. can be thought of as\")", "machine learning +(\"i.i.d. can be compared to\")"]}