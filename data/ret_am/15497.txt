{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Bayesian Model to Analyze the Association of Rheumatoid Arthritis ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8415718/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8415718", "snippet": "For model building <b>and validation</b>, the dataset was further divided into <b>training</b>, <b>validation</b>, and test categories (Table 2). The distribution of the variables were found to be nearly <b>equivalent</b> across each category, indicating an even split after data preprocessing. A slightly greater variation among the three <b>datasets</b> was observed for the RA group, which could be attributed to a substantially smaller number of individuals in this group than the control no arthritis group. In order to ...", "dateLastCrawled": "2021-09-09T13:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Secondary Education and Enrollment Statistics - UNICEF Data", "url": "https://data.unicef.org/topic/education/secondary-education/", "isFamilyFriendly": true, "displayUrl": "https://data.unicef.org/topic/education/secondary", "snippet": "The education and <b>training</b> that children receive in secondary school equip them with skills that are necessary to fully participate in society. Though the standards in each country vary, secondary education typically covers ages 12 to 17 and is divided into two levels: lower secondary education (spanning 3 to 4 years) and upper secondary education (spanning 2 to 3 years). However, in 2019, just two in three children attended either lower or upper secondary school, and only one in two ...", "dateLastCrawled": "2022-01-30T20:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Deep fair models for complex data: Graphs labeling and explainable face ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231221011140", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231221011140", "snippet": "Apart from using classical metrics <b>like</b> the Difference of <b>Demographic</b> <b>Parity</b> ... it is designed to deal with large graphs (such as social network graphs) sampling a fixed-size set of neighbors, while <b>achieving</b> competitive predictive <b>performance</b>, in particular on the considered inductive setting. The representation of a node v at layer k is defined as: (5) r k, v = ReLU W k \u00b7 mean {r k-1, v} \u222a {r k-1, u, \u2200 u \u2208 sample (N (v), n s)}, where W k is the matrix of parameters for the k-th ...", "dateLastCrawled": "2021-11-05T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Virtual Reality Robotic Surgery Warm-Up Improves Task <b>Performance</b> in a ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4082669/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4082669", "snippet": "High stakes professions <b>like</b> athletics and performing arts have long relied on the principles of the warm-up decrement (WUD, the decrease in <b>performance</b> after a period of rest) and the Activity Set hypothesis (the idea that to counter the WUD, some activity to elevate the arousal and readiness of the subject is required to boost <b>performance</b>) to optimize <b>performance</b> readiness.[13-16] Yet surgery does not involve a prescribed warm-up or pre-surgical rehearsal though it is a high stakes ...", "dateLastCrawled": "2017-02-07T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Towards Equity and Algorithmic Fairness in Student Grade ...", "url": "https://www.academia.edu/69838840/Towards_Equity_and_Algorithmic_Fairness_in_Student_Grade_Prediction", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69838840/Towards_Equity_and_Algorithmic_Fairness_in_Student...", "snippet": "A survey on <b>datasets</b> for fairness-aware machine learning. By Tai Le Quy. Assessing the Fairness of Intelligent Systems. By In\u00eas Valentim. An Enhanced Evolutionary Student <b>Performance</b> Prediction Model Using Whale Optimization Algorithm Boosted with Sine-Cosine Mechanism. By Thaer Thaher. Spatially Localized Perturbation GAN (SLP-GAN) for Generating Invisible Adversarial Patches. By Harashta Tatimma Larasati. Guaranteeing Correctness of Machine Learning Based Decision Making at Higher ...", "dateLastCrawled": "2022-01-29T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "RECOMMENDATIONS - NITI Aayog", "url": "https://niti.gov.in/planningcommission.gov.in/docs/aboutus/committee/wrkgrp11/wg11_resrch.doc", "isFamilyFriendly": true, "displayUrl": "https://niti.gov.in/planningcommission.gov.in/docs/aboutus/committee/wrkgrp11/wg11...", "snippet": "Frontier technologies <b>like</b> biotechnology, information and communication technology, renewable energy technologies and nanotechnology provide uncommon opportunities for launching an ever-green revolution capable of improving productivity in perpetuity without ecological harm. In field of genetic enhancement, 10 premier institutions should be identified where breeding of specific crops should be carried out by integrating the tools of both conventional and molecular methods of plant breeding ...", "dateLastCrawled": "2022-01-29T20:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Toward a clinical text encoder: pretraining for clinical natural ...", "url": "https://europepmc.org/article/MED/31233140", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/31233140", "snippet": "Once the encoders achieve an acceptable level of <b>performance</b>, we combine the <b>training</b> and the <b>validation</b> sets and retrain them. We train the DAN encoder with 5000 hidden units for 16 epochs with a learning rate of 0.001 and a batch size of 16 as determined by random search. We train the CNN encoder with 500 hidden units and 1024 filters of size 5 for 8 epochs with a learning rate of 0.001 and a batch size of 8 using AdaDelta optimizer, also as determined by random search. Encoder evaluation ...", "dateLastCrawled": "2021-11-26T12:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Gender <b>shades : intersectional phenotypic and demographic evaluation</b> of ...", "url": "https://www.researchgate.net/publication/323722163_Gender_shades_intersectional_phenotypic_and_demographic_evaluation_of_face_datasets_and_gender_classifiers", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323722163_Gender_shades_intersectional...", "snippet": "This work evaluates the <b>performance</b> obtained when <b>training</b> convolutional neural network models on commonly used driver drowsiness detection <b>datasets</b> and testing on <b>datasets</b> specifically chosen for ...", "dateLastCrawled": "2021-11-27T14:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "NIPS2017abs.md \u00b7 GitHub", "url": "https://gist.github.com/cwhy/ce9f21cbb649d11f646e273a04e0ed4c", "isFamilyFriendly": true, "displayUrl": "https://<b>gist</b>.github.com/cwhy/ce9f21cbb649d11f646e273a04e0ed4c", "snippet": "Collecting large <b>training</b> <b>datasets</b>, annotated with high quality labels, is a costly process. This paper proposes a novel framework for <b>training</b> deep convolutional neural networks from noisy labeled <b>datasets</b>. The problem is formulated using an undirected graphical model that represents the relationship between noisy and clean labels, trained in a semi-supervised setting. In the proposed structure, the inference over latent clean labels is tractable and is regularized during <b>training</b> using ...", "dateLastCrawled": "2022-01-31T00:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "New submissions for Wed, 30 Jun 21 \u00b7 Issue #137 \u00b7 dajinstory/daily ...", "url": "https://github.com/dajinstory/daily-arxiv-noti/issues/137", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/dajinstory/daily-arxiv-noti/issues/137", "snippet": "In this paper, we propose TANet++ to improve the <b>performance</b> on 3D Detection, which adopt a novel <b>training</b> strategy <b>on training</b> the TANet. In order to reduce the negative impact by the weak samples, the <b>training</b> strategy previously filtered the <b>training</b> data, and then the TANet++ is trained by the rest of data. The experimental results shows that AP score of TANet++ is 8.98% higher than TANet on JRDB benchmark.", "dateLastCrawled": "2021-08-21T23:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Predicting the success of vaginal birth after caesarean delivery: a ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6538023/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6538023", "snippet": "The <b>demographic</b> and clinical characteristics of women in the <b>training</b> cohort (N=1491, 80%) and the <b>validation</b> cohort (N=373, 20%) are shown in table 1. Comparison of the baseline data indicated that the <b>training</b> <b>and validation</b> groups showed no significant differences, with the exception of <b>parity</b> (p=0.03) and history of vaginal delivery (p=0.02).", "dateLastCrawled": "2021-12-23T17:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Gender Inequality in Household Chores and Work-Family Conflict", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6086200/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6086200", "snippet": "WFC negatively affects both health and general life such as work <b>performance</b> and work satisfaction within the organizational context, but it also increases conflict rates and decreases family satisfaction. From this perspective, and within a context of a more technological and digitalized society, gender equality at work is a matter of paramount importance, which must start with a gender equality at home. The aim of this study is to check whether the unequal involvement in household chores ...", "dateLastCrawled": "2022-02-02T07:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Optimized Feature Subset Selection Using Genetic Algorithm for Preterm ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8151582/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8151582", "snippet": "Table 3 shows the average <b>performance</b> for both base and ensemble classifiers for <b>training</b>, <b>validation</b> and testing dataset and Figure 4 shows the results of the Nemenyi post-hoc test of F1-score between different classifiers for both <b>validation</b> and testing <b>datasets</b>. In general, the base classifiers <b>performance</b> for <b>training</b> dataset was better than the <b>validation</b> dataset, as expected. The classifier metrics of the testing dataset was <b>similar</b> to or slightly inferior than the <b>validation</b> dataset ...", "dateLastCrawled": "2021-11-02T19:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Towards Equity and Algorithmic Fairness in Student Grade ...", "url": "https://www.academia.edu/69838840/Towards_Equity_and_Algorithmic_Fairness_in_Student_Grade_Prediction", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69838840/Towards_Equity_and_Algorithmic_Fairness_in_Student...", "snippet": "A survey on <b>datasets</b> for fairness-aware machine learning. By Tai Le Quy. Assessing the Fairness of Intelligent Systems. By In\u00eas Valentim. An Enhanced Evolutionary Student <b>Performance</b> Prediction Model Using Whale Optimization Algorithm Boosted with Sine-Cosine Mechanism. By Thaer Thaher. Spatially Localized Perturbation GAN (SLP-GAN) for Generating Invisible Adversarial Patches. By Harashta Tatimma Larasati. Guaranteeing Correctness of Machine Learning Based Decision Making at Higher ...", "dateLastCrawled": "2022-01-29T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The Influence of Affirming Kindness and Community on Broadening ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5898245/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5898245", "snippet": "Research on <b>validation</b> theory has shown positive effects on persistence when educators value what students bring to the ... we recommend collecting and tracking student data including (a) department level disaggregated <b>demographic</b> information (e.g., ethnicity/race, gender, socioeconomic status, first generation status), (b) participation in research <b>training</b> and support program, (c) mentorship, and (d) outcomes typically already tracked such as course progression, degree attainment, and time ...", "dateLastCrawled": "2022-01-06T13:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Bayesian Model to Analyze the Association of Rheumatoid Arthritis ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8415718/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8415718", "snippet": "For model building <b>and validation</b>, the dataset was further divided into <b>training</b>, <b>validation</b>, and test categories (Table 2). The distribution of the variables were found to be nearly <b>equivalent</b> across each category, indicating an even split after data preprocessing. A slightly greater variation among the three <b>datasets</b> was observed for the RA group, which could be attributed to a substantially smaller number of individuals in this group than the control no arthritis group. In order to ...", "dateLastCrawled": "2021-09-09T13:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Gender <b>shades : intersectional phenotypic and demographic evaluation</b> of ...", "url": "https://www.researchgate.net/publication/323722163_Gender_shades_intersectional_phenotypic_and_demographic_evaluation_of_face_datasets_and_gender_classifiers", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323722163_Gender_shades_intersectional...", "snippet": "This work evaluates the <b>performance</b> obtained when <b>training</b> convolutional neural network models on commonly used driver drowsiness detection <b>datasets</b> and testing on <b>datasets</b> specifically chosen for ...", "dateLastCrawled": "2021-11-27T14:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Frontiers | Fair and Effective Policing for Neighborhood Safety ...", "url": "https://www.frontiersin.org/articles/10.3389/fdata.2021.787459/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fdata.2021.787459", "snippet": "The most commonly used group fairness notions include <b>demographic</b> <b>parity</b> Andreev et al. (2002), equal opportunity Arneson (1989) ... then we randomly split the dataset as 7:2:1 for <b>training</b>, testing <b>and validation</b> respectively. For data processing, since some \u2018null\u2019 value only means \u2018False\u2019 in NYCSF stops. We carefully analyze the data, and replace \u2018(null)\u2019 with \u2018F\u2019. For the remaining data, we drop the data records with default or wrong values. For the textual feature, e.g ...", "dateLastCrawled": "2022-02-01T18:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fairness metrics and bias mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "For both <b>datasets</b>, we adopt an evaluation strategy <b>similar</b> to Yao and Huang (2017) and follow the general idea of a 5-fold cross <b>validation</b> evaluation approach. Specifically, the Movielens dataset is divided into 5 folds, and each fold is used for testing the collaborative filtering approach (trained on the other 4 folds) exactly once. For the synthetic data, we independently create the synthetic dataset 5 times. In both cases, the reported results represent the average for the 5 test folds ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Entropy | Free Full-Text | The Problem of Fairness in Synthetic ...", "url": "https://www.mdpi.com/1099-4300/23/9/1165/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1099-4300/23/9/1165/htm", "snippet": "Thus, there is a trade-off between resemblance (between synthetic data and real <b>training</b> data) and privacy, <b>similar</b> to the fit vs. robustness trade-off. Alas, avoiding overfitting is only a necessary condition to obtain privacy-preserving data [ 18 ], additional steps must be taken to downgrade the data to protect privacy, which in turn can effect utility [ 19 ].", "dateLastCrawled": "2021-12-12T16:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Blackbox Post-Processing for Multiclass Fairness", "url": "https://www.researchgate.net/publication/357790861_Blackbox_Post-Processing_for_Multiclass_Fairness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357790861_Blackbox_Post-Processing_for_Multi...", "snippet": "called <b>demographic</b> <b>parity</b> only requires the rate of class pre- dictions across different groups to be equal (Calders, Kami-ran, and Pechenizkiy 2009). De\ufb01nition 4 (Multiclass <b>Demographic</b> <b>Parity</b> ...", "dateLastCrawled": "2022-01-25T23:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Fairness metrics and bias mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "First, in both <b>datasets</b> the bias mitigation approach is successful in increasing fairness according to the specific target metric;i.e.,value-based bias mitigation reduces value unfairness, <b>parity</b>-based adjustment reduces <b>parity</b> in the empirical MovieLens dataset. Second, the effects of the bias mitigation on other metrics is complex, and thus representative of the complexity of using and comparing different definitions of fairness. In general, while the target fairness metric <b>can</b> be improved ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Data Collection and Quality Challenges in Deep Learning: A Data-Centric ...", "url": "https://vertexdoc.com/doc/data-collection-and-quality-challenges-in-deep-learning-a-data-centric-ai-perspective", "isFamilyFriendly": true, "displayUrl": "https://vertexdoc.com/doc/data-collection-and-quality-challenges-in-deep-learning-a...", "snippet": "As a result, software engineering needs to be re-<b>thought</b> where data becomes a first-class citizen on par with code. One striking observation is that 80-90% of the machine learning process is spent on data preparation. Without good data, even the best machine learning algorithms cannot perform well. As a result, data-centric AI practices are now becoming mainstream. Unfortunately, many <b>datasets</b> in the real world are small, dirty, biased, and even poisoned. In this survey, we study the ...", "dateLastCrawled": "2022-01-17T22:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Testing discrimination in practice", "url": "https://fairmlbook.org/testing.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/testing.html", "snippet": "A rebuttal might claim that the gap disappears after controlling for college GPA and <b>performance</b> review scores. Such studies <b>can</b> be seen as tests for conditional <b>demographic</b> <b>parity</b> (row 6 in the summary table). Testing conditional <b>demographic</b> <b>parity</b> using regression requires strong assumptions about the functional form of the relationship between the independent variables and the target variable. It <b>can</b> be hard to make sense of competing claims based on regression analysis. Which variables ...", "dateLastCrawled": "2022-01-30T14:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Confidence-Based Approach for Balancing Fairness and Accuracy ...", "url": "https://www.researchgate.net/publication/306061688_A_Confidence-Based_Approach_for_Balancing_Fairness_and_Accuracy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/306061688_A_Confidence-Based_Approach_for...", "snippet": "Our experiments show that our approach <b>can</b> achieve <b>parity</b> in terms of statistical <b>parity</b>, equal opportunity, and disparate mistreatment while maintaining good predictive <b>performance</b> for all ...", "dateLastCrawled": "2022-01-30T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Fairness in machine learning with tractable models</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0950705120308443", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0950705120308443", "snippet": "These approaches have been very successful in minimising statistical measures of discrimination, and <b>can</b> achieve near <b>demographic</b> <b>parity</b> ... and a <b>training</b>/<b>validation</b> set comprising the remaining 800 individuals. This was subsequently sub-divided into 5 blocks of 160 instances for a k-fold cross <b>validation</b> procedure. Each of the 5 <b>training</b> sets, comprising 640 applicants, served as a separate <b>training</b> set for the SPN. The binary sex attribute which we treat as \u2018protected\u2019 was originally ...", "dateLastCrawled": "2022-01-20T21:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>EDUCATION</b> \u2013 Dr Rajiv Desai", "url": "https://drrajivdesaimd.com/2016/02/28/education/", "isFamilyFriendly": true, "displayUrl": "https://drrajivdesaimd.com/2016/02/28/<b>education</b>", "snippet": "<b>Education</b> <b>can</b> <b>be thought</b> of as the transmission of the values and accumulated knowledge of a society. In this sense, it is <b>equivalent</b> to what social scientists term socialization or enculturation. Children\u2014whether conceived among New Guinea tribes people, the Renaissance Florentines, or the middle classes of Manhattan\u2014are born without culture. <b>Education</b> is designed to guide them in learning a culture, moulding their behaviour in the ways of adulthood, and directing them toward their ...", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Minutes of the 153rd <b>Meeting of the NATIONAL ADVISORY COUNCIL ON</b> ...", "url": "https://www.niaaa.nih.gov/about-niaaa/our-work/advisory-council/agenda-minutes/advisory-council-meeting-minutes/minutes-153rd-meeting-national-advisory-council-alcohol-abuse-and", "isFamilyFriendly": true, "displayUrl": "https://www.niaaa.nih.gov/about-niaaa/our-work/advisory-council/agenda-minutes/advisory...", "snippet": "Pay for <b>Performance</b> (P4P) is \u201cThe systematic and deliberate use of payment incentives that recognize and reward high levels of quality and quality improvement <b>can</b> serve as a powerful stimulus to drive institutional and provider behavior toward better quality\u201d (Institute of Medicine, 2007). Historically, both low and high quality providers earned the same income at the same volume levels. P4P or Results-based Financing (RBF) offers financial incentives to improve quality, care, access and ...", "dateLastCrawled": "2022-02-03T07:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Data Collection and Quality Challenges in Deep Learning: A Data-Centric ...", "url": "https://deepai.org/publication/data-collection-and-quality-challenges-in-deep-learning-a-data-centric-ai-perspective", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/data-collection-and-quality-challenges-in-deep-learning...", "snippet": "Data <b>validation</b> <b>can</b> be performed using visualizations and schema information. Data cleaning has been heavily studied where recent techniques are more tailored to improving model accuracy. Data sanitization has the different flavor of defending against poisoning attacks. 4 Robust Model <b>Training</b>. Even after collecting the right data and cleaning it, data quality may still be an issue during model <b>training</b>. It is widely agreed that real-world <b>datasets</b> are dirty and erroneous despite the data ...", "dateLastCrawled": "2022-01-27T18:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Proceedings of the 59th Annual Meeting of the Association for ...", "url": "https://aclanthology.org/volumes/2021.acl-long/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/volumes/2021.acl-long", "snippet": "While state-of-the-art NLP models have been <b>achieving</b> the excellent <b>performance</b> of a wide range of tasks in recent years, important questions are being raised about their robustness and their underlying sensitivity to systematic biases that may exist in their <b>training</b> and test data. Such issues come to be manifest in <b>performance</b> problems when faced with out-of-distribution data in the field. One recent solution has been to use counterfactually augmented <b>datasets</b> in order to reduce any ...", "dateLastCrawled": "2022-01-29T06:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Predicting the success of vaginal birth after caesarean delivery: a ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6538023/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6538023", "snippet": "The <b>demographic</b> and clinical characteristics of women in the <b>training</b> cohort (N=1491, 80%) and the <b>validation</b> cohort (N=373, 20%) are shown in table 1. Comparison of the baseline data indicated that the <b>training</b> <b>and validation</b> groups showed no significant differences, with the exception of <b>parity</b> (p=0.03) and history of vaginal delivery (p=0.02).", "dateLastCrawled": "2021-12-23T17:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimized Feature Subset Selection Using Genetic Algorithm for Preterm ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8151582/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8151582", "snippet": "Table 3 shows the average <b>performance</b> for both base and ensemble classifiers for <b>training</b>, <b>validation</b> and testing dataset and Figure 4 shows the results of the Nemenyi post-hoc test of F1-score between different classifiers for both <b>validation</b> and testing <b>datasets</b>. In general, the base classifiers <b>performance</b> for <b>training</b> dataset was better than the <b>validation</b> dataset, as expected. The classifier metrics of the testing dataset was similar to or slightly inferior than the <b>validation</b> dataset ...", "dateLastCrawled": "2021-11-02T19:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Societal individualism\u2013collectivism and uncertainty avoidance as ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5947744/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5947744", "snippet": "1.1. The job demands\u2013resources model. The JD\u2010R model, which evolved from the job demands\u2013control model (Karasek, 1979) and the job demands\u2013control\u2013support model (Johnson &amp; Hall, 1988), has been a dominant model in the occupational health and well\u2010being literature that explains how workplace factors influence employee physical and psychological strain (Demerouti et al., 2001).In these models, job demands refer to physical, social, or organizational aspects of the work environment ...", "dateLastCrawled": "2022-01-15T23:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "by topics | <b>Probabilistic Circuits</b>", "url": "https://arranger1044.github.io/probabilistic-circuits/topics", "isFamilyFriendly": true, "displayUrl": "https://arranger1044.github.io/<b>probabilistic-circuits</b>/topics", "snippet": "In particular, we aim to achieve <b>demographic</b> <b>parity</b> by enforcing certain independencies in the learned model. We also show that group fairness guarantees are meaningful only if the distribution used to provide those guarantees indeed captures the real-world data. In order to closely model the data distribution, we employ <b>probabilistic circuits</b>, an expressive and tractable probabilistic model, and propose an algorithm to learn them from incomplete data. We evaluate our approach on a synthetic ...", "dateLastCrawled": "2022-01-30T06:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Virtual Reality Robotic Surgery Warm-Up Improves Task <b>Performance</b> in a ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4082669/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4082669", "snippet": "Once successfully <b>achieving</b> <b>performance</b> benchmarks, surgeons were randomized to either receive a 3-5 minute VR simulator warm-up or read a leisure book for 10 minutes prior to performing similar and dissimilar (intracorporeal suturing) robotic surgery tasks. The primary outcomes <b>compared</b> were task time, tool path length, economy of motion, technical and cognitive errors. Results. Task time (-29.29sec, p=0.001, 95%CI-47.03,-11.56), path length (-79.87mm, p=0.014, 95%CI -144.48,-15.25), and ...", "dateLastCrawled": "2017-02-07T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Avoiding Resentment Via Monotonic Fairness</b> | DeepAI", "url": "https://deepai.org/publication/avoiding-resentment-via-monotonic-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>avoiding-resentment-via-monotonic-fairness</b>", "snippet": "Fair\u201d) learns a function that avoids the score resentment present in the \u201dFair\u201d classifier, while <b>achieving</b> similar <b>demographic</b> <b>parity</b> (odds ratio 1.11). No individual <b>can</b> claim that another individual with a lower non-protected attribute value received a higher probability of acceptance. This is achieved by reducing the certainty of acceptance from those with the highest attribute values, which are increasingly majority-dominated, and reducing the threshold attribute value required to ...", "dateLastCrawled": "2021-12-13T19:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Fairness and Robustness in Invariant Learning: A Case Study in Toxicity ...", "url": "https://www.arxiv-vanity.com/papers/2011.06485/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2011.06485", "snippet": "Table 2 reports the <b>performance</b> of ERM and IRM on the OOD set with respect to the <b>Demographic</b> <b>Parity</b> and Equalized Odds fairness definitions (Equations 3 and 4). We find that IRM yields substantially fairer predictions for both definitions on all considered sensitive attributes (with the exception of <b>Demographic</b> <b>Parity</b> for \u201cLGBTQ\u201d). These results are expected given the spurious correlation\u2019s reversal between the InD and OOD sets and our hypothesis that IRM learns invariant predictors ...", "dateLastCrawled": "2021-12-23T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) Towards Equity and Algorithmic Fairness in Student Grade ...", "url": "https://www.academia.edu/69838840/Towards_Equity_and_Algorithmic_Fairness_in_Student_Grade_Prediction", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69838840/Towards_Equity_and_Algorithmic_Fairness_in_Student...", "snippet": "A survey on <b>datasets</b> for fairness-aware machine learning. By Tai Le Quy. Assessing the Fairness of Intelligent Systems. By In\u00eas Valentim. An Enhanced Evolutionary Student <b>Performance</b> Prediction Model Using Whale Optimization Algorithm Boosted with Sine-Cosine Mechanism. By Thaer Thaher. Spatially Localized Perturbation GAN (SLP-GAN) for Generating Invisible Adversarial Patches. By Harashta Tatimma Larasati. Guaranteeing Correctness of Machine Learning Based Decision Making at Higher ...", "dateLastCrawled": "2022-01-29T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Demographic</b> Bias in Biometrics: A Survey on an Emerging Challenge", "url": "https://www.researchgate.net/publication/342262466_Demographic_Bias_in_Biometrics_A_Survey_on_an_Emerging_Challenge", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342262466_<b>Demographic</b>_Bias_in_Biometrics_A...", "snippet": "<b>datasets</b>, <b>training</b>\u2013testing data partitioning, imbalanced . <b>datasets</b>, etc. 2) Statistical signi\ufb01cance of the results due to relatively. small size of the used <b>datasets</b> in most cases (except, e ...", "dateLastCrawled": "2021-12-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Fairness in machine learning with tractable models</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0950705120308443", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0950705120308443", "snippet": "These approaches have been very successful in minimising statistical measures of discrimination, and <b>can</b> achieve near <b>demographic</b> <b>parity</b> ... then the model may lose <b>performance</b>, and in general very low levels of disparate treatment are only achieved at a fairly significant cost to classification accuracy . Moreover, it could be argued that certain individuals who score highly on one of the attributes (even though the remainder of their <b>demographic</b> generally does not) are unfairly penalised b", "dateLastCrawled": "2022-01-20T21:45:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "An example of prediction which complies with <b>Demographic</b> <b>Parity</b> and ...", "url": "https://vertexdoc.com/doc/an-example-of-prediction-which-complies-with-demographic-parity-and-equalizes-group-wise-risks-in-the-context", "isFamilyFriendly": true, "displayUrl": "https://vertexdoc.com/doc/an-example-of-prediction-which-complies-with-<b>demographic</b>...", "snippet": "However, <b>Demographic</b> <b>Parity</b> and EGWR only define fairness on the group level and inspecting the individual level reveals a critical flow of this prediction rule. We have constrained our predictors to those that do not produce Disparate Treatment by prohibiting them from having the sensitive variable as direct input. Nevertheless, enforcing group level fairness constraints (such as DP and EGWR) forces the prediction rule to guess the sensitive attribute corresponding to a given feature vector", "dateLastCrawled": "2022-02-05T21:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Pandas <b>Machine</b> <b>Learning</b> Example", "url": "https://groups.google.com/g/hslogb/c/-BvVGlSI3Ek", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/hslogb/c/-BvVGlSI3Ek", "snippet": "Regardless of your dataset, <b>demographic</b> <b>parity</b> is a <b>machine</b> <b>learning</b> algorithms. Data Munging It helps us to missing data of wedge form with another. Python with datetime module, i should equal to bring new example <b>machine</b>. Quite possibly the state important part clean the <b>machine</b> <b>learning</b> process is understanding the data you are working with and advantage it relates to reflect task you front to solve. Viewing the corresponding number of dropping down arrow illustrates that are not only all ...", "dateLastCrawled": "2022-01-24T06:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "Heidari et al. have written a paper comparing the three criteria \u2013 <b>demographic</b> <b>parity</b>, equality of opportunity, and predictive <b>parity</b> \u2013 to egalitarianism, equality of opportunity (EOP) in the Rawlsian sense, and EOP seen through the glass of luck egalitarianism, respectively. While the <b>analogy</b> is fascinating, it too assumes that we may take what is in the data at face value. In their likening predictive <b>parity</b> to luck egalitarianism, they have to go to especially great lengths, in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) On Fair Representation in <b>Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/341736051_On_Fair_Representation_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../341736051_On_Fair_Representation_in_<b>Machine</b>_<b>Learning</b>", "snippet": "<b>demographic</b> <b>parity</b> and metrics such as equalized odds are either ignored ( e.g. [21], [22]) or assumed to be automatically satis\ufb01ed by &quot;removing&quot; information about sensitive attributes", "dateLastCrawled": "2022-01-26T19:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "Simply put, the goal of classification is to determine a plausible value for an unknown variable Y given an observed variable X.For example, we might try to predict whether a loan applicant will pay back her loan by looking at various characteristics such as credit history, income, and net worth. Classification also applies in situations where the variable Y does not refer to an event that lies in the future. For example, we can try to determine if an image contains a cat by looking at the ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Human-centric Approach to Fairness in AI", "url": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "isFamilyFriendly": true, "displayUrl": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "snippet": "This includes measures such as <b>Demographic</b> <b>Parity</b> / Statistical <b>Parity</b> (Dwork et al., 2012), Equalized Odds Metric (Hardt et al., 2016) and Calibration within Groups (Chouldechova, 2017). They are all statistical measures derived from the predictions of a classification model and differ in terms of which element(s) of the confusion matrix they are trying to test for equivalence. In another survey of fairness definitions, Verma &amp; Rubin (2018) listed 20 definitions of fairness, 13 belonging to ...", "dateLastCrawled": "2022-02-03T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Mitigating Unwanted Biases with Adversarial <b>Learning</b>", "url": "http://www.m-mitchell.com/papers/Adversarial_Bias_Mitigation.pdf", "isFamilyFriendly": true, "displayUrl": "www.m-mitchell.com/papers/Adversarial_Bias_Mitigation.pdf", "snippet": "<b>Machine</b> <b>learning</b> is a tool for building models that accurately represent input training data. When undesired biases concern-ing <b>demographic</b> groups are in the training data, well-trained models will re\ufb02ect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously <b>learning</b> a predictor and an ad-versary. The input to the network X, here text or census data, produces a prediction Y, such as an <b>analogy</b> completion or in ...", "dateLastCrawled": "2022-01-23T20:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Adversarial Approaches to Debiasing Word Embeddings", "url": "https://web.stanford.edu/class/cs224n/reports/final_reports/report101.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/cs224n/reports/final_reports/report101.pdf", "snippet": "<b>Machine</b> <b>learning</b> for natural language processing (NLP) leverages valuable data from human language for useful downstream applications such as <b>machine</b> translation and sentiment analysis. Recent studies, however, have shown that training data in these applications are prone to harboring stereotypes and unwanted biases commonly exhibited in human language. Since NLP systems are designed to understand novel associations within training data, they are similarly vulnerable to propagating these ...", "dateLastCrawled": "2022-01-25T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Survey on Bias and <b>Fairness in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/a-survey-on-bias-and-fairness-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-survey-on-bias-and-<b>fairness-in-machine-learning</b>", "snippet": "With the popularity of AI and <b>machine</b> <b>learning</b> over the past decades, and their epidemic spread in different applications, safety and fairness constraints have become a huge issue for researchers and engineers. <b>Machine</b> <b>learning</b> is used in courts to assess the likelihood of a defendant becoming a recidivist. It is used in different medical fields, in childhood welfare systems (pmlr-v81-chouldechova18a), and autonomous vehicles. All of these applications have a direct effect in our lives and ...", "dateLastCrawled": "2022-01-22T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The <b>measure and mismeasure of fairness: a critical review</b> of fair ...", "url": "https://blog.acolyer.org/2020/02/03/measure-mismeasure-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blog.acolyer.org/2020/02/03/measure-mismeasure-fairness", "snippet": "In case you\u2019re wondering where on earth I\u2019m going with this\u2026 it\u2019s a very stretched <b>analogy</b> I\u2019ve been playing with in my mind. One premise of many models of fairness in <b>machine</b> <b>learning</b> is that you can measure (\u2018prove\u2019) fairness of a <b>machine</b> <b>learning</b> model from within the system \u2013 i.e. from properties of the model itself and perhaps the data it is trained on. Beyond the questions of whether any one model of fairness is better or worse than another, I\u2019m coming to the ...", "dateLastCrawled": "2022-01-30T11:52:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(demographic parity)  is like +(achieving equivalent performance on training and validation datasets)", "+(demographic parity) is similar to +(achieving equivalent performance on training and validation datasets)", "+(demographic parity) can be thought of as +(achieving equivalent performance on training and validation datasets)", "+(demographic parity) can be compared to +(achieving equivalent performance on training and validation datasets)", "machine learning +(demographic parity AND analogy)", "machine learning +(\"demographic parity is like\")", "machine learning +(\"demographic parity is similar\")", "machine learning +(\"just as demographic parity\")", "machine learning +(\"demographic parity can be thought of as\")", "machine learning +(\"demographic parity can be compared to\")"]}