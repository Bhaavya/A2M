{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>True Positive Rate</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/true-positive-rate", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>true-positive-rate</b>", "snippet": "The hit <b>rate</b> (<b>true positive rate</b>, TPR i) is defined as rater i&#39;s <b>positive</b> response when the correct answer is <b>positive</b> ... It is the <b>number</b> of <b>true</b> <b>positives</b> divided by the total <b>number</b> of elements labeled as belonging to the <b>positive</b> class. (3) P r e c i s i o n = T P T P + F P \u2022 The accuracy (M4) provides general information about how many samples are misclassified: (4) A c c u r a c y = T P + T N T P + T N + F P + F N \u2022 Area under curve (AUC) (M5): This metric is the summary ...", "dateLastCrawled": "2022-02-02T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Using Linear <b>Discriminant Analysis</b> to Predict Customer Churn", "url": "https://blogs.oracle.com/ai-and-datascience/post/using-linear-discriminant-analysis-to-predict-customer-churn", "isFamilyFriendly": true, "displayUrl": "https://blogs.oracle.com/ai-and-datascience/post/using-linear-<b>discriminant-analysis</b>-to...", "snippet": "Sensitivity also called the <b>true</b> <b>positive</b> <b>rate</b> is defined as the proportion <b>of actual</b> <b>positives</b> <b>that are correctly</b> <b>identified</b> by the model. The sensitivity of the model is 12.7% which is very low. For a churn prediction model, it is important that the model picks up <b>positives</b> as <b>positives</b>. It is important to make an accurate prediction of customers who will churn which is given by sensitivity. We will now vary the threshold of the model from the default 50% to other values to decide on a ...", "dateLastCrawled": "2022-01-29T03:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Breast Cancer</b> Detection Using <b>Machine</b> <b>Learning</b> | by randerson112358 ...", "url": "https://randerson112358.medium.com/breast-cancer-detection-using-machine-learning-38820fe98982", "isFamilyFriendly": true, "displayUrl": "https://randerson112358.medium.com/<b>breast-cancer</b>-detection-using-<b>machine</b>-<b>learning</b>...", "snippet": "<b>True</b> <b>Positive</b> (TP) = Sensitivity (also called the <b>true</b> <b>positive</b> <b>rate</b>, ... measures the proportion <b>of actual</b> <b>positives</b> <b>that are correctly</b> <b>identified</b> <b>as such</b>. <b>True</b> Negative (TN) = Specificity (also called the <b>true</b> negative <b>rate</b>) measures the proportion <b>of actual</b> negatives <b>that are correctly</b> <b>identified</b> <b>as such</b>. False Negative (FN) = A test result that indicates that a condition does not hold, while in fact it does. For example a test result that indicates a person does not have cancer when the ...", "dateLastCrawled": "2022-01-31T17:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Titanic</b> Survival Prediction Using <b>Machine</b> <b>Learning</b> | by randerson112358 ...", "url": "https://betterprogramming.pub/titanic-survival-prediction-using-machine-learning-4c5ff1e3fa16", "isFamilyFriendly": true, "displayUrl": "https://betterprogramming.pub/<b>titanic</b>-survival-prediction-using-<b>machine</b>-<b>learning</b>-4c5ff...", "snippet": "<b>True</b> <b>Positive</b> (TP)= Sensitivity (also called the <b>true</b> <b>positive</b> <b>rate</b>, or probability of detection in some fields), measures the proportion <b>of actual</b> <b>positives</b> <b>that are correctly</b> <b>identified</b> <b>as such</b>. <b>True</b> Negative (TN)= Specificity (also called the <b>true</b> negative <b>rate</b>), measures the proportion <b>of actual</b> negatives <b>that are correctly</b> <b>identified</b> <b>as such</b>.", "dateLastCrawled": "2022-02-03T04:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Top 70+ <b>Data Science Interview Questions and Answers</b> for 2022", "url": "https://intellipaat.com/blog/interview-question/data-science-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-question/data-science-interview-", "snippet": "<b>True</b> <b>positive</b> <b>rate</b>: In <b>Machine</b> <b>Learning</b>, <b>true</b>-<b>positive</b> rates, which are also referred to as sensitivity or recall, are used to measure the percentage <b>of actual</b> <b>positives</b> which are <b>correctly</b> <b>identified</b>. Formula: <b>True</b> <b>Positive</b> <b>Rate</b> = <b>True</b> <b>Positives</b>/<b>Positives</b> False <b>positive</b> <b>rate</b>: False <b>positive</b> <b>rate</b> is basically the probability of falsely rejecting the null hypothesis for a particular test. The false-<b>positive</b> <b>rate</b> is calculated as the ratio between the <b>number</b> of negative events wrongly ...", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Beyond Accuracy: <b>Precision</b> and <b>Recall</b> | by Will Koehrsen | Towards Data ...", "url": "https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/beyond-accuracy-<b>precision</b>-and-<b>recall</b>-3da06bea9f6c", "snippet": "The precise definition of <b>recall</b> is the <b>number</b> of <b>true</b> <b>positives</b> divided by the <b>number</b> of <b>true</b> <b>positives</b> plus the <b>number</b> of false negatives. <b>True</b> <b>positives</b> are data point classified as <b>positive</b> by the model that actually are <b>positive</b> (meaning they are correct), and false negatives are data points the model identifies as negative that actually are <b>positive</b> (incorrect). In the terrorism case, <b>true</b> <b>positives</b> are <b>correctly</b> <b>identified</b> terrorists, and false negatives would be individuals the model ...", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Evaluation of Classification Model Accuracy</b>: Essentials - Articles - STHDA", "url": "http://www.sthda.com/english/articles/36-classification-methods-essentials/143-evaluation-of-classification-model-accuracy-essentials/", "isFamilyFriendly": true, "displayUrl": "www.sthda.com/english/articles/36-classification-methods-essentials/143-evaluation-of...", "snippet": "Since we don\u2019t usually know the probability cutoff in advance, the ROC curve is typically used to plot the <b>true</b> <b>positive</b> <b>rate</b> (or sensitivity on y-axis) against the false <b>positive</b> <b>rate</b> (or \u201c1-specificity\u201d on x-axis) at all possible probability cutoffs. This shows the trade off between the <b>rate</b> at which you can <b>correctly</b> predict something with the <b>rate</b> of incorrectly predicting something. Another visual representation of the ROC plot is to simply display the sensitive against the ...", "dateLastCrawled": "2022-02-03T05:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Confusion Matrix</b>, Accuracy, Precision, Recall, F1 Score | by ...", "url": "https://medium.com/analytics-vidhya/confusion-matrix-accuracy-precision-recall-f1-score-ade299cf63cd", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>confusion-matrix</b>-accuracy-precision-recall-f1...", "snippet": "Accuracy represents the <b>number</b> of <b>correctly</b> classified data instances over the total <b>number</b> of data instances. In this example, Accuracy = (55 + 30)/(55 + 5 + 30 + 10 ) = 0.85 and in percentage ...", "dateLastCrawled": "2022-02-02T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is <b>Sensitivity, Specificity, False positive, False negative</b>?", "url": "https://microbenotes.com/sensitivity-specificity-false-positive-false-negative/", "isFamilyFriendly": true, "displayUrl": "https://microbenotes.com/<b>sensitivity-specificity-false-positive-false-negative</b>", "snippet": "It is also known as the <b>True</b> Negative <b>Rate</b> (TNR), i.e the percentage of healthy people who are <b>correctly</b> <b>identified</b> as not having the condition. A test that can identify all sample tests from healthy individuals to be negative is very specific. Therefore, a test with 100% specificity <b>correctly</b> identifies all patients without the disease, while a test with 80% specificity <b>correctly</b> reports 80% of patients without the disease as test negative (<b>true</b> negatives) but 20% patients without the ...", "dateLastCrawled": "2022-02-02T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>Accuracy</b>, <b>Precision</b>, and Recall? And Why are they Important ...", "url": "https://shiffdag.medium.com/what-is-accuracy-precision-and-recall-and-why-are-they-important-ebfcb5a10df2", "isFamilyFriendly": true, "displayUrl": "https://shiffdag.medium.com/what-is-<b>accuracy</b>-<b>precision</b>-and-recall-and-why-are-they...", "snippet": "The <b>accuracy</b> of a <b>machine</b> <b>learning</b> classification <b>algorithm</b> is one way to assess how often model classifies a data point <b>correctly</b>. The numerator is total <b>number</b> of predictions that were correct. The denominator is the total <b>number</b> of predictions. The numerator will only include TP and TN and the denominator will be include TP, TN, FP, and FN. <b>Accuracy</b> is a ratio of the <b>correctly</b> classified data to the total amount of classifications made by the model. For Binary Classification the formula ...", "dateLastCrawled": "2022-02-02T22:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>True Positive Rate</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/true-positive-rate", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>true-positive-rate</b>", "snippet": "The hit <b>rate</b> (<b>true positive rate</b>, TPR i) is defined as rater i&#39;s <b>positive</b> response when the correct answer is <b>positive</b> ... It is the <b>number</b> of <b>true</b> <b>positives</b> divided by the total <b>number</b> of elements labeled as belonging to the <b>positive</b> class. (3) P r e c i s i o n = T P T P + F P \u2022 The accuracy (M4) provides general information about how many samples are misclassified: (4) A c c u r a c y = T P + T N T P + T N + F P + F N \u2022 Area under curve (AUC) (M5): This metric is the summary ...", "dateLastCrawled": "2022-02-02T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Key techniques for Evaluating <b>Machine</b> <b>Learning</b> models - Data Analytics", "url": "https://vitalflux.com/key-techniques-evaluating-machine-learning-models-performance/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/key-techniques-evaluating-<b>machine</b>-<b>learning</b>-models-performance", "snippet": "Precision is defined as the <b>true</b> <b>positive</b> <b>rate</b> and tells how many <b>actual</b> <b>positives</b> were <b>identified</b> among all the <b>positives</b> predicted <b>by the machine</b> <b>learning</b> model. Recall or sensitivity (<b>true</b> <b>positive</b> <b>rate</b>) is also known as <b>true</b> discovery; <b>rate</b>. This is the <b>machine</b> <b>learning</b> model\u2019s ability to find all <b>positive</b> instances in a data set. Confusion matrices can be generated for <b>machine</b> <b>learning</b> evaluation using different <b>machine</b> <b>learning</b> libraries. In the case of Python, scikit-learn provides ...", "dateLastCrawled": "2022-01-31T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Using Linear <b>Discriminant Analysis</b> to Predict Customer Churn", "url": "https://blogs.oracle.com/ai-and-datascience/post/using-linear-discriminant-analysis-to-predict-customer-churn", "isFamilyFriendly": true, "displayUrl": "https://blogs.oracle.com/ai-and-datascience/post/using-linear-<b>discriminant-analysis</b>-to...", "snippet": "Sensitivity also called the <b>true</b> <b>positive</b> <b>rate</b> is defined as the proportion <b>of actual</b> <b>positives</b> <b>that are correctly</b> <b>identified</b> by the model. The sensitivity of the model is 12.7% which is very low. For a churn prediction model, it is important that the model picks up <b>positives</b> as <b>positives</b>. It is important to make an accurate prediction of customers who will churn which is given by sensitivity. We will now vary the threshold of the model from the default 50% to other values to decide on a ...", "dateLastCrawled": "2022-01-29T03:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Top 70+ <b>Data Science Interview Questions and Answers</b> for 2022", "url": "https://intellipaat.com/blog/interview-question/data-science-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-question/data-science-interview-", "snippet": "<b>True</b> <b>positive</b> <b>rate</b>: In <b>Machine</b> <b>Learning</b>, <b>true</b>-<b>positive</b> rates, which are also referred to as sensitivity or recall, are used to measure the percentage <b>of actual</b> <b>positives</b> which are <b>correctly</b> <b>identified</b>. Formula: <b>True</b> <b>Positive</b> <b>Rate</b> = <b>True</b> <b>Positives</b>/<b>Positives</b> False <b>positive</b> <b>rate</b>: False <b>positive</b> <b>rate</b> is basically the probability of falsely rejecting the null hypothesis for a particular test. The false-<b>positive</b> <b>rate</b> is calculated as the ratio between the <b>number</b> of negative events wrongly ...", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Top 10 <b>model</b> <b>performance</b> <b>metrics</b> for classification ML models | by Juhi ...", "url": "https://towardsdatascience.com/top-10-model-evaluation-metrics-for-classification-ml-models-a0a0f1d51b9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/top-10-<b>model</b>-evaluation-<b>metrics</b>-for-classification-ml...", "snippet": "Recall/ Sensitivity/ TPR (<b>True</b> <b>Positive</b> <b>Rate</b>) attempts to answer the following question: What proportion <b>of actual</b> <b>positives</b> was <b>identified</b> <b>correctly</b>? Source: Wikipedia. This metric gives us 78% as the Recall score in the above image. Recall is generally used in use cases where the truth-detection is of utmost importance. For example: The cancer prediction, the stock market classification, etc. over here the problem statement requires that the False negatives be minimized which implies ...", "dateLastCrawled": "2022-02-02T17:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | <b>Machine</b> ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/crash-course/classification/<b>true</b>-false...", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Understanding and using sensitivity, specificity and predictive values", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2636062", "snippet": "In cell \u2032a,\u2032 we enter those in whom the test in question <b>correctly</b> diagnosed the disease (as determined by the gold standard). In other words, the test is <b>positive</b>, as is the gold standard. These are the <b>true</b> <b>positives</b> (TP). In cell \u2032b,\u2032 we enter those who have <b>positive</b> results for the test in question but do not have disease according to the \u2032gold standard test.\u2032 The newer test has wrongly diagnosed the disease: These are false <b>positives</b> (FP). In cell \u2032c,\u2032 we enter those who ...", "dateLastCrawled": "2022-01-30T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Precision, Recall, Sensitivity and Specificity", "url": "https://iq.opengenus.org/precision-recall-sensitivity-specificity/", "isFamilyFriendly": true, "displayUrl": "https://iq.opengenus.org/precision-recall-sensitivity-specificity", "snippet": "All of the workers at an industry are undergoing a <b>machine</b> <b>learning</b>, primary diabetes scan. The majority of these tasks are of classification. This is especially <b>true</b> in binary classification. The output is always Boolean, indicating it is either <b>True</b> or False. The output is either Diabetic (+ve or <b>True</b>) or healthy (-ve or False). There are only four possible outcomes for any worker X. <b>True</b> <b>positive</b> (TP): Prediction is +ve and X is diabetic, Hit, this is what we desire. <b>True</b> negative (TN ...", "dateLastCrawled": "2022-01-31T23:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Python Examples - Data Science, <b>Machine</b> <b>Learning</b>, AI", "url": "https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>accuracy-precision-recall-f1-score-python</b>-example", "snippet": "Model accuracy is a <b>machine</b> <b>learning</b> model performance metric that is defined as the ratio of <b>true</b> <b>positives</b> and <b>true</b> negatives to all <b>positive</b> and negative observations. In other words, accuracy tells us how often we can expect our <b>machine</b> <b>learning</b> model will <b>correctly</b> predict an outcome out of the total <b>number</b> of times it made predictions. For example: Let\u2019s assume that you were testing your <b>machine</b> <b>learning</b> model with a dataset of 100 records and that your <b>machine</b> <b>learning</b> model ...", "dateLastCrawled": "2022-02-02T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Confusion Matrix</b>, Accuracy, Precision, Recall, F1 Score | by ...", "url": "https://medium.com/analytics-vidhya/confusion-matrix-accuracy-precision-recall-f1-score-ade299cf63cd", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>confusion-matrix</b>-accuracy-precision-recall-f1...", "snippet": "The predicted outcome (pregnancy +ve or -ve) using a <b>machine</b> <b>learning</b> <b>algorithm</b> is termed as the predicted label and the <b>true</b> outcome (in this case which we know from doctor\u2019s/expert\u2019s record ...", "dateLastCrawled": "2022-02-02T15:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Beyond Accuracy: <b>Precision</b> and <b>Recall</b> | by Will Koehrsen | Towards Data ...", "url": "https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/beyond-accuracy-<b>precision</b>-and-<b>recall</b>-3da06bea9f6c", "snippet": "The precise definition of <b>recall</b> is the <b>number</b> of <b>true</b> <b>positives</b> divided by the <b>number</b> of <b>true</b> <b>positives</b> plus the <b>number</b> of false negatives. <b>True</b> <b>positives</b> are data point classified as <b>positive</b> by the model that actually are <b>positive</b> (meaning they are correct), and false negatives are data points the model identifies as negative that actually are <b>positive</b> (incorrect). In the terrorism case, <b>true</b> <b>positives</b> are <b>correctly</b> <b>identified</b> terrorists, and false negatives would be individuals the model ...", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Top 70+ <b>Data Science Interview Questions and Answers</b> for 2022", "url": "https://intellipaat.com/blog/interview-question/data-science-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-question/data-science-interview-", "snippet": "<b>True</b> <b>positive</b> <b>rate</b>: In <b>Machine</b> <b>Learning</b>, <b>true</b>-<b>positive</b> rates, which are also referred to as sensitivity or recall, are used to measure the percentage <b>of actual</b> <b>positives</b> which are <b>correctly</b> <b>identified</b>. Formula: <b>True</b> <b>Positive</b> <b>Rate</b> = <b>True</b> <b>Positives</b>/<b>Positives</b> False <b>positive</b> <b>rate</b>: False <b>positive</b> <b>rate</b> is basically the probability of falsely rejecting the null hypothesis for a particular test. The false-<b>positive</b> <b>rate</b> is calculated as the ratio between the <b>number</b> of negative events wrongly ...", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "Recall is the <b>number</b> of <b>True</b> <b>Positives</b> divided by the <b>number</b> of <b>True</b> <b>Positives</b> and the <b>number</b> of False Negatives. Put another way it is the <b>number</b> of <b>positive</b> predictions divided by the <b>number</b> of <b>positive</b> class values in the test data. It is also called Sensitivity or the <b>True</b> <b>Positive</b> <b>Rate</b>. Recall <b>can</b> <b>be thought</b> of as a measure of a classifiers completeness. A low recall indicates many False Negatives. F1 Score (or F-score): A weighted average of precision and recall. I would also advise ...", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Introduction to <b>Machine</b> <b>Learning</b>, Neural Networks, and Deep <b>Learning</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7347027/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7347027", "snippet": "A receiver operating characteristic curve evaluates a model&#39;s <b>true</b> <b>positive</b> <b>rate</b> (TPR; i.e., sensitivity, recall), the <b>number</b> of samples <b>correctly</b> <b>identified</b> as <b>positive</b> divided by the total <b>number</b> of <b>positive</b> samples, versus its false-<b>positive</b> <b>rate</b> (FPR; i.e., 1 - specificity), the <b>number</b> of samples incorrectly <b>identified</b> as <b>positive</b> divided by the total <b>number</b> of negative samples (Fig. 3, Fig. 4 A).8, 9 Similarly, the precision-recall curve evaluates a model&#39;s <b>positive</b> predictive value ...", "dateLastCrawled": "2022-02-02T05:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Navigating the pitfalls of applying <b>machine</b> <b>learning</b> in genomics ...", "url": "https://www.nature.com/articles/s41576-021-00434-9", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41576-021-00434-9", "snippet": "The <b>true</b> <b>positive</b> <b>rate</b> (also known as \u2018recall\u2019 and \u2018power\u2019) is the <b>number</b> of <b>true</b> <b>positives</b> divided by the total <b>number</b> of <b>positives</b>. The false <b>positive</b> <b>rate</b> (FPR) is the <b>number</b> of false ...", "dateLastCrawled": "2022-02-01T15:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Classification: <b>Precision</b> and Recall | <b>Machine</b> <b>Learning</b> Crash Course ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/crash-course/classification/<b>precision</b>...", "snippet": "<b>Precision</b> = T P T P + F P = 8 8 + 2 = 0.8. Recall measures the percentage <b>of actual</b> spam emails that were <b>correctly</b> classified\u2014that is, the percentage of green dots that are to the right of the threshold line in Figure 1: Recall = T P T P + F N = 8 8 + 3 = 0.73. Figure 2 illustrates the effect of increasing the classification threshold. Figure 2.", "dateLastCrawled": "2022-01-30T23:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Accuracy, Recall, <b>Precision</b>, F-Score &amp; Specificity, which to optimize ...", "url": "https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/accuracy-recall-<b>precision</b>-f-score-specificity-which-to...", "snippet": "A school is running a <b>machine</b> <b>learning</b> primary diabetes scan on all of its students. The output is either diabetic (+ve) or healthy (-ve). There are only 4 cases any st u dent X could end up with. We\u2019ll be using the following as a reference later, So don\u2019t hesitate to re-read it if you get confused. <b>True</b> <b>positive</b> (TP): Prediction is +ve and X is diabetic, we want that; <b>True</b> negative (TN): Prediction is -ve and X is healthy, we want that too; False <b>positive</b> (FP): Prediction is +ve and X ...", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Confused About The Confusion Matrix? Learn All About It | by Kambria ...", "url": "https://medium.com/kambria-network/confused-about-the-confusion-matrix-learn-all-about-it-aadf922e0abe?source=post_internal_links---------7-------------------------------", "isFamilyFriendly": true, "displayUrl": "https://medium.com/kambria-network/confused-about-the-confusion-matrix-learn-all-about...", "snippet": "Figure 1: Basic parameters. Recall. The term recall refers to the proportion of genuine <b>positive</b> examples that a predictive model has <b>identified</b>. To put that another way, it is the <b>number</b> of <b>true</b> ...", "dateLastCrawled": "2021-11-11T15:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is <b>Sensitivity, Specificity, False positive, False negative</b>?", "url": "https://microbenotes.com/sensitivity-specificity-false-positive-false-negative/", "isFamilyFriendly": true, "displayUrl": "https://microbenotes.com/<b>sensitivity-specificity-false-positive-false-negative</b>", "snippet": "It is also known as the <b>True</b> Negative <b>Rate</b> (TNR), i.e the percentage of healthy people who are <b>correctly</b> <b>identified</b> as not having the condition. A test that <b>can</b> identify all sample tests from healthy individuals to be negative is very specific. Therefore, a test with 100% specificity <b>correctly</b> identifies all patients without the disease, while a test with 80% specificity <b>correctly</b> reports 80% of patients without the disease as test negative (<b>true</b> negatives) but 20% patients without the ...", "dateLastCrawled": "2022-02-02T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "AWS Certification - <b>Machine Learning Concepts</b> - Cheat Sheet", "url": "https://jayendrapatil.com/aws-certification-machine-learning-concepts-cheat-sheet/", "isFamilyFriendly": true, "displayUrl": "https://jayendrapatil.com/aws-certification-<b>machine-learning-concepts</b>-cheat-sheet", "snippet": "Confusion matrix shows that of the 19 samples that actually had tumors, the model <b>correctly</b> classified 18 as having tumors (18 <b>true</b> <b>positives</b>), and incorrectly classified 1 as not having a tumor (1 false negative).; Similarly, of 458 samples that actually did not have tumors, 452 were <b>correctly</b> classified (452 <b>true</b> negatives) and 6 were incorrectly classified (6 false <b>positives</b>). Confusion matrix for a multi-class classification problem <b>can</b> help you determine mistake patterns.For example, a ...", "dateLastCrawled": "2022-01-21T14:24:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>True Positive Rate</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/true-positive-rate", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>true-positive-rate</b>", "snippet": "The hit <b>rate</b> (<b>true positive rate</b>, TPR i) is defined as rater i&#39;s <b>positive</b> response when the correct answer is <b>positive</b> ... It is the <b>number</b> of <b>true</b> <b>positives</b> divided by the total <b>number</b> of elements labeled as belonging to the <b>positive</b> class. (3) P r e c i s i o n = T P T P + F P \u2022 The accuracy (M4) provides general information about how many samples are misclassified: (4) A c c u r a c y = T P + T N T P + T N + F P + F N \u2022 Area under curve (AUC) (M5): This metric is the summary ...", "dateLastCrawled": "2022-02-02T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | <b>Machine</b> ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/crash-course/classification/<b>true</b>-false...", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Beyond Accuracy: <b>Precision</b> and <b>Recall</b> | by Will Koehrsen | Towards Data ...", "url": "https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/beyond-accuracy-<b>precision</b>-and-<b>recall</b>-3da06bea9f6c", "snippet": "The precise definition of <b>recall</b> is the <b>number</b> of <b>true</b> <b>positives</b> divided by the <b>number</b> of <b>true</b> <b>positives</b> plus the <b>number</b> of false negatives. <b>True</b> <b>positives</b> are data point classified as <b>positive</b> by the model that actually are <b>positive</b> (meaning they are correct), and false negatives are data points the model identifies as negative that actually are <b>positive</b> (incorrect). In the terrorism case, <b>true</b> <b>positives</b> are <b>correctly</b> <b>identified</b> terrorists, and false negatives would be individuals the model ...", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What would you do if you have dataset with low <b>true</b> <b>positive</b> ratio as ...", "url": "https://www.quora.com/What-would-you-do-if-you-have-dataset-with-low-true-positive-ratio-as-compared-to-false-positive-How-would-you-modify-your-deep-learning-architecture", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-would-you-do-if-you-have-dataset-with-low-<b>true</b>-<b>positive</b>...", "snippet": "Answer: Sorry, but your question is unclear. A data set normally does not contain \u201c<b>true</b> <b>positive</b>\u201d or \u201cfalse <b>positive</b>\u201d. A data set (with binary labels) will ...", "dateLastCrawled": "2022-01-10T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>ROC Analysis with Practical Example</b> of <b>Machine</b> <b>Learning</b> <b>Algorithm</b> | by ...", "url": "https://towardsdatascience.com/roc-analysis-with-practical-example-f899cd10dd47", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>roc-analysis-with-practical-example</b>-f899cd10dd47", "snippet": "<b>ROC Analysis with Practical Example</b> of <b>Machine</b> <b>Learning</b> <b>Algorithm</b>. A Step by Step Guide of Receiver Operating Curve with Confusion Matrix. Imran Bangash . Nov 15, 2020 \u00b7 6 min read. Photo by Myriam Jessier on Unsplash. In <b>machine</b> <b>learning</b> applications, classification algorithms are used to get a prediction on the data stream in order to label objects for further analysis. In <b>such</b> applications, not only the accuracy of classification algorithms is important but also the sensitivity or <b>true</b> ...", "dateLastCrawled": "2022-01-13T06:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is False <b>Positive</b> <b>Rate</b> - Deepchecks", "url": "https://deepchecks.com/glossary/false-positive-rate/", "isFamilyFriendly": true, "displayUrl": "https://deepchecks.com/glossary/false-<b>positive</b>-<b>rate</b>", "snippet": "What is the false-<b>positive</b> <b>rate</b> in <b>machine</b> <b>learning</b>? A False <b>Positive</b> <b>Rate</b> is a metric that <b>can</b> be used to assess <b>machine</b> <b>learning</b> accuracy. A model must have some notion of \u201cground reality,\u201d or the <b>true</b> state of things, in order to get a reading on its <b>true</b> accuracy. The accuracy of models <b>can</b> then be directly evaluated by comparing their outputs to the ground reality. This is most common with supervised <b>learning</b> methods, where the ground truth is a set of labels that classify and ...", "dateLastCrawled": "2022-01-13T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "10.3 - <b>Sensitivity</b>, Specificity, <b>Positive</b> Predictive Value, and ...", "url": "https://online.stat.psu.edu/stat507/lesson/10/10.3", "isFamilyFriendly": true, "displayUrl": "https://online.stat.psu.edu/stat507/lesson/10/10.3", "snippet": "Cell A contains <b>true</b> <b>positives</b>, subjects with the disease and <b>positive</b> test results. Cell D subjects do not have the disease and the test agrees. A good test will have minimal numbers in cells B and C. Cell B identifies individuals without disease but for whom the test indicates &#39;disease&#39;. These are false <b>positives</b>. Cell C has the false negatives.", "dateLastCrawled": "2022-02-02T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Using Linear <b>Discriminant Analysis</b> to Predict Customer Churn", "url": "https://blogs.oracle.com/ai-and-datascience/post/using-linear-discriminant-analysis-to-predict-customer-churn", "isFamilyFriendly": true, "displayUrl": "https://blogs.oracle.com/ai-and-datascience/post/using-linear-<b>discriminant-analysis</b>-to...", "snippet": "Sensitivity also called the <b>true</b> <b>positive</b> <b>rate</b> is defined as the proportion <b>of actual</b> <b>positives</b> <b>that are correctly</b> <b>identified</b> by the model. The sensitivity of the model is 12.7% which is very low. For a churn prediction model, it is important that the model picks up <b>positives</b> as <b>positives</b>. It is important to make an accurate prediction of customers who will churn which is given by sensitivity. We will now vary the threshold of the model from the default 50% to other values to decide on a ...", "dateLastCrawled": "2022-01-29T03:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is <b>Accuracy</b>, <b>Precision</b>, and Recall? And Why are they Important ...", "url": "https://shiffdag.medium.com/what-is-accuracy-precision-and-recall-and-why-are-they-important-ebfcb5a10df2", "isFamilyFriendly": true, "displayUrl": "https://shiffdag.medium.com/what-is-<b>accuracy</b>-<b>precision</b>-and-recall-and-why-are-they...", "snippet": "The <b>accuracy</b> of a <b>machine</b> <b>learning</b> classification <b>algorithm</b> is one way to assess how often model classifies a data point <b>correctly</b>. The numerator is total <b>number</b> of predictions that were correct. The denominator is the total <b>number</b> of predictions. The numerator will only include TP and TN and the denominator will be include TP, TN, FP, and FN. <b>Accuracy</b> is a ratio of the <b>correctly</b> classified data to the total amount of classifications made by the model. For Binary Classification the formula ...", "dateLastCrawled": "2022-02-02T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is <b>True</b> Negative, and a pregnant woman whose test results say \u201cPregnant\u201d is <b>True</b> <b>Positive</b>. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning Accuracy</b>: <b>True</b> vs. False <b>Positive</b>/Negative", "url": "https://research.aimultiple.com/machine-learning-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://research.aimultiple.com/<b>machine-learning-accuracy</b>", "snippet": "There are various theoretical approaches to measuring accuracy* of competing <b>machine</b> <b>learning</b> models however, in most commercial applications, you simply need to assign a business value to 4 types of results: <b>true</b> positives, <b>true</b> negatives, false positives and false negatives.By multiplying number of results in each bucket with the associated business values, you will ensure that you use the best model available.", "dateLastCrawled": "2022-02-03T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "It essentially shows the <b>True</b> <b>Positive</b> <b>Rate</b> (TPR) against the False <b>Positive</b> <b>Rate</b> (FPR) for various threshold values. AUC The Area Under the Curve (AUC), is an aggregated measure of performance of a binary classifier on all possible threshold values (and therefore it is threshold invariant). AUC calculates the area under the ROC curve, and therefore it is between 0 and 1. One way of interpreting AUC is the probability that the model ranks a random <b>positive</b> example more highly than a random ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) A Comparison of Various <b>Machine</b> <b>Learning</b> Algorithms in a ...", "url": "https://www.academia.edu/68902781/A_Comparison_of_Various_Machine_Learning_Algorithms_in_a_Distributed_Denial_of_Service_Intrusion", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/68902781/A_Comparison_of_Various_<b>Machine</b>_<b>Learning</b>_Algorithms...", "snippet": "2) <b>True</b> <b>Positive</b> <b>Rate</b> (TPR) 4) Decision Tree (DT) This metric calculates how often the model is able to predict a This algorithm uses a tree structure <b>analogy</b> to represent a <b>positive</b> result correctly. Similar to Accuracy, but difference is series of rules that lead to a class or value [16]. It starts with a it only takes <b>positive</b> observation. root node, which is the best predictor. Then, it progresses TPR:: \ud835\udc47\ud835\udc43 through branch nodes to other predictors. Ultimately it reaches \ud835\udc47\ud835\udc43 ...", "dateLastCrawled": "2022-02-05T20:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The Receiver Operating Curve (ROC) and The Scale \u2014 Understanding ROC ...", "url": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the-scale-understanding-roc-through-an-analogy-8b8f9d954f84", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the...", "snippet": "The <b>rate</b> of <b>True</b> Positives is also called Sensitivity. Similarly, the <b>rate</b> of False Positives means counting the False Positives as part of the actual Negatives. In other words, represents the ...", "dateLastCrawled": "2021-02-13T00:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning from positive</b> and unlabeled data: a survey - <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "The SCAR assumption was introduced in <b>analogy</b> with the Missing Completely A Random assumption (MCAR) that is common when ... the <b>true</b> <b>positive</b> <b>rate</b>, the false <b>positive</b> <b>rate</b>, and precision. Hence, it is possible in this circumstance to report estimates of these metrics. PU <b>learning</b> methods. This section provides an overview of the methods that address PU <b>learning</b>. Most methods can be divided into the following three categories: Two-step techniques, biased <b>learning</b> and class prior ...", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is <b>True</b> Negative, and a pregnant woman whose test results say \u201cPregnant\u201d is <b>True</b> <b>Positive</b>. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Evaluation Metric Special ROC-AUC Candra\u2019s blog", "url": "https://saltfarmer.github.io/blog/machine%20learning/Evaluation-Metrics-Special-ROCAUC/", "isFamilyFriendly": true, "displayUrl": "https://saltfarmer.github.io/blog/<b>machine</b> <b>learning</b>/Evaluation-Metrics-Special-ROCAUC", "snippet": "The ROC curve is created by plotting the <b>true</b> <b>positive</b> <b>rate</b> (TPR) against the false <b>positive</b> <b>rate</b> (FPR) at various threshold settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s ...", "dateLastCrawled": "2022-02-03T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fairness Metrics - Data Analytics - Data Science, <b>Machine</b> <b>Learning</b>, AI", "url": "https://vitalflux.com/fairness-metrics-ml-model-sensitivity-bias-detection/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>fairness-metrics-ml-model-sensitivity</b>-bias-detection", "snippet": "There are many different ways in which <b>machine</b> <b>learning</b> ... Recall that Sensitivity is defined as the percentage of <b>true</b> positives or the <b>rate</b> of <b>true</b> positives. In simpler words, Sensitivity is the measure of the extent to which the model is correct in making <b>true</b> predictions about the <b>positive</b> cases. Mathematically, it can be represented as the following: Sensitivity = <b>True</b> <b>Positive</b> Predictions / Actual <b>Positive</b> Cases The above could also be represented as a function of predictions as ...", "dateLastCrawled": "2022-01-20T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "ROC (Receiver Operating Characteristic curve): A curve of <b>true</b> <b>positive</b> <b>rate</b> vs. false <b>positive</b> <b>rate</b> at different classification thresholds. The x-axis is False <b>Positive</b> <b>rate</b>, and the y-axis is <b>True</b> <b>Positive</b> <b>rate</b>. [3] . Close to the up left point (TPR=1.0, FPR=0.0) indicates the model is better.", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Chi-squared tests to <b>compare two machine learning models and determine</b> ...", "url": "https://towardsdatascience.com/chi-squared-tests-to-compare-two-machine-learning-models-and-determine-whether-they-are-random-2a405fc55181", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/chi-squared-tests-to-compare-two-<b>machine</b>-<b>learning</b>...", "snippet": "Take T as the random variable describing the number of <b>true</b> <b>positive</b> instances (Heads by the coin <b>analogy</b>). Doesn\u2019t T follow a binomial distribution with p=0.65 (probability of <b>positive</b>) and n=69 (total data instances)? Sure it does. I assume you know that binomial distribution can be approximated from a normal distribution, provided both np and n(1-p) exceed 10. Accordingly, we get a normal variable z~N(0,1)", "dateLastCrawled": "2022-01-29T04:24:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "On <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> - Online courses and text books ...", "url": "https://www.linkedin.com/pulse/machine-learning-deep-online-courses-text-books-point-ajay-taneja-1f", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/<b>machine</b>-<b>learning</b>-deep-online-courses-text-books-point...", "snippet": "On <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> - Online courses and text books - A point of view \u2013 Evaluation Metrics (Part 2) Published on October 4, 2020 October 4, 2020 \u2022 8 Likes \u2022 0 Comments", "dateLastCrawled": "2021-08-15T14:28:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(true positive rate)  is like +(number of actual positives that are correctly identified as such by the machine learning algorithm)", "+(true positive rate) is similar to +(number of actual positives that are correctly identified as such by the machine learning algorithm)", "+(true positive rate) can be thought of as +(number of actual positives that are correctly identified as such by the machine learning algorithm)", "+(true positive rate) can be compared to +(number of actual positives that are correctly identified as such by the machine learning algorithm)", "machine learning +(true positive rate AND analogy)", "machine learning +(\"true positive rate is like\")", "machine learning +(\"true positive rate is similar\")", "machine learning +(\"just as true positive rate\")", "machine learning +(\"true positive rate can be thought of as\")", "machine learning +(\"true positive rate can be compared to\")"]}