{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in the medical field: A systematic mapping and review ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "snippet": "Methods: This review was carried out according to the well-known systematic <b>map</b> and review process to analyze the literature on <b>interpretability</b> techniques when applied in the medical field with regard to different aspects: publication venues and publication year, contribution and empirical types, medical and ML disciplines and objectives, ML black-box techniques interpreted, <b>interpretability</b> techniques investigated, their performance and the best performing techniques, and lastly, the ...", "dateLastCrawled": "2022-01-23T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Interpretability</b> in the medical field: A systematic mapping and ...", "url": "https://www.researchgate.net/publication/357475684_Interpretability_in_the_medical_field_A_systematic_mapping_and_review_study", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357475684_<b>Interpretability</b>_in_the_medical...", "snippet": "Methods: This review was carried out according to the well-known systematic <b>map</b> and review process to analyze the literature on <b>interpretability</b> techniques when applied in the medical field with ...", "dateLastCrawled": "2022-01-26T13:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Local computational methods to improve the interpretability</b> and ...", "url": "https://europepmc.org/article/PMC/PMC7902670", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC7902670", "snippet": "Cryo-electron microscopy (cryo-EM) maps usually show heterogeneous distributions of B-factors and electron density occupancies and are typically B-factor sharpened to improve their contrast and <b>interpretability</b> at high-resolutions.However, \u2018over-sharpening\u2019 due to the application of a single global B-factor can distort processed maps causing connected densities to appear broken and disconnected.This issue limits the <b>interpretability</b> of cryo-EM maps, i.e. ab initio modelling.", "dateLastCrawled": "2021-03-16T18:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Local computational methods to improve the interpretability</b> and ...", "url": "https://www.nature.com/articles/s41467-021-21509-5", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-021-21509-5", "snippet": "The amplitude <b>map</b> m \u03c9 (r) is related to the \u2018strength\u2019 of the local <b>map</b> signal at resolution 1/\u03c9, while the phase <b>map</b> refers to its shape and it is limited to the [\u22121, +1] range.The ...", "dateLastCrawled": "2022-01-26T08:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Transparency of Deep Neural Networks for Medical Image Analysis: A ...", "url": "https://deepai.org/publication/transparency-of-deep-neural-networks-for-medical-image-analysis-a-review-of-interpretability-methods", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/transparency-of-deep-neural-networks-for-medical-image...", "snippet": "Transparency of Deep Neural Networks for Medical Image Analysis: A Review of <b>Interpretability</b> Methods. 11/01/2021 \u2219 by Zohaib Salahuddin, et al. \u2219 Maastricht University \u2219 22 \u2219 share . Artificial Intelligence has emerged as a useful aid in numerous clinical applications for diagnosis and treatment decisions. Deep neural networks have shown same or better performance than clinicians in many tasks owing to the rapid increase in the available data and computational power.", "dateLastCrawled": "2021-12-07T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Interpreting Deep Learning Models - GitHub Pages", "url": "https://ttumiel.github.io/blog/interp/", "isFamilyFriendly": true, "displayUrl": "https://ttumiel.github.io/blog/interp", "snippet": "The growing field of machine learning <b>interpretability</b> attempts to address this problem by applying various methods to uncover the reasoning behind a network&#39;s predictions, which helps the user of the model address failures and apply fixes. This is particularly important in applications that require a human to trust a model, such as in medical imaging. In this post, we will take a brief look at several methods of <b>interpretability</b>. Roadmap. First, let&#39;s plot our course for discussing ...", "dateLastCrawled": "2021-10-11T06:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Building Data-driven Models with Microstructural Images: Generalization ...", "url": "https://deepai.org/publication/building-data-driven-models-with-microstructural-images-generalization-and-interpretability", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/building-data-driven-models-with-microstructural-images...", "snippet": "Because of the known dependence of macroscopic properties on material microstructure, scanning electron <b>microscope</b> (SEM) images are a commonly collected data type for a wide range of different material categories. However, using these SEMs in data-driven methods is not straightforward because the data come in the form of images, not scalar data. These images can be represented as 2-dimensional or 3-dimensional (in the case of color images) arrays. The convolutional neural network (CNN) is a ...", "dateLastCrawled": "2022-01-03T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deep <b>multiple instance learning for digital histopathology</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/B9780128161760000272", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/B9780128161760000272", "snippet": "In the medical imaging domain <b>interpretability</b> is <b>a key</b> attribute of any machine learning method. Gaining insight in the inner workings of a machine learning model is of special interest for human doctors to properly analyze the diagnosis and prescribe appropriate treatment. For example, in digital pathology such a model can be used to highlight Regions Of Interest (ROI) that can be examined by a pathologist. ROIs could serve as indicators for \u201cwhere-to-look\u201d parts of an image and can ...", "dateLastCrawled": "2021-12-24T00:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "OpenAI launhes Mircoscope with Lucid Library to help unravel neural ...", "url": "https://www.technowize.com/openai-launches-mircoscope-with-lucid-library-to-help-unravel-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.technowize.com/openai-launches-mircoscope-with-lucid-library-to-help...", "snippet": "<b>Microscope</b> and the Lucid library will be a major help in model <b>interpretability</b>. Understanding neuron relationships is fundamental to understanding deep learning models and <b>Microscope</b> and Lucid ...", "dateLastCrawled": "2022-01-26T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[3dem] [ccpem] Which resolution?", "url": "https://mail.ncmir.ucsd.edu/pipermail/3dem/2020-February/007527.html", "isFamilyFriendly": true, "displayUrl": "https://mail.ncmir.ucsd.edu/pipermail/3dem/2020-February/007527.html", "snippet": "&gt; If we completely ignore prior information about what proteins look <b>like</b> - &gt; what does the \u2018<b>interpretability</b>&#39; of an EM <b>map</b> mean? Surely that would have &gt; to involve distinguishing \u2018signal\u2019 from \u2018noise\u2019 without relating it to &gt; 0.5FOM, i.e. a sigma factor FSC threshold.", "dateLastCrawled": "2021-07-16T09:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in the medical field: A systematic mapping and review ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "snippet": "Methods: This review was carried out according to the well-known systematic <b>map</b> and review process to analyze the literature on <b>interpretability</b> techniques when applied in the medical field with regard to different aspects: publication venues and publication year, contribution and empirical types, medical and ML disciplines and objectives, ML black-box techniques interpreted, <b>interpretability</b> techniques investigated, their performance and the best performing techniques, and lastly, the ...", "dateLastCrawled": "2022-01-23T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Interpretability</b> in the medical field: A systematic mapping and ...", "url": "https://www.researchgate.net/publication/357475684_Interpretability_in_the_medical_field_A_systematic_mapping_and_review_study", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357475684_<b>Interpretability</b>_in_the_medical...", "snippet": "Methods: This review was carried out according to the well-known systematic <b>map</b> and review process to analyze the literature on <b>interpretability</b> techniques when applied in the medical field with ...", "dateLastCrawled": "2022-01-26T13:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Transparency of Deep Neural Networks for Medical Image Analysis: A ...", "url": "https://deepai.org/publication/transparency-of-deep-neural-networks-for-medical-image-analysis-a-review-of-interpretability-methods", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/transparency-of-deep-neural-networks-for-medical-image...", "snippet": "Transparency of Deep Neural Networks for Medical Image Analysis: A Review of <b>Interpretability</b> Methods. 11/01/2021 \u2219 by Zohaib Salahuddin, et al. \u2219 Maastricht University \u2219 22 \u2219 share . Artificial Intelligence has emerged as a useful aid in numerous clinical applications for diagnosis and treatment decisions. Deep neural networks have shown same or better performance than clinicians in many tasks owing to the rapid increase in the available data and computational power.", "dateLastCrawled": "2021-12-07T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Interpreting Deep Learning Models - GitHub Pages", "url": "https://ttumiel.github.io/blog/interp/", "isFamilyFriendly": true, "displayUrl": "https://ttumiel.github.io/blog/interp", "snippet": "The growing field of machine learning <b>interpretability</b> attempts to address this problem by applying various methods to uncover the reasoning behind a network&#39;s predictions, which helps the user of the model address failures and apply fixes. This is particularly important in applications that require a human to trust a model, such as in medical imaging. In this post, we will take a brief look at several methods of <b>interpretability</b>. Roadmap. First, let&#39;s plot our course for discussing ...", "dateLastCrawled": "2021-10-11T06:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Local computational methods to improve the interpretability</b> and ...", "url": "https://europepmc.org/article/PMC/PMC7902670", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC7902670", "snippet": "The <b>map</b> densities are <b>similar</b> in the inner core of the protein as can be seen from the solid red rectangle in the figure, where we show a zoomed view of LocSpiral and Relion maps of the region indicated in the red rectangles over the maps. However, the <b>map</b> densities are quite different in the outer regions, where the Relion <b>map</b> shows thin and ...", "dateLastCrawled": "2021-03-16T18:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Local computational methods to improve the interpretability</b> and ...", "url": "https://www.nature.com/articles/s41467-021-21509-5", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-021-21509-5", "snippet": "The <b>map</b> densities are <b>similar</b> in the inner core of the protein as can be seen from the solid red rectangle in the figure, where we show a zoomed view of LocSpiral and Relion maps of the region ...", "dateLastCrawled": "2022-01-26T08:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep <b>multiple instance learning for digital histopathology</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/B9780128161760000272", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/B9780128161760000272", "snippet": "In the medical imaging domain <b>interpretability</b> is <b>a key</b> attribute of any machine learning method. Gaining insight in the inner workings of a machine learning model is of special interest for human doctors to properly analyze the diagnosis and prescribe appropriate treatment. For example, in digital pathology such a model can be used to highlight Regions Of Interest (ROI) that can be examined by a pathologist. ROIs could serve as indicators for \u201cwhere-to-look\u201d parts of an image and can ...", "dateLastCrawled": "2021-12-24T00:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Semantic Structure and Interpretability of Word Embeddings</b> | DeepAI", "url": "https://deepai.org/publication/semantic-structure-and-interpretability-of-word-embeddings", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>semantic-structure-and-interpretability-of-word-embeddings</b>", "snippet": "<b>Semantic Structure and Interpretability of Word Embeddings</b>. Dense word embeddings, which encode semantic meanings of words to low dimensional vector spaces have become very popular in natural language processing (NLP) research due to their state-of-the-art performances in many NLP tasks. Word embeddings are substantially successful in capturing ...", "dateLastCrawled": "2021-11-27T17:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "OpenAI launhes Mircoscope with Lucid Library to help unravel neural ...", "url": "https://www.technowize.com/openai-launches-mircoscope-with-lucid-library-to-help-unravel-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.technowize.com/openai-launches-mircoscope-with-lucid-library-to-help...", "snippet": "<b>Microscope</b> and the Lucid library will be a major help in model <b>interpretability</b>. Understanding neuron relationships is fundamental to understanding deep learning models and <b>Microscope</b> and Lucid ...", "dateLastCrawled": "2022-01-26T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[3dem] [ccpem] Which resolution?", "url": "https://mail.ncmir.ucsd.edu/pipermail/3dem/2020-February/007527.html", "isFamilyFriendly": true, "displayUrl": "https://mail.ncmir.ucsd.edu/pipermail/3dem/2020-February/007527.html", "snippet": "&gt; If we completely ignore prior information about what proteins look like - &gt; what does the \u2018<b>interpretability</b>&#39; of an EM <b>map</b> mean? Surely that would have &gt; to involve distinguishing \u2018signal\u2019 from \u2018noise\u2019 without relating it to &gt; 0.5FOM, i.e. a sigma factor FSC threshold.", "dateLastCrawled": "2021-07-16T09:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Probing Multiscale Disorder in Pyrochlore and Related Complex Oxides in ...", "url": "https://europepmc.org/article/PMC/PMC8668443", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC8668443", "snippet": "Pyrochlores <b>can</b> <b>be thought</b> of as ordered, oxygen-deficient fluorite superstructures, where the A 3+ cations substitute half the B 4+ fluorite cations and charge neutrality is maintained through the formation of oxygen vacancies on the 8(a) site (Chroneos et al., 2013). Both the cations and anions of pyrochlores are fully ordered on their respective sublattices, where A and B cations alternate along &lt;110&gt;. In addition to the fully-ordered pyrochlore and the disordered fluorite, there is a ...", "dateLastCrawled": "2022-01-05T05:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Frontiers | Probing Multiscale Disorder in Pyrochlore and Related ...", "url": "https://www.frontiersin.org/articles/10.3389/fchem.2021.743025/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fchem.2021.743025", "snippet": "Pyrochlores <b>can</b> <b>be thought</b> of as ordered, oxygen-deficient fluorite superstructures, where the A 3+ cations substitute half the B 4+ fluorite cations and charge neutrality is maintained through the formation of oxygen vacancies on the 8(a) site (Chroneos et al., 2013). Both the cations and anions of pyrochlores are fully ordered on their respective sublattices, where A and B cations alternate along &lt;110&gt;. In addition to the fully-ordered pyrochlore and the disordered fluorite, there is a ...", "dateLastCrawled": "2022-02-03T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Issues and Opportunities in the Application of Artificial Intelligence ...", "url": "https://smmc.ornl.gov/2018/wp-content/uploads/sites/2/2019/07/Womble-SMMC-2018-AI-approved-for-posting.pdf", "isFamilyFriendly": true, "displayUrl": "https://smmc.ornl.gov/2018/wp-content/uploads/sites/2/2019/07/Womble-SMMC-2018-AI...", "snippet": "\u2022 Definition 1: The scientific understanding of the mechanisms underlying <b>thought</b> and intelligent behavior and their embodiment in machines. (AAAI) \u2022 Definition 2: Computers trained to perform tasks that if performed by a human would be said to require intelligence \u2022 Definition 3: A class of data analytics algorithms in which the rules and/or models are not known a priori and are learned as part of the process Create Rules/Models Learning/Training Evaluation/ Inference Training data ...", "dateLastCrawled": "2021-11-18T10:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Deep Learning in Image Cytometry: A Review - Gupta - Wiley Online Library", "url": "https://onlinelibrary.wiley.com/doi/10.1002/cyto.a.23701", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1002/cyto.a.23701", "snippet": "In its simplest form a GAN <b>can</b> <b>be thought</b> of as instigating a zero-sum game between two networks\u2014a generator and a discriminator. The generator creates counterfeit data samples which it hopes to \u201cfool\u201d the discriminator with, while the discriminator attempts to correctly classify the real and fake samples. Convergence is reached when the discriminator <b>can</b> no longer differentiate between real and fake samples. However, convergence is not always guaranteed and GANs currently require ...", "dateLastCrawled": "2021-11-18T16:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Deep Learning in Image Cytometry: A Review. - Abstract - Europe PMC", "url": "https://europepmc.org/article/MED/30565841", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/30565841", "snippet": "In its simplest form a GAN <b>can</b> <b>be thought</b> of as instigating a zero\u2010sum game between two networks\u2014a generator and a discriminator. The generator creates counterfeit data samples which it hopes to \u201cfool\u201d the discriminator with, while the discriminator attempts to correctly classify the real and fake samples. Convergence is reached when the discriminator <b>can</b> no longer differentiate between real and fake samples. However, convergence is not always guaranteed and GANs currently require ...", "dateLastCrawled": "2021-06-24T09:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A sinusoidal transformation of the visual field is the basis for ...", "url": "https://www.sciencedirect.com/science/article/pii/S0896627321007261", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0896627321007261", "snippet": "The brain\u2019s maps of visual space are <b>thought</b> to preserve the topology of the retina ... Since the <b>map</b> in V1 <b>can</b> be abstracted as a duplicate of the visual field for our purposes, this simulation <b>can</b> also be interpreted as showing the connectivity between V1 and V2. If one connects regions in V1 along the sinusoid, one gets the banded <b>map</b> in V2 that matches functional data. Thus, the retinotopic maps in both V1 and V2 appear to be organized in a fashion that optimizes coverage of the visual ...", "dateLastCrawled": "2021-11-17T13:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "High-Throughput Methods in the Discovery and Study of Biomaterials and ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8154331/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8154331", "snippet": "Importantly, the surface physicochemical properties of the biomaterials <b>can</b> significantly affect the amount, orientation, and conformation of adsorbed proteins. 184 Interfacial interactions are <b>key</b> for implanted devices. 266 On one hand, proteins adsorbed onto the surface of biomaterials facilitate the activation of inflammatory cells. 267 On the other hand, the ECM proteins are also important signaling factors known to control cell attachment, and adjust subsequent cell activity ...", "dateLastCrawled": "2022-02-03T06:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Google AI Blog: Google Research: Themes from 2021 and Beyond", "url": "https://ai.googleblog.com/2022/01/google-research-themes-from-2021-and.html", "isFamilyFriendly": true, "displayUrl": "https://ai.googleblog.com/2022/01/google-research-themes-from-2021-and.html", "snippet": "Center: Probability <b>map</b> as predicted by MetNet-2. Right: ... Interactive analysis and debugging of models remains <b>key</b> to responsible use of ML. We have updated our Language <b>Interpretability</b> Tool with new capabilities and techniques to advance this line of work, including support for image and tabular data, a variety of features carried over from our previous work on the What-If Tool, and built-in support for fairness analysis through the technique of Testing with Concept Activation Vectors ...", "dateLastCrawled": "2022-02-03T16:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Human-Level Intelligence or Animal-Like Abilities</b>? | October 2018 ...", "url": "https://cacm.acm.org/magazines/2018/10/231373-human-level-intelligence-or-animal-like-abilities/fulltext", "isFamilyFriendly": true, "displayUrl": "https://cacm.acm.org/magazines/2018/10/231373", "snippet": "For example, one <b>can</b> now use learned functions to recognize cats in images without having to describe or model what a cat is, as originally <b>thought</b> and sought, by simply fitting a function based on labeled data of the form: (image, cat), (image, not cat). While this approach works better than modeling a cat (for now), it does not entail success in &quot;learning&quot; what a cat is, to the point where one <b>can</b> recognize, say, deformed images of cats or infer aspects of cats that are not relayed in the ...", "dateLastCrawled": "2022-01-12T11:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "On the nature and use of models in network <b>neuroscience</b> | Nature ...", "url": "https://www.nature.com/articles/s41583-018-0038-8", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41583-018-0038-8", "snippet": "Modern network <b>neuroscience</b> involves the use of various types of models to understand the brain. In this Review, Bassett, Zurn and Gold discuss the aims of this approach before examining how ...", "dateLastCrawled": "2022-02-01T04:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in the medical field: A systematic mapping and review ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "snippet": "<b>Interpretability</b> <b>can</b> be defined as the degree to which a human <b>can</b> understand the cause of a decision ... which <b>can</b> be explained by the fact that the results <b>can</b> <b>be compared</b> with other techniques evaluated on the same datasets and the availability of public datasets in the medical domain. Additionally, it is preferred to evaluate and interpret ML models on historical data before using real-time evaluation. 23% of the qualified studies were empirically evaluated using case study methods that ...", "dateLastCrawled": "2022-01-23T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Interpretability</b> in the medical field: A systematic mapping and ...", "url": "https://www.researchgate.net/publication/357475684_Interpretability_in_the_medical_field_A_systematic_mapping_and_review_study", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357475684_<b>Interpretability</b>_in_the_medical...", "snippet": "was <b>compared</b> against white-box models or other <b>interpretability</b> techniques by comparing the shifts in attribute ranks (a mean rank shift of 1.24), and expert knowledge was discussed qualita-", "dateLastCrawled": "2022-01-26T13:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Local computational methods to improve the interpretability</b> and ...", "url": "https://www.nature.com/articles/s41467-021-21509-5", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-021-21509-5", "snippet": "A <b>Map</b> obtained by LocSpiral approach (left) <b>compared</b> with the <b>map</b> as deposited in EMDB for EMD-21375. B B -factor maps to be used for sharpening (slope of the local Guinier plot multiplied by 4 ...", "dateLastCrawled": "2022-01-26T08:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Local computational methods to improve the interpretability</b> and ...", "url": "https://europepmc.org/article/PMC/PMC7902670", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC7902670", "snippet": "Cryo-electron microscopy (cryo-EM) maps usually show heterogeneous distributions of B-factors and electron density occupancies and are typically B-factor sharpened to improve their contrast and <b>interpretability</b> at high-resolutions.However, \u2018over-sharpening\u2019 due to the application of a single global B-factor <b>can</b> distort processed maps causing connected densities to appear broken and disconnected.This issue limits the <b>interpretability</b> of cryo-EM maps, i.e. ab initio modelling.", "dateLastCrawled": "2021-03-16T18:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Local computational methods to improve the interpretability</b> and ...", "url": "https://www.researchgate.net/publication/349528133_Local_computational_methods_to_improve_the_interpretability_and_analysis_of_cryo-EM_maps", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/349528133_Local_computational_methods_to...", "snippet": "approach (left) <b>compared</b> with the <b>map</b> as deposited in EMDB for EMD-21375. B B -factor maps to be used for sharpening (slope of the local Guinier plot multiplied by 4) obtained by LocBFactor ...", "dateLastCrawled": "2022-01-20T13:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Local computational methods to improve the <b>interpretability</b> and ...", "url": "https://www.biorxiv.org/content/10.1101/2020.05.11.088013v1.full.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.biorxiv.org/content/10.1101/2020.05.11.088013v1.full.pdf", "snippet": "reduced on the oscillating atoms <b>compared</b> to the atoms at rest (Sherwood, Cooper et al. 2011). B-factors <b>can</b> be further refined by model building packages, i.e. Phenix (Liebschner, Afonine et al. 2019) or Refmac (Winn, Murshudov et al. 2003) to improve the quality and accuracy of atomics models. Although B-factors are essential to \u2018sharpen ...", "dateLastCrawled": "2021-02-08T22:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Transparency of Deep Neural Networks for Medical Image Analysis: A ...", "url": "https://deepai.org/publication/transparency-of-deep-neural-networks-for-medical-image-analysis-a-review-of-interpretability-methods", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/transparency-of-deep-neural-networks-for-medical-image...", "snippet": "The <b>interpretability</b> of ProtoPNet does not come at a cost of performance when <b>compared</b> to black-box DL models. ... This attention mechanism not only improves classification performance but also produces a fine-grained attribution <b>map</b> that focuses on <b>key</b> parts of the image. The attention module calculates a compatibility score c s i between the local features l s i obtained from the convolutional layer s where i represents the spatial location within s and the global features g obtained from ...", "dateLastCrawled": "2021-12-07T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Building Data-driven Models with Microstructural Images: Generalization ...", "url": "https://deepai.org/publication/building-data-driven-models-with-microstructural-images-generalization-and-interpretability", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/building-data-driven-models-with-microstructural-images...", "snippet": "These characteristic textures <b>can</b> <b>be compared</b> to the SEM images of these classes in Fig. 4. The characteristic texture for the network class mimics the cell-like structures in this microconstituent. The characteristic texture for spheroidite is the same as the most important texture for the random forest classifier in this case, representing the dotted structure of spheroidite. For the pearlite microconstituent, the characteristic texture resembles long, thin lamellar structures.", "dateLastCrawled": "2022-01-03T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Using Fourier transform IR spectroscopy to analyze biological materials", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4480339/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4480339", "snippet": "The absorbance intensity at each spectral point within the <b>map</b> becomes an individual pixel in the resultant pseudocolor images, which <b>can</b> give details of how different biomolecules vary across the target area. In contrast to aperture-based systems, non-aperture-based instruments such as FPA and linear array detectors provide imaging using spatially arranged detectors. Multielement detectors allow for simultaneous spectral acquisition, which, combined with suitable optics, produce spectral ...", "dateLastCrawled": "2022-01-29T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "DeepLearnMOR: a deep-learning framework for fluorescence image-based ...", "url": "https://academic.oup.com/plphys/article-abstract/186/4/1786/6275758", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/plphys/article-abstract/186/4/1786/6275758", "snippet": "The highlighted features in the attention <b>map</b> <b>can</b> be shared with cell biologists to confirm the <b>interpretability</b> and reliability of the neural network, and further assure the application of the model in other research endeavors. Our current framework <b>can</b> be significantly expanded. The primary goal of this study was to demonstrate the ...", "dateLastCrawled": "2021-12-09T04:23:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "snippet": "This provides a novel <b>analogy</b> between data compression and regularization. Qualitative and quantitative state-of-the-art results on three datasets. 20 / 33. Interpretable Lens Variable Model (ILVM) 21 / 33. Interactive <b>Interpretability</b> via Active <b>Learning</b> Interactive \u2018human-in-the-loop\u2019 <b>interpretability</b> Choose the point with index j that maximizes : ^j = argmax jI(s ; ) = H(s ) E q \u02da(z js)[H(s jz j)] = Z p(s j)log p(s j)ds + E q \u02da(z js) Z p (s jjz)log p (s jjz)ds : (5) Choose the point ...", "dateLastCrawled": "2022-01-19T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Figure 1: <b>Interpretability</b> for <b>machine</b> <b>learning</b> models bridges the concrete objectives models optimize for and the real-world (and less easy to define) desiderata that ML applications aim to achieve. Introduction . The objectives <b>machine</b> <b>learning</b> models optimize for do not always reflect the actual desiderata of the task at hand. <b>Interpretability</b> in models allows us to evaluate their decisions and obtain information that the objective alone cannot confer. <b>Interpretability</b> takes many forms ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "There is increasing emphasis on interpretable <b>machine</b> <b>learning</b> in the world of data. Models have been growing ever more complex with the use of neural networks becoming more mainstream, along with the sheer size of data being analysed today. In many cases, such complex models may not be fit for human interpretation in their own right. Therefore, there has been a push to make the model interpretable, whereby both the results and the process in achieving those results are understood by humans ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-16T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://arxiv.org/abs/2005.12800", "isFamilyFriendly": true, "displayUrl": "https://<b>arxiv</b>.org/abs/2005.12800", "snippet": "Principles of analogical reasoning have recently been applied in the context of <b>machine</b> <b>learning</b>, for example to develop new methods for classification and preference <b>learning</b>. In this paper, we argue that, while analogical reasoning is certainly useful for constructing new <b>learning</b> algorithms with high predictive accuracy, is is arguably not less interesting from an <b>interpretability</b> and explainability point of view. More specifically, we take the view that an <b>analogy</b>-based approach is a ...", "dateLastCrawled": "2021-10-24T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Economic Methodology Meets Interpretable <b>Machine</b> <b>Learning</b> ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. But first ...", "dateLastCrawled": "2022-01-05T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Economic Methodology Meets Interpretable Machine Learning</b> - Part I ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. Intro - Part ...", "dateLastCrawled": "2022-01-22T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "Neuroscience \u2194 <b>Interpretability</b>. <b>Analogy</b>: model=brain. Artificial neural networks are historically inspired by neuroscience, but I used to be pretty skeptical that the connection was anything more than superficial. I&#39;ve since come around: I now think this is a very deep connection. The thing that personally persuaded me was that, in my own investigations of what goes on inside neural networks, we kept finding things that were previously discovered by neuroscientists. The most recent ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>SHAP</b>: A reliable way to analyze model <b>interpretability</b> | by Sharayu ...", "url": "https://towardsdatascience.com/shap-a-reliable-way-to-analyze-your-model-interpretability-874294d30af6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>shap</b>-a-reliable-way-to-analyze-your-model...", "snippet": "The balance: Accuracy vs. <b>Interpretability</b>. 2. How to interpret <b>machine</b> <b>learning</b> models? 3. LIME: Explaining predictions of <b>machine</b> <b>learning</b> models. In this blog, I wil l be talking about one of the most popular model agnostic technique that is used to explain predictions. <b>SHAP</b> stands for SHapley Additive exPlanations. Shapely values are obtained by incorporating concepts from Cooperative Game Theory and local explanations. Given a set of palyers, Cooperative Game Theory defines how well and ...", "dateLastCrawled": "2022-01-31T17:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chris Olah on what the hell is going on inside neural networks - 80,000 ...", "url": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/", "isFamilyFriendly": true, "displayUrl": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research", "snippet": "Chris is a <b>machine</b> <b>learning</b> researcher currently focused on neural network interpretability. Until last December he led OpenAI\u2019s interpretability team but along with some colleagues he recently moved on to help start a new AI lab focussed on large models and safety called Anthropic. Rob Wiblin: Before OpenAI he spent 4 years at Google Brain developing tools to visualize what\u2019s going on in neural networks. Chris was hugely impactful at Google Brain. He was second author on the launch of ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Marketing AI: Interpretability and Explainability</b> - Christopher S. Penn ...", "url": "https://www.christopherspenn.com/2021/03/marketing-ai-interpretability-and-explainability/", "isFamilyFriendly": true, "displayUrl": "https://www.christopherspenn.com/2021/03/<b>marketing-ai-interpretability-and-explainability</b>", "snippet": "<b>Interpretability is like</b> inspecting the baker\u2019s recipe for the cake. We look at the list of ingredients and the steps taken to bake the cake, and we verify that the recipe makes sense and the ingredients were good. This is a much more rigorous way of validating our results, but it\u2019s the most complete \u2013 and if we\u2019re in a high-stakes situation where we need to remove all doubt, this is the approach we take. Interpretability in AI is like that \u2013 we step through the code itself that ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Causal <b>Learning</b> From Predictive Modeling for Observational Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931928/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7931928", "snippet": "Given the recent success of <b>machine</b> <b>learning</b>, specifically deep <b>learning</b>, in several applications (Goodfellow et al., ... This statistical <b>interpretability is similar</b> in spirit to traditional interpretability. This allows to answer questions, such as \u201cdoes BMI influence susceptibility to Covid?\u201d Moreover, it has been argued that developing an effective CBN for practical applications requires expert knowledge when data collection is cumbersome (Fenton and Neil, 2012). This applies to ...", "dateLastCrawled": "2021-12-09T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimal <b>Predictive Clustering</b> - Dimitris Bertsimas", "url": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-predictive-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-<b>predictive-clustering</b>.pdf", "snippet": "Table 1 Comparison of major <b>machine</b> <b>learning</b> methods relative to each other across the metrics of performance (out-of-sample R2), scalability and interpretability. 1 is the best, while 5 is the worst. Optimal <b>Predictive Clustering</b> 3 From Table 1, we observe all existing methods have weakness in at least one category. We therefore seek to design a method that has strong performance in all three categories at the same time. Optimal <b>Predictive Clustering</b> (OPC) is an algorithm that uses mixed ...", "dateLastCrawled": "2021-11-24T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reviewing Challenges of Predicting Protein Melting Temperature Change ...", "url": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "snippet": "Predicting the effects of mutations on protein stability is a key problem in fundamental and applied biology, still unsolved even for the relatively simple case of small, soluble, globular, monomeric, two-state-folder proteins. Many articles discuss the limitations of prediction methods and of the datasets used to train them, which result in low reliability for actual applications despite globally capturing trends. Here, we review these and other issues by analyzing one of the most detailed ...", "dateLastCrawled": "2022-02-03T02:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "In my view, a shor t coming of interpretable <b>machine</b> <b>learning</b> is that it assumes to a degree that the data being fed into the model is always going to be suitable for human interpretation. This is not necessarily the case. For instance, let\u2019s say that a company is trying to implement interpretable <b>machine</b> <b>learning</b> to devise a credit scoring model, whereby prospective credit card applications are classified as approved or rejected based on numerous features. It is often the case that such ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Breaking the interpretability barrier - a</b> method for interpreting deep ...", "url": "http://www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "isFamilyFriendly": true, "displayUrl": "www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o between performance and inter-pretability. Graph classi cation is normally a domain which requires the ap-plication of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to in-terpret complex models post-hoc (brie y reviewed in section2). However, most ...", "dateLastCrawled": "2021-09-22T17:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Discovering Discriminative Nodes for Classi\ufb01cation with Deep Graph ...", "url": "http://muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "isFamilyFriendly": true, "displayUrl": "muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o\ufb00 between performance and inter-pretability. Graph classi\ufb01cation is normally a domain which requires the appli-cation of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to interpret complex models post-hoc (brie\ufb02y reviewed in Sect.2). However ...", "dateLastCrawled": "2021-09-02T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Confronting Abusive Language Online: A Survey from the Ethical and ...", "url": "https://www.arxiv-vanity.com/papers/2012.12305/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2012.12305", "snippet": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this ...", "dateLastCrawled": "2021-10-13T19:21:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(interpretability)  is like +(A map, a key, or a microscope)", "+(interpretability) is similar to +(A map, a key, or a microscope)", "+(interpretability) can be thought of as +(A map, a key, or a microscope)", "+(interpretability) can be compared to +(A map, a key, or a microscope)", "machine learning +(interpretability AND analogy)", "machine learning +(\"interpretability is like\")", "machine learning +(\"interpretability is similar\")", "machine learning +(\"just as interpretability\")", "machine learning +(\"interpretability can be thought of as\")", "machine learning +(\"interpretability can be compared to\")"]}