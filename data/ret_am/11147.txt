{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Unlabeled</b> <b>Example</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/unlabeled-example", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>unlabeled</b>-<b>example</b>", "snippet": "A hypothesis is induced from the <b>learning</b> set and used to label <b>a new</b> <b>example</b>. The newly labelled <b>example</b> is included in the <b>learning</b> set, and another, transduced hypothesis is induced. It is used to label the <b>new</b> <b>example</b> with the transduced label. The difference (distance) between induced and transduced labels (or probability distributions, if available) is evaluated as a quality estimation (or reliability of the original prediction). Different distance metrics can be used in classification ...", "dateLastCrawled": "2022-01-07T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Machine <b>Learning</b> with <b>Unlabeled</b> Training Data | iMerit", "url": "https://imerit.net/blog/machine-learning-with-unlabeled-training-data-all-pbm/", "isFamilyFriendly": true, "displayUrl": "https://imerit.net/blog/machine-<b>learning</b>-with-<b>unlabeled</b>-training-data-all-pbm", "snippet": "Post Machine <b>Learning</b> with <b>Unlabeled</b> Training Data. June 01, 2021. Machine <b>learning</b> relies on supervised <b>learning</b>, which uses labeled training data. However unsupervised <b>learning</b>, which uses <b>unlabeled</b> training data, can supplement supervised <b>learning</b>, and improve ML system performance.. Unsupervised <b>learning</b> uses <b>unlabeled</b> training samples to model basic characteristics of an ML system\u2019s input data.", "dateLastCrawled": "2022-01-28T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Positive and <b>Unlabeled</b> <b>Learning</b>: How Complex is Too Complex? | James D ...", "url": "https://jamesmccaffrey.wordpress.com/2021/11/11/positive-and-unlabeled-learning-how-complex-is-too-complex/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/11/11/positive-and-<b>unlabeled</b>-<b>learning</b>-how...", "snippet": "The output of the system is a pair of probabilities for each <b>unlabeled</b> data item, for <b>example</b> [0.123, 0.877], where the first value is probability of class 0, and second value is probability of class 1. The system uses a delta threshold where only those items where the difference between the prob(0) and prob(1) is greater than the delta, are used to make predictions. For <b>example</b>, if the threshold is 0.50 then a result <b>like</b> [0.20, 0.80] is used (prediction is class 1) but a result <b>like</b> [0.45 ...", "dateLastCrawled": "2022-01-11T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Positive and Unlabeled Learning</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2021/03/26/positive-and-unlabeled-learning/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/03/26/<b>positive-and-unlabeled-learning</b>", "snippet": "A <b>positive and unlabeled learning</b> problem is one where you want to make a binary classification model. In a regular binary classification problem you have training data that\u2019s labeled positive (class 1) and negative (class 0). But in a PUL problem you only have training data that labeled positive and <b>unlabeled</b> data. For <b>example</b>, suppose you have a dataset of people who have a disease (class 1) or don\u2019t have the disease (class 0). Your training data might look <b>like</b>:", "dateLastCrawled": "2022-01-17T14:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Label <b>Unlabeled</b> Tweets. Unsupervised <b>Learning</b> | by Huda | Geek ...", "url": "https://medium.com/geekculture/how-to-label-unlabeled-tweets-fb701b97ebf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/how-to-label-<b>unlabeled</b>-tweets-fb701b97ebf", "snippet": "While <b>learning</b> data science, we mostly get a well-labeled dataset to build our models on. However, in a real-world scenario, seldom do we get good labeled datasets. Many data science problems ...", "dateLastCrawled": "2022-01-27T11:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>A new</b> dictionary-based <b>positive and unlabeled learning</b> method ...", "url": "https://link.springer.com/article/10.1007/s10489-021-02344-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10489-021-02344-z", "snippet": "<b>Positive and unlabeled learning</b> (PU <b>learning</b>) is designed to solve the problem that we only utilize the labeled positive examples and the <b>unlabeled</b> examples to train a classifier. A variety of methods have been proposed to solve this problem by incorporating <b>unlabeled</b> examples into <b>learning</b>. However, many methods treat the original features as input in the training stage and then build the classifier. In this paper, by use of two-step strategy, a novel method with dictionary <b>learning</b> is ...", "dateLastCrawled": "2022-01-24T21:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Train without labeling data using Self-Supervised <b>Learning</b> by ...", "url": "https://towardsdatascience.com/train-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/train-without-labeling-data-using-self-supervised...", "snippet": "The aim of this story to introduce the <b>new</b> approach in training <b>unlabeled</b> data in deep <b>learning</b> using Representation <b>Learning</b>. Chien Vu . Aug 13, 2020 \u00b7 9 min read. Photo by Jason Leung on Unsplash Background and challenges \ud83d\udccb. In a modern deep <b>learning</b> algorithm, the dependence on manual annotation of <b>unlabeled</b> data is one of the major limitations. To train a good model, usually, we have to prepare a vast amount of labeled data. In the case of a small number of classes and data, we can ...", "dateLastCrawled": "2022-01-28T11:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Transformers Meet Active <b>Learning</b>: Less Data, Better Performance | by ...", "url": "https://towardsdatascience.com/transformers-meet-active-learning-less-data-better-performance-4cf931517ff6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/transformers-meet-active-<b>learning</b>-less-data-better...", "snippet": "Recently large <b>language</b> models (LLMs) pushed the state-of-the-art in many natural <b>language</b> processin g (NLP) tasks. Generally, these LLMs follow a two-step framework: a pre-training step, followed by a fine-tuning step. The pre-training uses a large number of <b>unlabeled</b> data to create the pre-trained weights. The fine-tuning step then loads these weights and trains on labeled data from downstream tasks. LLMs can achieve good results with a small set of labeled data, which leads to shorter ...", "dateLastCrawled": "2022-02-01T21:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What Is Machine <b>Learning</b>? \u2013 Ahmad Khawaja", "url": "https://ahmadkhawajasite.wordpress.com/2021/10/19/what-is-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://ahmadkhawajasite.wordpress.com/2021/10/19/what-is-machine-<b>learning</b>", "snippet": "Semi-supervised <b>learning</b> is a viable alternative to both supervised and unsupervised <b>learning</b>. It uses a small labeled data set to aid classification and feature extraction from a more extensive <b>unlabeled</b> data set during training. Semi-supervised <b>learning</b> can help alleviate the problem of not having enough labeled data to train a supervised <b>learning</b> algorithm or not being able to afford to label enough data.", "dateLastCrawled": "2022-02-03T10:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "CLIP: Mining the treasure trove of <b>unlabeled</b> image data | by Fabian ...", "url": "https://medium.com/dida-machine-learning/clip-mining-the-treasure-trove-of-unlabeled-image-data-48d373d09dd5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dida-machine-<b>learning</b>/clip-mining-the-treasure-trove-of-<b>unlabeled</b>...", "snippet": "In the context of natural <b>language</b> processing tasks, it is already common to take advantage of the masses of (<b>unlabeled</b>!) textual data that is available in digitized form (e.g. Wikipedia articles ...", "dateLastCrawled": "2022-01-05T02:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Unlabeled</b> <b>Example</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/unlabeled-example", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>unlabeled</b>-<b>example</b>", "snippet": "Transduction <b>is similar</b> to instance-based <b>learning</b>, a family of algorithms that compares <b>new</b> problem instances with training instances\u2014K-means clustering is an <b>example</b> (Section 5.3). If some labels are available, transductive <b>learning</b> <b>is similar</b> to semisupervised <b>learning</b>. Yet, transduction is different from all the <b>learning</b> approaches mentioned thus far. Instance-based <b>learning</b> can be inductive, and semisupervised <b>learning</b> is inductive, whereas transductive <b>learning</b> avoids inductive ...", "dateLastCrawled": "2022-01-07T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Positive and Unlabeled Learning</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2021/03/26/positive-and-unlabeled-learning/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/03/26/<b>positive-and-unlabeled-learning</b>", "snippet": "A <b>positive and unlabeled learning</b> problem is one where you want to make a binary classification model. In a regular binary classification problem you have training data that\u2019s labeled positive (class 1) and negative (class 0). But in a PUL problem you only have training data that labeled positive and <b>unlabeled</b> data. For <b>example</b>, suppose you have a dataset of people who have a disease (class 1) or don\u2019t have the disease (class 0). Your training data might look like:", "dateLastCrawled": "2022-01-17T14:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to Label <b>Unlabeled</b> Tweets. Unsupervised <b>Learning</b> | by Huda | Geek ...", "url": "https://medium.com/geekculture/how-to-label-unlabeled-tweets-fb701b97ebf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/how-to-label-<b>unlabeled</b>-tweets-fb701b97ebf", "snippet": "A prime <b>example</b> of <b>unlabeled</b> data is the tweets! I\u2019ll try to unbundle this enigma of <b>unlabeled</b> data by analyzing all the tweets related to Electric Cars! Why Electric Cars? Electric cars are the ...", "dateLastCrawled": "2022-01-27T11:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Positive and Unlabeled Learning (PUL) Using PyTorch</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2021/05/27/positive-and-unlabeled-learning-pul-using-pytorch/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/05/27/<b>positive-and-unlabeled-learning-pul</b>...", "snippet": "A <b>positive and unlabeled learning (PUL</b>) problem occurs when a machine <b>learning</b> set of training data has only a few positive labeled items and many <b>unlabeled</b> items. For <b>example</b>, suppose you want to train a machine <b>learning</b> model to predict if a hospital patient has a disease or not, based on predictor variables such as age, blood pressure, and so on. The training data might have a few dozen instances of items that are positive (class 1 = patient has disease) and many hundreds or thousands of ...", "dateLastCrawled": "2022-01-01T10:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "4 Approaches to Overcoming Label Bias in Positive and <b>Unlabeled</b> <b>Learning</b>", "url": "https://blogs.oracle.com/site/ai-and-datascience/post/4-approaches-to-overcoming-label-bias-in-positive-and-unlabeled-learning", "isFamilyFriendly": true, "displayUrl": "https://blogs.oracle.com/site/ai-and-datascience/post/4-approaches-to-overcoming-label...", "snippet": "Positive and <b>unlabeled</b> <b>learning</b> is a subset of supervised <b>learning</b> in which only the positive labels are known. The missing data mechanism here falls under \u2018Missing Not at Random\u2019 since all non-missing information will be a positive label (the label itself is a predictor of it being missing). For instance, let\u2019s say I own a grocery store, and keep track of what people are purchasing using their loyalty cards. Referring to our grocery store <b>example</b> again, the store knows with some ...", "dateLastCrawled": "2021-12-16T02:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning</b> to Classify Texts Using Positive and <b>Unlabeled</b> Data", "url": "https://www.cs.uic.edu/~liub/publications/ijcai03-textClass.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.uic.edu/~liub/publications/ijcai03-textClass.pdf", "snippet": "results show that the <b>new</b> method outperforms ex-isting methods significantly. 1 Introduction Text classification is an important problem and has been studied extensively in information retrieval and machine <b>learning</b>. To build a text classifier, the user first collects a set of training examples, which are labeled with pre-defined classes (labeling is often done manually). A classification algorithm is then applied to the training data to build a classifier. This approach to building ...", "dateLastCrawled": "2022-01-31T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning the language of proteins</b> - GitHub Pages", "url": "https://yangkky.github.io/2018/03/26/learning-the-language-of-proteins.html", "isFamilyFriendly": true, "displayUrl": "https://yangkky.github.io/2018/03/26/<b>learning-the-language-of-proteins</b>.html", "snippet": "<b>Learning the language of proteins</b>. Mar 26, 2018 Amino acids in a protein are analogous to letters in an alphabet, short subsequences of amino acids are analogous to words in an unknown <b>language</b>, and a protein\u2019s entire amino-acid sequence to a document encoding its structure and function. Therefore, I applied techniques from natural <b>language</b> processing to learn the <b>language</b> of proteins. Given a large collection of <b>unlabeled</b> texts, word2vec and doc2vec are well-established methods that learn ...", "dateLastCrawled": "2021-12-31T04:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Language</b> Model like Pre-Training for Acoustic Data | by Sundar V ...", "url": "https://towardsdatascience.com/language-model-like-pre-training-for-acoustic-data-f6057b3701ca", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>language</b>-model-like-pre-training-for-acoustic-data-f...", "snippet": "<b>Language</b> Model Pre-Training. Transfer <b>learning</b> is considerably popular these days, where a model trained for one task is re-purposed for another target task. In Computer Vision (CV), transfer <b>learning</b> is widespread; for <b>example</b>, it is prevalent to fine-tune a model pre-trained on ImageNet dataset for a target task to get reliable performance. But the problem here is it is hard to find ImageNet like massive labelled dataset for NLP or acoustic time-series data. To make use of the massive free ...", "dateLastCrawled": "2022-01-30T17:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Positive and <b>Unlabeled</b> Materials Machine <b>Learning</b> | by Nathan C. Frey ...", "url": "https://towardsdatascience.com/positive-and-unlabeled-materials-machine-learning-8b216edea899", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/positive-and-<b>unlabeled</b>-materials-machine-<b>learning</b>-8b216...", "snippet": "Image by author. We calculated a bunch of properties for all the materials we were interested in, built and trained a positive and <b>unlabeled</b> machine <b>learning</b> model to recognize what is special about the synthesized materials, and then predicted which <b>new</b> materials should be synthesizable. Our model learned to use some information that we already know is a good indicator of synthesizability, like how much the atoms want to be bonded together.", "dateLastCrawled": "2022-02-03T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Exploiting unlabeled utterances for spoken language understanding</b>.", "url": "https://www.researchgate.net/publication/221488573_Exploiting_unlabeled_utterances_for_spoken_language_understanding", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221488573_Exploiting_<b>unlabeled</b>_utterances_for...", "snippet": "The goal of adaptation is optimizing an existing model for <b>a new</b> target application, which <b>is similar</b> to the previous one but may have different classes or class distributions. Finally, we present ...", "dateLastCrawled": "2021-10-22T01:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Positive and Unlabeled Learning</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2021/03/26/positive-and-unlabeled-learning/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/03/26/<b>positive-and-unlabeled-learning</b>", "snippet": "A <b>positive and unlabeled learning</b> problem is one where you want to make a binary classification model. In a regular binary classification problem you have training data that\u2019s labeled positive (class 1) and negative (class 0). But in a PUL problem you only have training data that labeled positive and <b>unlabeled</b> data. For <b>example</b>, suppose you have a dataset of people who have a disease (class 1) or don\u2019t have the disease (class 0). Your training data might look like:", "dateLastCrawled": "2022-01-17T14:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Positive and <b>Unlabeled</b> <b>Learning</b>: How Complex is Too Complex? | James D ...", "url": "https://jamesmccaffrey.wordpress.com/2021/11/11/positive-and-unlabeled-learning-how-complex-is-too-complex/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/11/11/positive-and-<b>unlabeled</b>-<b>learning</b>-how...", "snippet": "The output of the system is a pair of probabilities for each <b>unlabeled</b> data item, for <b>example</b> [0.123, 0.877], where the first value is probability of class 0, and second value is probability of class 1. The system uses a delta threshold where only those items where the difference between the prob(0) and prob(1) is greater than the delta, are used to make predictions. For <b>example</b>, if the threshold is 0.50 then a result like [0.20, 0.80] is used (prediction is class 1) but a result like [0.45 ...", "dateLastCrawled": "2022-01-11T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is <b>Deep Learning</b> and How Does It Work?", "url": "https://www.techtarget.com/searchenterpriseai/definition/deep-learning-deep-neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.techtarget.com/searchenterpriseai/definition/<b>deep-learning</b>-deep-neural-network", "snippet": "At its simplest, <b>deep learning</b> <b>can</b> <b>be thought</b> of as a way to automate predictive analytics. ... This means, for <b>example</b>, a facial recognition model might make determinations about people&#39;s characteristics based on things like race or gender without the programmer being aware. The <b>learning</b> rate <b>can</b> also become a major challenge to <b>deep learning</b> models. If the rate is too high, then the model will converge too quickly, producing a less-than-optimal solution. If the rate is too low, then the ...", "dateLastCrawled": "2022-01-29T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Statistical Learning vs Machine Learning</b> | A Thorough Guide", "url": "https://onlinecoursescertifications.com/statistical-learning-vs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://onlinecoursescertifications.com/<b>statistical-learning-vs-machine-learning</b>", "snippet": "Statistical <b>learning</b> is often <b>thought</b> of as being a subcategory of machine <b>learning</b>. Typically, the <b>learning</b> process in machine <b>learning</b> goes as follows: Making observations of the phenomenon; Creating a model that represents this phenomenon; Making predictions based on this model; So, how do things differ in statistical modelling? Well, for starters, the <b>learning</b> process must be automated to allow the machine to absorb it and construct a statistical model. The statistical model&#39;s ...", "dateLastCrawled": "2022-02-02T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Can</b> someone help with <b>building sub-labels for unlabeled and labeled</b> ...", "url": "https://www.researchgate.net/post/Can-someone-help-with-building-sub-labels-for-unlabeled-and-labeled-documents", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/<b>Can</b>-someone-help-with-building-sub-labels-for...", "snippet": "Machine <b>learning</b> plays a key role in a wide range of applications such as data mining, natural <b>language</b> processing and expert systems. It provides a solution in all domains for further development ...", "dateLastCrawled": "2022-01-15T01:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is Data Labeling? | IBM", "url": "https://www.ibm.com/cloud/learn/data-labeling", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ibm.com</b>/cloud/learn/data-labeling", "snippet": "Labeled data is used in supervised <b>learning</b>, whereas <b>unlabeled</b> data is used in unsupervised <b>learning</b>. Labeled data is more difficult to acquire and store (i.e. time consuming and expensive), whereas <b>unlabeled</b> data is easier to acquire and store. Labeled data <b>can</b> be used to determine actionable insights (e.g. forecasting tasks), whereas <b>unlabeled</b> data is more limited in its usefulness. Unsupervised <b>learning</b> methods <b>can</b> help discover <b>new</b> clusters of data, allowing for <b>new</b> categorizations when ...", "dateLastCrawled": "2022-02-02T06:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "CLIP: Mining the treasure trove of <b>unlabeled</b> image data | by Fabian ...", "url": "https://medium.com/dida-machine-learning/clip-mining-the-treasure-trove-of-unlabeled-image-data-48d373d09dd5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dida-machine-<b>learning</b>/clip-mining-the-treasure-trove-of-<b>unlabeled</b>...", "snippet": "In the context of natural <b>language</b> processing tasks, it is already common to take advantage of the masses of (<b>unlabeled</b>!) textual data that is available in digitized form (e.g. Wikipedia articles ...", "dateLastCrawled": "2022-01-05T02:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How <b>words anchor categorization: conceptual flexibility with labeled</b> ...", "url": "https://www.cambridge.org/core/journals/language-and-cognition/article/how-words-anchor-categorization-conceptual-flexibility-with-labeled-and-unlabeled-categories/8A97991E4AA3FECA4DCF39EC97705C85", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/<b>language</b>-and-cognition/article/how-words...", "snippet": "How <b>words anchor categorization: conceptual flexibility with labeled</b> and <b>unlabeled</b> categories*\u2021 - Volume 7 Issue 2", "dateLastCrawled": "2022-01-25T04:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Data Mining MCQ</b> (Multiple Choice Questions) - Javatpoint", "url": "https://www.javatpoint.com/data-mining-mcq", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>data-mining-mcq</b>", "snippet": "Answer: d Explanation: Data cleaning is a kind of process that is applied to data set to remove the noise from the data (or noisy data), inconsistent data from the given data. It also involves the process of transformation where wrong data is transformed into the correct data as well. In other words, we <b>can</b> also say that data cleaning is a kind of pre-process in which the given set of data is prepared for the data warehouse.", "dateLastCrawled": "2022-02-02T21:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Language doesn&#39;t influence our thoughts ... except when</b> it does ...", "url": "https://scienceblogs.com/cognitivedaily/2008/01/07/language-doesnt-influence-our", "isFamilyFriendly": true, "displayUrl": "https://<b>scienceblogs.com</b>/cognitivedaily/2008/01/07/<b>language-doesnt-influence-our</b>", "snippet": "Just as we <b>can</b> learn <b>a new</b> <b>language</b>, we <b>can</b> learn to have thoughts that aren&#39;t expressible in any <b>language</b>. Lupyan, G., Rakison, D.H., McClelland, J.L. (2007). <b>Language</b> Is Not Just for Talking ...", "dateLastCrawled": "2022-02-02T13:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Label <b>Unlabeled</b> Tweets. Unsupervised <b>Learning</b> | by Huda | Geek ...", "url": "https://medium.com/geekculture/how-to-label-unlabeled-tweets-fb701b97ebf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/how-to-label-<b>unlabeled</b>-tweets-fb701b97ebf", "snippet": "While <b>learning</b> data science, we mostly get a well-labeled dataset to build our models on. However, in a real-world scenario, seldom do we get good labeled datasets. Many data science problems ...", "dateLastCrawled": "2022-01-27T11:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>A new</b> dictionary-based <b>positive and unlabeled learning</b> method ...", "url": "https://link.springer.com/article/10.1007/s10489-021-02344-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10489-021-02344-z", "snippet": "<b>Positive and unlabeled learning</b> (PU <b>learning</b>) is designed to solve the problem that we only utilize the labeled positive examples and the <b>unlabeled</b> examples to train a classifier. A variety of methods have been proposed to solve this problem by incorporating <b>unlabeled</b> examples into <b>learning</b>. However, many methods treat the original features as input in the training stage and then build the classifier. In this paper, by use of two-step strategy, a novel method with dictionary <b>learning</b> is ...", "dateLastCrawled": "2022-01-24T21:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Not All <b>Unlabeled Data are Equal: Learning</b> to Weight Data in Semi ...", "url": "https://deepai.org/publication/not-all-unlabeled-data-are-equal-learning-to-weight-data-in-semi-supervised-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/not-all-<b>unlabeled-data-are-equal-learning</b>-to-weight...", "snippet": "Existing semi-supervised <b>learning</b> (SSL) algorithms use a single weight to balance the loss of labeled and <b>unlabeled</b> examples, i.e., all <b>unlabeled</b> examples are equally weighted. But not all <b>unlabeled</b> data are equal. In this paper we study how to use a different weight for every <b>unlabeled</b> <b>example</b>. Manual tuning of all those weights \u2013 as done in prior work \u2013 is no longer possible.", "dateLastCrawled": "2021-12-30T11:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Unsupervised Machine learning</b> - Javatpoint", "url": "https://www.javatpoint.com/unsupervised-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>unsupervised-machine-learning</b>", "snippet": "It <b>can</b> <b>be compared</b> <b>to learning</b> which takes place in the human brain while <b>learning</b> <b>new</b> things. It <b>can</b> be defined as: Unsupervised <b>learning</b> is a type of machine <b>learning</b> in which models are trained using <b>unlabeled</b> dataset and are allowed to act on that data without any supervision. Unsupervised <b>learning</b> cannot be directly applied to a regression or classification problem because unlike supervised <b>learning</b>, we have the input data but no corresponding output data. The goal of unsupervised ...", "dateLastCrawled": "2022-02-02T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Facilitating information extraction without annotated data using ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8075513/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8075513", "snippet": "Various methods have been developed to handle PU data and to enable <b>learning</b> a traditional classifier (i.e. one that <b>can</b> distinguish between positive and negative examples) from PU data (i.e. data that contains only positive and <b>unlabeled</b> examples). 3 Broadly, these methods attempt to tackle the mixture of positive and negative among the <b>unlabeled</b> examples by either 1) looking for <b>unlabeled</b> examples that are very likely (&quot;reliable&quot;) negative or 2) considering all <b>unlabeled</b> examples as ...", "dateLastCrawled": "2021-11-02T12:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Labeled Example</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/labeled-example", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>labeled-example</b>", "snippet": "An active <b>learning</b> approach <b>can</b> ask a user (e.g., a domain expert) to label an <b>example</b>, which may be from a set of <b>unlabeled</b> examples or synthesized by the <b>learning</b> program. The goal is to optimize the model quality by actively acquiring knowledge from human users, given a constraint on how many examples they <b>can</b> be asked to label. Figure 1.12. Semi-supervised <b>learning</b>. You <b>can</b> see there are many similarities between data mining and machine <b>learning</b>. For classification and clustering tasks ...", "dateLastCrawled": "2022-01-19T15:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Different Types of Neural Networks in Deep <b>Learning</b>", "url": "https://www.naukri.com/learning/articles/different-types-of-neural-networks-in-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.naukri.com/<b>learning</b>/articles/different-types-of-neural-networks-in-deep...", "snippet": "For <b>example</b>, knowing the pixels of an image there will be a way to know what number is written. The input data are sequentially passing through different \u201clayers\u201d in which a series of <b>learning</b> rules modulated by a weight function is applied. After going through the last layer, the results are <b>compared</b> with the \u201ccorrect\u201d result, and the parameters are adjusted. Learn more \u2013 What ...", "dateLastCrawled": "2022-02-03T13:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Live-dead assay on <b>unlabeled</b> cells using phase imaging with ...", "url": "https://www.nature.com/articles/s41467-022-28214-x", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-022-28214-x", "snippet": "In 2018, Google presented \u201cin silico labeling\u201d, a deep <b>learning</b> based approach that <b>can</b> predict fluorescent labels from transmitted-light (bright field and phase contrast) images of <b>unlabeled</b> ...", "dateLastCrawled": "2022-02-07T11:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Self-supervised, semi-supervised, and multi-view <b>learning</b> // van der ...", "url": "https://www.vanderschaar-lab.com/self-semi-supervised-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.vanderschaar-lab.com/self-semi-supervised-<b>learning</b>", "snippet": "Datasets like these present huge opportunities for self- and semi-supervised <b>learning</b> algorithms, which <b>can</b> leverage the <b>unlabeled</b> data to further improve the performance of a predictive model. <b>Can</b>\u2019t we just use existing self-supervised <b>learning</b>? Naturally, self-supervised <b>learning</b> is not being introduced here as <b>a new</b> concept; in fact, it is an approach that has seen a great deal of success already in areas including image recognition (computer vision) and natural <b>language</b> processing. The ...", "dateLastCrawled": "2022-02-02T09:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is Unsupervised Machine <b>Learning</b> &amp; its examples? | NASSCOM ...", "url": "https://community.nasscom.in/communities/ai-inside/what-unsupervised-machine-learning-its-examples", "isFamilyFriendly": true, "displayUrl": "https://community.nasscom.in/.../ai-inside/what-unsupervised-machine-<b>learning</b>-its-<b>examples</b>", "snippet": "People who purchase <b>a new</b> home, for <b>example</b>, are more likely to purchase <b>new</b> furniture.Other examples include: &lt;&gt; A subset of cancer patients classified according to their gene expression levels.Shoppers are divided into groups depending on their browsing and purchasing habits.Movies are categorised based on the ratings given by moviegoers. &lt;&gt; Applications of unsupervised <b>learning</b> &lt;&gt; Machine <b>learning</b> techniques have become a popular way to enhance the user experience of a product and to test ...", "dateLastCrawled": "2022-01-27T13:38:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>The Types Of Machine Learning | Let\u2019s Understand Part</b> 2. \u2013 ML for Lazy", "url": "https://mlforlazy.in/the-types-of-machine-learning-lets-understand-part-2/", "isFamilyFriendly": true, "displayUrl": "https://mlforlazy.in/<b>the-types-of-machine-learning-lets-understand-part</b>-2", "snippet": "The <b>analogy</b>. In layman\u2019s language or in words that are easy to understand, semi-supervised <b>learning</b> is like supervising a student for a short amount of time and then letting him go and wander the field independently. It solves classification problems. That means that you will need some supervised parts. Then at the same time, you have to train the model on large datasets of unlabelled data, for which you need the unsupervised part of <b>machine</b> <b>learning</b>. The central concept is to cluster ...", "dateLastCrawled": "2022-01-09T08:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Types of <b>Machine</b> <b>Learning</b>. How do machines learn? There are many\u2026 | by ...", "url": "https://medium.com/@sameerkhan9/types-of-machine-learning-b046528d65f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@sameerkhan9/types-of-<b>machine</b>-<b>learning</b>-b046528d65f3", "snippet": "Unsupervised <b>learning</b> is a type of <b>learning</b> in which the <b>machine</b> must infer the function of input and outputs with <b>unlabeled</b> data. It is given data but the job of the <b>machine</b> is to figure out some ...", "dateLastCrawled": "2021-11-23T16:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Unsupervised <b>Machine</b> <b>Learning</b>: Examples and Use Cases | <b>AltexSoft</b>", "url": "https://www.altexsoft.com/blog/unsupervised-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>altexsoft</b>.com/blog/unsupervised-<b>machine</b>-<b>learning</b>", "snippet": "Unsupervised <b>machine</b> <b>learning</b> is the process of inferring underlying hidden patterns from historical data. Within such an approach, a <b>machine</b> <b>learning</b> model tries to find any similarities, differences, patterns, and structure in data by itself. No prior human intervention is needed. Let\u2019s get back to our <b>example</b> of a child\u2019s experiential <b>learning</b>. Picture a toddler. The child knows what the family cat looks like (provided they have one) but has no idea that there are a lot of other cats ...", "dateLastCrawled": "2022-02-03T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How does <b>Machine Learning</b> work?. What? Is that Wall-E? I guess you ...", "url": "https://medium.datadriveninvestor.com/what-is-machine-learning-and-how-does-it-work-ea4b2a6b1d32", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/what-is-<b>machine-learning</b>-and-how-does-it-work-ea...", "snippet": "Time for a bizarre attempt at an <b>analogy</b> for <b>machine learning</b> methods\u2026 There are three main methods of <b>machine learning</b>. Supervised <b>Learning</b>; Unsupervised <b>Learning</b>; Reinforcement <b>Learning</b>; For simplicity\u2019s sake, let\u2019s think of each of these methods as students at a school. And if we were to be considered a coder trying to code an ML program to tackle a certain problem, we could call ourselves teachers, in charge of teaching these students how to succeed at solving some problems. \ud83d\udc68 ...", "dateLastCrawled": "2022-01-28T02:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning from positive</b> and <b>unlabeled</b> data: a survey - <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "<b>Learning from positive</b> and <b>unlabeled</b> data or PU <b>learning</b> is the setting where a learner only has access to positive examples and <b>unlabeled</b> data. The assumption is that the <b>unlabeled</b> data can contain both positive and negative examples. This setting has attracted increasing interest within the <b>machine</b> <b>learning</b> literature as this type of data naturally arises in applications such as medical diagnosis and knowledge base completion. This article provides a survey of the current state of the art ...", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is <b>Learning</b>? <b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "\u2022Transfer <b>Learning</b> \u2022<b>Learning</b> by <b>Analogy</b> \u2022Multi-task <b>Learning</b> 5. 2 Inductive <b>Learning</b> \u2022Generalize from a given set of (training) examples so that accurate predictions can be made about futureexamples \u2022Learn unknown function:f(x)=y \u2013x: an input <b>example</b>(aka instance) \u2013y: the desired output \u2022Discrete or continuous scalar value \u2013h(hypothesis) function is learned that approximates f 6 Representing \u201cThings\u201d in <b>Machine</b> <b>Learning</b> \u2022An exampleor instance,x,represents a specific ...", "dateLastCrawled": "2022-02-03T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is <b>Machine</b> <b>Learning</b>? \u2014 Learned from K-Drama Start-Up | by Richardy ...", "url": "https://richardylobosapan.medium.com/what-is-machine-learning-learned-from-k-drama-start-up-a1328882808d", "isFamilyFriendly": true, "displayUrl": "https://richardylobosapan.medium.com/what-is-<b>machine</b>-<b>learning</b>-learned-from-k-drama...", "snippet": "<b>Machi n e</b> <b>learning</b> is just like Tarzan in Do-San\u2019s <b>analogy</b>. The process of <b>learning</b> of Tarzan begins with observations of data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that provided. The primary aim is to allow the computers, in this case Tarzan, to learn automatically without human intervention or assistance and adjust actions accordingly. A question then arises, why is <b>machine</b> ...", "dateLastCrawled": "2022-01-07T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b> <b>Learning</b>: A Layman Overview \u2013 Academic Techie", "url": "http://academictechie.com/machine-learning-a-layman-overview/", "isFamilyFriendly": true, "displayUrl": "academictechie.com/<b>machine</b>-<b>learning</b>-a-layman-overview", "snippet": "For <b>example</b>, let us take the case of a <b>Machine</b> <b>Learning</b> algorithm used to play chess. ... For a very (a little too) fundamental <b>analogy</b>, imagine a teacher supervising a class. The teacher already knows the correct answers but the <b>learning</b> process doesn\u2019t stop until the students learn the answers as well. Supervised <b>Machine</b> <b>Learning</b> presently makes up a majority of the applications that are being utilized throughout the world. The input variable (x) is associated with the output variable (y ...", "dateLastCrawled": "2022-01-13T06:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Detecting Textual Analogies Using Semi-Supervised <b>Learning</b>", "url": "https://portfolios.cs.earlham.edu/wp-content/uploads/2018/12/Detecting-textual-analogies-Rei.pdf", "isFamilyFriendly": true, "displayUrl": "https://portfolios.cs.earlham.edu/wp-content/uploads/2018/12/Detecting-textual...", "snippet": "other <b>machine</b> <b>learning</b> techniques. <b>Analogy</b> is an essential aspect of human communication, understanding, and knowledge sharing. However, strategies for detecting textual analogies using machines are largely unexplored. There is also no standard corpus of textual analogies. This paper presents a system for detecting analogies in a given text using two semi supervised <b>learning</b> techniques; trans-ductive support vector machines (TSVMs) and label propagation. Count vectorization, tf-idf, and hash ...", "dateLastCrawled": "2021-10-17T14:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine learning MCQs</b> | T4Tutorials.com", "url": "https://t4tutorials.com/machine-learning-mcqs/", "isFamilyFriendly": true, "displayUrl": "https://t4tutorials.com/<b>machine-learning-mcqs</b>", "snippet": "<b>Machine learning MCQs</b>. 1. The general concept and process of forming definitions from examples of concepts to be learned. E. All of these. F. None of these. 2. The computer is the best <b>learning</b> for.", "dateLastCrawled": "2022-01-30T16:47:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "2148 IEEE TRANSACTIONS ON NEURAL NETWORKS AND <b>LEARNING</b> SYSTEMS, VOL. 26 ...", "url": "http://www.kerenfu.top/sources/FLAP2015.pdf", "isFamilyFriendly": true, "displayUrl": "www.kerenfu.top/sources/FLAP2015.pdf", "snippet": "conventional <b>machine</b> <b>learning</b> algorithms. As a kind of iteration-based algorithm, it is proven that FLAP can converge more quickly than other iterative methods by analyzing the relationship between the convergence rate and the eigenvalues of the iteration matrix. We show that eigenvalues of the iteration matrix in FLAP are close to 1, while those in other methods may scatter in a wide range. This difference makes FLAP is superior to other iterative methods in terms of convergence speed. We ...", "dateLastCrawled": "2021-11-19T02:43:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(unlabeled example)  is like +(learning a new language)", "+(unlabeled example) is similar to +(learning a new language)", "+(unlabeled example) can be thought of as +(learning a new language)", "+(unlabeled example) can be compared to +(learning a new language)", "machine learning +(unlabeled example AND analogy)", "machine learning +(\"unlabeled example is like\")", "machine learning +(\"unlabeled example is similar\")", "machine learning +(\"just as unlabeled example\")", "machine learning +(\"unlabeled example can be thought of as\")", "machine learning +(\"unlabeled example can be compared to\")"]}