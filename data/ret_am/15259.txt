{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep Learning</b> - GitHub Pages", "url": "https://srdas.github.io/DLBook/ConvNets.html", "isFamilyFriendly": true, "displayUrl": "https://srdas.github.io/DLBook/ConvNets.html", "snippet": "LeCun et al. later put the two <b>pieces</b> of the <b>puzzle</b> together while working at Bell Labs during the 90s, and created the modern ConvNet, whose design was based on the NeoCognitron, and which could also be trained using Backprop. LeCun\u2019s system, called LeNet5, was successfully commercially deployed to read handwritten signatures in checks. Research in ConvNets lay dormant until 2012, when they were used for the winning entry in the ImageNet Large Scale Visual Recognition Competition (ILSVRC ...", "dateLastCrawled": "2022-01-31T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Python Machine Learning: Machine Learning and Deep Learning with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with...", "snippet": "Mini-<b>batch</b> gradient descent A compromise between <b>batch</b> gradient descent and SGD is so-called mini-<b>batch</b> learning. Mini-<b>batch</b> learning can be understood as applying <b>batch</b> gradient descent to smaller subsets of the training data, for example, 32 training examples at a time. The advantage over <b>batch</b> gradient descent is that convergence is reached faster via mini-batches because of the more frequent weight updates. Furthermore, mini-<b>batch</b> learning allows us to replace the for loop over the ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Growing Neural Cellular Automata - Distill", "url": "https://distill.pub/2020/growing-ca/", "isFamilyFriendly": true, "displayUrl": "https://distill.pub/2020/growing-ca", "snippet": "The biggest <b>puzzle</b> in this field is the question of how the cell collective knows what to build and when to stop. The sciences of genomics and stem cell biology are only part of the <b>puzzle</b>, as they explain the distribution of specific components in each cell, and the establishment of different types of cells. While we know of many genes that are required for the process of regeneration, we still do not know the algorithm that is sufficient for cells to know how to build or remodel complex ...", "dateLastCrawled": "2022-02-03T06:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Application of evolutionary and swarm optimization in <b>computer vision</b> ...", "url": "https://ipsjcva.springeropen.com/articles/10.1186/s41074-020-00065-9", "isFamilyFriendly": true, "displayUrl": "https://ipsjcva.springeropen.com/articles/10.1186/s41074-020-00065-9", "snippet": "The pairwise compatibility of the adjacent <b>pieces</b> is evaluated based on <b>color</b> similarity along their abutting edges. A chromosome is represented by a matrix of the same size as the <b>puzzle</b>, and each element is assigned a piece number. This simple encoding causes a serious problem: offspring yielded from a traditional crossover may contain duplicate and/or missing <b>pieces</b>. Thus, the authors proposed a novel crossover operator based on a kernel-growing technique, which starts with a single piece ...", "dateLastCrawled": "2022-02-02T18:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Deep Learning Pipeline: Building a Deep Learning Model with TensorFlow</b> ...", "url": "https://dokumen.pub/deep-learning-pipeline-building-a-deep-learning-model-with-tensorflow-1nbsped-1484253485-9781484253489.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>deep-learning-pipeline-building-a-deep</b>-learning-model-with-tensor...", "snippet": "Evaluate Algorithms Trying to understand the world through data <b>is like</b> trying to piece together reality using a noisy, incomplete jigsaw <b>puzzle</b> with a bunch of extra <b>pieces</b>. This is where mathematical modeling\u2014in particular statistical modeling too\u2014comes in. The language of statistics contains concepts for many frequent characteristics of data, such as wrong, redundant, or missing. Wrong data is the result of a mistake in measurement. Redundant data contains multiple aspects that convey ...", "dateLastCrawled": "2022-01-30T17:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "AI with Python \u00e2 Quick Guide - <b>Tutorialspoint</b>", "url": "https://www.tutorialspoint.com/artificial_intelligence_with_python/artificial_intelligence_with_python_quick_guide.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/artificial_intelligence_with_python/artificial...", "snippet": "The <b>normalization</b> of variables needed otherwise higher range variables can bias it. In KNN, we need to work on pre-processing stage <b>like</b> noise removal. K-Means Clustering. As the name suggests, it is used to solve the clustering problems. It is basically a type of unsupervised learning. The main logic of K-Means clustering algorithm is to classify the data set through a number of clusters. Follow these steps to form clusters by K-means \u2212. K-means picks k number of points for each cluster ...", "dateLastCrawled": "2022-02-03T00:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "notes-2/Deep Learning.md at master \u00b7 rsantana-isg/notes-2 \u00b7 GitHub", "url": "https://github.com/rsantana-isg/notes-2/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/rsantana-isg/notes-2/blob/master/Deep Learning.md", "snippet": "These more brain-<b>like</b> RNNs will allocate neighboring RNN parts to related behaviors, and distant RNN parts to less related ones, thus self-modularizing in a way more general than that of traditional self-<b>organizing</b> maps in feedforward neural networks. They will also implement Occam\u2019s razor as a by-product of energy minimization, by finding simple (highly generalizing) problem solutions that require few active neurons and few, mostly short connections. The more distant future may belong to ...", "dateLastCrawled": "2022-01-02T20:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Dehradun", "url": "https://www.dituniversity.edu.in/Uploads/image/1440imguf_7BTCSE(withML)-Course-StructureandSyllabus-Batch-2019-2023.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.dituniversity.edu.in/Uploads/image/1440imguf_7BTCSE(withML)-Course...", "snippet": "Applicable for <b>Batch</b>: 2019-23 Amended by the BoS and approved by the Academic Council at its 11th Meeting held on 29.04.2019 DIT UNIVERSITY Dehradun Detailed Course Structure&amp; Syllabus of B.Tech \u2013 CSE (with Specialization in ML) Course Structure&amp; Syllabus of B.Tech \u2013 Computer Science &amp; Engineering (With specialization in ML) Applicable for <b>Batch</b>: 2019-23 Amended by the BoS and approved by the Academic Council at its 11th Meeting held on 29.04.2019 Year: 1st Semester: I Course Category ...", "dateLastCrawled": "2021-10-14T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Artificial Intelligence: A Modern Approach</b>, 3rd Edition - SILO.PUB", "url": "https://silo.pub/artificial-intelligence-a-modern-approach-3rd-edition.html", "isFamilyFriendly": true, "displayUrl": "https://silo.pub/<b>artificial-intelligence-a-modern-approach</b>-3rd-edition.html", "snippet": "The general form of Bayes&#39; rule with <b>normalization</b> is (13.15) P(Y I X) = aP(X I Y)P(Y) , where a is the <b>normalization</b> constant needed to make the entries in P(Y I X) swn to l . One obvious question to ask about Bayes&#39; rule is why one might have available the conditional probability in one direction, but not the other. In the meningitis domain, perhaps the doctor knows that a stiff neck implies meningitis in 1 out of 5000 cases; that is, the doctor has quantitative information in the ...", "dateLastCrawled": "2022-01-31T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Is K means <b>clustering considered supervised or unsupervised</b> ... - Quora", "url": "https://www.quora.com/Is-K-means-clustering-considered-supervised-or-unsupervised-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-K-means-<b>clustering-considered-supervised-or-unsupervised</b>...", "snippet": "Answer (1 of 8): It\u2019s unsupervised. Roughly you don&#39;t have a label, in other words, you don&#39;t know what you are looking for. For example, you can use some personal data <b>like</b> age, genre, height and weight, after applying K-Means with, for instance, 4 centroids, your population will be clustered by...", "dateLastCrawled": "2021-12-16T17:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep Learning</b> - GitHub Pages", "url": "https://srdas.github.io/DLBook/ConvNets.html", "isFamilyFriendly": true, "displayUrl": "https://srdas.github.io/DLBook/ConvNets.html", "snippet": "This model was very <b>similar</b> model to modern ConvNets in its structure, however it lacked an efficient training algorithm, such as Backprop. LeCun et al. later put the two <b>pieces</b> of the <b>puzzle</b> together while working at Bell Labs during the 90s, and created the modern ConvNet, whose design was based on the NeoCognitron, and which could also be trained using Backprop. LeCun\u2019s system, called LeNet5, was successfully commercially deployed to read handwritten signatures in checks. Research in ...", "dateLastCrawled": "2022-01-31T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Deep Learning Pipeline: Building a Deep Learning Model with TensorFlow</b> ...", "url": "https://dokumen.pub/deep-learning-pipeline-building-a-deep-learning-model-with-tensorflow-1nbsped-1484253485-9781484253489.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>deep-learning-pipeline-building-a-deep</b>-learning-model-with-tensor...", "snippet": "You can think that you have a small piece of the <b>puzzle</b>, and the goal is to solve it. But the picture is messy because it is composed of a thousand little <b>pieces</b>, and in real-life data there\u2019s always measurement noise and missing <b>pieces</b>. So, by processing the data, you make it easier for the model to see the clear picture and understand it very well. This is a crucial step in the pipeline, and the accuracy of the model depends on it. This step is about preparing the data in such a way that ...", "dateLastCrawled": "2022-01-30T17:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Growing Neural Cellular Automata - Distill", "url": "https://distill.pub/2020/growing-ca/", "isFamilyFriendly": true, "displayUrl": "https://distill.pub/2020/growing-ca", "snippet": "The biggest <b>puzzle</b> in this field is the question of how the cell collective knows what to build and when to stop. The sciences of genomics and stem cell biology are only part of the <b>puzzle</b>, as they explain the distribution of specific components in each cell, and the establishment of different types of cells. While we know of many genes that are required for the process of regeneration, we still do not know the algorithm that is sufficient for cells to know how to build or remodel complex ...", "dateLastCrawled": "2022-02-03T06:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Python Machine Learning: Machine Learning and Deep Learning with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with...", "snippet": "Mini-<b>batch</b> gradient descent A compromise between <b>batch</b> gradient descent and SGD is so-called mini-<b>batch</b> learning. Mini-<b>batch</b> learning can be understood as applying <b>batch</b> gradient descent to smaller subsets of the training data, for example, 32 training examples at a time. The advantage over <b>batch</b> gradient descent is that convergence is reached faster via mini-batches because of the more frequent weight updates. Furthermore, mini-<b>batch</b> learning allows us to replace the for loop over the ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Application of evolutionary and swarm optimization in <b>computer vision</b> ...", "url": "https://ipsjcva.springeropen.com/articles/10.1186/s41074-020-00065-9", "isFamilyFriendly": true, "displayUrl": "https://ipsjcva.springeropen.com/articles/10.1186/s41074-020-00065-9", "snippet": "The pairwise compatibility of the adjacent <b>pieces</b> is evaluated based on <b>color</b> similarity along their abutting edges. A chromosome is represented by a matrix of the same size as the <b>puzzle</b>, and each element is assigned a piece number. This simple encoding causes a serious problem: offspring yielded from a traditional crossover may contain duplicate and/or missing <b>pieces</b>. Thus, the authors proposed a novel crossover operator based on a kernel-growing technique, which starts with a single piece ...", "dateLastCrawled": "2022-02-02T18:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "AI with Python \u00e2 Quick Guide - <b>Tutorialspoint</b>", "url": "https://www.tutorialspoint.com/artificial_intelligence_with_python/artificial_intelligence_with_python_quick_guide.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/artificial_intelligence_with_python/artificial...", "snippet": "The <b>normalization</b> of variables needed otherwise higher range variables can bias it. In KNN, we need to work on pre-processing stage like noise removal. K-Means Clustering . As the name suggests, it is used to solve the clustering problems. It is basically a type of unsupervised learning. The main logic of K-Means clustering algorithm is to classify the data set through a number of clusters. Follow these steps to form clusters by K-means \u2212. K-means picks k number of points for each cluster ...", "dateLastCrawled": "2022-02-03T00:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "notes-2/Deep Learning.md at master \u00b7 rsantana-isg/notes-2 \u00b7 GitHub", "url": "https://github.com/rsantana-isg/notes-2/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/rsantana-isg/notes-2/blob/master/Deep Learning.md", "snippet": "This <b>is similar</b> to plugging the pixels of the image into a char-rnn, but the RNNs run both horizontally and vertically over the image instead of just a 1D sequence of characters. But the ordering of the dimensions, although often arbitrary, can be critical to the training of the model. The sequential nature of this model limits its computational efficiency. For example, its sampling procedure is sequential and non-parallelizable. Additionally, there is no natural latent representation ...", "dateLastCrawled": "2022-01-02T20:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deep Learning for Coders with fastai and PyTorch [First edition ...", "url": "https://dokumen.pub/qdownload/deep-learning-for-coders-with-fastai-and-pytorch-first-edition-9781492045496-1492045497.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/qdownload/deep-learning-for-coders-with-fastai-and-pytorch-first...", "snippet": "<b>Color</b> Images Improving Training Stability A Simple Baseline Increase <b>Batch</b> Size 1cycle Training <b>Batch</b> <b>Normalization</b> Conclusion Questionnaire Further Research Chapter 14. ResNets Going Back to Imagenette Building a Modern CNN: ResNet Skip Connections A State-of-the-Art ResNet Bottleneck Layers Conclusion Questionnaire Further Research Chapter 15. Application Architectures Deep Dive Computer Vision cnn_learner unet_learner A Siamese Network Natural Language Processing Tabular Conclusion ...", "dateLastCrawled": "2022-01-29T10:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Dehradun", "url": "https://www.dituniversity.edu.in/Uploads/image/1440imguf_7BTCSE(withML)-Course-StructureandSyllabus-Batch-2019-2023.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.dituniversity.edu.in/Uploads/image/1440imguf_7BTCSE(withML)-Course...", "snippet": "CO2. Apply basic Engineering concepts based on force, <b>shape</b> and dimension for selection of material CO3. Comprehend the action of Forces, Moments and other loads on systems of rigid bodies. CO4. Compute the reactive forces and the effects that develop as a result of the external loads. CO5. Express the relationship between the motions of bodies. Text book [TB]: 3. Engineering Mechanics by S.S. Bhavikatti, New Age International Publisher, New Delhi, 3rd edition 2009. 4. Engineering Mechanics ...", "dateLastCrawled": "2021-10-14T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Is K means <b>clustering considered supervised or unsupervised</b> ... - Quora", "url": "https://www.quora.com/Is-K-means-clustering-considered-supervised-or-unsupervised-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-K-means-<b>clustering-considered-supervised-or-unsupervised</b>...", "snippet": "Answer (1 of 8): It\u2019s unsupervised. Roughly you don&#39;t have a label, in other words, you don&#39;t know what you are looking for. For example, you can use some personal data like age, genre, height and weight, after applying K-Means with, for instance, 4 centroids, your population will be clustered by...", "dateLastCrawled": "2021-12-16T17:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep Learning</b> - GitHub Pages", "url": "https://srdas.github.io/DLBook/ConvNets.html", "isFamilyFriendly": true, "displayUrl": "https://srdas.github.io/DLBook/ConvNets.html", "snippet": "x_train <b>shape</b>: (60000, 28, 28, 1) 60000 train samples 10000 test samples. Recall that each digit is coded as a \\(28 \\times 28\\) pixel frame, i.e., a set of 784 values. Each one ranges from 0 to 255, with zero signifying no ink in the pixel and 255 being the darkest <b>color</b> it <b>can</b> attain. The numerical coding of pixels is an important part of the ...", "dateLastCrawled": "2022-01-31T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "AI with Python \u00e2 Quick Guide - <b>Tutorialspoint</b>", "url": "https://www.tutorialspoint.com/artificial_intelligence_with_python/artificial_intelligence_with_python_quick_guide.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/artificial_intelligence_with_python/artificial...", "snippet": "Followings are two types of <b>normalization</b> which <b>can</b> be used in machine learning \u2212 . L1 <b>Normalization</b>. It is also referred to as Least Absolute Deviations. This kind of <b>normalization</b> modifies the values so that the sum of the absolute values is always up to 1 in each row. It <b>can</b> be implemented on the input data with the help of the following Python code \u2212 # Normalize data data_normalized_l1 = preprocessing.normalize(input_data, norm = &#39;l1&#39;) print(&quot;\\nL1 normalized data:\\n&quot;, data_normalized ...", "dateLastCrawled": "2022-02-03T00:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Python Machine Learning: Machine Learning and Deep Learning with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with...", "snippet": "Mini-<b>batch</b> gradient descent A compromise between <b>batch</b> gradient descent and SGD is so-called mini-<b>batch</b> learning. Mini-<b>batch</b> learning <b>can</b> be understood as applying <b>batch</b> gradient descent to smaller subsets of the training data, for example, 32 training examples at a time. The advantage over <b>batch</b> gradient descent is that convergence is reached faster via mini-batches because of the more frequent weight updates. Furthermore, mini-<b>batch</b> learning allows us to replace the for loop over the ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "notes-2/Deep Learning.md at master \u00b7 rsantana-isg/notes-2 \u00b7 GitHub", "url": "https://github.com/rsantana-isg/notes-2/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/rsantana-isg/notes-2/blob/master/Deep Learning.md", "snippet": "You <b>can</b> tell someone what <b>thought</b> you are having by producing a string of words that would normally give rise to that <b>thought</b> but this doesn&#39;t mean the <b>thought</b> is a string of symbols in some unambiguous internal language. The new recurrent network translation models make it clear that you <b>can</b> get a very long way by treating a <b>thought</b> as a big state vector. Traditional AI researchers will be horrified by the view that thoughts are merely the hidden states of a recurrent net and even more ...", "dateLastCrawled": "2022-01-02T20:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Machine Learning and Big Data Analytics Paradigms: Analysis ...", "url": "https://ebin.pub/machine-learning-and-big-data-analytics-paradigms-analysis-applications-and-challenges-1st-ed-2021-3030593371-9783030593377.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/machine-learning-and-big-data-analytics-paradigms-analysis...", "snippet": "Using fine-tuning CNN VGG16 model by adding several dense layers, <b>Batch</b> <b>Normalization</b> layer, Dropout layer and finally the classification layer, this lead to accuracy 95.87%. Automated hyperparameters optimization is important to help the human by reducing his effort necessary for applying machine learning. It used to enhance the performance of the algorithm for machine learning. The Gaussian method <b>can</b> be used for hyperparameters optimization. It uses the predictive distribution of the ...", "dateLastCrawled": "2022-01-29T22:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Dehradun", "url": "https://www.dituniversity.edu.in/Uploads/image/1440imguf_7BTCSE(withML)-Course-StructureandSyllabus-Batch-2019-2023.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.dituniversity.edu.in/Uploads/image/1440imguf_7BTCSE(withML)-Course...", "snippet": "Applicable for <b>Batch</b>: 2019-23 Amended by the BoS and approved by the Academic Council at its 11th Meeting held on 29.04.2019 At the end of the course, the student <b>can</b> : CO1. To know Newton\u2019s laws of motion, potentials, conservation of energy, momentum and angular momentum, and be able to apply them to projectiles, circular motion, and gravity", "dateLastCrawled": "2021-10-14T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Deep Learning Pipeline: Building a Deep Learning Model with TensorFlow</b> ...", "url": "https://dokumen.pub/deep-learning-pipeline-building-a-deep-learning-model-with-tensorflow-1nbsped-1484253485-9781484253489.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>deep-learning-pipeline-building-a-deep</b>-learning-model-with-tensor...", "snippet": "You <b>can</b> think that you have a small piece of the <b>puzzle</b>, and the goal is to solve it. But the picture is messy because it is composed of a thousand little <b>pieces</b>, and in real-life data there\u2019s always measurement noise and missing <b>pieces</b>. So, by processing the data, you make it easier for the model to see the clear picture and understand it very well. This is a crucial step in the pipeline, and the accuracy of the model depends on it. This step is about preparing the data in such a way that ...", "dateLastCrawled": "2022-01-30T17:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deep Learning for Coders with fastai and PyTorch [First edition ...", "url": "https://dokumen.pub/qdownload/deep-learning-for-coders-with-fastai-and-pytorch-first-edition-9781492045496-1492045497.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/qdownload/deep-learning-for-coders-with-fastai-and-pytorch-first...", "snippet": "We <b>can</b> take a look at a few of those items by calling the show_<b>batch</b> method on a DataLoader: dls.valid.show_<b>batch</b>(max_n=4, nrows=1) By default, Resize crops the images to fit a square <b>shape</b> of the size requested, using the full width or height. This <b>can</b> result in losing some important details. Alterna\u2010 tively, you <b>can</b> ask fastai to pad the ...", "dateLastCrawled": "2022-01-29T10:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Hierarchical Item Relationships</b> - Zotero Forums", "url": "https://forums.zotero.org/discussion/391/hierarchical-item-relationships/", "isFamilyFriendly": true, "displayUrl": "https://forums.zotero.org/discussion/391", "snippet": "There are two distinct <b>pieces</b> here: the hierarchical data model and user-defined types/fields. The current plan is to do hierarchical types first, with a defined ontology of types and fields. That&#39;s going to occupy a good amount of time, less for the implementation in the software itself (that&#39;ll be a pretty straightforward process) than for the interface design; figuring out exactly how to represent and work with hierarchical items isn&#39;t easy, and we&#39;ve got a lot of work to do. On the ...", "dateLastCrawled": "2022-02-03T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Donet Professional: <b>Interview Questions</b>", "url": "https://hackdotnet.blogspot.com/2008/04/interview-questions.html", "isFamilyFriendly": true, "displayUrl": "https://hackdotnet.blogspot.com/2008/04/<b>interview-questions</b>.html", "snippet": "I <b>can</b> update the actual database as a <b>batch</b>. ... no other letter <b>can</b> be 3 and all other M in the <b>puzzle</b> must be 3. 10)One of the four people - Mr. Clinton, his wife Monika, their son Mandy and their daughter Cindy - is a singer and another is a dancer. Mr. Clinton is older than his wife and Mady is older than his sister. If the singer and the dancer are the same sex, then the dancer is older than the singer. If neither the singer nor the dancer is the parent of the other, then the singer is ...", "dateLastCrawled": "2021-10-25T09:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Application of evolutionary and swarm optimization in <b>computer vision</b> ...", "url": "https://ipsjcva.springeropen.com/articles/10.1186/s41074-020-00065-9", "isFamilyFriendly": true, "displayUrl": "https://ipsjcva.springeropen.com/articles/10.1186/s41074-020-00065-9", "snippet": "The pairwise compatibility of the adjacent <b>pieces</b> is evaluated based on <b>color</b> similarity along their abutting edges. A chromosome is represented by a matrix of the same size as the <b>puzzle</b>, and each element is assigned a piece number. This simple encoding causes a serious problem: offspring yielded from a traditional crossover may contain duplicate and/or missing <b>pieces</b>. Thus, the authors proposed a novel crossover operator based on a kernel-growing technique, which starts with a single piece ...", "dateLastCrawled": "2022-02-02T18:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "AI with Python \u00e2 Quick Guide - <b>Tutorialspoint</b>", "url": "https://www.tutorialspoint.com/artificial_intelligence_with_python/artificial_intelligence_with_python_quick_guide.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/artificial_intelligence_with_python/artificial...", "snippet": "Followings are two types of <b>normalization</b> which <b>can</b> be used in machine learning \u2212 . L1 <b>Normalization</b>. It is also referred to as Least Absolute Deviations. This kind of <b>normalization</b> modifies the values so that the sum of the absolute values is always up to 1 in each row. It <b>can</b> be implemented on the input data with the help of the following Python code \u2212 # Normalize data data_normalized_l1 = preprocessing.normalize(input_data, norm = &#39;l1&#39;) print(&quot;\\nL1 normalized data:\\n&quot;, data_normalized ...", "dateLastCrawled": "2022-02-03T00:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Chapter 7 Data analysis in the current era</b> | Museum of Spatial ...", "url": "https://pachterlab.github.io/LP_2021/current-analysis.html", "isFamilyFriendly": true, "displayUrl": "https://pachterlab.github.io/LP_2021/current-analysis.html", "snippet": "The latent space <b>can</b> be concatenated to fixed covariates such as <b>batch</b>, technology used to collect data, spatial coordinates, and etc. and is estimated with black box variational inference. Missing data in gene expression and covariates <b>can</b> be estimated from the latent space, thus enabling mapping scRNA-seq cells to spatial coordinates and imputing gene expression, and the latent space <b>can</b> be collapsed across a covariate to remove its effect. The latent space has a Gaussian prior with ...", "dateLastCrawled": "2022-01-26T02:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Deep Learning Pipeline: Building a Deep Learning Model with TensorFlow</b> ...", "url": "https://dokumen.pub/deep-learning-pipeline-building-a-deep-learning-model-with-tensorflow-1nbsped-1484253485-9781484253489.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>deep-learning-pipeline-building-a-deep</b>-learning-model-with-tensor...", "snippet": "You <b>can</b> think that you have a small piece of the <b>puzzle</b>, and the goal is to solve it. But the picture is messy because it is composed of a thousand little <b>pieces</b>, and in real-life data there\u2019s always measurement noise and missing <b>pieces</b>. So, by processing the data, you make it easier for the model to see the clear picture and understand it very well. This is a crucial step in the pipeline, and the accuracy of the model depends on it. This step is about preparing the data in such a way that ...", "dateLastCrawled": "2022-01-30T17:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Deep Learning</b> - GitHub Pages", "url": "https://srdas.github.io/DLBook/ConvNets.html", "isFamilyFriendly": true, "displayUrl": "https://srdas.github.io/DLBook/ConvNets.html", "snippet": "x_train <b>shape</b>: (60000, 28, 28, 1) 60000 train samples 10000 test samples. Recall that each digit is coded as a \\(28 \\times 28\\) pixel frame, i.e., a set of 784 values. Each one ranges from 0 to 255, with zero signifying no ink in the pixel and 255 being the darkest <b>color</b> it <b>can</b> attain. The numerical coding of pixels is an important part of the ...", "dateLastCrawled": "2022-01-31T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Why are unsupervised learning algorithms such as K-means clustering ...", "url": "https://www.quora.com/Why-are-unsupervised-learning-algorithms-such-as-K-means-clustering-considered-machine-learning-when-in-fact-they-have-been-explicitly-programmed", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-are-unsupervised-learning-algorithms-such-as-K-means...", "snippet": "Answer (1 of 4): In K-means clustering, the centroids of each cluster are not determined explicitly. In fact, finding the actual global optima is NP complete. Instead, the centroids are learned from the data. Random subsets of data would lead to different centroids, hence, different cluster reg...", "dateLastCrawled": "2022-01-06T01:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "notes-2/Deep Learning.md at master \u00b7 rsantana-isg/notes-2 \u00b7 GitHub", "url": "https://github.com/rsantana-isg/notes-2/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/rsantana-isg/notes-2/blob/master/Deep Learning.md", "snippet": "&quot;<b>Compared</b> to recurrent networks these models <b>can</b> have many, many layers which <b>can</b> make up for the lack of explicit state to some extent. Also the fact that they <b>can</b> be fully parallelised across time during training and don&#39;t require backpropagation through time is a considerable advantage. Not to mention that it&#39;s much easier to build models with large temporal receptive fields.&quot;", "dateLastCrawled": "2022-01-02T20:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Donet Professional: <b>Interview Questions</b>", "url": "https://hackdotnet.blogspot.com/2008/04/interview-questions.html", "isFamilyFriendly": true, "displayUrl": "https://hackdotnet.blogspot.com/2008/04/<b>interview-questions</b>.html", "snippet": "I <b>can</b> update the actual database as a <b>batch</b>. ... no other letter <b>can</b> be 3 and all other M in the <b>puzzle</b> must be 3. 10)One of the four people - Mr. Clinton, his wife Monika, their son Mandy and their daughter Cindy - is a singer and another is a dancer. Mr. Clinton is older than his wife and Mady is older than his sister. If the singer and the dancer are the same sex, then the dancer is older than the singer. If neither the singer nor the dancer is the parent of the other, then the singer is ...", "dateLastCrawled": "2021-10-25T09:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is K means <b>clustering considered supervised or unsupervised</b> ... - Quora", "url": "https://www.quora.com/Is-K-means-clustering-considered-supervised-or-unsupervised-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-K-means-<b>clustering-considered-supervised-or-unsupervised</b>...", "snippet": "Answer (1 of 8): It\u2019s unsupervised. Roughly you don&#39;t have a label, in other words, you don&#39;t know what you are looking for. For example, you <b>can</b> use some personal data like age, genre, height and weight, after applying K-Means with, for instance, 4 centroids, your population will be clustered by...", "dateLastCrawled": "2021-12-16T17:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "techical interview | <b>Massive listing of interview Q</b> &amp; A", "url": "https://aninterview.wordpress.com/category/techical-interview/", "isFamilyFriendly": true, "displayUrl": "https://aninterview.wordpress.com/category/techical-interview", "snippet": "The <b>shape</b> in the sketch below is that of a square attached to half of a similar square. Divide it into four equal <b>pieces</b>. Ans: Hint : The figure <b>can</b> be divided into 12 equal triangles.===== START HERE =====20) There are two balls touching each other circumferencically. The radius of the big ball is 4 times the diameter of the small all. The outer small ball rotates in anticlockwise direction circumferencically over the bigger one at the rate of 16 rev/sec. The bigger wheel also rotates ...", "dateLastCrawled": "2022-02-03T05:37:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Understanding Batch Normalization</b> My musings on <b>Machine</b> <b>learning</b> and AI", "url": "https://udohsolomon.github.io/_posts/2017-06-21-understanding-batch-normalization/", "isFamilyFriendly": true, "displayUrl": "https://udohsolomon.github.io/_posts/2017-06-21-<b>understanding-batch-normalization</b>", "snippet": "<b>Understanding Batch Normalization</b> I ... As an <b>analogy</b>, let us say you train your dataset on all images of black cats, if you try to apply this same network to dataset with coloured cats where the positive examples are not just black cats, then your classifier or prediction will perform poorly. This concept where the training dataset distribution is different from the text dataset distribution is known as . The idea is that if you\u2019ve learned some to mapping, , and at any time the ...", "dateLastCrawled": "2022-01-31T01:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding <b>Batch</b> <b>Normalization</b> My musings on <b>Machine</b> <b>learning</b> and AI", "url": "https://udohsolomon.github.io/neural%20network/understanding-batch-normalization/", "isFamilyFriendly": true, "displayUrl": "https://udohsolomon.github.io/neural network/understanding-<b>batch</b>-<b>normalization</b>", "snippet": "Understanding <b>Batch</b> <b>Normalization</b> 4 minute read I ... As an <b>analogy</b>, let us say you train your dataset on all images of black cats, if you try to apply this same network to dataset with coloured cats where the positive examples are not just black cats, then your classifier or prediction will perform poorly. This concept where the training dataset distribution is different from the text dataset distribution is known as . The idea is that if you\u2019ve learned some to mapping, , and at any time ...", "dateLastCrawled": "2022-01-12T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A High-<b>Level Overview of Batch Normalization</b> | by Jason Jewik | The ...", "url": "https://medium.com/swlh/a-high-level-overview-of-batch-normalization-8d550cead20b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/a-high-<b>level-overview-of-batch-normalization</b>-8d550cead20b", "snippet": "<b>Batch</b> <b>normalization</b>: ... Many other <b>machine</b> <b>learning</b> algorithms also rest atop empirical evidence, sometimes more so than theory. \u00af\\_(\u30c4)_/\u00af Accelerating <b>Batch</b> <b>Normalization</b> Networks. The ...", "dateLastCrawled": "2021-08-06T01:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "13.6 <b>Batch Normalization</b> - GitHub Pages", "url": "https://jermwatt.github.io/machine_learning_refined/notes/13_Multilayer_perceptrons/13_6_Batch_normalization.html", "isFamilyFriendly": true, "displayUrl": "https://jermwatt.github.io/<b>machine</b>_<b>learning</b>_refined/notes/13_Multilayer_perceptrons/13...", "snippet": "* The following is part of an early draft of the second edition of <b>Machine</b> <b>Learning</b> Refined. The published text (with ... This natural extension of input <b>normalization</b> is popularly referred to as <b>batch normalization</b>. In [2]: <b>Batch normalization</b>\u00b6 In Section 9.3 we described standard <b>normalization</b>, a simple technique for normalizing a linear model that makes minimizing cost functions involving linear models considerably easier. With our generic linear model \\begin{equation} \\text{model}\\left ...", "dateLastCrawled": "2022-01-27T05:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "7.5. <b>Batch Normalization</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_convolutional-modern/batch-norm.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_convolutional-modern/<b>batch</b>-norm.html", "snippet": "To motivate <b>batch normalization</b>, let us review a few practical challenges that arise when training <b>machine</b> <b>learning</b> models and neural networks in particular. First, choices regarding data preprocessing often make an enormous difference in the final results. Recall our application of MLPs to predicting house prices (Section 4.10). Our first step ...", "dateLastCrawled": "2022-01-31T08:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Xavier initialization and batch normalization, my understanding</b> | by ...", "url": "https://shiyan.medium.com/xavier-initialization-and-batch-normalization-my-understanding-b5b91268c25c", "isFamilyFriendly": true, "displayUrl": "https://shiyan.medium.com/<b>xavier-initialization-and-batch-normalization-my</b>...", "snippet": "Mr. Ali Rahimi\u2019s recent talk put the <b>batch</b> <b>normalization</b> paper and the term \u201cinternal covariate shift\u201d under the spotlight. I kinda agree with Mr. Rahimi on this one, I too don\u2019t understand the necessity and the benefit of using this term. In this post, I\u2019d like to explain my understanding of <b>batch</b> <b>normalization</b> and also Xavier initialization, which I think is related to <b>batch</b> <b>normalization</b>.", "dateLastCrawled": "2022-01-31T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - Instance Normalisation vs <b>Batch</b> normalisation ...", "url": "https://stackoverflow.com/questions/45463778/instance-normalisation-vs-batch-normalisation", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/45463778", "snippet": "<b>machine</b>-<b>learning</b> neural-network computer-vision conv-neural-network <b>batch</b>-<b>normalization</b>. Share. Improve this question. Follow edited Jan 5 ... A simple <b>analogy</b>: during data pre-processing step, it&#39;s possible to normalize the data on per-image basis or normalize the whole data set. Credit: the formulas are from here. Which <b>normalization</b> is better? The answer depends on the network architecture, in particular on what is done after the <b>normalization</b> layer. Image classification networks usually ...", "dateLastCrawled": "2022-01-28T16:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Batch</b> <b>Normalization</b> and prediction of single sample : deeplearning", "url": "https://www.reddit.com/r/deeplearning/comments/s1g10a/batch_normalization_and_prediction_of_single/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/deep<b>learning</b>/comments/s1g10a/<b>batch</b>_<b>normalization</b>_and...", "snippet": "\ud83c\udfc3 Although a relatively simple optimization algorithm, gradient descent (and its variants) has found an irreplaceable place in the heart of <b>machine</b> <b>learning</b>. This is majorly due to the fact that it has shown itself to be quite handy when optimizing deep neural networks and other models. The models behind the latest advances in ML and computer vision are majorly optimized using gradient descent and its variants like Adam and gradient descent with momentum.", "dateLastCrawled": "2022-01-13T11:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Batch</b>, Mini <b>Batch</b> &amp; Stochastic <b>Gradient Descent</b> | by Sushant Patrikar ...", "url": "https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>batch</b>-mini-<b>batch</b>-stochastic-<b>gradient-descent</b>-7a62ecba642a", "snippet": "<b>Machine</b> <b>Learning</b> behind the scenes (Source: https: ... <b>Batch</b> <b>Gradient Descent</b> converges directly to minima. SGD converges faster for larger datasets. But, since in SGD we use only one example at a time, we cannot implement the vectorized implementation on it. This can slow down the computations. To tackle this problem, a mixture of <b>Batch</b> <b>Gradient Descent</b> and SGD is used. Neither we use all the dataset all at once nor we use the single example at a time. We use a <b>batch</b> of a fixed number of ...", "dateLastCrawled": "2022-02-02T11:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Classifying and completing word analogies by <b>machine</b> <b>learning</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0888613X21000141", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0888613X21000141", "snippet": "Still we have to acknowledge the fact that while <b>machine</b> <b>learning</b> techniques may be very powerful tools for dealing with <b>analogy</b> classification and <b>analogy</b> completion tasks, this does not provide any contribution on what is exactly an <b>analogy</b> between words. It is likely that a strict judgment for deciding if an analogical proportion is valid or not, or if is a matter of degree (or of context), would require more high level information than the one provided by embeddings.", "dateLastCrawled": "2021-11-13T01:15:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>batch normalization</b>?. How does it help? | by NVS Yashwanth ...", "url": "https://towardsdatascience.com/what-is-batch-normalization-46058b4f583", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/what-is-<b>batch-normalization</b>-46058b4f583", "snippet": "The intuition behind <b>batch normalization is similar</b>. <b>Batch normalization</b> does the same for hidden units. Why the word bat c h? Because it normalized the values in the current batch. These are sometimes called the batch statistics. Specifically, <b>batch normalization</b> normalizes the output of a previous layer by subtracting the batch mean and dividing by the batch standard deviation. This is much similar to feature scaling which is done to speed up the <b>learning</b> process and converge to a solution ...", "dateLastCrawled": "2022-02-02T15:27:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(batch normalization)  is like +(organizing puzzle pieces by color and shape)", "+(batch normalization) is similar to +(organizing puzzle pieces by color and shape)", "+(batch normalization) can be thought of as +(organizing puzzle pieces by color and shape)", "+(batch normalization) can be compared to +(organizing puzzle pieces by color and shape)", "machine learning +(batch normalization AND analogy)", "machine learning +(\"batch normalization is like\")", "machine learning +(\"batch normalization is similar\")", "machine learning +(\"just as batch normalization\")", "machine learning +(\"batch normalization can be thought of as\")", "machine learning +(\"batch normalization can be compared to\")"]}