{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) TRUST, <b>AUTOMATION</b> <b>BIAS</b> AND AVERSION: ALGORITHMIC DECISION-MAKING ...", "url": "https://www.academia.edu/67685259/TRUST_AUTOMATION_BIAS_AND_AVERSION_ALGORITHMIC_DECISION_MAKING_IN_THE_CONTEXT_OF_CREDIT_SCORING", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/67685259/TRUST_<b>AUTOMATION</b>_<b>BIAS</b>_AND_AVERSION_ALGORITHMIC...", "snippet": "Reducing cognitive load, <b>trusting</b> algorithmic <b>systems</b> more than <b>humans</b>, and handing <b>over</b> responsibility increase the occurrence <b>automation</b> <b>bias</b>. Moreover, the degree to which operators perceive themselves socially accountable \u2013 for instance, when in direct interaction with a customer to whom they must justify a decision \u2013 plays a role regarding the frequency of omission and commission errors. People who feel accountable were more thoroughly examining the decisions taken by an algorithmic ...", "dateLastCrawled": "2022-01-16T01:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>50 Cognitive Biases to be Aware</b> of so You Can be the Very ... - TitleMax", "url": "https://www.titlemax.com/discovery-center/lifestyle/50-cognitive-biases-to-be-aware-of-so-you-can-be-the-very-best-version-of-you/", "isFamilyFriendly": true, "displayUrl": "https://www.titlemax.com/disc<b>over</b>y-center/lifestyle/<b>50-cognitive-biases-to-be-aware</b>-of...", "snippet": "<b>Automation</b> <b>Bias</b>: We rely on <b>automated</b> <b>systems</b>, sometimes <b>trusting</b> too much in the <b>automated</b> correction of actually correct decisions. Google Effect (aka Digital Amnesia): We tend to forget information that\u2019s easily looked up in search engines. Reactance: We do the opposite of what we\u2019re told, especially when we perceive threats to personal freedoms. Confirmation <b>Bias</b>: We tend to find and remember information that confirms our perceptions. Backfire Effect: Disproving evidence sometimes ...", "dateLastCrawled": "2022-02-02T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Elon Musk Says to Be Aware of These 50 Cognitive Biases | by Yujian ...", "url": "https://medium.com/the-hive-mind/elon-musk-says-to-be-aware-of-these-50-cognitive-biases-bec1cc9c5471", "isFamilyFriendly": true, "displayUrl": "https://medium.com/the-hive-mind/elon-musk-says-to-be-aware-of-these-50-cognitive...", "snippet": "<b>Automation</b> <b>bias</b> is a relatively new cognitive <b>bias</b>. It refers to our tendency to rely on <b>automated</b> <b>systems</b> too much, sometimes <b>trusting</b> <b>automated</b> correction of already correct decisions. This is a ...", "dateLastCrawled": "2022-01-30T10:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Elon Musk says all children must be aware of these 50 cognitive biases ...", "url": "http://fintechweb.bond/2022/01/elon-musk-says-all-children-must-be-aware-of-these-50-cognitive-biases-and-to-avoid-them/", "isFamilyFriendly": true, "displayUrl": "fintechweb.bond/2022/01/...must-be-aware-of-these-50-cognitive-<b>bias</b>es-and-to-avoid-them", "snippet": "<b>Automation</b> <b>Bias</b>: We rely on <b>automated</b> <b>systems</b>, sometimes <b>trusting</b> too much in the <b>automated</b> correction of the actually correct decisions. 20. Google effect (aka Digital Amnesia): We tend to forget information that\u2019s easily looked up in search engines. 21. Reactance: We do the opposite of what we\u2019re told, especially when we perceive threats to personal freedoms. 22. Confirmation <b>Bias</b>: We tend to find and remember information that confirms our perceptions. 23. Backfire Effect: Disproving ...", "dateLastCrawled": "2022-01-31T08:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is <b>automation bias in cognitive psychology</b>? - Quora", "url": "https://www.quora.com/What-is-automation-bias-in-cognitive-psychology", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>automation-bias-in-cognitive-psychology</b>", "snippet": "Answer (1 of 5): From Wikipedia: \u201c<b>Automation</b> <b>bias</b> is the propensity for <b>humans</b> to favor suggestions from <b>automated</b> decision-making <b>systems</b> and to ignore contradictory information made without <b>automation</b>, even if it is correct.\u201dCummings, Mary (2004). &quot;<b>Automation</b> <b>Bias</b> in Intelligent Time Critical D...", "dateLastCrawled": "2022-01-16T04:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Elon Musk Says All Kids Need to Know About These 50 Cognitive Biases", "url": "https://www.businessinsider.com/elon-musk-says-children-should-learn-these-50-cognitive-biases-2022-1", "isFamilyFriendly": true, "displayUrl": "https://<b>www.businessinsider.com</b>/elon-musk-says-children-should-learn-these-50...", "snippet": "19. <b>Automation</b> <b>Bias</b>: We rely on <b>automated</b> <b>systems</b>, sometimes <b>trusting</b> too much in the <b>automated</b> correction of the actually correct decisions. 20. Google effect (aka Digital Amnesia): We tend to ...", "dateLastCrawled": "2022-02-02T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Automation Doesn\u2019t Make Systems Safer By Marginalizing Users</b> | by ...", "url": "https://medium.com/geekculture/automation-doesnt-make-systems-safer-by-marginalizing-users-8a96f8ce6a9e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/<b>automation-doesnt-make-systems-safer-by-marginalizing</b>...", "snippet": "One extremely well-researched example is <b>automation</b> <b>bias</b>, in which users tend to <b>over</b>-trust and <b>over</b>-rely on <b>automation</b> outputs (the majority of <b>automated</b> decision support <b>systems</b> are only 80\u201390 ...", "dateLastCrawled": "2021-03-24T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Measurement of Trust in <b>Automation</b>: A Narrative Review and Reference Guide", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8562383/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8562383", "snippet": "With the rise of <b>automated</b> and autonomous agents, research examining Trust in <b>Automation</b> (TiA) has attracted considerable attention <b>over</b> the last few decades. Trust is a rich and complex construct which has sparked a multitude of measures and approaches to study and understand it. This comprehensive narrative review addresses known methods that have been used to capture TiA. We examined measurements deployed in existing empirical works, categorized those measures into self-report, behavioral ...", "dateLastCrawled": "2022-01-15T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Misuse of <b>automated</b> decision aids: Complacency, <b>automation</b> <b>bias</b> and the ...", "url": "https://www.sciencedirect.com/science/article/pii/S1071581908000724", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1071581908000724", "snippet": "Similar to an <b>over</b>-<b>trusting</b> operator who does not monitor an <b>automated</b> process sufficiently, the user of an <b>automated</b> aid trusts the <b>automation</b> to such an extent that he/she directly follows the automatically generated advice without cross-checking its validity against other available and accessible information. Thus, complacency seems to signify a general issue of human\u2013<b>automation</b> interaction that might emerge independent of the kind of <b>automation</b> considered.", "dateLastCrawled": "2022-01-08T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How can we build trust in intelligent <b>automation</b>? - Emergn", "url": "https://www.emergn.com/insights/how-can-we-build-trust-in-intelligent-automation/", "isFamilyFriendly": true, "displayUrl": "https://www.emergn.com/insights/how-can-we-build-trust-in-intelligent-<b>automation</b>", "snippet": "Trust is a relatively new design component in interactive intelligent <b>systems</b> and is especially important in building Artificial Intelligence (AI) and Machine Learning (ML) technologies. When it comes to the adoption and reliance on these technologies, trust is essential to support the relationship between the user and the system \u2013 even one breach of trust can highly influence user perception of that technology. With AI, we can train computers to perform specific tasks, augmenting <b>humans</b> ...", "dateLastCrawled": "2021-12-18T08:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) TRUST, <b>AUTOMATION</b> <b>BIAS</b> AND AVERSION: ALGORITHMIC DECISION-MAKING ...", "url": "https://www.academia.edu/67685259/TRUST_AUTOMATION_BIAS_AND_AVERSION_ALGORITHMIC_DECISION_MAKING_IN_THE_CONTEXT_OF_CREDIT_SCORING", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/67685259/TRUST_<b>AUTOMATION</b>_<b>BIAS</b>_AND_AVERSION_ALGORITHMIC...", "snippet": "Reducing cognitive load, <b>trusting</b> algorithmic <b>systems</b> more than <b>humans</b>, and handing <b>over</b> responsibility increase the occurrence <b>automation</b> <b>bias</b>. Moreover, the degree to which operators perceive themselves socially accountable \u2013 for instance, when in direct interaction with a customer to whom they must justify a decision \u2013 plays a role regarding the frequency of omission and commission errors. People who feel accountable were more thoroughly examining the decisions taken by an algorithmic ...", "dateLastCrawled": "2022-01-16T01:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>50 Cognitive Biases to be Aware</b> of so You Can be the Very ... - TitleMax", "url": "https://www.titlemax.com/discovery-center/lifestyle/50-cognitive-biases-to-be-aware-of-so-you-can-be-the-very-best-version-of-you/", "isFamilyFriendly": true, "displayUrl": "https://www.titlemax.com/disc<b>over</b>y-center/lifestyle/<b>50-cognitive-biases-to-be-aware</b>-of...", "snippet": "<b>Automation</b> <b>Bias</b>: We rely on <b>automated</b> <b>systems</b>, sometimes <b>trusting</b> too much in the <b>automated</b> correction of actually correct decisions. Google Effect (aka Digital Amnesia): We tend to forget information that\u2019s easily looked up in search engines. Reactance: We do the opposite of what we\u2019re told, especially when we perceive threats to personal freedoms. Confirmation <b>Bias</b>: We tend to find and remember information that confirms our perceptions. Backfire Effect: Disproving evidence sometimes ...", "dateLastCrawled": "2022-02-02T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Misuse of <b>automated</b> decision aids: Complacency, <b>automation</b> <b>bias</b> and the ...", "url": "https://www.sciencedirect.com/science/article/pii/S1071581908000724", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1071581908000724", "snippet": "<b>Similar</b> to an <b>over</b>-<b>trusting</b> operator who does not monitor an <b>automated</b> process sufficiently, the user of an <b>automated</b> aid trusts the <b>automation</b> to such an extent that he/she directly follows the automatically generated advice without cross-checking its validity against other available and accessible information. Thus, complacency seems to signify a general issue of human\u2013<b>automation</b> interaction that might emerge independent of the kind of <b>automation</b> considered.", "dateLastCrawled": "2022-01-08T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The dangers of AI in <b>health care: risk homeostasis and automation bias</b> ...", "url": "https://towardsdatascience.com/the-dangers-of-ai-in-health-care-risk-homeostasis-and-automation-bias-148477a9080f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-dangers-of-ai-in-<b>health-care-risk-homeostasis-and</b>...", "snippet": "When in 1967 Sweden switched <b>over</b> to driving on the right, ... Human-machine interaction: <b>automation</b> <b>bias</b>. <b>Humans</b> show <b>similar</b> behaviors when interacting with machines performing <b>automated</b> tasks, known as <b>automation</b> <b>bias</b>: <b>Automation</b> <b>bias</b>: \u201cThe tendency to disregard or not search for contradictory information in light of a computer-generated solution that is accepted as correct\u201d (Parasuraman &amp; Riley, 1997) The study of <b>automation</b> <b>bias</b> in medicine has a rich history, but has become ...", "dateLastCrawled": "2022-01-10T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Why we place too much trust in machines - BBC Future", "url": "https://www.bbc.com/future/article/20211019-why-we-place-too-much-trust-in-machines", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bbc.com</b>/future/article/20211019-why-we-place-too-much-trust-in-machines", "snippet": "It is a well-studied phenomenon known as <b>automation</b> <b>bias</b>, which sometimes also leads to <b>automation</b> complacency, where people are less able to spot malfunctions when a computer is running the show ...", "dateLastCrawled": "2022-01-31T04:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Measurement of Trust in <b>Automation</b>: A Narrative Review and Reference Guide", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8562383/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8562383", "snippet": "With the rise of <b>automated</b> and autonomous agents, research examining Trust in <b>Automation</b> (TiA) has attracted considerable attention <b>over</b> the last few decades. Trust is a rich and complex construct which has sparked a multitude of measures and approaches to study and understand it. This comprehensive narrative review addresses known methods that have been used to capture TiA. We examined measurements deployed in existing empirical works, categorized those measures into self-report, behavioral ...", "dateLastCrawled": "2022-01-15T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Effects of <b>Automation</b> for Emergency Operating Procedures on Human ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8300853/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8300853", "snippet": "If <b>automation</b> <b>bias</b> is viewed as a special case of decision <b>bias</b>, our studies suggest that it depends on attentional processes that are the same as those involved in <b>automation</b>-related complacency. Complacency and <b>automation</b> <b>bias</b> show distinct manifestations of overlapping <b>automation</b>-induced phenomena, with attention working as an essential component. A model of complacency and <b>automation</b> <b>bias</b> demonstrates that they result from the dynamic interaction of personal, situational, and <b>automation</b> ...", "dateLastCrawled": "2022-02-03T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Trust ratings (checklist of trust between people and <b>automation</b>; Jian ...", "url": "https://researchgate.net/figure/Trust-ratings-checklist-of-trust-between-people-and-automation-Jian-Bisantz-and-Drury_fig3_282037777", "isFamilyFriendly": true, "displayUrl": "https://researchgate.net/figure/Trust-ratings-checklist-of-trust-between-people-and...", "snippet": "<b>Automation</b> <b>bias</b> is often times referred to as <b>over</b>-reliance on <b>automated</b> outputs [8], <b>over</b>-<b>trusting</b> output from <b>automated</b> <b>systems</b> even when it is wrong [47,84]. ...", "dateLastCrawled": "2021-06-18T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The role of trust in <b>automation</b> reliance - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1071581903000387", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1071581903000387", "snippet": "<b>Trusting</b> an <b>automated</b> aid that is less reliable than manual operation may lead to misuse. According to Mosier and Skitka&#39;s (1996) authority hypothesis, people rely on the <b>automated</b> <b>system&#39;s</b> decision because they believe it to be more reliable, and thus place greater trust in it. Misuse is defined as \u201coverreliance on <b>automation</b>\u201d (Parasuraman and Riley, 1997, p. 233). Parasuraman et al. (1993) and Singh et al. (1997) found misuse among operators performing monitoring functions. They ...", "dateLastCrawled": "2022-01-29T11:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How can we build trust in intelligent <b>automation</b>? - Emergn", "url": "https://www.emergn.com/insights/how-can-we-build-trust-in-intelligent-automation/", "isFamilyFriendly": true, "displayUrl": "https://www.emergn.com/insights/how-can-we-build-trust-in-intelligent-<b>automation</b>", "snippet": "By learning <b>humans</b>\u2019 capabilities, AI has emphasized the possibility of creating intelligent <b>systems</b> that can reason and behave <b>similar</b> to human brains and substitute human reasoning in performing certain tasks. Autonomous intelligent agents (an agent that is designed to function in the absence of human intervention) can perform speech recognition, decision-making, visual perception, and translation between languages.", "dateLastCrawled": "2021-12-18T08:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) TRUST, <b>AUTOMATION</b> <b>BIAS</b> AND AVERSION: ALGORITHMIC DECISION-MAKING ...", "url": "https://www.academia.edu/67685259/TRUST_AUTOMATION_BIAS_AND_AVERSION_ALGORITHMIC_DECISION_MAKING_IN_THE_CONTEXT_OF_CREDIT_SCORING", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/67685259/TRUST_<b>AUTOMATION</b>_<b>BIAS</b>_AND_AVERSION_ALGORITHMIC...", "snippet": "Reducing cognitive load, <b>trusting</b> algorithmic <b>systems</b> more than <b>humans</b>, and handing <b>over</b> responsibility increase the occurrence <b>automation</b> <b>bias</b>. Moreover, the degree to which operators perceive themselves socially accountable \u2013 for instance, when in direct interaction with a customer to whom they must justify a decision \u2013 plays a role regarding the frequency of omission and commission errors. People who feel accountable were more thoroughly examining the decisions taken by an algorithmic ...", "dateLastCrawled": "2022-01-16T01:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding Human <b>Over</b>-Reliance On Technology", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6534180/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6534180", "snippet": "<b>Automation</b>-<b>bias</b> errors of commission occur when users make choices based on incorrect suggestions or information provided by technology. 3 In the Dilantin incident, <b>automation</b> <b>bias</b> resulted in two errors: the first was the pharmacy staff member accepting dilTIAZem as the correct drug in the order-entry system. The second was the nurse identifying the discrepancy between the information displayed on the ADC and the information in the MAR, but <b>trusting</b> the ADC display <b>over</b> the handwritten ...", "dateLastCrawled": "2022-02-02T15:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Why we place too much trust in machines - BBC Future", "url": "https://www.bbc.com/future/article/20211019-why-we-place-too-much-trust-in-machines", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bbc.com</b>/future/article/20211019-why-we-place-too-much-trust-in-machines", "snippet": "It is a well-studied phenomenon known as <b>automation</b> <b>bias</b>, which sometimes also leads to <b>automation</b> complacency, where people are less able to spot malfunctions when a computer is running the show ...", "dateLastCrawled": "2022-01-31T04:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is <b>automation bias in cognitive psychology</b>? - Quora", "url": "https://www.quora.com/What-is-automation-bias-in-cognitive-psychology", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>automation-bias-in-cognitive-psychology</b>", "snippet": "Answer (1 of 5): From Wikipedia: \u201c<b>Automation</b> <b>bias</b> is the propensity for <b>humans</b> to favor suggestions from <b>automated</b> decision-making <b>systems</b> and to ignore contradictory information made without <b>automation</b>, even if it is correct.\u201dCummings, Mary (2004). &quot;<b>Automation</b> <b>Bias</b> in Intelligent Time Critical D...", "dateLastCrawled": "2022-01-16T04:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The role of trust in <b>automation</b> reliance - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1071581903000387", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1071581903000387", "snippet": "<b>Trusting</b> an <b>automated</b> aid that is less reliable than manual operation may lead to misuse. According to Mosier and Skitka&#39;s (1996) authority hypothesis, people rely on the <b>automated</b> <b>system&#39;s</b> decision because they believe it to be more reliable, and thus place greater trust in it. Misuse is defined as \u201coverreliance on <b>automation</b>\u201d (Parasuraman and Riley, 1997, p. 233). Parasuraman et al. (1993) and Singh et al. (1997) found misuse among operators performing monitoring functions. They ...", "dateLastCrawled": "2022-01-29T11:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Understanding human management of <b>automation</b> errors", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4221095/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4221095", "snippet": "Modern <b>automated</b> <b>systems</b> are present in a multitude of environments, including aviation, process control, transportation, and healthcare. These technologies are designed to support overall system performance, assisting human operators with tasks such as information acquisition and processing, decision making, and action execution Parasuraman et al. 2000). Many <b>automated</b> <b>systems</b> are not perfectly reliable, often due to technological limitations. For example, <b>automation</b> that involves sensing ...", "dateLastCrawled": "2021-11-15T13:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Trust between <b>Humans</b> and AI: A Short Review", "url": "https://aakritikumar.com/trust_review.pdf", "isFamilyFriendly": true, "displayUrl": "https://aakritikumar.com/trust_review.pdf", "snippet": "<b>Automation</b> abuse <b>can</b> also increase misuse and disuse of <b>automation</b> by <b>humans</b>. Researchers have identi ed competing cognitive biases that <b>humans</b> are likely to display when working with machines: algorithm aversion, algorithm appreciation, and <b>automation</b> <b>bias</b>. Dietvorst, Simmons, and Massey [9] de ne algorithm aversion as the tendency of a human to disregard the recommendations of a machine after observing that it made a mistake. In contrast, <b>automation</b> <b>bias</b> is the tendency to <b>over</b>-rely on ...", "dateLastCrawled": "2021-10-30T09:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Human Trust in <b>Other Humans, Automation, Robots, and Cognitive Agents</b>", "url": "https://www.researchgate.net/publication/271728463_Human_Trust_in_Other_Humans_Automation_Robots_and_Cognitive_Agents", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/271728463_Human_Trust_in_Other_<b>Humans</b>...", "snippet": "Human Trust in <b>Other Humans, Automation, Robots, and Cognitive Agents</b>. October 2014. Proceedings of the Human Factors and Ergonomics Society Annual Meeting 58 (1):340-344. DOI: 10.1177 ...", "dateLastCrawled": "2021-09-08T13:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "I Trust It, but I Don&#39;t Know Why: Effects of Implicit Attitudes Toward ...", "url": "https://www.researchgate.net/publication/247154061_I_Trust_It_but_I_Don't_Know_Why_Effects_of_Implicit_Attitudes_Toward_Automation_on_Trust_in_an_Automated_System", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/247154061_I_Trust_It_but_I_Don", "snippet": "The human-<b>automated</b> system literature to date has discovered that individual differences in <b>humans</b>, such as self-confidence, mood, and personality types, <b>can</b> influence the human-<b>automated</b> system ...", "dateLastCrawled": "2022-01-29T12:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>automation</b> | WE ARE <b>AUTOMATED</b>", "url": "https://weareautomated.com/tag/automation/", "isFamilyFriendly": true, "displayUrl": "https://weare<b>automated</b>.com/tag/<b>automation</b>", "snippet": "If you\u2019re a <b>trusting</b> person who wants to cut out the delay of screening new guests, just set up your Air bnb account for Instant book. 6) Include a video package. Including Netflix or Amazon Prime Video is a cheap way of giving your place the edge <b>over</b> your competition. Just make sure you have unlimited wi-fi, and that it\u2019s fast enough for good streaming. 7) Home <b>automation</b>. Installing a smart thermostat could save you a lot money on energy bills if you not around to monitor the heating ...", "dateLastCrawled": "2022-01-11T12:24:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) TRUST, <b>AUTOMATION</b> <b>BIAS</b> AND AVERSION: ALGORITHMIC DECISION-MAKING ...", "url": "https://www.academia.edu/67685259/TRUST_AUTOMATION_BIAS_AND_AVERSION_ALGORITHMIC_DECISION_MAKING_IN_THE_CONTEXT_OF_CREDIT_SCORING", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/67685259/TRUST_<b>AUTOMATION</b>_<b>BIAS</b>_AND_AVERSION_ALGORITHMIC...", "snippet": "Reducing cognitive load, <b>trusting</b> algorithmic <b>systems</b> more than <b>humans</b>, and handing <b>over</b> responsibility increase the occurrence <b>automation</b> <b>bias</b>. Moreover, the degree to which operators perceive themselves socially accountable \u2013 for instance, when in direct interaction with a customer to whom they must justify a decision \u2013 plays a role regarding the frequency of omission and commission errors. People who feel accountable were more thoroughly examining the decisions taken by an algorithmic ...", "dateLastCrawled": "2022-01-16T01:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Elon Musk Says to Be Aware of These 50 Cognitive Biases | by Yujian ...", "url": "https://medium.com/the-hive-mind/elon-musk-says-to-be-aware-of-these-50-cognitive-biases-bec1cc9c5471", "isFamilyFriendly": true, "displayUrl": "https://medium.com/the-hive-mind/elon-musk-says-to-be-aware-of-these-50-cognitive...", "snippet": "<b>Automation</b> <b>bias</b> is a relatively new cognitive <b>bias</b>. It refers to our tendency to rely on <b>automated</b> <b>systems</b> too much, sometimes <b>trusting</b> <b>automated</b> correction of already correct decisions. This is a ...", "dateLastCrawled": "2022-01-30T10:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Measurement of Trust in <b>Automation</b>: A Narrative Review and Reference Guide", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8562383/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8562383", "snippet": "With the rise of <b>automated</b> and autonomous agents, research examining Trust in <b>Automation</b> (TiA) has attracted considerable attention <b>over</b> the last few decades. Trust is a rich and complex construct which has sparked a multitude of measures and approaches to study and understand it. This comprehensive narrative review addresses known methods that have been used to capture TiA. We examined measurements deployed in existing empirical works, categorized those measures into self-report, behavioral ...", "dateLastCrawled": "2022-01-15T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Misuse of <b>automated</b> decision aids: Complacency, <b>automation</b> <b>bias</b> and the ...", "url": "https://www.sciencedirect.com/science/article/pii/S1071581908000724", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1071581908000724", "snippet": "Similar to an <b>over</b>-<b>trusting</b> operator who does not monitor an <b>automated</b> process sufficiently, the user of an <b>automated</b> aid trusts the <b>automation</b> to such an extent that he/she directly follows the automatically generated advice without cross-checking its validity against other available and accessible information. Thus, complacency seems to signify a general issue of human\u2013<b>automation</b> interaction that might emerge independent of the kind of <b>automation</b> considered.", "dateLastCrawled": "2022-01-08T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding human management of <b>automation</b> errors", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4221095/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4221095", "snippet": "Overall, our analysis revealed that an <b>automated</b> system\u2019s reliability influences a human\u2019s ability to manage <b>automation</b> errors. 100% reliable <b>systems</b> certainly support overall task performance <b>compared</b> to manual task performance. However, the benefit of imperfect <b>automation</b> is not quite as clear. Overall performance <b>can</b> be divided into two categories: (a) performance when the <b>automation</b> is working (routine performance), and (b) performance when the <b>automation</b> is erring or has failed ...", "dateLastCrawled": "2021-11-15T13:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The dangers of AI in <b>health care: risk homeostasis and automation bias</b> ...", "url": "https://towardsdatascience.com/the-dangers-of-ai-in-health-care-risk-homeostasis-and-automation-bias-148477a9080f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-dangers-of-ai-in-<b>health-care-risk-homeostasis-and</b>...", "snippet": "The lack of transparency in how these models arrive at a decision will present a challenge for eliciting trust in clinicians and avoiding <b>automation</b> <b>bias</b>. <b>Automated</b> <b>systems</b> exist on a spectrum from those that need human involvement, to full <b>automation</b> where <b>humans</b> are left out of any decision-making.", "dateLastCrawled": "2022-01-10T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Trust between <b>Humans</b> and AI: A Short Review", "url": "https://aakritikumar.com/trust_review.pdf", "isFamilyFriendly": true, "displayUrl": "https://aakritikumar.com/trust_review.pdf", "snippet": "<b>Automation</b> abuse <b>can</b> also increase misuse and disuse of <b>automation</b> by <b>humans</b>. Researchers have identi ed competing cognitive biases that <b>humans</b> are likely to display when working with machines: algorithm aversion, algorithm appreciation, and <b>automation</b> <b>bias</b>. Dietvorst, Simmons, and Massey [9] de ne algorithm aversion as the tendency of a human to disregard the recommendations of a machine after observing that it made a mistake. In contrast, <b>automation</b> <b>bias</b> is the tendency to <b>over</b>-rely on ...", "dateLastCrawled": "2021-10-30T09:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The role of trust in <b>automation</b> reliance - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1071581903000387", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1071581903000387", "snippet": "<b>Trusting</b> an <b>automated</b> aid that is less reliable than manual operation may lead to misuse. According to Mosier and Skitka&#39;s (1996) authority hypothesis, people rely on the <b>automated</b> <b>system&#39;s</b> decision because they believe it to be more reliable, and thus place greater trust in it. Misuse is defined as \u201coverreliance on <b>automation</b>\u201d (Parasuraman and Riley, 1997, p. 233). Parasuraman et al. (1993) and Singh et al. (1997) found misuse among operators performing monitoring functions. They ...", "dateLastCrawled": "2022-01-29T11:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Vis Ex Machina: An Analysis of Trust in Human versus Algorithmically ...", "url": "https://research.tableau.com/sites/default/files/vis-bias.pdf", "isFamilyFriendly": true, "displayUrl": "https://research.tableau.com/sites/default/files/vis-<b>bias</b>.pdf", "snippet": "tions <b>over</b> another, participants fell into two categories of behavior: all-rounders tended to focus on the quality of recommendations as a whole, while seekers honed in on the presence of particular visualizations or attributes. Our findings partially support existing assumptions in the com-munity that users trust <b>automated</b> visualization recommendation <b>systems</b>. Though some participants held onto folk theories about the capabilities of a given recommendation source, users on the whole ...", "dateLastCrawled": "2021-09-25T19:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Humans: Still Vital After All These Years of Automation</b>", "url": "https://www.researchgate.net/publication/23157821_Humans_Still_Vital_After_All_These_Years_of_Automation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/23157821_<b>Humans_Still_Vital_After_All_These</b>...", "snippet": "<b>Automation</b> is prevalent in safety-critical <b>systems</b> and increasingly in everyday life. Many studies of human performance in <b>automated</b> <b>systems</b> have been conducted <b>over</b> the past 30 years ...", "dateLastCrawled": "2022-01-24T23:33:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools from many of the leaders in <b>machine learning</b> development. Detecting <b>bias</b> starts with the data set. A data set might not represent the problem space (such as training an autonomous vehicle with only daytime data). A data set can also incorporate data that ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> Tutorial for Beginners: What is, Basics of ML", "url": "https://www.guru99.com/machine-learning-tutorial.html", "isFamilyFriendly": true, "displayUrl": "https://www.guru99.com/<b>machine-learning</b>-tutorial.html", "snippet": "<b>Machine Learning</b> is a system of computer algorithms that can learn from example through self-improvement without being explicitly coded by a programmer. <b>Machine learning</b> is a part of artificial Intelligence which combines data with statistical tools to predict an output which can be used to make actionable insights. The breakthrough comes with the idea that a <b>machine</b> can singularly learn from the data (i.e., example) to produce accurate results. <b>Machine learning</b> is closely related to data ...", "dateLastCrawled": "2022-02-02T13:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "If programming is <b>automation</b>, then <b>machine learning</b> is automating the process of <b>automation</b>. Writing software is the bottleneck, we don\u2019t have enough good developers. Let the data do the work instead of people. <b>Machine learning</b> is the way to make programming scalable. Traditional Programming: Data and program is run on the computer to produce the output. <b>Machine Learning</b>: Data and output is run on the computer to create a program. This program can be used in traditional programming ...", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Algorithmic Bias and Dangers of Machine Learning Systems</b> \u2013 Zilbest", "url": "https://zilbest.com/technology/algorithmic-bias-and-dangers-of-machine-learning-systems/", "isFamilyFriendly": true, "displayUrl": "https://zilbest.com/technology/<b>algorithmic-bias-and-dangers-of-machine-learning-systems</b>", "snippet": "<b>Algorithmic Bias and Dangers of Machine Learning Systems</b> Like it or not, a lot of social media platforms we often browse about use <b>machine</b> <b>learning</b> in their recommendation systems. Things like your next recommended YouTube video, Twitter topics that you might be interested in, your next hotel booking, all rely on this black box of <b>machine</b> <b>learning</b> algorithms.", "dateLastCrawled": "2021-11-29T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>learning</b> in engineering <b>automation</b> \u2014The present and the future ...", "url": "https://www.sciencedirect.com/science/article/pii/0166361591900233", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/0166361591900233", "snippet": "Keywords: <b>Machine</b> <b>learning</b>, <b>Machine</b> <b>learning</b> requirements, Engineering <b>automation</b>, Intelligent engineering. 1. Introduction In the past decade the computer has become an indispensable tool to the engineer. This trend will continue with more innovative software applica- tions being developed to use the ever increasing power of new processors. To continue the large gains in engineering productivity (even with in- creased computational speed) software programs will need to be more intelligent ...", "dateLastCrawled": "2021-12-03T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Artificial Intelligence, <b>Machine</b> <b>Learning</b>, and <b>Bias</b> In Finance ...", "url": "https://www.academia.edu/69033409/Artificial_Intelligence_Machine_Learning_and_Bias_In_Finance_Toward_Responsible_Innovation", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69033409/Artificial_Intelligence_<b>Machine</b>_<b>Learning</b>_and_<b>Bias</b>_In...", "snippet": "ARTIFICIAL INTELLIGENCE, <b>MACHINE</b> <b>LEARNING</b>, AND <b>BIAS</b> IN FINANCE: TOWARD RESPONSIBLE INNOVATION Kristin Johnson,* Frank Pasquale** &amp; Jennifer Chapman*** INTRODUCTION Over the last decade, a growing number of digital startups launched bids to lure business from the financial services industry.1 Armed with what they claim are vast quantities of data and sophisticated algorithmic platforms capable of interpreting the data,2 these financial technology (\u201cfintech\u201d)3 * McGlinchey Stafford ...", "dateLastCrawled": "2022-01-27T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Preliminary performance study of a brief review on <b>machine</b> <b>learning</b> ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "snippet": "<b>Analogy</b>-based effort estimation is the major task of software engineering which estimates the effort required for new software projects using existing histories for corresponding development and management. In general, the high accuracy of software effort estimation techniques can be a non-solvable problem we named as multi-objective problem. Recently, most of the authors have been used <b>machine</b> <b>learning</b> techniques for the same process however not possible to meet the higher performance ...", "dateLastCrawled": "2022-01-02T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Latent <b>bias</b> and the implementation of <b>artificial intelligence</b> in ...", "url": "https://academic.oup.com/jamia/article/27/12/2020/5859726", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/jamia/article/27/12/2020/5859726", "snippet": "<b>artificial intelligence</b>, <b>machine</b> <b>learning</b>, <b>bias</b>, clinical decision support, health informatics. INTRODUCTION. <b>Artificial intelligence</b> (AI) in general, and <b>machine</b> <b>learning</b> in particular, by all accounts, appear poised to revolutionize medicine. 1\u20133 With a wide spectrum of potential uses across translational research (from bench to bedside to health policy), clinical medicine (including diagnosis, treatment, prediction, and healthcare resource allocation), and public health, every area of ...", "dateLastCrawled": "2022-01-28T13:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Six useful metaphors for thinking about artificial intelligence ...", "url": "https://hackernoon.com/six-useful-metaphors-for-thinking-about-artificial-intelligence-c7468b1551fa", "isFamilyFriendly": true, "displayUrl": "https://hackernoon.com/six-useful-<b>metaphor</b>s-for-thinking-about-artificial-intelligence...", "snippet": "<b>Machine</b> <b>learning</b> will replace all labeling work inte the same way. No more need to manually and repeatedly identifying, categorizing and sorting things. We can expect to uptake of this technology happen rapidly because most human don\u2019t prefer to do repetitive work. A Japanese farmer took 7000 pictures of cucumbers that his mother had manually sorted and built and trained a <b>machine</b> to sort them automatically based on this technology. And Island of drunk people. Because we rarely understand ...", "dateLastCrawled": "2022-01-30T10:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning Methods for Planning</b> | ScienceDirect", "url": "https://www.sciencedirect.com/book/9781483207742/machine-learning-methods-for-planning", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/book/9781483207742", "snippet": "<b>Machine Learning Methods for Planning</b> provides information pertinent to <b>learning</b> methods for planning and scheduling. This book covers a wide variety of <b>learning</b> methods and <b>learning</b> architectures, including analogical, case-based, decision-tree, explanation-based, and reinforcement <b>learning</b>. Organized into 15 chapters, this book begins with an overview of planning and scheduling and describes some representative <b>learning</b> systems that have been developed for these tasks. This text then ...", "dateLastCrawled": "2022-01-10T04:15:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Lecture 6 notes - College-aantekeningen 6 - Man-<b>Machine</b>-Systems ...", "url": "https://www.studeersnel.nl/nl/document/technische-universiteit-delft/man-machine-systems/lecture-6-notes-college-aantekeningen-6/1302796", "isFamilyFriendly": true, "displayUrl": "https://www.studeersnel.nl/nl/document/technische-universiteit-delft/man-<b>machine</b>...", "snippet": "Man-<b>Machine</b>-Systems (ME41080) Lecture notes ME41080: Lecture 6. Human-computer interaction / automation (cont.) Joost de Winter. Slide Notes . 4\u201310 Automation pitfall 3: Low/hi gh mental wo rkload . Long periods of low workl oad with bursts of high w orkload (99% boredom, 1% terror) When the hum an superviso r is \u2018out of th e loop\u2019, he or she m ay have nothi ng meaningf ul to do for. prolonged per iods of tim e and therefo re may becom e bored, un der-arouse d, etc. In princi ple ...", "dateLastCrawled": "2022-01-14T18:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Summary Lecture 1-9 - Lecture 1 The Old Stone Age (also called Lower ...", "url": "https://www.studeersnel.nl/nl/document/technische-universiteit-delft/man-machine-systems/summary-lecture-1-9/3692239", "isFamilyFriendly": true, "displayUrl": "https://www.studeersnel.nl/nl/document/technische-universiteit-delft/man-<b>machine</b>...", "snippet": "Human <b>machine</b> systems lecture notes; Gerelateerde Studylists Q2. Voorbeeld tekst Download Opslaan. Summary Lecture 1-9. Vak:Man-<b>Machine</b>-Systems (ME41080) Lecture 1 . The Old Stone Age (also called Lower Palaeolithic) is the period from 2.6 (mega-annum = 10^6 years) to 0.3 Ma and consists of the Oldowan and ...", "dateLastCrawled": "2022-01-15T06:21:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(automation bias)  is like +(trusting automated systems over humans)", "+(automation bias) is similar to +(trusting automated systems over humans)", "+(automation bias) can be thought of as +(trusting automated systems over humans)", "+(automation bias) can be compared to +(trusting automated systems over humans)", "machine learning +(automation bias AND analogy)", "machine learning +(\"automation bias is like\")", "machine learning +(\"automation bias is similar\")", "machine learning +(\"just as automation bias\")", "machine learning +(\"automation bias can be thought of as\")", "machine learning +(\"automation bias can be compared to\")"]}