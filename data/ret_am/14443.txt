{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>What Is ROC Curve</b>?. In machine learning, <b>ROC curve</b> is an\u2026 | by Saurav ...", "url": "https://medium.com/analytics-vidhya/what-is-roc-curve-1f776103c998", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>what-is-roc-curve</b>-1f776103c998", "snippet": "<b>True</b> <b>negative</b> (<b>TN</b>): Given a <b>patient</b>\u2019s information, if your model predicts no heart <b>disease</b>, and the <b>patient</b> actually has no heart <b>disease</b> then, it is considered a <b>true</b> <b>negative</b>.", "dateLastCrawled": "2022-01-29T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Breast Cancer</b> Detection Using Machine Learning | by randerson112358 ...", "url": "https://randerson112358.medium.com/breast-cancer-detection-using-machine-learning-38820fe98982", "isFamilyFriendly": true, "displayUrl": "https://randerson112358.medium.com/<b>breast-cancer</b>-detection-using-machine-learning...", "snippet": "<b>True</b> <b>Negative</b> (<b>TN</b>) = Specificity (also called the <b>true</b> <b>negative</b> rate) measures the proportion of actual negatives that are <b>correctly</b> identified as such. False <b>Negative</b> (FN) = A test result that indicates that a condition <b>does</b> <b>not</b> hold, while in fact it <b>does</b>. For example a test result that indicates a person <b>does</b> <b>not</b> <b>have</b> cancer when the person actually <b>does</b> <b>have</b> it. Confusion Matrix from sklearn.metrics import confusion_matrix for i in range(len(model)): cm = confusion_matrix(Y_test, model[i ...", "dateLastCrawled": "2022-01-31T17:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Early and accurate detection and diagnosis of heart <b>disease</b> using ...", "url": "https://www.nature.com/articles/s41598-020-76635-9", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-020-76635-9", "snippet": "In confusion matrix <b>True</b> <b>Negative</b> (<b>TN</b>) shows that the <b>patient</b> has <b>not</b> heart <b>disease</b> and the model also predicts the same i.e. a healthy person is <b>correctly</b> classified by the model.", "dateLastCrawled": "2022-02-03T06:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Part 1: Simple Definition and Calculation of Accuracy, Sensitivity and ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4614595/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4614595", "snippet": "This <b>does</b> <b>not</b> happen in reality as the accuracy of a test varies for different diseases and in different situations. For example, the value of D-dimer for diagnosing pulmonary embolism varies based on pre-test probability. It shows high accuracy in low risk <b>patient</b> and low accuracy in high risk ones. The characteristics of a test that reflects the aforementioned abilities are accuracy, sensitivity, specificity, positive and <b>negative</b> predictive values and positive and <b>negative</b> likelihood ratios", "dateLastCrawled": "2022-02-02T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Look at <b>Precision</b>, Recall, and F1-Score | by Teemu Kanstr\u00e9n | Towards ...", "url": "https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-look-at-<b>precision</b>-recall-and-f1-score-36b5fd0dd3ec", "snippet": "For the <b>True</b> <b>Negative</b> (<b>TN</b>) example, the cat classifier <b>correctly</b> identifies a photo as <b>not</b> having a cat in it, and the medical image as the <b>patient</b> having no cancer. So the prediction is <b>Negative</b> and correct (<b>True</b>). False <b>Negative</b> (FN) In the False <b>Negative</b> (FN) case, the classifier has predicted a <b>Negative</b> result, while the actual result was positive. <b>Like</b> no cat when there is a cat. So the prediction was <b>Negative</b> and wrong (False). Thus it is a False <b>Negative</b>. Confusion Matrix. A confusion ...", "dateLastCrawled": "2022-01-31T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Understanding and using sensitivity, specificity and predictive values", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2636062", "snippet": "It is the percentage of patients with a <b>negative</b> test who do <b>not</b> <b>have</b> the <b>disease</b>. In 2 x 2 table ... / c+d (false <b>negative</b> + <b>true</b> <b>negative</b>) = Probability (<b>patient</b> <b>not</b> having <b>disease</b> when test is <b>negative</b>) Example: We will use sensitivity and specificity provided in Table 3 to calculate <b>negative</b> predictive value. NPV = a (<b>true</b> negatives) / c+d (false <b>negative</b> + <b>true</b> <b>negative</b>) = 85 / 85 + 25 = 85 / 110 = 77.3%. Positive and <b>negative</b> predictive values are directly related to the prevalence of ...", "dateLastCrawled": "2022-01-30T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Accuracy</b> Paradox. \u201cIf you don\u2019t know anything about\u2026 | by Tejumade ...", "url": "https://towardsdatascience.com/accuracy-paradox-897a69e2dd9b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>accuracy</b>-paradox-897a69e2dd9b", "snippet": "<b>TN</b> = <b>True</b> <b>Negative</b>; Hawkins Model\u2019s Prediction Result. After training their model with 70% of the data set, Hawkins scientist tested this model with the remaining 30% data to evaluate the model for its <b>accuracy</b>. Their model got 270 prediction right out of the 300. Hawkins <b>Accuracy</b> = 270 / 300 = 0.9. This looked <b>like</b> a pretty convincing model with an <b>accuracy</b> of 90%, why then did it fail? Solving The Mystery. Bob re-evaluated their model and below is the breakdown: Number of women with ...", "dateLastCrawled": "2022-02-03T05:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Diabetes Prediction Using Machine Learning</b> :: InBlog", "url": "https://inblog.in/Diabetes-Prediction-Using-Machine-Learning-xglR6Xm2Os", "isFamilyFriendly": true, "displayUrl": "https://inblog.in/<b>Diabetes-Prediction-Using-Machine-Learning</b>-xglR6Xm2Os", "snippet": "The doctor has <b>correctly</b> predicted that the <b>patient</b> has the <b>disease</b>. Cases in which the doctor predicted NO (they do <b>not</b> <b>have</b> the <b>disease</b>), and they don\u2019t <b>have</b> the <b>disease</b> will be termed as <b>TRUE</b> NEGATIVES (<b>TN</b>). The doctor has <b>correctly</b> predicted that the <b>patient</b> <b>does</b> <b>not</b> <b>have</b> the <b>disease</b>.", "dateLastCrawled": "2022-02-02T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is a <b>Confusion Matrix in Machine Learning</b>", "url": "https://machinelearningmastery.com/confusion-matrix-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/confusion-matrix-machine-learning", "snippet": "Such as <b>a disease</b> state or event from no <b>disease</b> state or no event. ... \u201c<b>true</b> <b>negative</b>\u201d for <b>correctly</b> predicted no-event values. \u201cfalse <b>negative</b>\u201d for incorrectly predicted no-event values. We can summarize this in the confusion matrix as follows: 1. 2. 3 event no-event. event <b>true</b> positive false positive. no-event false <b>negative</b> <b>true</b> <b>negative</b>. This can help in calculating more advanced classification metrics such as precision, recall, specificity and sensitivity of our classifier ...", "dateLastCrawled": "2022-01-29T19:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Accuracy, Precision, Recall &amp; F1-Score - Python</b> Examples - <b>Data Analytics</b>", "url": "https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>accuracy-precision-recall-f1-score-python</b>-example", "snippet": "For example, machine learning models are used in medical diagnosis applications where the doctor wants machine learning models that will <b>not</b> provide a label of pneumonia if the <b>patient</b> <b>does</b> <b>not</b> <b>have</b> this <b>disease</b>. Oncologists ideally want models that can identify all cancerous lesions without any false-positive results, and hence one could use a precision score in such cases. Note that a greater number of false positives will result in a lot of stress for the patients in general although that ...", "dateLastCrawled": "2022-02-02T22:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Measures of Diagnostic Accuracy: Basic Definitions", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4975285/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4975285", "snippet": "(<b>true</b> <b>negative</b> (<b>TN</b>) \u2013subjects without the <b>disease</b> with the value of a parameter of interest below the cut-off (false <b>negative</b> (FN) \u2013subjects with the <b>disease</b> with the value of a parameter of interest below the cut-off . The first step in the calculation of sensitivity and specificity is to make a 2x2 table with groups of subjects divided according to a gold standard or (reference method) in columns, and categories according to test in rows (Table 1.). Table 1. 2x2 table. Subjects with ...", "dateLastCrawled": "2022-02-03T07:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Non-Confusing Guide to <b>Confusion Matrix</b> | by Dario Rade\u010di\u0107 | Towards ...", "url": "https://towardsdatascience.com/a-non-confusing-guide-to-confusion-matrix-7071d2c2204f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-non-confusing-guide-to-<b>confusion-matrix</b>-7071d2c2204f", "snippet": "<b>True</b> <b>Negative</b> (<b>TN</b>) Your model predicted <b>negative</b> and the actual is <b>negative</b>; The model predicted 0, and it\u2019s 0 in the binomial variable; Eg. you predicted that the <b>patient</b> doesn\u2019t <b>have</b> the <b>disease</b>, and he doesn\u2019t <b>have</b> it; You see, there isn\u2019t anything confusing about <b>confusion matrix</b>. Sure, you need to memorize those terms, and yeah, they sound <b>similar</b>, but at least they aren\u2019t as abstract as some other machine learning concepts you\u2019ve probably encountered. Getting Down with the ...", "dateLastCrawled": "2022-01-26T04:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding and using sensitivity, specificity and predictive values", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2636062", "snippet": "It is the percentage of patients with a <b>negative</b> test who do <b>not</b> <b>have</b> the <b>disease</b>. In 2 x 2 table ... / c+d (false <b>negative</b> + <b>true</b> <b>negative</b>) = Probability (<b>patient</b> <b>not</b> having <b>disease</b> when test is <b>negative</b>) Example: We will use sensitivity and specificity provided in Table 3 to calculate <b>negative</b> predictive value. NPV = a (<b>true</b> negatives) / c+d (false <b>negative</b> + <b>true</b> <b>negative</b>) = 85 / 85 + 25 = 85 / 110 = 77.3%. Positive and <b>negative</b> predictive values are directly related to the prevalence of ...", "dateLastCrawled": "2022-01-30T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Diagnostics | Free Full-Text | A Deep Neural Network for Early ...", "url": "https://www.mdpi.com/2075-4418/12/1/116/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2075-4418/12/1/116/htm", "snippet": "The notCKD samples were <b>not</b> accurately identified, as indicated by a false-positive result (FP). <b>True</b> <b>negative</b> (<b>TN</b>) samples <b>have</b> been accurately categorized as <b>not</b> CKD. 4.2.1. Accuracy . It refers to the proportion of correct guesses to total predictions. Accuracy can be described as the ability to accurately predict the outcome of a situation. Accuracy = T P + <b>T N</b> T P + <b>T N</b> + F P + F N (5) 4.2.2. Recall. The recall calculates the proportion of accurately predicted positive observations to ...", "dateLastCrawled": "2022-01-27T01:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Diabetes Prediction Using Machine Learning</b> :: InBlog", "url": "https://inblog.in/Diabetes-Prediction-Using-Machine-Learning-xglR6Xm2Os", "isFamilyFriendly": true, "displayUrl": "https://inblog.in/<b>Diabetes-Prediction-Using-Machine-Learning</b>-xglR6Xm2Os", "snippet": "The doctor has <b>correctly</b> predicted that the <b>patient</b> has the <b>disease</b>. Cases in which the doctor predicted NO (they do <b>not</b> <b>have</b> the <b>disease</b>), and they don\u2019t <b>have</b> the <b>disease</b> will be termed as <b>TRUE</b> NEGATIVES (<b>TN</b>). The doctor has <b>correctly</b> predicted that the <b>patient</b> <b>does</b> <b>not</b> <b>have</b> the <b>disease</b>.", "dateLastCrawled": "2022-02-02T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How <b>can I calculate the accuracy</b>? - ResearchGate", "url": "https://www.researchgate.net/post/How_can_I_calculate_the_accuracy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/How_<b>can_I_calculate_the_accuracy</b>", "snippet": "<b>True</b>-<b>Negative</b> Rate = <b>TN</b> / <b>TN</b> + FP . False-<b>Negative</b> Rate = FN / FN + TP. For good classifiers, TPR and TNR both should be nearer to 100%. <b>Similar</b> is the case with precision and accuracy parameters ...", "dateLastCrawled": "2022-02-03T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is a <b>Confusion Matrix in Machine Learning</b>", "url": "https://machinelearningmastery.com/confusion-matrix-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/confusion-matrix-machine-learning", "snippet": "\u201c<b>true</b> <b>negative</b>\u201d for <b>correctly</b> predicted no-event values. \u201cfalse <b>negative</b>\u201d for incorrectly predicted no-event values. We can summarize this in the confusion matrix as follows: 1. 2. 3 event no-event. event <b>true</b> positive false positive. no-event false <b>negative</b> <b>true</b> <b>negative</b>. This can help in calculating more advanced classification metrics such as precision, recall, specificity and sensitivity of our classifier. For example, classification accuracy is calculated as <b>true</b> positives ...", "dateLastCrawled": "2022-01-29T19:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Accuracy, Precision, Recall &amp; F1-Score - Python</b> Examples - <b>Data Analytics</b>", "url": "https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>accuracy-precision-recall-f1-score-python</b>-example", "snippet": "Model accuracy is a machine learning model performance metric that is defined as the ratio of <b>true</b> positives and <b>true</b> negatives to all positive and <b>negative</b> observations. In other words, accuracy tells us how often we can expect our machine learning model will <b>correctly</b> predict an outcome out of the total number of times it made predictions. For example: Let\u2019s assume that you were testing your machine learning model with a dataset of 100 records and that your machine learning model ...", "dateLastCrawled": "2022-02-02T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Using Asymmetric Classification Cost Matrices in <b>Predicting</b> Diabetes", "url": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1011&context=icdss2007", "isFamilyFriendly": true, "displayUrl": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1011&amp;context=icdss2007", "snippet": "classifier for <b>predicting</b> <b>disease</b>. This is determined by the type of <b>disease</b>, its associated classification cost matrix and/or the target population on which the classifier will be used. Diabetes has higher costs associated with false negatives than <b>true</b> positives, as the <b>disease</b> can progress very rapidly when left untreated. There are two ways to skew a classifier to work towards the given classification cost matrix: (1) by changing the classification probability value, P* based on the ...", "dateLastCrawled": "2022-01-02T19:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Evaluating a <b>Classification Model</b> | Machine Learning, Deep Learning ...", "url": "https://www.ritchieng.com/machine-learning-evaluate-classification-model/", "isFamilyFriendly": true, "displayUrl": "https://www.ritchieng.com/machine-learning-evaluate-<b>classification-model</b>", "snippet": "Null accuracy: accuracy that could be achieved by always <b>predicting</b> the most frequent class. We must always compare with this; In [8]: # examine the class distribution of the testing set (using a Pandas Series method) y_test. value_counts Out[8]: 0 130 1 62 Name: label, dtype: int64. In [9]: # calculate the percentage of ones # because y_test only contains ones and zeros, we can simply calculate the mean = percentage of ones y_test. mean Out[9]: 0.3229166666666667. 32% of the. In [10 ...", "dateLastCrawled": "2022-02-03T00:57:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Diagnostic <b>accuracy</b> \u2013 Part 1 Basic concepts: sensitivity and ...", "url": "https://acutecaretesting.org/en/articles/diagnostic-accuracy--part-1brbasic-concepts-sensitivity-and-specificity-roc-analysis-stard-statement", "isFamilyFriendly": true, "displayUrl": "https://acutecaretesting.org/en/articles/diagnostic-<b>accuracy</b>--part-1brbasic-concepts...", "snippet": "<b>True</b> <b>negative</b> (<b>TN</b>) \u2013 subjects without stroke and S-100B ; 0.5 \u00b5g/L False <b>negative</b> (FN) \u2013 subjects having stroke and S-100B 0.5 \u00b5g/L The first step in calculating sensitivity and specificity is to make a 2 \u00d7 2 table with groups of subjects divided according to a gold standard or reference method (diagnostic criteria) in columns, and categories according to test (S-100B) in rows (TABLE 1).", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Predicting</b> <b>disease</b>-causing <b>variant combinations</b> | <b>PNAS</b>", "url": "https://www.pnas.org/content/116/24/11878", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/116/24/11878", "snippet": "Such a predictor should exclude the nonrelevant <b>variant combinations</b> [<b>true</b> <b>negative</b> (<b>TN</b>)], which will be abundantly present in a <b>patient</b>\u2019s exome, and accurately identify the scarce <b>disease</b>-causing ones [<b>true</b> positive (TP)]. To meet this challenge, we developed the Variant Combination Pathogenicity Predictor (VarCoPP), a pathogenicity predictor for combinations of variants in gene pairs, which is able to accurately identify <b>disease</b>-causing <b>variant combinations</b> using variant, gene, and gene ...", "dateLastCrawled": "2021-12-31T07:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "Specificity, also known as <b>True</b> <b>Negative</b> Rate is calculated as, Specificity = <b>TN</b> / (<b>TN</b> + FP). Since the formula <b>does</b> <b>not</b> contain FN and TP, Specificity may give you a biased result, especially for imbalanced classes. In the example of Fraud detection, it gives you the percentage of <b>Correctly</b> Predicted Non-Frauds from the pool of Actual Frauds pool of Actual Non-Frauds", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Transvaginal ultrasonography in ovarian cancer screening: current ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3873201/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3873201", "snippet": "In contrast, a <b>true</b>-<b>negative</b> screen is the absence of ovarian cancer for at least 12 months after a normal test. A false-<b>negative</b> screen is the occurrence of histologically confirmed invasive ovarian cancer within 12 months after a normal scan, whereas a false-positive screen is the absence of ovarian cancer in a <b>patient</b> with a positive screen. Regular screening should lower stage at detection and increase <b>disease</b>-specific ovarian cancer survival. Finally, ovarian cancer mortality should be ...", "dateLastCrawled": "2022-02-02T09:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Accuracy</b> Paradox. \u201cIf you don\u2019t know anything about\u2026 | by Tejumade ...", "url": "https://towardsdatascience.com/accuracy-paradox-897a69e2dd9b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>accuracy</b>-paradox-897a69e2dd9b", "snippet": "<b>TN</b> = <b>True</b> <b>Negative</b>; Hawkins Model\u2019s Prediction Result. After training their model with 70% of the data set, Hawkins scientist tested this model with the remaining 30% data to evaluate the model for its <b>accuracy</b>. Their model got 270 prediction right out of the 300. Hawkins <b>Accuracy</b> = 270 / 300 = 0.9. This looked like a pretty convincing model with an <b>accuracy</b> of 90%, why then did it fail? Solving The Mystery. Bob re-evaluated their model and below is the breakdown: Number of women with ...", "dateLastCrawled": "2022-02-03T05:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Sensitivity, Specificity, and Predictive Values of Diagnostic and ...", "url": "https://www.medschool.lsuhsc.edu/medical_education/graduate/Core_Curriculum/MK%204%20-%20Interpretation%20of%20Diagnostic%20Screening%20Tests.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.medschool.lsuhsc.edu/medical_education/graduate/Core_Curriculum/MK 4...", "snippet": "When many patients with <b>disease</b> <b>have</b> a <b>negative</b> test (false negatives) the sensitivity decreases. The test\u2019s utility as a screening test is diminished because the test fails to identify asymptomatic patients. 10 . Specificity The probability that a test will be <b>negative</b> in a <b>patient</b> without <b>disease</b>. <b>True</b> <b>negative</b> rate. 11 . <b>TN</b> <b>TN</b> + FP . CA-125 Protein as a Marker for Ovarian Cancer . 12 . <b>Disease</b> . No <b>Disease</b> . Test Positive ; 101 . 310 ; Test <b>Negative</b> . 9 ; 1540 . <b>TN</b> <b>TN</b> + FP . 1540 1540 ...", "dateLastCrawled": "2022-01-30T06:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Classification Accuracy is <b>Not</b> Enough: More Performance Measures You ...", "url": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/classification-accuracy-is-<b>not</b>-enough-", "snippet": "Precision <b>can</b> <b>be thought</b> of as a measure of a classifiers exactness. A low precision <b>can</b> also indicate a large number of False Positives. The precision of the All No Recurrence model is 0/(0+0) or <b>not</b> a number, or 0. The precision of the All Recurrence model is 85/(85+201) or 0.30. The precision of the CART model is 10/(10+13) or 0.43. The precision suggests CART is a better model and that the All Recurrence is more useful than the All No Recurrence model even though it has a lower accuracy ...", "dateLastCrawled": "2022-02-03T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 7, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Receiver operating characteristic</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Receiver_operating_characteristic", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Receiver_operating_characteristic</b>", "snippet": "Conversely, a <b>true</b> <b>negative</b> (<b>TN</b>) has occurred when both the prediction outcome and the actual value are n, and false <b>negative</b> (FN) is when the prediction outcome is n while the actual value is p. To get an appropriate example in a real-world problem, consider a diagnostic test that seeks to determine whether a person has a certain <b>disease</b>. A ...", "dateLastCrawled": "2022-02-02T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Probability and loss: two sides of the risk assessment coin | The ...", "url": "https://www.cambridge.org/core/journals/the-psychiatrist/article/probability-and-loss-two-sides-of-the-risk-assessment-coin/646CB1DD7C9C9BF2851CCF23DE974483", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/the-psychiatrist/article/probability-and-loss...", "snippet": "2 false positive (FP), were a person categorised as being at high probability of harm would <b>not</b> commit the harm; 3 <b>true</b> <b>negative</b> (<b>TN</b>), where a person categorised as being at low probability of harm would <b>not</b> commit the harm; and. 4 false <b>negative</b> (FN), where a person categorised as being at low probability of harm will commit that harm. These four outcomes <b>can</b> generate the well-known statistics associated with risk assessment. Sensitivity (TP/(TP + FN)) is the proportion of <b>correctly</b> ...", "dateLastCrawled": "2022-02-03T06:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The psychological drivers of misinformation belief and its resistance ...", "url": "https://www.nature.com/articles/s44159-021-00006-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s44159-021-00006-y", "snippet": "Misinformation is influential despite unprecedented access to high-quality, factual information. In this Review, Ecker et al. describe the cognitive, social and affective factors that drive ...", "dateLastCrawled": "2022-02-02T17:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>What Is ROC Curve</b>?. In machine learning, <b>ROC curve</b> is an\u2026 | by Saurav ...", "url": "https://medium.com/analytics-vidhya/what-is-roc-curve-1f776103c998", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>what-is-roc-curve</b>-1f776103c998", "snippet": "<b>True</b> <b>negative</b> (<b>TN</b>): Given a <b>patient</b>\u2019s information, if your model predicts no heart <b>disease</b>, and the <b>patient</b> actually has no heart <b>disease</b> then, it is considered a <b>true</b> <b>negative</b>.", "dateLastCrawled": "2022-01-29T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Diagnostic <b>accuracy</b> \u2013 Part 1 Basic concepts: sensitivity and ...", "url": "https://acutecaretesting.org/en/articles/diagnostic-accuracy--part-1brbasic-concepts-sensitivity-and-specificity-roc-analysis-stard-statement", "isFamilyFriendly": true, "displayUrl": "https://acutecaretesting.org/en/articles/diagnostic-<b>accuracy</b>--part-1brbasic-concepts...", "snippet": "<b>True</b> <b>negative</b> (<b>TN</b>) \u2013 subjects without stroke and S-100B ; 0.5 \u00b5g/L False <b>negative</b> (FN) \u2013 subjects having stroke and S-100B 0.5 \u00b5g/L The first step in calculating sensitivity and specificity is to make a 2 \u00d7 2 table with groups of subjects divided according to a gold standard or reference method (diagnostic criteria) in columns, and categories according to test (S-100B) in rows (TABLE 1).", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding and using sensitivity, specificity and predictive values", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2636062", "snippet": "It is the percentage of patients with a <b>negative</b> test who do <b>not</b> <b>have</b> the <b>disease</b>. In 2 x 2 table ... / c+d (false <b>negative</b> + <b>true</b> <b>negative</b>) = Probability (<b>patient</b> <b>not</b> having <b>disease</b> when test is <b>negative</b>) Example: We will use sensitivity and specificity provided in Table 3 to calculate <b>negative</b> predictive value. NPV = a (<b>true</b> negatives) / c+d (false <b>negative</b> + <b>true</b> <b>negative</b>) = 85 / 85 + 25 = 85 / 110 = 77.3%. Positive and <b>negative</b> predictive values are directly related to the prevalence of ...", "dateLastCrawled": "2022-01-30T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "UNAS-Net: A deep convolutional neural network for <b>predicting</b> Covid-19 ...", "url": "https://www.sciencedirect.com/science/article/pii/S2352914821003038", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2352914821003038", "snippet": "In addition, the proposed model has a <b>true</b> <b>negative</b> (<b>TN</b>) of 33, implying that 33 <b>negative</b> Covid-19 images were accurately classified. Moreover, as per ResNet50, 14 positive Covid-19 images are accurate, and 7 images are falsely classified. However, ResNet50 <b>have</b> <b>correctly</b> detected 33 of 34 <b>negative</b> Covid-19 images.", "dateLastCrawled": "2022-02-03T16:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is a <b>Confusion Matrix in Machine Learning</b>", "url": "https://machinelearningmastery.com/confusion-matrix-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/confusion-matrix-machine-learning", "snippet": "Such as <b>a disease</b> state or event from no <b>disease</b> state or no event. ... \u201c<b>true</b> <b>negative</b>\u201d for <b>correctly</b> predicted no-event values. \u201cfalse <b>negative</b>\u201d for incorrectly predicted no-event values. We <b>can</b> summarize this in the confusion matrix as follows: 1. 2. 3 event no-event. event <b>true</b> positive false positive. no-event false <b>negative</b> <b>true</b> <b>negative</b>. This <b>can</b> help in calculating more advanced classification metrics such as precision, recall, specificity and sensitivity of our classifier ...", "dateLastCrawled": "2022-01-29T19:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How <b>can I calculate the accuracy</b>? - ResearchGate", "url": "https://www.researchgate.net/post/How_can_I_calculate_the_accuracy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/How_<b>can_I_calculate_the_accuracy</b>", "snippet": "The accuracy <b>can</b> be defined as the percentage of <b>correctly</b> classified instances (TP + <b>TN</b>)/ (TP + <b>TN</b> + FP + FN). where TP, FN, FP and <b>TN</b> represent the number of <b>true</b> positives, false negatives ...", "dateLastCrawled": "2022-02-03T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Using Asymmetric Classification Cost Matrices in <b>Predicting</b> Diabetes", "url": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1011&context=icdss2007", "isFamilyFriendly": true, "displayUrl": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1011&amp;context=icdss2007", "snippet": "classifier for <b>predicting</b> <b>disease</b>. This is determined by the type of <b>disease</b>, its associated classification cost matrix and/or the target population on which the classifier will be used. Diabetes has higher costs associated with false negatives than <b>true</b> positives, as the <b>disease</b> <b>can</b> progress very rapidly when left untreated. There are two ways to skew a classifier to work towards the given classification cost matrix: (1) by changing the classification probability value, P* based on the ...", "dateLastCrawled": "2022-01-02T19:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Evaluating a <b>Classification Model</b> | Machine Learning, Deep Learning ...", "url": "https://www.ritchieng.com/machine-learning-evaluate-classification-model/", "isFamilyFriendly": true, "displayUrl": "https://www.ritchieng.com/machine-learning-evaluate-<b>classification-model</b>", "snippet": "Null accuracy: accuracy that could be achieved by always <b>predicting</b> the most frequent class. We must always compare with this; In [8]: # examine the class distribution of the testing set (using a Pandas Series method) y_test. value_counts Out[8]: 0 130 1 62 Name: label, dtype: int64. In [9]: # calculate the percentage of ones # because y_test only contains ones and zeros, we <b>can</b> simply calculate the mean = percentage of ones y_test. mean Out[9]: 0.3229166666666667. 32% of the. In [10 ...", "dateLastCrawled": "2022-02-03T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Classification Accuracy is <b>Not</b> Enough: More Performance Measures You ...", "url": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/classification-accuracy-is-<b>not</b>-enough-", "snippet": "I <b>have</b> an issue, I had an umbalced and poor training set, I did up sampling but I <b>have</b> a problem with neural network. It <b>does</b> <b>not</b> classify upsampled class. just to be clear: precision recall f1-score support. 1 0.56 1.00 0.72 1013 2 0.00 0.00 0.00 797. accuracy 0.56 1810", "dateLastCrawled": "2022-02-03T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Module 3 - GitHub Pages", "url": "https://it-gecbh.github.io/2020/resources/ML/module_3.pptx", "isFamilyFriendly": true, "displayUrl": "https://it-gecbh.github.io/2020/resources/ML/module_3.pptx", "snippet": "A <b>patient</b> has cancer or <b>not</b>. A <b>patient</b> takes a lab test and result comes back positive. The test returns a correct positive result in only 98% of the cases in which the <b>disease</b> actually present, and a correct <b>negative</b> result is only 97% of the cases in which the <b>disease</b> is <b>not</b> present. Furthermore .008 of the entire population <b>have</b> this cancer", "dateLastCrawled": "2022-01-31T20:05:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Confusion Matrix in <b>Machine</b> <b>Learning</b> \u2013 Naukri <b>Learning</b>", "url": "https://www.naukri.com/learning/articles/confusion-matrix-in-machine-learning-naukri-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.naukri.com/<b>learning</b>/articles/confusion-matrix-in-<b>machine</b>-<b>learning</b>-naukri...", "snippet": "Let\u2019s understand TP, FP, FN, <b>TN</b> in terms of Coronavirus affected people <b>analogy</b>. <b>True</b> Positive: Interpretation: You predicted positive and it\u2019s <b>true</b>. You predicted that a person is Corona positive and he actually is having Corona. <b>True</b> <b>Negative</b>: Interpretation: You predicted <b>negative</b> and it\u2019s <b>true</b>.", "dateLastCrawled": "2022-02-07T08:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding Confusion Matrix in <b>Machine</b> <b>Learning</b>, Let\u2019s Study ...", "url": "https://ulimazzadaislamy.medium.com/understanding-confusion-matrix-in-machine-learning-lets-study-together-7521090aaaf2", "isFamilyFriendly": true, "displayUrl": "https://ulimazzadaislamy.medium.com/understanding-confusion-matrix-in-<b>machine</b>-<b>learning</b>...", "snippet": "Let\u2019s understand TP, FP, FN, <b>TN</b> in terms of pregnancy <b>analogy</b>: The <b>analogy</b> from the picture: <b>True</b> Positive: Interpretation: You predicted positive and it\u2019s <b>true</b>. You predicted that a woman is pregnant and she actually is. <b>True</b> <b>Negative</b>: Interpretation: You predicted <b>negative</b> and it\u2019s <b>true</b>. You predicted that a man is not pregnant and he actually is not. False Positive: (Type 1 Error) Interpretation: You predicted positive and it\u2019s false. You predicted that a man is pregnant but he ...", "dateLastCrawled": "2022-01-13T10:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Insurance claims \u2014 Fraud detection using <b>machine</b> <b>learning</b> | by Punith ...", "url": "https://medium.com/geekculture/insurance-claims-fraud-detection-using-machine-learning-78f04913097", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/insurance-claims-fraud-detection-using-<b>machine</b>-<b>learning</b>...", "snippet": "<b>TN</b>/<b>True</b> <b>Negative</b>: the cases were <b>negative</b> and predicted <b>negative</b>. TP/<b>True</b> Positive: the cases were positive and predicted positive. FN/False <b>Negative</b>: the cases were positive but predicted ...", "dateLastCrawled": "2022-02-03T04:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Module 21 - How to build a <b>Machine</b> <b>Learning</b> Intrusion Detection system ...", "url": "https://www.blueteamsacademy.com/ml-ids/", "isFamilyFriendly": true, "displayUrl": "https://www.blueteamsacademy.com/ml-ids", "snippet": "Module 21 - How to build a <b>Machine</b> <b>Learning</b> Intrusion Detection system Module 21 - How to ... <b>tn</b> = <b>True</b> <b>Negative</b>; fn = False <b>Negative</b>; Precision . Precision or Positive Predictive Value, is the ratio of the positive samples that are correctly classified by the the total number of positive classified samples.Simply it is the number of the found samples were correct hits. Recall. Recall or <b>True</b> Positive Rate, is the ratio of <b>true</b> positive classifications by the total number of positive samples ...", "dateLastCrawled": "2022-01-31T06:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding Confusion Matrix. When we get the data, after data\u2026 | by ...", "url": "https://medium.com/@piyushpkc.4g/understanding-confusion-matrix-8549c97aad62", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@piyushpkc.4g/understanding-confusion-matrix-8549c97aad62", "snippet": "Confusion Matrix is a performance measurement for <b>machine</b> <b>learning</b> classification. ... FN, <b>TN</b> in terms of pregnancy <b>analogy</b>. <b>True</b> Positive : Interpretation: You predicted positive and it\u2019s <b>true</b> ...", "dateLastCrawled": "2021-08-25T08:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is <b>True</b> <b>Negative</b>, and a pregnant woman whose test results say \u201cPregnant\u201d is <b>True</b> Positive. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Top <b>50+ Machine Learning Interview Questions and Answers</b>", "url": "https://www.techgeekbuzz.com/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.techgeekbuzz.com/<b>machine</b>-<b>learning</b>-interview-questions", "snippet": "FN is false <b>negative</b>. These are positive values incorrectly predicted as <b>negative</b> values. <b>TN</b> is <b>true</b> <b>negative</b>. It is a <b>negative</b> value rightly predicted as an actual <b>negative</b>. The accuracy can be calculated as, Accuracy = TP + <b>TN</b> \u2014\u2014\u2014\u2014\u2014\u2014\u2013 TP + <b>TN</b> + FP + FN", "dateLastCrawled": "2022-01-20T21:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "Confusion Matrix Confusion Matrix is a performance measurement for a <b>machine learning</b> classification problem where output can be two or more classes. It is a table with 4 different combinations of predicted and actual values as shown below. It is very useful for measuring other <b>evaluation metrics</b> such as Recall, Precision, Specificity, Accuracy, and most importantly AUC-ROC Curve. Following is an example in terms of pregnancy <b>analogy</b> to help you better understand TP, <b>TN</b>, FP, and FN. <b>True</b> ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What is</b> AUC - <b>ROC</b> in <b>Machine</b> <b>Learning</b> | Overview of <b>ROC</b>", "url": "https://www.mygreatlearning.com/blog/roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>roc</b>-curve", "snippet": "However, any threshold applied to a dataset (in which PP is the positive population and NP is the <b>negative</b> population) is going to produce <b>true</b> positives (TP), false positives (FP), <b>true</b> negatives (<b>TN</b>) and false negatives (FN). We need a method which will take into account all of these numbers.", "dateLastCrawled": "2022-01-30T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Spectrofluorometric analysis combined with <b>machine</b> <b>learning</b> for ...", "url": "https://www.sciencedirect.com/science/article/pii/S0308814621011559", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0308814621011559", "snippet": "The effectiveness of the model was evaluated by the confusion matrix score probabilities, which are calculated from the values for <b>true</b> positive (TP), false positive (FP), <b>true</b> <b>negative</b> (<b>TN</b>) and false <b>negative</b> (FN) for each class, according to the \u201cmost probable\u201d prediction rule of the given classification algorithm (Eigenvector, 2017). This enabled the calculation of the following:", "dateLastCrawled": "2021-12-26T01:57:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(true negative (tn))  is like +(correctly predicting that a patient does not have a disease)", "+(true negative (tn)) is similar to +(correctly predicting that a patient does not have a disease)", "+(true negative (tn)) can be thought of as +(correctly predicting that a patient does not have a disease)", "+(true negative (tn)) can be compared to +(correctly predicting that a patient does not have a disease)", "machine learning +(true negative (tn) AND analogy)", "machine learning +(\"true negative (tn) is like\")", "machine learning +(\"true negative (tn) is similar\")", "machine learning +(\"just as true negative (tn)\")", "machine learning +(\"true negative (tn) can be thought of as\")", "machine learning +(\"true negative (tn) can be compared to\")"]}