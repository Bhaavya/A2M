{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Google AI\u2019s MURAL: <b>Multimodal</b>, Multi-task Retrieval Across Languages", "url": "https://analyticsindiamag.com/what-exactly-is-google-ais-mural-multimodal-multi-task-retrieval-across-languages/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/what-exactly-is-google-ais-mural-<b>multimodal</b>-multi-task...", "snippet": "This type of data mostly comes for highly-resourced languages <b>like</b> English and Chinese. To address this, Google AI has released the \u201cMURAL: <b>Multimodal</b>, Multitask Representations Across Languages\u201d <b>model</b> for image\u2013text matching. It uses multitask learning applied to image\u2013text pairs in combination with translation pairs covering over 100 languages. In the paper titled, \u201cMURAL: <b>Multimodal</b>, Multitask Retrieval Across Languages\u201c, the research team says they have explored dual encoder ...", "dateLastCrawled": "2022-01-29T08:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A deep dive into <b>multilingual</b> NLP models - Peltarion", "url": "https://peltarion.com/blog/data-science/a-deep-dive-into-multilingual-nlp-models", "isFamilyFriendly": true, "displayUrl": "https://peltarion.com/blog/data-science/a-deep-dive-into-<b>multilingual</b>-nlp-<b>models</b>", "snippet": "An alternative approach is to train a <b>multilingual</b> <b>model</b>, that is, a single <b>model</b> that can handle multiple languages simultaneously. This would circumvent having to train a monolingual <b>model</b> for every single language, and recent results suggest that <b>multilingual</b> models can even achieve better performance than monolingual models, especially for low-resource languages. In particular, XLM-R (Conneau et al., 2019), a 100-language <b>model</b> introduced by Facebook AI researchers in November 2019 ...", "dateLastCrawled": "2022-01-26T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Scientific modeling and translanguaging: A <b>multilingual</b> and <b>multimodal</b> ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1002/sce.21622", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1002/sce.21622", "snippet": "Together, these studies have identified several promising strategies for supporting <b>multilingual</b> and <b>multimodal</b> composing, including: Explicitly valuing students&#39; language and cultures (Garc\u00eda &amp; Kleifgen, 2019; L. W. Rowe, 2018), modeling <b>multilingual</b> composing (Machado &amp; Hartman, 2019), introducing <b>multilingual</b> mentor texts (Zapata &amp; Laman, 2016), leveraging digital tools to mediate heritage-language use (D. W&gt; Rowe &amp; Miller, 2016; L. W. Rowe, 2020; Vogel et al., 2018), and emphasizing ...", "dateLastCrawled": "2022-01-13T14:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "2019 International Conference on <b>Multimodal</b> Interaction: <b>Multi-modal</b> ...", "url": "https://dl.acm.org/doi/pdf/10.1145/3340555.3353742", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/pdf/10.1145/3340555.3353742", "snippet": "<b>multimodal</b>, and characterized by vast individual and contex-tual heterogeneity. To achieve meaningful <b>human</b>-computer and <b>human</b>-robot interactions, <b>multi-modal</b> models of the user\u2019s states (e.g., engagement) are therefore needed. Most of the existing works that try to build classifiers for the user\u2019s states assume that the data to train the models are fully labeled. Nevertheless, data labeling is costly and tedious, and also prone to subjective interpretations by the <b>human</b> coders. This is ...", "dateLastCrawled": "2022-01-30T16:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Multimodal</b> AI Takes Off - read.deeplearning.ai", "url": "https://read.deeplearning.ai/the-batch/issue-123/", "isFamilyFriendly": true, "displayUrl": "https://read.deeplearning.ai/the-batch/issue-123", "snippet": "Google said it would add <b>multimodal</b> (and <b>multilingual</b>) capabilities to its search engine. Its Muiltitask Unified <b>Model</b> returns links to text, audio, images, and videos in response to queries in any of 75 languages. Behind the news: The year\u2019s <b>multimodal</b> momentum built upon decades of research. In 1989, researchers at Johns Hopkins University and UC San Diego developed a system that classified vowels based on audio and visual data of people speaking. Over the next two decades, various ...", "dateLastCrawled": "2022-02-03T00:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Multimodality Talks Series: The Kinesemiotic Body: an empirical ...", "url": "https://mmodalityleeds.wordpress.com/2021/11/30/multimodality-talks-series-the-kinesemiotic-body-an-empirical-approach-to-investigating-the-multimodal-discourse-organization-of-dance%EF%BF%BC/", "isFamilyFriendly": true, "displayUrl": "https://mmodalityleeds.wordpress.com/2021/11/30/<b>multimodal</b>ity-talks-series-the-kine...", "snippet": "The Kinesemiotic Body project is an interdisciplinary project drawing on linguistics, <b>multimodal</b> semiotics, empirical <b>human</b>-motion studies, and dance. It is being carried out in collaboration with professional dancers from the English National Ballet and is jointly funded by the AHRC in the UK and the DFG in Germany. The project aims at evaluating the extent to which an explicit, linguistically-motivated formal and functional notion of <b>multimodal</b> discourse can deepen our understanding of how ...", "dateLastCrawled": "2022-01-28T14:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "MultiSubs: A <b>Large-scale Multimodal and Multilingual Dataset</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2103.01910/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2103.01910", "snippet": "This paper introduces a <b>large-scale multimodal and multilingual dataset</b> that aims to facilitate research on grounding words to images in their contextual usage in language. The dataset consists of images selected to unambiguously illustrate concepts expressed in sentences from movie subtitles. The dataset is a valuable resource as (i) the images are aligned to text fragments rather than whole sentences; (ii) multiple images are possible for a text fragment and a sentence; (iii) the sentences ...", "dateLastCrawled": "2021-11-25T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Cross-lingual Cross-modal Pretraining for <b>Multimodal</b> Retrieval", "url": "https://aclanthology.org/2021.naacl-main.285.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.naacl-main.285.pdf", "snippet": "To learn <b>multilingual</b> <b>multimodal</b> representa-tions, recent researchers utilized <b>multilingual</b> datasets to <b>model</b> images and text captions in a joint embedding space. Based on how the shared feature space is learned, there are two categories: word-level alignments (Mohammadshahi et al.,2019) and sentence-level alignments (Wehrmann et al.,", "dateLastCrawled": "2022-01-29T02:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Multimodal</b> Co-learning: Challenges, applications with datasets, recent ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "snippet": "<b>Multimodal</b> Factorization <b>Model</b> (MFM) factorizes <b>multimodal</b> data into a) discriminative factors, which are common across all modalities, and b) generative factors, which are specific to modality. Information-based interpretation over the entire dataset and gradient-based interpretation over a video segment is performed to study the contribution of each modality, and results are the same as <b>human</b> observations attributing to either presence of specific words or facial expressions.", "dateLastCrawled": "2022-01-27T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Extending BERT-<b>like</b> Language Models for Multiple Languages and Longer ...", "url": "https://peltarion.com/blog/data-science/extending-bert-like-language-models-for-multiple-languages-and-longer-documents", "isFamilyFriendly": true, "displayUrl": "https://peltarion.com/blog/data-science/extending-bert-<b>like</b>-language-<b>models</b>-for...", "snippet": "The Longformer <b>model</b>, made by researchers from Allen AI, is a Transformer agnostic <b>model</b> that can re-use part of the attention mapping a language <b>model</b>, such as BERT has already learned, and re-purpose that to efficiently learn contexts over longer passages. After extending the attention span of a <b>model</b> it is trained on a dataset with long sentences to learn those new mappings quickly. Using this method, we extended the attention span of a <b>multilingual</b> XLM-R <b>model</b> to 8 times its original ...", "dateLastCrawled": "2022-01-15T22:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "CMU-MOSEAS: A <b>Multimodal</b> Language Dataset for Spanish, Portuguese ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8106386/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8106386", "snippet": "Our evaluations on a state-of-the-art <b>multimodal</b> <b>model</b> demonstrates that CMU-MOSEAS enables further research for <b>multilingual</b> studies in <b>multimodal</b> language. 1. Introduction. Humans use a coordinated <b>multimodal</b> signal to communicate with each other. This communication signal is called <b>multimodal</b> language Perniss, 2018); a complex temporal and idiosyncratic signal which includes the modalities of language, visual and acoustic. On a daily basis across the world, intentions and emotions are ...", "dateLastCrawled": "2021-12-27T00:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A deep dive into <b>multilingual</b> NLP models - Peltarion", "url": "https://peltarion.com/blog/data-science/a-deep-dive-into-multilingual-nlp-models", "isFamilyFriendly": true, "displayUrl": "https://peltarion.com/blog/data-science/a-deep-dive-in<b>to-multilingual</b>-nlp-<b>models</b>", "snippet": "An alternative approach is to train a <b>multilingual</b> <b>model</b>, that is, a single <b>model</b> that can handle multiple languages simultaneously. This would circumvent having to train a monolingual <b>model</b> for every single language, and recent results suggest that <b>multilingual</b> models can even achieve better performance than monolingual models, especially for low-resource languages. In particular, XLM-R (Conneau et al., 2019), a 100-language <b>model</b> introduced by Facebook AI researchers in November 2019 ...", "dateLastCrawled": "2022-01-26T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Cross-lingual Cross-modal Pretraining for <b>Multimodal</b> Retrieval", "url": "https://aclanthology.org/2021.naacl-main.285.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.naacl-main.285.pdf", "snippet": "To learn <b>multilingual</b> <b>multimodal</b> representa-tions, recent researchers utilized <b>multilingual</b> datasets to <b>model</b> images and text captions in a joint embedding space. Based on how the shared feature space is learned, there are two categories: word-level alignments (Mohammadshahi et al.,2019) and sentence-level alignments (Wehrmann et al.,", "dateLastCrawled": "2022-01-29T02:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Forward and Backward <b>Multimodal</b> NMT for Improved Monolingual and ...", "url": "https://dl.acm.org/doi/pdf/10.1145/3372278.3390674", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/pdf/10.1145/3372278.3390674", "snippet": "cost of <b>human</b> annotation. The lack of coverage and diversity in the text descriptions thus inevitably constraints <b>model</b> performance in cross-modal tasks such as text-to-image retrieval and captioning. As analyzed by Dai et al. [8, 9], captioning models tend to overfit the ground-truth annotations and produce less distinctive descrip- tions while discouraging other reasonable alternatives. For cross-modal retrieval, Huang et al. [17] quantifies the impact of limited text content for learning ...", "dateLastCrawled": "2021-12-03T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Multilingual</b> <b>Multimodal</b> Machine Translation for Dravidian Languages ...", "url": "https://www.insight-centre.org/wp-content/uploads/2020/06/Multilingual-Multimodal-Machine-Translation-for-Dravidian-Languages-utilizing-Phonetic-Transcription.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.insight-centre.org/wp-content/uploads/2020/06/<b>Multilingual</b>-<b>Multimodal</b>...", "snippet": "<b>Multilingual</b> <b>Multimodal</b> Machine Translation for Dravidian Languages utilizing Phonetic Transcription Bharathi Raja Chakravarthi, Bernardo Stearns ,Mihael Arcan , Manel Zarrouk, and John P. McCrae Insight Centre for Data Analytics National University of Ireland Galway Galway, Ireland name.surname@insight-centre.org Ruba Priyadharshini Saraswathi Narayanan College, Madurai, India Arun Jayapal Smart Insights from Conversations, Hyderabad, India S. Sridevy Tamil Nadu Agricultural University ...", "dateLastCrawled": "2021-08-15T16:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "MURAL: <b>Multimodal</b>, Multitask Representations Across Languages", "url": "https://aclanthology.org/2021.findings-emnlp.293.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.findings-emnlp.293.pdf", "snippet": "<b>Multilingual</b> captions for images provide indirect but valuable associations between languages (Gella et al.,2017).Burns et al.(2020) exploit this to scale <b>multimodal</b> representations to support more languages with a smaller <b>model</b> than prior stud-ies. More recent work learns cross encoder models with multitask training objectives (Ni et al.,2021; Zhou et al.,2021); in these, a single <b>multimodal</b> encoder attends to both inputs and exploits deep associations between images and captions. Un ...", "dateLastCrawled": "2022-02-03T16:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "MultiSubs: A <b>Large-scale Multimodal and Multilingual Dataset</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2103.01910/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2103.01910", "snippet": "This paper introduces a <b>large-scale multimodal and multilingual dataset</b> that aims to facilitate research on grounding words to images in their contextual usage in language. The dataset consists of images selected to unambiguously illustrate concepts expressed in sentences from movie subtitles. The dataset is a valuable resource as (i) the images are aligned to text fragments rather than whole sentences; (ii) multiple images are possible for a text fragment and a sentence; (iii) the sentences ...", "dateLastCrawled": "2021-11-25T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Multimodal</b> Image News Article Alignment", "url": "https://mohammedhasanuzzaman.github.io/papers/CICLing1.pdf", "isFamilyFriendly": true, "displayUrl": "https://mohammedhasanuzzaman.github.io/papers/CICLing1.pdf", "snippet": "In another study [5] which is very <b>similar</b> to our work a ranking <b>model</b> that learns embeddings from <b>multimodal</b> and <b>multilingual</b> data has been proposed. Their <b>model</b> takes the images and descriptions of multiple languages into consideration. Like in the other models discussed above, they also introduce a pairwise ranking function that is adapted to rank the images and sentences having more than two or three input sources images and their corresponding <b>multilingual</b> sentences. Their objective ...", "dateLastCrawled": "2021-11-22T10:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Neural language models for the <b>multilingual</b>, transcultural, and ...", "url": "https://content.iospress.com/articles/semantic-web/sw190373", "isFamilyFriendly": true, "displayUrl": "https://content.iospress.com/articles/semantic-web/sw190373", "snippet": "Building on neural-symbolic reasoning, such systems could enable a <b>multilingual</b>, <b>multimodal</b> query-answering system on formally structured resources. Major challenges here are <b>similar</b> to those of transcultural modeling. Local contexts and linguistic variations need to be taken into account to grant broad information access and a high usability. Nevertheless, achieving a speech-empowered SW technologies strongly furthers the endeavor to break down access barriers to represented information.", "dateLastCrawled": "2022-01-13T18:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Model-based, multimodal interaction in document browsing</b> ...", "url": "https://www.academia.edu/2622767/Model_based_multimodal_interaction_in_document_browsing", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2622767/<b>Model_based_multimodal_interaction_in_document_browsing</b>", "snippet": "<b>Model-Based, Multimodal Interaction in Document Browsing</b> Parisa Eslambolchilar1 ,Roderick Murray-Smith1,2 1 Hamilton Institute, National University of Ireland, Maynooth, Co.Kildare, Ireland parisa.eslambolchilar@nuim.ie 2 Department of Computing Science, Glasgow University, Glasgow, Scotland rod@dcs.gla.ac.uk Abstract. In this paper we introduce a dynamic system approach to the design of <b>multimodal</b> interactive systems. We use an example where we support <b>human</b> behavior in browsing a document ...", "dateLastCrawled": "2022-01-22T23:32:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Multimodal Languaging as a Pedagogical Model\u2014A Case Study of</b> ... - MDPI", "url": "https://www.mdpi.com/2227-7102/7/1/9/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2227-7102/7/1/9/htm", "snippet": "The purpose of this study is to present a <b>multimodal</b> languaging <b>model</b> for mathematics education. The <b>model</b> consists of mathematical symbolic language, a pictorial language, and a natural language. By applying this <b>model</b>, the objective was to study how 4th grade pupils (N = 21) understand the concept of division. The data was collected over six hours of teaching sessions, during which the pupils expressed their mathematical thinking mainly by writing and drawing. Their productions, as well as ...", "dateLastCrawled": "2022-02-02T13:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "MultiSubs: A <b>Large-scale Multimodal and Multilingual Dataset</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2103.01910/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2103.01910", "snippet": "This paper introduces a <b>large-scale multimodal and multilingual dataset</b> that aims to facilitate research on grounding words to images in their contextual usage in language. The dataset consists of images selected to unambiguously illustrate concepts expressed in sentences from movie subtitles. The dataset is a valuable resource as (i) the images are aligned to text fragments rather than whole sentences; (ii) multiple images are possible for a text fragment and a sentence; (iii) the sentences ...", "dateLastCrawled": "2021-11-25T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Lessons Learned in <b>Multilingual</b> Grounded Language Learning", "url": "https://aclanthology.org/K18-1039.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/K18-1039.pdf", "snippet": "We demonstrate that a <b>multilingual</b> <b>model</b> <b>can</b> be trained equally well on either translations or comparable sentence pairs, and that annotating the same set of images in multiple language en- ables further improvements via an additional caption-caption ranking objective. 1 Introduction <b>Multimodal</b> representation learning is largely mo-tivated by evidence of perceptual grounding in <b>hu-man</b> concept acquisition and representation (Barsa-lou et al.,2003). It has been shown that visually grounded ...", "dateLastCrawled": "2022-01-05T16:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Multimodal</b> Co-learning: Challenges, applications with datasets, recent ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "snippet": "This relationship <b>can</b> serve as an alignment and supervised data to create <b>multimodal</b> <b>multilingual</b> embedding; contrastive learning methods help form intra-modal, inter-modal, and cross-lingual pairs among data points. Transformers trained using video and <b>multilingual</b> text has outperformed transformers trained on just video and English text for video search using <b>multilingual</b> text. They performed better at zero-shot learning. In the year 2016, the conference on machine translation (WMT16) had ...", "dateLastCrawled": "2022-01-27T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Multi-Language Image Description with Neural Sequence Models ...", "url": "https://www.academia.edu/69513738/Multi_Language_Image_Description_with_Neural_Sequence_Models", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/.../Multi_Language_Image_Description_with_Neural_Sequence_<b>Models</b>", "snippet": "A Shared Task on <b>Multimodal</b> Machine Translation and Crosslingual Image Description. By Khalil Sima&#39;an. Multi30K: <b>Multilingual</b> English-German Image Descriptions. By Khalil Sima&#39;an. Unsupervised <b>Multimodal</b> Neural Machine Translation with Pseudo Visual Pivoting. By Alexander Hauptmann. Using Images to Improve Machine-Translating E-Commerce Product Listings. By Pintu Lohar. MSVD-Turkish: A Comprehensive <b>Multimodal</b> Dataset for Integrated Vision and Language Research in Turkish. By Menekse Kuyu ...", "dateLastCrawled": "2022-02-01T00:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "MultiSubs: A Large-scale <b>Multimodal</b> and <b>Multilingual</b> Dataset", "url": "https://www.readkong.com/page/multisubs-a-large-scale-multimodal-and-multilingual-dataset-3463238", "isFamilyFriendly": true, "displayUrl": "https://www.readkong.com/page/multisubs-a-large-scale-<b>multimodal</b>-and-<b>multilingual</b>...", "snippet": "Page topic: &quot;MultiSubs: A Large-scale <b>Multimodal</b> and <b>Multilingual</b> Dataset&quot;. Created by: Beatrice Carr. Language: english.", "dateLastCrawled": "2021-10-06T19:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Meet ByteDance AI\u2019s <b>Xiaomingbot: World\u2019s First Multilingual</b> and ...", "url": "https://medium.com/syncedreview/meet-bytedance-ais-xiaomingbot-world-s-first-multilingual-and-multimodal-ai-news-agent-28e93316a2fc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/syncedreview/meet-bytedance-ais-xiaomingbot-world-s-first...", "snippet": "Next, a state-of-the-art transformer large <b>model</b> is used as a machine translation module to translate the abstract into the user-specified language. A text to speech (TTS) module with <b>multilingual</b> ...", "dateLastCrawled": "2020-12-21T12:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Multimodal human\u2013computer interaction</b>: A survey - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1077314206002335", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1077314206002335", "snippet": "In general, vision-based <b>human</b> motion analysis systems used for MMHCI <b>can</b> <b>be thought</b> of as having mainly four stages: (1) motion segmentation, (2) object classification, (3) tracking, and (4) interpretation. While some approaches use geometric primitives to <b>model</b> different components (e.g., cylinders used to <b>model</b> limbs, head, and torso for body movements, or for hand and fingers in gesture recognition), others use feature representations based on appearance (appearance-based methods). In ...", "dateLastCrawled": "2022-02-02T17:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Achieving Semantic Consistency for <b>Multilingual</b> Sentence Representation ...", "url": "https://www.mdpi.com/2076-3417/11/24/11699/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2076-3417/11/24/11699/htm", "snippet": "The proposed T SignX <b>model</b> <b>can</b> represent different sentences with the same tree if they have the same semantics. Because the order of the words does not affect its representation, it reduces the influence of language, which has the property of flexible order. A sentence becomes a case sentence through the case generation, which appends a case concept for each word, as shown in Definition 4.", "dateLastCrawled": "2022-01-14T00:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Bipasha Sen", "url": "https://bipashasen.github.io/", "isFamilyFriendly": true, "displayUrl": "https://bipashasen.github.io", "snippet": "<b>Human</b> actions <b>can</b> <b>be thought</b> of as a collective action of these parts. Hence, learning an effective spatio-temporal representation of the collective motion of these parts is key to action recognition. In this work, we propose an end-to-end pipeline for the task of <b>human</b> action recognition on video sequences using 2D joint trajectories estimated from a pose estimation framework. We use a Hierarchical Bidirectional Long Short Term Memory Network (HBLSTM) to <b>model</b> the spatio-temporal ...", "dateLastCrawled": "2022-01-31T12:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A STUDY ON DEEP LEARNING ALGORITHMS FOR <b>MULTIMODAL</b> AND <b>MULTILINGUAL</b> ...", "url": "https://www.worldwidejournals.com/indian-journal-of-applied-research-(IJAR)/recent_issues_pdf/2021/July/a-study-on-deep-learning-algorithms-for-multimodal-and-multilingual-cyberbullying-detection_July_2021_5415661132_4620274.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.worldwidejournals.com/indian-journal-of-applied-research-(IJAR)/recent...", "snippet": "patterns of the bullies and also it <b>can</b> generate a <b>model</b> to automatically detect cyberbullying actions. Two main challenges are identi ed related cyberbullying detection such as the lack of information on how multimedia <b>can</b> be handled in detection and building the <b>model</b>, and detecting the cyberbullying content in mixing of multiple languages. Recently, Deep Neural Network Based models have also been applied for the detection of cyberbullying due it improves accuracy when trained with huge ...", "dateLastCrawled": "2022-01-30T19:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A deep dive into <b>multilingual</b> NLP models - Peltarion", "url": "https://peltarion.com/blog/data-science/a-deep-dive-into-multilingual-nlp-models", "isFamilyFriendly": true, "displayUrl": "https://peltarion.com/blog/data-science/a-deep-dive-in<b>to-multilingual</b>-nlp-<b>models</b>", "snippet": "An alternative approach is to train a <b>multilingual</b> <b>model</b>, that is, a single <b>model</b> that <b>can</b> handle multiple languages simultaneously. This would circumvent having to train a monolingual <b>model</b> for every single language, and recent results suggest that <b>multilingual</b> models <b>can</b> even achieve better performance than monolingual models, especially for low-resource languages. In particular, XLM-R (Conneau et al., 2019), a 100-language <b>model</b> introduced by Facebook AI researchers in November 2019 ...", "dateLastCrawled": "2022-01-26T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Scientific modeling and translanguaging: A <b>multilingual</b> and <b>multimodal</b> ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1002/sce.21622", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1002/sce.21622", "snippet": "Together, these studies have identified several promising strategies for supporting <b>multilingual</b> and <b>multimodal</b> composing, including: Explicitly valuing students&#39; language and cultures (Garc\u00eda &amp; Kleifgen, 2019; L. W. Rowe, 2018), modeling <b>multilingual</b> composing (Machado &amp; Hartman, 2019), introducing <b>multilingual</b> mentor texts (Zapata &amp; Laman, 2016), leveraging digital tools to mediate heritage-language use (D. W&gt; Rowe &amp; Miller, 2016; L. W. Rowe, 2020; Vogel et al., 2018), and emphasizing ...", "dateLastCrawled": "2022-01-13T14:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Multimodal</b> Sentiment Analysis Using Multi-tensor Fusion Network with ...", "url": "https://www.tandfonline.com/doi/pdf/10.1080/08839514.2021.2000688", "isFamilyFriendly": true, "displayUrl": "https://www.tandfonline.com/doi/pdf/10.1080/08839514.2021.2000688", "snippet": "<b>Multimodal</b> Sentiment Analysis Using Multi-tensor Fusion Network with Cross-modal Modeling Xueming Yan a, Haiwei Xueb, Shengyi Jiang a, and Ziang Liuc aGuangzhou Key Laboratory of <b>Multilingual</b> Intelligent Processing &amp; School Information Science and Technology, Guangdong University of Foreign Studies, Guangzhou, China; bSchool of Information Science and Technology, Guangdong University of Foreign Studies, Guangzhou, China; cFaculty of Science, University of Alberta, Edmonton, Canada", "dateLastCrawled": "2022-01-27T01:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>UC2: Universal Cross-lingual Cross-modal</b> Vision-and-Language Pre ...", "url": "https://deepai.org/publication/uc2-universal-cross-lingual-cross-modal-vision-and-language-pre-training", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>uc2-universal-cross-lingual-cross-modal</b>-vision-and...", "snippet": "The world we navigate through is a <b>multimodal</b> and <b>multilingual</b> kaleidoscope. While tremendous success has been realized in <b>multimodal</b> research with the advent of vision-and-language (V+L) pre-training [UNITER, OSCAR, vilbert, tan2019lxmert, huang2020pixelbert], the majority of current literature is biased towards English.Although English-trained V+L models <b>can</b> be finetuned on each target language (given that there is sufficient language-specific data in downstream task), maintaining language ...", "dateLastCrawled": "2021-12-18T05:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Cross-lingual Cross-modal Pretraining for <b>Multimodal</b> Retrieval", "url": "https://aclanthology.org/2021.naacl-main.285.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.naacl-main.285.pdf", "snippet": "To learn <b>multilingual</b> <b>multimodal</b> representa-tions, recent researchers utilized <b>multilingual</b> datasets to <b>model</b> images and text captions in a joint embedding space. Based on how the shared feature space is learned, there are two categories: word-level alignments (Mohammadshahi et al.,2019) and sentence-level alignments (Wehrmann et al.,", "dateLastCrawled": "2022-01-29T02:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "MultiSubs: A <b>Large-scale Multimodal and Multilingual Dataset</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2103.01910/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2103.01910", "snippet": "This paper introduces a <b>large-scale multimodal and multilingual dataset</b> that aims to facilitate research on grounding words to images in their contextual usage in language. The dataset consists of images selected to unambiguously illustrate concepts expressed in sentences from movie subtitles. The dataset is a valuable resource as (i) the images are aligned to text fragments rather than whole sentences; (ii) multiple images are possible for a text fragment and a sentence; (iii) the sentences ...", "dateLastCrawled": "2021-11-25T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Enhancing multimodal deep representation learning by</b> fixed <b>model</b> reuse ...", "url": "https://link.springer.com/article/10.1007/s11042-018-6556-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11042-018-6556-6", "snippet": "The time cost of pre-training a unilingual OCR <b>model</b> <b>can</b> be simply eliminated <b>compared</b> to that of training a <b>multilingual</b> OCR <b>model</b>. We <b>can</b> easily pre-train a unilingual OCR <b>model</b> for our deep networks in any <b>multilingual</b> application scenarios. <b>Multimodal</b> representation learning architecture for long-text-based image retrieval. Traditional text-based image retrieval uses short-text query, like keyword or short description, to retrieve corresponding image. But the long-text-based image ...", "dateLastCrawled": "2021-12-14T15:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Model-based, multimodal interaction in document browsing</b> ...", "url": "https://www.academia.edu/2622767/Model_based_multimodal_interaction_in_document_browsing", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2622767/<b>Model_based_multimodal_interaction_in_document_browsing</b>", "snippet": "In this paper, as an illustration of how this approach <b>can</b> support <b>multimodal</b> interaction, we use the example of browsing and sensing <b>multilingual</b> texts. Here the focus-in-context method and the adaptive dynamics are coupled with soni- fication, based on a probabilistic language <b>model</b>, which <b>can</b> be linked to a wide range of inputs and feedback/display mechanisms. 2 Continuous Interaction and Text Browsing Our interaction <b>model</b> is an example of continuous interaction which means the user is ...", "dateLastCrawled": "2022-01-22T23:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "2019 International Conference on <b>Multimodal</b> Interaction: <b>Multi-modal</b> ...", "url": "https://dl.acm.org/doi/pdf/10.1145/3340555.3353742", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/pdf/10.1145/3340555.3353742", "snippet": "<b>Human</b> behavior expression and experience are inherently <b>multimodal</b>, and characterized by vast individual and contex-tual heterogeneity. To achieve meaningful <b>human</b>-computer and <b>human</b>-robot interactions, <b>multi-modal</b> models of the user\u2019s states (e.g., engagement) are therefore needed. Most of the existing works that try to build classifiers for the user\u2019s states assume that the data to train the models are fully labeled. Nevertheless, data labeling is costly and tedious, and also prone to ...", "dateLastCrawled": "2022-01-30T16:58:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Towards <b>Multimodal</b> <b>Machine</b> <b>Learning</b> Prediction of Individual Cognitive ...", "url": "http://oliverychen.github.io/files/doc/Stijn_Denissen_et_al.pdf", "isFamilyFriendly": true, "displayUrl": "oliverychen.github.io/files/doc/Stijn_Denissen_et_al.pdf", "snippet": "used to learn the function is the <b>model</b> of choice. The concept can be clari\ufb01ed by means of an <b>analogy</b>; a student studying for a future exam. In the \ufb01rst phase, the student will gather knowledge on the domain by using available resources such as books and lecture notes (training). The student subsequently veri\ufb01es whether additional study is necessary by completing an exam from previous years to which the answers are available (validation). Together, this is called the training phase. As ...", "dateLastCrawled": "2022-01-04T13:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A <b>multilayer multimodal detection and prediction</b> <b>model</b> based on ...", "url": "https://www.nature.com/articles/s41598-021-82098-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-82098-3", "snippet": "An interpretable <b>machine</b> <b>learning</b> <b>model</b> for diagnosis of Alzheimer\u2019s disease. PeerJ 7 , e6543 (2019). PubMed PubMed Central Article Google Scholar", "dateLastCrawled": "2022-02-02T22:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Quantum-Like <b>multimodal</b> network framework for modeling interaction ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "snippet": "Our double-slit experiment <b>analogy</b> for <b>multimodal</b> sentiment analysis. We use the wave function \u03c6(x) ... <b>Multimodal</b> deep <b>learning</b> (MDL) <b>model</b>: this <b>model</b> can learn a joint representation of various features extracted in different modalities, which is similar to the method proposed in . In , the authors used a restricted Boltzmann <b>machine</b> (RBM) to learn the joint distribution over image and text inputs. We choose to replace the RBM with a convolutional neural network (CNN) to learn the joint ...", "dateLastCrawled": "2022-01-24T13:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>Machine</b> <b>learning</b> approach for rapid disaster response based on multi ...", "url": "https://www.researchgate.net/publication/353658800_A_Machine_learning_approach_for_rapid_disaster_response_based_on_multi-modal_data_The_case_of_housing_shelter_needs/fulltext/6108fccb1ca20f6f86f712cb/A-Machine-learning-approach-for-rapid-disaster-response-based-on-multi-modal-data-The-case-of-housing-shelter-needs.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353658800_A_<b>Machine</b>_<b>learning</b>_approach_for...", "snippet": "Research has shown that using <b>multimodal</b> data for <b>machine</b> <b>learning</b> leads to more robust inference than learn- ing from a single modality [5,6,7,8]. There are two approaches to <b>multimodal</b> data fusion.", "dateLastCrawled": "2022-01-28T14:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> Models for Cultural Heritage Image Classification ...", "url": "https://pdfs.semanticscholar.org/6a10/3c66f0e252812acad7367b49c6af052d4eb8.pdf", "isFamilyFriendly": true, "displayUrl": "https://pdfs.semanticscholar.org/6a10/3c66f0e252812acad7367b49c6af052d4eb8.pdf", "snippet": "information rough sets and <b>analogy</b> based reasoning, and compares these with the results obtained from the Article <b>Machine</b> <b>Learning</b> Models for Cultural Heritage Image Classi\ufb01cation: Comparison Based on Attribute Selection Radmila Jankovic\u00b4 Mathematical Institute of the Serbian Academy of Sciences and Arts, 11000 Belgrade, Serbia; rjankovic@mi.sanu.ac.rs Received: 19 November 2019; Accepted: 21 December 2019; Published: 24 December 2019 Abstract: Image classi\ufb01cation is one of the most ...", "dateLastCrawled": "2021-12-30T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>machine</b> <b>learning</b> - How to identify the modes in a (<b>multimodal</b> ...", "url": "https://stackoverflow.com/questions/51179095/how-to-identify-the-modes-in-a-multimodal-continuous-variable", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/51179095", "snippet": "<b>machine</b>-<b>learning</b> statistics probability probability-density kernel-density. Share. Follow asked Jul 4 &#39;18 at 18:12. Paulo Paulo. 73 3 3 ... I&#39;ll recommend a mixture density <b>model</b>, with varying numbers of components. E.g. mixture with 1 component, mixture with 2 components, 3, 4, 5, etc. Note that with k components, the maximum possible number of modes is k, although, depending on the locations and scales of the components, there might be fewer modes. There are probably many libraries which ...", "dateLastCrawled": "2022-01-03T12:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "<b>Analogy</b>: <b>Model</b>=organism, evolution=<b>learning</b>. Even with the improvements we typically consider to be evolvability (discussed in the previous section), evolution is a slow learner. Since it relies on mutations, it can only happen on relatively large populations over several generations.", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Conceptualization as a Basis for Cognition \u2014 Human and <b>Machine</b> | by ...", "url": "https://towardsdatascience.com/conceptualization-as-a-basis-for-cognition-human-and-machine-345d9e687e3c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/conceptualization-as-a-basis-for-cognition-human-and...", "snippet": "2. Abstraction and <b>analogy</b> allow concepts to be re-applied in new domains. There are many, often conflicting, definitions and theories about what it means to conceptualize.For future AI systems, the following definition of conceptualization can be offered: The ability to abstract and evolve rich concept constructs within a world-view knowledge framework to facilitate broad deduction and generate new knowledge and skills.. Generalization is a Necessary but Insufficient Attribute of Cognitive AI", "dateLastCrawled": "2022-01-20T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep <b>Learning Models for Human Activity Recognition</b>", "url": "https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/deep-<b>learning-models-for-human-activity-recognition</b>", "snippet": "Human activity recognition, or HAR, is a challenging time series classification task. It involves predicting the movement of a person based on sensor data and traditionally involves deep domain expertise and methods from signal processing to correctly engineer features from the raw data in order to fit a <b>machine</b> <b>learning</b> <b>model</b>. Recently, deep <b>learning</b> methods such as convolutional neural networks and recurrent", "dateLastCrawled": "2022-02-02T16:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - What is the difference between multi-agent and multi ...", "url": "https://ai.stackexchange.com/questions/13794/what-is-the-difference-between-multi-agent-and-multi-modal-systems", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/13794/what-is-the-difference-between-multi...", "snippet": "<b>Multimodal</b> interaction (MI) refers to the interaction with a system (e.g. a computer) using multiple modalities (e.g. speech or gestures). For example, we usually can interact with a laptop using a keyboard and a touchpad (or mouse), so the keyboard and the touchpad are the two different modalities that are used to interact with the computer. MI could thus be considered a sub-field of", "dateLastCrawled": "2022-01-11T08:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(multimodal model)  is like +(multilingual human)", "+(multimodal model) is similar to +(multilingual human)", "+(multimodal model) can be thought of as +(multilingual human)", "+(multimodal model) can be compared to +(multilingual human)", "machine learning +(multimodal model AND analogy)", "machine learning +(\"multimodal model is like\")", "machine learning +(\"multimodal model is similar\")", "machine learning +(\"just as multimodal model\")", "machine learning +(\"multimodal model can be thought of as\")", "machine learning +(\"multimodal model can be compared to\")"]}