{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>AR Object Recognition: The Essentials And Two</b> ... - Roundtable <b>Learning</b>", "url": "https://roundtablelearning.com/ar-object-recognition/", "isFamilyFriendly": true, "displayUrl": "https://roundtable<b>learning</b>.com/ar-object-recognition", "snippet": "To <b>recognize</b> an object, the camera finds matches between the reference and frame images. ... Lacks soft-skills <b>learning</b> \u2014 AR isn\u2019t the best soft-skills teacher and is more beneficial for <b>learning</b> technical skills and processes. Soft-skills training is better taught under a different <b>modality</b>, <b>like</b> VR. How Does AR Object Recognition Technology Work? You may be wondering how AR object recognition software attaches a digital 3D object to a real-world object. To simplify, this process is ...", "dateLastCrawled": "2022-02-03T06:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Artistic Object Recognition by Unsupervised Style Adaptation", "url": "https://people.cs.pitt.edu/~chris/artistic_objects/accv2018.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.pitt.edu/~chris/artistic_<b>objects</b>/accv2018.pdf", "snippet": "<b>Computer</b> vision systems currently lack the ability to reli-ably <b>recognize</b> artistically rendered <b>objects</b>, especially when such data is limited. In this paper, we propose a method for recognizing <b>objects</b> in artistic modalities (such as paintings, cartoons, or sketches), without requiring any labeled data from those modalities. Our method explicitly accounts for stylistic domain shifts between and within domains. To do so, we introduce a complementary training <b>modality</b> constructed to be similar ...", "dateLastCrawled": "2021-11-05T03:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Train Image <b>Recognition</b> AI with 5 lines of code | by Moses Olafenwa ...", "url": "https://towardsdatascience.com/train-image-recognition-ai-with-5-lines-of-code-8ed0bdd8d9ba", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/train-image-<b>recognition</b>-ai-with-5-lines-of-code-8ed0bdd...", "snippet": "Then, in the 1990s, the concept of Machine <b>Learning</b> was introduced and it ushered in an era in which instead of telling computers what to look out for in recognizing scenes and <b>objects</b> in images and videos, we can instead design algorithms that will make computers to learn <b>how to recognize</b> scenes and <b>objects</b> in images by itself, just <b>like</b> a child learns to understand his/her environment by exploring. Machine <b>learning</b> opened the way for computers to learn to <b>recognize</b> almost any scene or ...", "dateLastCrawled": "2022-02-02T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Google Uses AI to Identify People</b> and <b>Objects</b>", "url": "https://www.bayometric.com/google-uses-ai-to-identify-people-objects/", "isFamilyFriendly": true, "displayUrl": "https://www.bayometric.com/<b>google-uses-ai-to-identify-people</b>-<b>objects</b>", "snippet": "These products leverage Google\u2019s expertise in machine <b>learning</b> and cloud processing to <b>recognize</b> people, places, <b>objects</b> and animals. Launched in May 2015, Google Photos is one of such products that comes equipped with AI powered recognition and image analysis capabilities. It is a photo sharing and storage service available as a browser and smartphone app. Google Photos may look <b>like</b> just another photo sharing app but it has a lot going under the hood. It can analyse images and ...", "dateLastCrawled": "2022-01-14T21:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Self-Supervised Feature <b>Learning</b> by Cross-<b>Modality</b> and Cross-View ...", "url": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Jing_Self-Supervised_Feature_Learning_by_Cross-Modality_and_Cross-View_Correspondences_CVPRW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Jing_Self-Supervised...", "snippet": "cilitate 3D <b>computer</b> vision research, more and more 3D datasets such as mesh and point cloud data have been re-cently proposed. Compared to the annotation process of 2D image data, 3D point cloud data are especially harder to an-notate and the cost is more expensive. To learn features from unlabeled data, many self-/un-supervised <b>learning</b> methods are proposed for images, videos [11,18,24], and 3D point cloud data [13] by train-ing deep neural networks to solve pretext tasks with au ...", "dateLastCrawled": "2022-01-25T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "From Sensory Signals to <b>Modality</b>-Independent Conceptual Representations ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640543/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4640543", "snippet": "For instance, people might use <b>modality</b>-specific representations of <b>objects</b> as a foundation for inferring <b>modality</b>-independent representations characterizing <b>objects</b>\u2019 intrinsic properties. To understand the nature of the latter representations, it is important to <b>recognize</b> the distinction between <b>objects</b>\u2019 intrinsic (or \u201cdeep\u201d) properties and the sensory (or \u201csurface\u201d) features that these properties give rise to. The shape of an object is a <b>modality</b>-independent intrinsic property ...", "dateLastCrawled": "2021-08-02T15:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Impact of distance education on academic performance in a ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5383158/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5383158", "snippet": "The distance <b>modality</b> took place in the Moodle platform, where didactic materials and <b>learning</b> <b>objects</b> were posted, as well as the activities were accomplishmed. It was also offered in each class the possibility of solving doubts via asynchronous forum. The face-to-face <b>modality</b> was held in the classroom or in a <b>computer</b> lab, as needed. The face-to-face classes also had the teaching materials available on the Moodle platform. Both in the distance and in the classroom, written texts and ...", "dateLastCrawled": "2022-01-30T20:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Cross-Modal Collaborative Representation <b>Learning</b> and a Large-Scale ...", "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Cross-Modal_Collaborative_Representation_Learning_and_a_Large-Scale_RGBT_Benchmark_for_CVPR_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Cross-Modal_Collaborative...", "snippet": "1School of <b>Computer</b> Science and Engineering, Sun Yat-sen University, China 2Pazhou Lab, Guangzhou, ... and may fail to accurately <b>recognize</b> the semantic <b>objects</b> in unconstraint scenarios. For instance, as shown in Fig. 1-(a,b), pedestrians are almost invisible in poor illumination conditions (such as backlight and night) and they are hard to be directly detected from RGB images. Moreover, some human-shaped <b>objects</b> (e.g., tiny pillars and blurry traf\ufb01c lights ...", "dateLastCrawled": "2022-02-02T23:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) 38 <b>PERCEPTION Recognizing Patterns and Objects CHAPTER</b> OUTLINE ...", "url": "https://www.academia.edu/7921621/38_PERCEPTION_Recognizing_Patterns_and_Objects_CHAPTER_OUTLINE_Gestalt_Approaches_to", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/7921621/38_<b>PERCEPTION_Recognizing_Patterns_and_Objects</b>...", "snippet": "The deficit seems <b>modality</b> specific: Patients with visual agnosia can\u2019t <b>recognize</b> <b>objects</b> by sight but may be able to <b>recognize</b> them by sound, touch, or smell. Put in our earlier terms, the problem seems to lie in creating a percept from the proximal stimulus. Researchers classify visual agnosias into different types. The first is called apperceptive agnosia. Patients with this disorder seem able to process a very limited amount of visual information. They can see the contours, or outlines ...", "dateLastCrawled": "2022-01-29T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Label Image Data for <b>Machine Learning</b> and Deep <b>Learning</b> Training ...", "url": "https://becominghuman.ai/how-to-label-image-data-for-machine-learning-and-deep-learning-training-414686d0d1ee", "isFamilyFriendly": true, "displayUrl": "https://becominghuman.ai/how-to-label-image-data-for-<b>machine-learning</b>-and-deep...", "snippet": "If you are looking to annotate the images, for deep <b>learning</b>, you need to choose the image annotation techniques <b>like</b> semantic segmentation annotation that provides a better and in-depth detection of images to <b>recognize</b> the object of interest with better accuracy. Image labeling for deep <b>learning</b> need extra precautions and accuracy which can be done only by professionals for best results.", "dateLastCrawled": "2022-01-30T21:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Learning to Recognize Objects from Unseen Modalities</b>", "url": "https://www.researchgate.net/publication/221305118_Learning_to_Recognize_Objects_from_Unseen_Modalities", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221305118_<b>Learning_to_Recognize_Objects_from</b>...", "snippet": "<b>Learning to Recognize Objects from Unseen Mo dalities</b> 13 4.4 Using unlabeled images for sense disambiguation in text W e now consider the problem of exploiting unlabeled images to disambiguate the", "dateLastCrawled": "2021-10-19T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Artistic Object Recognition by Unsupervised Style Adaptation", "url": "https://people.cs.pitt.edu/~chris/artistic_objects/accv2018.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.pitt.edu/~chris/artistic_<b>objects</b>/accv2018.pdf", "snippet": "<b>Computer</b> vision systems currently lack the ability to reli-ably <b>recognize</b> artistically rendered <b>objects</b>, especially when such data is limited. In this paper, we propose a method for recognizing <b>objects</b> in artistic modalities (such as paintings, cartoons, or sketches), without requiring any labeled data from those modalities. Our method explicitly accounts for stylistic domain shifts between and within domains. To do so, we introduce a complementary training <b>modality</b> constructed to be <b>similar</b> ...", "dateLastCrawled": "2021-11-05T03:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> to learn: From within-<b>modality</b> to cross-<b>modality</b> transfer ...", "url": "https://europepmc.org/articles/PMC3142657", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/articles/PMC3142657", "snippet": "<b>Learning</b> to learn: From within-<b>modality</b> to cross-<b>modality</b> transfer during infancy. ... (more experienced word learners) exhibited evidence of generalization \u2013 they also applied the learned word to <b>similar</b> <b>objects</b>. Furthermore, Smith (2003) demonstrated that previous experience with category <b>learning</b> is a predictor of whether 20-month-olds <b>recognize</b> an abstract caricature of a concrete object. These studies indicate that breadth of generalization (and transfer of <b>learning</b>) increases in the ...", "dateLastCrawled": "2022-01-15T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Train Image <b>Recognition</b> AI with 5 lines of code | by Moses Olafenwa ...", "url": "https://towardsdatascience.com/train-image-recognition-ai-with-5-lines-of-code-8ed0bdd8d9ba", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/train-image-<b>recognition</b>-ai-with-5-lines-of-code-8ed0bdd...", "snippet": "Then, in the 1990s, the concept of Machine <b>Learning</b> was introduced and it ushered in an era in which instead of telling computers what to look out for in recognizing scenes and <b>objects</b> in images and videos, we can instead design algorithms that will make computers to learn <b>how to recognize</b> scenes and <b>objects</b> in images by itself, just like a child learns to understand his/her environment by exploring. Machine <b>learning</b> opened the way for computers to learn to <b>recognize</b> almost any scene or ...", "dateLastCrawled": "2022-02-02T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning multisensory representations for auditory-visual transfer</b> of ...", "url": "https://link.springer.com/article/10.3758/s13423-014-0734-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.3758/s13423-014-0734-y", "snippet": "If a person is trained to <b>recognize</b> or categorize <b>objects</b> or events using one sensory <b>modality</b>, the person can often <b>recognize</b> or categorize those same (or <b>similar</b>) <b>objects</b> and events via a novel <b>modality</b>. This phenomenon is an instance of cross-modal transfer of knowledge. Here, we study the Multisensory Hypothesis which states that people extract the intrinsic, <b>modality</b>-independent properties of <b>objects</b> and events, and represent these properties in multisensory representations. These ...", "dateLastCrawled": "2021-10-10T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Google Uses AI to Identify People</b> and <b>Objects</b>", "url": "https://www.bayometric.com/google-uses-ai-to-identify-people-objects/", "isFamilyFriendly": true, "displayUrl": "https://www.bayometric.com/<b>google-uses-ai-to-identify-people</b>-<b>objects</b>", "snippet": "These products leverage Google\u2019s expertise in machine <b>learning</b> and cloud processing to <b>recognize</b> people, places, <b>objects</b> and animals. Launched in May 2015, Google Photos is one of such products that comes equipped with AI powered recognition and image analysis capabilities. It is a photo sharing and storage service available as a browser and smartphone app. Google Photos may look like just another photo sharing app but it has a lot going under the hood. It can analyse images and ...", "dateLastCrawled": "2022-01-14T21:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning</b> <b>Modality</b>-Invariant Representations for Speech and Images", "url": "https://groups.csail.mit.edu/sls/publications/2017/ASRU17_Leidal.pdf", "isFamilyFriendly": true, "displayUrl": "https://groups.csail.mit.edu/sls/publications/2017/ASRU17_Leidal.pdf", "snippet": "run on the raw audio waveform from the video to <b>recognize</b> the same information. In Aytar et al.&#39;s model, the shared semantic space consists of the two distributions over <b>objects</b> and scenes as opposed to being an arbitrary (yet highly lin-early correlated) semantic space, as is the case in our model. Wang et al. [3] gave a comprehensive overview of existing approaches to another practical application of shared seman-tic spaces: cross-<b>modality</b> information retrieval. The task is formulated as ...", "dateLastCrawled": "2021-02-16T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Learning</b> to learn: From within-<b>modality</b> to cross-<b>modality</b> transfer ...", "url": "https://www.sciencedirect.com/science/article/pii/S0022096511001305", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0022096511001305", "snippet": "One critical aspect of <b>learning</b> is the ability to apply learned knowledge to new situations. This ability to transfer is often limited, and its develo\u2026", "dateLastCrawled": "2021-12-12T09:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Learning</b> to Order <b>Objects</b> Using Haptic and Proprioceptive Exploratory ...", "url": "https://www.ijcai.org/Proceedings/16/Papers/489.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/Proceedings/16/Papers/489.pdf", "snippet": "in terms of how <b>similar</b> they are to the orders dis-covered during the unsupervised stage. Finally, the grounded models were used to <b>recognize</b> whether new object series were ordered by any of the three properties as well as to correctly insert additional <b>objects</b> into an existing series. 1 INTRODUCTION The ability to order physical <b>objects</b> by various properties emerges early in childhood development and is thought to be fundamental for understanding the property of numbers [Kingma and ...", "dateLastCrawled": "2021-12-09T12:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Label Image Data for <b>Machine Learning</b> and Deep <b>Learning</b> Training ...", "url": "https://becominghuman.ai/how-to-label-image-data-for-machine-learning-and-deep-learning-training-414686d0d1ee", "isFamilyFriendly": true, "displayUrl": "https://becominghuman.ai/how-to-label-image-data-for-<b>machine-learning</b>-and-deep...", "snippet": "If you are looking to annotate the images, for deep <b>learning</b>, you need to choose the image annotation techniques like semantic segmentation annotation that provides a better and in-depth detection of images to <b>recognize</b> the object of interest with better accuracy. Image labeling for deep <b>learning</b> need extra precautions and accuracy which can be done only by professionals for best results.", "dateLastCrawled": "2022-01-30T21:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "From Sensory Signals to <b>Modality</b>-Independent Conceptual Representations ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640543/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4640543", "snippet": "For instance, people might use <b>modality</b>-specific representations of <b>objects</b> as a foundation for inferring <b>modality</b>-independent representations characterizing <b>objects</b>\u2019 intrinsic properties. To understand the nature of the latter representations, it is important to <b>recognize</b> the distinction between <b>objects</b>\u2019 intrinsic (or \u201cdeep\u201d) properties and the sensory (or \u201csurface\u201d) features that these properties give rise to. The shape of an object is a <b>modality</b>-independent intrinsic property ...", "dateLastCrawled": "2021-08-02T15:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Impact of distance education on academic performance in a ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5383158/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5383158", "snippet": "The distance <b>modality</b> took place in the Moodle platform, where didactic materials and <b>learning</b> <b>objects</b> were posted, as well as the activities were accomplishmed. It was also offered in each class the possibility of solving doubts via asynchronous forum. The face-to-face <b>modality</b> was held in the classroom or in a <b>computer</b> lab, as needed. The face-to-face classes also had the teaching materials available on the Moodle platform. Both in the distance and in the classroom, written texts and ...", "dateLastCrawled": "2022-01-30T20:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> to Order <b>Objects</b> Using Haptic and Proprioceptive Exploratory ...", "url": "https://www.cs.utexas.edu/~jsinapov/papers/jsinapov_ijcai2016.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.utexas.edu/~jsinapov/papers/jsinapov_ijcai2016.pdf", "snippet": "supervised <b>learning</b> to discover how <b>objects</b> <b>can</b> be ordered using multiple and different types of sensorimotor features that the robot detects during object exploration. Next, the robot undergoes a supervised <b>learning</b> stage during which it is trained that speci\ufb01c example object orders are associated with speci\ufb01c object properties, namely \u201cheight\u201d, \u201cwidth\u201d, and \u201cweight\u201d. More speci\ufb01cally, the robot learns how the three ordinal concepts relate to the object orders discovered ...", "dateLastCrawled": "2021-05-20T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Learning</b> to Order <b>Objects</b> Using Haptic and Proprioceptive Exploratory ...", "url": "https://www.ijcai.org/Proceedings/16/Papers/489.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/Proceedings/16/Papers/489.pdf", "snippet": "grounded models were used to <b>recognize</b> whether new object series were ordered by any of the three properties as well as to correctly insert additional <b>objects</b> into an existing series. 1 INTRODUCTION The ability to order physical <b>objects</b> by various properties emerges early in childhood development and is <b>thought</b> to be fundamental for understanding the property of numbers [Kingma and Reuvekamp, 1984]. In the Montessori method of teaching [Montessori, 1917], children solve ordering tasks using ...", "dateLastCrawled": "2021-12-09T12:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Creating AI By Using Brain Theory | by John Ball | Pat Inc | Medium", "url": "https://medium.com/pat-inc/creating-ai-by-using-brain-theory-56fe48ce77aa", "isFamilyFriendly": true, "displayUrl": "https://medium.com/pat-inc/creating-ai-by-using-brain-theory-56fe48ce77aa", "snippet": "Brains <b>recognize</b> things (pattern matching), and <b>can</b> then produce motion as a response (pattern use, such as moving or speaking). Recognition requires (a) the storage of the pattern and (b) the ...", "dateLastCrawled": "2022-01-10T12:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning multisensory representations for auditory-visual transfer</b> of ...", "url": "https://link.springer.com/article/10.3758/s13423-014-0734-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.3758/s13423-014-0734-y", "snippet": "If a person is trained to <b>recognize</b> or categorize <b>objects</b> or events using one sensory <b>modality</b>, the person <b>can</b> often <b>recognize</b> or categorize those same (or similar) <b>objects</b> and events via a novel <b>modality</b>. This phenomenon is an instance of cross-modal transfer of knowledge. Here, we study the Multisensory Hypothesis which states that people extract the intrinsic, <b>modality</b>-independent properties of <b>objects</b> and events, and represent these properties in multisensory representations. These ...", "dateLastCrawled": "2021-10-10T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Perceptual System</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/perceptual-system", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/<b>computer</b>-science/<b>perceptual-system</b>", "snippet": "A sufficiently salient stimulus in any <b>modality</b> <b>can</b> supercede the robot&#39;s attention, just as a human watching a film might respond to sudden motion in the adjacent seat. MIT has implemented a number of intuitive arbitration rules into the system such as the fact that, all else being equal, larger <b>objects</b> are considered more salient than smaller ones. The goal is for the robot to be responsive to unexpected events, but also able to filter out superfluous ones. Otherwise the robot would become ...", "dateLastCrawled": "2022-01-19T17:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Learning to Recognize Objects</b> | Request PDF", "url": "https://www.researchgate.net/publication/10764144_Learning_to_Recognize_Objects", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/10764144_<b>Learning_to_Recognize_Objects</b>", "snippet": "For example, children show a &quot;shape bias&quot; in <b>learning</b> object labels (Landau, Smith, &amp; Jones, 1988) and, as they learn more object categories, they use shape to <b>recognize</b> stylized three-dimensional ...", "dateLastCrawled": "2021-11-27T01:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Learning</b> to <b>recognize objects in egocentric activitie</b> | Request PDF", "url": "https://www.researchgate.net/publication/224254805_Learning_to_recognize_objects_in_egocentric_activitie", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/224254805_<b>Learning</b>_to_<b>recognize</b>_<b>objects</b>_in...", "snippet": "Detecting small <b>objects</b> in video streams of head-worn augmented reality devices in near real-time is a huge challenge: training data is typically scarce, the input video stream <b>can</b> be of limited ...", "dateLastCrawled": "2021-10-24T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Chapter 5 Flashcards - <b>Learning</b> tools &amp; flashcards, for free | <b>Quizlet</b>", "url": "https://quizlet.com/525880302/psych-2410-chapter-5-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/525880302/<b>psych-2410-chapter-5</b>-flash-cards", "snippet": "By what age is an infant typically able to <b>recognize</b> visually which of two <b>objects</b> she just explored manually? 4 months. In Olivier Pascalis&#39;s study on infants&#39; formation of face prototypes, he found that 6-month-olds discriminated among monkey faces just as well as they discriminated among human faces. This finding suggests that- at 6 months of age, infants have yet to develop a well-organized prototype for human faces. As discussed in the text, 3- to 4-month-olds look longer at visual ...", "dateLastCrawled": "2021-02-21T23:31:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Learning to Recognize Objects from Unseen Modalities</b>", "url": "https://www.researchgate.net/publication/221305118_Learning_to_Recognize_Objects_from_Unseen_Modalities", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221305118_<b>Learning_to_Recognize_Objects_from</b>...", "snippet": "<b>Learning to Recognize Objects from Unseen Mo dalities</b> 13 4.4 Using unlabeled images for sense disambiguation in text W e now consider the problem of exploiting unlabeled images to disambiguate the", "dateLastCrawled": "2021-10-19T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Self-Supervised Feature <b>Learning</b> by Cross-<b>Modality</b> and Cross-View ...", "url": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Jing_Self-Supervised_Feature_Learning_by_Cross-Modality_and_Cross-View_Correspondences_CVPRW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Jing_Self-Supervised...", "snippet": "cilitate 3D <b>computer</b> vision research, more and more 3D datasets such as mesh and point cloud data have been re-cently proposed. <b>Compared</b> to the annotation process of 2D image data, 3D point cloud data are especially harder to an-notate and the cost is more expensive. To learn features from unlabeled data, many self-/un-supervised <b>learning</b> methods are proposed for images, videos [11,18,24], and 3D point cloud data [13] by train-ing deep neural networks to solve pretext tasks with au ...", "dateLastCrawled": "2022-01-25T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> <b>Modality</b>-Invariant Representations for Speech and Images", "url": "https://groups.csail.mit.edu/sls/publications/2017/ASRU17_Leidal.pdf", "isFamilyFriendly": true, "displayUrl": "https://groups.csail.mit.edu/sls/publications/2017/ASRU17_Leidal.pdf", "snippet": "<b>LEARNING</b> <b>MODALITY</b>-INVARIANT REPRESENTATIONS FOR SPEECH AND IMAGES Kenneth Leidal, David Harwath, James Glass <b>Computer</b> Science and Articial Intelligence Laboratory Massachusetts Institute of Technology Cambridge, MA 02139, USA fkkleidal, dharwath, glass g@mit.edu ABSTRACT In this paper, we explore the unsupervised <b>learning</b> of a se-mantic embedding space for co-occurring sensory inputs. Specically, we focus on the task of <b>learning</b> a semantic vec-tor space for both spoken and handwritten digits ...", "dateLastCrawled": "2021-02-16T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "From Sensory Signals to <b>Modality</b>-Independent Conceptual Representations ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640543/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4640543", "snippet": "For instance, people might use <b>modality</b>-specific representations of <b>objects</b> as a foundation for inferring <b>modality</b>-independent representations characterizing <b>objects</b>\u2019 intrinsic properties. To understand the nature of the latter representations, it is important to <b>recognize</b> the distinction between <b>objects</b>\u2019 intrinsic (or \u201cdeep\u201d) properties and the sensory (or \u201csurface\u201d) features that these properties give rise to. The shape of an object is a <b>modality</b>-independent intrinsic property ...", "dateLastCrawled": "2021-08-02T15:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Impact of distance education on academic performance in a ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5383158/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5383158", "snippet": "The distance <b>modality</b> took place in the Moodle platform, where didactic materials and <b>learning</b> <b>objects</b> were posted, as well as the activities were accomplishmed. It was also offered in each class the possibility of solving doubts via asynchronous forum. The face-to-face <b>modality</b> was held in the classroom or in a <b>computer</b> lab, as needed. The face-to-face classes also had the teaching materials available on the Moodle platform. Both in the distance and in the classroom, written texts and ...", "dateLastCrawled": "2022-01-30T20:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Computer</b> Vision: Self-Driving Car Perception in a Nutshell | by ...", "url": "https://medium.com/self-driving-cars/computer-vision-self-driving-car-perception-in-a-nutshell-43b1820b6b04", "isFamilyFriendly": true, "displayUrl": "https://medium.com/self-driving-cars/<b>computer</b>-vision-self-driving-car-perception-in-a...", "snippet": "Image preprocessing is crucial for increasing <b>learning</b> rate so we <b>can</b> detect <b>objects</b> faster and more accurately. Extracted features, like size of a truck and number of wheels in a motorbike, help ...", "dateLastCrawled": "2022-01-28T00:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) 38 <b>PERCEPTION Recognizing Patterns and Objects CHAPTER</b> OUTLINE ...", "url": "https://www.academia.edu/7921621/38_PERCEPTION_Recognizing_Patterns_and_Objects_CHAPTER_OUTLINE_Gestalt_Approaches_to", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/7921621/38_<b>PERCEPTION_Recognizing_Patterns_and_Objects</b>...", "snippet": "The deficit seems <b>modality</b> specific: Patients with visual agnosia <b>can</b>\u2019t <b>recognize</b> <b>objects</b> by sight but may be able to <b>recognize</b> them by sound, touch, or smell. Put in our earlier terms, the problem seems to lie in creating a percept from the proximal stimulus. Researchers classify visual agnosias into different types. The first is called apperceptive agnosia. Patients with this disorder seem able to process a very limited amount of visual information. They <b>can</b> see the contours, or outlines ...", "dateLastCrawled": "2022-01-29T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Ultimate Guide to Image Annotation [Tools + Datasets]", "url": "https://www.v7labs.com/blog/image-annotation-guide", "isFamilyFriendly": true, "displayUrl": "https://www.v7labs.com/blog/image-annotation-guide", "snippet": "And if you are trying to build reliable <b>computer</b> vision models to detect, <b>recognize</b>, and classify <b>objects</b>, the data you use to feed the <b>learning</b> algorithms must be accurately labeled. And here comes the bad news\u2014 Image annotation is a whole lot more nuanced than most people realize. And annotating your image data incorrectly <b>can</b> be expensive. Very expensive. Luckily, you&#39;ve come to the right place. In the next few minutes, we&#39;ll explain to you the ins and outs of image annotation and walk ...", "dateLastCrawled": "2022-01-30T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Learn to Recognize</b> | <b>Shadi Albarqouni</b>", "url": "https://albarqouni.github.io/project/learn-to-recognize/", "isFamilyFriendly": true, "displayUrl": "https://albarqouni.github.io/project/<b>learn-to-recognize</b>", "snippet": "It provides additional information that, when <b>compared</b> to the information available from conventional CT datasets, has the potential to benefit existing <b>computer</b> vision techniques by improving their accuracy and reliability. In order to evaluate the additional value of spectral versus conventional datasets when being used as input for machine <b>learning</b> algorithms, we implemented a weakly-supervised Convolutional Neural Network (CNN) that learns liver lesion localization and classification ...", "dateLastCrawled": "2021-12-22T21:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Activity recognition in manufacturing: The roles of ... - <b>Computer</b> Science", "url": "https://cseweb.ucsd.edu/~lriek/papers/kubtoa-iqbal-shah-riek-ICRA19.pdf", "isFamilyFriendly": true, "displayUrl": "https://cseweb.ucsd.edu/~lriek/papers/kubtoa-iqbal-shah-riek-ICRA19.pdf", "snippet": "Thus, robots <b>can</b> <b>recognize</b> gross motion daily living activities, such as walking or lifting items, with accuracies of as high as 99% [9], [13], [15], [33]. Research reported in this paper is supported by the National Science Foundation under Grant Nos. IIS-1724982 and IIS-1734482. 1Computer Science and Engineering, UC San Diego, La Jolla, CA 92093, USA (email: fakubota, lriekg@eng.ucsd.edu) 2Computer Science and Arti\ufb01cial Intelligence Lab, Massachusetts Insti-tute of Technology, 32 Vassar ...", "dateLastCrawled": "2022-01-31T01:41:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Types of Machine Learning</b> | Different Methods and Kinds of Model", "url": "https://www.educba.com/types-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>types-of-machine-learning</b>", "snippet": "<b>Machine</b> <b>learning</b> is further classified as Supervised, Unsupervised, Reinforcement, and Semi-Supervised <b>Learning</b> algorithms; all these types of <b>learning</b> techniques are used in different applications. What is <b>Machine</b> <b>Learning</b>? <b>Machine</b> <b>learning</b> is a small application area of Artificial Intelligence in which machines automatically learn from the operations and finesse themselves to give better output. Based on the data collected, the machines improve the computer programs aligning with the ...", "dateLastCrawled": "2022-02-02T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Machine</b> <b>Learning</b> and Theological Traditions of <b>Analogy</b>", "url": "https://www.researchgate.net/publication/349470559_Machine_Learning_and_Theological_Traditions_of_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/349470559_<b>Machine</b>_<b>Learning</b>_and_Theological...", "snippet": "theories of <b>analogy</b> to <b>machine</b> <b>learning</b> has brought us here, since much of it was developed, in the first place, in thinking about the use of shared vocabulary for creature and creator.", "dateLastCrawled": "2021-11-04T23:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> and Theological Traditions of <b>Analogy</b> - Davison - 2021 ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "snippet": "12 <b>Machine</b> <b>Learning</b>, <b>Analogy</b>, and God. The texts considered in this article come from theological sources. They have offered ways to think analogically about features of the world, in this case the similarities we are beginning to see between capacities in <b>machine</b> <b>learning</b> and those in human beings and other animals. Much of the mediaeval ...", "dateLastCrawled": "2021-04-16T10:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Modality and representation in analogy</b> | AI EDAM | Cambridge Core", "url": "https://www.cambridge.org/core/journals/ai-edam/article/modality-and-representation-in-analogy/F567723948DE2E845EDF1E048C87D9EF", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/ai-edam/article/<b>modality</b>-and-representation-in...", "snippet": "A deeper understanding of the cognitive mechanisms underlying design and <b>analogy</b> is a crucial step in developing these tools. This paper presents an experiment that explores the effects of representation within the <b>modality</b> of sketching, the effects of functional models, and the retrieval and use of analogies.", "dateLastCrawled": "2022-01-19T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Effects of <b>Analogical Learning Approaches and Presentation Modalities</b> ...", "url": "https://link.springer.com/article/10.1007/s10956-020-09835-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10956-020-09835-7", "snippet": "Regardless of being in the <b>analogy</b> or metaphor group, the students who learned with the picture <b>modality</b> allocated greater TMD than those learned with the text <b>modality</b> (Fig. 4). The results also showed that students <b>learning</b> with the textual analogies not only provided more frequent mapping behaviors and longer mapping durations but also built more complete relationships between the water wheel system and the electric circuit system than those <b>learning</b> with the textual metaphors.", "dateLastCrawled": "2022-01-06T22:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Modality</b> and representation in <b>analogy</b>", "url": "https://www.researchgate.net/publication/231787416_Modality_and_representation_in_analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/231787416_<b>Modality</b>_and_representation_in_<b>analogy</b>", "snippet": "cognitive mechanisms underlying design and <b>analogy</b> is a crucial step in developing these. tools. This paper presents an experiment that explores the effects of representation within the. <b>modality</b> ...", "dateLastCrawled": "2022-01-19T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Modality and representation in analogy</b> | Julie Linsey - Academia.edu", "url": "https://www.academia.edu/2838157/Modality_and_representation_in_analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2838157/<b>Modality_and_representation_in_analogy</b>", "snippet": "(a) The percentage of participants with a solution based on the target analogous product at each phase for design problem 1, and (b) 1215 the percentage of participants who had a solution based on the target analogous product and also identified the <b>analogy</b> at each phase for 1155 1216 design problem 1. 1156 1217 1157 1218 1158 1219 1159 1220 <b>Modality and representation in analogy</b> 95 1221 1282 1222 1283 1223 1284 1224 1285 1225", "dateLastCrawled": "2021-09-07T15:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "About generalization, abstraction and analogies | by Tudor Surdoiu ...", "url": "https://dacus-augustus.medium.com/about-generalization-abstraction-and-analogies-e59aa16e7871", "isFamilyFriendly": true, "displayUrl": "https://dacus-augustus.medium.com/about-generalization-abstraction-and-analogies-e59aa...", "snippet": "A presentation of essential cognition concepts inspired by the book Deep <b>Learning</b> with Python, second edition by Fran\u00e7ois Chollet. The pursuit of better generalization is probably the underlining\u2026 Get started. Open in app. Tudor Surdoiu. Sign in. Get started. Follow. 78 Followers. About. Get started. Open in app. About generalization, abstraction and analogies. Tudor Surdoiu. Just now \u00b7 4 min read. A presentation of essential cognition concepts inspired by the book Deep <b>Learning</b> with ...", "dateLastCrawled": "2022-01-30T15:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Analogical mapping across sensory modalities and evidence for a general ...", "url": "https://www.sciencedirect.com/science/article/pii/S0010027722000178", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0010027722000178", "snippet": "Example within-<b>modality</b> and cross-<b>modality</b> <b>analogy</b> trials. All <b>analogy</b> trials were of the form, \u201cA is to B as C is to D.\u201d Participants were instructed to indicate by button press whether each <b>analogy</b> was True or False. For example, in the True lines-to-sounds trial depicted in the figure, both the line analog (A-B) and sound analog (CD) were devised to convey the relation of paired elements (A: paired visual elements of an image; C: paired notes of a two-note chord) to a feature that ...", "dateLastCrawled": "2022-01-26T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Deep <b>Learning Models for Human Activity Recognition</b>", "url": "https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/deep-<b>learning-models-for-human-activity-recognition</b>", "snippet": "Statistical and <b>machine</b> <b>learning</b> models were then trained on the processed version of the data. A limitation of this approach is the signal processing and domain expertise required to analyze the raw data and engineer the features required to fit a model. This expertise would be required for each new dataset or sensor <b>modality</b>. In essence, it is expensive and not scalable. However, in most daily HAR tasks, those methods may heavily rely on heuristic handcrafted feature extraction, which is ...", "dateLastCrawled": "2022-02-02T16:15:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How Electrical Stimulation Is Used in Physical Therapy", "url": "https://www.verywellhealth.com/electrical-stimulation-2696122", "isFamilyFriendly": true, "displayUrl": "https://www.verywellhealth.com/electrical-stimulation-2696122", "snippet": "<b>Learning</b> the right movements and exercises for your specific condition is extremely important. Some professionals debate whether e-stim is something of value in physical therapy. And some research shows that electrical stim doesn&#39;t help injured people very much. Other research indicates that some types of stimulation can be useful. Despite the ongoing debate on whether e-stim truly helps, you may encounter it if you go to physical therapy. So knowing what it is and what to expect can be ...", "dateLastCrawled": "2022-02-02T07:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Ensemble of deep convolutional neural networks based</b> multi\u2010modality ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2019.0617", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2019.0617", "snippet": "In the last decades, pattern recognition and <b>machine</b> <b>learning</b> methods have been widely used in brain disease diagnosis, which extracts different kinds of the features from neuroimaging modalities to learn a model and predict class labels on an unknown object. In general, these feature extraction methods can be summarised into four categories: voxel-based morphometry (VBM) approach, region of interest (ROI)-based approach, patch-based approach and landmark-based approach. The VBM approach is ...", "dateLastCrawled": "2022-02-01T16:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Partnership - <b>Standigm</b> - <b>Standigm</b>", "url": "https://www.standigm.com/partnership/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>standigm</b>.com/partnership", "snippet": "*GPN (Graph Point Network) : A deep <b>learning</b> architecture that can use both graph-based 2d structural information and 3d information expressed by point net technique *Monet (Moiety based molecular Networks) : Proprietary deep <b>learning</b> model, which learns both whole structure and substructure, used to enumerate various derivative compounds from a seed molecule *NoSH (Novel Scaffold Hopping) : Module for scaffold hopping focused on novelty *IDEA-STAR : STAR is our proprietary <b>machine</b> <b>learning</b> ...", "dateLastCrawled": "2022-02-02T22:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Action science: Foundations of an emerging discipline | Request PDF", "url": "https://www.researchgate.net/publication/236625110_Action_science_Foundations_of_an_emerging_discipline", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/236625110_Action_science_Foundations_of_an...", "snippet": "Over the past decade, embodied cognition has become an influential paradigm in music research. Embodied music cognition is representative of the so-called &quot;pragmatic turn in cognitive science ...", "dateLastCrawled": "2022-01-06T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Datives and Other Cases</b> | LAURISRAEL ADOU - Academia.edu", "url": "https://www.academia.edu/38665770/Datives_and_Other_Cases", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/38665770", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-27T11:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Schellings Naturalism</b> | German Idealism | Georg Wilhelm Friedrich Hegel", "url": "https://www.scribd.com/document/386463765/Schellings-Naturalism", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/386463765/<b>Schellings-Naturalism</b>", "snippet": "up as a form of categorization at worst, and, as a simultaneously exploratory, and simplifying <b>machine</b>. of reason, at best.31 While I believe this view potentially sells Kant&#39;s notion of judgment short, it is. somewhat easy to see the troubling legislative aspect of Kant&#39;s transcendental conditions as they apply . 31 I will take up this issue in the following chapter in relationship to Kant&#39;s \u201cWhat is Called Orientation in Thinking?\u201d 30 to nature. In The Critique of the Power of Judgment ...", "dateLastCrawled": "2022-02-02T21:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Defining <b>Next-Generation Multi-Modal Communication in</b> Human Robot ...", "url": "https://www.researchgate.net/publication/273346003_Defining_Next-Generation_Multi-Modal_Communication_in_Human_Robot_Interaction", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/273346003_Defining_Next-Generation_Multi...", "snippet": "Alternatively, robotic <b>learning</b> techniques such as: gradual mutual adaptation (Ikemoto et al. 2012;Peternel et al. 2016a), reinforcement <b>learning</b> Palunko et al. (2014) or <b>learning</b> from ...", "dateLastCrawled": "2021-10-21T00:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Towards a typology of meaningful signals and</b> cues in social robotics", "url": "https://www.researchgate.net/publication/224256262_Towards_a_typology_of_meaningful_signals_and_cues_in_social_robotics", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/224256262_<b>Towards_a_typology_of_meaningful</b>...", "snippet": "Typologies and taxonomies have been proposed to classify signs and cues for HRI and conversational agents. For instance, Hegel et al. [43] propose a typology of signals and cues in HRI, and ...", "dateLastCrawled": "2021-10-19T19:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) [Wolf-Andreas Liebert, Gisela Redeker and Linda R 1997 Discourse ...", "url": "https://www.academia.edu/34526397/_Wolf_Andreas_Liebert_Gisela_Redeker_and_Linda_R_1997_Discourse_and_Perspectives_in_Cognitive_Linguistics", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/34526397/_Wolf_Andreas_Liebert_Gisela_Redeker_and_Linda_R...", "snippet": "[Wolf-Andreas Liebert, Gisela Redeker and Linda R 1997 Discourse and Perspectives in Cognitive Linguistics", "dateLastCrawled": "2022-02-03T13:59:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(modality)  is like +(computer learning how to recognize objects)", "+(modality) is similar to +(computer learning how to recognize objects)", "+(modality) can be thought of as +(computer learning how to recognize objects)", "+(modality) can be compared to +(computer learning how to recognize objects)", "machine learning +(modality AND analogy)", "machine learning +(\"modality is like\")", "machine learning +(\"modality is similar\")", "machine learning +(\"just as modality\")", "machine learning +(\"modality can be thought of as\")", "machine learning +(\"modality can be compared to\")"]}