{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Ethics, Fairness</b>, and <b>Bias</b> in AI - KDnuggets", "url": "https://www.kdnuggets.com/2021/06/ethics-fairness-ai.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2021/06/<b>ethics-fairness</b>-ai.html", "snippet": "<b>Bias</b> generated due to the <b>algorithm</b>. Popularity <b>Bias</b>: Most of the recommender systems suffer from this <b>bias</b> [5], i.e., the most popular items are recommended frequently, but less popular items are recommended rarely by the recommendation <b>algorithm</b>. However, for businesses, recommending rarely bought items is very important as they are less likely to be discovered. <b>Biases</b> due to user interactions. Behavioural <b>Bias</b>: A bank trained a model to predict the ability of the applicant to repay the ...", "dateLastCrawled": "2022-01-31T19:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias</b> and Discrimination in AI: A Cross-Disciplinary Perspective - IEEE ...", "url": "https://technologyandsociety.org/bias-and-discrimination-in-ai-a-cross-disciplinary-perspective/", "isFamilyFriendly": true, "displayUrl": "https://technologyandsociety.org/<b>bias</b>-and-discrimination-in-ai-a-cross-disciplinary...", "snippet": "We can distinguish between two general approaches to measure <b>bias</b>: 1) procedural approaches, which focus on identifying <b>biases</b> in the decision-making the process <b>of an algorithm</b> [6] and 2) relational approaches, which focus on identifying (and preventing) biased decisions in the data set or algorithmic output. Although ensuring unbiased outcomes is useful to attest whether a specific <b>algorithm</b> has a discriminatory impact on a population, focusing on the algorithmic process itself can help ...", "dateLastCrawled": "2022-01-30T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A <b>Tutorial to AI Ethics - Fairness, Bias &amp; Perception</b>", "url": "https://www.slideshare.net/KimKyllesbechLarsen/a-tutorial-to-ai-ethics-fairness-bias-perception", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/KimKyllesbechLarsen/a-<b>tutorial-to-ai-ethics-fairness</b>-<b>bias</b>...", "snippet": "Cognitive <b>biases</b> Statistical <b>bias</b> Contextual <b>biases</b> <b>Bias</b> is a disproportionate weight in favor of or against one thing, person, or group compared with another, usually in a way considered to be unfair. \u212cO MO = E MO \u2212 O O: Observation. M: Model estimator of observation O. E: Expected value (long-run average) B: <b>Bias</b> of model of O relative to O. Hundreds of cognitive <b>biases</b>, e.g., Anchoring, Aavailability, Confirmation <b>bias</b>, Belief <b>bias</b>, framing effect, etc\u2026 (See: https://en.wikipedia ...", "dateLastCrawled": "2022-02-02T01:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Machine Learning Glossary: <b>Fairness</b> | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/fairness", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/glossary/<b>fairness</b>", "snippet": "<b>bias</b> (<b>ethics/fairness</b>) #<b>fairness</b>. 1. Stereotyping, prejudice or favoritism towards some things, people, or groups over others. These <b>biases</b> can affect collection and interpretation of data, the design of a system, and how users interact with a system. Forms of this type of <b>bias</b> include: automation <b>bias</b>.", "dateLastCrawled": "2022-02-02T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Ethical</b> dilemmas of AI: fairness, transparency, collaboration, trust ...", "url": "https://uxdesign.cc/ethical-dilemmas-of-ai-fairness-transparency-human-machine-collaboration-trust-accountability-1fe9fc0ffff3", "isFamilyFriendly": true, "displayUrl": "https://uxdesign.cc/<b>ethical</b>-dilemmas-of-ai-fairness-transparency-human-machine...", "snippet": "In response to the problem, IBM, Facebook, Microsoft, and others all released \u201c<b>bias</b> busting\u201d tools earlier this year to expose and try to mitigate <b>bias</b> \u2014 sending more AI to fix AI \u2014 however, addressing <b>bias</b> requires more than a technological fix but an understanding of the underlying structural inequalities (Whittaker et al., 2018; United Nations, 2018). Whether explicit or implicit, <b>biases</b> are the symptom of a lack of diversity within the people who build the technology (Li, 2018 ...", "dateLastCrawled": "2022-01-26T09:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Sex and gender differences and <b>biases</b> in artificial intelligence for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7264169/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7264169", "snippet": "Desirable vs. undesirable <b>biases</b>. Despite the fact that the term \u201c<b>bias</b>\u201d has gained a negative connotation due to its association to unfair prejudice, the differential consideration and treatment to specific biomedical aspects is a necessary course of action in the context of Precision Medicine. Therefore, here we defined two main categories of sex and gender <b>biases</b>: desirable and undesirable (see Fig. Fig.2). 2). The difference between them is found in the impact that these <b>biases</b> have ...", "dateLastCrawled": "2022-01-30T00:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "seai/intro-<b>ethics-fairness</b>.md at S2021 \u00b7 ckaestne/seai \u00b7 GitHub", "url": "https://github.com/ckaestne/seai/blob/S2021/lectures/15_intro_ethics_fairness/intro-ethics-fairness.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ckaestne/seai/blob/S2021/lectures/15_intro_<b>ethics_fairness</b>/intro...", "snippet": "Should the <b>algorithm</b> reflect the reality? Note: &quot;An example of this type of <b>bias</b> can be found in a 2018 image search result where searching for women CEOs ultimately resulted in fewer female CEO images due to the fact that only 5% of Fortune 500 CEOs were woman\u2014which would cause the search results to be biased towards male CEOs.", "dateLastCrawled": "2021-08-29T22:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Ethical Implications of Bias in Machine</b> Learning", "url": "https://www.researchgate.net/publication/323378868_Ethical_Implications_of_Bias_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323378868_<b>Ethical_Implications_of_Bias_in</b>...", "snippet": "<b>Biases</b> in AI and machine learning algorithms are. presented and analyzed through two issues. management frameworks with the aim of showing h ow. ethical problems a nd dilemmas can evolve. While ...", "dateLastCrawled": "2022-01-16T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Cross Post: Biased Algorithms: Here&#39;s a More Radical Approach to ...", "url": "http://blog.practicalethics.ox.ac.uk/2019/01/cross-post-biased-algorithms-heres-a-more-radical-approach-to-creating-fairness/", "isFamilyFriendly": true, "displayUrl": "blog.practicalethics.ox.ac.uk/2019/01/cross-post-<b>bias</b>ed-<b>algorithms</b>-heres-a-more...", "snippet": "Aiming for substantive fairness outside of the <b>algorithm</b>\u2019s design would leave <b>algorithm</b> designers free to focus on maximising accuracy, with fairness left to state regulators, with expert and democratic input. This approach has been successful in other areas. In medicine, for instance, doctors focus on promoting the well-being of their patients while health funders and policymakers promote the fair allocation of healthcare resources across patients.", "dateLastCrawled": "2022-01-21T15:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The pros and cons of \u201cbig data\u201d lending decisions | You The Data", "url": "https://youthedata.com/2017/10/07/the-pros-and-cons-of-big-data-lending-decisions/", "isFamilyFriendly": true, "displayUrl": "https://youthedata.com/2017/10/07/the-pros-and-cons-of-big-data-lending-decisions", "snippet": "By this I mean to say, there is no way of knowing whether the data itself is already infused with <b>bias</b>, which consequently <b>biases</b> the predictions of the model. Much has been made of this issue within the domain of predictive policing, whereby a neighborhood which has been over zealously policed in the past is likely to have a high number of arrest records, which tells an unthinking <b>algorithm</b> to over-police it in the future, and so the cycle repeats\u2026 If poor data is being used to make ...", "dateLastCrawled": "2022-01-29T03:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Ethics, Fairness</b>, and <b>Bias</b> in AI - KDnuggets", "url": "https://www.kdnuggets.com/2021/06/ethics-fairness-ai.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2021/06/<b>ethics-fairness</b>-ai.html", "snippet": "<b>Bias</b> generated due to the <b>algorithm</b>. Popularity <b>Bias</b>: Most of the recommender systems suffer from this <b>bias</b> [5], i.e., the most popular items are recommended frequently, but less popular items are recommended rarely by the recommendation <b>algorithm</b>. However, for businesses, recommending rarely bought items is very important as they are less likely to be discovered. <b>Biases</b> due to user interactions. Behavioural <b>Bias</b>: A bank trained a model to predict the ability of the applicant to repay the ...", "dateLastCrawled": "2022-01-31T19:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Seven Types Of Data <b>Bias</b> In Machine Learning", "url": "https://www.telusinternational.com/articles/7-types-of-data-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.telusinternational.com/articles/7-types-of-data-<b>bias</b>-in-machine-learning", "snippet": "Recall <b>bias</b> arises when you label <b>similar</b> types of data inconsistently. This results in lower accuracy. For example, let\u2019s say you have a team labeling images of phones as damaged, partially-damaged, or undamaged. If someone labels one image as damaged, but a <b>similar</b> image as partially damaged, your data will be inconsistent. Observer <b>bias</b>: Also known as confirmation <b>bias</b>, observer <b>bias</b> is the effect of seeing what you expect to see or want to see in data. This can happen when researchers ...", "dateLastCrawled": "2022-02-03T11:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Machine Learning Glossary: <b>Fairness</b> | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/fairness", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/glossary/<b>fairness</b>", "snippet": "<b>bias</b> (<b>ethics/fairness</b>) #<b>fairness</b>. 1. Stereotyping, prejudice or favoritism towards some things, people, or groups over others. These <b>biases</b> can affect collection and interpretation of data, the design of a system, and how users interact with a system. Forms of this type of <b>bias</b> include: automation <b>bias</b>.", "dateLastCrawled": "2022-02-02T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Ethical <b>Bias</b> Meaning and <b>Similar</b> Products and Services List ...", "url": "https://www.listalternatives.com/ethical-bias-meaning", "isFamilyFriendly": true, "displayUrl": "https://www.listalternatives.com/ethical-<b>bias</b>-meaning", "snippet": "<b>Bias</b>. <b>Bias</b> is a prejudice toward one thing, person, or group compared with another. <b>Bias</b> is part of human evolutionary wiring designed to originally keep us safe and secure in unknown and harmful environments. However, while the world has evolved some of our <b>biases</b> - conscious or unconscious - have not, and thus can result in harmful ...", "dateLastCrawled": "2022-01-27T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Big Data <b>Ethics: Fairness</b> and Explainability Part 1", "url": "http://nobias.di.unipi.it/video/BDE.p1.pdf", "isFamilyFriendly": true, "displayUrl": "no<b>bias</b>.di.unipi.it/video/BDE.p1.pdf", "snippet": "<b>Biases</b>. N. Mehrabi et al. A Survey on <b>Bias</b> and Fairness in Machine Learning. (2019) A. Olteanu, C. Castillo, F. Diaz, E. Kiciman. Social Data: <b>Biases</b>, Methodological Pitfalls, and Ethical Boundaries. Frontiers Big Data 2: 13 (2019) Historical <b>bias</b> . is the already existing <b>bias</b> and socio-technical issues in the world", "dateLastCrawled": "2021-07-21T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Addressing <b>fairness</b> and inclusion in AI is an active area of research, from fostering an inclusive workforce that embodies critical and diverse knowledge, to assessing training datasets for potential sources of <b>bias</b>, to training models to remove or correct problematic <b>biases</b>, to evaluating machine learning models for disparities in performance, to continued testing of final systems for unfair outcomes. In fact, ML models can even be used to identify some of the conscious and unconscious ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Linguistics 575: Ethics in NLP</b> - <b>University of Washington</b>", "url": "https://faculty.washington.edu/ebender/2019_575/", "isFamilyFriendly": true, "displayUrl": "https://<b>faculty.washington.edu</b>/ebender/2019_575", "snippet": "What, if any, <b>bias</b> did the authors discover? What impacts do they describe following from that <b>bias</b>? What, if any, means of mitigating the <b>bias</b> do they authors propose? How are they evaluated? How do the scenarios described relate to the issue of using descriptive models prescriptively? 10/25: Term paper proposals due: 10/30: Language Variation and Emergent <b>Bias</b> Exclusion/Discrimination/<b>Bias</b> Read three papers total from the sections on Language Variation and Emergent <b>Bias</b> and Exclusion ...", "dateLastCrawled": "2022-01-29T04:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The pros and cons of \u201cbig data\u201d lending decisions | You The Data", "url": "https://youthedata.com/2017/10/07/the-pros-and-cons-of-big-data-lending-decisions/", "isFamilyFriendly": true, "displayUrl": "https://youthedata.com/2017/10/07/the-pros-and-cons-of-big-data-lending-decisions", "snippet": "By this I mean to say, there is no way of knowing whether the data itself is already infused with <b>bias</b>, which consequently <b>biases</b> the predictions of the model. Much has been made of this issue within the domain of predictive policing, whereby a neighborhood which has been over zealously policed in the past is likely to have a high number of arrest records, which tells an unthinking <b>algorithm</b> to over-police it in the future, and so the cycle repeats\u2026 If poor data is being used to make ...", "dateLastCrawled": "2022-01-29T03:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Ethical Implications and Accountability of Algorithms</b>", "url": "https://www.researchgate.net/publication/324896361_Ethical_Implications_and_Accountability_of_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324896361", "snippet": "on algorithms, an <b>algorithm</b> is a sequence of computational. steps that transform inputs into outputs\u2014<b>similar</b> to a rec -. ipe (Cormen 2009 ). Algorithms are viewed as maximizing. e\ufb03ciency or ...", "dateLastCrawled": "2022-01-16T00:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Algorithmic Accountability</b> \u2013 Moral Guillotines", "url": "https://moralguillotines.wordpress.com/2018/01/09/algorithmic-accountability/", "isFamilyFriendly": true, "displayUrl": "https://moralguillotines.wordpress.com/2018/01/09/<b>algorithmic-accountability</b>", "snippet": "<b>Personal</b> Data: namely, that we have lost control of it, and are unable to even access data that has been harvested. Furthermore, the ubiquity of algorithms and the necessity of using the internet and other resources that use algorithms to participate in society means that individuals cannot simply \u2018opt out\u2019 of divulging data. Misinformation: the proliferation of \u2018fake news\u2019 and misinformation online drowns out legitimate news and relevant information. Regardless of the context of the ...", "dateLastCrawled": "2022-01-30T21:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Seven Types Of Data <b>Bias</b> In Machine Learning", "url": "https://www.telusinternational.com/articles/7-types-of-data-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.telusinternational.com/articles/7-types-of-data-<b>bias</b>-in-machine-learning", "snippet": "How do I avoid data <b>bias</b> in machine learning projects? The prevention of data <b>bias</b> in machine learning projects is an ongoing process. Though it is sometimes difficult to know when your machine learning <b>algorithm</b>, data or model is biased, there are a number of steps you <b>can</b> take to help prevent <b>bias</b> or catch it early. Though far from a comprehensive list, the bullet points below provide an entry-level guide for thinking about data <b>bias</b> for machine learning projects.", "dateLastCrawled": "2022-02-03T11:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Ethical Implications of Bias in Machine</b> Learning", "url": "https://www.researchgate.net/publication/323378868_Ethical_Implications_of_Bias_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323378868_<b>Ethical_Implications_of_Bias_in</b>...", "snippet": "<b>Biases</b> in AI and machine learning algorithms are. presented and analyzed through two issues. management frameworks with the aim of showing h ow. ethical problems a nd dilemmas <b>can</b> evolve. While ...", "dateLastCrawled": "2022-01-16T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Kangaroo Court: Developing Trustworthy AI</b> | Association of Certified E ...", "url": "https://www.jdsupra.com/legalnews/kangaroo-court-developing-trustworthy-ai-2558450/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.jdsupra.com</b>/legalnews/<b>kangaroo-court-developing-trustworthy-ai</b>-2558450", "snippet": "<b>Biases</b> <b>can</b> also be created within AI systems and then become amplified as the algorithms evolve. AI algorithms are not static. They learn and change over time. Initially, an <b>algorithm</b> might make ...", "dateLastCrawled": "2022-01-13T00:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Ethics of AI <b>in Education</b>: Towards a Community-Wide Framework ...", "url": "https://link.springer.com/article/10.1007/s40593-021-00239-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s40593-021-00239-1", "snippet": "While <b>Artificial Intelligence in Education</b> (AIED) research has at its core the desire to support student learning, experience from other AI domains suggest that such ethical intentions are not by themselves sufficient. There is also the need to consider explicitly issues such as fairness, accountability, transparency, <b>bias</b>, autonomy, agency, and inclusion. At a more general level, there is also a need to differentiate between doing ethical things and doing things ethically, to understand and ...", "dateLastCrawled": "2022-01-30T23:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Ethical Implications and Accountability of Algorithms</b>", "url": "https://www.researchgate.net/publication/324896361_Ethical_Implications_and_Accountability_of_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324896361", "snippet": "the <b>algorithm</b> (a) is developed to create systematic <b>bias</b>, (b) that impacts the less fortunate, and (c) does so with the volume and veloc- ity attributed to big data initiatives, as weapons of math ...", "dateLastCrawled": "2022-01-16T00:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "From Learning to Relearning: A Framework for Diminishing <b>Bias</b> in Social ...", "url": "https://www.frontiersin.org/articles/10.3389/frobt.2021.650325/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/frobt.2021.650325", "snippet": "This <b>can</b> lead to unfair outcomes due to human <b>bias</b> that may be existing in the demonstrations, policies reflecting <b>personal</b> <b>bias</b>, unequal society roles, or under-representation of minorities. Specifically, if the learning from demonstration is performed in a shopping mall only from one city, there will be insufficient diversity. Similarly, if the robot is deployed in a different place, or when people belonging to minorities try to use the robot, the robot will maintain its social behavior ...", "dateLastCrawled": "2022-01-30T19:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Not AI alone but AI + ethics</b> | Founding Fuel", "url": "https://www.foundingfuel.com/article/not-ai-alone-but-ai-ethics/", "isFamilyFriendly": true, "displayUrl": "https://www.foundingfuel.com/article/<b>not-ai-alone-but-ai-ethics</b>", "snippet": "<b>Not AI alone but AI + ethics</b>. AI systems may be making important decisions that will fundamentally affect the lives of Indians. For AI to be truly transformative though, its ethical <b>biases</b> need to be rooted out. \u201cThe potential benefits are huge, since everything that civilization has to offer is a product of human intelligence; we cannot ...", "dateLastCrawled": "2022-01-27T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>bias</b> \u2013 paulvanderlaken.com", "url": "https://paulvanderlaken.com/tag/bias/", "isFamilyFriendly": true, "displayUrl": "https://paulvanderlaken.com/tag/<b>bias</b>", "snippet": "I just love psychological experiments around our human <b>biases</b>. In this case, Dan White visualized some of the psychological <b>biases</b> mentioned in Richard Shotton\u2018s book \u201cThe Choice Factory\u201c. These <b>biases</b> make for irrational human behavior in the way we make daily decisions.irrational human behavior in the way we make daily decisions.", "dateLastCrawled": "2022-01-20T17:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "AI (Artificial Intelligence) Governance: How To Get It Right", "url": "https://www.forbes.com/sites/tomtaulli/2020/10/10/ai-artificial-intelligence-governance-how-to-get-it-right/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.forbes.com</b>/sites/tomtaulli/2020/10/10/ai-artificial-intelligence...", "snippet": "This <b>can</b> be challenging because concepts like <b>ethics, fairness</b>, explainability and transparency are amorphous. What\u2019s more, each industry has its own nuances, as there is no one-size-fits all ...", "dateLastCrawled": "2022-01-28T00:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The role of corporations in addressing AI\u2019s ethical dilemmas", "url": "https://www.brookings.edu/research/how-to-address-ai-ethical-dilemmas/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.brookings.edu</b>/research/how-to-address-ai-ethical-dilemmas", "snippet": "The very same <b>algorithm</b> <b>can</b> serve a variety of purposes, which makes the ethics of decisionmaking very difficult. In addition, running through many ethical dilemmas is the problem of dual-use ...", "dateLastCrawled": "2022-02-01T18:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>Tutorial to AI Ethics - Fairness, Bias &amp; Perception</b>", "url": "https://www.slideshare.net/KimKyllesbechLarsen/a-tutorial-to-ai-ethics-fairness-bias-perception", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/KimKyllesbechLarsen/a-<b>tutorial-to-ai-ethics-fairness</b>-<b>bias</b>...", "snippet": "Cognitive <b>biases</b> Statistical <b>bias</b> Contextual <b>biases</b> <b>Bias</b> is a disproportionate weight in favor of or against one thing, person, or group <b>compared</b> with another, usually in a way considered to be unfair. \u212cO MO = E MO \u2212 O O: Observation. M: Model estimator of observation O. E: Expected value (long-run average) B: <b>Bias</b> of model of O relative to O. Hundreds of cognitive <b>biases</b>, e.g., Anchoring, Aavailability, Confirmation <b>bias</b>, Belief <b>bias</b>, framing effect, etc\u2026 (See: https://en.wikipedia ...", "dateLastCrawled": "2022-02-02T01:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Sex and gender differences and <b>biases</b> in artificial intelligence for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7264169/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7264169", "snippet": "Desirable vs. undesirable <b>biases</b>. Despite the fact that the term \u201c<b>bias</b>\u201d has gained a negative connotation due to its association to unfair prejudice, the differential consideration and treatment to specific biomedical aspects is a necessary course of action in the context of Precision Medicine. Therefore, here we defined two main categories of sex and gender <b>biases</b>: desirable and undesirable (see Fig. Fig.2). 2). The difference between them is found in the impact that these <b>biases</b> have ...", "dateLastCrawled": "2022-01-30T00:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bias</b> and Discrimination in AI: A Cross-Disciplinary Perspective - IEEE ...", "url": "https://technologyandsociety.org/bias-and-discrimination-in-ai-a-cross-disciplinary-perspective/", "isFamilyFriendly": true, "displayUrl": "https://technologyandsociety.org/<b>bias</b>-and-discrimination-in-ai-a-cross-disciplinary...", "snippet": "We <b>can</b> distinguish between two general approaches to measure <b>bias</b>: 1) procedural approaches, which focus on identifying <b>biases</b> in the decision-making the process <b>of an algorithm</b> [6] and 2) relational approaches, which focus on identifying (and preventing) biased decisions in the data set or algorithmic output. Although ensuring unbiased outcomes is useful to attest whether a specific <b>algorithm</b> has a discriminatory impact on a population, focusing on the algorithmic process itself <b>can</b> help ...", "dateLastCrawled": "2022-01-30T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Sex and gender differences and <b>biases</b> in artificial intelligence ...", "url": "https://www.researchgate.net/publication/341802125_Sex_and_gender_differences_and_biases_in_artificial_intelligence_for_biomedicine_and_healthcare", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341802125_Sex_and_gender_differences_and...", "snippet": "Evaluation <b>bias</b> Occurs when the evaluation and/or benchmark data for an <b>algorithm</b> does not represent the target population. e.g. underperformance of commercial facial recognition <b>algorithm</b> in dark ...", "dateLastCrawled": "2022-01-23T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Sex and gender differences and <b>biases</b> in artificial intelligence for ...", "url": "https://www.nature.com/articles/s41746-020-0288-5", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41746-020-0288-5", "snippet": "In other cases, an <b>algorithm</b> itself, and not the training dataset, <b>can</b> introduce <b>bias</b> by obscuring an inherent discrimination or inducing an unreasoned or irrelevant selectivity.", "dateLastCrawled": "2022-01-30T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "In fact, ML models <b>can</b> even be used to identify some of the conscious and unconscious human <b>biases</b> and barriers to inclusion that have developed and perpetuated throughout history, bringing about positive change. Far from a solved problem, <b>fairness</b> in AI presents both an opportunity and a challenge. Google is committed to making progress in all of these areas, and to creating tools, datasets, and other resources for the larger community. Our current thinking at Google is outlined below.", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Not AI alone but AI + ethics</b> | Founding Fuel", "url": "https://www.foundingfuel.com/article/not-ai-alone-but-ai-ethics/", "isFamilyFriendly": true, "displayUrl": "https://www.foundingfuel.com/article/<b>not-ai-alone-but-ai-ethics</b>", "snippet": "<b>Not AI alone but AI + ethics</b>. AI systems may be making important decisions that will fundamentally affect the lives of Indians. For AI to be truly transformative though, its ethical <b>biases</b> need to be rooted out. \u201cThe potential benefits are huge, since everything that civilization has to offer is a product of human intelligence; we cannot ...", "dateLastCrawled": "2022-01-27T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Ethical, Explainable Artificial Intelligence: Bias and Principles</b> ...", "url": "https://www.thefreelibrary.com/Ethical%2c+Explainable+Artificial+Intelligence%3a+Bias+and+Principles.-a0532528739", "isFamilyFriendly": true, "displayUrl": "https://www.thefreelibrary.com/Ethical,+Explainable+Artificial+Intelligence:+<b>Bias</b>+and...", "snippet": "However, many of these training sets <b>can</b> suffer from a variety of <b>biases</b>: Sets <b>can</b> be incomplete, skewed, non-representative, and rely on data improperly labeled by humans to embed <b>biases</b> and cultural assumptions. According to The AI Now Institute, the <b>biases</b> are &quot;difficult to find and understand, especially when systems are proprietary, treated as black boxes or taken at face value&quot; (&quot;AI Now 2017 Report,&quot; Campolo, Alex, Madelyn Sanfilippo, Meredith Whittaker, Kate Crawford, et al ...", "dateLastCrawled": "2021-03-25T07:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>bias</b> \u2013 paulvanderlaken.com", "url": "https://paulvanderlaken.com/tag/bias/", "isFamilyFriendly": true, "displayUrl": "https://paulvanderlaken.com/tag/<b>bias</b>", "snippet": "I just love psychological experiments around our human <b>biases</b>. In this case, Dan White visualized some of the psychological <b>biases</b> mentioned in Richard Shotton\u2018s book \u201cThe Choice Factory\u201c. These <b>biases</b> make for irrational human behavior in the way we make daily decisions.irrational human behavior in the way we make daily decisions.", "dateLastCrawled": "2022-01-20T17:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Ultimate Data Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-data-science-flash-cards", "snippet": "<b>Bias</b> (<b>ethics/fairness</b>) 1. Stereotyping, prejudice or favoritism towards some things, people, or groups over others. These <b>biases</b> <b>can</b> affect collection and interpretation of data, the design of a system, and how users interact with a system. Forms of this type of <b>bias</b> include: -automation <b>bias</b>. -confirmation <b>bias</b>.", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Is Bias in Machine Learning all Bad</b>? - KDnuggets", "url": "https://www.kdnuggets.com/2019/07/bias-machine-learning-bad.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2019/07/<b>bias</b>-<b>machine</b>-<b>learning</b>-bad.html", "snippet": "<b>Analogy</b> with previously learned generalizations; If a system is <b>learning</b> a collection of related concepts, or generalizations, then a possible constraint on generalizing any one of them is to consider successful generalization of others. For example, consider a task of <b>learning</b> structural descriptions of blocks-world objects, such as \u201darch\u201d, \u201dtower\u201d, etc. After <b>learning</b> several concepts, the learned descriptions may reveal that certain features are more significant for describing ...", "dateLastCrawled": "2022-01-22T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Is it really fair or did you automate it?", "url": "https://deep1401.github.io/data-ethics-2", "isFamilyFriendly": true, "displayUrl": "https://deep1401.github.io/data-ethics-2", "snippet": "<b>Machine</b> <b>learning</b> can amplify <b>bias</b>. As proposed by (De-Arteaga et al.,2019) ,it was observed that the algorithms were clearly amplifying <b>bias</b> in an already biased dataset. For example, the proportion of females in an occupation dataset who were surgeons was 14.6%.", "dateLastCrawled": "2022-01-14T15:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Data <b>bias</b> is another important consideration; learn more in practices on AI and <b>fairness</b>. Understand the limitations of your dataset and model . A model trained to detect correlations should not be used to make causal inferences, or imply that it can. E.g., your model may learn that people who buy basketball shoes are taller on average, but this does not mean that a user who buys basketball shoes will become taller as a result. <b>Machine</b> <b>learning</b> models today are largely a reflection of the ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Algorithmic injustice: a relational ethics approach", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7892355/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7892355", "snippet": "<b>Machine</b> classification and prediction are practices that act directly upon the world and result in tangible impact.64 Various companies, institutes, and governments use <b>machine</b>-<b>learning</b> systems across a variety of areas. These systems process people&#39;s behaviors, actions, and the social world at large. The <b>machine</b>-detected patterns often provide \u201canswers\u201d to fuzzy, contingent, and open-ended questions. These \u201canswers\u201d neither reveal any causal relations nor provide explanation on why ...", "dateLastCrawled": "2022-01-26T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Algorithmic injustice: a relational ethics approach</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S2666389921000155", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2666389921000155", "snippet": "<b>Machine</b> classification and prediction are practices that act directly upon the world and result in tangible impact. 64 Various companies, institutes, and governments use <b>machine</b>-<b>learning</b> systems across a variety of areas. These systems process people&#39;s behaviors, actions, and the social world at large. The <b>machine</b>-detected patterns often provide \u201canswers\u201d to fuzzy, contingent, and open-ended questions. These \u201canswers\u201d neither reveal any causal relations nor provide explanation on why ...", "dateLastCrawled": "2022-01-29T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Human-centric Approach to Fairness in AI", "url": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "isFamilyFriendly": true, "displayUrl": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "snippet": "A lot of what is discussed in the <b>machine</b> <b>learning</b> literature touches on fairness (or rather equivalence in certain outcomes) between groups, yet this narrowly constricts fairness to the notion of equality. Of course, we should think about fairness in the context of prejudiced groups, but we should also ask whether it is fair to an individual. Adding constraints in models might lead to worse outcomes for other individuals. If the decision making processs has serious consequences e.g. a fraud ...", "dateLastCrawled": "2022-02-03T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) A review of some techniques for inclusion of domain-knowledge ...", "url": "https://www.researchgate.net/publication/357983755_A_review_of_some_techniques_for_inclusion_of_domain-knowledge_into_deep_neural_networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357983755_A_review_of_some_techniques_for...", "snippet": "The <b>machine</b> <b>learning</b> system then conveys its explanations to the biologist. ... <b>ethics, fairness</b>, and explainability o ... <b>Analogy</b> Model 75 RNN. Transf orming Model. KBANN 86 MLP. Cascade-ARTMAP ...", "dateLastCrawled": "2022-01-21T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Algorithmic injustice: <b>a relational ethics approach</b>: <b>Patterns</b>", "url": "https://www.cell.com/patterns/fulltext/S2666-3899(21)00015-5", "isFamilyFriendly": true, "displayUrl": "https://www.cell.com/<b>patterns</b>/fulltext/S2666-3899(21)00015-5", "snippet": "Data science and <b>machine</b>-<b>learning</b> systems sit firmly within the rationalist tradition. The core of what <b>machine</b>-<b>learning</b> systems do can be exemplified as clustering similarities and differences, abstracting commonalities, and detecting <b>patterns</b>. <b>Machine</b>-<b>learning</b> systems \u201cwork\u201d by identifying <b>patterns</b> in vast amounts of data. Given immense, messy, and complex data, a <b>machine</b>-<b>learning</b> system can sort, classify, and cluster similarities based on seemingly shared features. Feed a neural ...", "dateLastCrawled": "2022-01-31T12:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>MATHEMATICS FOR MACHINE LEARNING</b> | g t - Academia.edu", "url": "https://www.academia.edu/41334219/MATHEMATICS_FOR_MACHINE_LEARNING", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/41334219", "snippet": "<b>MATHEMATICS FOR MACHINE LEARNING</b>. g t. Kong Yao Chee. fabio baca. book P D F services. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 37 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package ...", "dateLastCrawled": "2022-02-02T23:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Data Is the New What? Popular Metaphors &amp; Professional Ethics in ...", "url": "https://www.researchgate.net/publication/332828046_Data_Is_the_New_What_Popular_Metaphors_Professional_Ethics_in_Emerging_Data_Culture", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/332828046_Data_Is_the_New_What_Popular...", "snippet": "PDF | On Jan 1, 2019, Luke Stark and others published Data Is the New What? Popular Metaphors &amp; Professional Ethics in Emerging Data Culture | Find, read and cite all the research you need on ...", "dateLastCrawled": "2022-01-19T14:44:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bias (ethics/fairness))  is like +(personal biases of an algorithm)", "+(bias (ethics/fairness)) is similar to +(personal biases of an algorithm)", "+(bias (ethics/fairness)) can be thought of as +(personal biases of an algorithm)", "+(bias (ethics/fairness)) can be compared to +(personal biases of an algorithm)", "machine learning +(bias (ethics/fairness) AND analogy)", "machine learning +(\"bias (ethics/fairness) is like\")", "machine learning +(\"bias (ethics/fairness) is similar\")", "machine learning +(\"just as bias (ethics/fairness)\")", "machine learning +(\"bias (ethics/fairness) can be thought of as\")", "machine learning +(\"bias (ethics/fairness) can be compared to\")"]}