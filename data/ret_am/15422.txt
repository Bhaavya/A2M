{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding \u201cconvolution\u201d operations in CNN | by aditi kothiya ...", "url": "https://medium.com/analytics-vidhya/convolution-operations-in-cnn-deep-learning-compter-vision-128906ece7d3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/convolution-<b>operations</b>-in-cnn-deep-learning...", "snippet": "The convolution <b>operation</b> is the process of implying a combination of <b>two</b> functions that produce the third function as a result, employing <b>filters</b> <b>across</b> the entire input image allows the filter ...", "dateLastCrawled": "2022-01-27T14:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Convolutional Neural</b> Network: How is it different from the <b>other</b> ...", "url": "https://yangxiaozhou.github.io/data/2020/09/24/intro-to-cnn.html", "isFamilyFriendly": true, "displayUrl": "https://yangxiaozhou.github.io/data/2020/09/24/intro-to-cnn.html", "snippet": "They generally fall into <b>two</b> categories: Type of <b>convolutional</b> layer Depth: The number of <b>filters</b> to use for <b>each</b> layer. Stride: How big of a step to take when <b>sliding</b> the filter <b>across</b> the image, usually 1 (see the convolution GIF above) or 2. Size: Size of <b>each</b> convolution filter, e.g., the mean filter is 3-by-3.", "dateLastCrawled": "2022-01-28T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Convolutional</b> Neural Networks | Applied Machine Learning", "url": "https://kavir1698.github.io/aml/cnn.html", "isFamilyFriendly": true, "displayUrl": "https://kavir1698.github.io/aml/cnn.html", "snippet": "But using a convolution step, we only have 56 parameters to learn (<b>two</b> <b>filters</b> <b>each</b> with 27 elements and one bias term). The reason behind this reduction in parameter space is that we use the same feature detector (e.g. vertical edge detector), and hence the same parameters, every time we slide <b>across</b> the picture. Reducing the number of shared parameters by having sparse connections. In a <b>convolutional</b> layer, <b>each</b> new pixel depends only on a small number of pixels from the previous layer, i ...", "dateLastCrawled": "2022-02-03T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Intuitively Understanding Convolutions for Deep Learning | by Irhum ...", "url": "https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/intuitively-understanding-<b>convolution</b>s-for-deep...", "snippet": "However, understanding convolutions, especially for the first t i me can often feel a bit unnerving, with terms <b>like</b> kernels, <b>filters</b>, channels and so on all stacked onto <b>each</b> <b>other</b>. Yet, convolutions as a concept are fascinatingly powerful and highly extensible, and in this post, we\u2019ll break down the mechanics of the <b>convolution</b> <b>operation</b>, step-by-step, relate it to the standard fully connected network, and explore just how they build up a strong visual hierarchy, making them powerful ...", "dateLastCrawled": "2022-01-29T08:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Convolutional Neural Networks (CNNs) and</b> Layer Types - PyImageSearch", "url": "https://www.pyimagesearch.com/2021/05/14/convolutional-neural-networks-cnns-and-layer-types/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/05/14/<b>convolutional-neural-networks-cnns-and</b>-layer...", "snippet": "To make this concept more clear, let\u2019s consider the forward-pass of a CNN, where we convolve <b>each</b> of the K <b>filters</b> <b>across</b> the width and height of the input volume. More simply, we can think of <b>each</b> of our K kernels <b>sliding</b> <b>across</b> the input region, computing an element-wise multiplication, summing, and then storing the output value in a 2-dimensional activation map , such as in Figure 1 .", "dateLastCrawled": "2022-01-31T10:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How Do <b>Convolutional Layers</b> Work in Deep Learning Neural Networks?", "url": "https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>convolutional</b>", "snippet": "This means that if a <b>convolutional</b> layer has 32 <b>filters</b>, these 32 <b>filters</b> are not just <b>two</b>-dimensional for the <b>two</b>-dimensional image input, but are also three-dimensional, having specific filter weights for <b>each</b> of the three channels. Yet, <b>each</b> filter results in a single feature map. Which means that the depth of the output of applying the <b>convolutional</b> layer with 32 <b>filters</b> is 32 for the 32 feature maps created.", "dateLastCrawled": "2022-02-02T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Convolutional</b> Neural Networks, Explained | by Mayank Mishra | Towards ...", "url": "https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>convolutional</b>-neural-ne<b>two</b>rks-explained-9cc5188c4939", "snippet": "Illustration of Convolution <b>Operation</b> . During the forward pass, the kernel slides <b>across</b> the height and width of the image-producing the image representation of that receptive region. This produces a <b>two</b>-dimensional representation of the image known as an activation map that gives the response of the kernel at <b>each</b> spatial position of the ...", "dateLastCrawled": "2022-02-02T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Convolution and cross-correlation in neural networks</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2021/05/14/convolution-and-cross-correlation-in-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/05/14/<b>convolution-and-cross-correlation-in</b>-neural...", "snippet": "By applying <b>convolutional</b> <b>filters</b>, nonlinear activation functions, pooling, and backpropagation, CNNs are able to learn <b>filters</b> that can detect edges and blob-<b>like</b> structures in lower-level layers of the network \u2014 and then use the edges and structures as \u201cbuilding blocks,\u201d eventually detecting high-level objects (e.g., faces, cats, dogs, cups, etc.) in the deeper layers of the network.", "dateLastCrawled": "2022-01-30T23:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Understanding Convolution in Deep Learning</b> \u2014 Tim Dettmers", "url": "https://timdettmers.com/2015/03/26/convolution-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://timdettmers.com/2015/03/26/convolution-deep-learning", "snippet": "We can imagine the <b>operation</b> of convolution as a <b>two</b> part diffusion process: Firstly, there is strong diffusion where pixel intensities change (from black to white, or from yellow to blue, etc.) and secondly, the diffusion process in an area is regulated by the probability distribution of the convolution kernel. That means that <b>each</b> pixel in the kernel area, diffuses into another position within the kernel according to the kernel probability density. For the edge detector above almost all ...", "dateLastCrawled": "2022-02-02T16:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "In a CNN, when the convolution is done between 6 sources and 16 maps as ...", "url": "https://www.quora.com/In-a-CNN-when-the-convolution-is-done-between-6-sources-and-16-maps-as-in-LeNet-how-are-the-convolutions-done", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-a-CNN-when-the-convolution-is-done-between-6-sources-and-16...", "snippet": "Answer (1 of 3): VERY SIMPLE! There aren\u2019t really any difference in the <b>two</b> (or no matter how many) convolution layers you have. They all can be generalized. A <b>Convolutional</b> Layer is layer which converts an n-channel input image to a p-channel output image. Now this might be a bit confusing as ...", "dateLastCrawled": "2022-01-14T13:50:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Different Types of Convolution \u00b7 GitBook", "url": "https://ztlevi.github.io/Gitbook_Machine_Learning_Questions/neural_networks/different_types_of_convolution.html", "isFamilyFriendly": true, "displayUrl": "https://ztlevi.github.io/Gitbook_Machine_Learning_Questions/neural_ne<b>two</b>rks/different...", "snippet": "At <b>each</b> <b>sliding</b> position, we perform element-wise multiplication and addition, which results in a single number. In the example shown below, the <b>sliding</b> is performed at 5 positions horizontally and 5 positions vertically. Overall, we get a single output channel. Another way to think about 2D convolution: thinking of the process as <b>sliding</b> a 3D filter matrix through the input layer. Notice that the input layer and the filter have the same depth (channel number = kernel number). The 3D filter ...", "dateLastCrawled": "2022-01-27T15:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Convolutional Neural Networks (CNNs) and</b> Layer Types - PyImageSearch", "url": "https://www.pyimagesearch.com/2021/05/14/convolutional-neural-networks-cnns-and-layer-types/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/05/14/<b>convolutional-neural-networks-cnns-and</b>-layer...", "snippet": "Using S = 1, our kernel slides from left-to-right and top-to-bottom, one pixel at a time, producing the following output (Table 2, left).However, if we were to apply the same <b>operation</b>, only this time with a stride of S = 2, we skip <b>two</b> pixels at a time (<b>two</b> pixels along the x-axis and <b>two</b> pixels along the y-axis), producing a smaller output volume (right).", "dateLastCrawled": "2022-01-31T10:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Basic CNN Architecture: Explaining 5 Layers of <b>Convolutional</b> Neural ...", "url": "https://www.upgrad.com/blog/basic-cnn-architecture/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/basic-cnn-architecture", "snippet": "The second layer is a Pooling <b>operation</b> which filter size 2\u00d72 and stride of 2. Hence the resulting image dimension will be 14x14x6. Similarly, the third layer also involves in a convolution <b>operation</b> with 16 <b>filters</b> of size 5\u00d75 followed by a fourth pooling layer with <b>similar</b> filter size of 2\u00d72 and stride of 2. Thus, the resulting image ...", "dateLastCrawled": "2022-02-03T01:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Convolution and cross-correlation in neural networks</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2021/05/14/convolution-and-cross-correlation-in-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/05/14/<b>convolution-and-cross-correlation-in</b>-neural...", "snippet": "By applying <b>convolutional</b> <b>filters</b>, nonlinear activation functions, pooling, and backpropagation, CNNs are able to learn <b>filters</b> that can detect edges and blob-like structures in lower-level layers of the network \u2014 and then use the edges and structures as \u201cbuilding blocks,\u201d eventually detecting high-level objects (e.g., faces, cats, dogs, cups, etc.) in the deeper layers of the network.", "dateLastCrawled": "2022-01-30T23:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Convolutional Neural</b> Network: How is it different from the <b>other</b> ...", "url": "https://yangxiaozhou.github.io/data/2020/09/24/intro-to-cnn.html", "isFamilyFriendly": true, "displayUrl": "https://yangxiaozhou.github.io/data/2020/09/24/intro-to-cnn.html", "snippet": "They generally fall into <b>two</b> categories: Type of <b>convolutional</b> layer Depth: The number of <b>filters</b> to use for <b>each</b> layer. Stride: How big of a step to take when <b>sliding</b> the filter <b>across</b> the image, usually 1 (see the convolution GIF above) or 2. Size: Size of <b>each</b> convolution filter, e.g., the mean filter is 3-by-3.", "dateLastCrawled": "2022-01-28T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Convolutional</b> Neural Networks | Applied Machine Learning", "url": "https://kavir1698.github.io/aml/cnn.html", "isFamilyFriendly": true, "displayUrl": "https://kavir1698.github.io/aml/cnn.html", "snippet": "We want to apply <b>two</b> different <b>filters</b> on the image, <b>each</b> of which with dimensions \\(3 \\times 3 \\times 3\\), where the last 3 is again for the three channels RGB. The output of <b>sliding</b> <b>each</b> filter on the image will be of dimensions \\(4 \\times 4\\) (assuming padding is 0 and stride is 1). Now, this output needs to be nonlinearized. To that end, we first add a bias \\(b\\) to <b>each</b> element. This <b>is similar</b> to how we had a bias term in linear regression (\\(y = ax + b\\)). After that, we apply a ...", "dateLastCrawled": "2022-02-03T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Deep Learning for Computer Vision</b> | by Rachit Tayal | Towards Data Science", "url": "https://towardsdatascience.com/deep-learning-for-computer-vision-c4e5f191c522", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>deep-learning-for-computer-vision</b>-c4e5f191c522", "snippet": "<b>Convolutional</b> <b>Operation</b>: Convolution is one of the fundamental building blocks of CNNs. The prime objective of the <b>convolutional</b> <b>operation</b> is to extract features like edges, curves, corners, gradient orientation, etc from the input image. We\u2019ll understand the convolution <b>operation</b> with an edge detection example. Given an image and we want to extract all the horizontal and vertical edges in that image. The below image depicts the same. Example of <b>Convolutional</b> <b>Operation</b>. Consider we have a ...", "dateLastCrawled": "2022-01-30T23:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fully <b>convolutional</b> architecture vs <b>sliding-window</b> CNN for corneal ...", "url": "https://bmcbiomedeng.biomedcentral.com/articles/10.1186/s42490-019-0003-2", "isFamilyFriendly": true, "displayUrl": "https://bmcbiomedeng.biomedcentral.com/articles/10.1186/s42490-019-0003-2", "snippet": "To evaluate this, we built networks reaching comparable receptive fields: for the 3 \u00d73 <b>filters</b>, we added another <b>convolutional</b> layer at <b>each</b> resolution step of the contraction path (receptive field of 93 pixels); for the 5 \u00d75 <b>filters</b>, we removed the last <b>convolutional</b> layer of the contraction path (receptive field of 89 pixels). Still, accuracy and AUC for the network using <b>filters</b> of 4 \u00d74 were always slightly higher (data not included). Moreover, visual evaluation indicated that <b>filters</b> ...", "dateLastCrawled": "2022-01-25T03:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is it possible to combine <b>two</b> <b>Convolutional</b> Neural Networks by taking ...", "url": "https://www.quora.com/Is-it-possible-to-combine-two-Convolutional-Neural-Networks-by-taking-parts-of-each-to-form-a-new-network-in-an-evolutionary-manner-similar-to-combining-DNA-from-two-parents-thus-not-like-bilinear-CNNs-which-operate", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-it-possible-to-combine-<b>two</b>-<b>Convolutional</b>-Neural-Ne<b>two</b>rks-by...", "snippet": "Answer (1 of 2): What you are talking (or thinking) about relates to Genetic Programming (GP), a paradigm which is a generalization of the Genetic Algorithm (GA). GAs try to evolve a population of \u201cDNA\u201d strings, which in the canonical GA are strings of bits, in order to \u201doptimize\u201d some prescribe...", "dateLastCrawled": "2022-01-15T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What are the <b>major differences between Graph Convolution Network</b> (GCN ...", "url": "https://www.quora.com/What-are-the-major-differences-between-Graph-Convolution-Network-GCN-and-Convolution-Neural-Network-CNN", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-the-<b>major-differences-between-Graph-Convolution-Network</b>...", "snippet": "Answer (1 of 4): Graph <b>Convolutional</b> Networks (GCNs) are very different from our normal day-to-day Convnets. They are a way to apply convolutions (with shared weights) on Graph structured data (just like ConvNets apply them on image/text/timeseries data), and hence maybe the underlying mathematic...", "dateLastCrawled": "2022-01-25T08:11:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Convolutional Neural Networks</b> for Text Classification", "url": "https://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets/", "isFamilyFriendly": true, "displayUrl": "https://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets", "snippet": "A <b>Convolutional</b> Neural Network typically involves <b>two</b> operations, which <b>can</b> be though of as feature extractors: ... convolutions and pooling, <b>can</b> been <b>thought</b> of as a feature extractors, then we pass this features, usually as a reshaped vector of one row, further to the network, for instance, a multi-layer perceptron to be trained for classification. Example of multi-layer perceptron network used to train for classification. This was a briefly description of the ConvNet architecture when ...", "dateLastCrawled": "2022-01-28T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Convolutional Neural Networks (CNNs) explained</b> - deeplizard", "url": "https://deeplizard.com/learn/video/YRhxdVk_sIs", "isFamilyFriendly": true, "displayUrl": "https://deeplizard.com/learn/video/YRhxdVk_sIs", "snippet": "Just like any <b>other</b> layer, a <b>convolutional</b> layer receives input, transforms the input in some way, and then outputs the transformed input to the next layer. The inputs to <b>convolutional</b> layers are called input channels, and the outputs are called output channels. With a <b>convolutional</b> layer, the transformation that occurs is called a convolution <b>operation</b>. This is the term that&#39;s used by the deep learning community anyway. Mathematically, the convolution operations performed by <b>convolutional</b> ...", "dateLastCrawled": "2022-01-31T18:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "An introduction to <b>Convolutional</b> Neural Networks | by Christopher ...", "url": "https://towardsdatascience.com/an-introduction-to-convolutional-neural-networks-eb0b60b58fd7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-introduction-to-<b>convolutional</b>-neural-ne<b>two</b>rks-eb0b60...", "snippet": "Usually there is at least three <b>convolutional</b> kernels in order that <b>each</b> <b>can</b> act as a different filter to gain insight from <b>each</b> colour channel. The <b>convolution</b> kernels as a group make a four dimensional array, otherwise known as a rank four tensor. It is difficult, if not impossible, to visualise dimensions when they are higher than three. In this case imagine it as a list of three dimensional cubes. The filter moves <b>across</b> the input data in the same way, <b>sliding</b> or taking strides <b>across</b> ...", "dateLastCrawled": "2022-02-02T15:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Convolutional Neural Networks (CNNs): An Illustrated Explanation</b> - XRDSXRDS", "url": "https://blog.xrds.acm.org/2016/06/convolutional-neural-networks-cnns-illustrated-explanation/", "isFamilyFriendly": true, "displayUrl": "https://blog.xrds.acm.org/2016/06/<b>convolutional</b>-neural-ne<b>two</b>rks-cnns-illustrated...", "snippet": "For example, if the input is a volume of size 4x4x3, and the <b>sliding</b> window is of size 2\u00d72, then for <b>each</b> color channel, the values will be down-sampled to their representative maximum value if we perform the max pooling <b>operation</b>. No new parameters are introduced in the matrix by this <b>operation</b>. The <b>operation</b> <b>can</b> <b>be thought</b> of as applying a function over input values, taking fixed sized portions at a time, with the size, modifiable as a parameter. Pooling is optional in CNNs, and many ...", "dateLastCrawled": "2022-02-02T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Convolutional Neural Networks Explained</b> - Magoosh Data Science Blog", "url": "https://magoosh.com/data-science/convolutional-neural-networks-explained/", "isFamilyFriendly": true, "displayUrl": "https://magoosh.com/data-science/<b>convolutional-neural-networks-explained</b>", "snippet": "Depth: It defines the exact number of <b>filters</b> needed for the convolution <b>operation</b>. In the figure below, the convolution of the original boat image is performed using 3 distinct <b>filters</b>, thereby, generating 3 distinct feature maps. These feature maps <b>can</b> <b>be thought</b> of as stacked 2D matrices. So, the \u2018depth\u2019 of our feature map here would be 3.", "dateLastCrawled": "2022-01-29T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Comprehensive Guide to <b>Convolutional</b> Neural Networks", "url": "https://www.v7labs.com/blog/convolutional-neural-networks-guide", "isFamilyFriendly": true, "displayUrl": "https://www.v7labs.com/blog/<b>convolutional</b>-neural-ne<b>two</b>rks-guide", "snippet": "A filter <b>can</b> <b>be thought</b> of as a relatively small matrix for which we decide the number of rows and columns this matrix has. The value of this feature matrix is initialized with random numbers. When this <b>convolutional</b> layer receives pixel values of input data, the filter will convolve over <b>each</b> patch of the input matrix. The output of the <b>convolutional</b> layer is usually passed through the ReLU activation function to bring non-linearity to the model. It takes the feature map and replaces all ...", "dateLastCrawled": "2022-02-02T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Understanding Convolution in Deep Learning</b> \u2014 Tim Dettmers", "url": "https://timdettmers.com/2015/03/26/convolution-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://timdettmers.com/2015/03/26/convolution-deep-learning", "snippet": "We <b>can</b> imagine the <b>operation</b> of convolution as a <b>two</b> part diffusion process: Firstly, there is strong diffusion where pixel intensities change (from black to white, or from yellow to blue, etc.) and secondly, the diffusion process in an area is regulated by the probability distribution of the convolution kernel. That means that <b>each</b> pixel in the kernel area, diffuses into another position within the kernel according to the kernel probability density. For the edge detector above almost all ...", "dateLastCrawled": "2022-02-02T16:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Hands-On AI Part 15: Overview of <b>Convolutional</b> Neural Networks for...", "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/hands-on-ai-part-15-overview-of-convolutional-neural-networks-for-image-classification.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.intel.com</b>/content/www/us/en/developer/articles/technical/hands-on-ai-part...", "snippet": "<b>Each</b> neuron in the <b>convolutional</b> layer represents and implements one particular position of the kernel <b>sliding</b> <b>across</b> the initial image. Figure 3 (c). <b>Two</b> stacked 1D <b>convolutional</b> layers. There is one more important notion called receptive field. It reflects how many positions in the initial signal <b>can</b> be seen from the current neuron. For example, the receptive field in the first layer of the network shown in Figure 3 (c) equals the filter size 3 because <b>each</b> neuron has a connection to only ...", "dateLastCrawled": "2021-12-22T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Convolutional Neural Networks Tutorial in PyTorch</b> \u2013 Adventures in ...", "url": "https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-in-pytorch/", "isFamilyFriendly": true, "displayUrl": "https://adventuresinmachinelearning.com/<b>convolutional-neural-networks-tutorial-in-pytorch</b>", "snippet": "This <b>operation</b> <b>can</b> also be illustrated using standard neural network node diagrams: Moving 2\u00d72 filter \u2013 node diagram . The first position of the moving filter connections is illustrated by the blue connections, and the second is shown with the green lines. The weights of <b>each</b> of these connections, as stated previously, is 0.5. There are a few things in this <b>convolutional</b> step which improve training by reducing parameters/weights: Sparse connections \u2013 not every node in the first / input ...", "dateLastCrawled": "2022-01-29T11:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "1X1 <b>Convolution</b>, CNN, CV, Neural Networks | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1...", "snippet": "In their paper, He et all explains (page 6) how a bottle neck layer designed using a sequence of 3 <b>convolutional</b> layers with <b>filters</b> the size of 1X1, 3X3, followed by 1X1 respectively to reduce ...", "dateLastCrawled": "2022-02-02T22:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fully <b>convolutional</b> architecture vs <b>sliding-window</b> CNN for corneal ...", "url": "https://bmcbiomedeng.biomedcentral.com/articles/10.1186/s42490-019-0003-2", "isFamilyFriendly": true, "displayUrl": "https://bmcbiomedeng.biomedcentral.com/articles/10.1186/s42490-019-0003-2", "snippet": "To evaluate this, we built networks reaching comparable receptive fields: for the 3 \u00d73 <b>filters</b>, we added another <b>convolutional</b> layer at <b>each</b> resolution step of the contraction path (receptive field of 93 pixels); for the 5 \u00d75 <b>filters</b>, we removed the last <b>convolutional</b> layer of the contraction path (receptive field of 89 pixels). Still, accuracy and AUC for the network using <b>filters</b> of 4 \u00d74 were always slightly higher (data not included). Moreover, visual evaluation indicated that <b>filters</b> ...", "dateLastCrawled": "2022-01-25T03:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding \u201c<b>convolution</b>\u201d operations in CNN | by Pratik Choudhari ...", "url": "https://medium.com/analytics-vidhya/understanding-convolution-operations-in-cnn-1914045816d4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/understanding-<b>convolution</b>-<b>operations</b>-in-cnn...", "snippet": "<b>Filters</b> are one dimension higher than kernels and <b>can</b> be seen as multiple kernels stacked on <b>each</b> <b>other</b> where every kernel is for a particular channel. Therefore for an RGB image of (32x32) we ...", "dateLastCrawled": "2022-01-30T05:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Different Types of Convolution \u00b7 GitBook", "url": "https://ztlevi.github.io/Gitbook_Machine_Learning_Questions/neural_networks/different_types_of_convolution.html", "isFamilyFriendly": true, "displayUrl": "https://ztlevi.github.io/Gitbook_Machine_Learning_Questions/neural_ne<b>two</b>rks/different...", "snippet": "At <b>each</b> <b>sliding</b> position, we perform element-wise multiplication and addition, which results in a single number. In the example shown below, the <b>sliding</b> is performed at 5 positions horizontally and 5 positions vertically. Overall, we get a single output channel. Another way to think about 2D convolution: thinking of the process as <b>sliding</b> a 3D filter matrix through the input layer. Notice that the input layer and the filter have the same depth (channel number = kernel number). The 3D filter ...", "dateLastCrawled": "2022-01-27T15:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Convolutional</b> Neural Networks-CNN Concepts(p-5) | by VV Naveen Varma ...", "url": "https://naveen-varma.medium.com/convolutional-neural-networks-cnn-concepts-p-5-9abc6e733bcc", "isFamilyFriendly": true, "displayUrl": "https://naveen-varma.medium.com/<b>convolutional</b>-neural-ne<b>two</b>rks-cnn-concepts-p-5-9abc6e...", "snippet": "We <b>can</b> perform the <b>convolutional</b> <b>operation</b> by <b>sliding</b> the kernel at every location of the image. The amount by which we\u2019re shifting the kernel at every <b>operation</b> is known as the \u201cstride\u201d. In this case the stride is one, which makes the filter move one pixel at a time. \u201cThe bigger the stride the smaller the corresponding feature map.\u201d - Lets look at a smaller image for simplicity. example image for Kernel Convolution. The area where the <b>operation</b> takes place, the highlighted area ...", "dateLastCrawled": "2022-01-27T05:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Intuitively Understanding Convolutions for Deep Learning | by Irhum ...", "url": "https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/intuitively-understanding-<b>convolution</b>s-for-deep...", "snippet": "However, understanding convolutions, especially for the first t i me <b>can</b> often feel a bit unnerving, with terms like kernels, <b>filters</b>, channels and so on all stacked onto <b>each</b> <b>other</b>. Yet, convolutions as a concept are fascinatingly powerful and highly extensible, and in this post, we\u2019ll break down the mechanics of the <b>convolution</b> <b>operation</b>, step-by-step, relate it to the standard fully connected network, and explore just how they build up a strong visual hierarchy, making them powerful ...", "dateLastCrawled": "2022-01-29T08:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Convolutional Neural Networks (CNNs) and</b> Layer Types - You <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2021/05/14/convolutional-neural-networks-cnns-and-layer-types/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/05/14/<b>convolutional-neural-networks-cnns-and</b>-layer...", "snippet": "Using S = 1, our kernel slides from left-to-right and top-to-bottom, one pixel at a time, producing the following output (Table 2, left).However, if we were to apply the same <b>operation</b>, only this time with a stride of S = 2, we skip <b>two</b> pixels at a time (<b>two</b> pixels along the x-axis and <b>two</b> pixels along the y-axis), producing a smaller output volume (right).", "dateLastCrawled": "2022-01-31T10:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Convolutional Neural Networks Tutorial in PyTorch</b> \u2013 Adventures in ...", "url": "https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-in-pytorch/", "isFamilyFriendly": true, "displayUrl": "https://adventuresinmachinelearning.com/<b>convolutional-neural-networks-tutorial-in-pytorch</b>", "snippet": "This <b>operation</b> <b>can</b> also be illustrated using standard neural network node diagrams: Moving 2\u00d72 filter \u2013 node diagram . The first position of the moving filter connections is illustrated by the blue connections, and the second is shown with the green lines. The weights of <b>each</b> of these connections, as stated previously, is 0.5. There are a few things in this <b>convolutional</b> step which improve training by reducing parameters/weights: Sparse connections \u2013 not every node in the first / input ...", "dateLastCrawled": "2022-01-29T11:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "CoAtNet: how to perfectly combine CNNs and Transformers | by Leonardo ...", "url": "https://medium.com/codex/coatnet-how-to-perfectly-combine-cnns-and-transformer-9632e187ecbf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/codex/coatnet-how-to-perfectly-combine-cnns-and-transformer-9632e...", "snippet": "Given a 224\u00d7224\u00d73 RGB image, you <b>can</b> imagine using a <b>convolutional</b> layer with n <b>filters</b> 3\u00d73\u00d73. This means <b>sliding</b> <b>each</b> of the n <b>filters</b> over the images and performing the convolution <b>operation</b> ...", "dateLastCrawled": "2022-01-26T06:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Time Series Classification</b> with Deep Learning | by Marco Del Pra ...", "url": "https://towardsdatascience.com/time-series-classification-with-deep-learning-d238f0147d6f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>time-series-classification</b>-with-deep-learning-d238f0147d6f", "snippet": "The pre processing required in a <b>Convolutional</b> Neural Network is much lower as <b>compared</b> to <b>other</b> classification algorithms. While in many methods <b>filters</b> are hand-engineered, <b>Convolutional</b> Neural Network have the ability to learn these <b>filters</b>. Image by the author. As we <b>can</b> see in this Figure, a <b>Convolutional</b> Neural Network is composed of three different layers: <b>Convolutional</b> Layer; Pooling Layer; Fully-Connected Layer; Usually several <b>Convolutional</b> Layers and Pooling Layers are alternated ...", "dateLastCrawled": "2022-02-03T04:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What&#39;s the difference between <b>convolutional</b> and <b>recurrent</b> neural ...", "url": "https://stackoverflow.com/questions/20923574/whats-the-difference-between-convolutional-and-recurrent-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/20923574", "snippet": "The input <b>can</b> be one-dimensional or n-dimensional (n&gt;1), for example, it <b>can</b> be a <b>two</b>-dimensional image. One or more <b>filters</b> are also defined in <b>each</b> layer. Inputs are convolving with <b>each</b> filter. The method of convolution is almost similar to the convolution of <b>filters</b> in image processing. In general, the purpose of this section is to extract ...", "dateLastCrawled": "2022-01-28T23:18:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding \u201cconvolution\u201d operations in CNN | by aditi kothiya ...", "url": "https://medium.com/analytics-vidhya/convolution-operations-in-cnn-deep-learning-compter-vision-128906ece7d3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/convolution-<b>operations</b>-in-cnn-deep-<b>learning</b>...", "snippet": "Convolution neural network is the major building block of deep <b>learning</b>, which helps in image classification, object detection, image recognition, etc of computer vision tasks. We use many\u2026", "dateLastCrawled": "2022-01-27T14:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Graph Convolutions and <b>Machine</b> <b>Learning</b>", "url": "https://dash.harvard.edu/bitstream/handle/1/38811540/OTNESS-SENIORTHESIS-2018.pdf?sequence=1", "isFamilyFriendly": true, "displayUrl": "https://dash.harvard.edu/bitstream/handle/1/38811540/OTNESS-SENIORTHESIS-2018.pdf?...", "snippet": "of a standard <b>convolutional</b> neural network: locality and parameter reduction. However, the <b>operation</b> of convolution does not directly generalize to non-Euclidean domains and will require the development of a suitable <b>analogy</b>. Just as <b>convolutional</b> neural networks built on existing techniques in signal processing, there", "dateLastCrawled": "2022-01-09T08:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Complete Guide for Visualising <b>and Understanding Convolutional</b> ...", "url": "https://medium.com/analytics-vidhya/a-complete-guide-for-visualising-and-understanding-convolutional-networks-dc26f71c979f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/a-complete-guide-for-visualising-and-understanding...", "snippet": "There is a common <b>analogy</b> among practitioners that insights into the internal <b>operation</b> and behavior of these models or the reason how they achieve such good performance is a cumbersome task (if ...", "dateLastCrawled": "2022-01-07T00:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Convolutional Neural Networks (CNN): Step</b> 2 - <b>Machine</b> <b>Learning</b> | AI", "url": "https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-2-max-pooling/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>superdatascience</b>.com/blogs/<b>convolutional-neural-networks-cnn-step</b>-2-max...", "snippet": "The purpose of max pooling is enabling the <b>convolutional</b> neural network to detect the cheetah when presented with the image in any manner. This second example is more advanced. Here we have 6 different images of 6 different cheetahs (or 5, there is 1 that seems to appear in 2 photos) and they are each posing differently in different settings and from different angles. Again, max pooling is concerned with teaching your <b>convolutional</b> neural network to recognize that despite all of these ...", "dateLastCrawled": "2022-01-28T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Convolutional Neural Networks and their components for computer vision</b> ...", "url": "https://www.machinecurve.com/index.php/2018/12/07/convolutional-neural-networks-and-their-components-for-computer-vision/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2018/12/07/<b>convolutional</b>-neural-networks-and...", "snippet": "<b>Machine</b> <b>learning</b> (and consequently deep <b>learning</b>) can be used to train computers to see things. We know that <b>machine</b> <b>learning</b> is about feeding examples to machines, after which they derive the patterns in these examples themselves. Consequently, we can see that using <b>machine</b> <b>learning</b> for computer vision equals showing machines enough examples so that they can learn to recognize them on their own, for new data. In deep <b>learning</b>, we use deep neural networks to learn machines to recognize ...", "dateLastCrawled": "2022-01-30T13:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Convolution and cross-correlation in neural networks</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2021/05/14/convolution-and-cross-correlation-in-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/05/14/<b>convolution-and-cross-correlation-in</b>-neural...", "snippet": "All this math amounts to is a sign change in how we access the coordinates of the image I (i.e., we don\u2019t have to \u201cflip\u201d the kernel relative to the input when applying cross-correlation).. Again, many deep <b>learning</b> libraries use the simplified cross-correlation <b>operation</b> and call it convolution \u2014 we will use the same terminology here.For readers interested in <b>learning</b> more about the mathematics behind convolution vs. cross-correlation, please refer to Chapter 3 of Computer Vision ...", "dateLastCrawled": "2022-01-30T23:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is the best <b>analogy</b> <b>for a Convolutional Neural Network that you</b> ...", "url": "https://www.quora.com/What-is-the-best-analogy-for-a-Convolutional-Neural-Network-that-you-ever-read", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-<b>analogy</b>-<b>for-a-Convolutional-Neural-Network-that</b>...", "snippet": "Answer: The following intuition was given by Prof. Yann LeCun in one of his lectures: (He explained it at a very high level, I\u2019ve filled in the details for better exposition.) Suppose you have a set of hand-coded rules for a classification task. Then, you can rewrite them in terms of AND and OR...", "dateLastCrawled": "2022-01-14T13:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep <b>Learning</b>, <b>Convolutional</b> Neural Networks and Terminal Efficiency ...", "url": "https://www.camco.be/deep-learning-convolutional-neural-networks-and-terminal-efficiency/", "isFamilyFriendly": true, "displayUrl": "https://www.camco.be/deep-<b>learning</b>-<b>convolutional</b>-neural-networks-and-terminal-efficiency", "snippet": "DEEP <b>LEARNING</b> BASED IMAGE ANALYSIS. Deep <b>learning</b> is one of many, but perhaps the most popular domain within <b>Machine</b> <b>Learning</b> (ML) and includes several technologies. When working mostly with images, <b>Convolutional</b> Neural Networks (CNN) is one of those groundbreaking technologies. Their main use is to classify, detect or segment objects in an image.", "dateLastCrawled": "2022-01-26T22:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Do convolutional neural networks work the</b> same way as the networks in ...", "url": "https://www.quora.com/Do-convolutional-neural-networks-work-the-same-way-as-the-networks-in-our-brain", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Do-convolutional-neural-networks-work-the</b>-same-way-as-the...", "snippet": "Answer: NO. For starters, we don\u2019t completely know how the human brain works and therefore, we cannot possibly argue that <b>Convolutional</b> Networks (ConvNets) work the same way as the network of neurons in the human brain does. <b>Convolutional</b> Nets and other related architectures under the deep lear...", "dateLastCrawled": "2022-01-24T14:25:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "JOURNAL OF LA <b>Learning</b> Backtrackless Aligned-Spatial Graph ...", "url": "https://arxiv.org/pdf/1904.04238.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/1904.04238.pdf", "snippet": "representations where standard <b>machine</b> <b>learning</b> techniques can be directly employed for graph classi\ufb01cation or clustering. The aim of this paper is to develop a new Graph Convolu-tional Network (GCN) model to learn effective features for graph classi\ufb01cation. Our idea is to transform arbitrary-sized graphs into \ufb01xed-sized backtrackless aligned grid structures and de\ufb01ne a new backtrackless spatial graph convolution operation associated with the grid structures. We show that the ...", "dateLastCrawled": "2021-08-20T14:43:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(convolutional operation)  is like +(sliding two filters across each other)", "+(convolutional operation) is similar to +(sliding two filters across each other)", "+(convolutional operation) can be thought of as +(sliding two filters across each other)", "+(convolutional operation) can be compared to +(sliding two filters across each other)", "machine learning +(convolutional operation AND analogy)", "machine learning +(\"convolutional operation is like\")", "machine learning +(\"convolutional operation is similar\")", "machine learning +(\"just as convolutional operation\")", "machine learning +(\"convolutional operation can be thought of as\")", "machine learning +(\"convolutional operation can be compared to\")"]}