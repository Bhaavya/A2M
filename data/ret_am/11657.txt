{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Auto-Encoder in Deep Learning</b>? | by Anushka Jain | Analytics ...", "url": "https://medium.com/analytics-vidhya/what-is-auto-encoder-in-deep-learning-5d668f94651b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/what-is-<b>auto-encoder-in-deep-learning</b>-5d668f94651b", "snippet": "Artificial Neural Network (ANN)-It is a simple mathematical model of the <b>brain</b> which is used to process nonlinear relationships between inputs and outputs in parallel <b>like</b> a <b>human</b> <b>brain</b> does every ...", "dateLastCrawled": "2022-02-02T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "With new technology, mind control is no longer <b>science</b>-fiction", "url": "https://massivesci.com/articles/brain-brain-interfaces-mind-control/", "isFamilyFriendly": true, "displayUrl": "https://massivesci.com/articles/<b>brain</b>-<b>brain</b>-interfaces-mind-control", "snippet": "<b>Encoder</b> rats were surgically implanted with recording wires that measured activity in the motor areas of their <b>brain</b>, while decoder rats were implanted with stimulating wires in the same area. Each one was kept in a separate container, and only the <b>encoder</b> rats were shown the light signal on the levers. As the <b>encoder</b> rats chose a lever, neurons in their <b>brain</b> started firing.", "dateLastCrawled": "2022-01-27T09:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Rat Minds Connected in <b>Brain</b> Interface: Is <b>Human</b> Telepathy Far Behind ...", "url": "https://www.medicaldaily.com/rat-minds-connected-brain-interface-human-telepathy-far-behind-video-244550", "isFamilyFriendly": true, "displayUrl": "https://www.medicaldaily.com/rat-minds-connected-<b>brain</b>-interface-<b>human</b>-telepathy-far...", "snippet": "The <b>encoder</b> rat was then given larger rewards when the decoder also made the right choice, so when the decoder got the task wrong, the <b>encoder</b> would move more accurately the next time so its <b>brain</b> activity became clearer for the decoder the next time. Overall, the decoder rat pressed the right lever in the task seven out of 10 times - not as successful as the 95% accuracy of the <b>encoder</b> rats, but still far better than chance. You can watch a video explaining the rat <b>brain</b> &quot;telepathy&quot; study ...", "dateLastCrawled": "2022-01-29T10:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Instance-level contrastive learning yields</b> <b>human</b> <b>brain</b>-<b>like</b> ...", "url": "https://www.biorxiv.org/content/10.1101/2020.06.15.153247v1.full.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.biorxiv.org/content/10.1101/2020.06.15.153247v1.full.pdf", "snippet": "Architecturally, we used an Alexnet as the base image <b>encoder</b> (Krizhevsky et al., 2012), replacing the 1000-dimensional output layer with a 128-dimensional fully-connected layer with an L2 norm, following Wu et al. (2018). Further, we modi\ufb01ed the Alexnet to have group norm (gn) rather than batch norm (bn) layers, which enabled successful learning (see Appendix A). And, to preview our results, this slight modi\ufb01cation had a consequential effect on emergent <b>brain</b>-<b>like</b> representation. 3 ...", "dateLastCrawled": "2022-01-20T18:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Gated Transformer for Decoding <b>Human</b> <b>Brain</b> EEG Signals", "url": "https://assets.amazon.science/11/88/6e046cba4241a06e536cc50584b2/gated-transformer-for-decoding-human-brain-eeg-signals.pdf", "isFamilyFriendly": true, "displayUrl": "https://assets.amazon.science/11/88/6e046cba4241a06e536cc50584b2/gated-transformer-for...", "snippet": "Gated Transformer for Decoding <b>Human</b> <b>Brain</b> EEG Signals Yunzhe Tao 1, Tao Sun , Aashiq Muhamed2, Sahika Gency1, Dylan Jackson2, Ali Arsanjani3, Suri Yaddanapudi 2, Liang Li and Prachi Kumar2 Abstract\u2014In this work, we propose to use a deep learn-ing framework for decoding the electroencephalogram (EEG) signals of <b>human</b> <b>brain</b> activities. More speci\ufb01cally, we learn an end-to-end model that recognizes natural images or motor imagery by the EEG data that is collected from the corre-sponding ...", "dateLastCrawled": "2022-01-31T03:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Introduction of Blue Brain (world</b>&#39;s <b>first Artificial Brain) - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/introduction-of-blue-brain-worlds-first-artificial-brain/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/introduction-of-blue-<b>brain</b>-worlds-first-artificial-<b>brain</b>", "snippet": "Main objective behind Artificial <b>brain</b> is to establish a connection in between <b>human</b> <b>brain</b> and artificial <b>brain</b> so that machine can work <b>like</b> a <b>human</b> <b>brain</b> and important content of humans <b>like</b> knowledge, feelings, memories of a person be downloaded to artificial <b>brain</b> by applying high computational algorithms using supercomputers with large storage facilities which can be used forever for different purposes until erased.", "dateLastCrawled": "2022-02-03T02:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Attention in the <b>Human Brain and Its Applications in</b> ML", "url": "https://thegradient.pub/attention-in-human-brain-and-its-applications-in-ml/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/attention-in-<b>human-brain-and-its-applications-in</b>-ml", "snippet": "The discoveries and advancements that these researchers have made have helped AI researchers understand and mimic the process(es) in the <b>human</b> <b>brain</b>. Indeed, saliency and attention are active research topics in the AI community, too. The outcome is a wide spectrum of applications ranging from better language understanding to autonomous driving. But before we can understand the AI perspective on attention, we\u2019ll first have to understand it from the neuroscience perspective.", "dateLastCrawled": "2022-01-30T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is <b>general in deep learning, neural networks, and</b> a <b>human</b> <b>brain</b> ...", "url": "https://www.quora.com/What-is-general-in-deep-learning-neural-networks-and-a-human-brain", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>general-in-deep-learning-neural-networks-and</b>-a-<b>human</b>-<b>brain</b>", "snippet": "Answer (1 of 4): Neural networks attempt to mimic part of how the <b>brain</b> is thought to work. The initial work was done based on the idea of Hebbian learning. The idea is that the learning process is based on repeated stimulation and adjustment of synaptic connections in the <b>brain</b>. Neurons generate...", "dateLastCrawled": "2022-01-17T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Brain</b> image classification by the combination of different wavelet ...", "url": "https://link.springer.com/article/10.1007/s12652-020-02299-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-020-02299-y", "snippet": "The <b>human</b> <b>brain</b> is the primary organ, and it is located in the centre of the nervous system in the <b>human</b> body. The abnormal cells in the <b>brain</b> are known as a <b>brain</b> tumor. The tumor in the <b>brain</b> does not spread to the other parts of the <b>human</b> body. Early diagnosis of <b>brain</b> tumor is required. In this work, an efficient technique is presented for magnetic resonance imaging (MRI) <b>brain</b> image classification using different wavelet transforms <b>like</b> discrete wavelet transform (DWT), stationary ...", "dateLastCrawled": "2022-02-02T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Is CD audio quality good enough for <b>human</b> ears and <b>brain</b>? Why? - Quora", "url": "https://www.quora.com/Is-CD-audio-quality-good-enough-for-human-ears-and-brain-Why", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-CD-audio-quality-good-enough-for-<b>human</b>-ears-and-<b>brain</b>-Why", "snippet": "Answer (1 of 3): For my ears, absolutely. I spent my early teenage years during the early period of filesharing. (Read: giving my PC computer-herpes because I just HAD to have that one song by that one band.) This left a bad taste in my mouth when it came to mp3 files and digitization of music. ...", "dateLastCrawled": "2022-01-13T00:51:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Non-Local <b>Auto-Encoder With Collaborative Stabilization for</b> Image ...", "url": "https://pubmed.ncbi.nlm.nih.gov/26978824/", "isFamilyFriendly": true, "displayUrl": "https://pubmed.ncbi.nlm.nih.gov/26978824", "snippet": "A pivotal property of <b>human</b> <b>brain</b> is that <b>similar</b> visual cues can stimulate the same neuron to induce <b>similar</b> neurological signals. However, conventional neural networks do not consider this property, and the resulting models are, as a result, unstable regarding their internal propagation. In this paper, we develop the (stacked) non-local auto-<b>encoder</b>, which exploits self-<b>similar</b> information in natural images for stability. We propose that <b>similar</b> inputs should induce <b>similar</b> network ...", "dateLastCrawled": "2021-02-05T17:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Attention in the <b>Human Brain and Its Applications in</b> ML", "url": "https://thegradient.pub/attention-in-human-brain-and-its-applications-in-ml/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/attention-in-<b>human-brain-and-its-applications-in</b>-ml", "snippet": "The main reason I skip a good amount of great papers in soft-attention models is that they are all <b>similar</b>: they are using <b>encoder</b>-decoder architecture in which they learn to attend to a subset of input using a scoring system. Then the transformer came in. The major difference in the transformer is, it gets rid of the recurrent network, and uses only &quot;self- attention&quot;. Transformer general architecture. The self-attention reduces computational complexity and it can learn longer dependencies ...", "dateLastCrawled": "2022-01-30T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "BrainSeg-Net: <b>Brain</b> Tumor MR Image Segmentation via Enhanced <b>Encoder</b> ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7911842/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7911842", "snippet": "1. Introduction. In modern society, diseases related to the <b>brain</b> are emerging as a big problem especially malignant <b>brain</b> tumors which are greatly influencing <b>human</b> lives [].Gliomas are the most-occurring malignant <b>brain</b> tumor, they are caused by abnormal cell transformation, and are largely classified into High-Grade Gliomas (HGG) and Low-Grade Gliomas (LGG) [].HGG are malignant tumors that have already grown; their progress has considerably deteriorated and surgery is essential.", "dateLastCrawled": "2022-01-08T15:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is <b>Auto-Encoder in Deep Learning</b>? | by Anushka Jain | Analytics ...", "url": "https://medium.com/analytics-vidhya/what-is-auto-encoder-in-deep-learning-5d668f94651b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/what-is-<b>auto-encoder-in-deep-learning</b>-5d668f94651b", "snippet": "Anushka Jain. Dec 13, 2020 \u00b7 3 min read. Auto-<b>Encoder</b> is an unsupervised learning algorithm in which artificial neural network (ANN) is designed in a way to perform task of data encoding plus ...", "dateLastCrawled": "2022-02-02T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Reconstructing faces from fMRI patterns using deep generative</b> neural ...", "url": "https://www.nature.com/articles/s42003-019-0438-y/", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42003-019-0438-y", "snippet": "A notoriously difficult problem, however, is to distinguish <b>brain</b>-activity patterns evoked by visually <b>similar</b> inputs, such as objects from the same category, or distinct <b>human</b> faces 5,6,7,8,9 ...", "dateLastCrawled": "2022-01-29T13:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Learn Neural Networks and Deep Learning with Python", "url": "https://www.techlearn.live/course/learn-neural-networks-and-deep-learning-with-python", "isFamilyFriendly": true, "displayUrl": "https://www.techlearn.live/course/learn-neural-networks-and-deep-learning-with-python", "snippet": "Why Machine Learning fails for large dataset, introduction to deep learning, Neurons, neural networks, how they are <b>similar</b> <b>to human</b> <b>brain</b>. Not Scheduled | 60 min. Artificial Neural Networks - 1. Understanding artificial neural networks, neurons, input layers, output layers, wights, bias, activation functions. Case study on ANN. Not Scheduled | 60 min. Artificial Neural Networks - 2. Working of neural networks, forward propagation and backward propagation, deep layered neural networks Case ...", "dateLastCrawled": "2022-01-30T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Catalyst.Neuro: A 3D <b>Brain</b> Segmentation Pipeline for MRI | by Catalyst ...", "url": "https://medium.com/pytorch/catalyst-neuro-a-3d-brain-segmentation-pipeline-for-mri-b1bb1109276a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/pytorch/catalyst-neuro-a-3d-<b>brain</b>-segmentation-pipeline-for-mri-b1...", "snippet": "<b>Human</b> Connectome Project MRIs and FreeSurfer Labels. Due to the previously mentioned time and expense of manual labeling, the de facto standard for <b>brain</b> segmentation is automated tools.", "dateLastCrawled": "2022-01-26T10:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Mental imagery in the <b>human</b> <b>brain</b>: In space and time", "url": "https://fundacaobial.com/media/1608/mental-imagery-in-the-human-brain.pdf", "isFamilyFriendly": true, "displayUrl": "https://fundacaobial.com/media/1608/mental-imagery-in-the-<b>human</b>-<b>brain</b>.pdf", "snippet": "Mental imagery in the <b>human</b> <b>brain</b>: In space and time ABSTRACT: Background Mental imagery is the ability to voluntarily generate internal representations via topdown modulation, without any concurrent bottom-up input. Aims While viewed and imagined objects from different categories can be reliably decoded from fMRI <b>brain</b> response patterns, it has proved more difficult to distinguish visually <b>similar</b> inputs, such as different instances of the same category. Here, we aimed to reconstruct the ...", "dateLastCrawled": "2022-01-14T18:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Image reconstruction from <b>human</b> <b>brain</b> activity - GitHub", "url": "https://github.com/MariaPdg/thesis-fmri-reconstruction", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/MariaPdg/thesis-fmri-reconstruction", "snippet": "Image reconstruction from <b>human</b> <b>brain</b> activity is one of the central problems in <b>brain</b> decoding towards reproducing mental content and exploring the <b>human</b> visual system contributing to the detection and prevention of visual diseases. For the past few years, significant achievements in the fields of functional Magnetic Reasoning Imaging (fMRI) and artificial intelligence (AI) facilitated researchers to explore the <b>human</b> <b>brain</b> on a new level. The problem of reconstruction from fMRI is ...", "dateLastCrawled": "2022-01-25T19:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Semantic Similarity using Universal Sentence <b>Encoder</b> - Bits and Paradoxes", "url": "https://nish1001.github.io/programming/universal-sentence-encoder-semantic-search.html", "isFamilyFriendly": true, "displayUrl": "https://nish1001.github.io/programming/universal-sentence-<b>encoder</b>-semantic-search.html", "snippet": "Here I demonstrate how powerful sentence embeddings from Universal Sentence <b>Encoder</b> are. I have a bunch of textual data and query in an arbitary text to find the nearest match that is semantically <b>similar</b>. I am not diving into the architecture of the model itself. But rather focus its usecase for end-user. The notebook can be found here. Important Stuff. import numpy as np import tensorflow as tf import tensorflow_hub as hub import nltk import re. Universal Sentence <b>Encoder</b>. It is the model ...", "dateLastCrawled": "2022-01-04T12:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Brain Encoding and Decoding</b> in fMRI with Bidirectional Deep Generative ...", "url": "https://www.sciencedirect.com/science/article/pii/S2095809917305647", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2095809917305647", "snippet": "The relationship between <b>human</b> visual experience and the evoked neural activity is central to the field of computational neuroscience , .<b>Brain encoding and decoding</b> via functional magnetic resonance imaging (fMRI) are important in gaining an understanding of the visual perception system , , .An encoding model attempts to predict <b>brain</b> response based on a given visual stimulus , , whereas a decoding model attempts to predict the corresponding visual stimulus by analyzing a given <b>brain</b> ...", "dateLastCrawled": "2022-01-26T22:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "With new technology, mind control is no longer <b>science</b>-fiction", "url": "https://massivesci.com/articles/brain-brain-interfaces-mind-control/", "isFamilyFriendly": true, "displayUrl": "https://massivesci.com/articles/<b>brain</b>-<b>brain</b>-interfaces-mind-control", "snippet": "<b>Encoder</b> rats were surgically implanted with recording wires that measured activity in the motor areas of their <b>brain</b>, while decoder rats were implanted with stimulating wires in the same area. Each one was kept in a separate container, and only the <b>encoder</b> rats were shown the light signal on the levers. As the <b>encoder</b> rats chose a lever, neurons in their <b>brain</b> started firing.", "dateLastCrawled": "2022-01-27T09:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Memory Encoding</b> | Memory Processes Storage &amp; Retrieval", "url": "https://human-memory.net/memory-encoding/", "isFamilyFriendly": true, "displayUrl": "https://<b>human</b>-memory.net/<b>memory-encoding</b>", "snippet": "In stage three, there is more activity in the left interior region of the <b>brain</b>. These activities are <b>thought</b> to access semantic memory which is elicited by meaningful information. Younger adults encode memories with relative ease. The processing speed, working memory, and ability to perceive things correctly is better in younger people. <b>Brain</b> activity has been seen at its peak in early life years and it declines in the later stages of life. That is why younger adults <b>can</b> learn and encode ...", "dateLastCrawled": "2022-02-02T06:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>BRAIN</b> Publication Roundup \u2013 July 2020 | <b>BRAIN</b> Blog", "url": "https://brainblog.nih.gov/brain-blog/brain-publication-roundup-july-2020", "isFamilyFriendly": true, "displayUrl": "https://<b>brain</b>blog.nih.gov/<b>brain</b>-blog/<b>brain</b>-publication-roundup-july-2020", "snippet": "<b>Encoder</b>-decoder framework translates <b>human</b> cortical activity to text. Skip to main content U.S Department of Health and <b>Human</b> Services ... University showed that the neurobiological changes associated with aging are observed at a younger age than previously <b>thought</b> and that this process <b>can</b> be prevented or reversed by a diet low in carbohydrates. First, Dr. Mujica-Parodi and her team used two large-scale <b>human</b> fMRI datasets from 928 individuals across the life span (ages 18 to 88) to ...", "dateLastCrawled": "2022-01-25T12:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Future soldiers to use synthetic telepathy on the battlefield or <b>Brain</b> ...", "url": "https://idstch.com/technology/biosciences/future-soldiers-to-use-synthetic-telepathy-on-the-battlefield-or-brain-to-brain-communication-enabled-by-brain-to-brain-interfaces-bbi/", "isFamilyFriendly": true, "displayUrl": "https://idstch.com/technology/biosciences/future-soldiers-to-use-synthetic-telepathy...", "snippet": "<b>Brain</b> to <b>Brain</b> Communication in Humans. In November of 2014, the first real-time BBI for humans was developed by Rajesh Rao and colleagues at the University of Washington. The <b>human</b> device was non-invasive, meaning surgery wasn\u2019t required. This device transferred the movement signals from the <b>encoder</b> straight to the motor area of the <b>brain</b> of ...", "dateLastCrawled": "2022-02-01T10:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Human</b> Emotion Recognition: Review of Sensors and Methods", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7037130/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7037130", "snippet": "As all reactions in the <b>human</b> body are controlled by electric signals generated in the central nervous system, we <b>can</b> state that electric parameters are primary entities, which gives mostly precise results, and the measurement of non-electrical signals give reactions of the <b>human</b> body affected by electric signals. On the other hand, electrical signals <b>can</b> be measured using only contact measurement methods, and of course there is the possibility to send a signal to an acquisition unit using ...", "dateLastCrawled": "2022-02-02T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to Retain Information and Facilitate Your Learning", "url": "https://memoryos.com/article/how-to-retain-information-and-facilitate-your-learning", "isFamilyFriendly": true, "displayUrl": "https://memoryos.com/article/how-to-retain-information-and-facilitate-your-learning", "snippet": "The <b>brain</b> <b>can</b> retain information and facilitate learning if there is constant engagement in intellectual fitness and cognitive exercises. Thus, new powerful connections will develop and improve your <b>brain</b>&#39;s ability to retain information and, most importantly, utilize what was learned. \u200dA <b>human</b> <b>brain</b> is exposed to tons of new information daily. Millions of bits <b>can</b> be processed by our unconscious mind. However, only a small amount of that information <b>can</b> be handled consciously. If you want ...", "dateLastCrawled": "2022-01-30T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Hyperphantasia: The Truth About Photorealistic Imagination", "url": "https://memoryos.com/article/hyperphantasia-revealing-the-truth-about-photorealistic-imagination", "isFamilyFriendly": true, "displayUrl": "https://memoryos.com/article/hyperphantasia-revealing-the-truth-about-photorealistic...", "snippet": "The <b>human</b> <b>brain</b> is an ongoing mystery. Many scientists have dedicated their careers to closely analyzing and understanding a unique phenomenon within the <b>human</b> <b>brain</b>, known as photorealistic imagination. \u200dAn individual who has a photorealistic imagination is found to have extremely high levels of imagination, meaning one has an impressive ability to see with the mind&#39;s eye and visualize an endless array of situations and environments, also known as hyperphantasia symptoms. \u200dHowever, an ...", "dateLastCrawled": "2022-02-02T06:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Converting <b>Feeling/Thought to Text using Brain Waves(EEG</b>) | by Ambuje ...", "url": "https://medium.com/analytics-vidhya/feeling-thought-to-text-using-brain-waves-eeg-4ba8ba0565ac", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>feeling-thought-to-text-using-brain-waves-eeg</b>-4ba8...", "snippet": "It has a wider research opportunities for <b>thought</b> to text and voiceless communication. Information about values EEG device extracts It collects data from 4 nodes of our <b>brain</b>, TP9,AF7,AF8,TP10.", "dateLastCrawled": "2021-12-21T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Scientists develop AI that <b>can turn brain activity into text</b> ...", "url": "https://www.theguardian.com/science/2020/mar/30/scientists-develop-ai-that-can-turn-brain-activity-into-text", "isFamilyFriendly": true, "displayUrl": "https://<b>www.theguardian.com</b>/science/2020/mar/30/scientists-develop-ai-that-<b>can</b>-turn...", "snippet": "Last modified on Thu 2 Apr 2020 05.08 EDT. Reading minds has just come a step closer to reality: scientists have developed artificial intelligence that <b>can turn brain activity into text</b>. While the ...", "dateLastCrawled": "2022-01-30T22:11:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Novel <b>Encoder</b>-Decoder Knowledge Graph Completion Model for Robot <b>Brain</b>", "url": "https://pubmed.ncbi.nlm.nih.gov/34045950/", "isFamilyFriendly": true, "displayUrl": "https://pubmed.ncbi.nlm.nih.gov/34045950", "snippet": "The knowledge graph <b>can</b> act as the <b>brain</b> of a robot and provide intelligence, to support the interaction between the robot and the <b>human</b> beings. Although the large-scale knowledge graphs contain a large amount of information, they are still incomplete <b>compared</b> with real-world knowledge. Most existing methods for knowledge graph completion focus on entity representation learning. However, the importance of relation representation learning is ignored, as well as the cross-interaction between ...", "dateLastCrawled": "2021-11-08T04:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "BrainSeg-Net: <b>Brain</b> Tumor MR Image Segmentation via Enhanced <b>Encoder</b> ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7911842/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7911842", "snippet": "BrainSeg-Net has expressed a viable improvement in the results when <b>compared</b> with existing state-of-the-art semantic segmentation techniques for MR <b>brain</b> tumor images. The proposed BrainSeg-Net has also outperformed its baseline U-Net architecture. In future, we intend to improve this architecture further so that it <b>can</b> prove to be beneficial for <b>human</b> lives. The 2D U-Net has the restriction of important information loss in comparison to 3D U-Net. We have an intention to extend our research ...", "dateLastCrawled": "2022-01-08T15:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Novel <b>Encoder</b>-Decoder Knowledge Graph Completion Model for Robot <b>Brain</b>", "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2021.674428/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fnbot.2021.674428", "snippet": "The knowledge graph <b>can</b> act as the <b>brain</b> of a robot and provide intelligence, to support the interaction between the robot and the <b>human</b> beings. Although the large-scale knowledge graphs contain a large amount of information, they are still incomplete <b>compared</b> with the real world knowledge. Most existing methods for knowledge graph completion focus on entity representation learning. However, the importance of relation representation learning is ignored, as well the cross-interaction between ...", "dateLastCrawled": "2022-02-01T20:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Dynamic Electrode-to-Image (DETI) mapping reveals the <b>human</b> <b>brain</b>\u2019s ...", "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009456", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009456", "snippet": "The code to build the encoders and generate the <b>encoder</b> space <b>can</b> be downloaded here https://pbsc.colgate.edu ... The central portion of image space shows two waves of HSFs, with the first wave more centralized than the second. When <b>compared</b> to Fig 6, the first wave corresponds to 2\u20134 cpd, with the spatially broader wave corresponding to 8 cpd. The column-wise marginal analysis revealed additional asymmetries that were observed laterally across images with LSFs showing an early (~70 ms ...", "dateLastCrawled": "2021-09-27T23:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A self-supervised deep neural network for image completion resembles ...", "url": "https://pubmed.ncbi.nlm.nih.gov/34259828/", "isFamilyFriendly": true, "displayUrl": "https://pubmed.ncbi.nlm.nih.gov/34259828", "snippet": "Here, we investigated similarities between <b>human</b> early visual cortex and a CNN with <b>encoder</b>/decoder architecture, trained with self-supervised learning to fill occlusions and reconstruct an unseen image. Using representational similarity analysis (RSA), we <b>compared</b> 3T functional magnetic resonance imaging (fMRI) data from a nonstimulated patch of early visual cortex in <b>human</b> participants viewing partially occluded images, with the different CNN layer activations from the same images. Results ...", "dateLastCrawled": "2021-12-21T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Encoder</b>-Decoder Optimization for <b>Brain-Computer Interfaces</b>", "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004288", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004288", "snippet": "Author Summary <b>Brain-computer interfaces</b> are systems which allow a user to control a device in their environment via their neural activity. The system consists of hardware used to acquire signals from the <b>brain</b> of the user, algorithms to decode the signals, and some effector in the world that the user will be able to control, such as a cursor on a computer screen. When the user <b>can</b> see the effector under control, the system is closed-loop, such that the user <b>can</b> learn based on discrepancies ...", "dateLastCrawled": "2021-05-03T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep Learning <b>Human</b> Mind for Automated Visual Classification \u2013 Center ...", "url": "https://www.crcv.ucf.edu/research/deep-learning-human-mind-for-automated-visual-classification/", "isFamilyFriendly": true, "displayUrl": "https://www.crcv.ucf.edu/research/deep-learning-<b>human</b>-mind-for-automated-visual...", "snippet": "Afterward, we transfer the learned capabilities to machines by training a Convolutional Neural Network (CNN)\u2013based regressor to project images onto the learned manifold, thus allowing machines to employ <b>human</b> <b>brain</b>\u2013based features for automated visual classification. We use a 128-channel EEG with active electrodes to record <b>brain</b> activity of several subjects while looking at images of 40 ImageNet object classes. The proposed RNN-based approach for discriminating object classes using <b>brain</b> ...", "dateLastCrawled": "2022-01-29T13:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Gated Transformer for Decoding <b>Human</b> <b>Brain</b> EEG Signals", "url": "https://assets.amazon.science/11/88/6e046cba4241a06e536cc50584b2/gated-transformer-for-decoding-human-brain-eeg-signals.pdf", "isFamilyFriendly": true, "displayUrl": "https://assets.amazon.science/11/88/6e046cba4241a06e536cc50584b2/gated-transformer-for...", "snippet": "the image classi\ufb01cation task for a <b>human</b> <b>brain</b>-visual dataset and the classi\ufb01cation task for a motor imagery dataset. The experimental results show that our method achieves new state-of-the-art performance <b>compared</b> to multiple existing methods that are widely used for EEG classi\ufb01cation. I. INTRODUCTION Recently, the research on <b>brain</b>-computer interfaces (BCIs) has been an area of high public awareness. The main goal of BCI is to restore or provide assistance on some useful func-tions ...", "dateLastCrawled": "2022-01-31T03:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>BRAIN</b> Publication Roundup \u2013 July 2020 | <b>BRAIN</b> Blog", "url": "https://brainblog.nih.gov/brain-blog/brain-publication-roundup-july-2020", "isFamilyFriendly": true, "displayUrl": "https://<b>brain</b>blog.nih.gov/<b>brain</b>-blog/<b>brain</b>-publication-roundup-july-2020", "snippet": "SnRNA-seq is a valuable tool for classifying and characterizing <b>human</b> <b>brain</b> cells because it <b>can</b> be used on postmortem frozen tissue and it enables the alignment of cell type datasets across <b>brain</b> areas and species. By using this method, researchers identified 13 excitatory neuron types and found that VENs <b>can</b> be localized to a single transcriptomic cell type. This classification included cells with fork and pyramidal morphologies, however, researchers also identified new genetic markers for ...", "dateLastCrawled": "2022-01-25T12:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Representation Learning and Translation between</b> the Mouse and <b>Human</b> ...", "url": "https://icml-compbio.github.io/icml-website-2020/2020/papers/WCBICML2020_paper_29.pdf", "isFamilyFriendly": true, "displayUrl": "https://icml-compbio.github.io/icml-website-2020/2020/papers/WCBICML2020_paper_29.pdf", "snippet": "<b>Representation Learning and Translation between</b> the Mouse and <b>Human</b> <b>Brain</b> using a Deep Transformer Architecture Minxing Pang1 Jesper Tegn\u00b4er 1 2 Abstract Recent progress in single-cell genomics has pro- duced large single-cell data-sets of cell-types and organs from mouse and <b>human</b> samples. Since it is still dif\ufb01cult to transfer data across species we conceptualize this problem as language trans-lation task between mouse and <b>human</b>, requiring a latent space in which we <b>can</b> translate accord ...", "dateLastCrawled": "2022-01-09T23:15:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "9.6. <b>Encoder-Decoder</b> Architecture \u2014 Dive into Deep <b>Learning</b> 0.17.2 ...", "url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_recurrent-modern/<b>encoder-decoder</b>.html", "snippet": "<b>Encoder-Decoder</b> Architecture \u2014 Dive into Deep <b>Learning</b> 0.17.0 documentation. 9.6. <b>Encoder-Decoder</b> Architecture. As we have discussed in Section 9.5, <b>machine</b> translation is a major problem domain for sequence transduction models, whose input and output are both variable-length sequences. To handle this type of inputs and outputs, we can design ...", "dateLastCrawled": "2022-01-30T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/341668539_Towards_Analogy-Based_Explanations_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341668539_Towards_<b>Analogy</b>-Based_Explanations...", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that ...", "dateLastCrawled": "2022-01-06T06:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Solving Word <b>Analogies: A Machine Learning Perspective</b> | Request PDF", "url": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_Machine_Learning_Perspective", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_<b>Machine</b>...", "snippet": "We introduce a supervised corpus-based <b>machine</b> <b>learning</b> algorithm for classifying analogous word pairs, and we show that it can solve multiple-choice SAT <b>analogy</b> questions, TOEFL synonym questions ...", "dateLastCrawled": "2021-10-16T21:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Titanic \u2014 Predicting Survival rates using <b>Machine</b> <b>Learning</b> | by Punith ...", "url": "https://medium.com/codex/titanic-predicting-survival-rates-using-machine-learning-3e83c56af29f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/codex/titanic-predicting-survival-rates-using-<b>machine</b>-<b>learning</b>-3e83...", "snippet": "Label <b>Encoder</b> refers to converting the labels into numeric form so as to convert it into the <b>machine</b> readable form. <b>Machine</b> <b>learning</b> algorithms can then decide in a better way on how those labels ...", "dateLastCrawled": "2022-02-03T01:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Unsupervised <b>learning</b> \u2013 self <b>encoder</b> | deep <b>learning</b> (Li Hongyi) (19 ...", "url": "https://developpaper.com/unsupervised-learning-self-encoder-deep-learning-li-hongyi-19/", "isFamilyFriendly": true, "displayUrl": "https://developpaper.com/unsupervised-<b>learning</b>-self-<b>encoder</b>-deep-<b>learning</b>-li-hongyi-19", "snippet": "Auto <b>encoder</b> is an unsupervised <b>learning</b> method, which can be used to reduce the dimension of data. For our input data, we can obtain a low dimensional code through an <b>encoder</b>, and then reconstruct the original data through a decoder, which is trained together. The following figure shows this process by taking a handwritten digital data set as an example: Auto-<b>encoder</b>. <b>Analogy</b> PCA; In PCA, we put the data Multiply by a matrix Then we get the representation of low dimension, and we will ...", "dateLastCrawled": "2022-01-25T17:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Usage: In fraud detection, use Auto-<b>Encoder</b> to compress all data to dense vector, then kNN is used to detect outliers; Reinforcement <b>Learning</b> Definitions. Reinforcement <b>learning</b> (RL) is an area of <b>machine</b> <b>learning</b> that focuses on how agent to act in an environment in order to maximize some given reward. Markov Decision Processes (MDPs) Components", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The conceptual arithmetics of concepts | by Assaad MOAWAD | DataThings ...", "url": "https://medium.com/datathings/the-conceptual-arithmetics-of-concepts-369df29e4e0f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/datathings/the-conceptual-arithmetics-of-concepts-369df29e4e0f", "snippet": "<b>Machine</b> <b>learning</b> field is an amazing and very fast evolving domain. However, it is still hard to use it in its current state due to its cost and complexity. With time, we will have more and more ...", "dateLastCrawled": "2022-01-04T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Transformers in NLP: A beginner friendly explanation | Towards Data Science", "url": "https://towardsdatascience.com/transformers-89034557de14", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>transformer</b>s-89034557de14", "snippet": "<b>Encoder</b>-Decoder Attention: Attention between the input sequence and the output sequence. ... If you are looking for an <b>analogy</b> between self attention and attention, think of z serving the purpose of context vectors and not global alignment weights. The <b>Transformer</b>. \u26a0\ufe0f A word of caution: the contents of this image may appear exponentially more complicated than they are. We will break this scary beast down into small baby beasts and it will all make sense. (I promise #2) (left) The ...", "dateLastCrawled": "2022-02-02T13:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> <b>Learning</b> <b>Logistic Regression</b> with Python and Scikit-learn | by ...", "url": "https://dmarcisovska.medium.com/machine-learning-logistic-regression-with-python-and-scikit-learn-f278843aca4e", "isFamilyFriendly": true, "displayUrl": "https://dmarcisovska.medium.com/<b>machine</b>-<b>learning</b>-<b>logistic-regression</b>-with-python-and...", "snippet": "Many <b>machine</b> <b>learning</b> algorithms perform better when numerical data is scaled to a standard range. Data may have different units (such as year, hours, months, USD Dollar, etc.) which may mean the variables have different scales. Differences in the scales across our data may increase the difficulty of the problem being modeled. Standardizing a dataset involves rescaling the distribution of data so that the mean of observed values is 0 and the standard deviation is 1.", "dateLastCrawled": "2022-01-14T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - What is an <b>autoencoder</b>? - Data Science Stack Exchange", "url": "https://datascience.stackexchange.com/questions/80389/what-is-an-autoencoder", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/80389", "snippet": "I am a student and I am studying <b>machine</b> <b>learning</b>. I am focusing on deep generative models, and in particular to autoencoders and variational autoencoders (VAE).. I am trying to understand the concept, but I am having some problems. So far, I have understood that an <b>autoencoder</b> takes an input, for example an image, and wants to reduce this image into a latent space, which should contain the underlying features of the dataset, with an operation of encoding, then, with an operation of decoding ...", "dateLastCrawled": "2022-01-26T06:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Gentle Introduction to <b>LSTM Autoencoders</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/lstm-autoencoders/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>lstm-autoencoders</b>", "snippet": "This is challenging because <b>machine</b> <b>learning</b> algorithms, and neural networks in particular, are designed to work with fixed length inputs. Another challenge with sequence data is that the temporal ordering of the observations can make it challenging to extract features suitable for use as input to supervised <b>learning</b> models, often requiring deep expertise in the domain or in the field of signal processing. Finally, many predictive modeling problems involving sequences require a prediction ...", "dateLastCrawled": "2022-02-03T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>machine</b> <b>learning</b> - <b>Parameters tuning for auto-encoders</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/235114/parameters-tuning-for-auto-encoders", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/235114/<b>parameters-tuning-for-auto-encoders</b>", "snippet": "Actually, the cost function of a sparse auto-<b>encoder is like</b>. I tested with my datasets, it seems that all these four parameters have impact on the final results. Are there any general rules of &#39;optimal&#39; settings of these four parameters? When I was using Support Vector <b>Machine</b> based classifier, there is a &#39;grid search&#39; method to optimize the two hyper-parameters of the SVM. Are there any similar method available for (sparse) auto-encoders? As far as I see, grid search is feasible to ...", "dateLastCrawled": "2022-01-28T00:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Log Data Anomaly Detection Using a <b>Machine</b> <b>Learning</b> Model", "url": "https://insights.ltts.com/story/log-data-anomaly-detection-using-a-machine-learning-model/page/1", "isFamilyFriendly": true, "displayUrl": "https://insights.ltts.com/story/log-data-anomaly-detection-using-a-<b>machine</b>-<b>learning</b>...", "snippet": "In this paper, we have explored various <b>machine</b> <b>learning</b> algorithms and an auto encoder to detect anomalies which can help the developers to quickly identify and derive relevant and appropriate information from the logs maintained. &lt;small&gt;An Industry Perspective. System Logs: An Industry Perspective . There are multiple examples of system generated logs in use: Events of logs generated from server application ; A database system maintaining transaction logs which could be used for ...", "dateLastCrawled": "2022-01-26T20:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>The security of machine learning</b> - researchgate.net", "url": "https://www.researchgate.net/publication/220343885_The_security_of_machine_learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220343885_<b>The_security_of_machine_learning</b>", "snippet": "In particular, self-supervised <b>learning</b> aims to pre-train an encoder using a large amount of unlabeled data. The pre-trained <b>encoder is like</b> an &quot;operating system&quot; of the AI ecosystem. In ...", "dateLastCrawled": "2022-01-12T09:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Summary of \u2014 <b>SegNet</b>: <b>A Deep Convolutional Encoder-Decoder</b> Architecture ...", "url": "https://towardsdatascience.com/summary-of-segnet-a-deep-convolutional-encoder-decoder-architecture-for-image-segmentation-75b2805d86f5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/summary-of-<b>segnet</b>-<b>a-deep-convolutional-encoder-decoder</b>...", "snippet": "Fig 3: Encoder architecture. Each <b>encoder is like</b> Fig 3. The novelty is in the subsampling stage, Max-pooling is used to achieve translation invariance over small spatial shifts in the image, combine that with Subsampling and it leads to each pixel governing a larger input image context (spatial window). These methods achieve better classification accuracy but reduce the feature map size, this leads to lossy image representation with blurred boundaries which is not ideal for segmentation ...", "dateLastCrawled": "2022-01-30T01:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>machine</b> <b>learning</b> - What is the input for the prior model of VQ-VAE ...", "url": "https://ai.stackexchange.com/questions/17203/what-is-the-input-for-the-prior-model-of-vq-vae", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/17203", "snippet": "<b>machine</b>-<b>learning</b> generative-model variational-autoencoder. Share. Improve this question. Follow asked Dec 22 &#39;19 at 6:08. Diego Gomez Diego Gomez. 393 3 3 silver badges 9 9 bronze badges $\\endgroup$ Add a comment | 1 Answer Active Oldest Votes. 0 $\\begingroup$ Some notes about VQ-VAE: In the paper, they used PixelCNN to learn the prior. PixelCNN is trained on images. The discrete latent variables are just the indices of the embedding vectors. For example, you can put your embedding vectors ...", "dateLastCrawled": "2022-01-07T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "probability - why a denoising auto-<b>encoder is like</b> performing ...", "url": "https://math.stackexchange.com/questions/2318301/why-a-denoising-auto-encoder-is-like-performing-stochastic-gradient-this-on-this", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/2318301", "snippet": "why a denoising auto-<b>encoder is like</b> performing stochastic gradient this on this expression? Ask Question Asked 4 years, 7 months ago. Active 4 years, 7 months ago. Viewed 665 times 2 1 $\\begingroup$ I was reading ...", "dateLastCrawled": "2022-01-24T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[2110.15444] 10 Security and Privacy Problems in Self-Supervised <b>Learning</b>", "url": "https://arxiv.org/abs/2110.15444", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2110.15444", "snippet": "The pre-trained <b>encoder is like</b> an &quot;operating system&quot; of the AI ecosystem. Specifically, the encoder can be used as a feature extractor for many downstream tasks with little or no labeled training data. Existing studies on self-supervised <b>learning</b> mainly focused on pre-training a better encoder to improve its performance on downstream tasks in non-adversarial settings, leaving its security and privacy in adversarial settings largely unexplored. A security or privacy issue of a pre-trained ...", "dateLastCrawled": "2021-12-28T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Convolutional Coding</b> - GaussianWaves", "url": "https://www.gaussianwaves.com/2010/06/convolutional-coding-2/", "isFamilyFriendly": true, "displayUrl": "https://www.gaussianwaves.com/2010/06/<b>convolutional-coding</b>-2", "snippet": "Till now the <b>encoder is like</b> a black box to us in the sense that we don\u2019t know how the memory elements are utilized to generate the output bits from the input. To fully understand the encoder structure we need something called \u201cgenerator polynomials\u201d that tell us how the memory elements are linked to achieve encoding. The generator polynomials for a specific convolutional encoder set (n,k,L) are usually found through simulation. The set (n,k,L) along with n generator polynomials ...", "dateLastCrawled": "2022-01-09T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[2110.15444v2] 10 Security and Privacy Problems in Self-Supervised <b>Learning</b>", "url": "https://arxiv.org/abs/2110.15444v2", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2110.15444v2", "snippet": "Self-supervised <b>learning</b> has achieved revolutionary progress in the past several years and is commonly believed to be a promising approach for general-purpose AI. In particular, self-supervised <b>learning</b> aims to pre-train an encoder using a large amount of unlabeled data. The pre-trained <b>encoder is like</b> an &quot;operating system&quot; of the AI ecosystem. Specifically, the encoder can be used as a feature extractor for many downstream tasks with little or no labeled training data. Existing studies on ...", "dateLastCrawled": "2021-11-08T02:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Categorical Encoding with CatBoost Encoder</b> - GeeksforGeeks", "url": "https://www.geeksforgeeks.org/categorical-encoding-with-catboost-encoder/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/<b>categorical-encoding-with-catboost-encoder</b>", "snippet": "Many <b>machine</b> <b>learning</b> algorithms require data to be numeric. So, before training a model, we need to convert categorical data into numeric form. There are various categorical encoding methods available. Catboost is one of them. Catboost is a target-based categorical encoder. It is a supervised encoder that encodes categorical columns according to the target value. It supports binomial and continuous targets. Target encoding is a popular technique used for categorical encoding. It replaces a ...", "dateLastCrawled": "2022-02-03T12:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Implementing an <b>Autoencoder</b> in TensorFlow 2.0 | by Abien Fred Agarap ...", "url": "https://towardsdatascience.com/implementing-an-autoencoder-in-tensorflow-2-0-5e86126e9f7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/implementing-an-<b>autoencoder</b>-in-tensorflow-2-0-5e86126e9f7", "snippet": "We deal with huge amount of data in <b>machine</b> <b>learning</b> which naturally leads to more computations. However, we can also just pick the parts of the data that contribute the most to a model\u2019s <b>learning</b>, thus leading to less computations. The process of choosing the important parts of the data is known as feature selection, which is among the number of use cases for an <b>autoencoder</b>. But what exactly is an <b>autoencoder</b>? Well, let\u2019s first recall that a neural network is a computational model that ...", "dateLastCrawled": "2022-02-03T07:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "An Introduction to Generative <b>Deep Learning</b> | by Anil Chandra Naidu ...", "url": "https://medium.com/analytics-vidhya/an-introduction-to-generative-deep-learning-792e93d1c6d4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/an-introduction-to-generative-<b>deep-learning</b>-792e93...", "snippet": "An autoencoder is a type of ANN used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for ...", "dateLastCrawled": "2022-01-29T19:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Implementing an <b>Autoencoder</b> in TensorFlow 2.0 - Abien Fred Agarap", "url": "https://afagarap.github.io/2019/03/20/implementing-autoencoder-in-tensorflow-2.0.html", "isFamilyFriendly": true, "displayUrl": "https://afagarap.github.io/2019/03/20/implementing-<b>autoencoder</b>-in-tensorflow-2.0.html", "snippet": "Google announced a major upgrade on the world\u2019s most popular open-source <b>machine</b> <b>learning</b> library, TensorFlow, with a promise of focusing on simplicity and ease of use, eager execution, intuitive high-level APIs, and flexible model building on any platform. This post is a humble attempt to contribute to the body of working TensorFlow 2.0 examples. Specifically, we shall discuss the subclassing API implementation of an <b>autoencoder</b>. To install TensorFlow 2.0, use the following pip install ...", "dateLastCrawled": "2022-01-31T12:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Encoding</b> <b>categorical</b> variables - Stacked Turtles", "url": "https://kiwidamien.github.io/encoding-categorical-variables.html", "isFamilyFriendly": true, "displayUrl": "https://kiwidamien.github.io/<b>encoding</b>-<b>categorical</b>-variables.html", "snippet": "The way you encode <b>categorical</b> variables changes how effective your <b>machine</b> <b>learning</b> algorithm is. This article will go over some common <b>encoding</b> techniques, as well as their advantages and disadvantages. Some terminology. Levels: A levels of a non-numeric feature are the number of distinct values. The examples listed above are all examples of levels. The number of levels can vary wildly: the number of races for a patient is typically four (asian, black, hispanic, and white), the number of ...", "dateLastCrawled": "2022-01-30T23:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Network of Networks \u2014 A Neural-Symbolic Approach to Inverse-Graphics ...", "url": "https://towardsdatascience.com/network-of-networks-a-neural-symbolic-approach-to-inverse-graphics-acf3998ab3d", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/network-of-networks-a-neural-symbolic-approach-to...", "snippet": "The most common place one finds this kind of approach is in automated <b>machine</b> <b>learning</b> ... We assume, at least at the beginning, that our <b>encoder is similar</b> to a mean function. Obviously, with such a general mean function, any configuration of [Triangle] and [Square] would make a valid [House]. We don\u2019t want that. Let\u2019s again create an encoder-decoder pair with an agreement function. This time, we need to train the decoder instead of the encoder, but we\u2019ll train it on real houses. Now ...", "dateLastCrawled": "2022-01-31T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Hands-on with Feature Engineering Techniques</b>: Advanced Methods | by ...", "url": "https://heartbeat.comet.ml/hands-on-with-feature-engineering-advanced-methods-in-python-for-machine-learning-e05bf12da06a", "isFamilyFriendly": true, "displayUrl": "https://heartbeat.comet.ml/<b>hands-on-with-feature-engineering</b>-advanced-methods-in...", "snippet": "This post is a part of a series about <b>feature engineering techniques</b> for <b>machine</b> <b>learning</b> with Python. You can check out the rest of the articles: <b>Hands-on with Feature Engineering Techniques</b>: Broad Introduction. <b>Hands-on with Feature Engineering Techniques</b>: Variable Types. <b>Hands-on with Feature Engineering Techniques</b>: Common Issues in Datasets. <b>Hands-on with Feature Engineering Techniques</b>: Imputing Missing Values. <b>Hands-on with Feature Engineering Techniques</b>: Encoding Categorical Variables ...", "dateLastCrawled": "2022-02-01T14:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fully Convolutional Refined Auto-Encoding Generative Adversarial ...", "url": "https://becominghuman.ai/3d-multi-object-gan-7b7cee4abf80", "isFamilyFriendly": true, "displayUrl": "https://becominghuman.ai/<b>3d-multi-object-gan</b>-7b7cee4abf80", "snippet": "The basic architecture of <b>encoder is similar</b> to discriminator network of 3DGAN[1]. The difference is the last layer which is 1x1x1 fully convolution.-Generator. The basic architecture of generator is also similar to 3DGAN[1] as above figure. The difference is the last layer which has 12 channels and is activated by softmax. Also, the first layer of latent space is flatten. -Discriminator. The basic architecture of discriminator is also similar to 3DGAN[1]. The difference is the activation ...", "dateLastCrawled": "2022-01-26T00:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Frontiers | Deep <b>Learning</b> for Understanding <b>Satellite Imagery</b>: An ...", "url": "https://www.frontiersin.org/articles/10.3389/frai.2020.534696/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/frai.2020.534696", "snippet": "The left half of the network (<b>encoder) is similar</b> to a CNN, tasked with coming up with a low dimensional dense representation of the input, and the right side (decoder) then up-samples the learned feature representations to the same shape as the input. The shortcut connections let information flow from the encoder to the decoder and help the network keeping spatial information. As the work of Li et al. (2017) has impressively shown, U-Nets benefit greatly from a deeper model architecture. It ...", "dateLastCrawled": "2022-01-31T16:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Deep <b>learning for smart manufacturing: Methods and applications</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0278612518300037", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0278612518300037", "snippet": "Typical <b>machine</b> <b>learning</b> techniques are reviewed in [, ] for intelligent manufacturing, and their strengths and weaknesses are also discussed in a wide range of manufacturing applications. A comparative study of <b>machine</b> <b>learning</b> algorithms including Artificial Neural Network, Support Vector <b>Machine</b>, and Random Forest is performed for machining tool wear prediction. The schemes, techniques and paradigm of developing decision making support systems are reviewed for the monitoring of machining ...", "dateLastCrawled": "2022-02-02T21:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Encoder G25 G27 60 Slot - lgpfc.co.uk", "url": "https://lgpfc.co.uk/Encoder-G25-g27-60-Slot", "isFamilyFriendly": true, "displayUrl": "https://lgpfc.co.uk/Encoder-G25-g27-60-Slot", "snippet": "This gameplay is based on the traditional, casino-style slot <b>machine</b>. At the same time, each Online Encoder G25 G27 60 Slot Slots game will have its own unique set of individual rules and characteristics. Before playing any new Online Encoder G25 G27 60 Slot Slots game, you should become familiar with how the game works by trying the free demo version and having a close look at the game\u2019s paytable. Sports. Canada. The Canadian regulatory environment is <b>just as Encoder</b> G25 G27 60 Slot ...", "dateLastCrawled": "2022-01-16T21:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Google AI</b> Blog: July 2019", "url": "https://ai.googleblog.com/2019/07/", "isFamilyFriendly": true, "displayUrl": "https://ai.googleblog.com/2019/07", "snippet": "Such a multitask trained <b>encoder can be thought of as</b> <b>learning</b> a latent representation of the input that maintains information about the underlying linguistic content. Overview of the Parrotron model architecture. An input speech spectrogram is passed through encoder and decoder neural networks to generate an output spectrogram in a new voice. Case Studies To demonstrate a proof of concept, we worked with our fellow Google research scientist and mathematician Dimitri Kanevsky, who was born ...", "dateLastCrawled": "2022-01-29T22:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Google AI Blog: Parrotron: New Research into Improving Verbal ...", "url": "https://ai.googleblog.com/2019/07/parrotron-new-research-into-improving.html", "isFamilyFriendly": true, "displayUrl": "https://ai.googleblog.com/2019/07/parrotron-new-research-into-improving.html", "snippet": "Such a multitask trained <b>encoder can be thought of as</b> <b>learning</b> a latent representation of the input that maintains information about the underlying linguistic content. Overview of the Parrotron model architecture. An input speech spectrogram is passed through encoder and decoder neural networks to generate an output spectrogram in a new voice. Case Studies To demonstrate a proof of concept, we worked with our fellow Google research scientist and mathematician Dimitri Kanevsky, who was born ...", "dateLastCrawled": "2022-01-19T04:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Seq2seq and <b>Attention</b> - GitHub Pages", "url": "https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html", "isFamilyFriendly": true, "displayUrl": "https://lena-voita.github.io/nlp_course/seq2seq_and_<b>attention</b>.html", "snippet": "Intuitively, Transformer&#39;s <b>encoder can be thought of as</b> a sequence of reasoning steps (layers). At each step, tokens look at each other (this is where we need <b>attention</b> - self-<b>attention</b>), exchange information and try to understand each other better in the context of the whole sentence. This happens in several layers (e.g., 6).", "dateLastCrawled": "2022-02-02T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Using <b>Bidirectional</b> Generative Adversarial Networks to estimate Value ...", "url": "https://towardsdatascience.com/using-bidirectional-generative-adversarial-networks-to-estimate-value-at-risk-for-market-risk-c3dffbbde8dd", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-<b>bidirectional</b>-generative-adversarial-networks-to...", "snippet": "Note that given an optimal discriminator, the objective function of the generator and <b>encoder can be thought of as</b> that of an autoencoder, where the generator plays the role of a decoder. The objective function of the generator and encoder is simply to minimize the objective function of the discriminator, i.e., we have not explicitly specified the structure of the reconstruction loss as one might do so with an autoencoder. This implicit minimization of the reconstruction loss is yet another ...", "dateLastCrawled": "2022-01-31T10:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Distributed Coding</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/engineering/distributed-coding", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/engineering/<b>distributed-coding</b>", "snippet": "A Wyner\u2013Ziv <b>encoder can be thought of as</b> a quantizer followed by a Slepian\u2013Wolf encoder. In cases of images and video, existing <b>distributed coding</b> schemes add the Wyner\u2013Ziv encoder into the standard transform coding structure. As with the centralized case, a linear transform is independently applied to each image or video frame. Each transform coefficient is still treated independently, but it is fed into a Wyner\u2013Ziv coder instead of a scalar quantizer and an entropy coder. We refer ...", "dateLastCrawled": "2022-01-04T19:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Parrotron: An End-to-End Speech-to-Speech Conversion Model and its ...", "url": "https://deepai.org/publication/parrotron-an-end-to-end-speech-to-speech-conversion-model-and-its-applications-to-hearing-impaired-speech-and-speech-separation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/parrotron-an-end-to-end-speech-to-speech-conversion...", "snippet": "We apply more modern <b>machine</b> <b>learning</b> techniques to this problem, and demonstrate that, given sufficient training data, ... Such a multitask trained <b>encoder can be thought of as</b> <b>learning</b> a latent representation of the input that maintains information about the underlying transcript, i.e. one that is closer to the latent representation learned within a TTS sequence-to-sequence network. The decoder input is created by concatenating a 64-dim embedding for the grapheme emitted at the previous ...", "dateLastCrawled": "2022-01-18T09:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Distributed Source Coding: Theory, Algorithms and Applications</b> - PDF ...", "url": "https://epdf.pub/distributed-source-coding-theory-algorithms-and-applications.html", "isFamilyFriendly": true, "displayUrl": "https://epdf.pub/<b>distributed-source-coding-theory-algorithms-and-applications</b>.html", "snippet": "A Wyner\u2013Ziv <b>encoder can be thought of as</b> a quantizer followed by a Slepian\u2013Wolf encoder. In cases of images and video, existing distributed coding schemes add the Wyner\u2013 Ziv encoder into the standard transform coding structure. As with the centralized case, a linear transform is independently applied to each image or video frame. Each transform coef\ufb01cient is still treated independently, but it is fed into a Wyner\u2013Ziv coder instead of a scalar quantizer and an entropy coder. We ...", "dateLastCrawled": "2021-12-28T03:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Hands-On <b>Convolutional Neural Networks with TensorFlow</b>: Solve computer ...", "url": "https://dokumen.pub/hands-on-convolutional-neural-networks-with-tensorflow-solve-computer-vision-problems-with-modeling-in-tensorflow-and-python-9781789132823-1789132827.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/hands-on-<b>convolutional-neural-networks-with-tensorflow</b>-solve...", "snippet": "In the <b>machine</b> <b>learning</b> stage, all the feature vectors will be given to a <b>machine</b> <b>learning</b> system that creates a model. We hope that this model can generalize and is able to predict the digit for any future images given to the system that it wasn\u2019t trained on. An integral part of an ML system is evaluation. When we evaluate our model, we see how well our model has done in a particular task. In our example, we would look at how accurately it can predict the digit from the image. Accuracy of ...", "dateLastCrawled": "2022-01-24T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Parrotron: An End-to-End Speech-to-Speech Conversion Model and ...", "url": "https://www.researchgate.net/publication/335829307_Parrotron_An_End-to-End_Speech-to-Speech_Conversion_Model_and_its_Applications_to_Hearing-Impaired_Speech_and_Speech_Separation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335829307_Parrotron_An_End-to-End_Speech-to...", "snippet": "W.-c. W oo, \u201cConvolutional LSTM network: A <b>machine</b> <b>learning</b> approach for precipitation nowcasting,\u201d in Advances in Neural Information Processing Systems , 2015, pp. 802\u2013810.", "dateLastCrawled": "2022-01-29T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Error Diagnosis of Deep Monocular Depth Estimation Models", "url": "http://vision.soic.indiana.edu/papers/errordiagnosis2021iros.pdf", "isFamilyFriendly": true, "displayUrl": "vision.soic.indiana.edu/papers/errordiagnosis2021iros.pdf", "snippet": "<b>Machine</b> <b>learning</b>-based approaches such as Make3D [6], and more recent techniques based on deep <b>learning</b> [7], [8], have shown signi\ufb01cant promise. These techniques take a variety of approaches. For example, instead of directly estimating depth, BTS [9] estimates the parameters of local planes at various scales. The model is trained using only ground truth depth, as the local plane parameters are learned implicitly by the net-work. PlaneRCNN [10], another state-of-the-art technique, estimates ...", "dateLastCrawled": "2021-09-30T12:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Automatic <b>Machine</b> Translation Evaluation in Many Languages via Zero ...", "url": "https://aclanthology.org/2020.emnlp-main.8.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2020.emnlp-main.8.pdf", "snippet": "We frame the task of <b>machine</b> translation evaluation as one of scoring <b>machine</b> transla-tion output with a sequence-to-sequence para-phraser, conditioned on a human reference. We propose training the paraphraser as a multi-lingual NMT system, treating paraphrasing as a zero-shot translation task (e.g., Czech to Czech). This results in the paraphraser\u2019s out-put mode being centered around a copy of the input sequence, which represents the best case scenario where the MT system output matches a ...", "dateLastCrawled": "2022-01-21T14:24:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(encoder)  is like +(human brain)", "+(encoder) is similar to +(human brain)", "+(encoder) can be thought of as +(human brain)", "+(encoder) can be compared to +(human brain)", "machine learning +(encoder AND analogy)", "machine learning +(\"encoder is like\")", "machine learning +(\"encoder is similar\")", "machine learning +(\"just as encoder\")", "machine learning +(\"encoder can be thought of as\")", "machine learning +(\"encoder can be compared to\")"]}