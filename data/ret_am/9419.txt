{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Measuring Performance: AUPRC</b> and Average Precision \u2013 Glass Box", "url": "https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/", "isFamilyFriendly": true, "displayUrl": "https://glassboxmedicine.com/2019/03/02/<b>measuring-performance-auprc</b>", "snippet": "The <b>area</b> <b>under</b> the precision-recall <b>curve</b> (AUPRC) is a useful performance metric for imbalanced data in a problem setting where you care a lot about finding the positive examples. For example, perhaps you are building a classifier to detect pneumothorax in chest x-rays, and you want to ensure that you find all the pneumothoraces without incorrectly marking healthy lungs as positive for pneumothorax. If your <b>model</b> achieves a perfect AUPRC, it means your <b>model</b> found all of the positive ...", "dateLastCrawled": "2022-02-03T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "F1 <b>Score</b> vs ROC AUC vs <b>Accuracy</b> vs <b>PR</b> AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-<b>accuracy</b>-roc-auc-<b>pr</b>-auc", "snippet": "Similarly to ROC AUC <b>score</b> you can calculate the <b>Area</b> <b>Under</b> the Precision-Recall <b>Curve</b> to get one number that describes <b>model</b> performance. You can also think of <b>PR</b> AUC as the average of precision scores calculated for each recall threshold. You can also adjust this definition to suit your business needs by choosing/clipping recall thresholds if ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Which is More Accurate in <b>Measuring</b> the Blood Pressure? A Digital or an ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4843288/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4843288", "snippet": "The results showed that the <b>area</b> <b>under</b> the <b>curve</b> for both systolic and diastolic blood pressures measured by aneroid devices was more than that of the measurements done by digital device and it clearly depicts that, the diagnostic <b>accuracy</b> of aneroid sphygmomanometer was better than digital sphygmomanometer for <b>measuring</b> both systolic and diastolic blood pressures. The Youden index (sensitivity + specificity -1) which is calculated to detect the optimal threshold to detect a disease from the ...", "dateLastCrawled": "2022-02-03T00:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Area</b> <b>under</b> the ROC <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-the-roc-<b>curve</b>-assessing-discrimination...", "snippet": "We have seen that a <b>model</b> with discrimination ability has an ROC <b>curve</b> which goes closer to the top left hand corner of the plot, whereas a <b>model</b> with no discrimination ability has an ROC <b>curve</b> close to a 45 degree line. Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a <b>model</b> with no discrimination ability. The <b>area</b> <b>under</b> the ROC <b>curve</b> is also sometimes referred to as the c-statistic (c for concordance).", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Practical Guide to Logistic Regression Analysis in R - <b>HackerEarth Blog</b>", "url": "https://www.hackerearth.com/blog/developers/practical-guide-logistic-regression-analysis-r/", "isFamilyFriendly": true, "displayUrl": "https://www.hackerearth.com/blog/developers/practical-guide-logistic-regression-analysis-r", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (AUC), also referred to as index of <b>accuracy</b> (A) or concordant index, represents the performance of the ROC <b>curve</b>. Higher the <b>area</b>, better the <b>model</b>. ROC is plotted between True Positive Rate (Y axis) and False Positive Rate (X Axis). In this plot, our aim is to push the red <b>curve</b> (shown below) toward 1 (left corner) and maximize the <b>area</b> <b>under</b> <b>curve</b>. Higher the <b>curve</b>, better the <b>model</b>. The yellow line represents the ROC <b>curve</b> at 0.5 threshold. At this point ...", "dateLastCrawled": "2022-01-31T10:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Practical Guide to Logistic Regression Analysis in R Tutorials &amp; Notes ...", "url": "https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/logistic-regression-analysis-r/tutorial/", "isFamilyFriendly": true, "displayUrl": "https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/...", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (AUC), also referred to as index of <b>accuracy</b> (A) or concordant index, represents the performance of the ROC <b>curve</b>. Higher the <b>area</b>, better the <b>model</b>. ROC is plotted between True Positive Rate (Y axis) and False Positive Rate (X Axis). In this plot, our aim is to push the red <b>curve</b> (shown below) toward 1 (left corner) and maximize the <b>area</b> <b>under</b> <b>curve</b>. Higher the <b>curve</b>, better the <b>model</b>. The yellow line represents the ROC <b>curve</b> at 0.5 threshold. At this point ...", "dateLastCrawled": "2022-02-03T04:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "python - How to evaluate <b>accuracy</b> on highly unbalanced data (using ...", "url": "https://stackoverflow.com/questions/53772249/how-to-evaluate-accuracy-on-highly-unbalanced-data-using-naive-bayes-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/53772249", "snippet": "<b>Accuracy</b>, precision, recall, and F1 score are &quot;point metrics&quot; that are calculated AFTER you apply a particular decision threshold to your classifier&#39;s predicted probabilities. <b>Area</b> <b>under</b> the ROC <b>curve</b> (&quot;AUC&quot; or &quot;AUROC&quot;) and <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b> (AUPRC) are calculated BEFORE you apply a particular decision threshold. You can think of them as ...", "dateLastCrawled": "2022-01-18T21:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The <b>Area Under</b> an ROC <b>Curve</b>", "url": "http://gim.unmc.edu/dxtests/RoC3.htm", "isFamilyFriendly": true, "displayUrl": "gim.unmc.edu/dxtests/RoC3.htm", "snippet": "<b>Accuracy</b> is measured by the <b>area under</b> the ROC <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying <b>the accuracy</b> of a diagnostic test is the traditional academic point system: .90-1 = excellent (A) .80-.90 = good (B) .70-.80 = fair (C) .60-.70 = poor (D) .50-.60 = fail (F) Recall the T4 data from the previous section. The <b>area under</b> the T4 ROC <b>curve</b> is .86. The T4 would be considered to be &quot;good&quot; at separating hypothyroid ...", "dateLastCrawled": "2022-01-28T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "machine learning - Advantages of AUC vs standard <b>accuracy</b> - Data ...", "url": "https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/806", "snippet": "Really great question, and one that I find that most people don&#39;t really understand on an intuitive level. AUC is in fact often preferred over <b>accuracy</b> for binary classification for a number of different reasons. First though, let&#39;s talk about exactly what AUC is. Honestly, for being one of the most widely used efficacy metrics, it&#39;s surprisingly obtuse to figure out exactly how AUC works.. AUC stands for <b>Area</b> <b>Under</b> the <b>Curve</b>, which <b>curve</b> you ask?Well, that would be the ROC <b>curve</b>.ROC stands ...", "dateLastCrawled": "2022-01-27T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Measuring</b> <b>accuracy</b> of a <b>logistic regression</b>-based <b>model</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/18178/measuring-accuracy-of-a-logistic-regression-based-model", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/18178", "snippet": "Note that (depending on your used software/language of choice) there&#39;s a myriad of tools out there that already provide this. Wrt AUC: it is no more or less than the actual <b>area</b> <b>under</b> the ROC <b>curve</b>. Not the with a perfect random predictor, the ROC <b>curve</b> would be a straight line from (0,0) to (1,1), resulting in an AUC of 0.5.", "dateLastCrawled": "2022-02-02T16:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Measuring Performance: AUPRC</b> and Average Precision \u2013 Glass Box", "url": "https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/", "isFamilyFriendly": true, "displayUrl": "https://glassboxmedicine.com/2019/03/02/<b>measuring-performance-auprc</b>", "snippet": "The AUPRC is calculated as the <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. A <b>PR</b> <b>curve</b> shows the trade-off between precision and recall across different decision thresholds. (Note that \u201crecall\u201d is another name for the true positive rate (TPR). Thus, AUPRC and AUROC both make use of the TPR. For a review of TPR, precision, and decision thresholds, see <b>Measuring</b> Performance: The Confusion Matrix.) The x-axis of a <b>PR</b> <b>curve</b> is the recall and the y-axis is the precision. This is in contrast to ROC curves, where ...", "dateLastCrawled": "2022-02-03T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "F1 <b>Score</b> vs ROC AUC vs <b>Accuracy</b> vs <b>PR</b> AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-<b>accuracy</b>-roc-auc-<b>pr</b>-auc", "snippet": "Similarly to ROC AUC <b>score</b> you can calculate the <b>Area</b> <b>Under</b> the Precision-Recall <b>Curve</b> to get one number that describes <b>model</b> performance. You can also think of <b>PR</b> AUC as the average of precision scores calculated for each recall threshold. You can also adjust this definition to suit your business needs by choosing/clipping recall thresholds if ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Which is More Accurate in <b>Measuring</b> the Blood Pressure? A Digital or an ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4843288/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4843288", "snippet": "The results showed that the <b>area</b> <b>under</b> the <b>curve</b> for both systolic and diastolic blood pressures measured by aneroid devices was more than that of the measurements done by digital device and it clearly depicts that, the diagnostic <b>accuracy</b> of aneroid sphygmomanometer was better than digital sphygmomanometer for <b>measuring</b> both systolic and diastolic blood pressures. The Youden index (sensitivity + specificity -1) which is calculated to detect the optimal threshold to detect a disease from the ...", "dateLastCrawled": "2022-02-03T00:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Area</b> <b>under</b> the ROC <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-the-roc-<b>curve</b>-assessing-discrimination...", "snippet": "<b>Area</b> <b>under</b> the ROC <b>curve</b> A popular way of summarizing the discrimination ability <b>of a model</b> is to report the <b>area</b> <b>under</b> the ROC <b>curve</b>. We have seen that a <b>model</b> with discrimination ability has an ROC <b>curve</b> which goes closer to the top left hand corner of the plot, whereas a <b>model</b> with no discrimination ability has an ROC <b>curve</b> close to a 45 degree line. Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a <b>model</b> with no ...", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>MRR</b> vs MAP vs NDCG: Rank-Aware Evaluation Metrics And When To Use Them ...", "url": "https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832", "snippet": "Interpretation of the MAP measure through the <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. To compare two systems we want the largest possible <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. In the above example we compare systems A, B and ...", "dateLastCrawled": "2022-01-31T10:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Performance Measures for Multi-Class Problems</b> - Data Science Blog ...", "url": "https://www.datascienceblog.net/post/machine-learning/performance-measures-multi-class-problems/", "isFamilyFriendly": true, "displayUrl": "https://www.datascienceblog.net/post/machine-learning/performance-measures-multi-class...", "snippet": "The <b>area</b> <b>under</b> the ROC <b>curve</b> (AUC) is a useful tool for evaluating the quality of class separation for soft classifiers. In the multi-class setting, we can visualize the performance of multi-class models according to their one-vs-all precision-recall curves. The AUC can also be generalized to the multi-class setting.", "dateLastCrawled": "2022-02-02T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Practical Guide to Logistic Regression Analysis in R - <b>HackerEarth Blog</b>", "url": "https://www.hackerearth.com/blog/developers/practical-guide-logistic-regression-analysis-r/", "isFamilyFriendly": true, "displayUrl": "https://www.hackerearth.com/blog/developers/practical-guide-logistic-regression-analysis-r", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (AUC), also referred to as index of <b>accuracy</b> (A) or concordant index, represents the performance of the ROC <b>curve</b>. Higher the <b>area</b>, better the <b>model</b>. ROC is plotted between True Positive Rate (Y axis) and False Positive Rate (X Axis). In this plot, our aim is to push the red <b>curve</b> (shown below) toward 1 (left corner) and maximize the <b>area</b> <b>under</b> <b>curve</b>. Higher the <b>curve</b>, better the <b>model</b>. The yellow line represents the ROC <b>curve</b> at 0.5 threshold. At this point ...", "dateLastCrawled": "2022-01-31T10:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Evaluate AutoML experiment results - <b>Azure</b> Machine Learning | Microsoft ...", "url": "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml", "isFamilyFriendly": true, "displayUrl": "https://docs.microsoft.com/en-us/<b>azure</b>/machine-learning/how-to-<b>under</b>stand-automated-ml", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (AUC) can be interpreted as the proportion of correctly classified samples. More precisely, the AUC is the probability that the classifier ranks a randomly chosen positive sample higher than a randomly chosen negative sample. The shape of the <b>curve</b> gives an intuition for relationship between TPR and FPR as a function of the classification threshold or decision boundary. A <b>curve</b> that approaches the top-left corner of the chart is approaching a 100% TPR and 0% FPR, the ...", "dateLastCrawled": "2022-02-02T18:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Assessing and <b>Comparing Classifier Performance</b> with ROC Curves", "url": "https://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/assessing-<b>comparing-classifier-performance</b>-roc-<b>curves</b>-2", "snippet": "The most widely-used measure is the <b>area</b> <b>under</b> the <b>curve</b> (AUC). As you can see from Figure 2, the AUC for a classifier with no power, essentially random guessing, is 0.5, because the <b>curve</b> follows the diagonal. The AUC for that mythical being, the perfect classifier, is 1.0. Most classifiers have AUCs that fall somewhere between these two values.", "dateLastCrawled": "2022-01-29T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>accuracy</b> - Is <b>Gini coefficient</b> a good metric for <b>measuring</b> predictive ...", "url": "https://datascience.stackexchange.com/questions/19755/is-gini-coefficient-a-good-metric-for-measuring-predictive-model-performance-on", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/19755", "snippet": "Is <b>Gini coefficient</b> a good metric for <b>measuring</b> predictive <b>model</b> performance on highly imbalanced data. Ask Question Asked 4 years , 7 ... The <b>Gini Coefficient</b> can also be expressed in terms of the <b>area</b> <b>under</b> the ROC <b>curve</b> (AUC): G = 2*AUC -1 link. The ROC <b>curve</b> , on the other hand, is influenced by class imbalance through the false positive rate FP/(FP+TN). If the number of negatives is a lot larger, this could be a potential issue. In short, the <b>Gini Coefficient</b> has <b>similar</b> pros and cons ...", "dateLastCrawled": "2022-01-31T20:03:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Measuring Performance: AUPRC</b> and Average Precision \u2013 Glass Box", "url": "https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/", "isFamilyFriendly": true, "displayUrl": "https://glassboxmedicine.com/2019/03/02/<b>measuring-performance-auprc</b>", "snippet": "The AUPRC is calculated as the <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. A <b>PR</b> <b>curve</b> shows the trade-off between precision and recall across different decision thresholds. (Note that \u201crecall\u201d is another name for the true positive rate (TPR). Thus, AUPRC and AUROC both make use of the TPR. For a review of TPR, precision, and decision thresholds, see <b>Measuring</b> Performance: The Confusion Matrix.) The x-axis of a <b>PR</b> <b>curve</b> is the recall and the y-axis is the precision. This is in contrast to ROC curves, where ...", "dateLastCrawled": "2022-02-03T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Area</b> <b>under</b> the ROC <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-the-roc-<b>curve</b>-assessing-discrimination...", "snippet": "<b>Area</b> <b>under</b> the ROC <b>curve</b> A popular way of summarizing the discrimination ability <b>of a model</b> is to report the <b>area</b> <b>under</b> the ROC <b>curve</b>. We have seen that a <b>model</b> with discrimination ability has an ROC <b>curve</b> which goes closer to the top left hand corner of the plot, whereas a <b>model</b> with no discrimination ability has an ROC <b>curve</b> close to a 45 degree line. Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a <b>model</b> with no ...", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "F1 <b>Score</b> vs ROC AUC vs <b>Accuracy</b> vs <b>PR</b> AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-<b>accuracy</b>-roc-auc-<b>pr</b>-auc", "snippet": "In order to get one number that tells us how good our <b>curve</b> is, we <b>can</b> calculate the <b>Area</b> <b>Under</b> the ROC <b>Curve</b>, or ROC AUC <b>score</b>. The more top-left your <b>curve</b> is the higher the <b>area</b> and hence higher ROC AUC <b>score</b>. Alternatively, it <b>can</b> be shown that ROC AUC <b>score</b> is equivalent to calculating the rank correlation between predictions and targets. From an interpretation standpoint, it is more useful because it tells us that this metric shows how good at ranking predictions your <b>model</b> is. It ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>MRR</b> vs MAP vs NDCG: Rank-Aware Evaluation Metrics And When To Use Them ...", "url": "https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832", "snippet": "Interpretation of the MAP measure through the <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. To compare two systems we want the largest possible <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. In the above example we compare systems A, B and ...", "dateLastCrawled": "2022-01-31T10:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Better mAP for Object Detection | by Ivan Rala\u0161i\u0107 | Towards Data Science", "url": "https://towardsdatascience.com/a-better-map-for-object-detection-32662767d424", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-better-map-for-object-detection-32662767d424", "snippet": "AP@\u03b1 is the <b>Area</b> <b>Under</b> the precision-recall <b>curve</b> (AUC-<b>PR</b>). Mathematically, AP is defined as: Notation: AP@\u03b1 means Average Precision (AP) at the IoU threshold of \u03b1. Therefore AP@0.50 and AP@0.75 mean AP at IoU threshold of 50% and 75% respectively. A high AUC-<b>PR</b> implies high precision and high recall.", "dateLastCrawled": "2022-02-01T19:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>ROC Curve</b>, a Complete Introduction | by Reza Bagheri | Towards Data Science", "url": "https://towardsdatascience.com/roc-curve-a-complete-introduction-2f2da2e0434c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>roc-curve</b>-a-complete-introduction-2f2da2e0434c", "snippet": "To do that we calculate the <b>area</b> <b>under</b> the <b>ROC curve</b> as shown in Fig 22. Figure 22. We call this quantity AUC (<b>Area</b> <b>under</b> the <b>Curve</b>). For an ideal classifier, AUC is the <b>area</b> of a rectangle with length 1, so it is just 1. For a random classifier, it is roughly the <b>area</b> of the lower triangle which is 0.5. For other classifiers, AUC lies between 0.5 and 1. The higher the AUC, the better the classifier is, since it is closer to an ideal classifier. To calculate the AUC in Scikit-learn, you <b>can</b> ...", "dateLastCrawled": "2022-01-30T19:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The <b>Area Under</b> an ROC <b>Curve</b>", "url": "http://gim.unmc.edu/dxtests/RoC3.htm", "isFamilyFriendly": true, "displayUrl": "gim.unmc.edu/dxtests/RoC3.htm", "snippet": "<b>Accuracy</b> is measured by the <b>area under</b> the ROC <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying <b>the accuracy</b> of a diagnostic test is the traditional academic point system: .90-1 = excellent (A) .80-.90 = good (B) .70-.80 = fair (C) .60-.70 = poor (D) .50-.60 = fail (F) Recall the T4 data from the previous section. The <b>area under</b> the T4 ROC <b>curve</b> is .86. The T4 would be considered to be &quot;good&quot; at separating hypothyroid ...", "dateLastCrawled": "2022-01-28T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "machine learning - Advantages of AUC vs standard <b>accuracy</b> - Data ...", "url": "https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/806", "snippet": "Really great question, and one that I find that most people don&#39;t really understand on an intuitive level. AUC is in fact often preferred over <b>accuracy</b> for binary classification for a number of different reasons. First though, let&#39;s talk about exactly what AUC is. Honestly, for being one of the most widely used efficacy metrics, it&#39;s surprisingly obtuse to figure out exactly how AUC works.. AUC stands for <b>Area</b> <b>Under</b> the <b>Curve</b>, which <b>curve</b> you ask?Well, that would be the ROC <b>curve</b>.ROC stands ...", "dateLastCrawled": "2022-01-27T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Tour of <b>Evaluation Metrics for Imbalanced Classification</b>", "url": "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced...", "snippet": "The ROC <b>Curve</b> is a helpful diagnostic for one <b>model</b>. The <b>area</b> <b>under</b> the ROC <b>curve</b> <b>can</b> be calculated and provides a single score to summarize the plot that <b>can</b> be used to compare models. A no skill classifier will have a score of 0.5, whereas a perfect classifier will have a score of 1.0. ROC AUC = ROC <b>Area</b> <b>Under</b> <b>Curve</b>; Although generally effective, the ROC <b>Curve</b> and ROC AUC <b>can</b> be optimistic <b>under</b> a severe class imbalance, especially when the number of examples in the minority class is small ...", "dateLastCrawled": "2022-02-02T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>ROC AUC</b> and how to visualize it in <b>python</b> | by Angela ... - Medium", "url": "https://medium.com/@kunanba/what-is-roc-auc-and-how-to-visualize-it-in-python-f35708206663", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@kunanba/what-is-<b>roc-auc</b>-and-how-to-visualize-it-in-<b>python</b>-f35708206663", "snippet": "We <b>can</b> also qunatify <b>area</b> <b>under</b> the <b>curve</b> also know as <b>AUC</b> using scikit-learn\u2019s <b>roc_auc</b>_score metric, in order to assess the performance of the <b>model</b>. The closer the score to 1 the better the ...", "dateLastCrawled": "2022-02-02T21:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "F1 <b>Score</b> vs ROC AUC vs <b>Accuracy</b> vs <b>PR</b> AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-<b>accuracy</b>-roc-auc-<b>pr</b>-auc", "snippet": "In order to get one number that tells us how good our <b>curve</b> is, we <b>can</b> calculate the <b>Area</b> <b>Under</b> the ROC <b>Curve</b>, or ROC AUC <b>score</b>. The more top-left your <b>curve</b> is the higher the <b>area</b> and hence higher ROC AUC <b>score</b>. Alternatively, it <b>can</b> be shown that ROC AUC <b>score</b> is equivalent to calculating the rank correlation between predictions and targets. From an interpretation standpoint, it is more useful because it tells us that this metric shows how good at ranking predictions your <b>model</b> is. It ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The <b>area</b> <b>under</b> the precision\u2010recall <b>curve as a performance metric</b> for ...", "url": "https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13140", "isFamilyFriendly": true, "displayUrl": "https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13140", "snippet": "We evaluated the <b>area</b> <b>under</b> the precision-recall <b>curve</b> (AUC-<b>PR</b>) as a <b>performance metric for rare binary events</b>, focusing on the assessment of species distribution models. Precision is the probability that a species is present given a predicted presence, while recall (more commonly called sensitivity) is the probability the <b>model</b> predicts presence in locations where the species has been observed. We simulated species at three levels of prevalence, <b>compared</b> AUC-<b>PR</b> and the <b>area</b> <b>under</b> the ...", "dateLastCrawled": "2022-02-01T10:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Area</b> <b>under</b> the ROC <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-the-roc-<b>curve</b>-assessing-discrimination...", "snippet": "A popular way of summarizing the discrimination ability <b>of a model</b> is to report the <b>area</b> <b>under</b> the ROC <b>curve</b>. We have seen that a <b>model</b> with discrimination ability has an ROC <b>curve</b> which goes closer to the top left hand corner of the plot, whereas a <b>model</b> with no discrimination ability has an ROC <b>curve</b> close to a 45 degree line. Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a <b>model</b> with no discrimination ability. The <b>area</b> <b>under</b> ...", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Measuring Performance: AUC (AUROC</b>) \u2013 Glass Box", "url": "https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/", "isFamilyFriendly": true, "displayUrl": "https://glassboxmedicine.com/2019/02/23/<b>measuring-performance-auc-auroc</b>", "snippet": "The AUROC for a given <b>curve</b> is simply the <b>area</b> beneath it. The worst AUROC is 0.5, and the best AUROC is 1.0. An AUROC of 0.5 (<b>area</b> <b>under</b> the red dashed line in the figure above) corresponds to a coin flip, i.e. a useless <b>model</b>. An AUROC less than 0.7 is sub-optimal performance. An AUROC of 0.70 \u2013 0.80 is good performance.", "dateLastCrawled": "2022-02-03T07:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "machine learning - Advantages of AUC vs standard <b>accuracy</b> - Data ...", "url": "https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/806", "snippet": "Really great question, and one that I find that most people don&#39;t really understand on an intuitive level. AUC is in fact often preferred over <b>accuracy</b> for binary classification for a number of different reasons. First though, let&#39;s talk about exactly what AUC is. Honestly, for being one of the most widely used efficacy metrics, it&#39;s surprisingly obtuse to figure out exactly how AUC works.. AUC stands for <b>Area</b> <b>Under</b> the <b>Curve</b>, which <b>curve</b> you ask?Well, that would be the ROC <b>curve</b>.ROC stands ...", "dateLastCrawled": "2022-01-27T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Measuring</b> <b>accuracy</b> of a <b>logistic regression</b>-based <b>model</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/18178/measuring-accuracy-of-a-logistic-regression-based-model", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/18178", "snippet": "Note that (depending on your used software/language of choice) there&#39;s a myriad of tools out there that already provide this. Wrt AUC: it is no more or less than the actual <b>area</b> <b>under</b> the ROC <b>curve</b>. Not the with a perfect random predictor, the ROC <b>curve</b> would be a straight line from (0,0) to (1,1), resulting in an AUC of 0.5.", "dateLastCrawled": "2022-02-02T16:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Balanced <b>Accuracy</b>: When Should You Use It? - neptune.ai", "url": "https://neptune.ai/blog/balanced-accuracy", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/balanced-<b>accuracy</b>", "snippet": "ROC_AUC stands for \u201cReceiver Operator Characteristic_<b>Area</b> <b>Under</b> the <b>Curve</b>\u201d. It summarizes the trade-off between the true positive rates and the false-positive rates for a predictive <b>model</b>. ROC yields good results when the observations are balanced between each class. This metric <b>can</b>\u2019t be calculated from the summarized data in the confusion matrix. Doing so might lead to inaccurate and misleading results. It <b>can</b> be viewed using the ROC <b>curve</b>, this <b>curve</b> shows the variation at each ...", "dateLastCrawled": "2022-02-03T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Evaluation</b> Metrics for Machine Learning Models | by Bhajandeep Singh ...", "url": "https://heartbeat.comet.ml/evaluation-metrics-for-machine-learning-models-d42138496366", "isFamilyFriendly": true, "displayUrl": "https://heartbeat.comet.ml/<b>evaluation</b>-metrics-for-machine-learning-<b>models</b>-d42138496366", "snippet": "The AUC is one way to summarize the ROC <b>curve</b> into a single number so that it <b>can</b> <b>be compared</b> easily and automatically. A good ROC <b>curve</b> has a lot of space <b>under</b> it (because the true positive rate shoots up to 100% very quickly). A bad ROC <b>curve</b> covers very little <b>area</b>. So high AUC is good, and low AUC is not so good.", "dateLastCrawled": "2022-01-28T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Choosing the right KPIs to evaluate your models | by Amir Dolev ...", "url": "https://medium.com/riskified-technology/choosing-the-right-kpis-to-evaluate-your-models-1cb42a9a26d5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/.../choosing-the-right-kpis-to-evaluate-your-<b>models</b>-1cb42a9a26d5", "snippet": "Enter <b>the PR</b> <b>curve</b> and the PRAUC metric. Here the baseline will be the class distribution. The TPR (Recall) will move to the X axis, and the more interesting precision metric will replace the less ...", "dateLastCrawled": "2022-01-28T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Assessing and <b>Comparing Classifier Performance</b> with ROC Curves", "url": "https://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/assessing-<b>comparing-classifier-performance</b>-roc-<b>curves</b>-2", "snippet": "Any sort of data which <b>can</b> be fed into appropriate classifiers <b>can</b> be subjected to ROC <b>curve</b> analysis. Further Reading. A classic paper on using ROC curves, old, but still very relevant: Hanley, J. A. and B. J. McNeil (1982). \u201cThe meaning and use of the <b>area</b> <b>under</b> a receiver operating characteristic (ROC) <b>curve</b>.\u201d Radiology 143(1): 29-36.", "dateLastCrawled": "2022-01-29T05:28:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "<b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. See <b>PR</b> AUC (<b>Area</b> <b>under</b> <b>the PR</b> <b>Curve</b>). <b>area</b> <b>under</b> the ROC <b>curve</b> . See AUC (<b>Area</b> <b>under</b> the ROC <b>curve</b>). artificial general intelligence. A non-human mechanism that demonstrates a broad range of problem solving, creativity, and adaptability. For example, a program demonstrating artificial general intelligence could translate text, compose symphonies, and excel at games that have not yet been invented. artificial intelligence. A non-human program or model that can solve ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Learning</b> Curves in <b>Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/247934703_Learning_Curves_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/247934703_<b>Learning</b>_<b>Curves</b>_in_<b>Machine</b>_<b>Learning</b>", "snippet": "The <b>area</b> <b>under</b> the receiver operating characteristic (ROC) <b>curve</b> (AUC) was 0.62 (95% confidence interval [CI]: 0.57, 0.68) and the <b>area</b> <b>under</b> the precision\u2010recall <b>curve</b> was 0.58. <b>Learning</b> <b>curve</b> ...", "dateLastCrawled": "2021-12-15T10:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding <b>AUC</b> - ROC <b>Curve</b> | by Sarang Narkhede | Towards Data Science", "url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>auc</b>-roc-<b>curve</b>-68b2303cc9c5", "snippet": "In <b>Machine</b> <b>Learning</b>, performance measurement is an essential task. So when it comes to a classification problem, we can count on an <b>AUC</b> - ROC <b>Curve</b>. When we need to check or visualize the performance of the multi-class classification problem, we use the <b>AUC</b> <b>Area</b> <b>Under</b> The <b>Curve</b>) ROC (Receiver Operating Characteristics) <b>curve</b>. It is one of the most important evaluation metrics for checking any classification model\u2019s performance. It is also written as AUROC (<b>Area</b> <b>Under</b> the Receiver Operating ...", "dateLastCrawled": "2022-01-30T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Differential and Integral Calculus - Differentiate with Respect to Anything", "url": "https://machinelearningmastery.com/differential-and-integral-calculus-differentiate-with-respect-to-anything/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/differential-and-integral-calculus-differentiate...", "snippet": "The Sweeping <b>Area</b> <b>Analogy</b>. Perhaps a simpler <b>analogy</b> to help us relate integration to differentiation, is to imagine holding one of the thinly cut slices and dragging it rightwards <b>under</b> the <b>curve</b> in infinitesimally small steps. As it moves rightwards, the thinly cut slice will sweep a larger <b>area</b> <b>under</b> the <b>curve</b>, while its height will change according to the shape of the <b>curve</b>. The question that we would like to answer is, at which rate does the <b>area</b> accumulate as the thin slice sweeps ...", "dateLastCrawled": "2022-01-28T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Applying <b>machine</b> <b>learning</b> algorithms to predict default probability in ...", "url": "https://www.sciencedirect.com/science/article/pii/S1057521921002878", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1057521921002878", "snippet": "The results show that, first, based on the AUC (<b>area</b> <b>under</b> the ROC <b>curve</b>) value, accuracy rate and Brier score, the <b>machine</b> <b>learning</b> models can accurately predict the default risk of online borrowers. Second, the integrated discrimination improvement (IDI) test results show that the prediction performance of the <b>machine</b> <b>learning</b> algorithms is significantly better than that of the logistic model. Third, after constructing the investor profit function with misclassification cost, we find that ...", "dateLastCrawled": "2022-01-27T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>What is</b> AUC - <b>ROC</b> in <b>Machine</b> <b>Learning</b> | Overview of <b>ROC</b>", "url": "https://www.mygreatlearning.com/blog/roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>roc</b>-<b>curve</b>", "snippet": "By <b>analogy</b>, Higher the AUC, better the model is at distinguishing between patients with the disease and no disease. The <b>ROC</b> <b>curve</b> is plotted with TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis. Defining terms used in AUC and <b>ROC</b> <b>Curve</b>. Consider a two-class prediction problem, in which the outcomes are labeled either as positive (p) or negative (n). There are four possible outcomes from a binary classifier. If the outcome from a prediction is p and the actual value is ...", "dateLastCrawled": "2022-01-30T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Cohort-Derived <b>Machine Learning</b> Models for Individual Prediction of ...", "url": "https://academic.oup.com/jid/article/224/7/1198/5835004", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/jid/article/224/7/1198/5835004", "snippet": "Of 12 761 eligible individuals (median baseline eGFR, 103 mL/minute/1.73 m 2), 1192 (9%) developed a CKD after a median of 8 years.We used 64 static and 502 time-changing variables: Across prediction horizons and algorithms and in contrast to expert-based standard models, most <b>machine learning</b> models achieved state-of-the-art predictive performances with areas <b>under</b> the receiver operating characteristic <b>curve</b> and precision recall <b>curve</b> ranging from 0.926 to 0.996 and from 0.631 to 0.956 ...", "dateLastCrawled": "2021-12-15T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Bishop Pattern Recognition And Machine Learning Springer</b> | Xinyue ...", "url": "https://www.academia.edu/34528598/Bishop_Pattern_Recognition_And_Machine_Learning_Springer", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/34528598/<b>Bishop_Pattern_Recognition_And_Machine_Learning_Springer</b>", "snippet": "<b>Bishop Pattern Recognition And Machine Learning Springer</b>. 758 Pages. <b>Bishop Pattern Recognition And Machine Learning Springer</b>. Xinyue Liu. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 36 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package ...", "dateLastCrawled": "2022-02-02T07:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Driving skill analysis using <b>machine</b> <b>learning</b> The full <b>curve</b> and ...", "url": "https://www.researchgate.net/publication/261398439_Driving_skill_analysis_using_machine_learning_The_full_curve_and_curve_segmented_cases", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/261398439_Driving_skill_analysis_using...", "snippet": "In the full <b>curve</b> driving scene, principal component analysis and a support vector <b>machine</b>-based method accurately classified drivers in 95.7 % of cases when using driving data about high- and low ...", "dateLastCrawled": "2022-01-07T09:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - What is the <b>convex hull</b> in ROC <b>curve</b>? - Cross Validated", "url": "https://stats.stackexchange.com/questions/120361/what-is-the-convex-hull-in-roc-curve", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/120361/what-is-the-<b>convex-hull</b>-in-roc-<b>curve</b>", "snippet": "Taking the <b>convex hull</b> of the ROC <b>curve</b> points is just a way of enforcing a constraint that the estimated ROC <b>curve</b> be <b>convex</b> (concave down in this case). It is equivalent to assuming that the distributions of the marker in the cases and in the controls are unimodal. In situations where this assumption is reasonable then imposing the convexity constraint is warranted.", "dateLastCrawled": "2022-01-18T16:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Performance Evaluation of Machine Learning Algorithms in Apache</b> ...", "url": "https://www.researchgate.net/publication/330478085_Performance_Evaluation_of_Machine_Learning_Algorithms_in_Apache_Spark_for_Intrusion_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330478085_Performance_Evaluation_of_<b>Machine</b>...", "snippet": "The <b>area under the PR curve is like</b> the ROC. The . difference is that instead of it being a ratio bet ween the true and . false positive rates, it is a r atio between precision and t rue ...", "dateLastCrawled": "2021-11-04T12:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(area under the pr curve)  is like +(measuring the accuracy of a model)", "+(area under the pr curve) is similar to +(measuring the accuracy of a model)", "+(area under the pr curve) can be thought of as +(measuring the accuracy of a model)", "+(area under the pr curve) can be compared to +(measuring the accuracy of a model)", "machine learning +(area under the pr curve AND analogy)", "machine learning +(\"area under the pr curve is like\")", "machine learning +(\"area under the pr curve is similar\")", "machine learning +(\"just as area under the pr curve\")", "machine learning +(\"area under the pr curve can be thought of as\")", "machine learning +(\"area under the pr curve can be compared to\")"]}