{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Co-Training</b> as a Human Collaboration Policy", "url": "https://pages.cs.wisc.edu/~jerryzhu/pub/human_cotraining.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~jerryzhu/pub/human_<b>cotraining</b>.pdf", "snippet": "<b>learning</b> problems <b>like</b> that shown in Figure 1 we will see that our <b>Co-Training</b> collaboration policy leads participants to learn classi\ufb01cations typically thought to be very dif\ufb01cult for <b>humans</b>, and also to show more homogeneous behavior for stimuli de\ufb01ned along separable versus integral dimen-sions. Though we do not extend the approach to a real-world <b>learning</b> problem here, we will consider how the approach might be used to design collaboration policies for such prob-lems in cases where ...", "dateLastCrawled": "2022-02-02T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Co-Training</b> as a Human Collaboration Policy", "url": "https://ojs.aaai.org/index.php/AAAI/article/view/7945/7804", "isFamilyFriendly": true, "displayUrl": "https://ojs.aaai.org/index.php/AAAI/article/view/7945/7804", "snippet": "<b>Co-Training</b> algorithm in machine <b>learning</b>, in which the two people play the role of the base learners. The policy restricts <b>each</b> learner\u2019s view of the data and limits their communica-tion to only the exchange of their labelings on test items. In a series of empirical studies, we show that the <b>Co-Training</b> policy leads collaborators to jointly produce unique and po-tentially valuable classi\ufb01cation outcomes that are not gener-ated under <b>other</b> collaboration policies. We further demon-strate ...", "dateLastCrawled": "2022-01-01T10:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Co-Training as a Human Collaboration Policy</b>", "url": "https://www.researchgate.net/publication/221604476_Co-Training_as_a_Human_Collaboration_Policy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221604476_<b>Co-Training</b>_as_a_Human...", "snippet": "In this case, the problem can be considered as a supervised <b>learning</b> problem, and for its solution can be used conventional algorithms of ensemble <b>learning</b>, <b>like</b> boosting [10, 18, 6]. On the <b>other</b> ...", "dateLastCrawled": "2022-01-03T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Blog Classi\ufb01cation with <b>Co-training</b>", "url": "https://web.eecs.umich.edu/~cscott/past_courses/eecs545f07/projects/GerrishQazvinianShi.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.eecs.umich.edu/~cscott/past_courses/eecs545f07/projects/GerrishQazvinian...", "snippet": "This <b>is like</b> <b>co-training</b>, where one view is the document, and the <b>other</b> view is the word\u2019s context. 2. 1.3 Machine <b>learning</b> and the web There has been quite a bit of work using the web as a source of data for <b>learning</b> tasks. One of the ultimate goals is described by Tim Berners-Lee, creator of the World Wide Web as the Semantic Web [3]. The web pages in the semantic web will be readable by both <b>humans</b> and machines. Software agents will be able to automatically combine data from di\ufb00erent ...", "dateLastCrawled": "2022-01-12T19:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Email Classi\ufb01cation with <b>Co-Training</b>", "url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.408.8821&rep=rep1&type=pdf", "isFamilyFriendly": true, "displayUrl": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.408.8821&amp;rep=rep1&amp;type=pdf", "snippet": "by combining <b>co-training</b> and active <b>learning</b> in the form of using <b>humans</b> to correct inaccurate labels made by <b>co-training</b>. Another variant of combining <b>co-training</b> and active <b>learning</b> has been proposed in [12]. Co-Test(Co-EM) extends <b>co-training</b> in that it asks to explicitly label examples on which the two classi\ufb01ers of <b>co-training</b> have ...", "dateLastCrawled": "2021-09-22T07:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Co-training</b> Transformer with Videos and Images Improves Action ...", "url": "https://deepai.org/publication/co-training-transformer-with-videos-and-images-improves-action-recognition", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>co-training</b>-transformer-with-videos-and-images-improves...", "snippet": "<b>Co-training</b> improves the top-1 accuracy on K400 by 1.4% and SSv2 by 2.7%, which indicates that jointly <b>learning</b> K400 and SSv2 could enhance the performance of both tasks. We further include the MiT dataset into <b>co-training</b>. Compared with <b>co-training</b> on just two datasets, <b>co-training</b> on all three improves K400 and SSv2 performance by 0.8% and 0.7%, respectively. We observe that <b>co-training</b> with MiT also improves MiT performance by 1.0%. Finally, we co-train both image and video datasets ...", "dateLastCrawled": "2022-01-07T16:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Ensemble Based <b>Co-Training</b> | Jafar Tanha - Academia.edu", "url": "https://www.academia.edu/33536005/Ensemble_Based_Co_Training", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/33536005/Ensemble_Based_<b>Co_Training</b>", "snippet": "In <b>co-training</b>, two classifiers based on different views of data or on different <b>learning</b> algorithms are trained in parallel and then unlabeled data that are classified differently by the classifiers but for which one classifier has large confidence are labeled and used as training data for the <b>other</b>. In this paper, a new form of <b>co-training</b>, called Ensemble-<b>Co-Training</b>, is proposed that uses an ensemble of different <b>learning</b> al- gorithms. Based on a theorem by Angluin and Laird that ...", "dateLastCrawled": "2021-12-24T06:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Ensemble Based Co-Training</b> | Hamideh Afsarmanesh - Academia.edu", "url": "https://www.academia.edu/7170674/Ensemble_Based_Co_Training", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/7170674/<b>Ensemble_Based_Co_Training</b>", "snippet": "In <b>co-training</b>, two classifiers based on different views of data or on different <b>learning</b> algorithms are trained in parallel and then unlabeled data that are classified differently by the classifiers but for which one classifier has large confidence are labeled and used as training data for the <b>other</b>. In this paper, a new form of <b>co-training</b>, called Ensemble-<b>Co-Training</b>, is proposed that uses an ensemble of different <b>learning</b> al- gorithms. Based on a theorem by Angluin and Laird that ...", "dateLastCrawled": "2022-01-18T23:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Symmetry | Free Full-Text | <b>Co-Training Semi-Supervised Deep Learning</b> ...", "url": "https://www.mdpi.com/2073-8994/12/1/8/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2073-8994/12/1/8/htm", "snippet": "<b>Co-training</b> is a semi-supervised <b>learning</b> technique which trains two classifiers based on two different views of data . It assumes that <b>each</b> sample is described based on two different feature views that provide different, complementary information about the sample. Ideally, the two views are independent and <b>each</b> view is sufficient, such that the class of a sample can be accurately predicted <b>from each</b> view alone. <b>Co-training</b> first learns a separate classifier for <b>each</b> view using a small ...", "dateLastCrawled": "2022-01-11T20:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Co-Training</b> of Audio and Video Representations from Self-Supervised ...", "url": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi?article=1129&context=senior_theses", "isFamilyFriendly": true, "displayUrl": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi?article=1129&amp;context=senior...", "snippet": "<b>Co-Training</b> of Audio and Video <b>Representations from Self-Supervised Temporal Synchronization</b>. Undergraduate Thesis. written by Bruno Korbar under the supervision of Professor Lorenzo Torresani and Du Tran, and submitted to the Committee as a culminating experience for the degree of. Bachelor of Arts in Computer Science. at Dartmouth College. Date of the public presentation: Members of the Thesis Committee: May 29, 2018 Prof Lorenzo Torresani Prof Saeed Hassanpour Prof Venkatramanan Siva ...", "dateLastCrawled": "2021-12-29T12:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Co-Training</b> as a Human Collaboration Policy", "url": "https://pages.cs.wisc.edu/~jerryzhu/pub/human_cotraining.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~jerryzhu/pub/human_<b>cotraining</b>.pdf", "snippet": "<b>learning</b> point of view, <b>humans</b> can show quite different pat-terns of behavior depending on whether the dimensions are integral or separable. For instance, people have dif\ufb01culty <b>learning</b> non-axis-parallel boundaries for separable but not for integral feature dimensions (Nosofsky and Palmeri 1996; Ashby and Maddox 1990). This paper considers whether these characteristics of hu-man <b>learning</b> can be altered by leveraging insights from a machine <b>learning</b> algorithm, namely <b>Co-Training</b>. Co ...", "dateLastCrawled": "2022-02-02T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Co-Training</b> as a Human Collaboration Policy", "url": "https://ojs.aaai.org/index.php/AAAI/article/view/7945/7804", "isFamilyFriendly": true, "displayUrl": "https://ojs.aaai.org/index.php/AAAI/article/view/7945/7804", "snippet": "<b>Co-Training</b> algorithm in machine <b>learning</b>, in which the two people play the role of the base learners. The policy restricts <b>each</b> learner\u2019s view of the data and limits their communica-tion to only the exchange of their labelings on test items. In a series of empirical studies, we show that the <b>Co-Training</b> policy leads collaborators to jointly produce unique and po-tentially valuable classi\ufb01cation outcomes that are not gener-ated under <b>other</b> collaboration policies. We further demon-strate ...", "dateLastCrawled": "2022-01-01T10:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Co-Training as a Human Collaboration Policy</b>", "url": "https://www.researchgate.net/publication/221604476_Co-Training_as_a_Human_Collaboration_Policy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221604476_<b>Co-Training</b>_as_a_Human...", "snippet": "We propose a novel collaboration policy based on the <b>Co-Training</b> algorithm in machine <b>learning</b>, in which the two people play the role of the base learners. The policy restricts <b>each</b> learner\u2019s ...", "dateLastCrawled": "2022-01-03T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Blog Classi\ufb01cation with <b>Co-training</b>", "url": "https://web.eecs.umich.edu/~cscott/past_courses/eecs545f07/projects/GerrishQazvinianShi.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.eecs.umich.edu/~cscott/past_courses/eecs545f07/projects/GerrishQazvinian...", "snippet": "<b>Co-training</b> is somewhat <b>similar</b> to Yarowsky\u2019s approach to the word sense disambiguation task [14]. Some words have multiple meanings, some quite di\ufb00erent from another. An example is \u201cbanK\u201d, which can be a verb, as in \u201cthe plane banked to the right\u201d, or a noun, as in \u201cI deposited my money in the bank.\u201d The word sense disambiguation problem is to determine the sense of a word given it\u2019s surrounding context or use. Yarowsky observed that in a single document, all instances of ...", "dateLastCrawled": "2022-01-12T19:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Email Classi\ufb01cation with <b>Co-Training</b>", "url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.408.8821&rep=rep1&type=pdf", "isFamilyFriendly": true, "displayUrl": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.408.8821&amp;rep=rep1&amp;type=pdf", "snippet": "by combining <b>co-training</b> and active <b>learning</b> in the form of using <b>humans</b> to correct inaccurate labels made by <b>co-training</b>. Another variant of combining <b>co-training</b> and active <b>learning</b> has been proposed in [12]. Co-Test(Co-EM) extends <b>co-training</b> in that it asks to explicitly label examples on which the two classi\ufb01ers of <b>co-training</b> have di\ufb00erent opin-ions. Nigam and Ghani[13] performed exten-sive experiments comparing the performance of <b>co-training</b> and another popular algo-rithm that ...", "dateLastCrawled": "2021-09-22T07:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) A <b>review of research on co\u2010training</b>", "url": "https://www.researchgate.net/publication/350194568_A_review_of_research_on_co-training", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350194568_A_review_of_research_on_<b>co-training</b>", "snippet": "As a method of multi-view <b>learning</b>, <b>co-training</b> improves the gener alization ability of the model through the cooperation among multiple. learners (Figure 3). T ak e <b>co-training</b> under two views as ...", "dateLastCrawled": "2022-02-03T12:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Ensemble Based <b>Co-Training</b> | Jafar Tanha - Academia.edu", "url": "https://www.academia.edu/33536005/Ensemble_Based_Co_Training", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/33536005/Ensemble_Based_<b>Co_Training</b>", "snippet": "The rest of the <b>co-training</b> process in their method <b>is similar</b> to the standard <b>co-training</b>. Later, the same authors propose Democratic Co- <b>Learning</b> [14]. In democratic co-<b>learning</b>, a set of different <b>learning</b> algorithms is used to train a set of classifiers separately on the labeled data set in self-training manner. In this method also they use a statistical method for selecting unlabeled data for labeling. It does not rely on the existence of two views, but their method uses a time ...", "dateLastCrawled": "2021-12-24T06:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Frontiers | Time and Action <b>Co-Training</b> in Reinforcement <b>Learning</b> ...", "url": "https://www.frontiersin.org/articles/10.3389/fcteg.2021.722092/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fcteg.2021.722092", "snippet": "\u2022 <b>Co-training</b> time and action in a reinforcement <b>learning</b> agent on a simple task-switching scenario. \u2022 Temporal scaling: the time intervals of <b>each</b> circle occur at different speeds. For instance, at Speed 2, circle 1 in Figure 1 must be clicked between 750 and 850 ms; similarly, circles 2, 3, and 4 must be clicked at 1,450\u20131,550, 2,250\u20132,350, and 3,250\u20133,350 ms, respectively.", "dateLastCrawled": "2022-01-30T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Multiple Feature Fusion Based on <b>Co-Training</b> Approach and Time ...", "url": "https://www.hindawi.com/journals/am/2013/175064/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/am/2013/175064", "snippet": "<b>Other</b> works follow a <b>similar</b> reasoning but use different combination rules (max, product, etc.), as discussed in ... Experimental evaluation will reveal relative performances of <b>each</b> method with respect to baseline and with respect to <b>each</b> <b>other</b>. (a) (b) (a) (b) Figure 3 . <b>Co-Training</b> with late fusion (a); <b>Co-Training</b> with temporal accumulation (b). The full algorithm of the CO-DAS (or CO-TA-DAS if temporal accumulation is enabled) method is presented in Algorithm 1. Besides the base ...", "dateLastCrawled": "2022-01-23T00:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the difference between semi-supervised <b>learning</b> and ...", "url": "https://www.quora.com/What-is-the-difference-between-semi-supervised-learning-and-transductive-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-semi-supervised-<b>learning</b>-and...", "snippet": "Answer (1 of 2): <b>Similar</b> questions have been already asked and answered in Quora at the following links: What is transductive <b>learning</b>? What is the difference between inductive and transductive <b>learning</b>? Concisely, the difference is subtle, but you have to remember that the two terms refer to ...", "dateLastCrawled": "2022-01-26T17:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Co-Training</b> as a Human Collaboration Policy", "url": "https://pages.cs.wisc.edu/~jerryzhu/pub/human_cotraining.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~jerryzhu/pub/human_<b>cotraining</b>.pdf", "snippet": "<b>learning</b> point of view, <b>humans</b> <b>can</b> show quite different pat-terns of behavior depending on whether the dimensions are integral or separable. For instance, people have dif\ufb01culty <b>learning</b> non-axis-parallel boundaries for separable but not for integral feature dimensions (Nosofsky and Palmeri 1996; Ashby and Maddox 1990). This paper considers whether these characteristics of hu-man <b>learning</b> <b>can</b> be altered by leveraging insights from a machine <b>learning</b> algorithm, namely <b>Co-Training</b>. Co ...", "dateLastCrawled": "2022-02-02T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Co-Training</b> as a Human Collaboration Policy", "url": "https://ojs.aaai.org/index.php/AAAI/article/view/7945/7804", "isFamilyFriendly": true, "displayUrl": "https://ojs.aaai.org/index.php/AAAI/article/view/7945/7804", "snippet": "<b>each</b> learner\u2019s view of the data and limits their communica-tion to only the exchange of their labelings on test items. In a series of empirical studies, we show that the <b>Co-Training</b> policy leads collaborators to jointly produce unique and po-tentially valuable classi\ufb01cation outcomes that are not gener-ated under <b>other</b> collaboration policies. We further demon-strate that these observations <b>can</b> be explained with appropri-ate machine <b>learning</b> models. Though human <b>learning</b> abilities are ...", "dateLastCrawled": "2022-01-01T10:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Co-Training as a Human Collaboration Policy</b>", "url": "https://www.researchgate.net/publication/221604476_Co-Training_as_a_Human_Collaboration_Policy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221604476_<b>Co-Training</b>_as_a_Human...", "snippet": "In this case, the problem <b>can</b> be considered as a supervised <b>learning</b> problem, and for its solution <b>can</b> be used conventional algorithms of ensemble <b>learning</b>, like boosting [10, 18, 6]. On the <b>other</b> ...", "dateLastCrawled": "2022-01-03T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "6 Achieving Intelligence | <b>Computer Science: Reflections on the Field</b> ...", "url": "https://www.nap.edu/read/11106/chapter/8", "isFamilyFriendly": true, "displayUrl": "https://www.nap.edu/read/11106/chapter/8", "snippet": "The <b>co-training</b> problem setting <b>can</b> then be defined as a special case of <b>learning</b> a classifier, where (1) the input instances X <b>can</b> be described as X 1 \u00d7 X 2 (i.e., X 1 = hyperlink words, X 2 = Web page words), and where (2) one <b>can</b> compute f based on either X 1 or X 2 (formally, there exist functions g 1 and g 2 such that f(x) = g 1 (x 1) = g 2 (x 2) for any x = x 1, x 2.", "dateLastCrawled": "2021-11-07T07:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Artificial intelligence with multi-functional machine <b>learning</b> platform ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7078068/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7078068", "snippet": "Deep <b>learning</b> (253,254) has proven to be one of the most trending algorithms today, but this does not undermine the importance of <b>other</b> machine <b>learning</b> algorithms. We believe that a right approach and algorithm should be chosen for the development of the most effective solutions to the targeted problems. In spite of various traditional and AI-based solutions, current limitations and challenges by the healthcare community include uneven distribution of resources towards the future of digital ...", "dateLastCrawled": "2022-01-22T02:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Frontiers | Resilience Competence Face Framework for the Unforeseen ...", "url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2021.669904/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fpsyg.2021.669904", "snippet": "Preparing and <b>learning</b> from highly infrequent and unknown events therefore appears to represent a contradiction (Lanir, 1983; ... (P7), at formalized collaboration and <b>co-training</b> with <b>other</b> actors (P13). The second sub-theme, Leadership Competencies, primarily relates to relational aspects, and to the responsibility of ensuring that people are mentally, emotionally and practically prepared. It also refers to the ability to build situational awareness, and then make relevant decisions ...", "dateLastCrawled": "2021-12-09T19:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Speech Emotion Recognition</b>: Two Decades in a Nutshell, Benchmarks, and ...", "url": "https://cacm.acm.org/magazines/2018/5/227191-speech-emotion-recognition/fulltext", "isFamilyFriendly": true, "displayUrl": "https://cacm.acm.org/magazines/2018/5/227191", "snippet": "A similar <b>thought</b> is followed by the recent use of generative adversarial network topologies, where a first neural network learns to synthesize training material, and another to recognize real from synthesized material and the task of interest. 5 Obviously, transfer <b>learning</b> <b>can</b> bridge the gap between artificial and real speech. In future efforts, a closer and immediate coupling between synthesis and analysis of emotional speech could help render this process more efficient.", "dateLastCrawled": "2022-02-03T06:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How <b>are autonomous systems and machine learning related</b> to <b>each</b> <b>other</b> ...", "url": "https://www.quora.com/How-are-autonomous-systems-and-machine-learning-related-to-each-other", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>are-autonomous-systems-and-machine-learning-related</b>-to-<b>each</b>...", "snippet": "Answer (1 of 2): Just as you learned what you now know from experience throughout your life (and still going strong, I hope), and because you are also an autonomous system, <b>learning</b> of many kinds is a strong candidate from building a machine that acquires its knowledge through <b>learning</b>, tempered ...", "dateLastCrawled": "2022-01-19T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "ACL 2018 Highlights: Understanding Representations and Evaluation in ...", "url": "https://aylien.com/blog/acl-2018-highlights-understanding-representations-and-evaluation-in-more-challenging-settings", "isFamilyFriendly": true, "displayUrl": "https://aylien.com/blog/acl-2018-highlights-understanding-representations-and...", "snippet": "They find that in single-sentence context, models outperform <b>humans</b>, while <b>humans</b> are slightly better in multi-sentence contexts. Kuncoro et al. evaluate LSTMs on modeling subject-verb agreement. They find that with enough capacity, LSTMs <b>can</b> model subject-verb agreement, but that more syntax-sensitive models such as recurrent neural network grammars do even better. Blevins et al. evaluate models pretrained on different tasks whether they capture a hierarchical notion of syntax. Specifically ...", "dateLastCrawled": "2022-01-12T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>New submissions for Tue, 13 Apr</b> 21 \u00b7 Issue #309 \u00b7 kobiso/daily-arxiv ...", "url": "https://github.com/kobiso/daily-arxiv-noti/issues/309", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/kobiso/daily-arxiv-noti/issues/309", "snippet": "We study the problem of automated mechanism design with partial verification, where <b>each</b> type <b>can</b> (mis)report only a restricted set of types (rather than any <b>other</b> type), induced by the principal&#39;s limited verification power. We prove hardness results when the revelation principle does not necessarily hold, as well as when types have even minimally different preferences. In light of these hardness results, we focus on truthful mechanisms in the setting where all types share the same ...", "dateLastCrawled": "2021-10-20T12:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Co-Training</b> for Deep Object Detection: Comparing Single-Modal and Multi ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8125436/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8125436", "snippet": "In these settings, we have <b>compared</b> multi-modal <b>co-training</b> and appearance-based single-modal <b>co-training</b>. We have shown that multi-modal <b>co-training</b> is effective in all settings. In the standard SSL setting, from a 5% of human-labeled training data, <b>co-training</b> <b>can</b> already lead to a final object detection accuracy relatively close to upper bounds (i.e., with the 100% of human labeling). The same observation holds when using virtual-world data, i.e., without human labeling at all. Multi ...", "dateLastCrawled": "2021-11-15T05:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Co-Training</b> as a Human Collaboration Policy", "url": "https://pages.cs.wisc.edu/~jerryzhu/pub/human_cotraining.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~jerryzhu/pub/human_<b>cotraining</b>.pdf", "snippet": "<b>learning</b> point of view, <b>humans</b> <b>can</b> show quite different pat-terns of behavior depending on whether the dimensions are integral or separable. For instance, people have dif\ufb01culty <b>learning</b> non-axis-parallel boundaries for separable but not for integral feature dimensions (Nosofsky and Palmeri 1996; Ashby and Maddox 1990). This paper considers whether these characteristics of hu-man <b>learning</b> <b>can</b> be altered by leveraging insights from a machine <b>learning</b> algorithm, namely <b>Co-Training</b>. Co ...", "dateLastCrawled": "2022-02-02T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Cross-resolution face matching based on ensemble co-transfer <b>learning</b>", "url": "https://www.ijser.org/researchpaper/Cross-resolution-face-matching-based-on-ensemble-co-transfer-learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijser.org/researchpaper/Cross-resolution-face-matching-based-on-ensemble...", "snippet": "the amalgamation of transfer <b>learning</b> and <b>co-training</b> is shown in the below figure[1]. Figure 4: Cross pollination of transfer <b>learning</b> and <b>co-training</b> for transferring knowledge from the source domain to target domain . Transfer <b>learning</b>: <b>Humans</b> <b>can</b> often transfer knowledge learnt previously to novel situations.", "dateLastCrawled": "2021-09-16T06:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Co-Training</b> of Audio and Video Representations from Self-Supervised ...", "url": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi?article=1129&context=senior_theses", "isFamilyFriendly": true, "displayUrl": "https://digitalcommons.dartmouth.edu/cgi/viewcontent.cgi?article=1129&amp;context=senior...", "snippet": "<b>Co-Training</b> of Audio and Video <b>Representations from Self-Supervised Temporal Synchronization</b>. Undergraduate Thesis. written by Bruno Korbar under the supervision of Professor Lorenzo Torresani and Du Tran, and submitted to the Committee as a culminating experience for the degree of. Bachelor of Arts in Computer Science. at Dartmouth College. Date of the public presentation: Members of the Thesis Committee: May 29, 2018 Prof Lorenzo Torresani Prof Saeed Hassanpour Prof Venkatramanan Siva ...", "dateLastCrawled": "2021-12-29T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Frontiers | Time and Action <b>Co-Training</b> in Reinforcement <b>Learning</b> ...", "url": "https://www.frontiersin.org/articles/10.3389/fcteg.2021.722092/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fcteg.2021.722092", "snippet": "\u2022 <b>Co-training</b> time and action in a reinforcement <b>learning</b> agent on a simple task-switching scenario. \u2022 Temporal scaling: the time intervals of <b>each</b> circle occur at different speeds. For instance, at Speed 2, circle 1 in Figure 1 must be clicked between 750 and 850 ms; similarly, circles 2, 3, and 4 must be clicked at 1,450\u20131,550, 2,250\u20132,350, and 3,250\u20133,350 ms, respectively.", "dateLastCrawled": "2022-01-30T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Co-Training</b> for <b>Deep Object Detection: Comparing Single</b> ... - Europe PMC", "url": "https://europepmc.org/article/PMC/PMC8125436", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC8125436", "snippet": "Top-performing computer vision models are powered by convolutional neural networks (CNNs). Training an accurate CNN highly depends on both the raw sensor data and their associated", "dateLastCrawled": "2021-05-28T19:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Semi-Supervised <b>Learning</b>", "url": "https://www.cs.cmu.edu/~10701/slides/17_SSL.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~10701/slides/17_SSL.pdf", "snippet": "Semi-Supervised <b>learning</b> in <b>Humans</b> 6. <b>Can</b> unlabeled data help? Assume <b>each</b> class is a coherent group (e.g. Gaussian) Then unlabeled data <b>can</b> help identify the boundary more accurately. Positive labeled data Negative labeled data Unlabeled data Supervised Decision Boundary Semi-Supervised Decision Boundary 7. <b>Can</b> unlabeled data help? 3 5 8 7 9 4 2 1 5 4 2 1 \u201c0\u201d \u201c1\u201d \u201c2\u201d \u2026 \u201cSimilar\u201d data points have \u201csimilar\u201d labels 8 This embedding <b>can</b> be done by manifold <b>learning</b> ...", "dateLastCrawled": "2022-01-30T05:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Top 8 <b>Resources To Learn Self-Supervised Learning In</b> 2021", "url": "https://analyticsindiamag.com/top-8-resources-to-learn-self-supervised-learning-in-2021/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/top-8-<b>resources-to-learn-self-supervised-learning-in</b>-2021", "snippet": "It talks about popular semi-supervised <b>learning</b> models like self-training, mixture models, <b>co-training</b>, graph-based methods and more. The book further discusses the basic mathematical formulation, assumptions and limitations of <b>each</b> model. It is a good starting point for understanding the nuances of semi-supervised <b>learning</b> before experimenting ...", "dateLastCrawled": "2022-01-26T00:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Speech Emotion Recognition: Two Decades in</b> a Nutshell, Benchmarks, and ...", "url": "https://m-cacm.acm.org/magazines/2018/5/227191-speech-emotion-recognition/fulltext?mobile=true", "isFamilyFriendly": true, "displayUrl": "https://m-cacm.acm.org/magazines/2018/5/227191-speech-emotion-recognition/fulltext?...", "snippet": "In <b>other</b> words, one learns to estimate for new data if <b>humans</b> would agree or likely disagree on its emotion. Ideally, this <b>can</b> be targeted as a multitask problem <b>learning</b> the emotion and human agreement in parallel. 2) One <b>can</b> train a second <b>learning</b> algorithm to predict errors of the emotion recognition engine. To this end, one needs to run ...", "dateLastCrawled": "2022-01-16T23:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Never-Ending <b>Learning</b> | May 2018 | Communications of the ACM", "url": "https://cacm.acm.org/magazines/2018/5/227193-never-ending-learning/fulltext", "isFamilyFriendly": true, "displayUrl": "https://cacm.acm.org/magazines/2018/5/227193-never-ending-<b>learning</b>", "snippet": "<b>Other</b> machine <b>learning</b> paradigms exist as well (e.g., unsupervised clustering, topic modeling, reinforcement <b>learning</b>) but these paradigms also typically acquire only a single function or data model from a single dataset. In contrast to these paradigms for <b>learning</b> single functions from well organized data sets over short time-frames, <b>humans</b> learn many different functions (i.e., different types of knowledge) over years of accumulated diverse experience, using extensive background knowledge ...", "dateLastCrawled": "2022-01-24T06:22:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Self-Supervised Graph <b>Co-Training</b> for Session-based Recommendation | DeepAI", "url": "https://deepai.org/publication/self-supervised-graph-co-training-for-session-based-recommendation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/self-supervised-graph-<b>co-training</b>-for-session-based...", "snippet": "<b>Co-Training</b> is a classical semi-supervised <b>learning</b> paradigm to exploit unlabeled data (Blum and Mitchell, 1998; Da Costa et al., 2018; Han et al., 2020). Under this regime, two classifiers are separately trained on two views and then exchange confident pseudo labels of unlabeled instances to construct additional labeled training data for each other. Typically, the two views are two disjoint sets of features and can provide complementary information to each other. Blum", "dateLastCrawled": "2022-02-01T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Supervised Learning and Co-training</b> | Request PDF", "url": "https://www.researchgate.net/publication/268809884_Supervised_Learning_and_Co-training", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/268809884_<b>Supervised_Learning_and_Co-training</b>", "snippet": "\u2022 <b>Co-Training</b> [2]: It is a <b>machine</b> <b>learning</b> algorithm used when there are only some labeled data and large amounts of unlabeled data. One of its uses is in text mining for search engines. ...", "dateLastCrawled": "2021-10-24T01:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Co-training</b> and self-<b>training for word sense disambiguation</b> ...", "url": "https://www.academia.edu/1305075/Co_training_and_self_training_for_word_sense_disambiguation", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/1305075/<b>Co_training</b>_and_self_training_for_word_sense...", "snippet": "Self-training leads to the training to natural language <b>learning</b>, where one general highest precision for nine words, while <b>co-training</b> is win- classifier is build to cover the entire problem space, su- ning for eight words; there is a tie with equal performance pervised word sense disambiguation implies a different for both <b>co-training</b> and self-training for the remaining classifier for each individual word, resulting eventually twelve words. in thousands of different classifiers, each with ...", "dateLastCrawled": "2021-12-29T04:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Cooperative <b>Learning</b> of Energy-Based Model and Latent Variable Model ...", "url": "http://www.stat.ucla.edu/~ywu/CoopNets/doc/CoopNets_AAAI.pdf", "isFamilyFriendly": true, "displayUrl": "www.stat.ucla.edu/~ywu/CoopNets/doc/CoopNets_AAAI.pdf", "snippet": "3Amazon RSML (Retail System <b>Machine</b> <b>Learning</b>) Group Abstract This paper proposes a cooperative <b>learning</b> algorithm to train both the undirected energy-based model and the directed latent variable model jointly. The <b>learning</b> algorithm interweaves the maximum likelihood algorithms for <b>learning</b> the two models, and each iteration consists of the following two steps: (1) Modi\ufb01ed contrastive divergence for energy-based model: The <b>learning</b> of the energy-based model is based on the contrastive ...", "dateLastCrawled": "2022-02-03T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interacting meaningfully with machine learning systems</b>: Three ...", "url": "https://dl.acm.org/doi/10.1016/j.ijhcs.2009.03.004", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/10.1016/j.ijhcs.2009.03.004", "snippet": "Although <b>machine</b> <b>learning</b> is becoming commonly used in today&#39;s software, there has been little research into how end users might interact with <b>machine</b> <b>learning</b> systems, beyond communicating simple &#39;&#39;right/wrong&#39;&#39; judgments. If the users themselves could work hand-in-hand with <b>machine</b> <b>learning</b> systems, the users&#39; understanding and trust of the system could improve and the accuracy of <b>learning</b> systems could be improved as well. We conducted three experiments to understand the potential for ...", "dateLastCrawled": "2022-01-28T03:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Using Machine Learning to Understand and Enhance Human Learning Capacity</b>", "url": "http://pages.cs.wisc.edu/~jerryzhu/career/", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~jerryzhu/career", "snippet": "<b>Using Machine Learning to Understand and Enhance Human Learning Capacity</b> Research Projects The overall goal of the project is to develop computational <b>learning</b> models and theory, originally aimed at computers, to predict and influence human <b>learning</b> behaviors. Capacity measure of the human mind What is the VC-dimension of the human mind? In <b>machine</b> <b>learning</b>, the VC-dimension is a well-known capacity measure for a model family. What if the &quot;model family&quot; is the human mind, e.g., all the ...", "dateLastCrawled": "2022-02-01T10:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning from positive</b> and unlabeled data: a survey - <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "<b>Learning from positive</b> and unlabeled data or PU <b>learning</b> is the setting where a learner only has access to positive examples and unlabeled data. The assumption is that the unlabeled data can contain both positive and negative examples. This setting has attracted increasing interest within the <b>machine</b> <b>learning</b> literature as this type of data naturally arises in applications such as medical diagnosis and knowledge base completion. This article provides a survey of the current state of the art ...", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>100 Must-Read</b> NLP Papers | This is a list of 100 important natural ...", "url": "http://masatohagiwara.net/100-nlp-papers/", "isFamilyFriendly": true, "displayUrl": "masatohagiwara.net/100-nlp-papers", "snippet": "<b>Machine</b> <b>Learning</b>. Avrim Blum and Tom Mitchell: Combining Labeled and Unlabeled Data with <b>Co-Training</b>, 1998. John Lafferty, Andrew McCallum, Fernando C.N. Pereira: Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data, ICML 2001. Charles Sutton, Andrew McCallum. An Introduction to Conditional Random Fields for Relational <b>Learning</b>. Kamal Nigam, et al.: Text Classification from Labeled and Unlabeled Documents using EM. <b>Machine</b> <b>Learning</b>, 1999. Kevin Knight ...", "dateLastCrawled": "2022-01-31T22:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Do you know any simple criterion to split features into two views as in ...", "url": "https://www.quora.com/Do-you-know-any-simple-criterion-to-split-features-into-two-views-as-in-co-training", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Do-you-know-any-simple-criterion-to-split-features-into-two...", "snippet": "Answer: This is an extremely nontrivial task. One can do plenty of research and related work on it. If I&#39;d be doing it, I would try the following things, on the order of difficulty and excitement: 1) Compute how some features correlate with others. First, pick a data set and rank-order the va...", "dateLastCrawled": "2022-01-14T14:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Interacting meaningfully with <b>machine</b> <b>learning</b> systems : three ...", "url": "https://core.ac.uk/display/10196053", "isFamilyFriendly": true, "displayUrl": "https://core.ac.uk/display/10196053", "snippet": "Although <b>machine</b> <b>learning</b> is becoming commonly used in today&#39;s software, there has been little research into how end users might interact with <b>machine</b> <b>learning</b> systems, beyond communicating simple &quot;right/wrong&quot; judgments. If the users themselves could somehow work hand-in-hand with <b>machine</b> <b>learning</b> systems, the accuracy of <b>learning</b> systems could be improved and the users&#39; understanding and trust of the system could improve as well. We conducted three experiments to begin to understand the ...", "dateLastCrawled": "2018-09-22T01:11:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) A <b>literature survey of active machine learning</b> in the context of ...", "url": "https://www.researchgate.net/publication/228682097_A_literature_survey_of_active_machine_learning_in_the_context_of_natural_language_processing", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228682097_A_literature_survey_of_active...", "snippet": "Active <b>machine</b> <b>learning</b> is a supervised <b>learning</b> method in which the learner. is in control of the data from which it learns. That control is used by. the learner to ask an oracle, a teacher ...", "dateLastCrawled": "2022-02-01T01:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Deep <b>Learning</b> for Sensor-based Human Activity Recognition ...", "url": "https://www.researchgate.net/publication/338737352_Deep_Learning_for_Sensor-based_Human_Activity_Recognition_Overview_Challenges_and_Opportunities", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338737352_Deep_<b>Learning</b>_for_Sensor-based...", "snippet": "Many <b>machine</b> <b>learning</b> methods have been employed in human activity recognition. However ... The process of <b>co-training is like</b> the process of human <b>learning</b>. People can learn new knowledge. from ...", "dateLastCrawled": "2022-01-09T11:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Deep <b>Learning</b> for Sensor-based Human Activity Recognition: Overview ...", "url": "https://deepai.org/publication/deep-learning-for-sensor-based-human-activity-recognition-overview-challenges-and-opportunities", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/deep-<b>learning</b>-for-sensor-based-human-activity...", "snippet": "Transfer <b>learning</b> is a common <b>machine</b> <b>learning</b> technique that transfers the classification ability of the <b>learning</b> model from one predefined setting to a dynamic setting. Transfer <b>learning</b> is particularly effective in solving heterogeneity problems. It avoids the decline in the performance of <b>learning</b> models when the training data and the test data follow different distributions. In the activity recognition context, this problem appears when activity recognition models are deployed for ...", "dateLastCrawled": "2022-01-11T03:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Instance labeling in semi-supervised <b>learning</b> with meaning values of ...", "url": "https://www.sciencedirect.com/science/article/pii/S0952197617300672", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0952197617300672", "snippet": "In <b>machine</b> <b>learning</b> applications, especially in the field of text classification there are two conventional strategies; supervised <b>learning</b> and unsupervised <b>learning</b>. A sufficient amount of labeled data is required as training corpus to build the classifier in conventional supervised classification methods, which will be helpful to guess the class labels of the unlabeled instances. Conversely, unsupervised <b>learning</b>, only depends on unlabeled instances, and doesn\u2019t require class labels to ...", "dateLastCrawled": "2022-01-11T19:09:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(co-training)  is like +(humans learning from each other)", "+(co-training) is similar to +(humans learning from each other)", "+(co-training) can be thought of as +(humans learning from each other)", "+(co-training) can be compared to +(humans learning from each other)", "machine learning +(co-training AND analogy)", "machine learning +(\"co-training is like\")", "machine learning +(\"co-training is similar\")", "machine learning +(\"just as co-training\")", "machine learning +(\"co-training can be thought of as\")", "machine learning +(\"co-training can be compared to\")"]}