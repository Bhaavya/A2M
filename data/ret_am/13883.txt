{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What kind of risk-taker are you: Maximax, Minimin, or <b>Minimax</b>? A ...", "url": "https://cauzalai.medium.com/what-kind-of-risk-taker-are-you-maximax-minimin-or-minimax-a-decision-making-framework-e18cf05e8883", "isFamilyFriendly": true, "displayUrl": "https://cauzalai.medium.com/what-kind-of-risk-taker-are-you-maximax-minimin-or-<b>minimax</b>...", "snippet": "<b>Minimizing</b> the <b>potential</b> regret (<b>loss</b> or missing out) \u2014 <b>Minimax</b>; We all want to avoid regret while maximizing success in what we do. Oh, and all that with controlled risk, of course. How do we model that? Jeff Bezos made his Regret Minimization framework pretty famous: Jeff Bezos\u2019 regret minimization framework. Now\u2026while this is inspirational, I have a hard time applying that to most of my decisions. I am pretty analytical and I need more data to make decisions. The regret aversion ...", "dateLastCrawled": "2022-01-29T19:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What kind of risk-taker are you: Maximax, Maximin, or <b>Minimax</b>? A ...", "url": "https://www.linkedin.com/pulse/what-kind-risk-taker-you-maximax-minimin-minimax-framework-mahe", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/what-kind-risk-taker-you-maximax-minimin-<b>minimax</b>...", "snippet": "<b>Minimizing</b> the <b>potential</b> regret (<b>loss</b> or missing out) \u2014 <b>Minimax</b> We all want to avoid regret while maximizing success in what we do. Oh, and all that with controlled risk, of course.", "dateLastCrawled": "2022-01-18T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Algorithms from First Principles: <b>Minimax</b>", "url": "https://gtejas.com/algorithms-from-first-principles-minimax", "isFamilyFriendly": true, "displayUrl": "https://gtejas.com/algorithms-from-first-principles-<b>minimax</b>", "snippet": "<b>Minimax</b> is a backtracking algorithm used in Game Theory and Artificial Intelligence to minimize the worst-case <b>potential</b> <b>loss</b>. In better words, it is used to find an optimal strategy for two adversaries in a perfect information scenario. This algorithm is commonly used in two-player combinatorial games such as Chess and Go. The player employing this strategy considers the opponent&#39;s every move and assigns a payoff to the state of the game succeeding the opponent&#39;s move. He then picks the ...", "dateLastCrawled": "2021-12-04T08:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is <b>Minimax</b> decision analysis? - TreeHozz.com", "url": "https://treehozz.com/what-is-minimax-decision-analysis", "isFamilyFriendly": true, "displayUrl": "https://treehozz.com/what-is-<b>minimax</b>-decision-analysis", "snippet": "4.6/5 (62 Views . 34 Votes) <b>Minimax</b> (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for <b>minimizing</b> the possible <b>loss</b> for a worst case (maximum <b>loss</b>) scenario. When dealing with gains, it is referred to as &quot;maximin&quot;\u2014to maximize the minimum gain.", "dateLastCrawled": "2022-01-29T12:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What Type Of Algorithm Is <b>Minimax</b>? \u2013 chetumenu.com", "url": "https://chetumenu.com/what-type-of-algorithm-is-minimax/", "isFamilyFriendly": true, "displayUrl": "https://chetumenu.com/what-type-of-algorithm-is-<b>minimax</b>", "snippet": "<b>Minimax</b> (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for <b>minimizing</b> the possible <b>loss</b> for a worst case (maximum <b>loss</b>) scenario. When dealing with gains, it is referred to as &quot;maximin&quot;\u2014to maximize the minimum gain.", "dateLastCrawled": "2022-01-22T12:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 5, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Minimax</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Minimax", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Minimax</b>", "snippet": "<b>Minimax</b> (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for <b>minimizing</b> the possible <b>loss</b> for a worst case (maximum <b>loss</b>) scenario.When dealing with gains, it is referred to as &quot;maximin&quot;\u2014to maximize the minimum gain. Originally formulated for n-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been ...", "dateLastCrawled": "2022-02-03T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A <b>Minimax</b> <b>Surrogate Loss Approach to Conditional Difference Estimation</b> ...", "url": "https://deepai.org/publication/a-minimax-surrogate-loss-approach-to-conditional-difference-estimation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-<b>minimax</b>-<b>surrogate-loss-approach-to-conditional</b>...", "snippet": "The 0-1 <b>loss</b> implicit in their formulation seems to be the sum of 0-1 <b>losses</b> for predictions of both treatment and control outcomes rather than a 0-1 <b>loss</b> for treatment effects. In this work, we prove that the 0-1 <b>loss</b> for prediction of outcomes is an upper bound on a relevant 0-1 <b>loss</b> for treatment effects, motivating the use of their 0-1 <b>loss</b>, but showing that it is a loose upper bound. In our formulation we use a tighter upper bound than the sum of 0-1 <b>losses</b> for prediction. The method of", "dateLastCrawled": "2022-01-03T10:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Minimax Expected Opportunity Loss: A</b> New Criterion for Risk-Based ...", "url": "https://www.researchgate.net/publication/263154234_Minimax_Expected_Opportunity_Loss_A_New_Criterion_for_Risk-Based_Decision_Making", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/263154234_<b>Minimax_Expected_Opportunity_Loss_A</b>...", "snippet": "A risk measure, expected opportunity <b>loss</b> (EOL), is introduced to quantify the <b>potential</b> <b>loss</b> of making an incorrect choice in risk-based decision making. Different from Savage&#39;s (195122. Savage ...", "dateLastCrawled": "2021-10-23T18:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Minimax</b> Multi-Task Learning and a Generalized <b>Loss</b>-Compositional ...", "url": "https://www.researchgate.net/publication/230839821_Minimax_Multi-Task_Learning_and_a_Generalized_Loss-CompositionalParadigm_for_MTL", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/230839821_<b>Minimax</b>_Multi-Task_Learning_and_a...", "snippet": "Additionally, for the recently proposed <b>Minimax</b> MTL model [20], tasks are related by <b>minimizing</b> the maximum of the T <b>loss</b> functions, in order to guarantee some minimum level of accuracy for each ...", "dateLastCrawled": "2022-01-02T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "terminology - What does &quot;minmax&quot; mean? - Role-playing Games Stack Exchange", "url": "https://rpg.stackexchange.com/questions/64800/what-does-minmax-mean", "isFamilyFriendly": true, "displayUrl": "https://rpg.stackexchange.com/questions/64800", "snippet": "It comes from the term <b>minimax</b>, which is a zero-sum game theory (in a zero-sum game, your gains are exactly your opponents <b>losses</b>). The <b>minimax</b> theorem involves increasing your overall gains by <b>minimizing</b> your opponents maximum gains. This means you maximize your overall performance by <b>minimizing</b> your opponent&#39;s best performance.", "dateLastCrawled": "2022-01-29T01:01:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Minimax</b> decision analysis? - TreeHozz.com", "url": "https://treehozz.com/what-is-minimax-decision-analysis", "isFamilyFriendly": true, "displayUrl": "https://treehozz.com/what-is-<b>minimax</b>-decision-analysis", "snippet": "4.6/5 (62 Views . 34 Votes) <b>Minimax</b> (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for <b>minimizing</b> the possible <b>loss</b> for a worst case (maximum <b>loss</b>) scenario. When dealing with gains, it is referred to as &quot;maximin&quot;\u2014to maximize the minimum gain.", "dateLastCrawled": "2022-01-29T12:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 1, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Minimax</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Minimax", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Minimax</b>", "snippet": "<b>Minimax</b> (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for <b>minimizing</b> the possible <b>loss</b> for a worst case (maximum <b>loss</b>) scenario.When dealing with gains, it is referred to as &quot;maximin&quot;\u2014to maximize the minimum gain. Originally formulated for n-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been ...", "dateLastCrawled": "2022-02-03T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is <b>Minimax regret</b> rule? - TreeHozz.com", "url": "https://treehozz.com/what-is-minimax-regret-rule", "isFamilyFriendly": true, "displayUrl": "https://treehozz.com/what-is-<b>minimax-regret</b>-rule", "snippet": "<b>Minimax</b> (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for <b>minimizing</b> the possible <b>loss</b> for a worst case (maximum <b>loss</b>) scenario. When dealing with gains, it is referred to as &quot;maximin&quot;\u2014to maximize the minimum gain.", "dateLastCrawled": "2022-01-29T15:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Minimax</b> risk classifiers with 0-1 <b>loss</b> | Request PDF", "url": "https://www.researchgate.net/publication/357925572_Minimax_risk_classifiers_with_0-1_loss", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357925572_<b>Minimax</b>_risk_classifiers_with_0-1_<b>loss</b>", "snippet": "The <b>minimax</b> SVM, which is a relaxed version of the standard SVM, minimizes the worst-case 0-1 <b>loss</b> over the structured set of distribution, and by our numerical experiments can outperform the SVM ...", "dateLastCrawled": "2022-01-27T13:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Minimax</b> Pareto Fairness: A Multi Objective Perspective", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7912461/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7912461", "snippet": "Here we focus on <b>minimizing</b> the risk on the worst performing group (Definition 3.4), these two criteria often yield <b>similar</b> results, and can be shown to be identical for Pareto optimal classifiers when \u2223 A \u2223 = 2. For more than 2 sensitive groups, there may be situations where minimum risk discrepancy leads to higher <b>minimax</b> risk (e.g., a classifier that increases both the minimum and maximum risk but decreases their gap is still optimal if a third group sees their risk diminished ...", "dateLastCrawled": "2021-12-24T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Consolidation of a WSN and <b>Minimax</b> Method to Rapidly Neutralise ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3376604/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3376604", "snippet": "The aim is to minimise possible <b>losses</b> while maximising <b>potential</b> gain, in this context, this means capturing the intruders as soon as possible, avoiding as much as possible, any damage they can cause to the installations. Game theory has shown good results in problem solving in many contemporary fields, especially modelling and describing the behaviour of complex systems in economics [20,21]. One of these complex processes is risk analysis in strategic conflict . Some approaches face risk ...", "dateLastCrawled": "2017-01-05T19:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Minimax</b> Multi-Task Learning and a Generalized <b>Loss</b>-Compositional ...", "url": "https://www.researchgate.net/publication/230839821_Minimax_Multi-Task_Learning_and_a_Generalized_Loss-CompositionalParadigm_for_MTL", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/230839821_<b>Minimax</b>_Multi-Task_Learning_and_a...", "snippet": "Additionally, for the recently proposed <b>Minimax</b> MTL model [20], tasks are related by <b>minimizing</b> the maximum of the T <b>loss</b> functions, in order to guarantee some minimum level of accuracy for each ...", "dateLastCrawled": "2022-01-02T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A <b>Minimax</b> <b>Surrogate Loss Approach to Conditional Difference Estimation</b> ...", "url": "https://deepai.org/publication/a-minimax-surrogate-loss-approach-to-conditional-difference-estimation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-<b>minimax</b>-<b>surrogate-loss-approach-to-conditional</b>...", "snippet": "The 0-1 <b>loss</b> implicit in their formulation seems to be the sum of 0-1 <b>losses</b> for predictions of both treatment and control outcomes rather than a 0-1 <b>loss</b> for treatment effects. In this work, we prove that the 0-1 <b>loss</b> for prediction of outcomes is an upper bound on a relevant 0-1 <b>loss</b> for treatment effects, motivating the use of their 0-1 <b>loss</b>, but showing that it is a loose upper bound. In our formulation we use a tighter upper bound than the sum of 0-1 <b>losses</b> for prediction. The method of", "dateLastCrawled": "2022-01-03T10:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What <b>is a Maximin strategy game theory</b>? - AskingLot.com", "url": "https://askinglot.com/what-is-a-maximin-strategy-game-theory", "isFamilyFriendly": true, "displayUrl": "https://askinglot.com/what-<b>is-a-maximin-strategy-game-theory</b>", "snippet": "What is <b>Minimax</b> theory? In game theory, <b>minimax</b> is a decision rule used to minimize the worst-case <b>potential</b> <b>loss</b>; in other words, a player considers all of the best opponent responses to his strategies, and selects the strategy such that the opponent&#39;s best strategy gives a payoff as large as possible.", "dateLastCrawled": "2022-01-20T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Gmae Theory | PDF | Game Theory | Mathematical And Quantitative Methods ...", "url": "https://www.scribd.com/presentation/59054976/Gmae-Theory", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/presentation/59054976/Gmae-Theory", "snippet": "play is no more than the value of the game (<b>minimizing</b> his maximum <b>losses</b>). 6/30/2011. KOPPAR &amp; ASSOCIATES, CHARTERED ACCOUNTANTS Saddle Point (Equilibrium Point) y The concept of saddle point is illustrated with the help of the following example. Player B P Player A. Q 3 4 3 4. Minimum of row -3 -2 2 2 [Maximin &amp; <b>Minimax</b>] L M N Maximum of ...", "dateLastCrawled": "2022-01-28T04:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Minimax</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Minimax", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Minimax</b>", "snippet": "<b>Minimax</b> (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for <b>minimizing</b> the possible <b>loss</b> for a worst case (maximum <b>loss</b>) scenario.When dealing with gains, it is referred to as &quot;maximin&quot;\u2014to maximize the minimum gain. Originally formulated for n-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been ...", "dateLastCrawled": "2022-02-03T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Every Traders and Analysts should know their Limitations! for NYSE:PLTR ...", "url": "https://www.tradingview.com/chart/PLTR/AzEqV71d-Every-Traders-and-Analysts-should-know-their-Limitations/", "isFamilyFriendly": true, "displayUrl": "https://www.tradingview.com/chart/PLTR/AzEqV71d-Every-Traders-and-Analysts-should-know...", "snippet": "<b>Minimax</b> In game theory, <b>minimax</b> is a decision rule used to minimize the worst-case <b>potential</b> <b>loss</b>; in other words, a ... <b>Minimax</b>, as the name suggests, is a method in decision theory for <b>minimizing</b> the maximum <b>loss</b>. Alternatively, it <b>can</b> <b>be thought</b> of as maximizing the minimum gain, which is also known as Maximin. It all started from a two-player zero-sum game theory, covering both the cases where players take alternate moves and those where they made simultaneous moves. It has also been ...", "dateLastCrawled": "2021-12-28T00:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian/minimax duality for adversarial bandits</b> \u2013 Bandit Algorithms", "url": "https://banditalgs.com/2019/03/17/bayesianminimax-duality-for-adversarial-bandits/", "isFamilyFriendly": true, "displayUrl": "https://banditalgs.com/2019/03/17/<b>bayesianminimax-duality-for-adversarial-bandits</b>", "snippet": "The <b>minimizing</b> player\u2019s optimal strategy is defined as the strategy that achieves the smallest worst-case <b>loss</b>. In our case, this is $\\overline{BR}_n =\\inf_{\\pi}\\sup_{\\nu} BR_n(\\pi,\\nu)$. The value, $\\overline{BR}_n$, is called the <b>minimax</b> value of the game. Any strategy $\\pi^*$ that achieves this is a <b>minimax</b> strategy. Analogously, the ...", "dateLastCrawled": "2022-01-28T23:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>minimax</b> risk <b>strategy for</b> portfolio <b>immunization</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0167668798000286", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167668798000286", "snippet": "Following Reitano (1992), this shift <b>can</b> <b>be thought</b> of as vector having a direction, f(t), and a magnitude, x. Without <b>loss</b> of generality, we <b>can</b> assume that II f II2= f f(t)2dt = 1, and x = IIE II. After an interest rate shock, the instan- taneous forward rate is given by 3(t, x) = 3(t, O) + f(t)x. Before an interest rate shock, the present value of all cash flows is given by V(0) = fl(0). Most single factor models considered in the litera- ture depend upon the specification of g. For ...", "dateLastCrawled": "2021-11-28T13:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A <b>Stochastic View of Optimal Regret through Minimax Duality</b> | Request PDF", "url": "https://www.researchgate.net/publication/24168017_A_Stochastic_View_of_Optimal_Regret_through_Minimax_Duality", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/24168017_A_<b>Stochastic_View_of_Optimal_Regret</b>...", "snippet": "On the other hand, for the <b>loss</b> function in form of (1) without log utility or with linear approximation of log utility, the best possible regret in a <b>minimax</b> sense is at most O( \u221a n) (Abernethy ...", "dateLastCrawled": "2021-11-06T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Tic Tac Toe</b> - Creating Unbeatable AI | by Greg Surma | Medium", "url": "https://gsurma.medium.com/tic-tac-toe-creating-unbeatable-ai-with-minimax-algorithm-8af9e52c1e7d", "isFamilyFriendly": true, "displayUrl": "https://gsurma.medium.com/<b>tic-tac-toe</b>-creating-unbeatable-ai-with-<b>minimax</b>-algorithm-8...", "snippet": "You <b>can</b> think of the algorithm as a representation of the human <b>thought</b> process of saying, \u201cOK, if I make this move, then my opponent <b>can</b> only make two moves, and each of those would let me win. So this is the right move to make.\u201d Let\u2019s take a look at the code! Line 1. In order to calculate the <b>minimax</b> score, let\u2019s feed the <b>minimax</b> function with the current board state ([Player]) and an opponent player (Player) Lines 2\u20134. Then let\u2019s check if the board already has a winner. If it ...", "dateLastCrawled": "2022-02-01T10:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Review for NeurIPS paper: <b>Minimax</b> Estimation of Conditional Moment Models", "url": "https://papers.nips.cc/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Review.html", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Review.html", "snippet": "The word &quot;<b>minimax</b> estimation&quot; generally refers to <b>minimax</b> optimality of an estimation procedure. I would recommend the phrase &quot;min-max estimation&quot; or &quot;saddlepoint estimation&quot;. Typo in Theorem 2: should be R_n instead of R. Edit: author feedback is satisfactory. Review 2. Summary and Contributions: The authors feedback successfully answered my concerns about the experimental section of the paper, and the revisions and additional experiments that they propose to add should be easily carried ...", "dateLastCrawled": "2021-12-05T21:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "GANs from Scratch 1: A deep introduction. With code in PyTorch and ...", "url": "https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/ai-society/<b>gan</b>s-from-scratch-1-a-deep-introduction-with-code-in-py...", "snippet": "Since during training both the Discriminator and Generator are trying to optimize opposite <b>loss</b> functions, they <b>can</b> <b>be thought</b> of two agents playing a <b>minimax</b> game with value function V(G,D). In ...", "dateLastCrawled": "2022-02-03T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "In between Real <b>or Fake: Generative Adversarial Networks (GANs</b>) | by ...", "url": "https://medium.datadriveninvestor.com/in-between-real-or-fake-generative-adversarial-networks-gans-f46f64577fb5", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/in-between-real-or-fake-generative-adversarial...", "snippet": "In the <b>loss</b> schemes, we\u2019ll look at here, the generator and discriminator <b>losses</b> derive from a single measure of the distance between probability distributions. In both of these schemes, however, the generator <b>can</b> only affect one term in the distance measure: the term that reflects the distribution of the fake data. So during generator training, we drop the other term, which reflects the distribution of the real data.", "dateLastCrawled": "2022-01-12T22:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "6moons audio reviews: <b>Musse Audio MiniMax Vibration Dampers</b> &amp; PureMagic ...", "url": "https://www.6moons.com/audioreviews/musse/musse.html", "isFamilyFriendly": true, "displayUrl": "https://www.6moons.com/audioreviews/musse/musse.html", "snippet": "Besides this bit of <b>potential</b> tweaking and the appealing difference in cost, the at most minor <b>loss</b> of performance compels me to proclaim &quot;I&#39;ve already described the very audible benefits of this decoupling principle&quot;. I thus refer you to the above link for details. In a nutshell? Subtracting measurable resonance contamination from your equipment performs the proverbial spring cleaning in your soundstage. Image some &quot;grunge-be-gone&quot; TV commercial. It shows a cobweb-infested, dark and dusty ...", "dateLastCrawled": "2021-10-31T17:00:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Minimax</b> Multi-Task Learning and a Generalized <b>Loss</b>-Compositional ...", "url": "https://www.researchgate.net/publication/230839821_Minimax_Multi-Task_Learning_and_a_Generalized_Loss-CompositionalParadigm_for_MTL", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/230839821_<b>Minimax</b>_Multi-Task_Learning_and_a...", "snippet": "Mehta, Lee, and Gray (2012), in contrast, explore the i (\u03b8) j family of <b>losses</b> for multi-task learning, i.e., of <b>minimizing</b> the inorm of the <b>loss</b> vector, with 1 equivalent to the standard average ...", "dateLastCrawled": "2022-01-02T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Fractional insurance: strategies to deal with huge <b>potential</b> <b>losses</b>", "url": "https://faculty.wharton.upenn.edu/wp-content/uploads/2012/04/Fractional-insurance.pdf", "isFamilyFriendly": true, "displayUrl": "https://faculty.wharton.upenn.edu/wp-content/uploads/2012/04/Fractional-insurance.pdf", "snippet": "<b>minimax</b> <b>loss</b>, minimum expected <b>loss</b>, minimum expected <b>loss</b> with a limit on maximum <b>loss</b>, and maximum expected utility. The discussion is illustrated by satellite missions that <b>can</b> incur <b>losses</b> in excess of $100 million. 1. Introduction Insurance decisions re\ufb02ect attitudes toward risks and <b>losses</b>. Full insurance against", "dateLastCrawled": "2021-12-20T12:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Minimax</b> Pareto Fairness: A Multi Objective Perspective", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7912461/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7912461", "snippet": "Here we focus on <b>minimizing</b> the risk on the worst performing group (Definition 3.4), these two criteria often yield similar results, and <b>can</b> be shown to be identical for Pareto optimal classifiers when \u2223 A \u2223 = 2. For more than 2 sensitive groups, there may be situations where minimum risk discrepancy leads to higher <b>minimax</b> risk (e.g., a classifier that increases both the minimum and maximum risk but decreases their gap is still optimal if a third group sees their risk diminished ...", "dateLastCrawled": "2021-12-24T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Minimax</b> risk classifiers with 0-1 <b>loss</b> | Request PDF", "url": "https://www.researchgate.net/publication/357925572_Minimax_risk_classifiers_with_0-1_loss", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357925572_<b>Minimax</b>_risk_classifiers_with_0-1_<b>loss</b>", "snippet": "The <b>minimax</b> SVM, which is a relaxed version of the standard SVM, minimizes the worst-case 0-1 <b>loss</b> over the structured set of distribution, and by our numerical experiments <b>can</b> outperform the SVM ...", "dateLastCrawled": "2022-01-27T13:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 4, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Minimax</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Minimax", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Minimax</b>", "snippet": "<b>Minimax</b> (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for <b>minimizing</b> the possible <b>loss</b> for a worst case (maximum <b>loss</b>) scenario.When dealing with gains, it is referred to as &quot;maximin&quot;\u2014to maximize the minimum gain. Originally formulated for n-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been ...", "dateLastCrawled": "2022-02-03T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "EFFICIENCY OF THE MINMAX PORTFOLIO ON THE EUROPEAN CAPITAL MARKET - <b>CAN</b> ...", "url": "https://www.pressacademia.org/archives/jbef/v6/i2/3.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.pressacademia.org/archives/jbef/v6/i2/3.pdf", "snippet": "minimum between the largest <b>potential</b> <b>losses</b>, and therefore it is called minmax model. The main objective is to answer whether the <b>minimax</b> model tool performs better than the stock market index, and to verify the relationship between the established Markowitz mean- variance (MV) efficient portfolios and minmax optimum portfolio. We use data from the European capital market and Euro Stoxx 50 index as a reference index in the period 2004-2015, which we divided into two parts. We <b>compared</b> and ...", "dateLastCrawled": "2022-01-05T02:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Adversarial Multiclass Classification: A Risk Minimization Perspective</b>", "url": "https://proceedings.neurips.cc/paper/2016/file/ad13a2a07ca4b7642959dc0c4c740ab6-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2016/file/ad13a2a07ca4b7642959dc0c4c740ab6-Paper.pdf", "snippet": "Since directly <b>minimizing</b> this <b>loss</b> over training data via empirical risk minimization (ERM) [1] is generally NP-hard [2], convex surrogate <b>losses</b> are employed to approximate the zero-one <b>loss</b>. For example, the logarithmic <b>loss</b> is minimized by the logistic regression classi\ufb01er [3] and the hinge <b>loss</b> is minimized by the support vector machine (SVM) [4, 5]. Both are Fisher consistent [6, 7] and universally consistent [8, 9] for binary classi\ufb01cation, meaning they minimize the zero-one <b>loss</b> ...", "dateLastCrawled": "2022-01-19T02:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Preserving Privacy of Continuous High-dimensional Data with <b>Minimax</b> Filters", "url": "http://proceedings.mlr.press/v38/hamm15.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v38/hamm15.pdf", "snippet": "ters and <b>loss</b>/classi ers are de ned, and algo-rithms for learning the lers in batch or dis-tributed settings are presented. Experiments with several real-world tasks including facial expression recognition, speech emotion recog- nition, and activity recognition from motion, show that the <b>minimax</b> lter <b>can</b> simultane-ously achieve similar or better target task ac-curacy and lower privacy risk, often signi - cantly lower than previous methods. 1 Introduction When databases of multiple subjects ...", "dateLastCrawled": "2022-01-05T11:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Convergent Algorithms for (Relaxed) Minimax Fairness</b> - DeepAI", "url": "https://deepai.org/publication/convergent-algorithms-for-relaxed-minimax-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>convergent-algorithms-for-relaxed-minimax-fairness</b>", "snippet": "11/05/20 - We consider a recently introduced framework in which fairness is measured by worst-case outcomes across groups, rather than by the...", "dateLastCrawled": "2021-12-30T11:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Multiple Choice</b> Quiz - <b>Oxford University Press</b>", "url": "https://global.oup.com/us/companion.websites/9780199811786/student/chapt14/multiplechoice/", "isFamilyFriendly": true, "displayUrl": "https://<b>global.oup.com</b>/us/companion.websites/9780199811786/student/chapt14/<b>multiplechoice</b>", "snippet": "b. a <b>minimax</b> regret matrix. c. a payoff matrix. d. an expected utility matrix. The sequence of possible managerial decisions and their expected outcome under each set of circumstances <b>can</b> be represented and analyzed by using . a. the <b>minimax</b> regret criterion. b. a decision tree. c. a payoff matrix. d. simulation. According to a survey carried out by Gitman and Forrester that was published in 1977, the most common way for businesses in the United States to deal with risk in capital budgeting ...", "dateLastCrawled": "2022-02-03T12:30:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "In between Real <b>or Fake: Generative Adversarial Networks (GANs</b>) | by ...", "url": "https://medium.datadriveninvestor.com/in-between-real-or-fake-generative-adversarial-networks-gans-f46f64577fb5", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/in-between-real-or-fake-generative-adversarial...", "snippet": "<b>Minimax</b> <b>Loss</b>. In the paper that introduced GANs, the generator tries to minimize the following function while the discriminator tries to maximize it: Ex[log(D(x))]+Ez[log(1\u2212D(G(z)))] In this function: D(x) is the discriminator\u2019s estimate of the probability that real data instance x is real. Ex is the expected value over all real data instances. G(z) is the generator\u2019s output when given noise z. D(G(z)) is the discriminator\u2019s estimate of the probability that a fake instance is real ...", "dateLastCrawled": "2022-01-12T22:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding the 3 most common <b>loss</b> functions for <b>Machine</b> <b>Learning</b> ...", "url": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-the-3-most-common-<b>loss</b>-functions-for...", "snippet": "A <b>loss function</b> in <b>Machine</b> <b>Learning</b> is a measure of how accurately your ML model is able to predict the expected outcome i.e the ground truth. The <b>loss function</b> will take two items as input: the output value of our model and the ground truth expected value. The output of the <b>loss function</b> is called the <b>loss</b> which is a measure of how well our model did at predicting the outcome. A high value for the <b>loss</b> means our model performed very poorly. A low value for the <b>loss</b> means our model performed ...", "dateLastCrawled": "2022-02-02T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> Concepts for Revision | by Raunak Sarada | Medium", "url": "https://raunaksarada-cse21.medium.com/machine-learning-concepts-for-revision-491384952d27", "isFamilyFriendly": true, "displayUrl": "https://raunaksarada-cse21.medium.com/<b>machine</b>-<b>learning</b>-concepts-for-revision-491384952d27", "snippet": "ML Concepts. A.I \u2014 Intelligence showed by machines which is common for humans <b>Machine</b> <b>Learning</b>- Recognize the pattern in data and automatically learn and improve through experience without explicitly being programmed Deep <b>Learning</b>- branch of <b>machine</b> <b>learning</b>.We have to deal with lots of data so in that case problems can\u2019t be solved with simple ML algorithms.", "dateLastCrawled": "2022-01-25T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Generative Adversarial Networks (GANs) - TJ <b>Machine</b> <b>Learning</b>", "url": "https://tjmachinelearning.com/lectures/1920/guest/Generative_Adversarial_Networks.pdf", "isFamilyFriendly": true, "displayUrl": "https://tj<b>machinelearning</b>.com/lectures/1920/guest/Generative_Adversarial_Networks.pdf", "snippet": "Figure 1: <b>Minimax</b> objective function Density Models follow a stochastic approach. To simplify, Explicit Density models pick a random variable and then compare that random variable\u2019s value in the data provided (e.g. plotting the degree that some images are green) and then tries to learn a function to estimate this nature. Implicit models, aim to generate samples to mimic the given &quot;real&quot; data (training data). 3 Concept Generative Adversarial Networks are currently the state-of-the-art ...", "dateLastCrawled": "2021-08-25T21:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding Generative Adversarial Networks (GANs) | by Joseph Rocca ...", "url": "https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-generative-adversarial-networks-<b>gan</b>s-cd6e...", "snippet": "This way to twist the <b>loss</b> function to go from a direct comparison to an indirect one is really something that can be very inspiring for further works in the deep <b>learning</b> area. To conclude, let\u2019s say that we don\u2019t know if the idea of GANs is really \u201cthe most interesting idea in the last 10 years in <b>Machine</b> <b>Learning</b>\u201d\u2026 but it\u2019s pretty obvious that it is, at least, one of the most interesting!", "dateLastCrawled": "2022-02-03T05:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Intro to Generative Adversarial Networks (GANs) - PyImageSearch", "url": "https://www.pyimagesearch.com/2021/09/13/intro-to-generative-adversarial-networks-gans/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/09/13/intro-to-generative-adversarial-networks-gans", "snippet": "The <b>Minimax</b> game: G vs. D. Most deep <b>learning</b> models (for example, image classification) are based on optimization: finding the low value of the cost function. GANs are different because the two networks: the generator and discriminator, each has its own cost with opposite objectives: The generator tries to fool the discriminator into thinking the fake images as real; The discriminator tries to classify real and fake images correctly; The <b>minimax</b> game math function below illustrates this ...", "dateLastCrawled": "2022-02-03T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Synthetic data in <b>machine</b> <b>learning</b> for medicine and healthcare | Nature ...", "url": "https://www.nature.com/articles/s41551-021-00751-8", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41551-021-00751-8", "snippet": "GANs consist of two neural networks \u2014 a generator and a discriminator \u2014 that compete in a <b>minimax</b> game (that is, a game of minimizing the maximum possible <b>loss</b>) to fool each other. For ...", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Understanding <b>Gradient Descent with Python</b>", "url": "https://rubikscode.net/2021/06/28/ml-optimization-pt-1-gradient-descent-with-python/", "isFamilyFriendly": true, "displayUrl": "https://rubikscode.net/2021/06/28/ml-optimization-pt-1-<b>gradient-descent-with-python</b>", "snippet": "In general, every <b>machine</b> <b>learning</b> algorithm is composed of three integral parts: A <b>loss</b> function.; Optimization criteria based on the <b>loss</b> function, like a cost function.; Optimization technique \u2013 this process leverages training data to find a solution for optimization criteria (cost function).; As you were able to see in previous articles, some algorithms were created intuitively and didn\u2019t have optimization criteria in mind.", "dateLastCrawled": "2022-02-02T07:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> <b>Learning</b> \u2013 KejiTech", "url": "https://davideliu.com/category/machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://davideliu.com/category/<b>machine</b>-<b>learning</b>", "snippet": "Challenges of <b>machine</b> <b>learning</b> <b>Machine</b> <b>learning</b> is a complex field that borrows elements from different areas such as computer science, algebra and statistics. Hence, it is not immediate, even for experts in the field, to build strong <b>machine</b> <b>learning</b> models to solve predefined task. Furthermore, those models should also be optimized with a time-consuming and repetitive hyper-parameters search in order to find the best set \u2026", "dateLastCrawled": "2022-01-09T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning Gist</b> \u00b7 GitHub", "url": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "snippet": "Orthogonalization - Adjust one knob to adjust one parameter, to solve one problem - The TV knob <b>analogy</b> and the car <b>analogy</b>. Chain of assumptions in <b>Machine</b> <b>Learning</b> and different knobs to say improve performance on train/dev set. Andrew Ng does not recommend Early stopping, as it is a knob that affects multiple thing at once. Setting up your goal", "dateLastCrawled": "2022-01-29T03:42:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Using Latent Codes for Class Imbalance Problem in Unsupervised ...", "url": "https://www.researchgate.net/publication/335926235_Using_Latent_Codes_for_Class_Imbalance_Problem_in_Unsupervised_Domain_Adaptation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335926235_Using_Latent_Codes_for_Class...", "snippet": "PDF | We address the problem of severe class imbalance in unsupervised domain adaptation, when the class spaces in source and target domains diverge... | Find, read and cite all the research you ...", "dateLastCrawled": "2021-11-14T06:28:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(minimax loss)  is like +(minimizing potential losses)", "+(minimax loss) is similar to +(minimizing potential losses)", "+(minimax loss) can be thought of as +(minimizing potential losses)", "+(minimax loss) can be compared to +(minimizing potential losses)", "machine learning +(minimax loss AND analogy)", "machine learning +(\"minimax loss is like\")", "machine learning +(\"minimax loss is similar\")", "machine learning +(\"just as minimax loss\")", "machine learning +(\"minimax loss can be thought of as\")", "machine learning +(\"minimax loss can be compared to\")"]}