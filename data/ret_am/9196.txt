{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Convolutional neural networks (CNNs): concepts and applications in ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8342355/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8342355", "snippet": "The massive <b>accumulation</b> of <b>data</b> from genomics, transcriptomics, proteomics, metabolomics, ... However, their implications in analyzing one-dimensional <b>data</b> <b>like</b> biological sequence <b>data</b>, SMILES codes, or medical texts are not widely recognized [13\u201316]. Biological sequences <b>like</b> DNA, RNA, or protein sequences can be identified as simple one-dimensional <b>data</b> that characterize a biological system, while SMILES <b>data</b> can depict chemical compounds. The potential benefits of deep <b>learning</b> and ...", "dateLastCrawled": "2022-02-03T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Robust face <b>detection using local gradient patterns</b> and evidence ...", "url": "https://www.researchgate.net/publication/256822459_Robust_face_detection_using_local_gradient_patterns_and_evidence_accumulation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/256822459_Robust_face_detection_using_local...", "snippet": "Jun and Kim [14] proposed a face detection method using local <b>gradient</b> <b>patterns</b>; by their study, they found that local <b>gradient</b> pattern for face detection is much better than Fig. 1 System ...", "dateLastCrawled": "2021-11-07T17:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "machine-<b>learning</b>-interview-questions/q&amp;a.md at main \u00b7 usarawgi911 ...", "url": "https://github.com/usarawgi911/machine-learning-interview-questions/blob/main/q%26a.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/usarawgi911/machine-<b>learning</b>-interview-questions/blob/main/q&amp;a.md", "snippet": "The <b>accumulation</b> of small gradients results in a model that is incapable of <b>learning</b> meaningful insights since the weights and biases of the initial layers, which tends to learn the core features from the input <b>data</b> (X), will not be updated effectively. In the worst case scenario the <b>gradient</b> will be 0 which in turn will stop the network will stop further training.", "dateLastCrawled": "2022-01-03T01:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Deep Convolutional Neural Networks</b> - Run:AI", "url": "https://www.run.ai/guides/deep-learning-for-computer-vision/deep-convolutional-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.run.ai/guides/deep-<b>learning</b>-for-computer-vision/deep-convolutional-neural...", "snippet": "Deep <b>learning</b> is a machine <b>learning</b> technique used to build artificial intelligence (AI) systems. It is based on the idea of artificial neural networks (ANN), designed to perform complex analysis of large amounts of <b>data</b> by passing it through multiple layers of neurons. There is a wide variety of deep neural networks (DNN). <b>Deep convolutional neural networks</b> (CNN or DCNN) are the type most commonly used to identify <b>patterns</b> in images and video. DCNNs have evolved from traditional artificial ...", "dateLastCrawled": "2022-02-03T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning</b> of spatiotemporal <b>patterns</b> in a spiking neural network with ...", "url": "https://www.science.org/doi/10.1126/sciadv.aat4752", "isFamilyFriendly": true, "displayUrl": "https://www.science.org/doi/10.1126/sciadv.aat4752", "snippet": "In summary, a RRAM-based synaptic neuromorphic network is proposed to learn and <b>recognize</b> spatiotemporal <b>patterns</b>, including spike sequences and spike groups (for example, pairs) where the spike timing carries information. The time difference of spikes among different neurons provides spatiotemporal coding with high sparsity and high information capacity. Our experiments demonstrate that the RRAM-based SNN, combined with suitable neuron circuit and operation scheme, is capable of <b>learning</b> ...", "dateLastCrawled": "2022-01-29T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "10 <b>Clustering Algorithms With Python</b> - Machine <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/clustering-algorithms-with-python/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/<b>clustering-algorithms-with-python</b>", "snippet": "Clustering or cluster analysis is an unsupervised <b>learning</b> problem. It is often used as a <b>data</b> analysis technique for discovering interesting <b>patterns</b> <b>in data</b>, such as groups of customers based on their behavior. There are many clustering algorithms to choose from and no single best clustering algorithm for all cases. Instead, it is a good idea to explore a range of clustering", "dateLastCrawled": "2022-02-02T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Contouring learning rate to optimize neural</b> nets \u2013 O\u2019Reilly", "url": "https://www.oreilly.com/content/contouring-learning-rate-to-optimize-neural-nets/", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/content/<b>contouring-learning-rate-to-optimize-neural</b>-nets", "snippet": "<b>Learning</b> rate is the rate at which the <b>accumulation</b> of information in a neural network progresses over time. The <b>learning</b> rate determines how quickly (and whether at all) the network reaches the optimum, most conducive location in the network for the specific output desired. In plain Stochastic <b>Gradient</b> Descent (SGD), the <b>learning</b> rate is not ...", "dateLastCrawled": "2022-01-01T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Machine <b>Learning</b> with Python: <b>Regression</b> ... - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/machine-learning-with-python-regression-complete-tutorial-47268e546cea", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/machine-<b>learning</b>-with-python-<b>regression</b>-complete...", "snippet": "&#39;&#39;&#39; <b>Recognize</b> whether a column is numerical or categorical.:parameter:param dtf: dataframe - input <b>data</b>: ... machine <b>learning</b> model. I will first run a simple linear <b>regression</b> and use it as a baseline for a more complex model, <b>like</b> the <b>gradient</b> boosting algorithm. The first metric I normally use is the R squared, which indicates the proportion of the variance in the dependent variable that is predictable from the independent variable. I will compare the linear <b>regression</b> R squared with the ...", "dateLastCrawled": "2022-02-03T02:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep <b>learning</b> in analytical chemistry - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S016599362100282X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S016599362100282X", "snippet": "Main <b>data</b> operations performed as part of the CNN workflow including a) kernel convolution for <b>learning</b> local features of the input image and developing more informative <b>data</b> representations, b) the popular ReLU and Sigmoid activation functions to give the system more flexibility while <b>learning</b> non-linear <b>patterns</b> and c) the max pooling layer to reduce feature maps dimensionality.", "dateLastCrawled": "2022-01-26T16:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>A Comparison of Optimization Algorithms for Deep Learning</b>", "url": "https://www.researchgate.net/publication/339073808_A_Comparison_of_Optimization_Algorithms_for_Deep_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339073808_A_Comparison_of_Optimization...", "snippet": "Adam is defined as one of the most popular optimization algorithms for optimizing neural networks in deep <b>learning</b>, based on an adaptive <b>learning</b> rate algorithm [25], [26]. Finally, we can start ...", "dateLastCrawled": "2022-01-30T17:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Transfer <b>learning</b> compensates limited <b>data</b>, batch effects and ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8598306/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8598306", "snippet": "<b>Similar</b> to Sun-MTL in the computer vision field, the TMP also showed that knowledge transfer from large-scale bulk-cell sequencing <b>data</b> and meta-<b>learning</b> with fine-tuning dataset makes model training very time efficient (Figures (Figures2A 2A and 3B) and shows less variability in model performance (Figures (Figures2C 2C and 3C). The application of meta-transfer <b>learning</b> for building a few-shot classifier with heterogeneous omics datasets is very efficient in our model. When training a ...", "dateLastCrawled": "2021-11-26T01:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Contouring learning rate to optimize neural</b> nets \u2013 O\u2019Reilly", "url": "https://www.oreilly.com/content/contouring-learning-rate-to-optimize-neural-nets/", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/content/<b>contouring-learning-rate-to-optimize-neural</b>-nets", "snippet": "<b>Learning</b> rate is the rate at which the <b>accumulation</b> of information in a neural network progresses over time. The <b>learning</b> rate determines how quickly (and whether at all) the network reaches the optimum, most conducive location in the network for the specific output desired. In plain Stochastic <b>Gradient</b> Descent (SGD), the <b>learning</b> rate is not ...", "dateLastCrawled": "2022-01-01T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>A Comparison of Optimization Algorithms for Deep Learning</b>", "url": "https://www.researchgate.net/publication/339073808_A_Comparison_of_Optimization_Algorithms_for_Deep_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339073808_A_Comparison_of_Optimization...", "snippet": "Adam is defined as one of the most popular optimization algorithms for optimizing neural networks in deep <b>learning</b>, based on an adaptive <b>learning</b> rate algorithm [25], [26]. Finally, we can start ...", "dateLastCrawled": "2022-01-30T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "machine-<b>learning</b>-interview-questions/q&amp;a.md at main \u00b7 usarawgi911 ...", "url": "https://github.com/usarawgi911/machine-learning-interview-questions/blob/main/q%26a.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/usarawgi911/machine-<b>learning</b>-interview-questions/blob/main/q&amp;a.md", "snippet": "The <b>accumulation</b> of small gradients results in a model that is incapable of <b>learning</b> meaningful insights since the weights and biases of the initial layers, which tends to learn the core features from the input <b>data</b> (X), will not be updated effectively. In the worst case scenario the <b>gradient</b> will be 0 which in turn will stop the network will stop further training.", "dateLastCrawled": "2022-01-03T01:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "10 <b>Clustering Algorithms With Python</b> - Machine <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/clustering-algorithms-with-python/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/<b>clustering-algorithms-with-python</b>", "snippet": "Clustering or cluster analysis is an unsupervised <b>learning</b> problem. It is often used as a <b>data</b> analysis technique for discovering interesting <b>patterns</b> <b>in data</b>, such as groups of customers based on their behavior. There are many clustering algorithms to choose from and no single best clustering algorithm for all cases. Instead, it is a good idea to explore a range of clustering", "dateLastCrawled": "2022-02-02T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning</b> of spatiotemporal <b>patterns</b> in a spiking neural network with ...", "url": "https://www.science.org/doi/10.1126/sciadv.aat4752", "isFamilyFriendly": true, "displayUrl": "https://www.science.org/doi/10.1126/sciadv.aat4752", "snippet": "In summary, a RRAM-based synaptic neuromorphic network is proposed to learn and <b>recognize</b> spatiotemporal <b>patterns</b>, including spike sequences and spike groups (for example, pairs) where the spike timing carries information. The time difference of spikes among different neurons provides spatiotemporal coding with high sparsity and high information capacity. Our experiments demonstrate that the RRAM-based SNN, combined with suitable neuron circuit and operation scheme, is capable of <b>learning</b> ...", "dateLastCrawled": "2022-01-29T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Transfer <b>learning</b> compensates limited <b>data</b>, batch effects and ...", "url": "https://academic.oup.com/nargab/article/3/4/lqab104/6426025", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/nargab/article/3/4/lqab104/6426025", "snippet": "<b>Similar</b> to Sun-MTL in the computer vision field, the TMP also showed that knowledge transfer from large-scale bulk-cell sequencing <b>data</b> and meta-<b>learning</b> with fine-tuning dataset makes model training very time efficient (Figures 2A and 3B) and shows less variability in model performance (Figures 2C and 3C). The application of meta-transfer <b>learning</b> for building a few-shot classifier with heterogeneous omics datasets is very efficient in our model. When training a randomly initialized model ...", "dateLastCrawled": "2022-01-31T14:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Machine <b>Learning</b> with Python: <b>Regression</b> ... - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/machine-learning-with-python-regression-complete-tutorial-47268e546cea", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/machine-<b>learning</b>-with-python-<b>regression</b>-complete...", "snippet": "<b>Data</b> preprocessing is the phase of preparing raw <b>data</b> to make it suitable for a machine <b>learning</b> model. In particular: In particular: each observation must be represented by a single row, in other words, you can\u2019t have two rows describing the same passenger because they will be processed separately by the model (the dataset is already in such form, so ).", "dateLastCrawled": "2022-02-03T02:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The latitudinal taxonomy <b>gradient</b> | Request PDF", "url": "https://www.researchgate.net/publication/351999026_The_latitudinal_taxonomy_gradient", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/351999026_The_latitudinal_taxonomy_<b>gradient</b>", "snippet": "Available thermal tolerance <b>data</b> for several vertebrate taxa exhibit <b>similar</b> <b>patterns</b>, suggesting that these results are general for terrestrial ectotherms. Our analyses imply that, in the absence ...", "dateLastCrawled": "2022-01-14T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Prediction of <b>population behavior of Listeria monocytogenes</b> in food ...", "url": "https://www.nature.com/articles/s41598-021-90164-z", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-90164-z", "snippet": "<b>Data</b> mining combines statistical analysis, machine <b>learning</b>, and databases to extract hidden <b>patterns</b> from databases. The core of <b>data</b> mining is machine <b>learning</b> 12 , and various machine <b>learning</b> ...", "dateLastCrawled": "2022-01-31T19:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How <b>learning</b> unfolds in the brain: toward an optimization view ...", "url": "https://www.sciencedirect.com/science/article/pii/S0896627321006772", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0896627321006772", "snippet": "According to this point of view, which we will refer to as the \u201coptimization framework\u201d (), <b>learning</b> is the outcome of optimizing an objective function (also called a \u201ccost function\u201d) using a <b>learning</b> rule, subject to constraints.For example, one <b>can</b> train an artificial network to <b>recognize</b> handwritten digits using an objective function known as cross-entropy and a <b>learning</b> rule known as backpropagation (Figures 1A\u20131D).In neuroscience, the idea that the brain learns by modifying ...", "dateLastCrawled": "2022-01-16T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "An introduction to <b>Glacier Mass Balance</b>", "url": "https://www.antarcticglaciers.org/glacier-processes/mass-balance/introduction-glacier-mass-balance/", "isFamilyFriendly": true, "displayUrl": "https://www.antarcticglaciers.org/glacier-processes/mass-balance/introduction-glacier...", "snippet": "Mass balance <b>can</b> <b>be thought</b> of as the \u2018health of a glacier\u2019; glaciers losing more mass than they receive will be in negative mass balance and so will recede. Glaciers gaining more mass than they lose will be in positive mass balance and will advance. Glaciers gaining and losing approximately the same amount of snow and ice are <b>thought</b> of as \u2018in equilibrium\u2019, and will neither advance nor recede. For clarification: when we talk about glaciers advancing, receding or being in equilibrium ...", "dateLastCrawled": "2022-01-29T16:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Cognitive computational neuroscience", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6706072/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6706072", "snippet": "Reinforcement <b>learning</b> models use environmental feedback that is more realistic in quality and <b>can</b> provide BCMs of <b>learning</b> processes. ... recurrent networks <b>can</b> <b>recognize</b>, predict, and generate dynamical <b>patterns</b>. Both feedforward and recurrent networks are defined by their architecture and the setting of the connection weights. One way to set the weights is through iterative small adjustments that bring the output closer to some desired output (supervised <b>learning</b>). Each weight is adjusted ...", "dateLastCrawled": "2022-01-27T01:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fatty Liver: Imaging Patterns and</b> Pitfalls", "url": "https://pubs.rsna.org/doi/pdf/10.1148/rg.266065004", "isFamilyFriendly": true, "displayUrl": "https://pubs.rsna.org/doi/pdf/10.1148/rg.266065004", "snippet": "<b>LEARNING</b> OBJECTIVES After reading this article and taking the test, the reader will be able to: <b>Recognize</b> the im-aging features of fat <b>accumulation</b> in the liver. Describe the pos-sible causes of fat <b>accumulation</b> in the liver. Differentiate fat <b>accumulation</b> in the liver from malignant and benign mimics. Okka W. Hamer, MD Diego A. Aguirre, MD Giovanna Casola, MD Joel E. Lavine, MD Matthias Woenckhaus, MD Claude B. Sirlin, MD Fat <b>accumulation</b> is one of the most common abnormalities of the liver ...", "dateLastCrawled": "2022-02-03T06:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Deep <b>learning</b> in analytical chemistry - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S016599362100282X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S016599362100282X", "snippet": "DL techniques <b>can</b> achieve a high level of abstraction during the training process, such as ignoring insignificant <b>data</b> <b>patterns</b>, while retaining critical features related to the particular task at hand. Several popular DL architectures were satisfactorily applied for two- and three-dimensional <b>data</b> analysis. For example, deep neural networks (DNNs), convolutional neural networks (CNNs), recurrent neural networks (RNNs), and auto-encoders (AEs) made breakthrough progress in computer vision ...", "dateLastCrawled": "2022-01-26T16:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Robust face <b>detection using local gradient patterns</b> and evidence ...", "url": "https://www.researchgate.net/publication/256822459_Robust_face_detection_using_local_gradient_patterns_and_evidence_accumulation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/256822459_Robust_face_detection_using_local...", "snippet": "Jun and Kim [14] proposed a face detection method using local <b>gradient</b> <b>patterns</b>; by their study, they found that local <b>gradient</b> pattern for face detection is much better than Fig. 1 System ...", "dateLastCrawled": "2021-11-07T17:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "On the pursuit of the brain network for proto-syntactic <b>learning</b> in non ...", "url": "https://royalsocietypublishing.org/doi/10.1098/rstb.2012.0073", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rstb.2012.0073", "snippet": "to conclude that: \u2018Considerable controversy remains as to whether any nonhuman species <b>can</b> truly <b>recognize</b> strictly context-free <b>patterns</b>\u2019. Context-free pattern <b>learning</b> may someday be demonstrated in certain animals [ 4 ], yet, even if it is not, it remains important to understand how human capabilities with CFGs and beyond may have evolved from abilities lower in the FLH that are present in other living animals.", "dateLastCrawled": "2022-01-23T11:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Exam 4 Learning Curve Questions</b> (Ch.11.4 - 14) Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/453254396/exam-4-learning-curve-questions-ch114-14-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/453254396/<b>exam-4-learning-curve-questions-ch114-14</b>-flash-cards", "snippet": "The fruit fly cross shown here analyzes the transmission of two genes on the X chromosome. The male parent has mutant alleles for both the white gene (w-) that results in white eyes and the crossveinless gene (cv-) that results in the absence of crossveins of the fly wings. The female parent has nonmutant forms of these genes (w+ and cv+).", "dateLastCrawled": "2022-01-28T08:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Advances in modeling <b>learning</b> and decision-making in neuroscience ...", "url": "https://www.nature.com/articles/s41386-021-01126-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41386-021-01126-y", "snippet": "Early efforts in the domain of <b>learning</b> and decision making show that correlates of brain function, including PFC, <b>can</b> be found when deep RL agents perform complex tasks [ 263, 264 ]. However, at ...", "dateLastCrawled": "2022-01-21T01:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Deep Learning for Computer Vision: A</b> comparision between Convolutiona\u2026", "url": "https://www.slideshare.net/VincenzoLomonaco/deep-learning-for-computer-vision-a-comparision-between-convolutional-neural-networks-and-hierarchical-temporal-memories-on-object-recognition-tasks-masters-degree-thesis", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/VincenzoLomonaco/<b>deep-learning-for-computer-vision-a</b>-com...", "snippet": "A supervised <b>learning</b> algorithm analyzes the training <b>data</b> and produces an inferred function, which <b>can</b> generalize from the training <b>data</b> to unseen situations in a \u201creasonable\u201d way. \u2022 Unsupervised <b>learning</b>: Closely related to pattern recognition, unsupervised <b>learning</b> is about analyzing <b>data</b> and looking for <b>patterns</b>. It is an extremely powerful tool for identifying structure <b>in data</b>. Unsupervised <b>learning</b> <b>can</b> be a goal in itself or a means towards an end. \u2022 Reinforcement <b>learning</b>: Is ...", "dateLastCrawled": "2022-01-24T17:51:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Convolutional neural networks (CNNs): concepts and applications in ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8342355/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8342355", "snippet": "The massive <b>accumulation</b> of <b>data</b> from genomics, transcriptomics, proteomics, ... A parameter is a variable that is interior to the model and configured by <b>learning</b> the <b>data</b>. Parameters <b>can</b> only be initialized but are not set by the user, and it determines the performance of the model, for instance, kernel and weights. Hyperparameters are set by the user and are external to the model. These include <b>learning</b> rates, number of iterations, and number of layers. Tuning involves collecting weights ...", "dateLastCrawled": "2022-02-03T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Transfer <b>learning</b> compensates limited <b>data</b>, batch effects and ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8598306/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8598306", "snippet": "Based on this pre-trained model, we adapted it for two different datasets: (i) TCGA cancer dataset to analyze the few-shot <b>learning</b> model concerning its ability to <b>recognize</b> transferable molecular <b>patterns</b> and (ii) to human single-cell pancreas datasets to show the possibility of cross-modal <b>data</b> integrative analysis. TMP <b>can</b> learn gene expression <b>patterns</b> from GTEx and thus <b>can</b> be directly applied for other datasets and tasks. Furthermore, with these adjusted parameters, the model <b>can</b> ...", "dateLastCrawled": "2021-11-26T01:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How <b>learning</b> unfolds in the brain: toward an optimization view ...", "url": "https://www.sciencedirect.com/science/article/pii/S0896627321006772", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0896627321006772", "snippet": "According to this point of view, which we will refer to as the \u201coptimization framework\u201d (), <b>learning</b> is the outcome of optimizing an objective function (also called a \u201ccost function\u201d) using a <b>learning</b> rule, subject to constraints.For example, one <b>can</b> train an artificial network to <b>recognize</b> handwritten digits using an objective function known as cross-entropy and a <b>learning</b> rule known as backpropagation (Figures 1A\u20131D).In neuroscience, the idea that the brain learns by modifying ...", "dateLastCrawled": "2022-01-16T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Deep <b>learning</b>-based garbage image recognition algorithm | SpringerLink", "url": "https://link.springer.com/article/10.1007/s13204-021-02068-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13204-021-02068-z", "snippet": "To solve the problems of over-fitting, poor convergence, and reduced recall and accuracy of traditional image recognition algorithms, a junk image recognition algorithm based on deep <b>learning</b> is proposed. Dropout is introduced to overcome over fitting, adagrad adaptive method is used to debug the parameters of deep neural network, and ReLU is adopted to solve the <b>gradient</b> dispersion of neural network training, realize the centralized processing of garbage image <b>data</b>, and extract the edge ...", "dateLastCrawled": "2022-01-15T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>A Comparison of Optimization Algorithms for Deep Learning</b>", "url": "https://www.researchgate.net/publication/339073808_A_Comparison_of_Optimization_Algorithms_for_Deep_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339073808_A_Comparison_of_Optimization...", "snippet": "Moreover, six optimization algorithms including stochastic <b>gradient</b> descent (SGD), RMSprop, Adam, Adadelta, Adagrad, Adamax, and Nadam, are used in the <b>learning</b> stage for training the CNN [20 ...", "dateLastCrawled": "2022-01-30T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Deep Convolutional Neural Networks</b> - Run:AI", "url": "https://www.run.ai/guides/deep-learning-for-computer-vision/deep-convolutional-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.run.ai/guides/deep-<b>learning</b>-for-computer-vision/deep-convolutional-neural...", "snippet": "Deep <b>learning</b> is a machine <b>learning</b> technique used to build artificial intelligence (AI) systems. It is based on the idea of artificial neural networks (ANN), designed to perform complex analysis of large amounts of <b>data</b> by passing it through multiple layers of neurons. There is a wide variety of deep neural networks (DNN). Deep convolutional ...", "dateLastCrawled": "2022-02-03T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep <b>learning</b> in analytical chemistry - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S016599362100282X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S016599362100282X", "snippet": "DL techniques <b>can</b> achieve a high level of abstraction during the training process, such as ignoring insignificant <b>data</b> <b>patterns</b>, while retaining critical features related to the particular task at hand. Several popular DL architectures were satisfactorily applied for two- and three-dimensional <b>data</b> analysis. For example, deep neural networks (DNNs), convolutional neural networks (CNNs), recurrent neural networks (RNNs), and auto-encoders (AEs) made breakthrough progress in computer vision ...", "dateLastCrawled": "2022-01-26T16:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "10 <b>Clustering Algorithms With Python</b> - Machine <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/clustering-algorithms-with-python/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/<b>clustering-algorithms-with-python</b>", "snippet": "Clustering or cluster analysis is an unsupervised <b>learning</b> problem. It is often used as a <b>data</b> analysis technique for discovering interesting <b>patterns</b> <b>in data</b>, such as groups of customers based on their behavior. There are many clustering algorithms to choose from and no single best clustering algorithm for all cases. Instead, it is a good idea to explore a range of clustering", "dateLastCrawled": "2022-02-02T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Exam 4 Learning Curve Questions</b> (Ch.11.4 - 14) Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/453254396/exam-4-learning-curve-questions-ch114-14-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/453254396/<b>exam-4-learning-curve-questions-ch114-14</b>-flash-cards", "snippet": "The fruit fly cross shown here analyzes the transmission of two genes on the X chromosome. The male parent has mutant alleles for both the white gene (w-) that results in white eyes and the crossveinless gene (cv-) that results in the absence of crossveins of the fly wings. The female parent has nonmutant forms of these genes (w+ and cv+).", "dateLastCrawled": "2022-01-28T08:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Soccer Ball Detection by Comparing Different Feature Extraction ...", "url": "https://www.hindawi.com/journals/aai/2012/512159/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/aai/2012/512159", "snippet": "Then a feature extraction scheme is used to represent image <b>patterns</b>, and finally <b>data</b> classification is performed by using a supervised <b>learning</b> scheme. Figure 1 schematizes the proposed approach, whereas, in the following sections, a detailed description of the involved algorithmic procedures is given. Figure 1 . Graphical overview of the proposed approach. 3. Candidate Ball Regions Detection. Ball candidates are identified in two phases: at first, all the moving regions are detected ...", "dateLastCrawled": "2022-01-21T11:55:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The Hitchhiker\u2019s Guide to Optimization in <b>Machine Learning</b> | by Aman ...", "url": "https://towardsdatascience.com/the-hitchhikers-guide-to-optimization-in-machine-learning-edcf5a104210", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-hitchhikers-guide-to-optimization-in-<b>machine</b>...", "snippet": "<b>Gradient</b> descent is one of the easiest to implement (and arguably one of the worst) optimization algorithms in <b>machine learning</b>. It is a first-order (i.e., <b>gradient</b>-based) optimization algorithm where we iteratively update the parameters of a differentiable cost function until its minimum is attained. Before we understand how <b>gradient</b> descent ...", "dateLastCrawled": "2022-02-02T19:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Deeper Look into <b>Gradient</b> Based <b>Learning</b> for Neural Networks | by ...", "url": "https://towardsdatascience.com/a-deeper-look-into-gradient-based-learning-for-neural-networks-ad7a35b17b93", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-deeper-look-into-<b>gradient</b>-based-<b>learning</b>-for-neural...", "snippet": "In practice, larger \u03b7 also causes overshooting in <b>machine</b> <b>learning</b> and is termed as the <b>learning</b> rate and is a hyper parameter. Limitations. One of the limitations of Vanilla <b>Gradient</b> Descent is that in the region of gentle slopes, computed gradients are very small resulting in a very slow convergence. One may simply increase the value of \u03b7 ...", "dateLastCrawled": "2022-02-01T13:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Deep Learning</b> <b>Optimizers-Hard?Not.[2</b>] | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/neural-network-optimizers-hard-not-2-7ecc677892cc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/neural-network-<b>optimizers-hard-not-2</b>-7ecc677892cc", "snippet": "<b>Machine</b> <b>Learning</b>; Hackathon ; Contribute; Free Courses ... the negative <b>gradient</b> is the force <b>analogy</b>. It pushes the parameters through the parameter space with the <b>accumulation</b> accelerating ...", "dateLastCrawled": "2021-01-11T12:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>ML Optimization - Advanced Optimizers from scratch with</b> Python", "url": "https://rubikscode.net/2020/11/02/ml-optimization-advanced-optimizers-from-scratch-with-python/", "isFamilyFriendly": true, "displayUrl": "https://rubikscode.net/2020/11/02/<b>ml-optimization-advanced-optimizers-from-scratch</b>...", "snippet": "We also talked about how to quantify <b>machine</b> <b>learning</b> model performance and how to improve it with ... this algorithm restricts the <b>accumulation</b> of gradients by using a decay hyperparameter. So instead of adding complete square <b>gradient</b> to the s vector every iteration, it does it like this: where betta is the decay hyperparameter. Hinton proposed a value of 0.9 for \u03b2 and 0.001 for the <b>learning</b> rate. The parameter update is done in the same way as for AdaGrad: Python Implementation. As you ...", "dateLastCrawled": "2022-01-31T01:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Dynamical <b>machine</b> <b>learning</b> volumetric reconstruction of objects ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8027224/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8027224", "snippet": "Later, a <b>machine</b> <b>learning</b> approach with a Convolutional Neural Network (CNN) replacing the iterative <b>gradient</b> descent algorithm exhibited even better robustness to strong scattering for layered objects, which match well with the BPM assumptions 45. Despite great progress reported by these prior works, the problem of reconstruction through multiple scattering remains difficult due to the extreme ill-posedness and uncertainty in the forward operator; residual distortion and artifacts are not ...", "dateLastCrawled": "2022-01-08T19:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Dynamical machine learning volumetric reconstruction of</b> objects ...", "url": "https://www.nature.com/articles/s41377-021-00512-x", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41377-021-00512-x", "snippet": "The <b>analogy</b> of the BPM computational structure with a neural network was exploited, in conjunction with <b>gradient</b> descent optimization, to obtain the 3D refractive index as the \u201cweights\u201d of the ...", "dateLastCrawled": "2022-02-02T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Regularization : What? Why? and How? (Part -1) | by Siddhant Rai ...", "url": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "isFamilyFriendly": true, "displayUrl": "https://medium.com/m<b>learning</b>-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "snippet": "In general <b>machine</b> <b>learning</b> sense, it is solving an objective function to perform maximum or minimum evaluation. In reality, optimization is lot more profound in usage. Then we have two terms ...", "dateLastCrawled": "2022-01-28T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Solving Word <b>Analogies: A Machine Learning Perspective</b> | Request PDF", "url": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_Machine_Learning_Perspective", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_<b>Machine</b>...", "snippet": "From a <b>machine</b> <b>learning</b> perspective, this provides guidelines to build training sets of positive and negative examples. We then suggest improved methods to classify word-analogies and also to ...", "dateLastCrawled": "2021-10-16T21:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Spectrofluorometric analysis combined with <b>machine</b> <b>learning</b> for ...", "url": "https://www.sciencedirect.com/science/article/pii/S0308814621011559", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0308814621011559", "snippet": "Data from the confusion matrix presented in Table 2 reiterates the 100% accuracy, with the maximum result achieved for all parameters for each varietal class with multi-block analysis. In comparison, analysis using only EEM data with XGBDA afforded somewhat lower accuracy (96.1% correct classification) and inferior model parameters, especially when sample numbers were low (i.e., Merlot and Shiraz/Cabernet Sauvignon, Table S5 of the Supplementary material).Fluorescence spectroscopy has been ...", "dateLastCrawled": "2021-12-26T01:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Automatic Differentiation Using</b> <b>Gradient</b> Tapes - Gowri Shankar", "url": "https://gowrishankar.info/blog/automatic-differentiation-using-gradient-tapes/", "isFamilyFriendly": true, "displayUrl": "https://gowrishankar.info/blog/<b>automatic-differentiation-using</b>-<b>gradient</b>-tapes", "snippet": "<b>Automatic Differentiation Using</b> <b>Gradient</b> Tapes. Posted December 14, 2020 by Gowri Shankar &amp;dash; 9 min read As a Data Scientist or Deep <b>Learning</b> Researcher, one must have a deeper knowledge in various differentiation techniques due to the fact that <b>gradient</b> based optimization techniques like Backpropagation algorithms are critical for model efficiency and convergence.", "dateLastCrawled": "2022-01-28T07:43:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Memory-Efficient Pipeline-Parallel DNN Training</b>", "url": "https://www.researchgate.net/publication/342258674_Memory-Efficient_Pipeline-Parallel_DNN_Training", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342258674_Memory-Efficient_Pipeline-Parallel...", "snippet": "<b>gradient accumulation is similar</b>, with the minibatch size mul- tiplied by an appropriate scale factor (number of replicas, or degree of gradient accumulation), similar to data parallelism.", "dateLastCrawled": "2022-02-02T12:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Memory-Efficient Pipeline-Parallel DNN Training \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2006.09503/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2006.09503", "snippet": "Many state-of-the-art results in domains such as NLP and computer vision have been obtained by scaling up the number of parameters in existing models. However, the weight parameters and intermediate outputs of these large models often do not fit in the main memory of a single accelerator device; this means that it is necessary to use multiple accelerators to train large models, which is challenging to do in a time-efficient way. In this work, we propose PipeDream-2BW, a system that performs ...", "dateLastCrawled": "2021-09-14T05:28:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(gradient accumulation)  is like +(learning how to recognize patterns in data)", "+(gradient accumulation) is similar to +(learning how to recognize patterns in data)", "+(gradient accumulation) can be thought of as +(learning how to recognize patterns in data)", "+(gradient accumulation) can be compared to +(learning how to recognize patterns in data)", "machine learning +(gradient accumulation AND analogy)", "machine learning +(\"gradient accumulation is like\")", "machine learning +(\"gradient accumulation is similar\")", "machine learning +(\"just as gradient accumulation\")", "machine learning +(\"gradient accumulation can be thought of as\")", "machine learning +(\"gradient accumulation can be compared to\")"]}