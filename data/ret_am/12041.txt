{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Partial</b> derivatives - Ximera", "url": "https://ximera.osu.edu/mooculus/calculus2TextbookBySection/partialDerivatives/partialDerivativesAndTheGradientVector/digInPartialDerivatives", "isFamilyFriendly": true, "displayUrl": "https://ximera.osu.edu/mooculus/calculus2TextbookBySection/<b>partialDerivatives</b>/<b>partial</b>...", "snippet": "One way to think of a function of several variables is as a \u201c<b>machine</b>\u201d with lots of knobs: One way to try and understand the <b>machine</b> above would be to hold all but one of the knobs constant, and see what happens when you \u201cwiggle\u201d a single <b>knob</b>. As a explicit example, let Here is our \u201c<b>machine</b>\u201d and the variables and are the \u201cknobs.\u201d Fixing , allows us to focus our attention to all points on the surface where the -value is , We can now focus our attention on the curve . and ...", "dateLastCrawled": "2022-01-01T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Partial derivatives</b> - Ximera", "url": "https://ximera.osu.edu/mooculus/calculus3/partialDerivativesAndTheGradientVector/digInPartialDerivatives", "isFamilyFriendly": true, "displayUrl": "https://ximera.osu.edu/mooculus/calculus3/<b>partialDerivatives</b>AndTheGradientVector/digIn...", "snippet": "One way to think of a function of several variables is as a \u201c<b>machine</b>\u201d with lots of knobs: One way to try and understand the <b>machine</b> above would be to hold all but one of the knobs constant, and see what happens when you \u201cwiggle\u201d a single <b>knob</b>. As a explicit example, let Here is our \u201c<b>machine</b>\u201d and the variables and are the \u201cknobs.\u201d Fixing , allows us to focus our attention to all points on the surface where the -value is , We can now focus our attention on the curve . and ...", "dateLastCrawled": "2022-01-05T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Basic concepts in <b>machine</b> learning | by Samuele Bolotta | MLearning.ai ...", "url": "https://medium.com/mlearning-ai/basic-concepts-in-machine-learning-a20de41137cc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/mlearning-ai/basic-concepts-in-<b>machine</b>-learning-a20de41137cc", "snippet": "A very useful concept for doing this is something called the gradient, whose symbol is \u2207. The \u2207 is a vector; every dimension of that vector is the <b>partial</b> <b>derivative</b> of our function with ...", "dateLastCrawled": "2022-01-10T22:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning Crash Course: Part</b> 3 - ML@B Blog", "url": "https://ml.berkeley.edu/blog/posts/crash-course/part-3/", "isFamilyFriendly": true, "displayUrl": "https://ml.berkeley.edu/blog/posts/crash-course/part-3", "snippet": "and taking the <b>derivative</b> of a matrix means taking the <b>derivative</b> of the elements; While this may seem <b>like</b> a daunting task at first, it turns out that the only tool we really need is our good friend chain rule (if you haven\u2019t met it already, allow us to introduce you). By blindly throwing the chain rule at our cost function, we\u2019ll ...", "dateLastCrawled": "2022-01-30T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>YOU CANalytics</b> | Math of <b>Deep Learning Neural Networks - Simplified</b> ...", "url": "https://ucanalytics.com/blogs/math-of-deep-learning-neural-networks-simplified-part-2/", "isFamilyFriendly": true, "displayUrl": "https://ucanalytics.com/blogs/math-of-<b>deep-learning-neural-networks-simplified-part</b>-2", "snippet": "The <b>knob</b> on top of the brass tap <b>is like</b> the parameters to the output layer (i.e. W 5, W 6, and b 3). Now, you are also using the red <b>knob</b>, in addition to the <b>knob</b> on the tap, to get the desired output from the tap. Your effort of the red <b>knob</b> will depend on these factors.", "dateLastCrawled": "2021-12-23T07:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>machine</b> learning - Should the lambda for L1 norm regularizer inversely ...", "url": "https://datascience.stackexchange.com/questions/73134/should-the-lambda-for-l1-norm-regularizer-inversely-be-proportional-to-the-numbe", "isFamilyFriendly": true, "displayUrl": "https://<b>datascience.stackexchange</b>.com/questions/73134/should-the-lambda-for-l1-norm...", "snippet": "Backpropagation doesn&#39;t handle Regularization <b>like</b> this i.e. if you are thinking &quot;10 weights make penalty 100, so 100 weights will make penalty 1000. So let&#39;s have a smaller $\\lambda$ Backpropagation uses the <b>partial</b> differentiation of the Loss.", "dateLastCrawled": "2022-01-19T09:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Calculating energy derivatives for quantum chemistry on a quantum ...", "url": "https://www.nature.com/articles/s41534-019-0213-4", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-019-0213-4", "snippet": "In this section, we present and compare various methods for calculating energy derivatives on a quantum computer. In Table 1, we estimate the computational complexity of all studied methods in ...", "dateLastCrawled": "2022-01-30T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[D] What is the gradient of a reduction operation on a Matrix ...", "url": "https://www.reddit.com/r/MachineLearning/comments/6zho5z/d_what_is_the_gradient_of_a_reduction_operation/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>Machine</b>Learning/comments/6zho5z/d_what_is_the_gradient_of_a...", "snippet": "My question comes from the following comment in the TensorFlow source code: // The <b>partial</b> <b>derivative</b> for any input along a &quot;reduced&quot; dimension. // is just 1, so we only need replicate the output gradient on such a. // dimension to its &quot;expanded&quot; shape. // Running example:", "dateLastCrawled": "2021-01-28T01:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "As there is a Jacobian and Hessian matrix, is there a third <b>partial</b> ...", "url": "https://www.quora.com/As-there-is-a-Jacobian-and-Hessian-matrix-is-there-a-third-partial-derivative-matrix", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/As-there-is-a-Jacobian-and-Hessian-matrix-is-there-a-third...", "snippet": "Answer: Let F:R^n\u2014\u2192R be a real(higher order) differentiable function and let X=(x1, x2, x3 \u2026 , xn) . The <b>derivative</b> of F is the row matrix dF/dX=[F1 , F2 , F3 ...", "dateLastCrawled": "2022-01-19T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "&quot;Or-<b>sets&quot;: my attempt to understand calculus</b> : CasualMath", "url": "https://www.reddit.com/r/CasualMath/comments/hx3kfh/orsets_my_attempt_to_understand_calculus/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/CasualMath/comments/hx3kfh/or<b>sets_my_attempt_to_understand</b>...", "snippet": "We can actually assign a value to 1/0. For any complex number z, it holds that z = &lt;z&gt;. That is, every number is equal to its own singleton or-set. But that doesn&#39;t mean every arithmetic operation must necessarily result in a singleton or-set. For instance, with or-sets, we can now define 1/0 by simply saying 1/0 = &lt;&gt;.", "dateLastCrawled": "2021-09-08T04:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Partial derivatives</b> - Ximera", "url": "https://ximera.osu.edu/mooculus/calculus3/partialDerivativesAndTheGradientVector/digInPartialDerivatives", "isFamilyFriendly": true, "displayUrl": "https://ximera.osu.edu/mooculus/calculus3/<b>partialDerivatives</b>AndTheGradientVector/digIn...", "snippet": "One way to think of a function of several variables is as a \u201c<b>machine</b>\u201d with lots of knobs: One way to try and understand the <b>machine</b> above would be to hold all but one of the knobs constant, and see what happens when you \u201cwiggle\u201d a single <b>knob</b>. As a explicit example, let Here is our \u201c<b>machine</b>\u201d and the variables and are the \u201cknobs.\u201d Fixing , allows us to focus our attention to all points on the surface where the -value is , We can now focus our attention on the curve . and ...", "dateLastCrawled": "2022-01-05T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Partial</b> derivatives - Ximera", "url": "https://ximera.osu.edu/mooculus/calculus2TextbookBySection/partialDerivatives/partialDerivativesAndTheGradientVector/digInPartialDerivatives", "isFamilyFriendly": true, "displayUrl": "https://ximera.osu.edu/mooculus/calculus2TextbookBySection/<b>partialDerivatives</b>/<b>partial</b>...", "snippet": "Compute: F ( 0, 1) ( x, y) = \\answer x 2 + 3 y 2. We have shown how to compute a <b>partial</b> <b>derivative</b>, but it may still not be clear what a <b>partial</b> <b>derivative</b> means. Given z = F ( x, y), F ( 1, 0) ( x, y) measures the rate at which z changes as only x varies: y is held constant. Imagine standing in a rolling meadow, then beginning to walk due east.", "dateLastCrawled": "2022-01-01T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>YOU CANalytics</b> | Math of <b>Deep Learning Neural Networks - Simplified</b> ...", "url": "https://ucanalytics.com/blogs/math-of-deep-learning-neural-networks-simplified-part-2/", "isFamilyFriendly": true, "displayUrl": "https://ucanalytics.com/blogs/math-of-<b>deep-learning-neural-networks-simplified-part</b>-2", "snippet": "Essentially, this <b>is similar</b> to the change in water pressure observed at the output by turning the <b>knob</b> on the top of the tap. The chain rule states this: The chain rule states this: The above equation for chain rule is fairly simple since equation on the right-hand side will become the one on the left-hand side by simple division.", "dateLastCrawled": "2021-12-23T07:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Basic concepts in <b>machine</b> learning | by Samuele Bolotta | MLearning.ai ...", "url": "https://medium.com/mlearning-ai/basic-concepts-in-machine-learning-a20de41137cc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/mlearning-ai/basic-concepts-in-<b>machine</b>-learning-a20de41137cc", "snippet": "At a saddle point, the <b>partial</b> <b>derivative</b> with respect to each dimension of the function is zero, but the function is increasing in some of the dimensions and decreasing in other dimensions.", "dateLastCrawled": "2022-01-10T22:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning Crash Course: Part</b> 3 - ML@B Blog", "url": "https://ml.berkeley.edu/blog/posts/crash-course/part-3/", "isFamilyFriendly": true, "displayUrl": "https://ml.berkeley.edu/blog/posts/crash-course/part-3", "snippet": "<b>Similar</b> to a perceptron, a neuron takes in any number of numerical inputs and spits out just one output. To get to this output, the neuron calculates an intermediate value called s s s by multiplying each input by a different weight, adding them all together, and adding an additional number called the bias. In math: s = w e i g h t 1 \u00d7 i n p u t 1 +... + w e i g h t n \u00d7 i n p u t n + b i a s s = weight_{1}\\times input_{1}+...+weight_{n}\\times input_{n}+bias s = w e i g h t 1 \u00d7 i n p u t 1 ...", "dateLastCrawled": "2022-01-30T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Calculating energy derivatives for quantum chemistry on a quantum ...", "url": "https://www.nature.com/articles/s41534-019-0213-4", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-019-0213-4", "snippet": "In this section, we present and compare various methods for calculating energy derivatives on a quantum computer. In Table 1, we estimate the computational complexity of all studied methods in ...", "dateLastCrawled": "2022-01-30T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "An overview of gradient descent optimization algorithms", "url": "https://ruder.io/optimizing-gradient-descent/", "isFamilyFriendly": true, "displayUrl": "https://ruder.io/optimizing-gradient-descent", "snippet": "This post explores how many of the most popular gradient-based optimization algorithms actually work. Note: If you are looking for a review paper, this blog post is also available as an article on arXiv.. Update 20.03.2020: Added a note on recent optimizers.. Update 09.02.2018: Added AMSGrad.. Update 24.11.2017: Most of the content in this article is now also available as slides.. Update 15.06.2017: Added derivations of AdaMax and Nadam.. Update 21.06.16: This post was posted to Hacker News.", "dateLastCrawled": "2022-02-02T21:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "karpathy.github.io/nntutorial.md at master \u00b7 karpathy/karpathy.github.io", "url": "https://github.com/karpathy/karpathy.github.io/blob/master/nntutorial.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/karpathy/karpathy.github.io/blob/master/nntutorial.md", "snippet": "The entire symbol \\( \\frac{\\<b>partial</b> f(x,y)}{\\<b>partial</b> x} \\) is a single thing: the <b>derivative</b> of the function \\( f(x,y) \\) with respect to \\( x \\). The horizontal line on the right is division. I know it&#39;s confusing but it&#39;s standard notation. Anyway, I hope it doesn&#39;t look too scary because it isn&#39;t: The circuit was giving some initial output ...", "dateLastCrawled": "2021-08-22T16:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Can you <b>explain briefly about machine learning, deep learning</b>, AI ...", "url": "https://www.quora.com/Can-you-explain-briefly-about-machine-learning-deep-learning-AI-neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Can-you-<b>explain-briefly-about-machine-learning-deep-learning</b>-AI...", "snippet": "Answer (1 of 3): Below is a chart that I often present to illustrate the nested hierarchical relationship between many of the frameworks that are often discussed today. I also find it helpful to use definitions that build off of each other. * Automation - Processing according to pre-programmed ...", "dateLastCrawled": "2022-01-17T15:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Bren \u2013 <b>The Armourers Bench</b>", "url": "https://armourersbench.com/tag/bren/", "isFamilyFriendly": true, "displayUrl": "https://armourersbench.com/tag/bren", "snippet": "The design team at the Royal Small Arms Factory at Enfield developed a belt-fed <b>derivative</b> of the Bren light <b>machine</b> gun. The X11 series of prototypes sought to convert the Bren\u2019s proven design into a weapon capable of sustained fire. The X11 made a number of changes to the Bren included the addition of a detachable butt/grip/trigger assembly which could be swapped for a pair of spade grips and a paddle trigger for static sustained fire from a tripod. This resulted in the pistol grip being ...", "dateLastCrawled": "2022-02-01T13:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The <b>Partial</b> <b>Derivative</b> <b>Machine</b> - Semantic Scholar", "url": "https://pdfs.semanticscholar.org/90c5/e9d6d94280b81e6a66973e3635aa9d163f98.pdf", "isFamilyFriendly": true, "displayUrl": "https://pdfs.semanticscholar.org/90c5/e9d6d94280b81e6a66973e3635aa9d163f98.pdf", "snippet": "The <b>Partial</b> <b>Derivative</b> <b>Machine</b> Grant Sherer, Mary Bridget Kustusch, Corinne A. Manogue and David Roundy Department of Physics, Weniger 301, Oregon State University, Corvallis, Oregon 97331 Abstract. Research has shown that students struggle to understand the use of <b>partial</b> derivatives in thermodynamics. We have designed an apparatus, which we have called a <b>Partial</b> <b>Derivative</b> <b>Machine</b>, that serves as a mechanical analogue of a thermodynamic system. Using this device, students have a tangible ...", "dateLastCrawled": "2021-10-10T11:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning Crash Course: Part</b> 3 - ML@B Blog", "url": "https://ml.berkeley.edu/blog/posts/crash-course/part-3/", "isFamilyFriendly": true, "displayUrl": "https://ml.berkeley.edu/blog/posts/crash-course/part-3", "snippet": "We <b>can</b> visualize this <b>thought</b> process with various neurons tasked with identifying increasingly abstract objects in the image: ... going back to our <b>machine</b> analogy you <b>can</b> imagine yourself turning the <b>knob</b> for single parameter and watching the cost function go up or down. The slope for a particular parameter will tell you which way to turn the <b>knob</b> to make the cost function go down. Once we find out which way to turn each of the knobs (in other words, once we have the <b>derivative</b> of the cost ...", "dateLastCrawled": "2022-01-30T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Hacker&#39;s guide to Neural Networks</b> - GitHub Pages", "url": "http://karpathy.github.io/neuralnets/", "isFamilyFriendly": true, "displayUrl": "karpathy.github.io/neuralnets", "snippet": "The <b>derivative</b> <b>can</b> <b>be thought</b> of as a force on each input as we pull on the output to become higher. So how do we exactly evaluate this force (<b>derivative</b>)? It turns out that there is a very simple procedure for this. We will work backwards: Instead of pulling on the circuit\u2019s output, we\u2019ll iterate over every input one by one, increase it very slightly and look at what happens to the output value. The amount the output changes in response is the <b>derivative</b>. Enough intuitions for now. Lets ...", "dateLastCrawled": "2022-01-26T16:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> Learning | Good Math/Bad Math", "url": "http://www.goodmath.org/blog/category/good-math/machine-learning/", "isFamilyFriendly": true, "displayUrl": "www.goodmath.org/blog/category/good-math/<b>machine</b>-learning", "snippet": "We <b>can</b> think of this simple model of a neuron in computational terms as a computing element that takes a set of weighted input values, combines them into a single value, and then generates an output of \u201c1\u201d if that value exceeds a threshold, and 0 if it does not. In slightly more formal terms, where: is the number of inputs to the <b>machine</b>.", "dateLastCrawled": "2021-12-14T18:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>control system engineering (6th edition) solution</b> | Aqeel Ahmad ...", "url": "https://www.academia.edu/11776817/control_system_engineering_6th_edition_solution", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/11776817", "snippet": "<b>control system engineering (6th edition) solution</b>", "dateLastCrawled": "2022-01-28T20:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "[D] What is the gradient of a reduction operation on a Matrix ...", "url": "https://www.reddit.com/r/MachineLearning/comments/6zho5z/d_what_is_the_gradient_of_a_reduction_operation/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>Machine</b>Learning/comments/6zho5z/d_what_is_the_gradient_of_a...", "snippet": "My question comes from the following comment in the TensorFlow source code: // The <b>partial</b> <b>derivative</b> for any input along a &quot;reduced&quot; dimension. // is just 1, so we only need replicate the output gradient on such a. // dimension to its &quot;expanded&quot; shape. // Running example:", "dateLastCrawled": "2021-01-28T01:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Brainly.com - For students. By students.", "url": "https://brainly.com/", "isFamilyFriendly": true, "displayUrl": "https://brainly.com", "snippet": "Here you <b>can</b> find step by step solutions to the problems in your textbook, created by experts. Algebra and Trigonometry, 2nd Edition. Probability and Statistics for Engineering and the Sciences, 8th Edition. find your book. Ruled by students, supported by parents. 4.4. review from Google Play &quot;This app is so much more than I expected. I was just needing help to figure out a math problem, but I was surprised with what I found.&quot; Katie B. Tap into the brainpower of thousands of experts ...", "dateLastCrawled": "2022-02-03T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How <b>can</b> I get <b>better with solving derivatives and Calculus in</b> ... - Quora", "url": "https://www.quora.com/How-can-I-get-better-with-solving-derivatives-and-Calculus-in-general", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>can</b>-I-get-<b>better-with-solving-derivatives-and-Calculus-in</b>...", "snippet": "Answer (1 of 3): Get to know derivatives, integrals (dk if you started this topic yet) and the difference between the two. In school, we often tend to solve problems using rules given by our teachers without trying to find sense in it; without ever having the subject \u2018click\u2019 in perfectly. Try to ...", "dateLastCrawled": "2022-01-18T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "&quot;Or-<b>sets&quot;: my attempt to understand calculus</b> : CasualMath", "url": "https://www.reddit.com/r/CasualMath/comments/hx3kfh/orsets_my_attempt_to_understand_calculus/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/CasualMath/comments/hx3kfh/or<b>sets_my_attempt_to_understand</b>...", "snippet": "We <b>can</b> actually assign a value to 1/0. For any complex number z, it holds that z = &lt;z&gt;. That is, every number is equal to its own singleton or-set. But that doesn&#39;t mean every arithmetic operation must necessarily result in a singleton or-set. For instance, with or-sets, we <b>can</b> now define 1/0 by simply saying 1/0 = &lt;&gt;.", "dateLastCrawled": "2021-09-08T04:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Can</b> you <b>explain briefly about machine learning, deep learning</b>, AI ...", "url": "https://www.quora.com/Can-you-explain-briefly-about-machine-learning-deep-learning-AI-neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Can</b>-you-<b>explain-briefly-about-machine-learning-deep-learning</b>-AI...", "snippet": "Answer (1 of 3): Below is a chart that I often present to illustrate the nested hierarchical relationship between many of the frameworks that are often discussed today. I also find it helpful to use definitions that build off of each other. * Automation - Processing according to pre-programmed ...", "dateLastCrawled": "2022-01-17T15:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The <b>Partial</b> <b>Derivative</b> <b>Machine</b>", "url": "https://sites.science.oregonstate.edu/physics/coursewikis/portfolioswiki/_media/perc2013pdmposter7026.pdf_%3b?cache=cache", "isFamilyFriendly": true, "displayUrl": "https://sites.science.oregonstate.edu/physics/coursewikis/portfolioswiki/_media...", "snippet": "The <b>Partial</b> <b>Derivative</b> <b>Machine</b> is an apparatus consisting of a central spring system that <b>can</b> be stretched via four strings extending outward. This central system is on a large piece of particle board which features a pulley on two adjacent corners (Corners C and D), and a <b>knob</b> on all four corners. The system is held in place using the knobs at A and B. Adding weight to the strings at C and D causes the system to stretch, and this stretching <b>can</b> be measured using the flags on the strings ...", "dateLastCrawled": "2022-01-05T01:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Partial derivatives</b> - Ximera", "url": "https://ximera.osu.edu/mooculus/calculusA2/partialDerivativesAndTheGradientVector/digInPartialDerivatives", "isFamilyFriendly": true, "displayUrl": "https://ximera.osu.edu/mooculus/calculusA2/<b>partialDerivatives</b>AndTheGradientVector/di...", "snippet": "The second pure <b>partial</b> <b>derivative</b> of with respect to then is ; The second pure <b>partial</b> <b>derivative</b> of with respect to then is ; Moreover, there is also the notion of a mixed <b>partial</b> <b>derivative</b>, and The notation is ambiguous, it does not state which <b>derivative</b> should be taken first. As we will see, in practice this is not too much of a problem.", "dateLastCrawled": "2022-01-13T20:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning Crash Course: Part</b> 3 - ML@B Blog", "url": "https://ml.berkeley.edu/blog/posts/crash-course/part-3/", "isFamilyFriendly": true, "displayUrl": "https://ml.berkeley.edu/blog/posts/crash-course/part-3", "snippet": "<b>Compared</b> to our complex organ, even our most powerful supercomputers are a joke. In 2014, Japanese researchers used a ... going back to our <b>machine</b> analogy you <b>can</b> imagine yourself turning the <b>knob</b> for single parameter and watching the cost function go up or down. The slope for a particular parameter will tell you which way to turn the <b>knob</b> to make the cost function go down. Once we find out which way to turn each of the knobs (in other words, once we have the <b>derivative</b> of the cost with ...", "dateLastCrawled": "2022-01-30T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "DEVELOPMENT OF AN AC <b>TO DC CONVERTER USING MICROCONTROLLER</b>", "url": "http://ethesis.nitrkl.ac.in/301/1/AC2DC.pdf", "isFamilyFriendly": true, "displayUrl": "ethesis.nitrkl.ac.in/301/1/AC2DC.pdf", "snippet": "3.4.2 Voltage Control by the <b>Knob</b> 16 3.4.3 Circuit Schematic 17 4. Simulation in Multisim (N.I.) 18 4.1 Simulation Circuit Diagram 19 ... 5.1 The Proportional-Integral-<b>Derivative</b> (PID) algorithm 24 5.1.1 A Proportional algorithm 24 5.1.2 A Proportional Integral algorithm 25 5.1.3 A Proportional Integral <b>Derivative</b> algorithm 25 5.2 The characteristics of P, I and D controllers 26 5.3 PID implementation on Output voltage control 27 5.3.1 Determination of Average output voltage 28 5.3.2 PID ...", "dateLastCrawled": "2022-01-05T18:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Calculating energy derivatives for quantum chemistry on a quantum ...", "url": "https://www.nature.com/articles/s41534-019-0213-4", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-019-0213-4", "snippet": "One <b>can</b> easily foresee a powerful combination of highly accurate forces generated on a quantum computer with <b>machine</b>-learning algorithms for the generation of reliable and broadly applicable force ...", "dateLastCrawled": "2022-01-30T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "An overview of gradient descent optimization algorithms", "url": "https://ruder.io/optimizing-gradient-descent/", "isFamilyFriendly": true, "displayUrl": "https://ruder.io/optimizing-gradient-descent", "snippet": "This way, it a) reduces the variance of the parameter updates, which <b>can</b> lead to more stable convergence; and b) <b>can</b> make use of highly optimized matrix optimizations common to state-of-the-art deep learning libraries that make computing the gradient w.r.t. a mini-batch very efficient. Common mini-batch sizes range between 50 and 256, but <b>can</b> vary for different applications. Mini-batch gradient descent is typically the algorithm of choice when training a neural network and the term SGD ...", "dateLastCrawled": "2022-02-02T21:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Help with cost function in neural networks : MLQuestions", "url": "https://www.reddit.com/r/MLQuestions/comments/8pcl2q/help_with_cost_function_in_neural_networks/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/MLQuestions/comments/8pcl2q/help_with_cost_function_in_neural...", "snippet": "What&#39;s happening here is the <b>partial</b> <b>derivative</b> is computed with respect to each parameter for each example and is then summed up into one (n x 1) vector. For this particular loss function the gradient includes a multiplication by the constant (1/m). Now we have a (n x 1) gradient vector which we <b>can</b> multiply by the learning rate to compute the final parameter update. 0. w = w - \u03b1 * (1/m) * X T (Xw-y) w = (n x 1) - (\u03b1/m) * (n x 1) w = (n x 1) - (n x 1) w = (n x 1) Parameters in a neural ...", "dateLastCrawled": "2022-02-03T12:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Egans Chapter 45 Mechanical Ventilators Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/406039579/egans-chapter-45-mechanical-ventilators-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/406039579/egans-chapter-45-mechanical-ventilators-flash-cards", "snippet": "Volume is the <b>derivative</b> of flow. 3. Flow is the <b>derivative</b> of volume. a. 1 and 2 only b. 1 and 3 only c. 2 and 3 only d. 1, 2, and 3 ANS: B This follows from the fact that volume and flow are inverse functions of time (i.e., volume is the integral of flow and flow is the <b>derivative</b> of volume). DIF: Application REF: p. 998 OBJ: 2 15. A ventilator&#39;s pressure waveform changes when a patient&#39;s lung mechanics change, but its volume waveform remains the same. The device does not directly control ...", "dateLastCrawled": "2021-04-14T05:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "3rd class Power Engineering A2 Chapter 11 Flashcards | Quizlet", "url": "https://quizlet.com/ca/342510242/3rd-class-power-engineering-a2-chapter-11-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/ca/342510242/3rd-class-power-engineering-a2-chapter-11-flash-cards", "snippet": "c. <b>Derivative</b> d. Gain e. Set point. a _____ are used to convert physical quantities of flow, level, temperature, pressure, and weight into electrical signals that represent those quantities as accurately as possible. a. Controllers. b. Control valves. c. Transmitters. d. Level switches. e. Transducers. c. For purposes of control theory, a process <b>can</b> be defined as an action in which material and/or _____ is modified into a different form. a. Fluids. b. Energy. c. Gas. d. Oil. e. Power. b ...", "dateLastCrawled": "2020-01-07T03:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How would you summarize the <b>core ideas of Machine Learning and</b> Deep ...", "url": "https://www.quora.com/How-would-you-summarize-the-core-ideas-of-Machine-Learning-and-Deep-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-would-you-summarize-the-<b>core-ideas-of-Machine-Learning-and</b>...", "snippet": "Answer (1 of 3): Learned behavior entails three cognitive functions: -- ability to operate given <b>partial</b> information, as if complete information had been given In order to do this, one must be able to reduce complete info into <b>partial</b> information, reduce complexity. This is accomplished by linear...", "dateLastCrawled": "2022-01-14T17:39:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning derivatives</b> - Geoffrey Huck", "url": "https://geoffreyhuck.com/articles/machine-learning-derivatives", "isFamilyFriendly": true, "displayUrl": "https://geoffreyhuck.com/articles/<b>machine-learning-derivatives</b>", "snippet": "An <b>analogy</b> would be finding which direction you should take to reach the highest mountain but with the restriction of only being able to see one meter away. In this article, we will first recall the rules of derivatives and <b>partial</b> derivatives. Then we will feature a few derivatives of functions that are commonly used in <b>machine</b> <b>learning</b>. The derivatives rules. The basics. Let\u2019s start by the derivatives of common functions. In the following : is a constant. is the variable by which we ...", "dateLastCrawled": "2021-12-29T05:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b> 101: An Intuitive Introduction to <b>Gradient</b> Descent ...", "url": "https://towardsdatascience.com/machine-learning-101-an-intuitive-introduction-to-gradient-descent-366b77b52645", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-101-an-intuitive-introduction-to...", "snippet": "In other words, the <b>gradient</b> is a vector, and each of its components is a <b>partial</b> <b>derivative</b> with respect to one specific variable. Take the function, f(x, y) = 2x\u00b2 + y \u00b2 as another example. Here, f(x, y) is a multi-variable function. Its <b>gradient</b> is a vector, containing the <b>partial</b> derivatives of f(x, y). The first with respect to x, and the second with respect to y. If we calculate the partials of f(x,y) we get. So the <b>gradient</b> is the following vector: Note that each component indicates ...", "dateLastCrawled": "2022-01-30T05:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> in <b>Machine</b> <b>Learning</b>", "url": "https://cambum.net/CCE/LearningParameter.pdf", "isFamilyFriendly": true, "displayUrl": "https://cambum.net/CCE/<b>Learning</b>Parameter.pdf", "snippet": "<b>Learning</b> Rate \u2013 Basic Algorithm 21 The delta-bar-delta algorithm is an early heuristic approach to adapting individual <b>learning</b> rates for model parameters during training. If the <b>partial</b> <b>derivative</b> of the loss, with respect to a given model parameter, remains the same sign, then the <b>learning</b> rate should increase.", "dateLastCrawled": "2022-01-29T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> with Spreadsheets! Part 1: <b>Gradient</b> Descent and ...", "url": "https://medium.com/excel-with-ml/machine-learning-with-spreadsheets-part-1-gradient-descent-f9316676db9b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/excel-with-ml/<b>machine</b>-<b>learning</b>-with-spreadsheets-part-1-<b>gradient</b>...", "snippet": "<b>Gradient</b> descent: Step-by-step spreadsheets show you how machines learn without the code. Go under the hood with backprop, <b>partial</b> derivatives, and <b>gradient</b> descent.", "dateLastCrawled": "2022-01-29T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Analogues in thermodynamics: the <b>Partial</b> <b>Derivative</b> <b>Machine</b> and ...", "url": "https://www.compadre.org/per/items/4833.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.compadre.org/per/items/4833.pdf", "snippet": "foster student <b>learning</b> in thermodynamics, the Oregon State University Physics Education Research Group de-veloped the <b>Partial</b> <b>Derivative</b> <b>Machine</b> (PDM) as a me-chanical analogue to a thermodynamic system [2]. The PDM (Fig. 1) allows students to explore challenging aspects of thermodynamics, including inaccessible vari-ables and thermodynamic potentials, on a mechanical system that students can understand without having to rst learn new thermodynamic concepts [3]. We con-ducted post ...", "dateLastCrawled": "2021-10-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Mathematics <b>for Machine Learning: Multivariate Calculus</b> | by Isaac Ng ...", "url": "https://medium.com/@isaacng/mathematics-for-machine-learning-multivariate-calculus-7102c7a586c6", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@isaacng/mathematics-<b>for-machine-learning-multivariate-calculus</b>...", "snippet": "Graph with no <b>derivative</b> at 0. Finding the gradient. The gradient of a variable in a function is the rise over run against the other variables. In the classic x, y coordinate plot, the rise over ...", "dateLastCrawled": "2022-01-25T18:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - <b>Neural Network Regularization and derivation</b> - Cross ...", "url": "https://stats.stackexchange.com/questions/502047/neural-network-regularization-and-derivation", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/502047/neural-network-regularization-and...", "snippet": "The p index is there for us to carry out matrix multiplication. Recall that to perform matrix-vector multiplication A x where A \u2208 R m \u00d7 n and x \u2208 R n, the i -th entry is equal to \u2211 p = 1 n A i p x p . Notice that we are using <b>partial</b> <b>derivative</b> and hence \u2202 W j p [ l] \u2202 W j k [ l] = { 1, p = k 0, p \u2260 k.", "dateLastCrawled": "2022-01-22T09:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Notes on <b>Deep Learning and Differential Equations</b>. \u2013 Cloud Computing ...", "url": "https://cloud4scieng.org/2020/06/10/notes-on-deep-learning-and-differential-equations/", "isFamilyFriendly": true, "displayUrl": "https://cloud4scieng.org/2020/06/10/notes-on-<b>deep-learning-and-differential-equations</b>", "snippet": "We now turn to the work on using neural networks to solve <b>partial</b> differential equations. The examples we will study are from four papers. Raissi, Perdikaris, and Karniadakis, \u201cPhysics Informed Deep <b>Learning</b> (Part II): Data-driven Discovery of Nonlinear <b>Partial</b> Di\ufb00erential Equations\u201d, Nov 2017, is the paper that introduces PINNS and demonstrates the concept by showing how to solve several \u201cclassical\u201d PDEs. Yang, Zhang, and Karniadakis, \u201cPhysics-Informed Generative Adversarial ...", "dateLastCrawled": "2022-02-03T00:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "neural network - Gradient descent and <b>partial derivatives</b> - Data ...", "url": "https://datascience.stackexchange.com/questions/28691/gradient-descent-and-partial-derivatives", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/28691", "snippet": "Data Science Stack Exchange is a question and answer site for Data science professionals, <b>Machine</b> <b>Learning</b> specialists, and those interested in <b>learning</b> more about the field.", "dateLastCrawled": "2022-02-01T18:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "18.4. Multivariable Calculus \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "http://www.d2l.ai/chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html", "isFamilyFriendly": true, "displayUrl": "www.d2l.ai/chapter_appendix-mathematics-for-deep-<b>learning</b>/multivariable-calculus.html", "snippet": "Note that we have taken our direction to have length one for convenience, and used \\(\\theta\\) for the angle between \\(\\mathbf{v}\\) and \\(\\nabla_{\\mathbf{w}} L(\\mathbf{w})\\).If we want to find the direction that decreases \\(L\\) as rapidly as possible, we want to make this expression as negative as possible. The only way the direction we pick enters into this equation is through \\(\\cos(\\theta)\\), and thus we wish to make this cosine as negative as possible.Now, recalling the shape of cosine ...", "dateLastCrawled": "2022-01-29T17:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "[1\uc8fc\ucc28] Coursera <b>Machine</b> <b>Learning</b> : <b>Regression</b>", "url": "https://enthan.tistory.com/41", "isFamilyFriendly": true, "displayUrl": "https://enthan.tistory.com/41", "snippet": "<b>partial derivative is like</b> a derivative with respect to w1, treating all variables as constants . Convex =&gt; solution is unique + gradient descent algorithm will converge to minimum . \ubc18\uc751\ud615 . \uacf5\uc720\ud558\uae30. \uae00 \uc694\uc18c. \uad6c\ub3c5\ud558\uae30 \uc5d4\uc9c0\ub2c8\uc5b4\uc758 \ub534\uc0dd\uac01 &#39;Data Science &gt; <b>Machine</b> <b>Learning</b>&#39; \uce74\ud14c\uace0\ub9ac\uc758 \ub2e4\ub978 \uae00 (0) 2021.05.27 [2\uc8fc\ucc28] Multiple <b>Regression</b> (0) 2021.05.27 [1\uc8fc\ucc28] Coursera <b>Machine</b> <b>Learning</b> : <b>Regression</b> (0) 2021.05.27: Scikit-Learn\uc744 \uc774\uc6a9\ud55c \uba38\uc2e0\ub7ec\ub2dd (0) 2020.10 ...", "dateLastCrawled": "2021-12-25T20:07:00.0000000Z", "language": "ko", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b>", "url": "https://feisky.xyz/machine-learning/tensorflow/getting-started.html", "isFamilyFriendly": true, "displayUrl": "https://feisky.xyz/<b>machine</b>-<b>learning</b>/tensorflow/getting-started.html", "snippet": "Too large # jumps risk inaccuracy, too small slow the <b>learning</b>. <b>learning</b>_rate = 0.002 # In TensorFlow, we need to run everything in the context of a session. with tf. Session() as sess: # Set up all the tensors. # Our input layer is the x value and the bias node. input = tf. constant(x_with_bias) # Our target is the y values.", "dateLastCrawled": "2021-05-17T21:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Gradient Descent | Programming <b>Machine</b> <b>Learning</b> by Paolo Perrotta | The ...", "url": "https://medium.com/pragmatic-programmers/gradient-descent-1a227b6ddba5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/pragmatic-programmers/gradient-descent-1a227b6ddba5", "snippet": "Programming <b>Machine</b> <b>Learning</b> \u2014 by Paolo Perrotta (20 / 133) Let\u2019s look for a better train algorithm. The job of train is to find the parameters that minimize the loss, so let\u2019s start by ...", "dateLastCrawled": "2021-08-23T13:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "October | 2012 | <b>SLog of the most illogical mind</b>", "url": "https://slogofillogicalmind.wordpress.com/2012/10/", "isFamilyFriendly": true, "displayUrl": "https://slogofillogicalmind.wordpress.com/2012/10", "snippet": "Abstract data type is like a imaginary <b>machine</b> that have some skills that we need to use. Programmer is the engineer to build this robot. But if you just simply want to this robot, you just need to know what operation you can use with this. For example there is a stack in ADT. Just think of one robot called \u201cstack\u201d and what it does is stores all the things that you put in it and take it back to you the item but in reverse order that you put in. So the item that you put in at the last ...", "dateLastCrawled": "2022-01-26T01:55:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Predicting <b>cell phone adoption metrics</b> using <b>machine</b> <b>learning</b> and ...", "url": "https://www.sciencedirect.com/science/article/pii/S0736585321000617", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0736585321000617", "snippet": "In this paper we present a <b>machine</b> <b>learning</b> method that uses publicly available satellite imagery to predict telecoms demand metrics, including cell phone adoption and spending on mobile services, and apply the method to Malawi and Ethiopia. Our predictive <b>machine</b> <b>learning</b> approach consistently outperforms baseline models which use population density or nightlight luminosity, with an improvement in data variance prediction of at least 40%. The method is a starting point for developing more ...", "dateLastCrawled": "2021-10-21T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Predicting cell phone adoption metrics using machine learning</b> and ...", "url": "https://www.researchgate.net/publication/350756678_Predicting_cell_phone_adoption_metrics_using_machine_learning_and_satellite_imagery", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350756678_Predicting_cell_phone_adoption...", "snippet": "<b>machine</b> <b>learning</b> with call records and satellite image ry, to address a similar set of questions relating to poverty estimation (Ayush et al., 2020; Jean et al., 2016; Perez et al., 2017; Steele ...", "dateLastCrawled": "2021-12-25T00:20:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(partial derivative)  is like +(knob on a machine)", "+(partial derivative) is similar to +(knob on a machine)", "+(partial derivative) can be thought of as +(knob on a machine)", "+(partial derivative) can be compared to +(knob on a machine)", "machine learning +(partial derivative AND analogy)", "machine learning +(\"partial derivative is like\")", "machine learning +(\"partial derivative is similar\")", "machine learning +(\"just as partial derivative\")", "machine learning +(\"partial derivative can be thought of as\")", "machine learning +(\"partial derivative can be compared to\")"]}