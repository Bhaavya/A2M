{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The \u201c<b>black box</b>\u201d metaphor in machine learning | by Dallas Card | Medium", "url": "https://dallascard.medium.com/the-black-box-metaphor-in-machine-learning-4e57a3a1d2b0", "isFamilyFriendly": true, "displayUrl": "https://dallascard.medium.com/the-<b>black-box</b>-metaphor-in-machine-learning-4e57a3a1d2b0", "snippet": "In addition to being an incredibly successful rebranding of neural networks and machine learning (itself arguably a rather successful rebranding of statistics), the term <b>deep</b> learning refers to a particular type of <b>model</b>, one in which the outputs are the results of a series of many simple transformations applied to the inputs (much <b>like</b> our wiring diagram from above). Although <b>deep</b> learning models are certainly complex, they are not <b>black</b> boxes. In fact, it would be more accurate to refer to ...", "dateLastCrawled": "2022-02-02T16:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Deep</b> learning doesn\u2019t need to be a <b>black</b> <b>box</b> - <b>KDnuggets</b>", "url": "https://www.kdnuggets.com/2021/02/deep-learning-not-black-box.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2021/02/<b>deep</b>-learning-not-<b>black</b>-<b>box</b>.html", "snippet": "While these methods are helpful, they still treat <b>deep</b> learning models <b>like</b> <b>black</b> boxes and don\u2019t paint a definite picture of the workings of neural networks. \u201c\u2019Explanation\u2019 methods are often summary statistics of performance (e.g., local approximations, general trends on node activation) rather than actual explanations of the <b>model</b>\u2019s calculations,\u201d the authors of the concept whitening paper write.", "dateLastCrawled": "2022-02-02T09:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "terminology - Why are Machine Learning models called <b>black</b> boxes ...", "url": "https://datascience.stackexchange.com/questions/22335/why-are-machine-learning-models-called-black-boxes", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/22335", "snippet": "However, <b>deep</b> neural networks are the paradigmatic example of <b>black box</b> algorithms. No one, not even the most expert person in the world grasp the function that is actually modeled by training a neural network. An insight about this can be provided by adversarial examples: some slight (and unnoticeable by a human) change in a training sample can lead the network to think that it belongs to a totally different label. There are some techniques to create adversarial examples, and some ...", "dateLastCrawled": "2022-01-21T00:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Peeking inside the <b>Black</b> <b>Box</b>: Interpreting <b>Deep</b> Learning Models ...", "url": "https://www.academia.edu/69799916/Peeking_inside_the_Black_Box_Interpreting_Deep_Learning_Models_for_Exoplanet_Atmospheric_Retrievals", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69799916/Peeking_inside_the_<b>Black</b>_<b>Box</b>_Interpreting_<b>Deep</b>...", "snippet": "Draft version July 26, 2021 Typeset using LATEX twocolumn style in AASTeX62 Peeking inside the <b>Black</b> <b>Box</b>: Interpreting <b>Deep</b> Learning Models for Exoplanet Atmospheric Retrievals Kai Hou Yip,1 Quentin Changeat,1 Nikolaos Nikolaou,1 Mario Morvan,1 Billy Edwards,1 Ingo P. Waldmann,1 and Giovanna Tinetti1 1 Departmentof Physics and Astronomy University College London arXiv:2011.11284v2 [astro-ph.EP] 23 Jul 2021 Gower Street,WC1E 6BT London, United Kingdom (Accepted July 20, 2021) Submitted to AJ ...", "dateLastCrawled": "2022-02-05T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "machine learning - Why are neural networks described as <b>black-box</b> ...", "url": "https://stats.stackexchange.com/questions/93705/why-are-neural-networks-described-as-black-box-models", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/93705", "snippet": "$\\begingroup$ I <b>like</b> to add point to Jack, when we look at MLP in machine learning point of view, ... A <b>black box</b> <b>model</b> is a <b>model</b> that is extremely hard or practically impossible to interpret. $\\endgroup$ \u2013 user289381. Jul 29 &#39;20 at 20:22. Add a comment | 2 Answers Active Oldest Votes. 46 $\\begingroup$ A neural network is a <b>black box</b> in the sense that while it can approximate any function, studying its structure won&#39;t give you any insights on the structure of the function being ...", "dateLastCrawled": "2022-01-26T21:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Artificial Intelligence <b>Black Box</b> and the Failure of Intent and ...", "url": "https://jolt.law.harvard.edu/assets/articlePDFs/v31/The-Artificial-Intelligence-Black-Box-and-the-Failure-of-Intent-and-Causation-Yavar-Bathaee.pdf", "isFamilyFriendly": true, "displayUrl": "https://jolt.law.harvard.edu/assets/articlePDFs/v31/The-Artificial-Intelligence-<b>Black</b>...", "snippet": "<b>Deep</b> Neural Networks and Complexity.....901 2. Support Vector Machines and Dimensionality.....903 D. Weak and Strong ... AI <b>Black Box</b>: Failure of Intent &amp; Causation 891 is built on legal doctrines that are focused on human conduct,5 which when applied to AI, may not function. Notably, the doctrines that pose the greatest risk of failing are two of the most ubiquitous in American law \u2014 intent and causation. The reason intent and causation may fail to function is because of the nature of the ...", "dateLastCrawled": "2022-01-30T08:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Demystifying the <b>Black</b> <b>Box</b> That Is AI - <b>Scientific American</b>", "url": "https://www.scientificamerican.com/article/demystifying-the-black-box-that-is-ai/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.scientificamerican.com</b>/article/demystifying-the-<b>black</b>-<b>box</b>-that-is-ai", "snippet": "One approach\u2014called <b>model</b> induction, or the \u201cobserver approach\u201d\u2014treats an AI system <b>like</b> a <b>black</b> <b>box</b>. \u201cYou experiment with it and try to infer its behavior,\u201d says David Gunning, who ...", "dateLastCrawled": "2022-01-28T06:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Solving the AI <b>black</b> <b>box</b> problem through transparency", "url": "https://www.techtarget.com/searchenterpriseai/feature/How-to-solve-the-black-box-AI-problem-through-transparency", "isFamilyFriendly": true, "displayUrl": "https://www.techtarget.com/searchenterpriseai/feature/How-to-solve-the-<b>black</b>-<b>box</b>-AI...", "snippet": "But even with those concerns, <b>black</b> <b>box</b> development is currently the primary method of <b>deep</b> learning modeling. In this approach, millions of data points are inputted into the algorithm, which then identifies correlations between specific data features to produce an output. The process inside the <b>box</b>, however, is mostly self-directed and is generally difficult for data scientists, programmers and users to interpret.", "dateLastCrawled": "2022-01-30T11:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What are <b>black</b> <b>box</b>, grey <b>box</b>, and white <b>box</b> penetration testing ...", "url": "https://resources.infosecinstitute.com/topic/what-are-black-box-grey-box-and-white-box-penetration-testing/", "isFamilyFriendly": true, "displayUrl": "https://resources.infosecinstitute.com/topic/what-are-<b>black</b>-<b>box</b>-grey-<b>box</b>-and-white-<b>box</b>...", "snippet": "<b>Black</b>-<b>box</b> penetration testers also need to be capable of creating their own map of a target network based on their observations, since no such diagram is provided to them. The limited knowledge provided to the penetration tester makes <b>black</b>-<b>box</b> penetration tests the quickest to run, since the duration of the assignment largely depends on the tester\u2019s ability to locate and exploit vulnerabilities in the target\u2019s outward-facing services. The major downside of this approach is that if the ...", "dateLastCrawled": "2022-02-03T06:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[D] share your ML/DL <b>model</b> as <b>black</b> <b>box</b> : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/sjt557/d_share_your_mldl_model_as_black_box/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/sjt557/d_share_your_mldl_<b>model</b>_as_<b>black</b>_<b>box</b>", "snippet": "Greetings. I want to share my pytorch <b>deep</b> learning <b>model</b> in the form of a <b>black</b> <b>box</b>. So other person cant see the architecture, loading, pre-processing, prediction happens in the <b>box</b>. The user just send an input and get a output. One way is to server via django and host it. But i want the user to use it locally. I dont know if any such thing ...", "dateLastCrawled": "2022-02-03T20:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Why Are We Using <b>Black</b> <b>Box</b> Models in AI When We Don\u2019t Need To? A Lesson ...", "url": "https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/5", "isFamilyFriendly": true, "displayUrl": "https://hdsr.mitpress.mit.edu/pub/f9kuryi8/release/5", "snippet": "Even in computer vision, where <b>deep</b> neural networks (the most difficult kind of <b>black</b> <b>box</b> <b>model</b> to explain) are the state-of-the-art, we and other scientists (e.g., Chen et al., 2019; Y. Li et al., 2017; L. Li, Liu, Chen, &amp; Rudin, 2018; Ming, Xu, Qu, &amp; Ren, 2019) have found ways to add interpretability constraints to <b>deep</b> learning models, leading to more transparent computations. These interpretability constraints have not come at the expense of accuracy, even for <b>deep</b> neural networks for ...", "dateLastCrawled": "2021-10-17T02:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability vs Explainability: The Black</b> <b>Box</b> of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-interpretability-vs-explainability", "snippet": "The benefit a <b>deep</b> neural net offers to engineers is it creates a <b>black</b> <b>box</b> of parameters, like fake additional data points, that allow a <b>model</b> to base its decisions against. These fake data points go unknown to the engineer. The <b>black</b> <b>box</b>, or hidden layers, allow a <b>model</b> to make associations among the given data points to predict better results. For example, if we are deciding how long someone might have to live, and we use career data as an input, it is possible the <b>model</b> sorts the careers ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What are <b>black</b> <b>box</b>, grey <b>box</b>, and white <b>box</b> penetration testing ...", "url": "https://resources.infosecinstitute.com/topic/what-are-black-box-grey-box-and-white-box-penetration-testing/", "isFamilyFriendly": true, "displayUrl": "https://resources.infosecinstitute.com/topic/what-are-<b>black</b>-<b>box</b>-grey-<b>box</b>-and-white-<b>box</b>...", "snippet": "Unlike <b>black</b>-<b>box</b> and gray-<b>box</b> testing, white-<b>box</b> penetration testers are able to perform static code analysis, making familiarity with source code analyzers, debuggers and <b>similar</b> tools important for this type of testing. However, dynamic analysis tools and techniques are also important for white-<b>box</b> testers since static analysis can miss vulnerabilities introduced by misconfiguration of target systems.", "dateLastCrawled": "2022-02-03T06:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 3, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Black box</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Black_box", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Black_box</b>", "snippet": "With backtesting, out of time data is always used when testing the <b>black box</b> <b>model</b>. Data has to be written down before it is pulled for <b>black box</b> inputs. Other theories . The observed hydrograph is a graphic of the response of a watershed (a <b>blackbox</b>) with its runoff (red) to an input of rainfall (blue). <b>Black box</b> theories are theories defined only in terms of their function. The term <b>black box</b> theory is applied to any field, philosophy and science or otherwise where some inquiry or ...", "dateLastCrawled": "2022-02-03T00:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The <b>AI Black Box Explanation Problem</b> - KDnuggets", "url": "https://www.kdnuggets.com/2019/03/ai-black-box-explanation-problem.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2019/03/<b>ai-black-box-explanation-problem</b>.html", "snippet": "<b>model</b> inspection when the object is to understand how internally the <b>black</b> <b>box</b> behaves changing the input by means of a visual tool. Figure 1: Open the <b>black</b> <b>box</b> problems taxonomy. We are focusing on the open challenge of constructing a global meaningful explanation for a <b>black</b> <b>box</b> <b>model</b> in the BBX setting by exploiting local explanations of why a specific case has received a certain classification outcome.", "dateLastCrawled": "2022-01-31T18:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to Explain the Prediction of a <b>Machine Learning</b> <b>Model</b>?", "url": "https://lilianweng.github.io/lil-log/2017/08/01/how-to-explain-the-prediction-of-a-machine-learning-model.html", "isFamilyFriendly": true, "displayUrl": "https://lilianweng.github.io/lil-log/2017/08/01/how-to-explain-the-prediction-of-a...", "snippet": "Approaches to explaining a <b>black</b>-<b>box</b> <b>model</b> aim to extract information from the trained <b>model</b> to justify its prediction outcome, without knowing how the <b>model</b> works in details. To keep the interpretation process independent from the <b>model</b> implementation is good for real-world applications: Even when the base <b>model</b> is being constantly upgraded and refined, the interpretation engine built on top would not worry about the changes. Without the concern of keeping the <b>model</b> transparent and ...", "dateLastCrawled": "2022-02-01T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "3.5 <b>Properties of Explanations</b> | Interpretable Machine Learning", "url": "https://christophm.github.io/interpretable-ml-book/properties.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-book/properties.html", "snippet": "Fidelity: How well does the explanation approximate the prediction of the <b>black</b> <b>box</b> <b>model</b>? High fidelity is one of the most important properties of an explanation, because an explanation with low fidelity is useless to explain the machine learning <b>model</b>. Accuracy and fidelity are closely related. If the <b>black</b> <b>box</b> <b>model</b> has high accuracy and the explanation has high fidelity, the explanation also has high accuracy. Some explanations offer only local fidelity, meaning the explanation only ...", "dateLastCrawled": "2022-02-03T10:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Understanding <b>model</b> predictions with <b>LIME</b> | by Lars Hulstaert | Towards ...", "url": "https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-<b>model</b>-predictions-with-<b>lime</b>-a582fdff3a3b", "snippet": "<b>LIME</b> assumes a <b>black</b> <b>box</b> machine learning <b>model</b> and investigates the relationship between input and output, represented by the <b>model</b>. <b>Model</b>-specific approaches aim to understand the <b>black</b> <b>model</b> machine learning <b>model</b> by analysing the internal components and how they interact. In <b>deep</b> learning models, it is e.g. possible to investigate activation units and to link internal activations back to the input. This requires a thorough understanding of the network and doesn\u2019t scale to other models ...", "dateLastCrawled": "2022-02-03T00:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Different Types Of Deep Learning Models Explained</b> | RoboticsBiz", "url": "https://roboticsbiz.com/different-types-of-deep-learning-models-explained/", "isFamilyFriendly": true, "displayUrl": "https://roboticsbiz.com/<b>different-types-of-deep-learning-models-explained</b>", "snippet": "The fine-tuning of the <b>deep</b> belief network is very <b>similar</b> to the multilayer perceptron. Such <b>deep</b> belief networks are useful in acoustic modeling. Convolutional Neural Networks. A convolutional neural network (CNN) is another variant of the feedforward multilayer perceptron. It is a type of feedforward neural network, where the individual neurons are ordered in a way that they respond to all overlapping regions in the visual area. <b>Deep</b> CNN works by consecutively modeling small pieces of ...", "dateLastCrawled": "2022-01-31T10:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "YOLO : You Only Look Once \u2013 Real Time Object Detection", "url": "https://www.geeksforgeeks.org/yolo-you-only-look-once-real-time-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/yolo-you-only-look-once-real-time-object-detection", "snippet": "YOLO was proposed by Joseph Redmond et al. in 2015.It was proposed to deal with the problems faced by the object recognition models at that time, Fast R-CNN is one of the state-of-the-art models at that time but it has its own challenges such as this network cannot be used in real-time, because it takes 2-3 seconds to predicts an image and therefore cannot be used in real-time.", "dateLastCrawled": "2022-02-01T03:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The \u201c<b>black box</b>\u201d metaphor in machine learning | by Dallas Card | Medium", "url": "https://dallascard.medium.com/the-black-box-metaphor-in-machine-learning-4e57a3a1d2b0", "isFamilyFriendly": true, "displayUrl": "https://dallascard.medium.com/the-<b>black-box</b>-metaphor-in-machine-learning-4e57a3a1d2b0", "snippet": "As a simpler example of a <b>black box</b>, consider a <b>thought</b> experiment from Skinner: you are given a <b>box</b> with a set of inputs (switches and buttons) and a set of outputs (lights which are either on or off). By manipulating the inputs, you are able to observe the corresponding outputs, but you cannot look inside to see how the <b>box</b> works. In the simplest case, such as a light switch in a room, it is easy to determine with great confidence that the switch controls the light level. For a ...", "dateLastCrawled": "2022-02-02T16:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Why Are We Using <b>Black</b> <b>Box</b> Models in AI When We Don\u2019t Need To? A Lesson ...", "url": "https://hdsr.mitpress.mit.edu/pub/f9kuryi8", "isFamilyFriendly": true, "displayUrl": "https://hdsr.mitpress.mit.edu/pub/f9kuryi8", "snippet": "Trusting a <b>black</b> <b>box</b> <b>model</b> means that you trust not only the <b>model</b>\u2019s equations, but also the entire database that it was built from. For instance, in the scenario of the robot and the surgeon, without knowing how the 2% and 15% were estimated, we should question the relevance of these numbers for any particular subpopulation of medical patients. Every reasonably complex dataset we have seen contains imperfections. These <b>can</b> range from huge amounts of missing data (that are not missing at ...", "dateLastCrawled": "2021-12-18T06:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "An overview of <b>model</b> <b>explainability</b> in modern machine learning | by Rui ...", "url": "https://towardsdatascience.com/an-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-overview-of-<b>model</b>-<b>explainability</b>-in-modern-machine...", "snippet": "It\u2019s often the case that certain \u201c<b>black</b> <b>box</b>\u201d models such as <b>deep</b> neural networks are deployed to production and are running critical systems from everything in your workplace security cameras to your smartphone. It\u2019s a scary <b>thought</b> that not even the developers of these algorithms understand why exactly the algorithms make the decisions they do \u2014 or even worse, how to prevent an adversary from exploiting them. While there are many challenges facing the designer of a \u201c<b>black</b> <b>box</b> ...", "dateLastCrawled": "2022-01-31T22:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>New Theory Cracks Open the Black Box of Deep Learning</b> | Quanta Magazine", "url": "https://www.quantamagazine.org/new-theory-cracks-open-the-black-box-of-deep-learning-20170921/", "isFamilyFriendly": true, "displayUrl": "https://www.quantamagazine.org/<b>new-theory-cracks-open-the-black-box-of-deep-learning</b>...", "snippet": "The duo discovered that a <b>deep</b>-learning algorithm invented by Hinton called the \u201c<b>deep</b> belief net\u201d works, in a particular case, exactly like renormalization, a technique used in physics to zoom out on a physical system by coarse-graining over its details and calculating its overall state. When Schwab and Mehta applied the <b>deep</b> belief net to a <b>model</b> of a magnet at its \u201ccritical point,\u201d where the system is fractal, or self-similar at every scale, they found that the network ...", "dateLastCrawled": "2022-02-02T17:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Explainable AI</b> | <b>IBM</b>", "url": "https://www.ibm.com/watson/explainable-ai", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ibm.com</b>/watson/<b>explainable-ai</b>", "snippet": "ML models are often <b>thought</b> <b>of as black</b> boxes that are impossible to interpret.\u00b2 Neural networks used in <b>deep</b> learning are some of the hardest for a human to understand. Bias, often based on race, gender, age or location, has been a long-standing risk in training AI models. Further, AI <b>model</b> performance <b>can</b> drift or degrade because production data differs from training data. This makes it crucial for a business to continuously monitor and manage models to promote AI explainability while ...", "dateLastCrawled": "2022-02-02T14:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Not So Mysterious After All: Researchers Show How to Crack AI\u2019s <b>Black</b> <b>Box</b>", "url": "https://singularityhub.com/2021/10/25/not-so-mysterious-after-all-researchers-show-how-to-crack-ais-black-box/", "isFamilyFriendly": true, "displayUrl": "https://singularityhub.com/2021/10/25/not-so-mysterious-after-all-researchers-show-how...", "snippet": "A group from Nvidia has shown that they <b>can</b> infer the data the <b>model</b> was trained on without even seeing any examples of the trained data. They used an approach called <b>model</b> inversion, which effectively runs the neural net in reverse. This technique is often used to analy z e neural networks, but using it to recover the input data had only been achieved on simple networks under very specific sets of assumptions. I n a recent paper, the resea rchers describe d how they were able to scale the ...", "dateLastCrawled": "2022-01-31T02:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpreting Image Classification Model with</b> LIME | by Ruben Winastwan ...", "url": "https://towardsdatascience.com/interpreting-image-classification-model-with-lime-1e7064a2f2e5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpreting-image-classification-model-with</b>-lime-1e...", "snippet": "<b>Model</b> agnostic, which means that LIME is <b>model</b>-independent. In other words, LIME is able to explain any <b>black</b>-<b>box</b> classifier you <b>can</b> think of. Interpretable, which means that LIME provides you a solution to understand why your <b>model</b> behaves the way it does. Local, which means that LIME tries to find the explanation of your <b>black</b>-<b>box</b> <b>model</b> by ...", "dateLastCrawled": "2022-02-01T00:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is <b>Deep Learning</b> and How Does It Work?", "url": "https://www.techtarget.com/searchenterpriseai/definition/deep-learning-deep-neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.techtarget.com/searchenterpriseai/definition/<b>deep-learning</b>-<b>deep</b>-neural-network", "snippet": "At its simplest, <b>deep learning</b> <b>can</b> <b>be thought</b> of as a way to automate predictive analytics. ... the data used during the training stage must be labeled so the <b>model</b> <b>can</b> see if its guess was accurate. This means, though many enterprises that use big data have large amounts of data, unstructured data is less helpful. Unstructured data <b>can</b> only be analyzed by a <b>deep learning</b> <b>model</b> once it has been trained and reaches an acceptable level of accuracy, but <b>deep learning</b> models <b>can</b>&#39;t train on ...", "dateLastCrawled": "2022-01-29T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "AI Generates Hypotheses Human Scientists Have Not <b>Thought</b> Of ...", "url": "https://www.scientificamerican.com/article/ai-generates-hypotheses-human-scientists-have-not-thought-of/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.scientificamerican.com</b>/article/ai-generates-hypotheses-human-scientists...", "snippet": "This lack of transparency has been nicknamed \u201cthe <b>black</b> <b>box</b> problem\u201d because no one <b>can</b> see inside the network to explain its \u201c<b>thought</b>\u201d process. Not only does this opacity undermine trust ...", "dateLastCrawled": "2022-01-28T22:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The <b>Dark Secret at the Heart of</b> AI | <b>MIT Technology Review</b>", "url": "https://www.technologyreview.com/2017/04/11/5113/the-dark-secret-at-the-heart-of-ai/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.technologyreview.com</b>/2017/04/11/5113/the-<b>dark-secret-at-the-heart-of</b>-ai", "snippet": "But by its nature, <b>deep</b> learning is a particularly dark <b>black</b> <b>box</b>. You <b>can</b>\u2019t just look inside a <b>deep</b> neural network to see how it works. A network\u2019s reasoning is embedded in the behavior of ...", "dateLastCrawled": "2022-01-30T21:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Peeking inside the <b>Black</b> <b>Box</b>: Interpreting <b>Deep</b> Learning Models ...", "url": "https://www.academia.edu/69799916/Peeking_inside_the_Black_Box_Interpreting_Deep_Learning_Models_for_Exoplanet_Atmospheric_Retrievals", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69799916/Peeking_inside_the_<b>Black</b>_<b>Box</b>_Interpreting_<b>Deep</b>...", "snippet": "Draft version July 26, 2021 Typeset using LATEX twocolumn style in AASTeX62 Peeking inside the <b>Black</b> <b>Box</b>: Interpreting <b>Deep</b> Learning Models for Exoplanet Atmospheric Retrievals Kai Hou Yip,1 Quentin Changeat,1 Nikolaos Nikolaou,1 Mario Morvan,1 Billy Edwards,1 Ingo P. Waldmann,1 and Giovanna Tinetti1 1 Departmentof Physics and Astronomy University College London arXiv:2011.11284v2 [astro-ph.EP] 23 Jul 2021 Gower Street,WC1E 6BT London, United Kingdom (Accepted July 20, 2021) Submitted to AJ ...", "dateLastCrawled": "2022-02-05T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Deep Learning Objective Type Questions and Answers</b>", "url": "http://onlinemlquiz.com/ebooks/ebook_deep_learning_objective_type_questions.pdf", "isFamilyFriendly": true, "displayUrl": "onlinemlquiz.com/ebooks/ebook_<b>deep_learning_objective_type_questions</b>.pdf", "snippet": "Interpretability: Machine Learning algorithms are more interpretable as <b>compared</b> to <b>deep</b> learning algorithms. <b>Deep</b> learning models mostly act as <b>black</b> <b>box</b>. For example, decision tree in machine learning <b>can</b> be easily interpreted by human beings and they <b>can</b> easily get to know how the final values are computed. On the other hand, it is very hard to know what calculations happened inside the hidden layers of the neural networks, how convoluted layers in CNN identified the various portions of ...", "dateLastCrawled": "2022-02-02T12:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Hands-on Machine Learning <b>Model</b> <b>Interpretation</b> | by Dipanjan (DJ ...", "url": "https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on...", "snippet": "It tests out what happens to you <b>black</b> <b>box</b> <b>model</b>\u2019s predictions when you feed variations or perturbations of your dataset into the <b>black</b> <b>box</b> <b>model</b>. Typically, LIME generates a new dataset consisting of perturbed samples and the associated <b>black</b> <b>box</b> <b>model</b>\u2019s predictions. On this dataset LIME then trains an interpretable <b>model</b> weighted by the proximity of the sampled instances to the instance of interest. Following is a standard high-level workflow for this.", "dateLastCrawled": "2022-02-02T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What are the <b>advantages of using Artificial Neural Network compared to</b> ...", "url": "https://www.researchgate.net/post/What-are-the-advantages-of-using-Artificial-Neural-Network-compared-to-other-approaches", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What-are-the-<b>advantages-of-using-Artificial-Neural</b>...", "snippet": "The colleague described ANN being <b>black</b> <b>box</b> <b>model</b> as a disadvantage, which I see an advantage coz the user does not have to be the expert of ANN to use it. One <b>can</b> apply ANNs to the problem at ...", "dateLastCrawled": "2022-02-01T13:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Can</b> we open the <b>black</b> <b>box</b> of AI? : Nature News &amp; Comment", "url": "https://www.nature.com/news/can-we-open-the-black-box-of-ai-1.20731", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/news/<b>can</b>-we-open-the-<b>black</b>-<b>box</b>-of-ai-1.20731", "snippet": "Illustration by Simon Prades. Dean Pomerleau <b>can</b> still remember his first tussle with the <b>black</b>-<b>box</b> problem. The year was 1991, and he was making a pioneering attempt to do something that has now ...", "dateLastCrawled": "2022-01-31T15:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Explain Your <b>Model</b> with the <b>SHAP</b> Values | by Dr. Dataman | Towards Data ...", "url": "https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/explain-your-<b>model</b>-with-the-<b>shap</b>-values-bc36aac4de3d", "snippet": "A sophisticated machine learning algorithms usually <b>can</b> produce accurate predictions, but its notorious \u201c<b>black</b> <b>box</b>\u201d nature does not help adoption at all. Think about this: If you ask me to swallow a <b>black</b> pill without telling me what\u2019s in it, I certainly don\u2019t want to swallow it. The interpretability of a <b>model</b> is like a label on a drug bottle. We need to make our effective pill transparent for easy adoption. How <b>can</b> we do th a t? The <b>SHAP</b> value is a great tool among others like LIME ...", "dateLastCrawled": "2022-02-02T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Advantages of <b>Deep</b> Learning, Plus Use Cases and Examples | Scalr.ai", "url": "https://www.width.ai/post/advantages-of-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.width.ai/post/advantages-of-<b>deep</b>-learning", "snippet": "A typical neural network or <b>deep</b> learning <b>model</b> takes days to learn the parameters that define the <b>model</b>. Parallel and distributed algorithms address this pain point by allowing <b>deep</b> learning models to be trained much faster. Models <b>can</b> be trained using local training (use one machine to train the <b>model</b>), with GPUs, or a combination of both. However, the sheer volume of the training datasets involved could mean that storing it in a single machine becomes impossible. And that\u2019s where data ...", "dateLastCrawled": "2022-02-03T12:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>The Difference Between Deep Learning &amp; Machine Learning</b>", "url": "https://analyticsindiamag.com/understanding-difference-deep-learning-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/understanding-difference-<b>deep</b>-learning-machine-learning", "snippet": "In <b>Deep</b> Learning, one <b>can</b> feed raw pixels to process images and correctly classify objects in images with higher accuracy DL Algorithms Scale With Data Vis-\u00e0-Vis ML Besides the automated feature extraction in <b>deep</b> learning models which makes it highly suitable for computer vision tasks such as image classification and face recognition, <b>deep</b> learning algorithms scale with data, as opposed to machine learning.", "dateLastCrawled": "2022-01-28T14:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Top 10 Most Popular AI <b>Models</b> - DZone AI", "url": "https://dzone.com/articles/top-10-most-popular-ai-models", "isFamilyFriendly": true, "displayUrl": "https://dzone.com/articles/top-10-most-popular-ai-<b>models</b>", "snippet": "The most common case is when we have some historical data X and Y and <b>can</b> deploy the AI <b>model</b> to provide the best mapping between these values. The result cannot be 100% accurate, as otherwise ...", "dateLastCrawled": "2022-02-03T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Deep drawing</b>, <b>deep drawing</b> products, micro <b>deep drawing</b> factory in ...", "url": "https://sipxmach.com/deep-drawing/", "isFamilyFriendly": true, "displayUrl": "https://<b>sipxmach</b>.com/<b>deep-drawing</b>", "snippet": "<b>Deep drawing</b> is one of the most common techniques of metal forming accessible to producers\u2013it includes the use of metal dies to form blank sheets of metal in a required form. In particular, if the depth of the generated product is equal to or higher than its radius, then <b>deep drawing</b> <b>can</b> be called the process of metal forming.", "dateLastCrawled": "2022-01-25T15:52:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://<b>deep</b>ai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor <b>model</b> fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Deep learning vs. machine learning</b>: What\u2019s the difference?", "url": "https://www.zendesk.com/blog/machine-learning-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.zendesk.com/blog/<b>machine</b>-<b>learning</b>-and-<b>deep</b>-<b>learning</b>", "snippet": "A <b>deep</b> <b>learning</b> <b>model</b> is able to learn through its own method of computing\u2014a technique that makes it seem like it has its own brain. To recap, the key differences between <b>machine</b> <b>learning</b> and <b>deep</b> <b>learning</b> are: <b>Machine</b> <b>learning</b> uses algorithms to parse data, learn from that data, and make informed decisions based on what it has learned.", "dateLastCrawled": "2022-01-29T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor <b>model</b> fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "In addition to three invited talks, the meeting also included workshops on CBR and <b>Deep</b> <b>Learning</b>, Computer <b>Analogy</b>, and Process-Oriented CBR, as well as a Doctoral Consortium, the ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Analogies between Biology and <b>Deep</b> <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "There are a number of exciting connections between physics and <b>deep</b> <b>learning</b>. Perhaps the most discussed are scaling laws (e.g. ... Evolvability seems at least partially analogous to what we call &quot;meta-<b>learning</b>&quot; in <b>machine</b> <b>learning</b>, a broad category of ideas around <b>machine</b> <b>learning</b> systems <b>learning</b> to learn better (see discussion in Gajewski et al, 2019). At the same time, if one tries to apply some of the ideas we include in meta-<b>learning</b> to evolution, they often seem much broader than ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Using <b>Deep</b> <b>Learning</b> for Image Analogies | by Tomer Amit | Towards Data ...", "url": "https://towardsdatascience.com/using-deep-learning-for-image-analogies-aa2e7d7af337", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-<b>deep</b>-<b>learning</b>-for-image-analogies-aa2e7d7af337", "snippet": "Another concept, related to language processing and <b>deep</b> <b>learning</b>, is Word Embeddings. Given a large corpus of text, say with 100,000 words, we build an embedding, or a mapping, giving each word a vector in a smaller space of dimension n=500, say. This kind of dimesionality reduction gives us a compact representation of the words. And indeed, Word Embeddings are useful for many tasks, including sentiment analysis, <b>machine</b> translation, and also Word Analogies , i.e, solving an <b>analogy</b> of the ...", "dateLastCrawled": "2022-01-19T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Types of Machine Learning</b> | Different Methods and Kinds of <b>Model</b>", "url": "https://www.educba.com/types-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>types-of-machine-learning</b>", "snippet": "Introduction to <b>Types of Machine Learning</b>. <b>Machine</b> <b>learning</b> is the subfield of AI that focuses on the development of the computer programs which have access to data by providing a system with the ability to learn and improve automatically. For example, finding patterns in the database without any human interventions or actions is based upon the ...", "dateLastCrawled": "2022-02-02T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Difference Between Algorithm and Model</b> in <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/difference-between-algorithm-and-model-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>difference-between-algorithm-and-model</b>-", "snippet": "A <b>machine learning</b> <b>model</b> is more challenging for a beginner because there is not a clear <b>analogy</b> with other algorithms in computer science. For example, the sorted list output of a sorting algorithm is not really a <b>model</b>. The best <b>analogy</b> is to think of the <b>machine learning</b> <b>model</b> as a \u201cprogram.\u201d The <b>machine learning</b> <b>model</b> \u201cprogram\u201d is comprised of both data and a procedure for using the data to make a prediction. For example, consider the linear regression algorithm and resulting ...", "dateLastCrawled": "2022-01-31T01:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine</b> <b>Learning</b> with Spreadsheets! Part 1: <b>Gradient</b> Descent and ...", "url": "https://medium.com/excel-with-ml/machine-learning-with-spreadsheets-part-1-gradient-descent-f9316676db9b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/excel-with-ml/<b>machine</b>-<b>learning</b>-with-spreadsheets-part-1-<b>gradient</b>...", "snippet": "<b>Gradient</b> descent: Step-by-step spreadsheets show you how machines learn without the code. Go under the hood with backprop, partial derivatives, and <b>gradient</b> descent.", "dateLastCrawled": "2022-01-29T01:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Li Hongyi &quot;Deep <b>Learning</b>&quot; study notes-GNN - Programmer Sought", "url": "https://www.programmersought.com/article/25166341055/", "isFamilyFriendly": true, "displayUrl": "https://www.programmersought.com/article/25166341055", "snippet": "The flat model has a poorer <b>learning</b> effect than the deep model, because the <b>deep model is like</b> a modular, each layer only recognizes some features, and t... 2020 Li Hongyi study notes-64.Deep Reinforcement <b>Learning</b>. 1. Concept: The content in this section is just some introductory aspects of reinforcement <b>learning</b> (Scratching the surface). First, I will start with examples, and then take the bee on the red and wh... Li Hongyi &quot;Deep <b>Learning</b> Language Processing&quot; study notes. Deep <b>Learning</b>-Li ...", "dateLastCrawled": "2022-01-13T08:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Li Hongyi study in deep <b>learning</b> (seven) - Programmer Sought", "url": "https://www.programmersought.com/article/38149282673/", "isFamilyFriendly": true, "displayUrl": "https://www.programmersought.com/article/38149282673", "snippet": "Introduced the development of artificial intelligence, <b>machine</b> <b>learning</b>, deep <b>learning</b>, and the relationship between the three. This paper introduces the related technologies of <b>machine</b> <b>learning</b>: Scenario, problem (task), and methods or models that solve problems (Method). return Introduced the definition of the regression: Find a function function, output a value Y by entering the feature X. Model step: STEP1 model assumption (model), STEP2 model evaluation (policies, loss functions), STEP3 ...", "dateLastCrawled": "2022-01-27T12:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Deep Learning, Pachinko, and James Watt: Efficiency</b> is the Driver of ...", "url": "https://inverseprobability.com/2016/03/04/deep-learning-and-uncertainty", "isFamilyFriendly": true, "displayUrl": "https://inverseprobability.com/2016/03/04/deep-<b>learning</b>-and-uncertainty", "snippet": "In <b>machine</b> <b>learning</b> this is known as deep <b>learning</b>. For some authors it is related to the brain or a fundamental way of thinking about AI, but we can simply think of it as a sensible idea of applying a set of simple transformations to an image to built a complex transformation. The challenge of <b>machine</b> <b>learning</b> is how to determine what these transformations should be. Each of the simpler deterministic transformations can actually have very many parameters. In the case of DeepFace there are ...", "dateLastCrawled": "2021-12-08T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Deep <b>Learning, Pachinko, and James Watt: Efficiency</b> is the Driver of ...", "url": "https://www.kdnuggets.com/2016/06/deep-learning-pachinko-james-watt-efficiency-driver-uncertainty.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2016/06/deep-<b>learning</b>-pachinko-james-watt-efficiency-driver...", "snippet": "In <b>machine</b> <b>learning</b> this is known as deep <b>learning</b>. For some authors it is related to the brain or a fundamental way of thinking about AI, but we can simply think of it as a sensible idea of applying a set of simple transformations to an image to built a complex transformation. The challenge of <b>machine</b> <b>learning</b> is how to determine what these transformations should be. Each of the simpler deterministic transformations can actually have very many parameters. In the case of DeepFace there are ...", "dateLastCrawled": "2022-01-15T03:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Wide and deep <b>learning</b> for <b>peer-to-peer lending</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S095741741930377X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S095741741930377X", "snippet": "After training the model, it is crucial to evaluate the performance of the model on the test samples and compare its performance with the benchmarks, namely, deep <b>learning</b> (DP), wide <b>learning</b> (WL), random forest (RF), gradient boosting regression algorithm (GB), and support vector <b>machine</b> (SVM). 15 Precision and recall are used as performance metrics of the models. It is well-known that in the presence of imbalanced dataset, accuracy is not a proper performance metric, and precision and ...", "dateLastCrawled": "2021-12-28T02:33:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>Learning</b> Demystified. From Optimization to Deep <b>Learning</b> | by ...", "url": "https://medium.com/walmartglobaltech/deep-learning-demystified-693a2d7ec79e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/walmartglobaltech/deep-<b>learning</b>-demystified-693a2d7ec79e", "snippet": "What it says is that a <b>deep model can be thought of as</b> a function N, parameterized by \u03b8, that given the input data d, ... <b>Learning</b> <b>Machine</b> <b>Learning</b> \u2014 Part 4: Neural Network Theory. Ryan ...", "dateLastCrawled": "2022-01-04T10:16:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(deep model)  is like +(black box)", "+(deep model) is similar to +(black box)", "+(deep model) can be thought of as +(black box)", "+(deep model) can be compared to +(black box)", "machine learning +(deep model AND analogy)", "machine learning +(\"deep model is like\")", "machine learning +(\"deep model is similar\")", "machine learning +(\"just as deep model\")", "machine learning +(\"deep model can be thought of as\")", "machine learning +(\"deep model can be compared to\")"]}