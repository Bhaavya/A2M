{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Evaluation</b> of <b>Text Generation</b>: A Survey | DeepAI", "url": "https://deepai.org/publication/evaluation-of-text-generation-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>evaluation</b>-of-<b>text-generation</b>-a-survey", "snippet": "The <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>bleu</b>) is one of the first metrics used to measure the similarity between <b>two</b> sentences (Papineni et al., 2002). Originally proposed for machine translation, it compares a candidate translation of text to one or more reference translations. <b>bleu</b>. is a weighted geometric mean of . n-gram precision scores ...", "dateLastCrawled": "2022-02-03T15:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Evaluation</b> <b>of English\u2013Slovak Neural and Statistical Machine</b> ...", "url": "https://www.researchgate.net/publication/350393331_Evaluation_of_English-Slovak_Neural_and_Statistical_Machine_Translation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350393331_<b>Evaluation</b>_of_English-Slovak_Neural...", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) [14], which is used in our research, is a geometric mean of n-gram prec isions ( \ud835\udc5d = \ud835\udc34 / \ud835\udc35 ), and the second pa rt is a brevity", "dateLastCrawled": "2022-01-20T21:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What are <b>the benefits/disadvantages associated with word</b> error rate ...", "url": "https://www.quora.com/What-are-the-benefits-disadvantages-associated-with-word-error-rate-WER-compared-to-the-BLEU-bilingual-evaluation-understudy-metric", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>the-benefits-disadvantages-associated-with-word</b>-error...", "snippet": "Answer: WER tends to predicate a raw metric of how many updates must be performed - in terms of deletion, editing, etc. Where as of <b>BLEU</b> tends to measure the translation strength - in comparison to what would be judged as being \u201cfavored by people\u201d. However - I think both of them run into distin...", "dateLastCrawled": "2022-01-21T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Hierarchy Parsing for Image Captioning | Request PDF", "url": "https://www.researchgate.net/publication/339555503_Hierarchy_Parsing_for_Image_Captioning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339555503_Hierarchy_Parsing_for_Image_Captioning", "snippet": "While <b>BLEU</b>, which stands for <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> and has been used by various researchers [15,73, 74] and is generally a text quality assessment algorithm that assesses the quality of ...", "dateLastCrawled": "2022-02-01T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Analysis <b>of human versus machine translation accuracy</b> \u2013 TRANSLATOLOGIA", "url": "http://www.translatologia.ukf.sk/2017/01/analysis-of-human-versus-machine-translation-accuracy/", "isFamilyFriendly": true, "displayUrl": "www.translatologia.ukf.sk/2017/01/analysis-<b>of-human-versus-machine-translation-accuracy</b>", "snippet": "Using reliable, objective, and consistent methods such as <b>BLEU</b> (<b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>) and NIST (National Institute of Standards and Technology), they translated text from 13 <b>languages</b> into English. The domain consisted of a large corpus of legal texts of importance to law librarians and law library users. Users with MT tool experience were able to identify limitations of MT, which was generally not able to identify language exceptions and ambiguities (for example lexical ambiguity ...", "dateLastCrawled": "2021-12-06T15:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "DELPH-IN", "url": "http://svn.delph-in.net/odc/trunk/wescience/A/unsegmented.txt", "isFamilyFriendly": true, "displayUrl": "svn.delph-in.net/odc/trunk/wescience/A/unsegmented.txt", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) is a method for <b>evaluating</b> the quality of text which has been translated from one natural language to another using machine translation. <b>BLEU</b> was one of the first software metrics to report high correlation with human judgements of quality. The metric is currently one of the most popular in the field. The central idea behind the metric is that, &quot;the closer a machine translation is to a professional human translation, the better it is&quot;. The metric ...", "dateLastCrawled": "2021-12-28T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "DELPH-IN", "url": "http://svn.delph-in.net/odc/trunk/wescience/pre-AB.txt", "isFamilyFriendly": true, "displayUrl": "svn.delph-in.net/odc/trunk/wescience/pre-AB.txt", "snippet": "<b>BLEU</b>:&#39;&#39;This page is about the <b>evaluation</b> metric for machine translation. For other meanings, please see [[<b>Bleu</b>]].&#39;&#39; &#39;&#39;&#39;<b>BLEU</b>&#39;&#39;&#39; (&#39;&#39;&#39;<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>&#39;&#39;&#39;) is a method for <b>evaluating</b> the quality of text which has been translated from one [[natural language]] to another using [[machine translation]]. <b>BLEU</b> was one of the first [[software metric]]s to report high [[correlation]] with human judgements of quality. The metric is currently one of the most popular in the field. The ...", "dateLastCrawled": "2022-01-29T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Survey of <b>Evaluation</b> Metrics Used for NLG Systems \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2008.12009/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2008.12009", "snippet": "For example, for <b>evaluating</b> a translation system one could use <b>bilingual</b> experts (expensive) or even monolingual experts (relatively less expensive). The monolingual experts could just compare the output to an available reference output whereas with <b>bilingual</b> experts such a reference output is not needed. Further, <b>a bilingual</b> expert will be able to better evaluate where the nuances in the source language are accurately captured in the target language. If the speed of <b>evaluation</b> is the ...", "dateLastCrawled": "2021-10-08T04:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Statistical machine translation : textbook</b> - PDF Free Download", "url": "https://epdf.pub/statistical-machine-translation-textbook.html", "isFamilyFriendly": true, "displayUrl": "https://epdf.pub/<b>statistical-machine-translation-textbook</b>.html", "snippet": "Since <b>bilingual</b> speakers are much harder to come by than monolingual speakers, this reduces the cost of correcting the output. One may also imagine a scenario in which a monolingual posteditor fixes the mistakes in <b>fluency</b> of the English output and a second <b>bilingual</b> post-editor fixes the mistakes in meaning. Note that if the monolingual post-editor knows something about the subject matter of the text, he will catch many mistakes in meaning already. Post-editing 1.3.6 Tools for Translators ...", "dateLastCrawled": "2021-12-08T05:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "BibTeX bibliography tallip.bib", "url": "http://ftp.math.utah.edu/pub/tex/bib/tallip.html", "isFamilyFriendly": true, "displayUrl": "ftp.math.utah.edu/pub/tex/bib/tallip.html", "snippet": "Using a third language to link <b>two</b> other <b>languages</b> is a well-known solution and usually requires only <b>two</b> input <b>bilingual</b> dictionaries A-B and B-C to automatically induce the new one, A-C. This approach, however, has never been demonstrated to utilize the complete structures of the input <b>bilingual</b> dictionaries, and this is a key failing because the dropped meanings negatively influence the result. This article proposes a constraint approach to pivot-based dictionary induction where language ...", "dateLastCrawled": "2021-09-17T22:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Evaluation</b> of <b>Text Generation</b>: A Survey | DeepAI", "url": "https://deepai.org/publication/evaluation-of-text-generation-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>evaluation</b>-of-<b>text-generation</b>-a-survey", "snippet": "The <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>bleu</b>) is one of the first metrics used to measure the similarity between <b>two</b> sentences (Papineni et al., 2002). Originally proposed for machine translation, it compares a candidate translation of text to one or more reference translations. <b>bleu</b>. is a weighted geometric mean of . n-gram precision scores ...", "dateLastCrawled": "2022-02-03T15:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Evaluation</b> <b>of English\u2013Slovak Neural and Statistical Machine</b> ...", "url": "https://www.researchgate.net/publication/350393331_Evaluation_of_English-Slovak_Neural_and_Statistical_Machine_Translation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350393331_<b>Evaluation</b>_of_English-Slovak_Neural...", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) [14], which is used in our research, is a geometric mean of n-gram prec isions ( \ud835\udc5d = \ud835\udc34 / \ud835\udc35 ), and the second pa rt is a brevity", "dateLastCrawled": "2022-01-20T21:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What are <b>the benefits/disadvantages associated with word</b> error rate ...", "url": "https://www.quora.com/What-are-the-benefits-disadvantages-associated-with-word-error-rate-WER-compared-to-the-BLEU-bilingual-evaluation-understudy-metric", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>the-benefits-disadvantages-associated-with-word</b>-error...", "snippet": "Answer: WER tends to predicate a raw metric of how many updates must be performed - in terms of deletion, editing, etc. Where as of <b>BLEU</b> tends to measure the translation strength - in comparison to what would be judged as being \u201cfavored by people\u201d. However - I think both of them run into distin...", "dateLastCrawled": "2022-01-21T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Neural Wikipedian: Generating Textual Summaries from Knowledge</b> Base ...", "url": "https://www.sciencedirect.com/science/article/pii/S1570826818300313", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1570826818300313", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) is precision-oriented metric for measuring the quality of generated text by comparing it to the actual, empirical text. <b>BLEU</b>-n calculates a similarity scores based on the co-occurrence of up to n-grams (i.e. 1-grams, \u2026, n-grams) in the generated and the actual text. 15", "dateLastCrawled": "2021-11-03T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Hierarchy Parsing for Image Captioning | Request PDF", "url": "https://www.researchgate.net/publication/339555503_Hierarchy_Parsing_for_Image_Captioning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339555503_Hierarchy_Parsing_for_Image_Captioning", "snippet": "While <b>BLEU</b>, which stands for <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> and has been used by various researchers [15,73, 74] and is generally a text quality assessment algorithm that assesses the quality of ...", "dateLastCrawled": "2022-02-01T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Unsupervised <b>Evaluation</b> of Human Translation Quality", "url": "https://danushka.net/papers/kdir_zhou.pdf", "isFamilyFriendly": true, "displayUrl": "https://danushka.net/papers/kdir_zhou.pdf", "snippet": "gual <b>evaluation</b> <b>understudy</b> (<b>BLEU</b>) method to automatically evaluate the quality of MT. They take professional HTs as golden references and consider a better MT should be the one closer to the golden HTs. In contrast, HTs quality <b>evalua-tion</b> must be done manually because such golden references are not available. People who are fa-miliar with both the source and the target <b>lan-guages</b> are required to evaluate the quality of HTs. The number of such <b>bilingual</b> speakers are limited and might not ...", "dateLastCrawled": "2021-06-26T21:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Analysis <b>of human versus machine translation accuracy</b> \u2013 TRANSLATOLOGIA", "url": "http://www.translatologia.ukf.sk/2017/01/analysis-of-human-versus-machine-translation-accuracy/", "isFamilyFriendly": true, "displayUrl": "www.translatologia.ukf.sk/2017/01/analysis-<b>of-human-versus-machine-translation-accuracy</b>", "snippet": "Using reliable, objective, and consistent methods such as <b>BLEU</b> (<b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>) and NIST (National Institute of Standards and Technology), they translated text from 13 <b>languages</b> into English. The domain consisted of a large corpus of legal texts of importance to law librarians and law library users. Users with MT tool experience were able to identify limitations of MT, which was generally not able to identify language exceptions and ambiguities (for example lexical ambiguity ...", "dateLastCrawled": "2021-12-06T15:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Survey of <b>Evaluation</b> Metrics Used for NLG Systems \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2008.12009/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2008.12009", "snippet": "For example, for <b>evaluating</b> a translation system one could use <b>bilingual</b> experts (expensive) or even monolingual experts (relatively less expensive). The monolingual experts could just compare the output to an available reference output whereas with <b>bilingual</b> experts such a reference output is not needed. Further, <b>a bilingual</b> expert will be able to better evaluate where the nuances in the source language are accurately captured in the target language. If the speed of <b>evaluation</b> is the ...", "dateLastCrawled": "2021-10-08T04:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Cognitive_Effort_in_Post-Editing</b>_of_Mach1.pdf | Qualitative Research ...", "url": "https://www.scribd.com/document/407270799/Cognitive-Effort-in-Post-Editing-of-Mach1-pdf", "isFamilyFriendly": true, "displayUrl": "https://www.<b>scribd</b>.com/document/407270799/<b>Cognitive-Effort-in-Post-Editing</b>-of-Mach1-pdf", "snippet": "<b>Scribd</b> is the world&#39;s largest social reading and publishing site.", "dateLastCrawled": "2021-12-22T20:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "BibTeX bibliography tallip.bib", "url": "http://ftp.math.utah.edu/pub/tex/bib/tallip.html", "isFamilyFriendly": true, "displayUrl": "ftp.math.utah.edu/pub/tex/bib/tallip.html", "snippet": "Using a third language to link <b>two</b> other <b>languages</b> is a well-known solution and usually requires only <b>two</b> input <b>bilingual</b> dictionaries A-B and B-C to automatically induce the new one, A-C. This approach, however, has never been demonstrated to utilize the complete structures of the input <b>bilingual</b> dictionaries, and this is a key failing because the dropped meanings negatively influence the result. This article proposes a constraint approach to pivot-based dictionary induction where language ...", "dateLastCrawled": "2021-09-17T22:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Evaluation</b> of <b>Text Generation</b>: A Survey | DeepAI", "url": "https://deepai.org/publication/evaluation-of-text-generation-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>evaluation</b>-of-<b>text-generation</b>-a-survey", "snippet": "The <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>bleu</b>) is one of the first metrics used to measure the similarity between <b>two</b> sentences (Papineni et al., 2002). Originally proposed for machine translation, it compares a candidate translation of text to one or more reference translations. <b>bleu</b>. is a weighted geometric mean of . n-gram precision scores ...", "dateLastCrawled": "2022-02-03T15:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What are <b>the benefits/disadvantages associated with word</b> error rate ...", "url": "https://www.quora.com/What-are-the-benefits-disadvantages-associated-with-word-error-rate-WER-compared-to-the-BLEU-bilingual-evaluation-understudy-metric", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>the-benefits-disadvantages-associated-with-word</b>-error...", "snippet": "Answer: WER tends to predicate a raw metric of how many updates must be performed - in terms of deletion, editing, etc. Where as of <b>BLEU</b> tends to measure the translation strength - in comparison to what would be judged as being \u201cfavored by people\u201d. However - I think both of them run into distin...", "dateLastCrawled": "2022-01-21T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Survey of <b>Evaluation</b> Metrics Used for NLG Systems \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2008.12009/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2008.12009", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (Papineni et al., 2002)): This was the among the first and most popular metrics proposed for automatic <b>evaluation</b> of MT systems. It is a precision-based metric that computes the n -gram overlap between the reference and the hypothesis.", "dateLastCrawled": "2021-10-08T04:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Image Captioning via Hierarchical Attention Mechanism and Policy</b> ...", "url": "https://www.researchgate.net/publication/336244653_Image_Captioning_via_Hierarchical_Attention_Mechanism_and_Policy_Gradient_Optimization", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/336244653_Image_Captioning_via_Hierarchical...", "snippet": "While <b>BLEU</b>, which stands for <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> and has been used by various researchers [15, 73, 74] and is generally a text quality assessment algorithm that assesses the quality of ...", "dateLastCrawled": "2021-10-18T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Translation Evaluation and Optimization</b> | Request PDF", "url": "https://www.researchgate.net/publication/234194809_Machine_Translation_Evaluation_and_Optimization", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/234194809_Machine_Translation_<b>Evaluation</b>_and...", "snippet": "We compare the results of 124 human evaluations of machine trans-lated sentences to the scores generated by <b>two</b> automatic <b>evaluation</b> metrics (<b>BLEU</b> and NIST). When datasets are held constant or ...", "dateLastCrawled": "2021-12-23T20:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "DELPH-IN", "url": "http://svn.delph-in.net/odc/trunk/wescience/pre-AB.txt", "isFamilyFriendly": true, "displayUrl": "svn.delph-in.net/odc/trunk/wescience/pre-AB.txt", "snippet": "<b>BLEU</b>:&#39;&#39;This page is about the <b>evaluation</b> metric for machine translation. For other meanings, please see [[<b>Bleu</b>]].&#39;&#39; &#39;&#39;&#39;<b>BLEU</b>&#39;&#39;&#39; (&#39;&#39;&#39;<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>&#39;&#39;&#39;) is a method for <b>evaluating</b> the quality of text which has been translated from one [[natural language]] to another using [[machine translation]]. <b>BLEU</b> was one of the first [[software metric]]s to report high [[correlation]] with human judgements of quality. The metric is currently one of the most popular in the field. The ...", "dateLastCrawled": "2022-01-29T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Translation Quality Assessment: Joss Moorkens Sheila Castilho Federico ...", "url": "https://www.scribd.com/document/535235279/3-Machine-Translation-Technologies-and-Applications-1-Joss-Moorkens-Sheila-Castilho-Federico-Gaspari-Stephen-Doherty-Translation-Quality-Asses", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/535235279/3-Machine-Translation-Technologies-and...", "snippet": "The assessment of adequacy requires some degree of <b>bilingual</b> proficiency, while \u2013 at least in principle \u2013 <b>fluency</b> requires only proficiency in the target-language; both professional and amateur evaluators <b>can</b> be employed in TQA tasks adopting this double integrated approach (see Sect. 3.6 for a more detailed discussion of the key issues concerning evaluators).", "dateLastCrawled": "2022-01-30T00:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Investigating the Effects of Controlled</b> Language on the Reading ...", "url": "https://www.academia.edu/4646058/Investigating_the_Effects_of_Controlled_Language_on_the_Reading_and_Comprehension_of_Machine_Translated_Texts_A_Mixed_Methods_Approach", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/4646058/<b>Investigating_the_Effects_of_Controlled</b>_Language_on...", "snippet": "<b>Investigating the Effects of Controlled</b> Language on the Reading <b>and Comprehension of Machine Translated Texts</b>: A Mixed-Methods Approach", "dateLastCrawled": "2021-12-31T04:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "6th International Conference on ICTCS 2021 &amp; SMARTCOM ... - ictcs.sched.com", "url": "https://ictcs.sched.com/list/descriptions/", "isFamilyFriendly": true, "displayUrl": "https://ictcs.sched.com/list/descriptions", "snippet": "Professor and Head of Department, Computer Engineering in Sinhgad Institute of Technology and Science, India. Professor and Head of Department, Computer Engineering in Sinhgad Institute of Technology and Science, Pune. Saturday December 18, 2021 2:41pm - 2:50pm IST. Virtual Room C Jaipur, India.", "dateLastCrawled": "2022-01-27T02:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Cognitive_Effort_in_Post-Editing</b>_of_Mach1.pdf | Qualitative Research ...", "url": "https://www.scribd.com/document/407270799/Cognitive-Effort-in-Post-Editing-of-Mach1-pdf", "isFamilyFriendly": true, "displayUrl": "https://www.<b>scribd</b>.com/document/407270799/<b>Cognitive-Effort-in-Post-Editing</b>-of-Mach1-pdf", "snippet": "<b>Scribd</b> is the world&#39;s largest social reading and publishing site.", "dateLastCrawled": "2021-12-22T20:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Evaluation</b> of <b>Text Generation</b>: A Survey | DeepAI", "url": "https://deepai.org/publication/evaluation-of-text-generation-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>evaluation</b>-of-<b>text-generation</b>-a-survey", "snippet": "The <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>bleu</b>) is one of the first metrics used to measure the similarity between <b>two</b> sentences (Papineni et al., 2002). Originally proposed for machine translation, it compares a candidate translation of text to one or more reference translations. <b>bleu</b>. is a weighted geometric mean of . n-gram precision scores ...", "dateLastCrawled": "2022-02-03T15:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What are <b>the benefits/disadvantages associated with word</b> error rate ...", "url": "https://www.quora.com/What-are-the-benefits-disadvantages-associated-with-word-error-rate-WER-compared-to-the-BLEU-bilingual-evaluation-understudy-metric", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>the-benefits-disadvantages-associated-with-word</b>-error...", "snippet": "Answer: WER tends to predicate a raw metric of how many updates must be performed - in terms of deletion, editing, etc. Where as of <b>BLEU</b> tends to measure the translation strength - in comparison to what would be judged as being \u201cfavored by people\u201d. However - I think both of them run into distin...", "dateLastCrawled": "2022-01-21T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Evaluation</b> <b>of English\u2013Slovak Neural and Statistical Machine</b> ...", "url": "https://www.researchgate.net/publication/350393331_Evaluation_of_English-Slovak_Neural_and_Statistical_Machine_Translation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350393331_<b>Evaluation</b>_of_English-Slovak_Neural...", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) [14], which is used in our research, is a geometric mean of n-gram prec isions ( \ud835\udc5d = \ud835\udc34 / \ud835\udc35 ), and the second pa rt is a brevity", "dateLastCrawled": "2022-01-20T21:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Hierarchy Parsing for Image Captioning | Request PDF", "url": "https://www.researchgate.net/publication/339555503_Hierarchy_Parsing_for_Image_Captioning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339555503_Hierarchy_Parsing_for_Image_Captioning", "snippet": "While <b>BLEU</b>, which stands for <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> and has been used by various researchers [15,73, 74] and is generally a text quality assessment algorithm that assesses the quality of ...", "dateLastCrawled": "2022-02-01T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Neural Wikipedian: Generating Textual Summaries from Knowledge</b> Base ...", "url": "https://www.sciencedirect.com/science/article/pii/S1570826818300313", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1570826818300313", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) is precision-oriented metric for measuring the quality of generated text by comparing it to the actual, empirical text. <b>BLEU</b>-n calculates a similarity scores based on the co-occurrence of up to n-grams (i.e. 1-grams, \u2026, n-grams) in the generated and the actual text. 15", "dateLastCrawled": "2021-11-03T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Analysis <b>of human versus machine translation accuracy</b> \u2013 TRANSLATOLOGIA", "url": "http://www.translatologia.ukf.sk/2017/01/analysis-of-human-versus-machine-translation-accuracy/", "isFamilyFriendly": true, "displayUrl": "www.translatologia.ukf.sk/2017/01/analysis-<b>of-human-versus-machine-translation-accuracy</b>", "snippet": "Using reliable, objective, and consistent methods such as <b>BLEU</b> (<b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>) and NIST (National Institute of Standards and Technology), they translated text from 13 <b>languages</b> into English. The domain consisted of a large corpus of legal texts of importance to law librarians and law library users. Users with MT tool experience were able to identify limitations of MT, which was generally not able to identify language exceptions and ambiguities (for example lexical ambiguity ...", "dateLastCrawled": "2021-12-06T15:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Translation Quality Assessment: Joss Moorkens Sheila Castilho Federico ...", "url": "https://www.scribd.com/document/535235279/3-Machine-Translation-Technologies-and-Applications-1-Joss-Moorkens-Sheila-Castilho-Federico-Gaspari-Stephen-Doherty-Translation-Quality-Asses", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/535235279/3-Machine-Translation-Technologies-and...", "snippet": "The assessment of adequacy requires some degree of <b>bilingual</b> proficiency, while \u2013 at least in principle \u2013 <b>fluency</b> requires only proficiency in the target-language; both professional and amateur evaluators <b>can</b> be employed in TQA tasks adopting this double integrated approach (see Sect. 3.6 for a more detailed discussion of the key issues concerning evaluators).", "dateLastCrawled": "2022-01-30T00:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Unsupervised <b>Evaluation</b> of Human Translation Quality", "url": "https://danushka.net/papers/kdir_zhou.pdf", "isFamilyFriendly": true, "displayUrl": "https://danushka.net/papers/kdir_zhou.pdf", "snippet": "A <b>person\u2019s</b> first language, L1, refers to the native language of that person, whereas L2 is a second language spoken by that person. HTs created by L2 speakers <b>can</b> be erroneous due to the different levels of experiences and knowledge of the trans-lators. Often, the quality of translations provided by L2 speakers must be manually verified by pro-fessional translators before they <b>can</b> be accepted. A good translation must demonstrate six prop-erties: intelligibility, fidelity, <b>fluency</b>, adequacy ...", "dateLastCrawled": "2021-06-26T21:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Survey of <b>Evaluation</b> Metrics Used for NLG Systems \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2008.12009/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2008.12009", "snippet": "For instance, <b>evaluating</b> <b>fluency</b> (grammatical correctness) of the generated sentence does not require a reference output. References are helpful when the <b>evaluation</b> criteria <b>can</b> be reduced to a problem of comparing the similarity of information contained in the <b>two</b> texts. For example, in most cases, a generated translation <b>can</b> be evaluated for ...", "dateLastCrawled": "2021-10-08T04:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "6th International Conference on ICTCS 2021 &amp; SMARTCOM ... - ictcs.sched.com", "url": "https://ictcs.sched.com/list/descriptions/", "isFamilyFriendly": true, "displayUrl": "https://ictcs.sched.com/list/descriptions", "snippet": "Professor and Head of Department, Computer Engineering in Sinhgad Institute of Technology and Science, India. Professor and Head of Department, Computer Engineering in Sinhgad Institute of Technology and Science, Pune. Saturday December 18, 2021 2:41pm - 2:50pm IST. Virtual Room C Jaipur, India.", "dateLastCrawled": "2022-01-27T02:34:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> Glossary: Language <b>Evaluation</b> | Google Developers", "url": "https://developers.google.com/machine-learning/glossary/language", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/glossary/language", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) #language. A score between 0.0 and 1.0, inclusive, indicating the quality of a translation between two human languages (for example, between English and Russian). A <b>BLEU</b> score of 1.0 indicates a perfect translation; a <b>BLEU</b> score of 0.0 indicates a terrible translation. C. causal language model. #language. Synonym for unidirectional language model. See bidirectional language model to contrast different directional approaches in language modeling. crash ...", "dateLastCrawled": "2022-01-29T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Evaluation</b> of an <b>NLP</b> model \u2014 latest benchmarks | by Ria Kulshrestha ...", "url": "https://towardsdatascience.com/evaluation-of-an-nlp-model-latest-benchmarks-90fd8ce6fae5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>evaluation</b>-of-an-<b>nlp</b>-model-latest-benchmarks-90fd8ce6fae5", "snippet": "<b>BLEU</b> Score \u2014 <b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>. As the name suggests, it was originally used to evaluate translations from one language to another. How to calculate <b>BLEU</b> score? Calculating unigram precision: Step 1: Look at each word in the output sentence and assign it a score of 1 if it shows up in any of the reference sentences and 0 if it doesn\u2019t. Step 2: Normalize that count, so that it\u2019s always between 0 and 1, by dividing the number of words that showed up in one of the reference ...", "dateLastCrawled": "2022-01-28T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Natrual language processing basic concepts - language model - word ...", "url": "https://shuffleai.blog/blog/nlp_concepts_part_1.html", "isFamilyFriendly": true, "displayUrl": "https://shuffleai.blog/blog/nlp_concepts_part_1.html", "snippet": "<b>BLEU</b> stands for <b>bilingual</b> <b>evaluation</b> <b>understudy</b>. It&#39;s an automatic metric to evaluate how close a sequence of text generated by a language model is to a reference. At first, it&#39;s used to evaluate the quality of <b>machine</b> translation text. Now other natural language processing tasks such as task-oriented dialogue generation adopt it as well. For a reference &quot;The man returned to the store&quot;, a generated text &quot;the the man the&quot; would get a BLUE score as below. For each word in the generated text ...", "dateLastCrawled": "2021-12-24T07:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Sequence Models - Deep <b>Learning</b> Specialization 5 - Yuet&#39;s Blog", "url": "https://yestinyang.github.io/2018/02/19/DLS-5-Sequence-Models.html", "isFamilyFriendly": true, "displayUrl": "https://yestinyang.github.io/2018/02/19/DLS-5-Sequence-Models.html", "snippet": "<b>Bleu</b> Score: <b>bilingual</b> <b>evaluation</b> <b>understudy</b>. Evaluate \u2018accuracy\u2019 of a model predicting multiply equally good answers, being a substitute for human evaluating each output Attention Model. Counter the problem of long sentence, which requires the ability of memory but not badly need a NN to do this kind of job. Instead of \u2018remembering\u2019 the ...", "dateLastCrawled": "2022-01-22T18:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) pathak2019.pdf | Aditya Kumar Pathak and Priyankit Acharya ...", "url": "https://www.academia.edu/38228943/pathak2019_pdf", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/38228943/pathak2019_pdf", "snippet": "The standard metric people are using for <b>evaluation</b> of MT systems is <b>BLEU</b> score.<b>Bilingual</b> <b>evaluation</b> <b>understudy</b> (<b>BLEU</b>) is the algorithm to determine the quality of text translated by a <b>machine</b> translation. Quality is the comparison between <b>machine</b>-translated output to that of human-generated output; the closer <b>machine</b> translation is to human-generated translation, the better is the <b>BLEU</b> score. <b>BLEU</b> score is a n-gram overlap of <b>machine</b> translation to that of reference translation.<b>BLEU</b> \u00bc min ...", "dateLastCrawled": "2021-02-16T17:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The <b>Computational</b> Limits of Deep <b>Learning</b> | DeepAI", "url": "https://deepai.org/publication/the-computational-limits-of-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/the-<b>computational</b>-limits-of-deep-<b>learning</b>", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) [papineni2002bleu] score is a metric for translation and computes the similarity between human translation and <b>machine</b> translation based on n-gram. An n-gram is a continuous sequence of n items from a given text. The score is based on precision, brevity penalty, and clipping. The modified n-gram precision ...", "dateLastCrawled": "2022-01-28T07:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "9.7. <b>Sequence</b> to <b>Sequence</b> <b>Learning</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 ...", "url": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>), though originally proposed for evaluating <b>machine</b> translation results [Papineni et al., 2002], has been extensively used in measuring the quality of output sequences for different applications.", "dateLastCrawled": "2022-01-26T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Arti cial Intelligence Master Thesis", "url": "https://upcommons.upc.edu/bitstream/handle/2117/105513/122533.pdf?sequence=1", "isFamilyFriendly": true, "displayUrl": "https://upcommons.upc.edu/bitstream/handle/2117/105513/122533.pdf?sequence=1", "snippet": "2:87 <b>BLEU</b> (<b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>) score over the baseline; attention model, for German-English translation, and 0:34 <b>BLEU</b> score improvement for Catalan-Spanish trans-lation. Keywords <b>Machine</b> <b>Learning</b>, Deep <b>Learning</b>, Natural Language Processing, Neural <b>Machine</b> Transla-tion", "dateLastCrawled": "2021-12-27T01:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>The Evolution of Machine Translation</b> | LLM Law Review", "url": "https://www.llmlawreview.com/2018/01/26/the-evolution-of-machine-translation/", "isFamilyFriendly": true, "displayUrl": "https://www.llmlawreview.com/2018/01/26/<b>the-evolution-of-machine-translation</b>", "snippet": "Using the <b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) method to score the outcome, they found that NMT scored consistently higher than PBSMT for accuracy. In addition, human translators whose native language was Catalan but who were also fluent in English, evaluated sections of the MT translation in three of the books. Once again, the NMT outperformed its rival. It was estimated that \u201cbetween 17% and 34% of the translations \u2026 are perceived by native speakers of the target language to be of ...", "dateLastCrawled": "2022-01-19T23:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Evaluation of machine translation systems and related procedures</b>", "url": "https://www.researchgate.net/publication/326320090_Evaluation_of_machine_translation_systems_and_related_procedures", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/326320090_<b>Evaluation</b>_of_<b>machine</b>_translation...", "snippet": "<b>Evaluation of machine translation systems and related procedures</b>. June 2018 ; Journal of Engineering and Applied Sciences 13(12):3961-3972; Project: <b>Machine</b> <b>learning</b>; Authors: Musatafa Albadr ...", "dateLastCrawled": "2022-01-15T04:04:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bleu (bilingual evaluation understudy))  is like +(evaluating a bilingual person's fluency in two languages)", "+(bleu (bilingual evaluation understudy)) is similar to +(evaluating a bilingual person's fluency in two languages)", "+(bleu (bilingual evaluation understudy)) can be thought of as +(evaluating a bilingual person's fluency in two languages)", "+(bleu (bilingual evaluation understudy)) can be compared to +(evaluating a bilingual person's fluency in two languages)", "machine learning +(bleu (bilingual evaluation understudy) AND analogy)", "machine learning +(\"bleu (bilingual evaluation understudy) is like\")", "machine learning +(\"bleu (bilingual evaluation understudy) is similar\")", "machine learning +(\"just as bleu (bilingual evaluation understudy)\")", "machine learning +(\"bleu (bilingual evaluation understudy) can be thought of as\")", "machine learning +(\"bleu (bilingual evaluation understudy) can be compared to\")"]}