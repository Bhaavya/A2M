{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Mitigating <b>implicit bias in machine learning</b>", "url": "https://faraday.ai/blog/implicit-bias-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://faraday.ai/blog/<b>implicit</b>-<b>bias</b>-<b>machine</b>-<b>learning</b>", "snippet": "How to minimize the effects of <b>implicit bias in machine learning</b>, from data sourcing to model predictions. An <b>algorithm</b> contains the biases of its builder. At Faraday, we have a handful of approaches we use to minimize these effects at each level of our <b>machine</b> <b>learning</b> pipeline. Blog. \u2261 20 Oct 2020 \u2022 3 min read The weighted scale: Mitigating <b>implicit</b> <b>bias</b> in data science. An <b>algorithm</b> contains the biases of its builder. At Faraday, we have a handful of approaches we use to minimize ...", "dateLastCrawled": "2021-12-24T05:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias</b> in <b>Machine</b> <b>Learning</b> Algorithms | by Foxh0und | Medium", "url": "https://foxh0und.medium.com/bias-in-machine-learning-algorithms-4d70bb1bcf15", "isFamilyFriendly": true, "displayUrl": "https://foxh0und.medium.com/<b>bias</b>-in-<b>machine</b>-<b>learning</b>-<b>algorithms</b>-4d70bb1bcf15", "snippet": "For example, a <b>machine</b> <b>learning</b> <b>algorithm</b> might be used by a credit reporting agency to decide whether a consumer\u2019s application for credit is approved or declined. The consumer\u2019s application is declined and that decision is fed back into the model, further reducing the consumer\u2019s chances of successfully applying for credit in future and compounding the problem. Where the input data are implicitly biased, the model will reinforce the <b>bias</b> that is present in the data, as demonstrated by ...", "dateLastCrawled": "2022-01-14T14:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Understanding Racial Bias in Machine Learning Algorithms</b> | by The ...", "url": "https://betterprogramming.pub/understanding-racial-bias-in-machine-learning-algorithms-1c5afe76f8b", "isFamilyFriendly": true, "displayUrl": "https://betterprogramming.pub/<b>understanding-racial-bias-in-machine-learning-algorithms</b>...", "snippet": "<b>Implicit</b> <b>bias</b> refers to the attitudes, beliefs, and stereotypes that we hold about groups of people. Biases impact how we treat and respond to others, even involuntarily. <b>Implicit</b> <b>bias</b> is pervasive in the tech industry \u2014 in hiring practices, but also in the products and technologies that well-intentioned developers create. In particular, researchers identify <b>machine</b> <b>learning</b> and artificial intelligence as technologies that suffer from <b>implicit</b> racial biases. If software development is ...", "dateLastCrawled": "2022-01-25T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "Often <b>machine</b> <b>learning</b> programs inherit social patterns reflected in their training data without any directed effort by programmers to include such biases. Computer scientists call this algorithmic <b>bias</b>. This paper explores the relationship between <b>machine</b> <b>bias</b> and human cognitive <b>bias</b>. In it, I argue similarities between algorithmic and cognitive biases indicate a disconcerting sense in which sources of <b>bias</b> emerge out of seemingly innocuous patterns of information processing. The emergent ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Dangers of Human-<b>Like</b> <b>Bias</b> in <b>Machine</b>-<b>Learning</b> Algorithms", "url": "https://scholarsmine.mst.edu/cgi/viewcontent.cgi?article=1030&context=peer2peer", "isFamilyFriendly": true, "displayUrl": "https://scholarsmine.mst.edu/cgi/viewcontent.cgi?article=1030&amp;context=peer2peer", "snippet": "<b>algorithm</b> how to solve a problem (Osaba and Welser 2017). This particular style of training, ... <b>implicit</b> <b>bias</b>. It can be very difficult, then, to predict all the possible associations an MLAG could learn from a given set of training data. Even if a hidden <b>bias</b> can be identified, it might be impractical or impossible to directly correct that set of training data. However, using purely statistical MLAGs as a method for revealing hidden biases in training data can reveal a need for a new set ...", "dateLastCrawled": "2021-12-22T20:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Research shows AI is often biased. Here&#39;s how to make algorithms work ...", "url": "https://www.weforum.org/agenda/2021/07/ai-machine-learning-bias-discrimination/", "isFamilyFriendly": true, "displayUrl": "https://www.weforum.org/agenda/2021/07/ai-<b>machine</b>-<b>learning</b>-<b>bias</b>-discrimination", "snippet": "Ridding AI and <b>machine</b> <b>learning</b> of <b>bias</b> involves taking their many uses into consideration ... these include: <b>implicit</b> <b>bias</b>, sampling <b>bias</b>, temporal <b>bias</b>, over-fitting to training data, and edge cases and outliers. <b>Implicit</b> <b>bias</b> <b>Implicit</b> <b>bias</b> is discrimination or prejudice against a person or group that is unconscious to the person with the <b>bias</b>. It is dangerous because the person is unaware of the <b>bias</b> \u2013 whether it be on grounds of gender, race, disability, sexuality or class. Sampling ...", "dateLastCrawled": "2022-01-31T15:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Potential Biases in <b>Machine</b> <b>Learning</b> Algorithms Using Electronic Health ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6347576/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6347576", "snippet": "A promise of <b>machine</b> <b>learning</b> in health care is the avoidance of biases in diagnosis and treatment; a computer <b>algorithm</b> could objectively synthesize and interpret the data in the medical record. Integration of <b>machine</b> <b>learning</b> with clinical decision support tools, such as computerized alerts or diagnostic support, may offer physicians and others who provide health care targeted and timely information that can improve clinical decisions. <b>Machine</b> <b>learning</b> algorithms, however, may also be ...", "dateLastCrawled": "2022-01-27T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Bias in Natural Language Processing (NLP): A Dangerous</b> But Fixable ...", "url": "https://towardsdatascience.com/bias-in-natural-language-processing-nlp-a-dangerous-but-fixable-problem-7d01a12cf0f7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bias-in-natural-language-processing-nlp-a-dangerous</b>-but...", "snippet": "What is <b>bias</b> in <b>machine</b> <b>learning</b> models? Essentially, it\u2019s when <b>machine</b> <b>learning</b> algorithms express <b>implicit</b> biases that often pass undetected during testing because most papers test their models for raw accuracy. Take, for example, the following instances of deep <b>learning</b> models expressing gender <b>bias</b>. According to our deep <b>learning</b> models, \u201cHe is doctor\u201d has a higher likelihood than \u201cShe is doctor.\u201d Man is to woman as computer programmer is to homemaker. Sentences with female ...", "dateLastCrawled": "2022-02-02T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Amazon scraps secret AI recruiting tool that showed <b>bias</b> against women ...", "url": "https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reuters.com</b>/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G", "snippet": "<b>Machine</b> <b>learning</b> was gaining traction in the technology world, thanks to a surge in low-cost computing power. And Amazon\u2019s Human Resources department was about to embark on a hiring spree: Since ...", "dateLastCrawled": "2022-02-02T22:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "Often <b>machine</b> <b>learning</b> programs inherit social patterns reflected in their training data without any directed effort by programmers to include such biases. Computer scientists call this algorithmic <b>bias</b>. This paper explores the relationship between <b>machine</b> <b>bias</b> and human cognitive <b>bias</b>. In it, I argue similarities between algorithmic and cognitive biases indicate a disconcerting sense in which sources of <b>bias</b> emerge out of seemingly innocuous patterns of information processing. The emergent ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Potential Biases in <b>Machine</b> <b>Learning</b> Algorithms Using Electronic Health ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6347576/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6347576", "snippet": "A promise of <b>machine</b> <b>learning</b> in health care is the avoidance of biases in diagnosis and treatment; a computer <b>algorithm</b> could objectively synthesize and interpret the data in the medical record. Integration of <b>machine</b> <b>learning</b> with clinical decision support tools, such as computerized alerts or diagnostic support, may offer physicians and others who provide health care targeted and timely information that can improve clinical decisions. <b>Machine</b> <b>learning</b> algorithms, however, may also be ...", "dateLastCrawled": "2022-01-27T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Understanding Racial Bias in Machine Learning Algorithms</b> | by The ...", "url": "https://betterprogramming.pub/understanding-racial-bias-in-machine-learning-algorithms-1c5afe76f8b", "isFamilyFriendly": true, "displayUrl": "https://betterprogramming.pub/<b>understanding-racial-bias-in-machine-learning-algorithms</b>...", "snippet": "<b>Implicit</b> <b>bias</b> is pervasive in the tech industry \u2014 in hiring practices, but also in the products and technologies that well-intentioned developers create. In particular, researchers identify <b>machine</b> <b>learning</b> and artificial intelligence as technologies that suffer from <b>implicit</b> racial biases. If software development is truly \u201ceating the world ...", "dateLastCrawled": "2022-01-25T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Fix <b>Bias in Machine Learning Algorithms</b>? - Yields.io", "url": "https://www.yields.io/blog/how-to-fix-bias-in-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.yields.io/blog/how-to-fix-<b>bias-in-machine-learning-algorithms</b>", "snippet": "Pre-existing <b>bias</b> in algorithms is a consequence of underlying social and institutional ideologies, which can have an impact on the designers or programmers of the software \u2013 human <b>bias</b> in <b>machine</b> <b>learning</b>. These preconceptions can be explicit and conscious, or <b>implicit</b> and unconscious. In general, <b>bias</b> can appear in algorithms through both the modeling approach but also through the use of poor data, or data from a biased source.", "dateLastCrawled": "2022-01-25T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Yale researchers combat biases in <b>machine</b> <b>learning</b> algorithms - Yale ...", "url": "https://yaledailynews.com/blog/2021/11/28/yale-researchers-combat-biases-in-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://yaledailynews.com/blog/2021/11/28/yale-researchers-combat-<b>bias</b>es-in-<b>machine</b>...", "snippet": "In contrast, the \u201ctrain then mask\u201d <b>algorithm</b> was correct 82.3 percent of the time and without <b>implicit</b> <b>bias</b>. A recent investigation in \u201cThe Markup\u201d reported that with conventional mortgage-approval algorithms, Black loan applicants are 80 percent more likely to be rejected than <b>similar</b> white applicants. \u201cTrain then mask\u201d algorithms ...", "dateLastCrawled": "2022-01-31T04:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The Dangers of Human-Like <b>Bias</b> in <b>Machine</b>-<b>Learning</b> Algorithms", "url": "https://scholarsmine.mst.edu/cgi/viewcontent.cgi?article=1030&context=peer2peer", "isFamilyFriendly": true, "displayUrl": "https://scholarsmine.mst.edu/cgi/viewcontent.cgi?article=1030&amp;context=peer2peer", "snippet": "optimizing the <b>algorithm</b>&#39;s performance (Mooney 1996); however, learned biases can cause greater harm when the data set involves actual humans. Learned biases formed on human-related data frequently resemble . human-like. biases towards race, sex, religion, and many other common forms of discrimination. This discrimination and the question of the fairness of artificial intelligence have received increasing public attention thanks to the numerous social media-based AIs launched in recent years ...", "dateLastCrawled": "2021-12-22T20:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Addressing Fairness, <b>Bias</b>, and Appropriate Use of Artificial ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8107824/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8107824", "snippet": "While the <b>bias</b> found in other application domains of <b>machine</b> <b>learning</b> (finance, employment, law enforcement, etc.) may often be due to sampling <b>bias</b> or <b>implicit</b> cultural <b>bias</b>, the domain of health also contains true systematic <b>bias</b> inherent in biological processes which may not be possible to mitigate or \u201crepair.\u201d In the domain of health, there are true genetic differences across different races and ethnic groups which affect disease prevalence, and these differences cannot (and should ...", "dateLastCrawled": "2021-12-05T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Algorithm bias</b> \u2013 Data, Analytics and beyond", "url": "https://tombreur.wordpress.com/2019/05/12/algorithm-bias/", "isFamilyFriendly": true, "displayUrl": "https://tombreur.wordpress.com/2019/05/12/<b>algorithm-bias</b>", "snippet": "<b>Machine</b> <b>Learning</b> and Artificial Intelligence are invading our lives. Every day an <b>algorithm</b> drives decision making, it continues to impact society. This technology has become pervasive, and will likely continue to permeate more and more parts of society. Every day, millions of lives are affected. If we leave this to chance, there is (very) little reason to believe that an invisible hand will gear algorithms towards equity and equality. That\u2019s just not how business governance works.", "dateLastCrawled": "2022-01-22T12:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Amazon scraps secret AI recruiting tool that showed <b>bias</b> against women ...", "url": "https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reuters.com</b>/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G", "snippet": "<b>Machine</b> <b>learning</b> was gaining traction in the technology world, thanks to a surge in low-cost computing power. And Amazon\u2019s Human Resources department was about to embark on a hiring spree: Since ...", "dateLastCrawled": "2022-02-02T22:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Algorithmic <b>Bias</b> in <b>Machine</b> <b>Learning</b> - Duke Forge", "url": "https://forge.duke.edu/sites/default/files/atoms/files/Algorithmic%20Bias%20in%20Machine%20Learning_0.pdf", "isFamilyFriendly": true, "displayUrl": "https://forge.duke.edu/sites/default/files/atoms/files/<b>Algorithm</b>ic <b>Bias</b> in <b>Machine</b>...", "snippet": "The impetus for the Algorithmic <b>Bias</b> in <b>Machine</b> <b>Learning</b> conference, hosted by Duke Forge, grew out of conversations that centered on the increasing excitement in the world of medicine about the potential for artificial intelligence (AI) and <b>machine</b> <b>learning</b>, the prevailing puzzlement about why its use has yet to permeate clinical practice (other than some relatively simple linear equations), and concerns about the potential for algorithmic technologies to introduce or exacerbate harmful ...", "dateLastCrawled": "2022-01-19T02:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Artificial Intelligence Has An <b>Implicit</b> <b>Bias</b> Diversity Dilemma", "url": "https://carpenterwellington.com/post/artificial-intelligence-implicit-bias-diversity-dilemma/", "isFamilyFriendly": true, "displayUrl": "https://carpenterwellington.com/post/artificial-intelligence-<b>implicit</b>-<b>bias</b>-diversity...", "snippet": "Growing Concern About <b>Implicit</b> <b>Bias</b>. There is growing concern about <b>implicit</b> biases built into artificial intelligence systems. These biases could lead to unfair outcomes. The foundation of these systems is the data inputs and the people behind designing the technology. If the <b>implicit</b> biases of the people building the technology skew the data, that will carry forward to skewed outputs. After all, <b>machine</b> <b>learning</b> algorithms are limited to the data sets available to them. Few Women, Fewer ...", "dateLastCrawled": "2022-01-26T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Artificial Intelligence Has An <b>Implicit</b> <b>Bias</b> Diversity Dilemma - Lexology", "url": "https://www.lexology.com/library/detail.aspx?g=413dcae7-871c-417d-b562-bb5bac88e276", "isFamilyFriendly": true, "displayUrl": "https://www.lexology.com/library/detail.aspx?g=413dcae7-871c-417d-b562-bb5bac88e276", "snippet": "The lack of diverse engineers and researchers <b>can</b> lead to products with built-in gender and racial biases. This in turn <b>can</b> result in the propagation of <b>bias</b> on a large-scale. Tech giants such as ...", "dateLastCrawled": "2021-12-30T13:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "News and Media <b>Bias</b> Detection using <b>Machine Learning</b> | by Jerry Wei ...", "url": "https://towardsdatascience.com/news-and-media-bias-detection-using-machine-learning-a-potential-way-to-find-fake-news-13c766aa3988", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/news-and-media-<b>bias</b>-detection-using-<b>machine-learning</b>-a...", "snippet": "<b>Machine learning</b> has recently seen a huge increase because of a rise in both available data and computational power. Researchers have also been working to make even more complex neural networks with more and more layers (deep <b>learning</b>), which allows them to solve even harder problems. <b>Machine learning</b> itself has a bunch of applications in almost every field imaginable; recent advances in <b>machine learning</b> include self-driving cars, language translation, and facial recognition. I previously ...", "dateLastCrawled": "2022-01-20T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Analyzing &amp; <b>Preventing Unconscious Bias in Machine Learning</b>", "url": "https://www.infoq.com/presentations/unconscious-bias-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.infoq.com/presentations/unconscious-<b>bias</b>-<b>machine</b>-<b>learning</b>", "snippet": "So, one is that <b>machine</b> <b>learning</b> <b>can</b> actually amplify <b>bias</b>. There is an interesting paper called &quot;Men also like shopping&quot; where they looked at a dataset. These are kind commonly site datasets ...", "dateLastCrawled": "2022-02-03T03:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>The Implicit Bias Challenge</b> - JobSync", "url": "https://www.jobsync.io/the-implicit-bias-challenge/", "isFamilyFriendly": true, "displayUrl": "https://www.jobsync.io/<b>the-implicit-bias-challenge</b>", "snippet": "Sexism, racism and other unrecognized biases <b>can</b> be built into <b>machine</b>-<b>learning</b> algorithms underlying the intelligence and shape the way people are categorized and addressed. This risks perpetuating an already vicious cycle of <b>bias</b>\u2026The truth is that most of the programming and data analytics are being created globally by white males\u2026has shown that women are less likely than men to be shown ads on Google for executive jobs\u2026these algorithmic flaws are not easy to detect. Ingrained <b>bias</b> ...", "dateLastCrawled": "2022-01-25T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Social Bias in Machine Learning</b> | <b>Machine</b> <b>Learning</b> Medium", "url": "https://machinelearningmedium.com/2018/10/09/algorithmic-fairness/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>medium.com/2018/10/09/<b>algorithm</b>ic-fairness", "snippet": "Recently <b>machine</b> <b>learning</b> has seen its utilitization in a lot of important decision making pipelines such as predicting time of recidivism, college acceptance, loan approvals etc., and hence it becomes increasingly important to question the <b>machine</b> <b>learning</b> models being developed in terms of <b>implicit</b> <b>bias</b> that they might be inheriting from the data that they train on. In order to do away with such biases in a <b>machine</b> <b>learning</b> <b>algorithm</b> one needs to understand how exactly does <b>bias</b> creep in ...", "dateLastCrawled": "2021-12-28T06:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Learning Thoughts</b>: Philosophy", "url": "https://ml.typepad.com/machine_learning_thoughts/philosophy/", "isFamilyFriendly": true, "displayUrl": "https://ml.typepad.com/<b>machine_learning_thoughts</b>/philosophy", "snippet": "The <b>bias</b> of a <b>learning</b> <b>algorithm</b> <b>can</b> <b>be thought</b> of as the way this <b>algorithm</b> ranks the possible functions. The point is that in order to build a function, one needs a way to decide which function to pick among all the functions that (at least partially) agree with the data. So the question is whether there could exist some sort of optimal ranking of functions, or optimal way to decide which function to pick. The problem is that, given a <b>learning</b> problem characterized by the function to be ...", "dateLastCrawled": "2022-01-16T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Frontiers | Addressing Fairness, <b>Bias</b>, and Appropriate Use of ...", "url": "https://www.frontiersin.org/articles/10.3389/frai.2020.561802/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/frai.2020.561802", "snippet": "While the eventual optimal tuning of an <b>algorithm</b> <b>can</b> thus depend on many factors, including the local system of laws and community values, the overall goal of this paper is to introduce and define the notions of <b>bias</b>, fairness, and appropriate use, as it pertains to <b>machine</b> <b>learning</b> in global health, and also to illustrate how a given <b>machine</b> <b>learning</b> model <b>can</b> be analyzed to identify and quantify issues of <b>bias</b> and fairness. With this goal in mind, this paper is intended for the audience ...", "dateLastCrawled": "2022-01-29T07:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>An Empirical Study on Algorithmic Bias</b>", "url": "https://www.researchgate.net/publication/341411703_An_Empirical_Study_on_Algorithmic_Bias", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341411703_<b>An_Empirical_Study_on_Algorithmic_Bias</b>", "snippet": "<b>An Empirical Study on Algorithmic Bias</b>. May 2020. DOI: 10.1109/COMPSAC48688.2020.00-95. Conference: AIML 2020: The 3rd IEEE International Workshop on Advances in Artificial Intelligence &amp; <b>Machine</b> ...", "dateLastCrawled": "2022-01-19T07:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans <b>can</b> be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans <b>can</b> introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we <b>can</b> detect <b>bias</b> in <b>machine learning</b> models and how it <b>can</b> be eliminated. Types of <b>bias</b> . <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools from many of the leaders in <b>machine learning</b> development. Detecting <b>bias</b> starts with the data set. A data set might not represent the problem space ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Potential Biases in <b>Machine</b> <b>Learning</b> Algorithms Using Electronic Health ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6347576/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6347576", "snippet": "Practitioners <b>can</b> have <b>bias</b> in their diagnostic or therapeutic decision makingthat might be circumvented if a computer <b>algorithm</b> could objectively synthesize and interpret the data in the medical record and offer clinical decision support toaid or guide diagnosis and treatment. Although all statistical models existalonga continuum offully human-guided vs fully <b>machine</b>-guided data analyses, 1 <b>machine</b> learningalgorithms in general tend to rely less on human specification (ie, defininga set of ...", "dateLastCrawled": "2022-01-27T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "Often <b>machine</b> <b>learning</b> programs inherit social patterns reflected in their training data without any directed effort by programmers to include such biases. Computer scientists call this algorithmic <b>bias</b>. This paper explores the relationship between <b>machine</b> <b>bias</b> and human cognitive <b>bias</b>. In it, I argue similarities between algorithmic and cognitive biases indicate a disconcerting sense in which sources of <b>bias</b> emerge out of seemingly innocuous patterns of information processing. The emergent ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Racially Unbiased, <b>Machine</b> <b>Learning</b> Approach to Prediction of ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7644374/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7644374", "snippet": "This study aims to determine whether a <b>machine</b> <b>learning</b> <b>algorithm</b> <b>can</b> minimize racial <b>bias</b> in patient risk predictions as <b>compared</b> with commonly used rules-based methods. Methods. Data Processing . Data were drawn from the Medical Information Mart for Intensive Care\u2013III (MIMIC-III) database . The database consists of data on more than 53,000 patient encounters for patients admitted to the intensive care unit at a large academic health center between 2001 and 2012. Patients were included if ...", "dateLastCrawled": "2021-12-18T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Fix <b>Bias in Machine Learning Algorithms</b>? - Yields.io", "url": "https://www.yields.io/blog/how-to-fix-bias-in-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.yields.io/blog/how-to-fix-<b>bias-in-machine-learning-algorithms</b>", "snippet": "Pre-existing <b>bias</b> in algorithms is a consequence of underlying social and institutional ideologies, which <b>can</b> have an impact on the designers or programmers of the software \u2013 human <b>bias</b> in <b>machine</b> <b>learning</b>. These preconceptions <b>can</b> be explicit and conscious, or <b>implicit</b> and unconscious. In general, <b>bias</b> <b>can</b> appear in algorithms through both the modeling approach but also through the use of poor data, or data from a biased source.", "dateLastCrawled": "2022-01-25T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bias and Fairness in Machine Learning</b> - Abhishek Tiwari", "url": "https://www.abhishek-tiwari.com/bias-and-fairness-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.abhishek-tiwari.com/<b>bias-and-fairness-in-machine-learning</b>", "snippet": "In AI and <b>machine</b> <b>learning</b>, the future resembles the past and <b>bias</b> refers to prior information. There has been a growing interest in identifying the harmful biases in the <b>machine</b> <b>learning</b>. Often these harmful biases are just the reflection or amplification of human biases which algorithms learn from training data. Some training data sets such as text, medical, criminal, educational, financial etc. are more susceptible to human biases <b>compared</b> to others. For example, weather data is little or ...", "dateLastCrawled": "2022-01-29T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Artificial Intelligence Has An <b>Implicit</b> <b>Bias</b> Diversity Dilemma - Lexology", "url": "https://www.lexology.com/library/detail.aspx?g=413dcae7-871c-417d-b562-bb5bac88e276", "isFamilyFriendly": true, "displayUrl": "https://www.lexology.com/library/detail.aspx?g=413dcae7-871c-417d-b562-bb5bac88e276", "snippet": "Awareness of the issue <b>can</b> lead to artificial intelligence researchers being more likely to consider diverse data inputs when training <b>machine</b> <b>learning</b> algorithms. This also means paying attention ...", "dateLastCrawled": "2021-12-30T13:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Artificial Intelligence Has An <b>Implicit</b> <b>Bias</b> Diversity Dilemma", "url": "https://carpenterwellington.com/post/artificial-intelligence-implicit-bias-diversity-dilemma/", "isFamilyFriendly": true, "displayUrl": "https://carpenterwellington.com/post/artificial-intelligence-<b>implicit</b>-<b>bias</b>-diversity...", "snippet": "Growing Concern About <b>Implicit</b> <b>Bias</b>. There is growing concern about <b>implicit</b> biases built into artificial intelligence systems. These biases could lead to unfair outcomes. The foundation of these systems is the data inputs and the people behind designing the technology. If the <b>implicit</b> biases of the people building the technology skew the data, that will carry forward to skewed outputs. After all, <b>machine</b> <b>learning</b> algorithms are limited to the data sets available to them. Few Women, Fewer ...", "dateLastCrawled": "2022-01-26T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Which is easier to correct, an algorithm</b>\u2019s <b>bias</b> or a human\u2019s? | by ...", "url": "https://medium.com/enrique-dans/which-is-easier-to-correct-an-algorithms-bias-or-a-human-s-1d2fae7090e1", "isFamilyFriendly": true, "displayUrl": "https://medium.com/enrique-dans/<b>which-is-easier-to-correct-an-algorithm</b>s-<b>bias</b>-or-a...", "snippet": "While personal <b>bias</b> <b>can</b> also be identified using mathematical analysis, <b>compared</b> to the biases of <b>machine</b> <b>learning</b> algorithms, it is much more difficult to correct, and sometimes requires ...", "dateLastCrawled": "2021-01-29T15:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Algorithmic <b>bias</b> detection and mitigation: Best practices and policies ...", "url": "https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.brookings.edu</b>/research/<b>algorithm</b>ic-<b>bias</b>-detection-and-mitigation-best-", "snippet": "Turner Lee, Nicol. Detecting racial <b>bias</b> in algorithms and <b>machine</b> <b>learning</b>. Journal of Information, Communication and Ethics in Society 2018, Vol. 16 Issue 3, pp. 252-260. Available at https ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Implicit/Machine learning gender bias</b> | ReberLab", "url": "https://www.reberlab.psych.northwestern.edu/2018/10/11/implicitmachine-learning-gender-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.reberlab.psych.northwestern.edu/.../10/11/<b>implicitmachine-learning-gender-bias</b>", "snippet": "First, I have found myself describing on a few recent occasions that it is reasonable to think of <b>implicit</b> <b>learning</b> (IL) as the brain\u2019s <b>machine</b> <b>learning</b> (ML) algorithm. ML is a super-hot topic in AI and data science research, so this might be a useful <b>analogy</b> to help people understand what we mean by studying IL. We characterize IL as the statistical extraction of patterns in the environment and the shaping of cognitive processing to maximize efficiency and effectiveness to these patterns ...", "dateLastCrawled": "2020-11-16T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "Often <b>machine</b> <b>learning</b> programs inherit social patterns reflected in their training data without any directed effort by programmers to include such biases. Computer scientists call this algorithmic <b>bias</b>. This paper explores the relationship between <b>machine</b> <b>bias</b> and human cognitive <b>bias</b>. In it, I argue similarities between algorithmic and cognitive biases indicate a disconcerting sense in which sources of <b>bias</b> emerge out of seemingly innocuous patterns of information processing. The emergent ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Harnessing data for unbiased <b>Learning</b> of Machines | by Vivek Gupta | Medium", "url": "https://gvivek.medium.com/harnessing-data-for-unbiased-learning-of-machines-dc614497a29c", "isFamilyFriendly": true, "displayUrl": "https://gvivek.medium.com/harnessing-data-for-un<b>bias</b>ed-<b>learning</b>-of-<b>machines</b>-dc614497a29c", "snippet": "In <b>Machine</b> <b>Learning</b>, the input data reflects stereotypes and biases of the broader society, then the output of the <b>learning</b> algorithm also captures these stereotypes. Here, we will discuss the gender stereotypes in word embedding. word-embedding encode semantic information, they also exhibit hidden biases inherent in the dataset they are trained on associations such as: father:doctor :: mother:nurse. man:computer programmer :: woman:homemaker. The prejudices and stereotypes in these ...", "dateLastCrawled": "2022-01-12T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning</b> | Gendered Innovations", "url": "http://genderedinnovations.stanford.edu/case-studies/machinelearning.html", "isFamilyFriendly": true, "displayUrl": "genderedinnovations.stanford.edu/case-studies/<b>machinelearning</b>.html", "snippet": "As <b>machine learning</b> becomes increasingly ubiquitous in everyday lives, such <b>bias</b>, if uncorrected, can lead to social inequities. Researchers need to understand how gender and ethnicity operate within the context of their algorithm in order to enhance or, at least, not reinforce social equalities. Here we suggest avenues for reducing <b>bias</b> in training data and algorithms in efforts to produce AI that enhances social equalities.", "dateLastCrawled": "2022-01-25T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>How machine learning can amplify or remove gender stereotypes</b> \u2013 Social ...", "url": "https://socialmediacollective.org/2016/08/06/amplifying-and-neutralizing-gender-bias-using-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://socialmediacollective.org/2016/08/06/amplifying-and-neutralizing-gender-<b>bias</b>...", "snippet": "TLDR: It&#39;s easier to remove gender biases from <b>machine</b> <b>learning</b> algorithms than from people. In a recent paper, Saligrama, Bolukbasi, Chang, Zou, and I stumbled across some good and bad news about Word Embeddings. Word Embeddings are a wildly popular tool of the trade among AI researchers. They can be used to solve <b>analogy</b> puzzles. For instance, for\u2026", "dateLastCrawled": "2021-12-23T11:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Ways <b>to think about machine learning</b> \u2014 Benedict Evans", "url": "https://www.ben-evans.com/benedictevans/2018/06/22/ways-to-think-about-machine-learning-8nefy", "isFamilyFriendly": true, "displayUrl": "https://www.ben-evans.com/.../2018/06/22/ways-<b>to-think-about-machine-learning</b>-8nefy", "snippet": "<b>Machine</b> <b>learning</b> lets us find patterns or structures in data that are <b>implicit</b> and probabilistic (hence \u2018inferred\u2019) rather than explicit, that previously only people and not computers could find. They address a class of questions that were previously \u2018hard for computers and easy for people\u2019, or, perhaps more usefully, \u2018hard for people to describe to computers\u2019. And we\u2019ve seen some cool (or worrying, depending on your perspective) speech and vision demos.", "dateLastCrawled": "2022-01-30T10:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word ...", "url": "https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf", "snippet": "signi\ufb01cant risk and challenge for <b>machine</b> <b>learning</b> and its applications. The analogies generated from these embeddings spell out the <b>bias</b> <b>implicit</b> in the data on which they were trained. Hence, word embeddings may serve as a means to extract <b>implicit</b> gender associations from a large text corpus", "dateLastCrawled": "2022-02-02T05:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning is Requirements Engineering</b> \u2014 On the Role of Bugs ...", "url": "https://medium.com/analytics-vidhya/machine-learning-is-requirements-engineering-8957aee55ef4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>machine-learning-is-requirements-engineering</b>-8957...", "snippet": "A <b>machine</b>-learned model is not an attempt at implementing an <b>implicit</b> specification; a <b>machine</b>-learned model is a specification! It is a learned description of how the system shall behave. The ...", "dateLastCrawled": "2022-01-19T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Man is to Computer Programmer as Woman is</b> to Homemaker? | by Sheldon ...", "url": "https://towardsdatascience.com/man-is-to-computer-programmer-as-woman-is-to-homemaker-e57b07cbde96", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>man-is-to-computer-programmer-as-woman-is</b>-to-homemaker...", "snippet": "The paper discusses gender <b>bias</b> in <b>machine</b> <b>learning</b> as a result of using biased training data and proposes a solution to debias the model. This article contains an overview of the paper and discusses key findings in the python implementation of the paper. Overview. The authors of the paper used Word Embe d ding Model to demonstrate gender <b>bias</b> in the training data. The Word Embedding Model was trained on Google News articles and the vector representation of all words were stored in the ...", "dateLastCrawled": "2022-01-30T22:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "CSWA: <b>Unconscious Bias</b> | American Astronomical Society", "url": "https://aas.org/comms/cswa/resources/unconsciousbias", "isFamilyFriendly": true, "displayUrl": "https://aas.org/comms/cswa/resources/<b>unconsciousbias</b>", "snippet": "The intervention is based on the premise that <b>implicit bias is like</b> a habit that can be broken through a combination of awareness of implicit bias, concern about the effects of that bias, and the application of strategies to reduce bias. In a 12-week longitudinal study, people who received the intervention showed dramatic reductions in implicit race bias. People who were concerned about discrimination or who reported using the strategies showed the greatest reductions. The intervention also ...", "dateLastCrawled": "2022-02-03T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Patrick Forscher</b> \u2013 Research Lead \u2013 Busara Center for Behavioral ...", "url": "https://ch.linkedin.com/in/patrick-forscher-91163854", "isFamilyFriendly": true, "displayUrl": "https://ch.linkedin.com/in/<b>patrick-forscher</b>-91163854", "snippet": "The intervention is based on the premise that <b>implicit bias is like</b> a habit that can be broken through a combination of awareness of implicit bias, concern about the effects of that bias, and the application of strategies to reduce bias. In a 12-week longitudinal study, people who received the intervention showed dramatic reductions in implicit race bias. People who were\u2026 We developed a multi-faceted prejudice habit-breaking intervention to produce long-term reductions in implicit race ...", "dateLastCrawled": "2022-02-03T15:10:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Those designing healthcare algorithms must become actively</b> anti-racist ...", "url": "https://www.nature.com/articles/s41591-020-1020-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41591-020-1020-3", "snippet": "<b>Just as \u2018implicit bias</b>\u2019 training for police does little to change racist behavior 10 \u2014in large part because departmental cultures do not fully support the lessons of anti-racism\u2014healthcare ...", "dateLastCrawled": "2021-11-15T00:12:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(implicit bias)  is like +(machine learning algorithm)", "+(implicit bias) is similar to +(machine learning algorithm)", "+(implicit bias) can be thought of as +(machine learning algorithm)", "+(implicit bias) can be compared to +(machine learning algorithm)", "machine learning +(implicit bias AND analogy)", "machine learning +(\"implicit bias is like\")", "machine learning +(\"implicit bias is similar\")", "machine learning +(\"just as implicit bias\")", "machine learning +(\"implicit bias can be thought of as\")", "machine learning +(\"implicit bias can be compared to\")"]}