{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian Neural network</b>. In a <b>traditional</b> <b>neural network</b>\u2026 | by Sabber ...", "url": "https://towardsdatascience.com/bayesian-neural-network-7041dd09f2cc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bayesian-neural-network</b>-7041dd09f2cc", "snippet": "<b>Bayesian Neural network</b>. Sabber Ahamed. Jan 19, 2021 \u00b7 4 min read. Figure-1: The schematic diagram shows the architecture of the <b>Bayesian neural network</b> used in this work. The <b>network</b> has one input layer with eight parameters, one hidden layer with twelve nodes, and an output layer with a single node. Weights between input and hidden layers ...", "dateLastCrawled": "2022-01-30T10:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian</b> <b>Neural</b> Networks", "url": "https://turing.ml/dev/tutorials/03-bayesian-neural-network/", "isFamilyFriendly": true, "displayUrl": "https://turing.ml/dev/tutorials/03-<b>bayesian</b>-<b>neural</b>-<b>network</b>", "snippet": "Generic <b>Bayesian</b> <b>Neural</b> Networks\u00b6. The below code is intended for use in more general applications, where you need to be able to change the basic <b>network</b> shape fluidly. The code above is highly rigid, and adapting it for other architectures would be time consuming. Currently the code below only supports networks of Dense layers.", "dateLastCrawled": "2022-02-03T02:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Hands-on Guide to <b>Bayesian Neural Network in Classification</b>", "url": "https://analyticsindiamag.com/hands-on-guide-to-bayesian-neural-network-in-classification/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/hands-on-guide-to-<b>bayesian-neural-network-in-classification</b>", "snippet": "In a <b>traditional</b> <b>neural</b> <b>network</b>, each layer has fixed weights and biases that determine the output. But, a <b>Bayesian</b> <b>neural</b> <b>network</b> will have a probability distribution attached to each layer as shown below. For a classification problem, you perform multiple forward passes each time with new samples of weights and biases.", "dateLastCrawled": "2022-02-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>Bayesian neural network for toxicity prediction</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S2468111320300438", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2468111320300438", "snippet": "A <b>Bayesian</b> <b>Neural</b> <b>Network</b> does not overfit on small datasets in contrast with <b>traditional</b> <b>neural</b> networks. Abstract. Predicting the toxicity of a compound preclinically enables better decision making, thereby reducing development costs and increasing patient safety. It is a complex issue, but in vitro assays and physicochemical properties of compounds can be used to predict clinical toxicity. <b>Neural</b> networks (NNs) are a popular predictive tool due to their flexibility and ability to model ...", "dateLastCrawled": "2021-11-09T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Variational Inference: <b>Bayesian</b> <b>Neural</b> Networks \u2014 PyMC3 3.11.4 ...", "url": "https://docs.pymc.io/en/stable/pymc-examples/examples/variational_inference/bayesian_neural_network_advi.html", "isFamilyFriendly": true, "displayUrl": "https://docs.pymc.io/.../examples/variational_inference/<b>bayesian</b>_<b>neural</b>_<b>network</b>_advi.html", "snippet": "Unfortunately, when it comes to <b>traditional</b> ML problems <b>like</b> classification or (non-linear) regression, ... Some ideas are: * Uncertainty in predictions: As we will see below, the <b>Bayesian</b> <b>Neural</b> <b>Network</b> informs us about the uncertainty in its predictions. I think uncertainty is an underappreciated concept in Machine Learning as it\u2019s clearly important for real-world applications. But it could also be useful in training. For example, we could train the model specifically on samples it is ...", "dateLastCrawled": "2022-01-31T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Are <b>Bayesian</b> <b>neural</b> networks intrinsically good at out-of-distribution ...", "url": "https://deepai.org/publication/are-bayesian-neural-networks-intrinsically-good-at-out-of-distribution-detection", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/are-<b>bayesian</b>-<b>neural</b>-<b>networks</b>-intrinsically-good-at-out...", "snippet": "In the previous section, we recalled the connection between BNNs and GPs, namely that <b>Bayesian</b> inference in an infinite-width <b>neural</b> <b>network</b> can be studied in the GP framework (assuming a proper choice of prior). This connection allows studying how the kernels induced by architectural choices shape the prior in function space, and how these choices ultimately determine OOD behavior. In this section, we analyze this OOD behavior for <b>traditional</b> as well as NNGP-induced kernels. To minimize the ...", "dateLastCrawled": "2022-01-24T03:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[D] Dropout for <b>Bayesian</b> <b>Neural</b> Networks and Alternatives ...", "url": "https://www.reddit.com/r/MachineLearning/comments/j81jmt/d_dropout_for_bayesian_neural_networks_and/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/j81jmt/d_dropout_for_<b>bayesian</b>_<b>neural</b>_<b>networks</b>_and", "snippet": "Unlike <b>traditional</b> <b>neural</b> networks where each layer of nodes is connected to every node in the next layer, a graph <b>neural</b> <b>network</b> has a graph-<b>like</b> structure. With this model, they managed to simulate a wide range of materials including sand, water, goop, and rigid solids. Instead of predicting the positions of particles, the model predicts the accelerations, and the velocities and positions are computed using an Euler integration. The simulation data were generated using a range of physics ...", "dateLastCrawled": "2021-09-09T16:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Uncertainty Estimation in Bayesian Neural Networks</b> And Links to ...", "url": "https://people.csail.mit.edu/lrchai/files/Chai_thesis.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.csail.mit.edu/lrchai/files/Chai_thesis.pdf", "snippet": "<b>like</b> deep <b>neural</b> networks, they are often difficult to interpret \u2013 we do not know how correct predictions are made and what makes the prediction uncertain. Numerous approaches to interpreting <b>neural</b> <b>network</b> predictions have been studied, but there is limited work on interpreting uncertainty in model predictions. Here, we propose a method to visualise the contribution of individual features to predictive uncertainty, epistemic uncertainty (from the model weights), and aleatoric uncertainty ...", "dateLastCrawled": "2022-01-30T23:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Bayesian</b> <b>neural</b> networks for uncertainty quantification in data-driven ...", "url": "https://www.sciencedirect.com/science/article/pii/S0045782521004102", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0045782521004102", "snippet": "Examples of <b>Bayesian</b>-<b>like</b> model averaging procedures applied to <b>Bayesian</b> <b>neural</b> networks include where model averaging is performed using the <b>Bayesian</b> information criterion (BIC), or in to select a <b>neural</b> <b>network</b> architecture using a logarithmic score utility function. In these works however, the predictive density for a given <b>neural</b> <b>network</b> model is obtained via some sort of linearization. In the following we propose to use a pseudo-<b>Bayesian</b> model averaging procedure to combine outputs of ...", "dateLastCrawled": "2022-01-18T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Constraining cosmological parameters from N-body simulations with ...", "url": "http://bayesiandeeplearning.org/2021/papers/57.pdf", "isFamilyFriendly": true, "displayUrl": "<b>bayesian</b>deeplearning.org/2021/papers/57.pdf", "snippet": "simulations [5] are used to extract cosmological information via two approaches: a <b>traditional</b> <b>neural</b> <b>network</b> and a <b>Bayesian</b> one, which has the advantage of estimating the associated uncertainty. The main contributions of this paper are the following: 1. Propose probabilistic <b>neural</b> networks approaches for cosmological analysis and provide alternative techniques for extracting complex information from simulations. 2. Compare the performance and advantages of BNNs with respect to the ...", "dateLastCrawled": "2022-02-03T03:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian Neural network</b>. In a <b>traditional</b> <b>neural network</b>\u2026 | by Sabber ...", "url": "https://towardsdatascience.com/bayesian-neural-network-7041dd09f2cc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bayesian-neural-network</b>-7041dd09f2cc", "snippet": "In a <b>traditional</b> <b>neural network</b>, weights are assigned as a single value or point estimate, whereas in BNN, weights are considered a probability distribution. These probability distributions of <b>network</b> weights are used to estimate the uncertainty in weights and predictions. Figure-1 shows a schematic diagram of a BNN where weights are normally distributed. The posterior of the weights are calculated using Bayes theorem as:", "dateLastCrawled": "2022-01-30T10:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A <b>Bayesian</b> <b>Neural</b> Model for Documents&#39; Relevance Estimation", "url": "http://ceur-ws.org/Vol-2950/paper-15.pdf", "isFamilyFriendly": true, "displayUrl": "ceur-ws.org/Vol-2950/paper-15.pdf", "snippet": "<b>Bayesian</b> <b>Neural</b> Layer (BNL) [19]. A BNL <b>is similar</b> to a <b>traditional</b> <b>neural</b> <b>network</b>, where the weights of each layer are probability distributions instead of scalar values. We realized this layer employing the flipout technique, an efficient method for decorrelating the gradients within a mini-batch by implicitly sampling pseudo-independent", "dateLastCrawled": "2021-12-14T23:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Stochastic <b>Bayesian</b> <b>Neural</b> Networks", "url": "https://api.deepai.org/publication-download-pdf/stochastic-bayesian-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://api.deepai.org/publication-download-pdf/stochastic-<b>bayesian</b>-<b>neural</b>-<b>networks</b>", "snippet": "as stochastic <b>bayesian</b> <b>neural</b> <b>network</b>. The update step <b>is similar</b> to the <b>traditional</b> backpropagation method in our method. In this method, a BNN is trained to produce a custom distribution with small KL-divergence with the true posterior. We do this by maximizing the Evidence Lower Bound (ELBO) by sampling based approximation. We specify stochastic process priors which are by their inherent nature rich in structured dependencies between function values. Using this method, we can model ...", "dateLastCrawled": "2022-01-27T06:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is the <b>difference between a Bayesian network and Bayesian neural</b> ...", "url": "https://www.researchgate.net/post/What_is_the_difference_between_a_Bayesian_network_and_Bayesian_neural_network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What_is_the_<b>difference_between_a_Bayesian_network</b>...", "snippet": "Popular Answers (1) Classical <b>neural</b> networks use maximum likelihood to determine <b>network</b> parameters (weights and biases) and hence make predictions. <b>Bayesian</b> <b>neural</b> networks marginalize over the ...", "dateLastCrawled": "2022-02-02T00:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bayesian Neural</b> Networks: 1 Why Bother? | by Adam Woolf | Towards Data ...", "url": "https://towardsdatascience.com/bayesian-neural-networks-1-why-bother-b585375b38ec", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bayesian-neural</b>-<b>networks</b>-1-why-bother-b585375b38ec", "snippet": "But if we\u2019ve trained the <b>Bayesian Neural</b> <b>network</b> well our predictions will be very <b>similar</b> (for continuous, floating point, regression outputs) and the same for (categorical outputs.). And if we train our <b>neural</b> <b>network</b> badly we\u2019ll get very different results each time. If the <b>Bayesian</b> <b>network</b> could speak it would say the difference between it\u2019s predictions being <b>similar</b> or its predictions being very different is its uncertainty. Think of uncertainty as confidence (only <b>Bayesian neural</b> ...", "dateLastCrawled": "2022-01-26T09:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Bayesian neural network for toxicity prediction</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S2468111320300438", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2468111320300438", "snippet": "A <b>Bayesian</b> <b>Neural</b> <b>Network</b> does not overfit on small datasets in contrast with <b>traditional</b> <b>neural</b> networks. Abstract. Predicting the toxicity of a compound preclinically enables better decision making, thereby reducing development costs and increasing patient safety. It is a complex issue, but in vitro assays and physicochemical properties of compounds can be used to predict clinical toxicity. <b>Neural</b> networks (NNs) are a popular predictive tool due to their flexibility and ability to model ...", "dateLastCrawled": "2021-11-09T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Informed MCMC with <b>Bayesian</b> <b>Neural</b> Networks for Facial Image Analysis", "url": "http://bayesiandeeplearning.org/2018/papers/38.pdf", "isFamilyFriendly": true, "displayUrl": "<b>bayesian</b>deeplearning.org/2018/papers/38.pdf", "snippet": "<b>Bayesian</b> <b>Neural</b> Networks. A <b>Bayesian</b> <b>Neural</b> <b>Network</b> (BNN) estimates, in contrast <b>to traditional</b> <b>Neural</b> Networks, not only a point estimate but also the corresponding uncertainties. In [5], Kendall and Gal describe model (Epistemic) and data (Heteroscedastic Aleatoric) uncertainties to be crucial for computer vision tasks and introduce an approach to unify both uncertainties within a BNN. We build upon this approach and estimate our global distribution Q I(jx) with a BNN which is in turn used ...", "dateLastCrawled": "2022-02-02T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Uncertainty Estimation in Bayesian Neural Networks</b> And Links to ...", "url": "https://people.csail.mit.edu/lrchai/files/Chai_thesis.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.csail.mit.edu/lrchai/files/Chai_thesis.pdf", "snippet": "Numerous approaches to interpreting <b>neural</b> <b>network</b> predictions have been studied, but there is limited work on interpreting uncertainty in model predictions. Here, we propose a method to visualise the contribution of individual features to predictive uncertainty, epistemic uncertainty (from the model weights), and aleatoric uncertainty (inherent in the input). Our approach measures the change in uncertainty when a given feature of the input is known, compared to when it is unknown. Applying ...", "dateLastCrawled": "2022-01-30T23:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep <b>Neural</b> Networks as Gaussian Processes - <b>Bayesian</b> Deep Learning", "url": "http://bayesiandeeplearning.org/2017/papers/59.pdf", "isFamilyFriendly": true, "displayUrl": "<b>bayesian</b>deeplearning.org/2017/papers/59.pdf", "snippet": "<b>Network</b> GP (NNGP) \u2013 to perform <b>Bayesian</b> inference for deep <b>neural</b> networks on MNIST and CIFAR-10 across different hyperparameters including <b>network</b> depth, nonlinearity, training set size (up to and including the full dataset consisting of tens of thousands of images), and weight and bias variance. To utilize the exact <b>Bayesian</b> results for regression, we treat classi\ufb01cation as regression on one-hot targets; our intention here is to provide a \ufb01rst proof of concept for our method, and we ...", "dateLastCrawled": "2022-01-25T01:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Are <b>Bayesian</b> <b>neural</b> networks intrinsically good at out-of-distribution ...", "url": "https://deepai.org/publication/are-bayesian-neural-networks-intrinsically-good-at-out-of-distribution-detection", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/are-<b>bayesian</b>-<b>neural</b>-<b>networks</b>-intrinsically-good-at-out...", "snippet": "In the previous section, we recalled the connection between BNNs and GPs, namely that <b>Bayesian</b> inference in an infinite-width <b>neural</b> <b>network</b> can be studied in the GP framework (assuming a proper choice of prior). This connection allows studying how the kernels induced by architectural choices shape the prior in function space, and how these choices ultimately determine OOD behavior. In this section, we analyze this OOD behavior for <b>traditional</b> as well as NNGP-induced kernels. To minimize the ...", "dateLastCrawled": "2022-01-24T03:21:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The <b>very Basics of Bayesian Neural Networks</b> \u2013 Sanjay Thakur", "url": "https://sanjaykthakur.com/2018/12/05/the-very-basics-of-bayesian-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://sanjaykthakur.com/2018/12/05/the-<b>very-basics-of-bayesian-neural-networks</b>", "snippet": "<b>Bayesian</b> <b>Neural</b> Networks (BNN) are NN whose weights or parameters are expressed as a distribution rather than a deterministic value and learned using <b>Bayesian</b> inference. Their innate potential to simultaneously learn complex non-linear functions from data and express uncertainties have lent them a major role in our pursuit to develop more capable AI. In this blog post, I will cover their significance where <b>traditional</b> (deterministic) NNs fall short. I will also walk the readers through their ...", "dateLastCrawled": "2022-02-03T13:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Are <b>Bayesian</b> <b>neural</b> networks intrinsically good at out-of-distribution ...", "url": "https://deepai.org/publication/are-bayesian-neural-networks-intrinsically-good-at-out-of-distribution-detection", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/are-<b>bayesian</b>-<b>neural</b>-<b>networks</b>-intrinsically-good-at-out...", "snippet": "In the previous section, we recalled the connection between BNNs and GPs, namely that <b>Bayesian</b> inference in an infinite-width <b>neural</b> <b>network</b> <b>can</b> be studied in the GP framework (assuming a proper choice of prior). This connection allows studying how the kernels induced by architectural choices shape the prior in function space, and how these choices ultimately determine OOD behavior. In this section, we analyze this OOD behavior for <b>traditional</b> as well as NNGP-induced kernels. To minimize the ...", "dateLastCrawled": "2022-01-24T03:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian</b> <b>neural</b> networks for uncertainty quantification in data-driven ...", "url": "https://www.sciencedirect.com/science/article/pii/S0045782521004102", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0045782521004102", "snippet": "A materials data example is then presented where a <b>Bayesian</b> <b>neural</b> <b>network</b> is trained to serve as a surrogate of a costly finite element model of a composite material with randomly placed circular fibers. This random placement of fibers induces some aleatoric uncertainty in the data, while the amount of epistemic uncertainty <b>can</b> be controlled by varying the amount of data used for training.", "dateLastCrawled": "2022-01-18T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>Bayesian neural network for toxicity prediction</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S2468111320300438", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2468111320300438", "snippet": "A <b>Bayesian</b> <b>Neural</b> <b>Network</b> does not overfit on small datasets in contrast with <b>traditional</b> <b>neural</b> networks. Abstract. Predicting the toxicity of a compound preclinically enables better decision making, thereby reducing development costs and increasing patient safety. It is a complex issue, but in vitro assays and physicochemical properties of compounds <b>can</b> be used to predict clinical toxicity. <b>Neural</b> networks (NNs) are a popular predictive tool due to their flexibility and ability to model ...", "dateLastCrawled": "2021-11-09T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Classifying the <b>Universe</b> with <b>Bayesian</b> <b>Neural</b> Networks | by Joe Kennedy ...", "url": "https://towardsdatascience.com/classifying-the-universe-with-bayesian-neural-networks-f20d0983e9b5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/classifying-the-<b>universe</b>-with-<b>bayesian</b>-<b>neural</b>-<b>networks</b>...", "snippet": "<b>Traditional</b> <b>neural</b> networks are not well suited to estimating prediction uncertainty as they <b>can</b> only provide a single prediction for the class of a single test example. Training the <b>network</b> on slightly different training data or adding modified noise to a test example might dramatically affect a prediction given by a <b>neural</b> <b>network</b> [3]. In an attempt to tackle these issues <b>Bayesian</b> <b>neural</b> networks (BNNs) were developed which, rather than obtaining fixed values for the weights during ...", "dateLastCrawled": "2022-01-16T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Comprehensive Introduction to <b>Bayesian</b> Deep Learning - Joris Baan", "url": "https://jorisbaan.nl/2021/03/02/introduction-to-bayesian-deep-learning.html", "isFamilyFriendly": true, "displayUrl": "https://jorisbaan.nl/2021/03/02/introduction-to-<b>bayesian</b>-deep-learning.html", "snippet": "<b>Bayesian</b> Deep Learning. A <b>Bayesian</b> <b>Neural</b> <b>Network</b> (BNN) is simply posterior inference applied to a <b>neural</b> <b>network</b> architecture. To be precise, a prior distribution is specified for each weight and bias. Because of their huge parameter space, however, inferring the posterior is even more difficult than usual.", "dateLastCrawled": "2022-02-03T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Graph Neural Processes Towards Bayesian Graph Neural</b> Networks", "url": "https://andrewnc.github.io/Graph_Neural_Processes.pdf", "isFamilyFriendly": true, "displayUrl": "https://andrewnc.github.io/Graph_<b>Neural</b>_Processes.pdf", "snippet": "convolution operation from <b>traditional</b> deep learning. These features, when used in conjunction with the <b>traditional</b> CNP architecture offer local representations of the graph around edges and assist in the learning of high level abstractions across classes of graphs. Graph <b>Neural</b> Processes learn a high level representation across a family of graphs, in part by utilizing these instructive features. Preprint. Under review. Figure 1: Conditional <b>Neural</b> Process Architecture. The data likelihood ...", "dateLastCrawled": "2022-01-31T14:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) A <b>Bayesian</b> <b>neural</b> <b>network</b> for toxicity prediction", "url": "https://www.researchgate.net/publication/341063872_A_Bayesian_neural_network_for_toxicity_prediction", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341063872_A_<b>Bayesian</b>_<b>neural</b>_<b>network</b>_for...", "snippet": "<b>Bayesian</b> <b>neural</b> networks (BNNs) are able to avoid these pitfalls by using prior distributions on the parameters of a NN model and representing uncertainty about the predictions in the form of a ...", "dateLastCrawled": "2021-09-19T19:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Why hasn&#39;t the <b>Bayesian network been as successful</b> as the Deep <b>Neural</b> ...", "url": "https://www.quora.com/Why-hasnt-the-Bayesian-network-been-as-successful-as-the-Deep-Neural-Network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-hasnt-the-<b>Bayesian-network-been-as-successful</b>-as-the-Deep...", "snippet": "Answer (1 of 5): Well, the definition of \u201csuccessful\u201d is important, here. <b>Bayesian</b> networks are arguably more successful than deep <b>neural</b> networks to date. They are widely applied across industries and <b>can</b> readily be used for inference, modelling, and prediction. Presumably your question is real...", "dateLastCrawled": "2022-01-15T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Can Neural Networks Generate Better Memes Than</b> Humans?", "url": "https://analyticsindiamag.com/can-neural-networks-generate-better-memes-than-humans/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/<b>can-neural-networks-generate-better-memes-than</b>-humans", "snippet": "The <b>Bayesian</b> statistics <b>can</b> be used for parameter tuning and also it <b>can</b> make the process faster especially in the case of <b>neural</b> networks. we <b>can</b> say performing <b>Bayesian</b> statistics is a process of optimization using which we <b>can</b> perform hyperparameter tuning.", "dateLastCrawled": "2022-01-25T06:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is the <b>difference between a Bayesian network and Bayesian neural</b> ...", "url": "https://www.researchgate.net/post/What_is_the_difference_between_a_Bayesian_network_and_Bayesian_neural_network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What_is_the_<b>difference_between_a_Bayesian_network</b>...", "snippet": "<b>Bayesian</b> <b>neural</b> <b>network</b> <b>can</b> employ <b>Bayesian</b> prior to regularize the <b>neural</b> <b>network</b>. This <b>can</b> find the optimum complexity for the model I.e. optimum sparsity that minimizes overfitting, provides an ...", "dateLastCrawled": "2022-02-02T00:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A <b>Bayesian neural network for toxicity prediction</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S2468111320300438", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2468111320300438", "snippet": "A <b>Bayesian</b> <b>Neural</b> <b>Network</b> does not overfit on small datasets in contrast with <b>traditional</b> <b>neural</b> networks. Abstract. Predicting the toxicity of a compound preclinically enables better decision making, thereby reducing development costs and increasing patient safety. It is a complex issue, but in vitro assays and physicochemical properties of compounds <b>can</b> be used to predict clinical toxicity. <b>Neural</b> networks (NNs) are a popular predictive tool due to their flexibility and ability to model ...", "dateLastCrawled": "2021-11-09T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian Learning for Neural Networks</b> - Semantic Scholar", "url": "https://www.semanticscholar.org/paper/Bayesian-Learning-for-Neural-Networks-Neal/db869fa192a3222ae4f2d766674a378e47013b1b", "isFamilyFriendly": true, "displayUrl": "https://www.semanticscholar.org/paper/<b>Bayesian-Learning-for-Neural-Networks</b>-Neal/db869...", "snippet": "<b>Bayesian Learning for Neural Networks</b> shows that <b>Bayesian</b> methods allow complex <b>neural</b> <b>network</b> models to be used without fear of the &quot;overfitting&quot; that <b>can</b> occur with <b>traditional</b> <b>neural</b> <b>network</b> learning methods. Artificial &quot;<b>neural</b> networks&quot; are widely used as flexible models for classification and regression applications, but questions remain about how the power of these models <b>can</b> be safely exploited when training data is limited. This book demonstrates how <b>Bayesian</b> methods allow complex ...", "dateLastCrawled": "2022-02-02T17:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Uncertainty Estimation in Bayesian Neural Networks</b> And Links to ...", "url": "https://people.csail.mit.edu/lrchai/files/Chai_thesis.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.csail.mit.edu/lrchai/files/Chai_thesis.pdf", "snippet": "Numerous approaches to interpreting <b>neural</b> <b>network</b> predictions have been studied, but there is limited work on interpreting uncertainty in model predictions. Here, we propose a method to visualise the contribution of individual features to predictive uncertainty, epistemic uncertainty (from the model weights), and aleatoric uncertainty (inherent in the input). Our approach measures the change in uncertainty when a given feature of the input is known, <b>compared</b> to when it is unknown. Applying ...", "dateLastCrawled": "2022-01-30T23:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Bayesian</b> <b>neural</b> <b>network</b> with pretrained protein embedding ...", "url": "https://www.researchgate.net/publication/351529193_Bayesian_neural_network_with_pretrained_protein_embedding_enhances_prediction_accuracy_of_drug-protein_interaction", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/351529193_<b>Bayesian</b>_<b>neural</b>_<b>network</b>_with_p...", "snippet": "small dataset is the <b>Bayesian</b> <b>neural</b> <b>network</b> (BNN) (Gal and Ghahramani (2015)). <b>Compared</b> to a conventional DNN, which gives a de\ufb01nite. point prediction for each given input, a BNN returns a ...", "dateLastCrawled": "2022-02-03T03:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Comparing <b>Bayesian</b> and <b>neural</b> <b>network</b> supported lithotype prediction ...", "url": "https://www.pdgm.com/resource-library/articles-and-papers/2020/comparing-bayesian-and-neural-network-supported-li/", "isFamilyFriendly": true, "displayUrl": "https://www.pdgm.com/.../2020/comparing-<b>bayesian</b>-and-<b>neural</b>-<b>network</b>-supported-li", "snippet": "Comparing <b>Bayesian</b> and <b>neural</b> <b>network</b> supported lithotype prediction from seismic data Sabine Klarner1*, Dmitriy Kirnos 1, Natalya Ivanova, Aleksey Gritsenko and Olga Malinovskaya2 benchmark advanced <b>neural</b> <b>network</b> algorithms against standard probabilistic lithology classifications from seismic data to find out which approach works best and under which circumstances. Introduction In the past few years there has been increasing interest in the application of machine learning in the industry ...", "dateLastCrawled": "2022-01-07T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "High Dimensional Level Set Estimation with <b>Bayesian</b> <b>Neural</b> <b>Network</b>", "url": "https://www.aaai.org/AAAI21Papers/AAAI-5072.HaH.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aaai.org/AAAI21Papers/AAAI-5072.HaH.pdf", "snippet": "<b>Bayesian</b> <b>Neural</b> Networks <b>Bayesian</b> <b>neural</b> networks (BNN) provide a probabilistic interpretation of <b>neural</b> net-works by inferring probability distribution of the networks\u2019 weights (MacKay 1992; Neal 1995). Given a training data D tr = fx i;y igNi =1, a BNN <b>can</b> provide the posterior distri-bution p(!jD tr) with !being the <b>neural</b> <b>network</b> weights.", "dateLastCrawled": "2022-01-14T11:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Informed MCMC with <b>Bayesian</b> <b>Neural</b> Networks for Facial Image Analysis", "url": "http://bayesiandeeplearning.org/2018/papers/38.pdf", "isFamilyFriendly": true, "displayUrl": "<b>bayesian</b>deeplearning.org/2018/papers/38.pdf", "snippet": "Contribution. In this work, we propose to use a <b>Bayesian</b> <b>Neural</b> <b>Network</b> for estimating an image dependent proposal distribution Q(jx). <b>Compared</b> to a standard Gaussian random walk proposal, this will accelerate the sampler in \ufb01nding regions of the posterior with high value. In this way, we <b>can</b> signi\ufb01cantly reduce the number of samples needed to perform facial image analysis. 2 Methodology Generative Face Model. In the context of facial image analysis, the 3D Morphable Model (3DMM) [2] is ...", "dateLastCrawled": "2022-02-02T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Why hasn&#39;t the <b>Bayesian network been as successful</b> as the Deep <b>Neural</b> ...", "url": "https://www.quora.com/Why-hasnt-the-Bayesian-network-been-as-successful-as-the-Deep-Neural-Network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-hasnt-the-<b>Bayesian-network-been-as-successful</b>-as-the-Deep...", "snippet": "Answer (1 of 5): Well, the definition of \u201csuccessful\u201d is important, here. <b>Bayesian</b> networks are arguably more successful than deep <b>neural</b> networks to date. They are widely applied across industries and <b>can</b> readily be used for inference, modelling, and prediction. Presumably your question is real...", "dateLastCrawled": "2022-01-15T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Bayesian Optimization Approach for Analog Circuit</b> Synthesis Using ...", "url": "https://deepai.org/publication/bayesian-optimization-approach-for-analog-circuit-synthesis-using-neural-network", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>bayesian-optimization-approach-for-analog-circuit</b>...", "snippet": "In this paper, we propose a <b>Bayesian optimization approach for analog circuit synthesis using neural network</b>. We use deep <b>neural</b> <b>network</b> to extract good feature representations, and then define Gaussian process using the extracted features. Model averaging method is applied to improve the quality of uncertainty prediction. <b>Compared</b> to Gaussian process model with explicitly defined kernel functions, the <b>neural</b>-<b>network</b>-based Gaussian process model <b>can</b> automatically learn a kernel function from ...", "dateLastCrawled": "2022-01-04T11:26:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>machine</b> <b>learning</b> approach to <b>Bayesian</b> parameter estimation | npj ...", "url": "https://www.nature.com/articles/s41534-021-00497-w", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-021-00497-w", "snippet": "The parameter estimation discussed in this manuscript is divided in two parts: i) a <b>neural</b> <b>network</b> is trained and ii) <b>Bayesian</b> estimation performed on a test set, which we detail below.", "dateLastCrawled": "2022-02-03T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "9.7. <b>Bayesian</b> <b>neural</b> networks \u2014 <b>Learning</b> from data", "url": "https://furnstahl.github.io/Physics-8820/notebooks/Machine_learning/Bayesian_neural_networks_tif285.html", "isFamilyFriendly": true, "displayUrl": "https://furnstahl.github.io/.../<b>Machine</b>_<b>learning</b>/<b>Bayesian</b>_<b>neural</b>_<b>networks</b>_tif285.html", "snippet": "<b>Bayesian</b> <b>neural</b> networks differ from plain <b>neural</b> networks in that their weights are assigned a probability distribution instead of a single value or point estimate. These probability distributions describe the uncertainty in weights and can be used to estimate uncertainty in predictions. Training a <b>Bayesian</b> <b>neural</b> <b>network</b> via variational inference learns the parameters of these distributions instead of the weights directly.", "dateLastCrawled": "2021-12-21T06:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "<b>Bayesian</b> <b>neural</b> networks are best explained using an <b>analogy</b> example. Suppose that instead of a <b>neural</b> <b>network</b>, you have a prediction equation y = (8.5 * x1) + (9.5 * x2) + 2.5 where y is the predicted income of an employee, x1 is normalized age, and x2 is years of job tenure. The predicted income of a 30-year old who has been on the job for 4 years would be y = (8.5 * 3.0) + (9.5 * 4.0) + 2.5 = 64.5 = $64,500. If you feed the same (age, tenure) input of (3.0, 4.0) to the prediction equation ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bayesian</b> <b>Neural Network</b> Series Post 2: Background Knowledge | by Kumar ...", "url": "https://medium.com/neuralspace/bayesian-neural-network-series-post-2-background-knowledge-fdec6ac62d43", "isFamilyFriendly": true, "displayUrl": "https://medium.com/<b>neural</b>space/<b>bayesian</b>-<b>neural-network</b>-series-post-2-background...", "snippet": "I will try to brief the <b>neural</b> networks <b>analogy</b> with the brain and will spend more time explaining the Probabilistic <b>Machine</b> <b>Learning</b> segments that we will work on in future. Brain Analogies. A ...", "dateLastCrawled": "2022-01-30T12:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep <b>neural</b> <b>network</b> models, and it has been used for conducting ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bayesian Belief Network in Artificial Intelligence</b> - Javatpoint", "url": "https://www.javatpoint.com/bayesian-belief-network-in-artificial-intelligence", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>bayesian-belief-network-in-artificial-intelligence</b>", "snippet": "<b>Bayesian Belief Network in artificial intelligence</b>. <b>Bayesian</b> belief <b>network</b> is key computer technology for dealing with probabilistic events and to solve a problem which has uncertainty. We can define a <b>Bayesian</b> <b>network</b> as: &quot;A <b>Bayesian</b> <b>network</b> is a probabilistic graphical model which represents a set of variables and their conditional ...", "dateLastCrawled": "2022-02-02T21:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "ML MCQ all 5 - <b>Machine</b> <b>Learning</b> MCQ&#39;s - KCS 052 - StuDocu", "url": "https://www.studocu.com/in/document/dr-apj-abdul-kalam-technical-university/machine-learning-techniques/ml-mcq-all-5-machine-learning-mcqs/16412586", "isFamilyFriendly": true, "displayUrl": "https://www.studocu.com/.../ml-mcq-all-5-<b>machine</b>-<b>learning</b>-mcqs/16412586", "snippet": "Which of the following is not numerical functions in the various function representation of <b>Machine</b> <b>Learning</b>? (A) <b>Neural</b> <b>Network</b> (B) Support Vector Machines (C) Case-based (D) Linear Regression. Answer Correct option is C . FIND-S Algorithm starts from the most specific hypothesis and generalize it by considering only ____ examples. (A) Negative (B) Positive (C) Negative or Positive (D) None of the above; Answer Correct option is B. FIND-S algorithm ignores ___ examples. (A) Negative (B ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Neural Networks and Learning Machines</b> - uniba.sk", "url": "https://dai.fmph.uniba.sk/courses/NN/haykin.neural-networks.3ed.2009.pdf", "isFamilyFriendly": true, "displayUrl": "https://dai.fmph.uniba.sk/courses/NN/haykin.<b>neural</b>-<b>networks</b>.3ed.2009.pdf", "snippet": "<b>Neural Networks and Learning Machines</b> Third Edition Simon Haykin McMaster University Hamilton, Ontario, Canada New York Boston San Francisco London Toronto Sydney Tokyo Singapore Madrid Mexico City Munich Paris Cape Town Hong Kong Montreal. Library of Congress Cataloging-in-Publication Data Haykin, Simon <b>Neural networks and learning machines</b> / Simon Haykin.\u20143rd ed. p. cm. Rev. ed of: <b>Neural</b> networks. 2nd ed., 1999. Includes bibliographical references and index. ISBN-13: 978-0-13-147139-9 ...", "dateLastCrawled": "2022-02-02T00:48:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bayesian neural network)  is like +(traditional neural network)", "+(bayesian neural network) is similar to +(traditional neural network)", "+(bayesian neural network) can be thought of as +(traditional neural network)", "+(bayesian neural network) can be compared to +(traditional neural network)", "machine learning +(bayesian neural network AND analogy)", "machine learning +(\"bayesian neural network is like\")", "machine learning +(\"bayesian neural network is similar\")", "machine learning +(\"just as bayesian neural network\")", "machine learning +(\"bayesian neural network can be thought of as\")", "machine learning +(\"bayesian neural network can be compared to\")"]}