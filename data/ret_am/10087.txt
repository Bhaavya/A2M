{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "DeepGoal: <b>Learning</b> <b>to drive</b> with <b>driving intention from human control</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0921889019308048", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0921889019308048", "snippet": "A human-<b>like</b> visual navigation skill based on GPS signal can be transferred to autonomous driving. ... There are three criteria used for evaluation on intention generation: <b>IoU</b>, \u0394 y a w, and E (l 2). <b>IoU</b> is the intersection over union between predicted driving intention and human demonstration. It is a widely used metric for visual area prediction tasks, which shows both the correlation and the relative scale to ground truth. \u0394 y a w is the angle difference of driving directions between ...", "dateLastCrawled": "2021-09-04T20:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Guide to <b>Car</b> <b>Detection</b> using YOLO | by Bryan Tan | Towards Data Science", "url": "https://towardsdatascience.com/guide-to-car-detection-using-yolo-48caac8e4ded", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/guide-to-<b>car</b>-<b>detection</b>-using-yolo-48caac8e4ded", "snippet": "As a critical component of this project, you\u2019d <b>like</b> to first build <b>a car</b> <b>detection</b> system. To collect data, you\u2019ve mounted a camera to the hood of the <b>car</b>\u2026 Get started. Open in app. Sign in. Get started. Follow. 618K Followers \u00b7 Editors&#39; Picks Features Deep Dives Grow Contribute. About. Get started. Open in app. Guide to <b>Car</b> <b>Detection</b> using YOLO. In-depth concept of the YOLO algorithm \u2014 bounding boxes, non-max suppression and <b>IOU</b>. Bryan Tan. May 2, 2020 \u00b7 13 min read. Real-time ...", "dateLastCrawled": "2022-02-03T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Intersection over Union (<b>IoU</b>) for object detection - PyImageSearch", "url": "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-<b>iou</b>-for-object-detection", "snippet": "If you have performed any previous machine <b>learning</b> in your career, ... The reason for this is because our HOG + Linear SVM detector likely couldn\u2019t \u201cfind\u201d the <b>car</b> in the lower layers of the image pyramid and instead fired near the top of the pyramid where the image is much smaller. The following example is an extremely good detection with an Intersection over Union score of 0.9472: Figure 9: Measuring object detection performance using Intersection over Union. Notice how the predicted ...", "dateLastCrawled": "2022-02-02T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Two Minute Drill: <b>Get an IOU for Everything You Do</b>", "url": "https://www.crossroads.sandler.com/blog/get_an_IOU", "isFamilyFriendly": true, "displayUrl": "https://www.crossroads.sandler.com/blog/get_an_<b>IOU</b>", "snippet": "\u201cIt\u2019s <b>like</b> with that publishing company. They needed a part for the press, and I took all day Saturday <b>to drive</b> out to the warehouse and back to get it for them. All I got was a thank-you. That\u2019s it. Nothing more.\u201d \u201cWhat else?\u201d she inquired. \u201cWell, three weeks ago I filled up my <b>car</b> with that special proofing paper for my advertising", "dateLastCrawled": "2022-01-01T00:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning</b> to Simulate. How <b>learning</b> to simulate better\u2026 | by Nataniel ...", "url": "https://towardsdatascience.com/learning-to-simulate-c53d8b393a56", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>learning</b>-to-simulate-c53d8b393a56", "snippet": "We monitor the validation <b>Car</b> <b>IoU</b> metric for each of these networks and pick the one with highest validation reward. We then test it on the unseen KITTI test set . We train <b>learning</b> to simulate for 600 iterations and obtain <b>a Car</b> <b>IoU</b> (widespread segmentation metric) of 0.579, much higher than the 0.480 achieved using the random parameter baseline (random params).", "dateLastCrawled": "2022-01-31T14:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "neural-networks-and-deep-<b>learning</b>/Autonomous driving application <b>Car</b> ...", "url": "https://github.com/fanghao6666/neural-networks-and-deep-learning/blob/master/py/Autonomous%20driving%20application%20Car%20detection.py.html", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/fanghao6666/neural-networks-and-deep-<b>learning</b>/blob/master/py...", "snippet": "# You are working on a self-driving <b>car</b>. As a critical component of this project, you&#39;d <b>like</b> to first build <b>a car</b> detection system. To collect data, you&#39;ve mounted a camera to the hood (meaning the front) of the <b>car</b>, which takes pictures of the road ahead every few seconds while you <b>drive</b> around. # # &lt; center &gt;", "dateLastCrawled": "2022-02-01T20:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Autonomous driving application - <b>Car</b> detection - v3", "url": "https://datascience-enthusiast.com/DL/Autonomous_driving_Car_detection.html", "isFamilyFriendly": true, "displayUrl": "https://datascience-enthusiast.com/DL/<b>Autonomous_driving_Car_detection</b>.html", "snippet": "As a critical component of this project, you&#39;d <b>like</b> to first build <b>a car</b> detection system. To collect data, you&#39;ve mounted a camera to the hood (meaning the front) of the <b>car</b>, which takes pictures of the road ahead every few seconds while you <b>drive</b> around. Pictures taken from <b>a car</b>-mounted camera while driving around Silicon Valley.", "dateLastCrawled": "2022-01-29T23:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Autonomous_driving_application_<b>Car</b>_detection_v3a", "url": "https://kawshikbuet17.github.io/Coursera-Deep-Learning/04-Convolutional-Neural-Networks/Codes/week3/Car%20detection%20for%20Autonomous%20Driving/Autonomous_driving_application_Car_detection_v3a.html", "isFamilyFriendly": true, "displayUrl": "https://kawshikbuet17.github.io/Coursera-Deep-<b>Learning</b>/04-Convolutional-Neural-Networks...", "snippet": "As a critical component of this project, you&#39;d <b>like</b> to first build <b>a car</b> detection system. To collect data, you&#39;ve mounted a camera to the hood (meaning the front) of the <b>car</b>, which takes pictures of the road ahead every few seconds while you <b>drive</b> around. Pictures taken from <b>a car</b>-mounted camera while driving around Silicon Valley.", "dateLastCrawled": "2022-02-02T18:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Autonomous Driving \u2013 Car detection with</b> YOLO Model with Keras in Python ...", "url": "https://sandipanweb.wordpress.com/2018/03/11/autonomous-driving-car-detection-with-yolo-in-python/", "isFamilyFriendly": true, "displayUrl": "https://<b>sandipanweb</b>.wordpress.com/2018/03/11/<b>autonomous-driving-car-detection-with</b>...", "snippet": "Let\u2019s assume that we are working on a self-driving <b>car</b>. As a critical component of this project, we\u2019d <b>like</b> to first build <b>a car</b> detection system. To collect data, we\u2019ve mounted a camera to the hood (meaning the front) of the <b>car</b>, which takes pictures of the road ahead every few seconds while we <b>drive</b> around. The above pictures are taken from <b>a car</b>-mounted camera while driving around Silicon Valley. We would <b>like</b> to especially thank <b>drive</b>.ai for providing this dataset! <b>Drive</b>.ai is a ...", "dateLastCrawled": "2022-02-03T17:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Craving Cars : cars", "url": "https://www.reddit.com/r/cars/comments/g6iou2/craving_cars/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>car</b>s/comments/g6<b>iou</b>2/craving_<b>car</b>s", "snippet": "My problem now is that my family is so low income, my dream <b>car</b> of a simple subie seems <b>like</b> a pipe dream. I currently <b>drive</b> an old beat up Crown Victoria, no not the interceptor, and its nice <b>to drive</b> something a little spunky as its v8 certainly still has pep but I just feel locked in. I am not asking for money or even advice. I just ask that if you relate to my story of not being able <b>to drive</b> the nice cars our favorite youtubers or influencers <b>drive</b> that you share your story. 14 comments ...", "dateLastCrawled": "2021-01-10T08:00:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Autonomous_driving_application_<b>Car</b>_detection_v3a", "url": "https://kawshikbuet17.github.io/Coursera-Deep-Learning/04-Convolutional-Neural-Networks/Codes/week3/Car%20detection%20for%20Autonomous%20Driving/Autonomous_driving_application_Car_detection_v3a.html", "isFamilyFriendly": true, "displayUrl": "https://kawshikbuet17.github.io/Coursera-Deep-<b>Learning</b>/04-Convolutional-Neural-Networks...", "snippet": "<b>iou</b>: clarify instructions for finding the intersection. <b>iou</b>: give variable names for all 8 box vertices, for clarity. ... This <b>is similar</b> to Python array indexing, where you can select the last position of an array using arrayname[-1]. Applying max normally collapses the axis for which the maximum is applied. keepdims=False is the default option, and allows that dimension to be removed. We don&#39;t need to keep the last dimension after applying the maximum here. Even though the documentation ...", "dateLastCrawled": "2022-02-02T18:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "DeepGoal: <b>Learning</b> <b>to drive</b> with <b>driving intention from human control</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0921889019308048", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0921889019308048", "snippet": "There are three criteria used for evaluation on intention generation: <b>IoU</b>, \u0394 y a w, and E (l 2). <b>IoU</b> is the intersection over union between predicted driving intention and human demonstration. It is a widely used metric for visual area prediction tasks, which shows both the correlation and the relative scale to ground truth.", "dateLastCrawled": "2021-09-04T20:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Intersection over Union (<b>IoU</b>) for object detection - PyImageSearch", "url": "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-<b>iou</b>-for-object-detection", "snippet": "Figure 2: Computing the Intersection over Union is as simple as dividing the area of overlap between the bounding boxes by the area of union (thank you to the excellent Pittsburg HW4 assignment for the inspiration for this figure). Examining this equation you can see that Intersection over Union is simply a ratio. In the numerator we compute the area of overlap between the predicted bounding box and the ground-truth bounding box.. The denominator is the area of union, or more simply, the ...", "dateLastCrawled": "2022-02-02T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The Data Science Behind <b>Self-Driving</b> Cars | by Fei Qi | Medium", "url": "https://medium.com/@feiqi9047/the-data-science-behind-self-driving-cars-eb7d0579c80b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@feiqi9047/the-data-science-behind-<b>self-driving</b>-<b>car</b>s-eb7d0579c80b", "snippet": "Using Machine <b>Learning</b> and Deep <b>Learning</b>, and AI, it really is an iterative process where the cycle of collecting data to interpreting the data to training the algorithm is endless. In other words ...", "dateLastCrawled": "2022-01-27T14:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning</b> to Simulate. How <b>learning</b> to simulate better\u2026 | by Nataniel ...", "url": "https://towardsdatascience.com/learning-to-simulate-c53d8b393a56", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>learning</b>-to-simulate-c53d8b393a56", "snippet": "We monitor the validation <b>Car</b> <b>IoU</b> metric for each of these networks and pick the one with highest validation reward. We then test it on the unseen KITTI test set . We train <b>learning</b> to simulate for 600 iterations and obtain <b>a Car</b> <b>IoU</b> (widespread segmentation metric) of 0.579, much higher than the 0.480 achieved using the random parameter baseline (random params).", "dateLastCrawled": "2022-01-31T14:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Meta <b>Learning</b> \u2014 <b>Learning</b> To Learn | by McGroce - Machine Grocery | Medium", "url": "https://medium.com/@mcgrocedata/meta-learning-learning-to-learn-5ccb5de6b7e6", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@mcgrocedata/meta-<b>learning</b>-<b>learning</b>-to-learn-5ccb5de6b7e6", "snippet": "<b>Learning</b> <b>To Drive</b> <b>A Car</b> In 20 Minutes This paper showed the self-driving <b>car</b> community that by reshaping reward and MDP of the problem faster training could be made with the monocular camera and a ...", "dateLastCrawled": "2021-05-25T16:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The Meaning Of <b>Iou</b>", "url": "https://groups.google.com/g/trxiawwl/c/Kn1uA9BdhqU", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/trxiawwl/c/Kn1uA9BdhqU", "snippet": "Your afternoon <b>drive</b> is weave and you eat instant ratification. And, fulfil a result, the ECONOMY has been created. Money gonna be called an <b>IOU</b> of sorts, as destination mention has my video above, BUT, counsel does like mean who has strength value under some conspiracy theorists believe. For both types of warrants, redeeming them they be delayed until funds are available. What <b>iou</b> means in hindi, <b>iou</b> meaning in hindi, <b>iou</b> definition, examples and pronunciation of <b>iou</b> in hindi language. An ...", "dateLastCrawled": "2022-01-15T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Object detection for self-driving cars - Deep <b>Learning</b> - <b>HackerEarth Blog</b>", "url": "https://www.hackerearth.com/blog/developers/object-detection-for-self-driving-cars/", "isFamilyFriendly": true, "displayUrl": "https://www.hackerearth.com/blog/developers/object-detection-for-self-driving-<b>car</b>s", "snippet": "We also got an overview of the YOLO (You Look Only Once algorithm). In this blog, we will extend our <b>learning</b> and will dive deeper into the YOLO algorithm. We will learn topics such as intersection over area metrics, non maximal suppression, multiple object detection, anchor boxes, etc. Finally, we will build an object detection detection system for a self-driving <b>car</b> using the YOLO algorithm. We will be using the Berkeley driving dataset to train our model. Data Preprocessing. Before, we ...", "dateLastCrawled": "2022-02-02T16:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Self-Driving-Cars/Module5-Semantic_Segmentation.md at master ... - <b>GitHub</b>", "url": "https://github.com/qiaoxu123/Self-Driving-Cars/blob/master/Part3-Visual_Perception_for_Self-Driving_Cars/Module5-Semantic_Segmentation/Module5-Semantic_Segmentation.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/qiaoxu123/Self-Driving-<b>Car</b>s/blob/master/Part3-Visual_Perception_for...", "snippet": "Lane estimation is the task of estimating where a self-driving <b>car</b> can <b>drive</b> given a drivable surface. Many methods exist in the literature to accomplish this task. For example, some methods directly estimate lane markings from ConvNets to determine where the <b>car</b> can <b>drive</b>. However, for higher-level decision-making, a self-driving <b>car</b> should also be aware of what is at the boundary of the lane. Classes at the boundary of the lame can range from a curb, a road, where opposite traffic resides ...", "dateLastCrawled": "2021-09-08T17:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Vision-based <b>vehicle</b> <b>detection</b> and counting system using deep <b>learning</b> ...", "url": "https://etrr.springeropen.com/articles/10.1186/s12544-019-0390-4", "isFamilyFriendly": true, "displayUrl": "https://etrr.springeropen.com/articles/10.1186/s12544-019-0390-4", "snippet": "The Stanford <b>Car</b> Dataset is a <b>vehicle</b> dataset taken by non-monitoring cameras with a bright <b>vehicle</b> appearance. This dataset includes 19,618 categories of vehicles covering the brands, models, and production years of the vehicles. The Comprehensive Cars Dataset <b>is similar</b> to the Stanford <b>Car</b> Dataset but contains many pictures. The 27,618 images ...", "dateLastCrawled": "2022-01-29T20:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Get an <b>IOU</b> for everything you do - Sandler Training", "url": "https://www.simoninc.sandler.com/blog/Get-an-IOU-for-everything-you-do", "isFamilyFriendly": true, "displayUrl": "https://www.simoninc.sandler.com/blog/Get-an-<b>IOU</b>-for-everything-you-do", "snippet": "However, the offer to do something should always be paired with an <b>IOU</b>. When the offer is paired with the <b>IOU</b>, the customer is making an implied mental contract with you. \u201cI do this for you; you do this for me.\u201d. There are thousands of implied contracts that <b>can</b> be established. A simple lead generation contract . . .", "dateLastCrawled": "2021-12-11T12:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Portland OR Sales Tactic #43: <b>Get An IOU For Everything You Do</b> ...", "url": "https://www.schneider.sandler.com/blog/get_an_IOU_for_everything_you_do", "isFamilyFriendly": true, "displayUrl": "https://www.schneider.sandler.com/blog/<b>get_an_IOU_for_everything_you_do</b>", "snippet": "Getting <b>an IOU for everything you do</b> is as simple as telling the customer you expect one. FREE RESEARCH PAPER. Leading From the Front in Challenging Times. As 2020 closed, we set out to discover the current challenges and changes in operating style faced by sales leaders with the arrival of the COVID-19 pandemic. Download Your FREE report.", "dateLastCrawled": "2021-12-21T08:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Two Minute Drill: <b>Get an IOU for Everything You Do</b>", "url": "https://www.crossroads.sandler.com/blog/get_an_IOU", "isFamilyFriendly": true, "displayUrl": "https://www.crossroads.sandler.com/blog/get_an_<b>IOU</b>", "snippet": "Always do whatever you <b>can</b> to keep a customer for life and, at the same time, create an implied contract so that the customer never expects something for free. <b>THOUGHT</b>: Getting <b>an IOU for everything you do</b> is as simple as telling the customer you expect one.", "dateLastCrawled": "2022-01-01T00:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Autonomous Driving \u2013 Car detection with</b> YOLO Model with Keras in Python ...", "url": "https://sandipanweb.wordpress.com/2018/03/11/autonomous-driving-car-detection-with-yolo-in-python/", "isFamilyFriendly": true, "displayUrl": "https://<b>sandipanweb</b>.wordpress.com/2018/03/11/<b>autonomous-driving-car-detection-with</b>...", "snippet": "In this article, object detection using the very powerful YOLO model will be described, particularly in the context of <b>car</b> detection for autonomous driving. This problem appeared as an assignment in the coursera course Convolution Networks which is a part of the Deep <b>Learning</b> Specialization (taught by Prof. Andrew Ng., from Stanford and deeplearning.ai, the lecture videos corresponding to the YOLO algorithm <b>can</b> be found here).. The problem description is taken straightaway from the ...", "dateLastCrawled": "2022-02-03T17:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The Meaning Of <b>Iou</b>", "url": "https://groups.google.com/g/trxiawwl/c/Kn1uA9BdhqU", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/trxiawwl/c/Kn1uA9BdhqU", "snippet": "Tags: <b>iou</b> meaning in telugu, <b>iou</b> ka matalab telugu me, telugu meaning of <b>iou</b>, <b>iou</b> meaning dictionary. However, conscious <b>thought</b>, necessary <b>can</b> concrete the astrological information of <b>IOU</b> acronym in Astrology. In either fix, these Fed IOUs are slippery most negotiable in the economy. To certain, click the pepper. What slot the definition of <b>IOU</b> acronym in Chat? Infoplease knows the value but having sources you bake trust. This mindboggling English to Hindi dictionary surely enhance your ...", "dateLastCrawled": "2022-01-15T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Iou Ideas For Husband</b> - carolinajd.com", "url": "https://carolinajd.com/iou-ideas-for-husband", "isFamilyFriendly": true, "displayUrl": "https://<b>car</b>olinajd.com/<b>iou-ideas-for-husband</b>", "snippet": "Take out and <b>drive</b> him or arranged pursuant to hold onto the larger number of things fresh and is. Count on the logic required to school as a night. Goes around the same media engagement present for adults of. Grueling day you from <b>iou</b> ideas husband, we are the grossest thing with your own after the size, i personalize the corner. January that comes with and everything she <b>can</b> both enjoy together, mothers day coupons that are often the thing. Newsletter to be printed material will be sure he ...", "dateLastCrawled": "2021-12-20T07:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Now is <b>the Time for Reinforcement Learning on Real Robots</b>", "url": "https://alexgkendall.com/reinforcement_learning/now_is_the_time_for_reinforcement_learning_on_real_robots/", "isFamilyFriendly": true, "displayUrl": "https://alexgkendall.com/reinforcement_<b>learning</b>/now_is_the_time_for_reinforcement...", "snippet": "first example of deep reinforcement <b>learning</b> on a self-driving <b>car</b>, <b>learning</b> to lane-follow from 11 episodes of training data. sim2real, where we demonstrated that it is possible to train a robot in simulation, then transfer the policy to the real-world. We drove <b>a car</b> for 3km+ on UK roads using a policy trained only from labelled simulated data using image-to-image translation techniques. Some of the most important things we learned from this work so far could not have come from studies on ...", "dateLastCrawled": "2022-01-29T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Self-Driving-Cars/Module5-Semantic_Segmentation.md at master ... - <b>GitHub</b>", "url": "https://github.com/qiaoxu123/Self-Driving-Cars/blob/master/Part3-Visual_Perception_for_Self-Driving_Cars/Module5-Semantic_Segmentation/Module5-Semantic_Segmentation.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/qiaoxu123/Self-Driving-<b>Car</b>s/blob/master/Part3-Visual_Perception_for...", "snippet": "Lane estimation is the task of estimating where a self-driving <b>car</b> <b>can</b> <b>drive</b> given a drivable surface. Many methods exist in the literature to accomplish this task. For example, some methods directly estimate lane markings from ConvNets to determine where the <b>car</b> <b>can</b> <b>drive</b>. However, for higher-level decision-making, a self-driving <b>car</b> should also be aware of what is at the boundary of the lane. Classes at the boundary of the lame <b>can</b> range from a curb, a road, where opposite traffic resides ...", "dateLastCrawled": "2021-09-08T17:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Self-Driving-Cars/Module4-2D_Object_Detection.md at master - <b>GitHub</b>", "url": "https://github.com/qiaoxu123/Self-Driving-Cars/blob/master/Part3-Visual_Perception_for_Self-Driving_Cars/Module4-2D_Object_Detection/Module4-2D_Object_Detection.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/qiaoxu123/Self-Driving-<b>Car</b>s/blob/master/Part3-Visual_Perception_for...", "snippet": "Object detection is a top level module required to identify the locations of vehicles, pedestrians, signs, and lights, so our <b>car</b> knows where and how it <b>can</b> <b>drive</b>. This week, we will be going in depth to define the 2D object detection problem, how to apply ConvNets to tackle it, and why the problem of 2D object detection is difficult. We will then explain how object detection is used as input for the 2D object tracking problem, and how to perform the tracking task in the context of self ...", "dateLastCrawled": "2021-11-22T06:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "I don&#39;t like driving or even being in <b>a car</b>! : CasualConversation", "url": "https://www.reddit.com/r/CasualConversation/comments/38ufpr/i_dont_like_driving_or_even_being_in_a_car/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/38ufpr/i_dont_like_driving_or_even_being_in_<b>a_car</b>", "snippet": "Just hate driving. I think I <b>can</b> count the times I&#39;ve driven <b>a car</b> in the last 7 years on one hand. 2. Share. Report Save. level 1 \u00b7 6y. I used have a lot of anxiety while driving, and even now I still do. I&#39;m 24 and still have my permit, but I&#39;m hoping to get my license in a month or two. I think what helped curb my anxiety a lot was the fact that I realized I needed it. Everyone else around me had a license and <b>a car</b>, and it makes things so much easier and opens up new doors. Before I ...", "dateLastCrawled": "2021-09-25T01:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Intersection over Union (<b>IoU</b>) for object detection - PyImageSearch", "url": "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-<b>iou</b>-for-object-detection", "snippet": "Figure 2: Computing the Intersection over Union is as simple as dividing the area of overlap between the bounding boxes by the area of union (thank you to the excellent Pittsburg HW4 assignment for the inspiration for this figure). Examining this equation you <b>can</b> see that Intersection over Union is simply a ratio. In the numerator we compute the area of overlap between the predicted bounding box and the ground-truth bounding box.. The denominator is the area of union, or more simply, the ...", "dateLastCrawled": "2022-02-02T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "DeepGoal: <b>Learning</b> <b>to drive</b> with <b>driving intention from human control</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0921889019308048", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0921889019308048", "snippet": "An innovate <b>learning</b>-based automotive driving system is developed. The system learns from images and low-cost GPS-level route planner to achieve goal-directed driving intention without precise localization. It eases problem complexity for end2end approach and <b>can</b> be efficiently integrated for modular motion planning.", "dateLastCrawled": "2021-09-04T20:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Vision-based <b>vehicle</b> <b>detection</b> and counting system using deep <b>learning</b> ...", "url": "https://etrr.springeropen.com/articles/10.1186/s12544-019-0390-4", "isFamilyFriendly": true, "displayUrl": "https://etrr.springeropen.com/articles/10.1186/s12544-019-0390-4", "snippet": "<b>Compared</b> with the existing public datasets, the proposed dataset contains annotated tiny objects in the image, which provides the complete data foundation for <b>vehicle</b> <b>detection</b> based on deep <b>learning</b>. In the proposed <b>vehicle</b> <b>detection</b> and counting system, the highway road surface in the image is first extracted and divided into a remote area and a proximal area by a newly proposed segmentation method; the method is crucial for improving <b>vehicle</b> <b>detection</b>. Then, the above two areas are placed ...", "dateLastCrawled": "2022-01-29T20:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A DEEP <b>LEARNING</b> APPROACH TO AUTONOMOUS DRIVING IN URBAN ENVIRONMENT", "url": "https://www.scientificbulletin.upb.ro/rev_docs_arhiva/rezf3d_973031.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.scientificbulletin.upb.ro/rev_docs_arhiva/rezf3d_973031.pdf", "snippet": "1989, called ALVINN, <b>a car</b> that used a neural network <b>to drive</b>. These days, advanced systems are able to perform automated driving in diverse and complex conditions [3][4]. The automotive industry has defined six levels of autonomy for cars, starting from Level 0 (no autonomy) to Level 5 (full autonomy). At this moment, the most advanced systems released in production <b>can</b> be matched to an area around Level 3 (Conditional Automation) where we <b>can</b> talk about autonomous 1 PhD Student, Dept. of ...", "dateLastCrawled": "2022-01-16T16:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "YOLO\u2014 Real-Time Object Detection. A simplified explanation of the\u2026 | by ...", "url": "https://medium.com/x8-the-ai-community/yolo-real-time-object-detection-f5022d80560b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/x8-the-ai-community/yolo-real-time-object-detection-f5022d80560b", "snippet": "As you <b>can</b> see that the predicted yellow box is off the <b>car</b> and dissimilar to the shape of the actual box. To tackle this mismatch we slide boxes of different sizes over the image. Also in this ...", "dateLastCrawled": "2021-11-16T00:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Context-driven detection of <b>distracted driving</b> using images from in-<b>car</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S254266052100024X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S254266052100024X", "snippet": "Setting a larger <b>learning</b> rate allows the model to learn fast but it <b>can</b> cause the model to converge too quickly to a sub-optimal solution, whereas setting a smaller <b>learning</b> rate may allow the model to learn more optimal sets of weight but training time increases. Considering these complexities, initially we let our model to learn basic features quickly with a relatively high <b>learning</b> rate. After certain steps, we decreased the <b>learning</b> rate to learn finer-grained features so that accuracy ...", "dateLastCrawled": "2022-02-02T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Vision\u2010based vehicle behaviour analysis: a structured <b>learning</b> approach ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-its.2019.0419", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-its.2019.0419", "snippet": "<b>Compared</b> to the general machine <b>learning</b> model, the structured models allow for more variables and interactions, resulting in a rich model that <b>can</b> represent the complex relationships which exist between image data and quantities of interest. Typical structured models include probability map models , structured random forest models and structured support vector machine models and so on. Structured objects are ubiquitous in nature and <b>drive</b> related computer vision tasks, such as protein ...", "dateLastCrawled": "2021-11-22T05:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Object Detection Using OpenCV</b> YOLO | Great <b>Learning</b>", "url": "https://www.mygreatlearning.com/blog/yolo-object-detection-using-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/yolo-<b>object-detection-using-opencv</b>", "snippet": "<b>IoU</b> for two overlapping boxes. We define a box using its two corners (upper left and lower right): (x1, y1, x2, y2) rather than the midpoint and height/width.Next, we also need to find the coordinates (xi1, yi1, xi2, yi2) of the intersection of two boxes where :xi1 = maximum of the x1 coordinates of the two boxes yi1 = maximum of the y1 coordinates of the two boxes xi2 = minimum of the x2 coordinates of the two boxes yi2 = minimum of the y2 coordinates of the two boxes", "dateLastCrawled": "2022-02-03T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine learning</b>, explained | MIT Sloan", "url": "https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained", "isFamilyFriendly": true, "displayUrl": "https://mitsloan.mit.edu/ideas-made-to-matter/<b>machine-learning</b>-explained", "snippet": "He <b>compared</b> the traditional way of programming computers, or \u201csoftware 1.0,\u201d to baking, where a recipe calls for precise amounts of ingredients and tells the baker to mix for an exact amount of time. Traditional programming similarly requires creating detailed instructions for the computer to follow. But in some cases, writing a program for the machine to follow is time-consuming or impossible, such as training a computer to recognize pictures of different people. While humans <b>can</b> do ...", "dateLastCrawled": "2022-02-02T11:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Vehicle <b>Number</b> Plate Detection and OCR (TCS HUMAIN 2019) | by Mehul ...", "url": "https://medium.com/data-science-in-your-pocket/vehicle-number-plate-detection-and-ocr-tcs-humain-2019-a253019e52a1", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-in-your-pocket/vehicle-<b>number</b>-plate-detection-and-ocr...", "snippet": "This problem <b>can</b> be tackled using the Object Detection approach where we need to train our model using the <b>car</b>/other vehicle images with <b>number</b> plates. Extracting text from the detected <b>Number</b> Plate .", "dateLastCrawled": "2022-01-31T18:19:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Difference Between <b>Iou</b> And Map", "url": "https://groups.google.com/g/wjtvxlz/c/V9yHAwM4mAQ", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/wjtvxlz/c/V9yHAwM4mAQ", "snippet": "When a difference between these parts of using <b>machine</b> <b>learning</b> images using generated different <b>iou</b> is limited support for help debug in. It harder for different. It is bleak if you want its use darknet with a GPU. The architectures discussed so vivid are heard much designed for accuracy and noun for speed. The differences btw appearance changes caused by a scan across many places such as discussed together and autonomous driving scenarios of. Renters still owe landlords back rent. That ...", "dateLastCrawled": "2022-01-20T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>What is intersection over union in deep</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-intersection-over-union-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-intersection-over-union-in-deep</b>-<b>learning</b>", "snippet": "Answer (1 of 2): Generally Intersection over union(<b>IOU</b>) is a measure of overlap between two bounding box . In computer vision it is used for correctly detecting an object.To know object detection first you have to know about object localization . Object localization refers to figuring out where i...", "dateLastCrawled": "2022-01-19T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding the 3 most common loss functions for <b>Machine</b> <b>Learning</b> ...", "url": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for...", "snippet": "A <b>loss function</b> in <b>Machine</b> <b>Learning</b> is a measure of how accurately your ML model is able to predict the expected outcome i.e the ground truth. The <b>loss function</b> will take two items as input: the output value of our model and the ground truth expected value. The output of the <b>loss function</b> is called the loss which is a measure of how well our model did at predicting the outcome. A high value for the loss means our model performed very poorly. A low value for the loss means our model performed ...", "dateLastCrawled": "2022-02-02T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning Gist</b> \u00b7 GitHub", "url": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "snippet": "<b>Machine Learning Gist</b>. GitHub Gist: instantly share code, notes, and snippets. ... to solve one problem - The TV knob <b>analogy</b> and the car <b>analogy</b>. Chain of assumptions in <b>Machine</b> <b>Learning</b> and different knobs to say improve performance on train/dev set. Andrew Ng does not recommend Early stopping, as it is a knob that affects multiple thing at once. Setting up your goal. Set a SINGLE NUMBER for metrics- precision and recall- but these are two numbers, and you ideally need one number. ENTER ...", "dateLastCrawled": "2022-01-29T03:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Calculating IOU of masks using tensorflow</b> : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/ns8c8q/calculating_iou_of_masks_using_tensorflow/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/ns8c8q/calculating_<b>iou</b>_of_masks...", "snippet": "<b>Calculating IOU of masks using tensorflow</b>. Hello! I&#39;m trying to speed up a process from my computer vision pipeline where I calculate <b>IOU</b> of two binary masks by using tensorflow 1.15. I&#39;ll post a snippet of code showing how I&#39;m doing it with numpy and how I&#39;m trying to do it with tensorflow, so far tensorflow is waaaay slower and was hoping someone could point out why that is happening. ...", "dateLastCrawled": "2021-12-28T03:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Explaining <b>precision</b> and <b>recall</b>. The first days and weeks of getting ...", "url": "https://medium.com/@klintcho/explaining-precision-and-recall-c770eb9c69e9", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@klintcho/explaining-<b>precision</b>-and-<b>recall</b>-c770eb9c69e9", "snippet": "The first days and weeks of getting into NLP, I had a hard time grasping the concepts of <b>precision</b>, <b>recall</b> and F1-score. Accuracy is also a metric which is tied to these, as well as micro-<b>precision</b>\u2026", "dateLastCrawled": "2022-01-27T17:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Deep Learning applied to Follow-Me</b> in robotics | by Bruno Santos ...", "url": "https://towardsdatascience.com/drone-follow-me-ed0d15e62498", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/drone-follow-me-ed0d15e62498", "snippet": "As an <b>analogy</b>, 1x1 convolution layer works like a Fully Connected Layer since combines linearly the depth layers and input a RELU , although reversely to Fully Connected Layers it preserves spatial information. 1x1 convolution. Finally, the decoder is composed by bilinear upsampling layers followed by convolution layer+ batch-normalization and skip connections with encoder layers to improve lost spatial features resolution. Let\u2019s break down these three important concepts: Bilinear ...", "dateLastCrawled": "2022-01-26T12:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Understanding <b>Focal Loss</b> in 5 mins | Medium | VisionWizard", "url": "https://medium.com/visionwizard/understanding-focal-loss-a-quick-read-b914422913e7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/visionwizard/understanding-<b>focal-loss</b>-a-quick-read-b914422913e7", "snippet": "The <b>focal loss</b> gives less weight to easy examples and gives more weight to hard misclassified examples. This, in turn, helps to solve the class imbalance problem.", "dateLastCrawled": "2022-01-29T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine-learned Regularization and Polygonization of Building</b> ...", "url": "https://deepai.org/publication/machine-learned-regularization-and-polygonization-of-building-segmentation-masks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>machine-learned-regularization-and-polygonization</b>-of...", "snippet": "<b>Machine-learned Regularization and Polygonization of Building Segmentation Masks</b>. 07/24/2020 \u2219 by Stefano Zorzi, et al. \u2219 1 \u2219 share . We propose a <b>machine</b> <b>learning</b> based approach for automatic <b>regularization and polygonization of building segmentation masks</b>. Taking an image as input, we first predict building segmentation maps exploiting generic fully convolutional network (FCN).", "dateLastCrawled": "2021-12-01T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "13.4. <b>Anchor</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/anchor.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>anchor</b>.html", "snippet": "After changing the shape of the <b>anchor</b> box variable Y to (image height, image width, number of <b>anchor</b> boxes centered on the same pixel, 4), we can obtain all the <b>anchor</b> boxes centered on a specified pixel position. In the following, we access the first <b>anchor</b> box centered on (250, 250). It has four elements: the \\((x, y)\\)-axis coordinates at the upper-left corner and the \\((x, y)\\)-axis coordinates at the lower-right corner of the <b>anchor</b> box.The coordinate values of both axes are divided by ...", "dateLastCrawled": "2022-01-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Know Your English | Fireman (Steam Engine) | Stress (Linguistics)", "url": "https://es.scribd.com/document/49395857/Know-Your-English", "isFamilyFriendly": true, "displayUrl": "https://es.scribd.com/document/49395857/Know-Your-English", "snippet": "The \u2018ct&#39; is like the \u2018sh&#39; in \u2018ship&#39; and \u2018shape&#39;, and the \u2018<b>iou&#39; is like</b> the \u2018a&#39; in \u2018china&#39;. The word is pronounced \u2018ram-BUNK-shes&#39; with the stress on the second syllable. When you refer to a child or a puppy as being rambunctious, you mean that they are full of youthful energy, and therefore somewhat difficult to control. The word can also be used to mean very noisy and disorderly. Some people say that the word is an alteration of \u2018rumbustious&#39;. *The rambunctious entertainer ...", "dateLastCrawled": "2021-11-20T18:01:00.0000000Z", "language": "es", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Hindu Kye Final-9!10!2013 | Misdemeanor | Stress (Linguistics) - Scribd", "url": "https://www.scribd.com/document/234733183/The-Hindu-Kye-Final-9-10-2013", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/234733183/<b>The-Hindu-Kye-Final-9-10-2013</b>", "snippet": "The Hindu Kye Final-9!10!2013 - Free ebook download as PDF File (.pdf), Text File (.txt) or read book online for free. This file is the consolidated collection from The Hindu&#39;s Know Your English by Mr.S.Upendran. I feel it is very useful for the readers and develop their vocabulary. The information provided in the coloumns is crystal clear with suitable examples and usage. I am very much thankful to Mr.S.Upendran for this valuable work.", "dateLastCrawled": "2021-12-12T00:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Object-based <b>detection of vehicles</b> using combined <b>optical and elevation</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0924271617303672", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0924271617303672", "snippet": "While for the Zeebrugge dataset, the mean <b>IoU is similar</b> to S (L v \u222a L e), the recall is 0.96. For the Vaihingen dataset, this is reversed, with a recall even slightly above S (L v \u222a L e), but a significantly reduced mean IoU. As all these methods used both data sources, it is evident that data fusion is crucial for high quality results. However, reasonable results could also be obtained even with single sensor data. If the threshold of the IoU is set to 0.5, the distances between the ...", "dateLastCrawled": "2021-12-21T22:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Towards a Meaningful 3D Map Using a</b> 3D Lidar and a Camera", "url": "https://www.researchgate.net/publication/326875064_Towards_a_Meaningful_3D_Map_Using_a_3D_Lidar_and_a_Camera", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/326875064_<b>Towards_a_Meaningful_3D_Map_Using_a</b>...", "snippet": "In this study, we developed semantic 3D mapping by fusing a 3D Lidar with a camera. Our goal. is to create a semantic 3D map with the following seven labels: road, sidewalk, building, fence, pole ...", "dateLastCrawled": "2022-01-31T02:23:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(iou)  is like +(learning to drive a car)", "+(iou) is similar to +(learning to drive a car)", "+(iou) can be thought of as +(learning to drive a car)", "+(iou) can be compared to +(learning to drive a car)", "machine learning +(iou AND analogy)", "machine learning +(\"iou is like\")", "machine learning +(\"iou is similar\")", "machine learning +(\"just as iou\")", "machine learning +(\"iou can be thought of as\")", "machine learning +(\"iou can be compared to\")"]}