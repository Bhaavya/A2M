{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Relations among sensitivity, specificity and predictive values of ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7949469/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7949469", "snippet": "We use two parameters to characterise the behaviour of the <b>test</b>. 8 The sensitivity (Se), also called the <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>), is the probability that the <b>test</b> assigns a diseased individual as <b>positive</b>. It shows how sensitive the <b>test</b> is to detecting the disease. A perfect <b>test</b> has the sensitivity of 100%. However, 100% sensitivity does not mean the <b>test</b> is perfect. For example, a <b>test</b> that always reports <b>positive</b> for any individual in the population has 100% sensitivity but is useless ...", "dateLastCrawled": "2022-01-22T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Measuring Performance: AUPRC</b> and Average Precision \u2013 Glass Box", "url": "https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/", "isFamilyFriendly": true, "displayUrl": "https://glassboxmedicine.com/2019/03/02/<b>measuring-performance-auprc</b>", "snippet": "(Note that \u201crecall\u201d is another name for the <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>). Thus, AUPRC and AUROC both make use of the <b>TPR</b>. For a review of <b>TPR</b>, precision, and decision thresholds, see Measuring Performance: The Confusion Matrix.) The x-axis of a PR curve is the recall and the y-axis is the precision. This is in contrast to ROC curves, where the ...", "dateLastCrawled": "2022-02-03T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is <b>Sensitivity, Specificity, False positive, False negative</b>?", "url": "https://microbenotes.com/sensitivity-specificity-false-positive-false-negative/", "isFamilyFriendly": true, "displayUrl": "https://microbenotes.com/<b>sensitivity-specificity-false-positive-false-negative</b>", "snippet": "It is also known as the <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>), ... It is also known as the <b>True</b> Negative <b>Rate</b> (TNR), i.e the percentage of healthy people who are correctly identified as not having the condition. A <b>test</b> that can identify all sample tests from healthy individuals to be negative is very specific. Therefore, a <b>test</b> with 100% specificity correctly identifies all patients without the disease, while a <b>test</b> with 80% specificity correctly reports 80% of patients without the disease as <b>test</b> ...", "dateLastCrawled": "2022-02-02T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Guide <b>to Evaluation Metrics for Classification Models</b> | Deepchecks", "url": "https://deepchecks.com/a-guide-to-evaluation-metrics-for-classification-models/", "isFamilyFriendly": true, "displayUrl": "https://deepchecks.com/a-guide-<b>to-evaluation-metrics-for-classification-models</b>", "snippet": "Recall, sensitivity or <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>) gives us a measure for how many of the real \u201c<b>true</b>\u201d values we detected. When we want to keep the false positives to a minimum, we want to increase the precision of our model, and when we want to reduce false negatives, we want to increase the recall.", "dateLastCrawled": "2022-02-02T04:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>TRUE</b> <b>POSITIVE</b> <b>RATE</b> - Encyclopedia Information", "url": "https://webot.org/info/en/?search=True_positive_rate", "isFamilyFriendly": true, "displayUrl": "https://webot.org/info/en/?search=<b>True</b>_<b>positive</b>_<b>rate</b>", "snippet": "Sensitivity and specificity mathematically describe the accuracy of a <b>test</b> which reports the presence or absence of a condition, in comparison to a \u2018 Gold Standard\u2019 or definition.. Sensitivity (<b>True</b> <b>Positive</b> <b>Rate</b>) refers to the proportion of those who received a <b>positive</b> result on this <b>test</b> out of those who actually have the condition (when judged by the \u2018Gold Standard\u2019).; Specificity (<b>True</b> Negative <b>Rate</b>) refers to the proportion of those who received a negative result on this <b>test</b> ...", "dateLastCrawled": "2021-11-06T01:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Different metrics to evaluate the performance of a <b>Machine Learning</b> ...", "url": "https://medium.com/analytics-vidhya/different-metrics-to-evaluate-the-performance-of-a-machine-learning-model-90acec9e8726", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/different-metrics-to-evaluate-the-performance-of-a...", "snippet": "Let\u2019s take a <b>medical</b> application where the model diagnoses if a person has <b>cancer</b> or not. Given the person has <b>cancer</b> the model should classify it as TP hence <b>TPR</b> must be very high. Given the ...", "dateLastCrawled": "2022-02-02T16:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Python Code for Evaluation Metrics in <b>ML/AI for Classification Problems</b>", "url": "https://analyticsindiamag.com/evaluation-metrics-in-ml-ai-for-classification-problems-wpython-code/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/evaluation-metrics-in-<b>ml-ai-for-classification-problems</b>...", "snippet": "It is also called the <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>). Recall of negative class is also termed specificity and is defined as the ratio of the <b>True</b> Negative to the number of actual negative cases. It can intuitively be expressed as the ability of the classifier to capture all the negative cases. It is also called <b>True</b> Negative <b>Rate</b> (TNR). In python, sensitivity and specificity can be calculated as. recall_sensitivity = metrics.recall_score(y_<b>test</b>, preds, pos_label=1) recall_specificity = metrics ...", "dateLastCrawled": "2022-02-02T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is <b>true positive and true negative \u2013 confusion matrix</b> | Vikas D More", "url": "https://moredvikas.wordpress.com/2017/09/12/what-is-true-positive-and-true-negative-confusion-matrix/", "isFamilyFriendly": true, "displayUrl": "https://moredvikas.wordpress.com/2017/09/12/what-is-<b>true-positive-and-true-negative</b>...", "snippet": "In other words Recall or Sensitivity or <b>True</b> <b>Positive</b> <b>Rate</b> corresponds to the proportion of <b>positive</b> data points that are correctly considered as <b>positive</b>, with respect to all <b>positive</b> data points. Sensitivity (SN) is calculated as the number of correct <b>positive</b> predictions divided by the total number of positives. It is also called recall (REC) or <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>). The best sensitivity is 1.0, whereas the worst is 0.0.", "dateLastCrawled": "2022-02-03T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Performance Metrics: <b>Confusion matrix</b>, Precision, Recall, and F1 Score ...", "url": "https://towardsdatascience.com/performance-metrics-confusion-matrix-precision-recall-and-f1-score-a8fe076a2262", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/performance-metrics-<b>confusion-matrix</b>-precision-recall...", "snippet": "The <b>test</b> dataset consists of 100 people. <b>Confusion Matrix</b> for tumor detection . <b>True</b> <b>Positive</b> (TP) \u2014 model correctly predicts the <b>positive</b> class (prediction and actual both are <b>positive</b>). In the above example, 10 people who have tumors are predicted positively by the model. <b>True</b> Negative (TN) \u2014 model correctly predicts the negative class (prediction and actual both are negative). In the above example, 60 people who don\u2019t have tumors are predicted negatively by the model. False <b>Positive</b> ...", "dateLastCrawled": "2022-01-29T23:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A Gentle Introduction to Bayes Theorem for <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/bayes-theorem-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/bayes-theorem-for-<b>machine-learning</b>", "snippet": "Bayes Theorem provides a principled way for calculating a conditional probability. It is a deceptively simple calculation, although it can be used to easily calculate the conditional probability of events where intuition often fails. Although it is a powerful tool in the field of probability, Bayes Theorem is also widely used in the field of <b>machine learning</b>. Including its use in a", "dateLastCrawled": "2022-01-28T19:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sensitivity vs Specificity</b> | Technology Networks", "url": "https://www.technologynetworks.com/analysis/articles/sensitivity-vs-specificity-318222", "isFamilyFriendly": true, "displayUrl": "https://www.technologynetworks.com/analysis/articles/<b>sensitivity-vs-specificity</b>-318222", "snippet": "The sensitivity of a <b>test</b> is also called the <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>) and is the proportion of samples that are genuinely <b>positive</b> that give a <b>positive</b> result using the <b>test</b> in question. For example, a <b>test</b> that correctly identifies all <b>positive</b> samples in a panel is very sensitive. Another <b>test</b> that only detects 60 % of the <b>positive</b> samples in the panel would be deemed to have lower sensitivity as it is missing positives and giving higher a false negative <b>rate</b> (FNR). Also referred to as ...", "dateLastCrawled": "2022-01-27T20:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Measuring Performance: AUPRC</b> and Average Precision \u2013 Glass Box", "url": "https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/", "isFamilyFriendly": true, "displayUrl": "https://glassboxmedicine.com/2019/03/02/<b>measuring-performance-auprc</b>", "snippet": "(Note that \u201crecall\u201d is another name for the <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>). Thus, AUPRC and AUROC both make use of the <b>TPR</b>. For a review of <b>TPR</b>, precision, and decision thresholds, see Measuring Performance: The Confusion Matrix.) The x-axis of a PR curve is the recall and the y-axis is the precision. This is in contrast to ROC curves, where the ...", "dateLastCrawled": "2022-02-03T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Multi- class classification of breast <b>cancer</b> abnormalities using Deep ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8389446/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8389446", "snippet": "In the training process, a number of metrics were used such as <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>), number of epochs, accuracy, data points, <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>), false negative <b>rate</b> (FNR) and false <b>positive</b> <b>rate</b> (FPR). The proposed machine learning method provided classification performance of 93.75%. In addition, K-fold cross validation was also used to confirm the validity of the results.", "dateLastCrawled": "2022-01-22T01:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Markers for early <b>detection of cancer: Statistical guidelines</b> for ...", "url": "https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-2-4", "isFamilyFriendly": true, "displayUrl": "https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-2-4", "snippet": "The <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>), or the <b>test</b> sensitivity, is the probability the marker is <b>positive</b> given <b>cancer</b>. The false <b>positive</b> <b>rate</b> (FPR), or 1 \u2013 specificity, is the probability the marker is <b>positive</b> given no <b>cancer</b>. In Table 1, <b>TPR</b> is estimated by 80/100 = .80, and FPR is estimated by 10/1000 = 01. For a perfect <b>test</b>, <b>TPR</b> = 1 and the FPR ...", "dateLastCrawled": "2022-01-14T13:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>TRUE</b> <b>POSITIVE</b> <b>RATE</b> - Encyclopedia Information", "url": "https://webot.org/info/en/?search=True_positive_rate", "isFamilyFriendly": true, "displayUrl": "https://webot.org/info/en/?search=<b>True</b>_<b>positive</b>_<b>rate</b>", "snippet": "Sensitivity and specificity mathematically describe the accuracy of a <b>test</b> which reports the presence or absence of a condition, in comparison to a \u2018 Gold Standard\u2019 or definition.. Sensitivity (<b>True</b> <b>Positive</b> <b>Rate</b>) refers to the proportion of those who received a <b>positive</b> result on this <b>test</b> out of those who actually have the condition (when judged by the \u2018Gold Standard\u2019).; Specificity (<b>True</b> Negative <b>Rate</b>) refers to the proportion of those who received a negative result on this <b>test</b> ...", "dateLastCrawled": "2021-11-06T01:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Estimation of disease prevalence, <b>true</b> <b>positive</b> <b>rate</b>, and false ...", "url": "https://www.researchgate.net/publication/51585210_Estimation_of_disease_prevalence_true_positive_rate_and_false_positive_rate_of_two_screening_tests_when_disease_verification_is_applied_on_only_screen-positives_A_hierarchical_model_using_multi-center", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/51585210_Estimation_of_disease_prevalence...", "snippet": "In this paper, Accuracy (A) is used to evaluate the BAT-MC model. Except for accuracy, false <b>positive</b> <b>rate</b> (<b>TPR</b>) and false <b>positive</b> <b>rate</b> (FPR) are also introduced [51]. These three indicators are ...", "dateLastCrawled": "2021-12-15T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep Learning on MRI Images for Diagnosis of Lung <b>Cancer</b> Spinal Bone ...", "url": "https://www.hindawi.com/journals/cmmi/2021/5294379/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/cmmi/2021/5294379", "snippet": "<b>True</b> <b>positive</b> <b>rate</b> (<b>TPR</b>) was 2.3%, and false negative <b>rate</b> (FNR) was 1.15%. 45 MRI images with hot spots were utilized as <b>test</b> set to detect the segmentation accuracy of CV, maximum between-cluster variance method (OTSU), and region growing algorithm. The results showed that the Dice index and Jaccard coefficient of the CV algorithm were 0.8591 ...", "dateLastCrawled": "2022-01-21T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model correctly predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model correctly predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Different metrics to evaluate the performance of a <b>Machine Learning</b> ...", "url": "https://medium.com/analytics-vidhya/different-metrics-to-evaluate-the-performance-of-a-machine-learning-model-90acec9e8726", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/different-metrics-to-evaluate-the-performance-of-a...", "snippet": "For example, the <b>true</b> class label is <b>positive</b>, Model 1 gives the probability of this point belonging to the <b>positive</b> class as 0.9 whereas Model 2 gives 0.6 probability. Now if we use accuracy as a ...", "dateLastCrawled": "2022-02-02T16:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Predict <b>Imbalanced</b> Classes in Python | Towards Data Science", "url": "https://towardsdatascience.com/how-to-effectively-predict-imbalanced-classes-in-python-e8cd3b5720c4", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-effectively-predict-<b>imbalanced</b>-classes-in-python...", "snippet": "The ROC curve plots a binary classifier\u2019s False <b>Positive</b> <b>Rate</b> (FPR) on the x-axis and <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>, Recall) on the y-axis with for all possible probability threshold values between 0 and 1. <b>TPR</b> is calculated as follows: The default probability threshold value for any classifier is usually 0.5, that is, classify a sample as belonging to the <b>positive</b> class if its predicted probability is greater than 0.5. However, this default assumption should not be used for <b>imbalanced</b> datasets ...", "dateLastCrawled": "2022-02-02T20:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The Use of Diagnostic Tests: A Probabilistic Approach - Assessment of ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK235178/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK235178", "snippet": "One measure is called the sensitivity of the <b>test</b> (<b>true</b>-<b>positive</b> <b>rate</b>, or <b>TPR</b>). It represents the likelihood of a <b>positive</b> <b>test</b> in a diseased person, as is shown in the following equation: Example: There have been many studies of the exercise electrocardiogram. In these studies, a patient with chest pain undergoes both the exercise electrocardiogram and a definitive <b>test</b> for coronary artery disease, the coronary arteriogram. About 70 percent of patients who had a <b>positive</b> arteriogram also ...", "dateLastCrawled": "2022-01-29T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Sensitivity, Specificity, False positive, False negative</b>?", "url": "https://microbenotes.com/sensitivity-specificity-false-positive-false-negative/", "isFamilyFriendly": true, "displayUrl": "https://microbenotes.com/<b>sensitivity-specificity-false-positive-false-negative</b>", "snippet": "It is also known as the <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>), i.e. the percentage of sick persons who are correctly identified as having the condition. Therefore sensitivity is the extent to which actual positives are not overlooked. For example, a <b>test</b> that correctly identifies all <b>positive</b> samples in a panel is a very sensitive <b>test</b> while a <b>test</b> that only detects 80 % of the <b>true</b> <b>positive</b> samples and 20% of the samples are undetected, hence false negatives in the panel. This <b>test</b> will be termed to ...", "dateLastCrawled": "2022-02-02T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bias Mitigation \u2014 Methods</b>. How to build a Fair Model | by ... - Medium", "url": "https://adabhishekdabas.medium.com/bias-mitigation-methods-a2a6618dbdc7", "isFamilyFriendly": true, "displayUrl": "https://adabhishekdabas.medium.com/<b>bias-mitigation-methods</b>-a2a6618dbdc7", "snippet": "Recall or <b>True</b> <b>Positive</b> <b>Rate</b>(<b>TPR</b>) \u2014 Out of all the <b>positive</b> classes, how much we predicted correctly. It should be as high as possible. Recall = TP / (TP + FN) Precision \u2014 Out of all the <b>positive</b> classes we have predicted correctly, how many are actually <b>positive</b>. Precision = TP / (TP + FP) Accuracy \u2014 Out of all the classes predicted, which ones were correctly predicted. Accuracy= TP+TN /(TP+TN+TN+FN) Specificity or <b>True</b> Negative <b>Rate</b>(TNR)\u2014 the proportion of actual negatives that are ...", "dateLastCrawled": "2022-01-27T02:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>ROC Curve</b> - Devopedia", "url": "https://devopedia.org/roc-curve", "isFamilyFriendly": true, "displayUrl": "https://devopedia.org/<b>roc-curve</b>", "snippet": "<b>ROC curve</b> plots <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>) versus False <b>Positive</b> <b>Rate</b> (FPR). <b>TPR</b> is also called recall or sensitivity. <b>TPR</b> is the probability that we detect a signal when it&#39;s present. FPR is the complement of specificity: (1-specificity). FPR is the probability that we detect a signal when it&#39;s not present. Being based on only recall and specificity, <b>ROC curve</b> is independent of prevalence, that is, how common is the condition in the population. An ideal classifier will have an <b>ROC curve</b> that ...", "dateLastCrawled": "2022-02-03T08:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Receiver Operating Characteristic</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/engineering/receiver-operating-characteristic", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/engineering/<b>receiver-operating-characteristic</b>", "snippet": "It is created by plotting the <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>), or Sensitivity, against the false <b>positive</b> <b>rate</b> (FPR), i.e., 1-Specificity, for different threshold settings of a parameter. For every possible parameter value selected to discriminate between two classes or cases, some data will be correctly classified as <b>positive</b> (TP = <b>True</b> <b>Positive</b>) and some incorrectly classified as negative (FN = False Negative fraction). Conversely, some data will be correctly classified as negative (TN = <b>True</b> ...", "dateLastCrawled": "2022-02-02T22:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Measuring Performance: AUPRC</b> and Average Precision \u2013 Glass Box", "url": "https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/", "isFamilyFriendly": true, "displayUrl": "https://glassboxmedicine.com/2019/03/02/<b>measuring-performance-auprc</b>", "snippet": "Precision <b>can</b> <b>be thought</b> of as the ability of the classifier not to wrongly label a negative sample as <b>positive</b> ; Because PR curves don\u2019t use <b>true</b> negatives anywhere, the AUPRC won\u2019t be \u201cswamped\u201d by a large proportion of <b>true</b> negatives in the data. You <b>can</b> use AUPRC on a dataset with 98% negative/2% <b>positive</b> examples, and it will ...", "dateLastCrawled": "2022-02-03T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bootstrap estimated true and false positive</b> rates and ROC curve ...", "url": "https://www.researchgate.net/publication/23629765_Bootstrap_estimated_true_and_false_positive_rates_and_ROC_curve", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/23629765_<b>Bootstrap_estimated_true_and_false</b>...", "snippet": "Recall or sensitivity (<b>true</b> <b>positive</b> <b>rate</b>, <b>TPR</b>) and missing <b>rate</b> (false negative <b>rate</b>, FNR) are the rates at which shadow areas are correctly and incorrectly segmented, respectively, while the ...", "dateLastCrawled": "2021-10-23T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Gentle Introduction to Bayes Theorem for <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/bayes-theorem-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/bayes-theorem-for-<b>machine-learning</b>", "snippet": "Plugging things in, we <b>can</b> calculate the probability of a <b>positive</b> <b>test</b> result (a <b>positive</b> prediction) as the probability of a <b>positive</b> <b>test</b> result given <b>cancer</b> (the <b>true</b> <b>positive</b> <b>rate</b>) multiplied by the base <b>rate</b> for having <b>cancer</b> (the <b>positive</b> class), plus the probability if a <b>positive</b> <b>test</b> result given no <b>cancer</b> (the false <b>positive</b> <b>rate</b>) plus the probability of not having <b>cancer</b> (the negative class).", "dateLastCrawled": "2022-01-28T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Understanding <b>medical</b> tests: sensitivity, specificity, and <b>positive</b> ...", "url": "https://www.healthnewsreview.org/toolkit/tips-for-understanding-studies/understanding-medical-tests-sensitivity-specificity-and-positive-predictive-value/", "isFamilyFriendly": true, "displayUrl": "https://www.healthnewsreview.org/toolkit/tips-for-understanding-studies/understanding...", "snippet": "Understanding <b>medical</b> tests: sensitivity, specificity, and <b>positive</b> predictive value. \u201c Prostate <b>cancer</b> breakthrough as UK team develops more accurate <b>test</b> \u201c. \u201cA Simple 3-Part <b>Test</b> May ...", "dateLastCrawled": "2022-02-03T05:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Accuracy, Recall, <b>Precision</b>, F-Score &amp; Specificity, which to optimize ...", "url": "https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/accuracy-recall-<b>precision</b>-f-score-specificity-which-to...", "snippet": "<b>True</b> <b>positive</b> (TP): Prediction is +ve and X is diabetic, we want that; <b>True</b> negative (TN): Prediction is -ve and X is healthy, we want that too; False <b>positive</b> (FP): Prediction is +ve and X is healthy, false alarm, bad; False negative (FN): Prediction is -ve and X is diabetic, the worst; To remember that, there are 2 tricks - If it starts with <b>True</b> then the prediction was correct whether diabetic or not, so <b>true</b> <b>positive</b> is a diabetic person correctly predicted &amp; a <b>true</b> negative is a healthy ...", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Estimation of disease prevalence, <b>true</b> <b>positive</b> <b>rate</b>, and false ...", "url": "https://www.researchgate.net/publication/51585210_Estimation_of_disease_prevalence_true_positive_rate_and_false_positive_rate_of_two_screening_tests_when_disease_verification_is_applied_on_only_screen-positives_A_hierarchical_model_using_multi-center", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/51585210_Estimation_of_disease_prevalence...", "snippet": "Despite a higher positivity <b>rate</b> among HIV-infected women [224,226], knowledge of cervical <b>cancer</b> screening [75,225,227,228] and uptake [72,75,227,228] is still low.", "dateLastCrawled": "2021-12-15T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How do you interpret a <b>positive</b> likelihood ratio?", "url": "https://psichologyanswers.com/library/lecture/read/34052-how-do-you-interpret-a-positive-likelihood-ratio", "isFamilyFriendly": true, "displayUrl": "https://psichologyanswers.com/.../34052-how-do-you-interpret-a-<b>positive</b>-likelihood-ratio", "snippet": "<b>True</b> <b>positive</b> <b>rate</b> (or sensitivity): <b>TPR</b>=TP/(TP+FN) False <b>positive</b> <b>rate</b>: FPR=FP/(FP+TN) <b>True</b> negative <b>rate</b> (or specificity): TNR=TN/(FP+TN) Which is another term of <b>true</b> <b>positive</b> <b>rate</b>? Definition. In machine learning, the <b>true</b> <b>positive</b> <b>rate</b>, also referred to sensitivity or recall, is used to measure the percentage of actual positives which are correctly identified. Which of the following is an example of a false <b>positive</b>? Some examples of false positives: A pregnancy <b>test</b> is <b>positive</b>, when ...", "dateLastCrawled": "2022-01-29T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is <b>Sensitivity, Specificity, False positive, False negative</b>?", "url": "https://microbenotes.com/sensitivity-specificity-false-positive-false-negative/", "isFamilyFriendly": true, "displayUrl": "https://microbenotes.com/<b>sensitivity-specificity-false-positive-false-negative</b>", "snippet": "It is also known as the <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>), i.e. the percentage of sick persons who are correctly identified as having the condition. Therefore sensitivity is the extent to which actual positives are not overlooked. For example, a <b>test</b> that correctly identifies all <b>positive</b> samples in a panel is a very sensitive <b>test</b> while a <b>test</b> that only detects 80 % of the <b>true</b> <b>positive</b> samples and 20% of the samples are undetected, hence false negatives in the panel. This <b>test</b> will be termed to ...", "dateLastCrawled": "2022-02-02T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 3, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Sensitivity and specificity</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Sensitivity_and_specificity", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Sensitivity_and_specificity</b>", "snippet": "In <b>medical</b> diagnosis, <b>test</b> sensitivity is the ability of a <b>test</b> to correctly identify those with the disease (<b>true</b> <b>positive</b> <b>rate</b>), whereas <b>test</b> specificity is the ability of the <b>test</b> to correctly identify those without the disease (<b>true</b> negative <b>rate</b>). If 100 patients known to have a disease were tested, and 43 <b>test</b> <b>positive</b>, then the <b>test</b> has 43% sensitivity. If 100 with no disease are tested and 96 return a completely negative result, then the <b>test</b> has 96% specificity. Sensitivity and ...", "dateLastCrawled": "2022-02-02T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>TRUE</b> <b>POSITIVE</b> <b>RATE</b> - Encyclopedia Information", "url": "https://webot.org/info/en/?search=True_positive_rate", "isFamilyFriendly": true, "displayUrl": "https://webot.org/info/en/?search=<b>True</b>_<b>positive</b>_<b>rate</b>", "snippet": "Sensitivity and specificity mathematically describe the accuracy of a <b>test</b> which reports the presence or absence of a condition, in comparison to a \u2018 Gold Standard\u2019 or definition.. Sensitivity (<b>True</b> <b>Positive</b> <b>Rate</b>) refers to the proportion of those who received a <b>positive</b> result on this <b>test</b> out of those who actually have the condition (when judged by the \u2018Gold Standard\u2019).; Specificity (<b>True</b> Negative <b>Rate</b>) refers to the proportion of those who received a negative result on this <b>test</b> ...", "dateLastCrawled": "2021-11-06T01:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Deep Learning on MRI Images for Diagnosis of Lung <b>Cancer</b> Spinal Bone ...", "url": "https://www.hindawi.com/journals/cmmi/2021/5294379/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/cmmi/2021/5294379", "snippet": "<b>True</b> <b>positive</b> <b>rate</b> (<b>TPR</b>) was 2.3%, and false negative <b>rate</b> (FNR) was 1.15%. 45 MRI images with hot spots were utilized as <b>test</b> set to detect the segmentation accuracy of CV, maximum between-cluster variance method (OTSU), and region growing algorithm. The results showed that the Dice index and Jaccard coefficient of the CV algorithm were 0.8591 and 0.8002, respectively, which were considerably superior to OTSU (0.6125 and 0.5541) and region growing algorithm (0.7293 and 0.6598). In summary ...", "dateLastCrawled": "2022-01-21T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bootstrap estimated true and false positive</b> rates and ROC curve ...", "url": "https://www.researchgate.net/publication/23629765_Bootstrap_estimated_true_and_false_positive_rates_and_ROC_curve", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/23629765_<b>Bootstrap_estimated_true_and_false</b>...", "snippet": "Recall or sensitivity (<b>true</b> <b>positive</b> <b>rate</b>, <b>TPR</b>) and missing <b>rate</b> (false negative <b>rate</b>, FNR) are the rates at which shadow areas are correctly and incorrectly segmented, respectively, while the ...", "dateLastCrawled": "2021-10-23T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model correctly predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model correctly predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Performance Metrics: <b>Confusion matrix</b>, Precision, Recall, and F1 Score ...", "url": "https://towardsdatascience.com/performance-metrics-confusion-matrix-precision-recall-and-f1-score-a8fe076a2262", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/performance-metrics-<b>confusion-matrix</b>-precision-recall...", "snippet": "The <b>test</b> dataset consists of 100 people. <b>Confusion Matrix</b> for tumor detection. <b>True</b> <b>Positive</b> (TP) \u2014 model correctly predicts the <b>positive</b> class (prediction and actual both are <b>positive</b>). In the above example, 10 people who have tumors are predicted positively by the model. <b>True</b> Negative (TN) \u2014 model correctly predicts the negative class (prediction and actual both are negative). In the above example, 60 people who don\u2019t have tumors are predicted negatively by the model. False <b>Positive</b> ...", "dateLastCrawled": "2022-01-29T23:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Measuring Performance: AUC (AUROC</b>) \u2013 Glass Box", "url": "https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/", "isFamilyFriendly": true, "displayUrl": "https://glassboxmedicine.com/2019/02/23/<b>measuring-performance-auc-auroc</b>", "snippet": "First, you provide to the function sklearn.metrics.roc_curve() the ground truth <b>test</b> set labels as the vector y_<b>true</b> and your model\u2019s predicted probabilities as the vector y_score, to obtain the outputs fpr, <b>tpr</b>, and thresholds. fpr is a vector with the calculated false <b>positive</b> <b>rate</b> for different thresholds; <b>tpr</b> is a vector with the calculated <b>true</b> <b>positive</b> <b>rate</b> for different thresholds; thresholds is a vector with the actual threshold values, and is just provided in case you\u2019d like to ...", "dateLastCrawled": "2022-02-03T07:38:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "It essentially shows the <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>) against the False <b>Positive</b> <b>Rate</b> (FPR) for various threshold values. AUC The Area Under the Curve (AUC), is an aggregated measure of performance of a binary classifier on all possible threshold values (and therefore it is threshold invariant). AUC calculates the area under the ROC curve, and therefore it is between 0 and 1. One way of interpreting AUC is the probability that the model ranks a random <b>positive</b> example more highly than a random ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) A Comparison of Various <b>Machine</b> <b>Learning</b> Algorithms in a ...", "url": "https://www.academia.edu/68902781/A_Comparison_of_Various_Machine_Learning_Algorithms_in_a_Distributed_Denial_of_Service_Intrusion", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/68902781/A_Comparison_of_Various_<b>Machine</b>_<b>Learning</b>_Algorithms...", "snippet": "2) <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>) 4) Decision Tree (DT) This metric calculates how often the model is able to predict a This algorithm uses a tree structure <b>analogy</b> to represent a <b>positive</b> result correctly. Similar to Accuracy, but difference is series of rules that lead to a class or value [16]. It starts with a it only takes <b>positive</b> observation. root node, which is the best predictor. Then, it progresses <b>TPR</b>:: \ud835\udc47\ud835\udc43 through branch nodes to other predictors. Ultimately it reaches \ud835\udc47\ud835\udc43 ...", "dateLastCrawled": "2022-02-05T20:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Evaluation Metric Special ROC-AUC Candra\u2019s blog", "url": "https://saltfarmer.github.io/blog/machine%20learning/Evaluation-Metrics-Special-ROCAUC/", "isFamilyFriendly": true, "displayUrl": "https://saltfarmer.github.io/blog/<b>machine</b> <b>learning</b>/Evaluation-Metrics-Special-ROCAUC", "snippet": "The ROC curve is created by plotting the <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>) against the false <b>positive</b> <b>rate</b> (FPR) at various threshold settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s ...", "dateLastCrawled": "2022-02-03T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Understanding <b>Classification</b> Thresholds Using Isocurves | by Druce ...", "url": "https://towardsdatascience.com/understanding-classification-thresholds-using-isocurves-9e5e7e00e5a2", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-<b>classification</b>-<b>threshold</b>s-using-isocurves...", "snippet": "The <b>true</b>-<b>positive</b> <b>rate</b> (<b>TPR</b>) is the number of <b>true</b> positives / ground truth positives (also called recall or sensitivity). Ground truth positives = <b>true</b> positives + false negatives: <b>TPR</b> = tp / (tp+fn) A false <b>positive</b> is a false observation incorrectly predicted to be <b>true</b>. The false-<b>positive</b> <b>rate</b> (FPR) is the number of false positives / ground truth negatives (1 \u2014 FPR is the specificity). Ground truth negatives = <b>true</b> negatives + false positives: FPR = fp / (tn + fp) The best point to be ...", "dateLastCrawled": "2022-02-02T19:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "More Performance Evaluation Metrics for Classification Problems You ...", "url": "https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/04/performance-evaluation-metrics-classification.html", "snippet": "A ROC curve plots the <b>true</b> <b>positive</b> <b>rate</b> (<b>tpr</b>) versus the false <b>positive</b> <b>rate</b> (fpr) as a function of the model\u2019s threshold for classifying a <b>positive</b>. Given that c is a constant known as decision threshold, the below ROC curve suggests that by default c=0.5, when c=0.2, both <b>tpr</b> and fpr increase.", "dateLastCrawled": "2022-01-26T05:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evaluation Metrics. when it comes to unsupervised <b>learning</b>\u2026 | by Khalid ...", "url": "https://khalidgharib.medium.com/evaluation-metrics-69f3905880b", "isFamilyFriendly": true, "displayUrl": "https://khalidgharib.medium.com/evaluation-metrics-69f3905880b", "snippet": "Recall also known as sensitivity or <b>True</b> <b>Positive</b> <b>Rate</b>(<b>TPR</b>), is saying that when the actual number of positives is 5, ... in other words, the higher the AUC, the better the model is at predicting 0s as 0s and 1s as 1s. By <b>analogy</b>, the Higher the AUC, the better the model is at distinguishing between patients with the disease and no disease. you can see as I mentioned earlier depending on where your threshold or criterion value is placed you can reduce the number of FP but will inevitably ...", "dateLastCrawled": "2022-01-31T06:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Evaluating a <b>Machine</b> <b>Learning</b> Model: Regression and Classification ...", "url": "https://arnavbansal-8232.medium.com/evaluating-a-machine-learning-model-regression-and-classification-metrics-4f2316e180b4", "isFamilyFriendly": true, "displayUrl": "https://arnavbansal-8232.medium.com/evaluating-a-<b>machine</b>-<b>learning</b>-model-regression-and...", "snippet": "<b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> plays a vital role in all this. ... This <b>analogy</b> is <b>true</b> only when we have balanced data, meaning the number of rows for each class should be the same. Contradicting this <b>analogy</b> one can say that for a binary classification algorithm if we have 100 samples, where 90 denote one class, and the remaining 10 samples denote another class. In that case our <b>analogy</b> fails. (here, we can easily get 90% accuracy by just giving all samples to first class, which seems ...", "dateLastCrawled": "2022-01-05T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Evaluation metric for Supervised <b>Learning</b>: | by Anuganti Suresh | Medium", "url": "https://anugantisuresh.medium.com/evaluation-metric-for-supervised-learning-ba063f1bb1af", "isFamilyFriendly": true, "displayUrl": "https://anugantisuresh.medium.com/evaluation-metric-for-supervised-<b>learning</b>-ba063f1bb1af", "snippet": "A higher <b>TPR</b> and a lower FNR is desirable since we want to correctly classify the <b>positive</b> class. The area under the curve represents the area under the curve when the false <b>positive</b> <b>rate</b> is plotted against the <b>True</b> <b>positive</b> <b>rate</b> as below. AUC ranges between 0 and 1. A value of 0 means 100% prediction of the model is incorrect. A value of 1 ...", "dateLastCrawled": "2022-01-06T20:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is the AUC \u2014 <b>ROC</b> Curve?. AUC-<b>ROC</b> CURVE | CONFUSION MATRIX |\u2026 | by ...", "url": "https://medium.com/computer-architecture-club/what-is-the-auc-roc-curve-47fbdcbf7a4a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/computer-architecture-club/what-is-the-auc-<b>roc</b>-curve-47fbdcbf7a4a", "snippet": "By <b>analogy</b>, Higher the AUC, ... Sensitivity / <b>TPR</b> (<b>True</b> <b>Positive</b> <b>Rate</b>) / Recall. Sensitivity tells us what proportion of the <b>positive</b> class got correctly classified. A simple example would be to ...", "dateLastCrawled": "2022-01-26T00:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>Machine</b> <b>Learning-Based Data Fusion Approach for Improved Corrosion</b> ...", "url": "https://link.springer.com/article/10.1007/s10712-019-09558-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10712-019-09558-4", "snippet": "The <b>true</b> <b>positive</b> <b>rate</b> of 0.58 marks a performance increase of nearly 20% over the full dataset. The best result achieved with a single feature is by using the relative potential change from the HP method (feature 4). However, with a <b>TPR</b> of 21%, the sensitivity is low. The corrosion detection for the first campaign fails due to a relatively low ...", "dateLastCrawled": "2022-01-22T23:24:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How <b>to calculate the image accuracy through ROC method</b>?", "url": "https://www.researchgate.net/post/How_to_calculate_the_image_accuracy_through_ROC_method", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/How_<b>to_calculate_the_image_accuracy_through_ROC_method</b>", "snippet": "<b>True Positive Rate (TPR) is like</b> a recall and is defined as mathematically . TPR = (TP/TP+FN) False Positive Rate (FPR) is defined as mathematically . FPR = (FP/FP+TN) An ROC curve plots TPR vs ...", "dateLastCrawled": "2022-01-17T03:34:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(true positive rate (tpr))  is like +(medical test for cancer)", "+(true positive rate (tpr)) is similar to +(medical test for cancer)", "+(true positive rate (tpr)) can be thought of as +(medical test for cancer)", "+(true positive rate (tpr)) can be compared to +(medical test for cancer)", "machine learning +(true positive rate (tpr) AND analogy)", "machine learning +(\"true positive rate (tpr) is like\")", "machine learning +(\"true positive rate (tpr) is similar\")", "machine learning +(\"just as true positive rate (tpr)\")", "machine learning +(\"true positive rate (tpr) can be thought of as\")", "machine learning +(\"true positive rate (tpr) can be compared to\")"]}