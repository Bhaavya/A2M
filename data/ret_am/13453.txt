{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "New submissions for Mon, 18 Oct 21 \u00b7 Issue #153 \u00b7 zoq/arxiv-updates ...", "url": "https://github.com/zoq/arxiv-updates/issues/153", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/zoq/arxiv-updates/issues/153", "snippet": "Aligning with recent work~\\cite{gulrajani2020search}, we find that a straightforward <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) baseline consistently outperforms existing DG methods. We present ablation studies indicating that the choice of backbone, data augmentation, and optimization algorithms overshadows the many tricks and trades explored in the prior art. Our work leads to a new state of the art on the four popular DG datasets, surpassing previous methods by large margins. Furthermore, as a key ...", "dateLastCrawled": "2022-01-12T21:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Hybrid <b>evolutionary</b> algorithms in a SVR traffic flow forecasting model ...", "url": "https://www.sciencedirect.com/science/article/pii/S0096300311001081", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0096300311001081", "snippet": "As mentioned above that traditional artificial intelligent approaches have tended to be based on finding functions to map as training errors over training set, i.e., <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>). However, the <b>ERM</b> does not guarantee good generalization to novel testing data set. To separate the classes with a surface (hyperplane) that maximizes the margin between training data set, SVMs employ the SRM principle that aims to minimize a bound on the generalization error, rather than ...", "dateLastCrawled": "2022-01-26T17:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Training genetic programming classifiers by vicinal-<b>risk</b> <b>minimization</b> ...", "url": "https://link.springer.com/article/10.1007%2Fs10710-014-9222-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10710-014-9222-4", "snippet": "A straightforward illustration of the deficiencies of <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) ... As \\(\\sigma ^2 \\rightarrow 0\\), the Gaussian kernel in tends to a \\(\\delta \\)-<b>function</b> and so the VR tends to the <b>empirical</b> <b>risk</b> in . Thus ER can be understood as a special case of vicinal <b>risk</b>. As \\(\\sigma ^2 \\rightarrow \\infty \\), the value of <b>risk</b> tends to \\(0.5\\) since in the limit, \u2018half\u2019 the kernel extends either side of the decision surface. \\(\\sigma ^2\\) defines a characteristic \u2018scale ...", "dateLastCrawled": "2021-12-10T13:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Adversarial</b> Learning in the Cyber Security Domain | DeepAI", "url": "https://deepai.org/publication/adversarial-learning-in-the-cyber-security-domain", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>adversarial</b>-learning-in-the-cyber-security-domain", "snippet": "The model\u2019s <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) is defined as E (x, y) \u223c D [L o s s (x, y, \u03b8)], where x is the original sample, and y is the original label. By modifying the <b>ERM</b> definition by allowing the adversary to perturb the input x by the scalar value S, <b>ERM</b> is represented by min \u03b8 \u03c1 ( \u03b8 ) : \u03c1 ( \u03b8 ) = E ( x , y ) \u223c D [ m a x \u03b4 \u2208 S L o s s ( x + r , y , \u03b8 ) ] , where \u03c1 ( \u03b8 ) denotes the objective <b>function</b>.", "dateLastCrawled": "2022-01-09T14:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The use of <b>vicinal-risk minimization for training decision trees</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494615001507", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494615001507", "snippet": "Since <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) does not necessarily produce acceptable margins, this motivates us to investigate a superior <b>risk</b> functional and apply it to decision trees. Download : Download full-size image; Fig. 1. Illustration, for the simple case of classifying linearly separable patterns, of the deficiency of minimizing <b>empirical</b> <b>risk</b>. The crosses and circles represent patterns of differing classes. The principal contribution of this paper is to report the induction of decision ...", "dateLastCrawled": "2022-01-14T15:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Training genetic programming classifiers by vicinal</b>-<b>risk</b> <b>minimization</b> ...", "url": "https://www.researchgate.net/publication/271658464_Training_genetic_programming_classifiers_by_vicinal-risk_minimization", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/271658464_Training_genetic_programming...", "snippet": "The <b>fitness</b> <b>function</b> in ... {vapnik1999nature}, is an <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) variant that replaces Dirac masses with vicinal functions. Although there is strong numerical evidence ...", "dateLastCrawled": "2021-09-30T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Utilization of Support Vector <b>Models and Gene Expression Programming</b> ...", "url": "https://link.springer.com/article/10.1007/s13369-020-04441-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13369-020-04441-6", "snippet": "The proposed method works on the principle of the Structural <b>Risk</b> <b>Minimization</b> (SRM) which is superior to <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) techniques and over other modeling methods such as fuzzy systems, ANN, and decision tree. SVM has a great ability to generalize the model, which is the main goal in statistical learning. The major advantage of SVM is that it works on SRM in which inductive principle is used to minimize the <b>risk</b> <b>function</b> w.r.t. parameters viz. confidence interval and ...", "dateLastCrawled": "2021-12-02T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Logistic regression analysis LogR has also been used to investigate the ...", "url": "https://www.coursehero.com/file/p4ctm388/Logistic-regression-analysis-LogR-has-also-been-used-to-investigate-the/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p4ctm388/Logistic-regression-analysis-LogR-has-also...", "snippet": "Logistic regression analysis LogR has also been used to investigate the from FINANCE 1001 at National University of Singapore", "dateLastCrawled": "2021-12-29T03:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Tesis: &quot;<b>Empirical</b> algorithms&quot; \u2013 Grafiati", "url": "https://www.grafiati.com/es/literature-selections/empirical-algorithms/dissertation/", "isFamilyFriendly": true, "displayUrl": "https://www.grafiati.com/es/literature-selections/<b>empirical</b>-algorithms/dissertation", "snippet": "In the first chapter we propose an adaptive variant of stochastic dual coordinate ascent (SDCA) for solving the regularized <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) problem. Our modification consists in allowing the method to adaptively change the probability distribution over the dual variables throughout the iterative process. AdaSDCA achieves a provably better complexity bound than SDCA with the best fixed probability distribution, known as importance sampling. However, it is of a theoretical ...", "dateLastCrawled": "2022-01-26T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "New submissions for Mon, 14 Jun 21 \u00b7 Issue #79 \u00b7 zoq/arxiv-updates \u00b7 GitHub", "url": "https://github.com/zoq/arxiv-updates/issues/79", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/zoq/arxiv-updates/issues/79", "snippet": "PyGAD is designed as a general-purpose optimization library that allows the user to customize the <b>fitness</b> <b>function</b>. Its usage consists of 3 main steps: build the <b>fitness</b> <b>function</b>, create an instance of the pygad.GA class, and calling the pygad.GA.run() method. The library supports training deep learning models created either with PyGAD itself or with frameworks <b>like</b> Keras and PyTorch. Given its stable state, PyGAD is also in active development to respond to the user&#39;s requested features and ...", "dateLastCrawled": "2021-08-07T23:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Multiple-Point Temperature Gradient Algorithm for Ring Laser Gyroscope ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4721698/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4721698", "snippet": "However, in the model training stage, the <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) principle was employed, which could lead to over-fitting or under-fitting, compromising local optimization. To resolve these problems, RLG bias compensation models utilizing SVM have been developed as substitutes. Least-square SVMs (LS-SVMs) used in the system-level temperature compensation of RLG have effectively reduced the temperature variation influence on the RLG bias and improved the accuracy . By choosing the ...", "dateLastCrawled": "2021-11-13T01:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Tikhonov Regularization as a Complexity Measure in Multiobjective ...", "url": "https://1library.net/document/nq7230nz-tikhonov-regularization-complexity-measure-multiobjective-genetic-programming.html", "isFamilyFriendly": true, "displayUrl": "https://1library.net/document/nq7230nz-tikhonov-regularization-complexity-measure...", "snippet": "A straightforward illustration of the deficiencies of <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) is shown in Figure 1 where a small training set of non-separable data is as-sumed drawn from two, arbitrary, two-dimensional class distributions, also shown. The training data are separated by two arbitrary candidate decision surfaces,g1and g2.", "dateLastCrawled": "2022-02-02T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "New submissions for Mon, 18 Oct 21 \u00b7 Issue #153 \u00b7 zoq/arxiv-updates ...", "url": "https://github.com/zoq/arxiv-updates/issues/153", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/zoq/arxiv-updates/issues/153", "snippet": "Aligning with recent work~\\cite{gulrajani2020search}, we find that a straightforward <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) baseline consistently outperforms existing DG methods. We present ablation studies indicating that the choice of backbone, data augmentation, and optimization algorithms overshadows the many tricks and trades explored in the prior art. Our work leads to a new state of the art on the four popular DG datasets, surpassing previous methods by large margins. Furthermore, as a key ...", "dateLastCrawled": "2022-01-12T21:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The use of <b>vicinal-risk minimization for training decision trees</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494615001507", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494615001507", "snippet": "In general, training in machine learning is ill-posed and <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) does not necessarily produce best generalization over an unseen test set, a problem which is exacerbated by small datasets; it is this \u2018small data\u2019 scenario we explicitly address in this paper. The deficiencies of <b>ERM</b> are illustrated in Fig. 1 for the trivial case of classifying linearly separable patterns with a plane. Reduction of the ER to zero can be achieved by any of the infinite number of ...", "dateLastCrawled": "2022-01-14T15:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Model selection in genetic programming</b>", "url": "https://www.researchgate.net/publication/220743408_Model_selection_in_genetic_programming", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220743408_<b>Model_selection_in_genetic_programming</b>", "snippet": "Findings \u2013 The results show that the <b>fitness</b> <b>function</b>, structural <b>risk</b> <b>minimization</b> (SRM) gives better generalization ability of the models than those of other <b>fitness</b> functions. Originality ...", "dateLastCrawled": "2022-01-24T08:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Training genetic programming classifiers by vicinal-<b>risk</b> <b>minimization</b> ...", "url": "https://link.springer.com/article/10.1007%2Fs10710-014-9222-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10710-014-9222-4", "snippet": "A straightforward illustration of the deficiencies of <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) ... As \\(\\sigma ^2 \\rightarrow 0\\), the Gaussian kernel in tends to a \\(\\delta \\)-<b>function</b> and so the VR tends to the <b>empirical</b> <b>risk</b> in . Thus ER can be understood as a special case of vicinal <b>risk</b>. As \\(\\sigma ^2 \\rightarrow \\infty \\), the value of <b>risk</b> tends to \\(0.5\\) since in the limit, \u2018half\u2019 the kernel extends either side of the decision surface. \\(\\sigma ^2\\) defines a characteristic \u2018scale ...", "dateLastCrawled": "2021-12-10T13:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Utilization of Support Vector <b>Models and Gene Expression Programming</b> ...", "url": "https://link.springer.com/article/10.1007/s13369-020-04441-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13369-020-04441-6", "snippet": "The proposed method works on the principle of the Structural <b>Risk</b> <b>Minimization</b> (SRM) which is superior to <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) techniques and over other modeling methods such as fuzzy systems, ANN, and decision tree. SVM has a great ability to generalize the model, which is the main goal in statistical learning. The major advantage of SVM is that it works on SRM in which inductive principle is used to minimize the <b>risk</b> <b>function</b> w.r.t. parameters viz. confidence interval and ...", "dateLastCrawled": "2021-12-02T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Training genetic programming classifiers by vicinal</b>-<b>risk</b> <b>minimization</b> ...", "url": "https://www.researchgate.net/publication/271658464_Training_genetic_programming_classifiers_by_vicinal-risk_minimization", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/271658464_Training_genetic_programming...", "snippet": "The <b>fitness</b> <b>function</b> in ... {vapnik1999nature}, is an <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) variant that replaces Dirac masses with vicinal functions. Although there is strong numerical evidence ...", "dateLastCrawled": "2021-09-30T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "New submissions for Mon, 14 Jun 21 \u00b7 Issue #79 \u00b7 zoq/arxiv-updates \u00b7 GitHub", "url": "https://github.com/zoq/arxiv-updates/issues/79", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/zoq/arxiv-updates/issues/79", "snippet": "For such settings, a line of recent work has proposed the use of a variant of <b>empirical</b> <b>risk</b> <b>minimization</b>(<b>ERM</b>) known as distributionally robust optimization (DRO). In this work, we apply DRO to real, large-scale tasks with subpopulation shift, and observe that DRO performs relatively poorly, and moreover has severe instability. We identify one direct cause of this phenomenon: sensitivity of DRO to outliers in the datasets. To resolve this issue, we propose the framework of DORO, for ...", "dateLastCrawled": "2021-08-07T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Mathematics | Free Full-Text | Machine Learning Modeling of Aerobic ...", "url": "https://www.mdpi.com/2227-7390/8/6/913/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2227-7390/8/6/913/htm", "snippet": "<b>Similar</b> to other <b>evolutionary</b> programs, the genetic expression program is based on scattered information on chromosomes. In a general set of data (population), <b>fitness</b> <b>function</b> is used to evaluate each chromosome and designate a specific value. Different <b>fitness</b> functions in a genetic expression program have been used previously . Suitable chromosomes are picked up in the next generation. These chromosomes are further controlled by particular gene operators after being selected. The process ...", "dateLastCrawled": "2021-12-12T18:08:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Training genetic programming classifiers by vicinal-<b>risk</b> <b>minimization</b> ...", "url": "https://link.springer.com/article/10.1007%2Fs10710-014-9222-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10710-014-9222-4", "snippet": "A straightforward illustration of the deficiencies of <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) ... <b>can</b> be approximated by placing a vicinity <b>function</b> on each training datum\u2014this process <b>can</b> <b>be thought</b> of as either resampling or, equivalently , interpolating \\(\\fancyscript{D}\\). Since the shortcomings of 0/1 loss are due to its discrete nature, smoothing the training set will have the effect of stabilizing the training process. Vapnik described two possible types of vicinity functions, hard and ...", "dateLastCrawled": "2021-12-10T13:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The use of <b>vicinal-risk minimization for training decision trees</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494615001507", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494615001507", "snippet": "In general, training in machine learning is ill-posed and <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) does not necessarily produce best generalization over an unseen test set, a problem which is exacerbated by small datasets; it is this \u2018small data\u2019 scenario we explicitly address in this paper. The deficiencies of <b>ERM</b> are illustrated in Fig. 1 for the trivial case of classifying linearly separable patterns with a plane. Reduction of the ER to zero <b>can</b> be achieved by any of the infinite number of ...", "dateLastCrawled": "2022-01-14T15:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Tikhonov Regularization as a Complexity Measure in Multiobjective ...", "url": "https://1library.net/document/nq7230nz-tikhonov-regularization-complexity-measure-multiobjective-genetic-programming.html", "isFamilyFriendly": true, "displayUrl": "https://1library.net/document/nq7230nz-tikhonov-regularization-complexity-measure...", "snippet": "A straightforward illustration of the deficiencies of <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) is shown in Figure 1 where a small training set of non-separable data is as-sumed drawn from two, arbitrary, two-dimensional class distributions, also shown. The training data are separated by two arbitrary candidate decision surfaces,g1and g2.", "dateLastCrawled": "2022-02-02T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Adaptation, Performance and Vapnik-Chervonenkis Dimension of ...", "url": "https://www.researchgate.net/publication/221009428_Adaptation_Performance_and_Vapnik-Chervonenkis_Dimension_of_Straight_Line_Programs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221009428_Adaptation_Performance_and_Vapnik...", "snippet": "Two statistical methods are compared: model selection based on <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) and model selection based on Structural <b>Risk</b> <b>Minimization</b> (SRM). For this purpose we have ...", "dateLastCrawled": "2021-12-10T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The use of vicinal-<b>risk</b> <b>minimization</b> for training decision trees ...", "url": "https://www.researchgate.net/publication/274263679_The_use_of_vicinal-risk_minimization_for_training_decision_trees", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/274263679_The_use_of_vicinal-<b>risk</b>...", "snippet": "The vicinal <b>risk</b> <b>minimization</b> (VRM) principle is an <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) variant that replaces Dirac masses with vicinal functions. There is strong numerical and theoretical evidence ...", "dateLastCrawled": "2022-02-02T04:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Understanding Machine Learning 9781107057135, 1107057132</b> - DOKUMEN.PUB", "url": "https://dokumen.pub/understanding-machine-learning-9781107057135-1107057132-w-5259393.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>understanding-machine-learning-9781107057135-1107057132</b>-w-5259393.html", "snippet": "We describe the <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>), Structural <b>Risk</b> <b>Minimization</b> (SRM), and Minimum Description Length (MDL) learning rules, which show \u201chow a machine <b>can</b> learn.\u201d We quantify the amount of data needed for learning using the <b>ERM</b>, SRM, and MDL rules and show how learning might fail by deriving a \u201cno-free-lunch\u201d theorem. We also discuss how much <b>computation</b> time is required for learning. In the second part of the book we describe various learning algorithms. For some of ...", "dateLastCrawled": "2022-01-19T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Risk</b> Management in Supply Chains: Using Linear and Non-linear Models ...", "url": "https://ebin.pub/risk-management-in-supply-chains-using-linear-and-non-linear-models-9780367359515-9780429342820.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/<b>risk</b>-management-in-supply-chains-using-linear-and-non-linear-models...", "snippet": "Such frequency-\u00addependent <b>fitness</b> payoffs are the basis of <b>evolutionary</b> game theory (Weibull, 1995) and new attempts to conceive the population as a coherent society (see Millstein, 2006). The <b>fitness</b> of, for example, a poisonous trait that deters predators is a positive <b>function</b> of the frequency of such a trait in the population. If the trait ...", "dateLastCrawled": "2021-12-19T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Bibliography of Support Vector Machine", "url": "http://subasish.github.io/pages/TRB2016/svr.html", "isFamilyFriendly": true, "displayUrl": "subasish.github.io/pages/TRB2016/svr.html", "snippet": "{SVR} is preferred for model construction because it utilizes structural <b>risk</b> <b>minimization</b> (SRM) principle which is superior to <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) theory, used in traditional learning algorithms such as neural networks. A group of 2879 data points was used for model construction and 1176 data points were employed for assessment of {SVR} model. A comparison between measured and {SVR} predicted data showed {SVR} was capable of accurately extract shear wave velocity, hidden in ...", "dateLastCrawled": "2022-01-19T16:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "An adaptive technique to control the load frequency of hybrid ...", "url": "https://link.springer.com/article/10.1007/s00500-019-03779-w", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00500-019-03779-w", "snippet": "In the case of <b>minimization</b> problems, the quality or <b>fitness</b> of a solution <b>can</b> simply be proportional to the minus value of the objective <b>function</b>. The flowchart of the cuckoo search for the proposed approach is described in Fig. 2. The steps of the proposed improved CS algorithm <b>can</b> be summarized as the following.", "dateLastCrawled": "2021-12-28T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "notes-2/Deep Learning.md at master \u00b7 rsantana-isg/notes-2 \u00b7 GitHub", "url": "https://github.com/rsantana-isg/notes-2/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/rsantana-isg/notes-2/blob/master/Deep Learning.md", "snippet": "&quot;The basic reason we get potentially exponential gains in deep neural networks is that we have compositionality of the parameters, i.e., the same parameters <b>can</b> be re-used in many contexts, so O(N) parameters <b>can</b> allow to distinguish O(2^N) regions in input space, whereas with nearest-neighbor-like things, you need O(N) parameters (i.e. O(N) examples) to characterize a <b>function</b> that <b>can</b> distinguish betwen O(N) regions.&quot;", "dateLastCrawled": "2022-01-02T20:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Model selection in genetic programming</b>", "url": "https://www.researchgate.net/publication/220743408_Model_selection_in_genetic_programming", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220743408_<b>Model_selection_in_genetic_programming</b>", "snippet": "Two statistical methods are <b>compared</b>: model selection based on <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) and model selection based on Structural <b>Risk</b> <b>Minimization</b> (SRM). For this purpose we have ...", "dateLastCrawled": "2022-01-24T08:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Multiple-Point Temperature Gradient Algorithm for Ring Laser Gyroscope ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4721698/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4721698", "snippet": "<b>Compared</b> to multiple linear regression (MLR) and traditional RBFNN, the RLG bias compensation result with the modified RBFNN achieved higher accuracy and required less computational time. However, in the model training stage, the <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) principle was employed, which could lead to over-fitting or under-fitting, compromising local optimization. To resolve these problems, RLG bias compensation models utilizing SVM have been developed as substitutes. Least-square SVMs ...", "dateLastCrawled": "2021-11-13T01:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A New Method on Software Reliability Prediction", "url": "https://www.hindawi.com/journals/mpe/2013/385372/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/mpe/2013/385372", "snippet": "It is an approximate implementation to the structure <b>risk</b> <b>minimization</b> (SRM) principle in statistical learning theory, rather than the <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) method . <b>Compared</b> with traditional neural networks, SVM <b>can</b> use the theory of minimizing the structure <b>risk</b> to avoid the problems of excessive study, calamity data, local minimal value, and so on.", "dateLastCrawled": "2022-01-22T05:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "New submissions for Mon, 18 Oct 21 \u00b7 Issue #153 \u00b7 zoq/arxiv-updates ...", "url": "https://github.com/zoq/arxiv-updates/issues/153", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/zoq/arxiv-updates/issues/153", "snippet": "Aligning with recent work~\\cite{gulrajani2020search}, we find that a straightforward <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) baseline consistently outperforms existing DG methods. We present ablation studies indicating that the choice of backbone, data augmentation, and optimization algorithms overshadows the many tricks and trades explored in the prior art. Our work leads to a new state of the art on the four popular DG datasets, surpassing previous methods by large margins. Furthermore, as a key ...", "dateLastCrawled": "2022-01-12T21:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Learning Functions to Study the Benefit of Multitask Learning | DeepAI", "url": "https://deepai.org/publication/learning-functions-to-study-the-benefit-of-multitask-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/learning-<b>functions</b>-to-study-the-benefit-of-multitask...", "snippet": "Maurer et al. used the <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) framework to derive their theoretical results. A general formulation of <b>ERM</b> for multitask learning settings adds the notion of optimizing for multiple tasks jointly. Given T tasks {t 1, t 2,..., t T}, where each task has its own dataset with samples of the form z t = (x t, i, y t, i). Suppose we are given n independent and identically distributed samples for each task and these samples are generated from unknown distributions p t (z ...", "dateLastCrawled": "2021-11-30T10:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The use of <b>vicinal-risk minimization for training decision trees</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494615001507", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494615001507", "snippet": "In general, training in machine learning is ill-posed and <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) does not necessarily produce best generalization over an unseen test set, a problem which is exacerbated by small datasets; it is this \u2018small data\u2019 scenario we explicitly address in this paper. The deficiencies of <b>ERM</b> are illustrated in Fig. 1 for the trivial case of classifying linearly separable patterns with a plane. Reduction of the ER to zero <b>can</b> be achieved by any of the infinite number of ...", "dateLastCrawled": "2022-01-14T15:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Adversarial</b> Learning in the Cyber Security Domain | DeepAI", "url": "https://deepai.org/publication/adversarial-learning-in-the-cyber-security-domain", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>adversarial</b>-learning-in-the-cyber-security-domain", "snippet": "The model\u2019s <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) is defined as E (x, y) \u223c D [L o s s (x, y, \u03b8)], where x is the original sample, and y is the original label. By modifying the <b>ERM</b> definition by allowing the adversary to perturb the input x by the scalar value S, <b>ERM</b> is represented by min \u03b8 \u03c1 ( \u03b8 ) : \u03c1 ( \u03b8 ) = E ( x , y ) \u223c D [ m a x \u03b4 \u2208 S L o s s ( x + r , y , \u03b8 ) ] , where \u03c1 ( \u03b8 ) denotes the objective <b>function</b>.", "dateLastCrawled": "2022-01-09T14:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "New submissions for Mon, 14 Jun 21 \u00b7 Issue #79 \u00b7 zoq/arxiv-updates \u00b7 GitHub", "url": "https://github.com/zoq/arxiv-updates/issues/79", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/zoq/arxiv-updates/issues/79", "snippet": "For such settings, a line of recent work has proposed the use of a variant of <b>empirical</b> <b>risk</b> <b>minimization</b>(<b>ERM</b>) known as distributionally robust optimization (DRO). In this work, we apply DRO to real, large-scale tasks with subpopulation shift, and observe that DRO performs relatively poorly, and moreover has severe instability. We identify one direct cause of this phenomenon: sensitivity of DRO to outliers in the datasets. To resolve this issue, we propose the framework of DORO, for ...", "dateLastCrawled": "2021-08-07T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Improved Accuracy of PSO and <b>DE using Normalization: an Application to</b> ...", "url": "https://thesai.org/Downloads/Volume3No9/Paper_30-Improved_Accuracy_of_PSO_and_DE_using_Normalization_an_Application_to_Stock_Price_Prediction.pdf", "isFamilyFriendly": true, "displayUrl": "https://thesai.org/Downloads/Volume3No9/Paper_30-Improved_Accuracy_of_PSO_and_DE_using...", "snippet": "SRM (Structural <b>Risk</b> <b>Minimization</b>) instead of <b>ERM</b> (<b>Empirical</b> <b>Risk</b> <b>Minimization</b>) which aims at minimizing (1) : min R emp+ \u221a @ A @ A (1) Here, l is number of samples in training set, 1-\u03b7 is the probability of the equation ( (1) \u2265 R pred , R pred is the total <b>risk</b> of prediction) to be true and h is VC dimension to depress overfitting in data processing [25]. SVM parameters: The performance of SVM is based on three basic parameters C (cost penalty), \u03f5 (insensitive loss <b>function</b> parameter ...", "dateLastCrawled": "2022-01-24T14:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Tesis: &quot;<b>Empirical</b> algorithms&quot; \u2013 Grafiati", "url": "https://www.grafiati.com/es/literature-selections/empirical-algorithms/dissertation/", "isFamilyFriendly": true, "displayUrl": "https://www.grafiati.com/es/literature-selections/<b>empirical</b>-algorithms/dissertation", "snippet": "In the first chapter we propose an adaptive variant of stochastic dual coordinate ascent (SDCA) for solving the regularized <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) problem. Our modification consists in allowing the method to adaptively change the probability distribution over the dual variables throughout the iterative process. AdaSDCA achieves a provably better complexity bound than SDCA with the best fixed probability distribution, known as importance sampling. However, it is of a theoretical ...", "dateLastCrawled": "2022-01-26T08:25:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Statistical <b>Learning</b> Theory and the C-Loss cost function", "url": "http://www.cnel.ufl.edu/courses/EEL6814/closs.pdf", "isFamilyFriendly": true, "displayUrl": "www.cnel.ufl.edu/courses/EEL6814/closs.pdf", "snippet": "<b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) principle Let us consider a <b>learning</b> <b>machine</b> x,d are real r.v. with joint distribution P(x,y). F(x) is a function of some parameters w, i.e. f(x,w). d d. <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) principle How can we find the possible best <b>learning</b> <b>machine</b> that generalizes for unseen data from the same distribution? Define the <b>Risk</b> functional as L(.) is called the Loss function, and minimize it w.r.t. w achieving the best possible loss. But we can not do this ...", "dateLastCrawled": "2022-01-28T20:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Empirical</b> <b>Risk</b> <b>Minimization</b> and Stochastic Gradient Descent for ...", "url": "http://proceedings.mlr.press/v89/veitch19a/veitch19a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v89/veitch19a/veitch19a.pdf", "snippet": "where F(Sn) is the <b>empirical</b> distribution.2 The <b>ERM</b> dogma is to select the predictor \u03c0\u02c6\u03b8 n given by \u02c6\u03b8 n = argmin\u03b8 R\u02c6(\u03b8,Sn). That is, the objective function that de\ufb01nes <b>learning</b> is the <b>empirical</b> <b>risk</b>. <b>ERM</b> has two useful properties. (1) It provides a prin-cipled framework for de\ufb01ning new <b>machine</b> <b>learning</b> methods. In particular, when ...", "dateLastCrawled": "2021-09-18T06:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Computational and Statistical <b>Learning</b> Theory", "url": "https://home.ttic.edu/~nati/Teaching/TTIC31120/2015/Lecture17.pdf", "isFamilyFriendly": true, "displayUrl": "https://home.ttic.edu/~nati/Teaching/TTIC31120/2015/Lecture17.pdf", "snippet": "<b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) / Sample Average Approximation (SAA): Collect sample z1UYU zm ... SGD for <b>Machine</b> <b>Learning</b> Initialize S 4 L r At iteration t: Draw T \u00e7\u00e1U \u00e71\u00de If U \u00e7 S \u00e7 \u00e1\u00f6 T \u00e7 O s\u00e1 S \u00e7 &gt; 5 Z S \u00e7 E\u00df \u00e7U \u00e7\u00f6 T \u00e7 else: S \u00e7 &gt; 5 Z S \u00e7 Return S % \u00cd L 5 \u00cd \u00c3 \u00cd S \u00e7 \u00e7 @ 5 Draw T 5\u00e1U 5 \u00e1\u00e5\u00e1 T \u00e0 \u00e1U \u00e0 1\u00de Initialize S 4 L r At iteration t: Pick E \u00d0 s\u00e5I at random If U \u00dc S \u00e7 \u00e1\u00f6 T \u00dc O s\u00e1 S \u00e7 &gt; 5 Z S \u00e7 E\u00df \u00e7U \u00dc\u00f6 T \u00dc else: S \u00e7 &gt; 5 Z S \u00e7 S \u00e7 &gt; 5 Z ...", "dateLastCrawled": "2022-01-26T03:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Basics of <b>Machine</b> <b>Learning</b>", "url": "https://courses.cs.duke.edu/spring21/compsci527/slides/s_04_deep_learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://courses.cs.duke.edu/spring21/compsci527/slides/s_04_deep_<b>learning</b>.pdf", "snippet": "This is called <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) COMPSCI 527 \u2014 Computer Vision Basics of <b>Machine</b> <b>Learning</b> 15/26. Loss and <b>Risk</b> <b>Machine</b> <b>Learning</b> and the Statistical <b>Risk</b> <b>ERM</b>: w^ 2argmin w2R m L T(w) In <b>machine</b> <b>learning</b>, we go much farther: We also want h to do well on previously unseen inputs To relate past and future data, assume that all data comes from the same joint probability distribution p(x;y) p is called the generative data model or just model The goal of <b>machine</b> <b>learning</b> is to ...", "dateLastCrawled": "2021-11-06T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Topics in <b>Machine</b> <b>Learning</b> (TIML-09)", "url": "https://www.cse.iitb.ac.in/~saketh/teaching/cs689.html", "isFamilyFriendly": true, "displayUrl": "https://www.cse.iitb.ac.in/~saketh/teaching/cs689.html", "snippet": "Introduction to Statistical <b>Learning</b> Theory (SLT): Definitions of loss function, <b>risk</b>, <b>empirical</b> <b>risk</b>, motivation for <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) Further Reading, Supplementary: Jan 12: Consistency of <b>ERM</b>, Sufficient condition for <b>ERM</b> as one-sided uniform convergence, Analysis for finite sets of functions and extensions to general case using Symmetrization trick, Shattering Coeff. Further Reading, Supplementary: Jan 15: Shattering coeff., growth function, VC dimension, Annealed Entropy ...", "dateLastCrawled": "2022-01-11T09:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Stratified <b>Sampling Meets Machine Learning</b>", "url": "http://proceedings.mlr.press/v48/liberty16.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v48/liberty16.pdf", "snippet": "3. <b>Empirical</b> <b>Risk</b> <b>Minimization</b> <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>) is a standard ap-proach in <b>machine</b> <b>learning</b> in which the chosen model is the minimizer of the <b>empirical</b> <b>risk</b>. The <b>empirical</b> <b>risk</b> R emp(p) is de\ufb01ned as an average loss of the model over the training set Q. Here Qis a query log containing a ran-", "dateLastCrawled": "2021-10-13T10:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Lecture 1: Reinforcement <b>Learning</b>: What and Why?", "url": "https://imada.sdu.dk/~kandemir/rl-lecture1.pdf", "isFamilyFriendly": true, "displayUrl": "https://imada.sdu.dk/~kandemir/rl-lecture1.pdf", "snippet": "<b>machine</b> <b>learning</b> and is referred to as <b>Empirical</b> <b>Risk</b> <b>Minimization</b> (<b>ERM</b>). 3 Challenges of reinforcement <b>learning</b> Consider the cart pole balancing problem, where a cart carrying an unactuated pole \ufb02oats on a straight horizontal track. The cart is actuated by a torque applied either to the right or the left direction. Seeherefor a real cart ...", "dateLastCrawled": "2021-09-30T12:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>GitHub</b> - gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Loss function 3.1 Categories 3.2 <b>Empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) and Structural <b>risk</b> <b>minimization</b> (SRM) 3.2.1 MLE 3.2.2 MAP 4. Evaluation metrics 4.1 Accuracy, precision, recall and F1 4.2 ROC, AUC 4.3 BLEU 5. Sample projects 6. Classical questions 6.1 Why is logistic regression a generalized linear model ?", "dateLastCrawled": "2021-09-12T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Loss function 3.1 Categories 3.2 <b>Empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) and Structural <b>risk</b> <b>minimization</b> (SRM) 3.2.1 MLE 3.2.2 MAP 4. Evaluation metrics 4.1 Accuracy, precision, recall and F1 4.2 ROC, AUC 4.3 BLEU 5. Sample projects 6. Classical questions 6.1 Why is logistic regression a generalized linear model ?", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[2006.09461] Robust <b>Compressed Sensing using Generative Models</b> - arXiv", "url": "https://arxiv.org/abs/2006.09461", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2006.09461", "snippet": "Classical recovery approaches such as <b>empirical</b> <b>risk</b> <b>minimization</b> (<b>ERM</b>) are guaranteed to succeed when the measurement matrix is sub-Gaussian. However, when the measurement matrix and measurements are heavy-tailed or have outliers, recovery may fail dramatically. In this paper we propose an algorithm inspired by the Median-of-Means (MOM). Our algorithm guarantees recovery for heavy-tailed data, even in the presence of outliers. Theoretically, our results show our novel MOM-based algorithm ...", "dateLastCrawled": "2021-06-27T11:19:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "ToyotaTechnologicalInstituteatChicago UniversityofTexasatAustin surbhi ...", "url": "https://arxiv.org/pdf/2005.07652.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/2005.07652.pdf", "snippet": "<b>Just as empirical risk minimization (ERM</b>) is central for non-robust PAC <b>learning</b>, a core component of adversarially robust <b>learning</b> is minimizing the robust empirical risk on a dataset S, \u02c6h \u2208 RERM U(S) ,argmin h\u2208H 1 m Xm i=1 sup z\u2208U(x) 1 [h(z) 6= y]. In this paper, we provide necessary and su\ufb03cient conditions on perturbation sets U ...", "dateLastCrawled": "2021-07-27T03:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Efficiently Learning Adversarially Robust Halfspaces with</b> Noise | DeepAI", "url": "https://deepai.org/publication/efficiently-learning-adversarially-robust-halfspaces-with-noise", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>efficiently-learning-adversarially-robust-halfspaces</b>...", "snippet": "<b>Just as empirical risk minimization (ERM</b>) is central for non-robust PAC <b>learning</b>, a core component of adversarially robust <b>learning</b> is minimizing the robust empirical risk on a dataset S, ^ h \u2208 R E R M U ( S ) \u225c argmin h \u2208 H 1 m m \u2211 i = 1 sup z \u2208 U ( x ) 1 [ h ( z ) \u2260 y ] .", "dateLastCrawled": "2021-12-05T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Efficiently <b>Learning</b> Adversarially Robust Halfspaces with Noise", "url": "http://proceedings.mlr.press/v119/montasser20a/montasser20a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v119/montasser20a/montasser20a.pdf", "snippet": "remains a major challenge in <b>machine</b> <b>learning</b>. A line of work has shown that predictors learned by deep neural networks are not robust to adversarial examples (Szegedy et al.,2014;Biggio et al.,2013;Goodfellow et al.,2015). This has led to a long line of research studying different aspects of robustness to adversarial examples. In this paper, we consider the problem of distribution-independent <b>learning</b> of halfspaces that are robust to ad-versarial examples at test time, also referred to as ...", "dateLastCrawled": "2021-11-21T12:03:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(empirical risk minimization (erm))  is like +(fitness function in evolutionary computation)", "+(empirical risk minimization (erm)) is similar to +(fitness function in evolutionary computation)", "+(empirical risk minimization (erm)) can be thought of as +(fitness function in evolutionary computation)", "+(empirical risk minimization (erm)) can be compared to +(fitness function in evolutionary computation)", "machine learning +(empirical risk minimization (erm) AND analogy)", "machine learning +(\"empirical risk minimization (erm) is like\")", "machine learning +(\"empirical risk minimization (erm) is similar\")", "machine learning +(\"just as empirical risk minimization (erm)\")", "machine learning +(\"empirical risk minimization (erm) can be thought of as\")", "machine learning +(\"empirical risk minimization (erm) can be compared to\")"]}