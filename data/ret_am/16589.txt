{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "<b>A true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. Similarly, <b>a true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Evaluation Metrics</b>, ROC-Curves and imbalanced datasets", "url": "https://www.davidsbatista.net/blog/2018/08/19/NLP_Metrics/", "isFamilyFriendly": true, "displayUrl": "https://www.davidsbatista.net/blog/2018/08/19/NLP_Metrics", "snippet": "<b>True</b> <b>Positive</b> (<b>TP</b>): predict an <b>event</b> when there was an <b>event</b>. <b>True</b> Negative (TN): predict no <b>event</b> when in fact there was no <b>event</b>. Accuracy. Accuracy simply measures the number of correct predicted samples over the total number of samples. For instance, if the classifier is 90% correct, it means that out of 100 instance it <b>correctly</b> predicts the class for 90 of them. \\[\\textrm{accuracy} = \\frac{\\textrm{nr. correct predictions}}{\\textrm{nr. total predictions}} = \\frac{\\textrm{<b>TP</b>+TN}}{\\textrm ...", "dateLastCrawled": "2022-01-26T11:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "python - Scikit-learn: How to obtain <b>True Positive</b>, <b>True</b> Negative ...", "url": "https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/31324218", "snippet": "After this, I would <b>like</b> to obtain the <b>True Positive</b>(<b>TP</b>), <b>True</b> Negative(TN), False <b>Positive</b>(FP) and False Negative(FN) values. I&#39;ll use these parameters to obtain the Sensitivity and Specificity. Finally, I would use this to put in HTML in order to show a chart with the TPs of each label. Code: The variables I have for the moment: trainList #It is a list with all the data of my dataset in JSON form labelList #It is a list with all the labels of my data Most part of the method: #I transform ...", "dateLastCrawled": "2022-01-26T12:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Accuracy, Recall, <b>Precision</b>, F-Score &amp; Specificity, which to optimize ...", "url": "https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/accuracy-recall-<b>precision</b>-f-score-specificity-which-to...", "snippet": "<b>True</b> <b>positive</b> (<b>TP</b>): Prediction is +ve and X is diabetic, we want that; <b>True</b> negative (TN): Prediction is -ve and X is healthy, we want that too; False <b>positive</b> (FP): Prediction is +ve and X is healthy, false alarm, bad; False negative (FN): Prediction is -ve and X is diabetic, the worst; To remember that, there are 2 tricks - If it starts with <b>True</b> then the prediction was correct whether diabetic or not, so <b>true</b> <b>positive</b> is a diabetic person <b>correctly</b> predicted &amp; <b>a true</b> negative is a healthy ...", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Top 40 <b>Machine Learning Interview Questions</b> &amp; Answers 2022", "url": "https://intellipaat.com/blog/interview-question/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-question/<b>machine-learning-interview-questions</b>", "snippet": "16. Explain false negative, false <b>positive</b>, <b>true</b> negative, and <b>true</b> <b>positive</b> with a simple example. <b>True</b> <b>Positive</b> (<b>TP</b>): When the Machine Learning model <b>correctly</b> predicts the condition, it is said to have <b>a True</b> <b>Positive</b> value. <b>True</b> Negative (TN): When the Machine Learning model <b>correctly</b> predicts the negative condition or class, then it is ...", "dateLastCrawled": "2022-01-30T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is a ROC <b>Curve and How to Interpret It</b> - Displayr", "url": "https://www.displayr.com/what-is-a-roc-curve-how-to-interpret-it/", "isFamilyFriendly": true, "displayUrl": "https://www.displayr.com/what-is-a-roc-curve-how-to-interpret-it", "snippet": "The <b>true</b> <b>positive</b> rate is the proportion of observations that were <b>correctly</b> predicted to be <b>positive</b> out of all <b>positive</b> observations (<b>TP</b>/(<b>TP</b> + FN)). Similarly, the false <b>positive</b> rate is the proportion of observations that are incorrectly predicted to be <b>positive</b> out of all negative observations (FP/(TN + FP)). For example, in medical testing, the <b>true</b> <b>positive</b> rate is the rate in which people are <b>correctly</b> identified to test <b>positive</b> for the disease in question. A discrete classifier that ...", "dateLastCrawled": "2022-02-03T06:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Machine Learning Prediction of Companies\u2019 Business Success", "url": "http://cs229.stanford.edu/proj2018/report/88.pdf", "isFamilyFriendly": true, "displayUrl": "cs229.stanford.edu/proj2018/report/88.pdf", "snippet": "<b>TP</b> (<b>true</b> <b>positive</b>): an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. TN (<b>true</b> negative): an outcome where the model <b>correctly</b> predicts the negative class. FP (false <b>positive</b>): an outcome where the model incorrectly predicts the <b>positive</b> class. FN (false negative): an outcome where the model incorrectly predicts the negative class.", "dateLastCrawled": "2022-01-18T18:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Learning \u2013 K-Nearest Neighbor (KNN) Algorithm</b> \u2013 AI Decades", "url": "https://aidecades.wordpress.com/2020/03/03/machine-learning-k-nearest-neighbor-knn-algorithm/", "isFamilyFriendly": true, "displayUrl": "https://aidecades.wordpress.com/2020/03/03/<b>machine-learning-k-nearest-neighbor-knn</b>...", "snippet": "\u201c<b>true</b> <b>positive</b>\u201d for <b>correctly</b> predicted <b>event</b> values. \u201cfalse <b>positive</b>\u201d for incorrectly predicted <b>event</b> values. \u201c<b>true</b> negative\u201d for <b>correctly</b> predicted no-<b>event</b> values. \u201cfalse negative\u201d for incorrectly predicted no-<b>event</b> values. Classification Report: A Classification report is used to measure the quality of predictions from a classification algorithm. How many predictions are <b>True</b> and how many are False. Accuracy: Accuracy refers to how close a measurement is to the <b>true</b> ...", "dateLastCrawled": "2022-02-02T13:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is <b>True</b> Negative, and a pregnant woman whose test results say \u201cPregnant\u201d is <b>True</b> <b>Positive</b>. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Confusion Matrix</b>, Accuracy, Precision, Recall, F1 Score | by ...", "url": "https://medium.com/analytics-vidhya/confusion-matrix-accuracy-precision-recall-f1-score-ade299cf63cd", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>confusion-matrix</b>-accuracy-precision-recall-f1...", "snippet": "Figure 4. False Negative. What we desire is <b>TRUE</b> <b>POSITIVE</b> and <b>TRUE</b> NEGATIVE but due to the misclassifications, we may also end up in FALSE <b>POSITIVE</b> and FALSE NEGATIVE.So there is a confusion in ...", "dateLastCrawled": "2022-02-02T15:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "<b>A true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. Similarly, <b>a true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>True Positive Rate</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/true-positive-rate", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>true-positive-rate</b>", "snippet": "<b>True positive rate</b> (TPR) (M1). It is the proportion of <b>positive</b> instances (ie, feature vectors of malicious applications) classified <b>correctly</b>: where <b>TP</b> is the number of <b>positive</b> instances <b>correctly</b> classified and FN is the number of <b>positive</b> instances misclassified. False <b>positive</b> rate (FPR) (M2).", "dateLastCrawled": "2022-02-02T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Top 40 <b>Machine Learning Interview Questions</b> &amp; Answers 2022", "url": "https://intellipaat.com/blog/interview-question/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-question/<b>machine-learning-interview-questions</b>", "snippet": "16. Explain false negative, false <b>positive</b>, <b>true</b> negative, and <b>true</b> <b>positive</b> with a simple example. <b>True</b> <b>Positive</b> (<b>TP</b>): When the Machine Learning model <b>correctly</b> predicts the condition, it is said to have <b>a True</b> <b>Positive</b> value. <b>True</b> Negative (TN): When the Machine Learning model <b>correctly</b> predicts the negative condition or class, then it is ...", "dateLastCrawled": "2022-01-30T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "python - Scikit-learn: How to obtain <b>True Positive</b>, <b>True</b> Negative ...", "url": "https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/31324218", "snippet": "After this, I would like to obtain the <b>True Positive</b>(<b>TP</b>), <b>True</b> Negative(TN), False <b>Positive</b>(FP) and False Negative(FN) values. I&#39;ll use these parameters to obtain the Sensitivity and Specificity. Finally, I would use this to put in HTML in order to show a chart with the TPs of each label. Code: The variables I have for the moment: trainList #It is a list with all the data of my dataset in JSON form labelList #It is a list with all the labels of my data Most part of the method: #I transform ...", "dateLastCrawled": "2022-01-26T12:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Accuracy, Recall, <b>Precision</b>, F-Score &amp; Specificity, which to optimize ...", "url": "https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/accuracy-recall-<b>precision</b>-f-score-specificity-which-to...", "snippet": "<b>True</b> <b>positive</b> (<b>TP</b>): Prediction is +ve and X is diabetic, we want that; <b>True</b> negative (TN): Prediction is -ve and X is healthy, we want that too; False <b>positive</b> (FP): Prediction is +ve and X is healthy, false alarm, bad; False negative (FN): Prediction is -ve and X is diabetic, the worst; To remember that, there are 2 tricks - If it starts with <b>True</b> then the prediction was correct whether diabetic or not, so <b>true</b> <b>positive</b> is a diabetic person <b>correctly</b> predicted &amp; <b>a true</b> negative is a healthy ...", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evaluating a <b>Classification Model</b> | Machine Learning, Deep Learning ...", "url": "https://www.ritchieng.com/machine-learning-evaluate-classification-model/", "isFamilyFriendly": true, "displayUrl": "https://www.ritchieng.com/machine-learning-evaluate-<b>classification-model</b>", "snippet": "<b>True</b> Positives (<b>TP</b>): we <b>correctly</b> predicted that they do have diabetes. 15; <b>True</b> Negatives (TN): we <b>correctly</b> predicted that they don&#39;t have diabetes. 118; False Positives (FP): we incorrectly predicted that they do have diabetes (a &quot;Type I error&quot;) 12; Falsely predict <b>positive</b>; Type I error; False Negatives (FN): we incorrectly predicted that they don&#39;t have diabetes (a &quot;Type II error&quot;) 47; Falsely predict negative; Type II error; 0: negative class; 1: <b>positive</b> class; In [15]: # print the ...", "dateLastCrawled": "2022-02-03T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "10.3 - <b>Sensitivity</b>, Specificity, <b>Positive</b> Predictive Value, and ...", "url": "https://online.stat.psu.edu/stat507/lesson/10/10.3", "isFamilyFriendly": true, "displayUrl": "https://online.stat.psu.edu/stat507/lesson/10/10.3", "snippet": "The rows indicate the results of the test, <b>positive</b> or negative. Cell A contains <b>true</b> positives, subjects with the disease and <b>positive</b> test results. Cell D subjects do not have the disease and the test agrees. A good test will have minimal numbers in cells B and C. Cell B identifies individuals without disease but for whom the test indicates &#39;disease&#39;. These are false positives. Cell C has the false negatives. If these results are from a population-based study, prevalence can be calculated ...", "dateLastCrawled": "2022-02-02T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Must-know Machine Learning Questions \u2013 <b>Logistic Regression</b>", "url": "https://www.upgrad.com/blog/machine-learning-interview-questions-answers-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/<b>machine-learning-interview-questions-answers</b>-logistic...", "snippet": "A CRV consists of the <b>true</b> <b>positive</b> rate or the percentage of positives <b>correctly</b> classified on the Y-axis and the percentage of the population targeted on the X-axis. It is important to note that the percentage of the population will be ranked by the model in descending order (either the probabilities or the expected values). If the model is good, then by targeting a top portion of the ranked list, all high percentages of positives will be captured. As with the ROC curve, there will be a ...", "dateLastCrawled": "2022-02-03T08:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is <b>True</b> Negative, and a pregnant woman whose test results say \u201cPregnant\u201d is <b>True</b> <b>Positive</b>. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Confusion Matrix</b>, Accuracy, Precision, Recall, F1 Score | by ...", "url": "https://medium.com/analytics-vidhya/confusion-matrix-accuracy-precision-recall-f1-score-ade299cf63cd", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>confusion-matrix</b>-accuracy-precision-recall-f1...", "snippet": "Figure 4. False Negative. What we desire is <b>TRUE</b> <b>POSITIVE</b> and <b>TRUE</b> NEGATIVE but due to the misclassifications, we may also end up in FALSE <b>POSITIVE</b> and FALSE NEGATIVE.So there is a confusion in ...", "dateLastCrawled": "2022-02-02T15:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Accuracy, Recall, <b>Precision</b>, F-Score &amp; Specificity, which to optimize ...", "url": "https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/accuracy-recall-<b>precision</b>-f-score-specificity-which-to...", "snippet": "<b>True</b> <b>positive</b> (<b>TP</b>): Prediction is +ve and X is diabetic, we want that; <b>True</b> negative (TN): Prediction is -ve and X is healthy, we want that too; False <b>positive</b> (FP): Prediction is +ve and X is healthy, false alarm, bad; False negative (FN): Prediction is -ve and X is diabetic, the worst; To remember that, there are 2 tricks - If it starts with <b>True</b> then the prediction was correct whether diabetic or not, so <b>true</b> <b>positive</b> is a diabetic person <b>correctly</b> predicted &amp; <b>a true</b> negative is a healthy ...", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "python - Scikit-learn: How to obtain <b>True Positive</b>, <b>True</b> Negative ...", "url": "https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/31324218", "snippet": "After this, I would like to obtain the <b>True Positive</b>(<b>TP</b>), <b>True</b> Negative(TN), False <b>Positive</b>(FP) and False Negative(FN) values. I&#39;ll use these parameters to obtain the Sensitivity and Specificity. Finally, I would use this to put in HTML in order to show a chart with the TPs of each label. Code: The variables I have for the moment: trainList #It is a list with all the data of my dataset in JSON form labelList #It is a list with all the labels of my data Most part of the method: #I transform ...", "dateLastCrawled": "2022-01-26T12:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding and Identifying Unfairness in Machine Learning | by ...", "url": "https://cannon-m-bray.medium.com/understanding-and-identifying-unfairness-in-machine-learning-80178a16357c", "isFamilyFriendly": true, "displayUrl": "https://<b>can</b>non-m-bray.medium.com/understanding-and-identifying-unfairness-in-machine...", "snippet": "<b>True</b> Positives (<b>TP</b>) \u2014 How often the model predicts the <b>positive</b> class <b>correctly</b>; False Positives (FP) \u2014 How often the model predicts the <b>positive</b> class incorrectly; False Negatives (FN) \u2014 How often the model predicts the negative class incorrectly; <b>True</b> Negatives (TN) \u2014 How often the model predicts the negative class <b>correctly</b>; The confusion matrix gives a better idea of a model\u2019s predictive power than just a simple accuracy, especially when <b>predicting</b> a rare <b>event</b>. For example, if ...", "dateLastCrawled": "2022-01-21T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Classification Accuracy is Not Enough: More Performance Measures You ...", "url": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-", "snippet": "It is also called Sensitivity or the <b>True</b> <b>Positive</b> Rate. Recall <b>can</b> <b>be thought</b> of as a measure of a classifiers completeness. A low recall indicates many False Negatives. The recall of the All No Recurrence model is 0/(0+85) or 0. The recall of the All Recurrence model is 85/(85+0) or 1. The recall of CART is 10/(10+75) or 0.12. As you would expect, the All Recurrence model has a perfect recall because it predicts \u201crecurrence\u201d for all instances. The recall for CART is lower than that of ...", "dateLastCrawled": "2022-02-03T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What metrics should be used for evaluating a model on an <b>imbalanced</b> ...", "url": "https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/what-metrics-should-we-use-on-<b>imbalanced</b>-data-set...", "snippet": "In the ROC curve we l o ok at: TPR (<b>True</b> <b>Positive</b> Rate) = # <b>True</b> positives / # positives = Recall = <b>TP</b> / (<b>TP</b>+FN) FPR (False <b>Positive</b> Rate) = # False Positives / # negatives = FP / (FP+TN) Here we will focus on the TPR (<b>True</b> <b>Positive</b> Rate) and FPR (False <b>Positive</b> Rate) of a single point (this will indicate the general performance of the ROC curve which consists of the TPR and FPR through various probability thresholds).", "dateLastCrawled": "2022-01-29T20:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 5, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Receiver operating characteristic</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Receiver_operating_characteristic", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Receiver_operating_characteristic</b>", "snippet": "<b>true</b> <b>positive</b> (<b>TP</b>) A test result that <b>correctly</b> indicates the presence of a condition or characteristic <b>true</b> negative (TN) A test result that <b>correctly</b> indicates the absence of a condition or characteristic false <b>positive</b> (FP) A test result which wrongly indicates that a particular condition or attribute is present false negative (FN) A test result which wrongly indicates that a particular condition or attribute is absent. sensitivity, recall, hit rate, or <b>true</b> <b>positive</b> rate (TPR ...", "dateLastCrawled": "2022-02-02T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "machine learning - Calculating <b>F-Score</b>, which is the &quot;<b>positive</b>&quot; class ...", "url": "https://stats.stackexchange.com/questions/191645/calculating-f-score-which-is-the-positive-class-the-majority-or-minority-cla", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/191645", "snippet": "<b>true</b> <b>positive</b> rate = <b>true</b> positives / ( <b>True</b> <b>positive</b> + False negative) Coming to <b>F-score</b>, it is a measure of trade-off between precision and recall. Lets assume you set the thresh-hold for <b>predicting</b> a <b>positive</b> as very high. Say <b>predicting</b> <b>positive</b> if h(x) &gt;= 0.8, and negative if h(x) &lt; 0.8 you have huge", "dateLastCrawled": "2022-01-24T21:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Module 3 - GitHub Pages", "url": "https://it-gecbh.github.io/2020/resources/ML/module_3.pptx", "isFamilyFriendly": true, "displayUrl": "https://it-gecbh.github.io/2020/resources/ML/module_3.pptx", "snippet": "TPR = <b>True</b> <b>Positive</b> Rate = <b>TP</b>/( <b>TP</b> + FN )= Fraction of <b>positive</b> examples <b>correctly</b> classified = Sensitivity. FPR = False <b>Positive</b> Rate = FP /(FP + TN) = Fraction of negative examples incorrectly classified = 1 \u2212 Specificity . ROC space. We plot the values of FPR along the horizontal axis (that is , x-axis) and the values of TPR along the vertical axis (that is, y-axis) in a plane. For each classifier, there is a unique point in this plane with coordinates (FPR,TPR). The ROC space is the ...", "dateLastCrawled": "2022-01-31T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "logistic regression - Roc curve and cut off point. <b>Python</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/28719067", "snippet": "The optimal cut off point would be where \u201c<b>true</b> <b>positive</b> rate\u201d is high and the \u201cfalse <b>positive</b> rate ... I <b>thought</b> that the threshold moved between 0 and 1, and that the goal was to find the value in this range that maximized tpr-fpr \u2013 RafaelCaballero. Nov 3 &#39;19 at 23:47. @cgnorthcutt Your code is correct. But TPR = <b>TP</b>/(real <b>positive</b>), FPR = FP/(real negative). TPR + FPR != 1. \u2013 Qinsi. Dec 25 &#39;19 at 7:45 | Show 1 more comment. 17 Vanilla <b>Python</b> Implementation of Youden&#39;s J-Score. def ...", "dateLastCrawled": "2022-01-28T10:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Diagnostic <b>accuracy</b> \u2013 Part 1 Basic concepts: sensitivity and ...", "url": "https://acutecaretesting.org/en/articles/diagnostic-accuracy--part-1brbasic-concepts-sensitivity-and-specificity-roc-analysis-stard-statement", "isFamilyFriendly": true, "displayUrl": "https://acutecaretesting.org/en/articles/diagnostic-<b>accuracy</b>--part-1brbasic-concepts...", "snippet": "Discriminative measures are mostly used by health-policy decision makers; predictive measures are most useful for <b>predicting</b> the probability of a disease in an individual. Some measures assess the global performance of a test, whereas others are related to its ability to detect or exclude the disease, or to the clinical significance of a <b>positive</b> or negative test result in a specific patient. Furthermore, measures of a test performance are not fixed indicators of a test quality, but are very ...", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "<b>A true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. Similarly, <b>a true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Accuracy, Recall, <b>Precision</b>, F-Score &amp; Specificity, which to optimize ...", "url": "https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/accuracy-recall-<b>precision</b>-f-score-specificity-which-to...", "snippet": "<b>True</b> <b>positive</b> (<b>TP</b>): Prediction is +ve and X is diabetic, we want that; <b>True</b> negative (TN): Prediction is -ve and X is healthy, we want that too; False <b>positive</b> (FP): Prediction is +ve and X is healthy, false alarm, bad; False negative (FN): Prediction is -ve and X is diabetic, the worst; To remember that, there are 2 tricks - If it starts with <b>True</b> then the prediction was correct whether diabetic or not, so <b>true</b> <b>positive</b> is a diabetic person <b>correctly</b> predicted &amp; <b>a true</b> negative is a healthy ...", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Classification Table</b> | Real Statistics Using Excel", "url": "https://www.real-statistics.com/logistic-regression/classification-table/", "isFamilyFriendly": true, "displayUrl": "https://www.real-statistics.com/logistic-regression/<b>classification-table</b>", "snippet": "<b>True</b> Positives (<b>TP</b>) = the number of cases which were <b>correctly</b> classified to be <b>positive</b>, i.e. were predicted to be a success and were actually observed to be a success. False Positives (FP) = the number of cases which were incorrectly classified as <b>positive</b>, i.e. were predicted to be a success but were actually observed to be a failure. <b>True</b> Negatives (TN) = the number of cases which were <b>correctly</b> classified to be negative, i.e. were predicted to be a failure and were actually observed to ...", "dateLastCrawled": "2022-02-02T16:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Confusion matrix (<b>TP</b>: <b>True</b> <b>Positive</b>, TN: <b>True</b> Negative, FP: False ...", "url": "https://researchgate.net/figure/Confusion-matrix-TP-True-Positive-TN-True-Negative-FP-False-Positive-and-FN-False_tbl2_342404080", "isFamilyFriendly": true, "displayUrl": "https://researchgate.net/figure/Confusion-matrix-<b>TP</b>-<b>True</b>-<b>Positive</b>-TN-<b>True</b>-Negative-FP...", "snippet": "Download scientific diagram | Confusion matrix (<b>TP</b>: <b>True</b> <b>Positive</b>, TN: <b>True</b> Negative, FP: False <b>Positive</b>, and FN: False Negative). from publication: A New End-to-End Multi-Dimensional CNN ...", "dateLastCrawled": "2021-06-28T06:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Evaluating a <b>Classification Model</b> | Machine Learning, Deep Learning ...", "url": "https://www.ritchieng.com/machine-learning-evaluate-classification-model/", "isFamilyFriendly": true, "displayUrl": "https://www.ritchieng.com/machine-learning-evaluate-<b>classification-model</b>", "snippet": "<b>True</b> Positives (<b>TP</b>): we <b>correctly</b> predicted that they do have diabetes. 15; <b>True</b> Negatives (TN): we <b>correctly</b> predicted that they don&#39;t have diabetes. 118; False Positives (FP): we incorrectly predicted that they do have diabetes (a &quot;Type I error&quot;) 12; Falsely predict <b>positive</b>; Type I error; False Negatives (FN): we incorrectly predicted that they don&#39;t have diabetes (a &quot;Type II error&quot;) 47; Falsely predict negative; Type II error; 0: negative class; 1: <b>positive</b> class; In [15]: # print the ...", "dateLastCrawled": "2022-02-03T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "10.3 - <b>Sensitivity</b>, Specificity, <b>Positive</b> Predictive Value, and ...", "url": "https://online.stat.psu.edu/stat507/lesson/10/10.3", "isFamilyFriendly": true, "displayUrl": "https://online.stat.psu.edu/stat507/lesson/10/10.3", "snippet": "The rows indicate the results of the test, <b>positive</b> or negative. Cell A contains <b>true</b> positives, subjects with the disease and <b>positive</b> test results. Cell D subjects do not have the disease and the test agrees. A good test will have minimal numbers in cells B and C. Cell B identifies individuals without disease but for whom the test indicates &#39;disease&#39;. These are false positives. Cell C has the false negatives. If these results are from a population-based study, prevalence <b>can</b> be calculated ...", "dateLastCrawled": "2022-02-02T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Diagnostic <b>accuracy</b> \u2013 Part 1 Basic concepts: sensitivity and ...", "url": "https://acutecaretesting.org/en/articles/diagnostic-accuracy--part-1brbasic-concepts-sensitivity-and-specificity-roc-analysis-stard-statement", "isFamilyFriendly": true, "displayUrl": "https://acutecaretesting.org/en/articles/diagnostic-<b>accuracy</b>--part-1brbasic-concepts...", "snippet": "Sensitivity (%) defines the proportion of <b>true</b> <b>positive</b> subjects with the disease in a total group of subjects with the disease (<b>TP</b> / (<b>TP</b> + FN)). In other words, sensitivity is defined as the probability of getting a <b>positive</b> test result in subjects with the disease. Hence, it relates to the potential of a test to identify subjects with the ...", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Must-know Machine Learning Questions \u2013 <b>Logistic Regression</b>", "url": "https://www.upgrad.com/blog/machine-learning-interview-questions-answers-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/<b>machine-learning-interview-questions-answers</b>-logistic...", "snippet": "A CRV consists of the <b>true</b> <b>positive</b> rate or the percentage of positives <b>correctly</b> classified on the Y-axis and the percentage of the population targeted on the X-axis. It is important to note that the percentage of the population will be ranked by the model in descending order (either the probabilities or the expected values). If the model is good, then by targeting a top portion of the ranked list, all high percentages of positives will be captured. As with the ROC curve, there will be a ...", "dateLastCrawled": "2022-02-03T08:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Machine Learning Prediction of Companies\u2019 Business Success", "url": "http://cs229.stanford.edu/proj2018/report/88.pdf", "isFamilyFriendly": true, "displayUrl": "cs229.stanford.edu/proj2018/report/88.pdf", "snippet": "they built to classify a company as successful or not-successful had <b>a True</b> <b>Positive</b> Rate (TPR) of 94.1% (the highest reported using data from CrunchBase) and a False <b>Positive</b> Rate of 7.8%. Xiang [6] and used CrunchBase with pro\ufb01les and news articles on TechCrunch to predict company acquisitions. Eugene and Daphne [2] performed descriptive data mining with CrunchBase to \ufb01nd general rules for companies seeking investment involving investors\u2019 preference to invest. They used social ...", "dateLastCrawled": "2022-01-18T18:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is <b>True</b> Negative, and a pregnant woman whose test results say \u201cPregnant\u201d is <b>True</b> <b>Positive</b>. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Confusion Matrix in <b>Machine</b> <b>Learning</b> \u2013 Naukri <b>Learning</b>", "url": "https://www.naukri.com/learning/articles/confusion-matrix-in-machine-learning-naukri-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.naukri.com/<b>learning</b>/articles/confusion-matrix-in-<b>machine</b>-<b>learning</b>-naukri...", "snippet": "Let\u2019s understand <b>TP</b>, FP, FN, TN in terms of Coronavirus affected people <b>analogy</b>. <b>True</b> <b>Positive</b>: Interpretation: You predicted <b>positive</b> and it\u2019s <b>true</b>. You predicted that a person is Corona <b>positive</b> and he actually is having Corona. <b>True</b> Negative: Interpretation: You predicted negative and it\u2019s <b>true</b>.", "dateLastCrawled": "2022-02-07T08:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding Confusion Matrix in <b>Machine</b> <b>Learning</b>, Let\u2019s Study ...", "url": "https://ulimazzadaislamy.medium.com/understanding-confusion-matrix-in-machine-learning-lets-study-together-7521090aaaf2", "isFamilyFriendly": true, "displayUrl": "https://ulimazzadaislamy.medium.com/understanding-confusion-matrix-in-<b>machine</b>-<b>learning</b>...", "snippet": "Let\u2019s understand <b>TP</b>, FP, FN, TN in terms of pregnancy <b>analogy</b>: The <b>analogy</b> from the picture: <b>True</b> <b>Positive</b>: Interpretation: You predicted <b>positive</b> and it\u2019s <b>true</b>. You predicted that a woman is pregnant and she actually is. <b>True</b> Negative: Interpretation: You predicted negative and it\u2019s <b>true</b>. You predicted that a man is not pregnant and he actually is not. False <b>Positive</b>: (Type 1 Error) Interpretation: You predicted <b>positive</b> and it\u2019s false. You predicted that a man is pregnant but he ...", "dateLastCrawled": "2022-01-13T10:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning Accuracy</b>: <b>True</b> vs. False <b>Positive</b>/Negative", "url": "https://research.aimultiple.com/machine-learning-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://research.aimultiple.com/<b>machine-learning-accuracy</b>", "snippet": "There are various theoretical approaches to measuring accuracy* of competing <b>machine</b> <b>learning</b> models however, in most commercial applications, you simply need to assign a business value to 4 types of results: <b>true</b> positives, <b>true</b> negatives, false positives and false negatives.By multiplying number of results in each bucket with the associated business values, you will ensure that you use the best model available.", "dateLastCrawled": "2022-02-03T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "ROAL OF CONFUSION MATRIX IN CYBER CRIME | by HM | Medium", "url": "https://h17.medium.com/roal-of-confusion-matrix-in-cyber-crime-41e7c9c3f57b", "isFamilyFriendly": true, "displayUrl": "https://h17.medium.com/roal-of-confusion-matrix-in-cyber-crime-41e7c9c3f57b", "snippet": "Let\u2019s understand <b>TP</b>, FP, FN, TN in terms of pregnancy <b>analogy</b>. <b>True</b> <b>Positive</b>: Interpretation: You predicted <b>positive</b> and it\u2019s <b>true</b>. You predicted that a woman is pregnant and she actually is. <b>True</b> Negative: Interpretation: You predicted negative and it\u2019s <b>true</b>. You predi c ted that a man is not pregnant and he actually is not. False <b>Positive</b>: (Type 1 Error) Interpretation: You predicted <b>positive</b> and it\u2019s false. You predicted that a man is pregnant but he actually is not. False ...", "dateLastCrawled": "2022-01-10T21:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Evaluating a <b>Machine</b> <b>Learning</b> Model: Regression and Classification ...", "url": "https://arnavbansal-8232.medium.com/evaluating-a-machine-learning-model-regression-and-classification-metrics-4f2316e180b4", "isFamilyFriendly": true, "displayUrl": "https://arnavbansal-8232.medium.com/evaluating-a-<b>machine</b>-<b>learning</b>-model-regression-and...", "snippet": "<b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> plays a vital role in all this. ... <b>True</b> <b>positive</b> (<b>TP</b>) \u2014 actual = 1; predicted = 1 (11 = 1) False <b>positive</b> (FP) \u2014 actual = 0; predicted = 1 (01 = 0) False negative (FN) \u2014 actual = 1; predicted = 0 (10 = 0) <b>True</b> negative (TN) \u2014 actual = 0; predicted = 0 (00 = 1) \u201cXNOR gate\u201d produces this kind of output. Our objective is to train the model, so that our algorithm predicts the same as the <b>true</b> output. Hence, our algorithm should produce more outputs ...", "dateLastCrawled": "2022-01-05T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is <b>True</b> Negative, and a pregnant woman whose test results say \u201cPregnant\u201d is <b>True</b> <b>Positive</b>. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "Confusion Matrix Confusion Matrix is a performance measurement for a <b>machine learning</b> classification problem where output can be two or more classes. It is a table with 4 different combinations of predicted and actual values as shown below. It is very useful for measuring other <b>evaluation metrics</b> such as Recall, Precision, Specificity, Accuracy, and most importantly AUC-ROC Curve. Following is an example in terms of pregnancy <b>analogy</b> to help you better understand <b>TP</b>, TN, FP, and FN. <b>True</b> ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Model 1: accuracy = 92%. Model 2: accuracy = 95%. Model 2 has higher accuracy than model 1, but model 2 is useless. This is called accuracy paradox, which means the model with higher accuracy may not have better generalization power. In general, when <b>TP</b> &lt; FP, the accuracy will always increase when we change the classifier to always output &#39;negative&#39;.Conversely, when TN &lt; FN, the same will happen when we change the classifier to always output &#39;<b>positive</b>&#39; [1].. Recall@k", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Understanding <b>Confusion Matrix</b> | by Sarang Narkhede | Towards Data Science", "url": "https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-<b>confusion-matrix</b>-a9ad42dcfd62", "snippet": "It is a table with 4 different combinations of predicted and actual values. <b>Confusion Matrix</b> [Image 2] (Image courtesy: My Photoshopped Collection) It is extremely useful for measuring Recall, Precision, Specificity, Accuracy, and most importantly AUC-ROC curves. Let\u2019s understand <b>TP</b>, FP, FN, TN in terms of pregnancy <b>analogy</b>.", "dateLastCrawled": "2022-02-02T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Receiver Operating Curve (ROC) and The Scale \u2014 Understanding ROC ...", "url": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the-scale-understanding-roc-through-an-analogy-8b8f9d954f84", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the...", "snippet": "The Receiver Operating Curve (ROC) is used to evaluate and improve classification <b>Machine</b> <b>Learning</b> models. Who does not want an accurate classifier, that place observations where they actually\u2026", "dateLastCrawled": "2021-02-13T00:05:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(true positive (tp))  is like +(correctly predicting a true positive event)", "+(true positive (tp)) is similar to +(correctly predicting a true positive event)", "+(true positive (tp)) can be thought of as +(correctly predicting a true positive event)", "+(true positive (tp)) can be compared to +(correctly predicting a true positive event)", "machine learning +(true positive (tp) AND analogy)", "machine learning +(\"true positive (tp) is like\")", "machine learning +(\"true positive (tp) is similar\")", "machine learning +(\"just as true positive (tp)\")", "machine learning +(\"true positive (tp) can be thought of as\")", "machine learning +(\"true positive (tp) can be compared to\")"]}