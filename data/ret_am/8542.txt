{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>Brief History of Neural Nets and Deep Learning</b> \u2013 Skynet Today", "url": "https://www.skynettoday.com/overviews/neural-net-history", "isFamilyFriendly": true, "displayUrl": "https://www.skynettoday.com/overviews/neural-net-history", "snippet": "Having taken several classes on Machine <b>Learning</b>, and even used it in undergraduate research, I could not help but wonder if this <b>new</b> \u2018Deep <b>Learning</b>\u2019 was anything fancy or just a scaled up version of the \u2018artificial neural nets\u2019 that were already developed by the late 80s. And let me tell you, the answer is quite a story - the story of not just neural nets, not just of a sequence of research breakthroughs that make Deep <b>Learning</b> somewhat more interesting than \u2018big neural nets ...", "dateLastCrawled": "2022-02-03T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Unsupervised <b>learning</b> of phonemes of whispered speech in a noisy ...", "url": "https://www.sciencedirect.com/science/article/abs/pii/S0020025513006798", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/abs/pii/S0020025513006798", "snippet": "<b>A new</b> convolutive non-negative matrix factorization ... The first characteristic is a turbulence-<b>like</b> excitation pattern that results because whispered speech is produced with no vibration of a vocal cord, which results in the lack of pitch. The second characteristic is the coupling of the trachea with the vocal tract due to the opening of the vocal folds [39]. Whispered speech is often used in some public places where normal speech is prohibited or when the speaker wants to avoid being ...", "dateLastCrawled": "2022-01-04T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Deep <b>Learning for NLP and Speech Recognition</b> | William Jacome ...", "url": "https://www.academia.edu/43190210/Deep_Learning_for_NLP_and_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43190210/Deep_<b>Learning_for_NLP_and_Speech_Recognition</b>", "snippet": "Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome. Download PDF. Download Full PDF Package. This paper. A short summary of this paper. 37 Full PDFs related to this paper. READ PAPER. Deep <b>Learning for NLP and Speech Recognition</b> . Download. Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "On the Opportunities and Risks of Foundation Models \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2108.07258/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2108.07258", "snippet": "Though there are many differing theories about what types of theoretical abstractions the human <b>language</b> system makes (e.g., Comrie, 1989; Chomsky, 2014; Croft, 2001; Jackendoff, 2011), it is generally agreed that humans learn <b>language</b> in a way that allows them to easily slot <b>new</b> knowledge into existing abstractions, and productively create <b>new</b> grammatical sentences. For example, a ten-year-old child has acquired a lot of the abstractions about how their <b>language</b> works, though the actual ...", "dateLastCrawled": "2022-01-27T21:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Adversarial Multi-Task Learning of</b> Deep Neural Networks for Robust ...", "url": "https://www.researchgate.net/publication/307889496_Adversarial_Multi-Task_Learning_of_Deep_Neural_Networks_for_Robust_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/307889496_<b>Adversarial_Multi-Task_Learning_of</b>...", "snippet": "There has Figure 1: Automatic <b>spoken</b> <b>language</b> assessment system. been work on <b>learning</b> domain invariant feature representations [16, 17, 18,19], but few, if any, has done so at the front-end ...", "dateLastCrawled": "2022-01-19T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Linguistics and Pop Culture</b> \u2013 The LINGUIST List", "url": "https://blog.linguistlist.org/category/linguistics-and-pop-culture/", "isFamilyFriendly": true, "displayUrl": "https://blog.linguistlist.org/category/<b>linguistics-and-pop-culture</b>", "snippet": "The Yiddish <b>language</b> has undergone seriously decline in recent decades but the creators of the <b>new</b> version hope that having such an iconic musical entirely in Yiddish will encourage an improved image for the <b>language</b>. Much of the Yiddish-speaking population now resides in the <b>New</b> York City area. With the production of \u201cFiddler of the Roof\u201d happening nearby, it is hoped that increased exposure will strengthen the <b>language</b>\u2019s vitality in the region and encourage the rising generation to ...", "dateLastCrawled": "2021-12-31T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Google publi</b> \u00b7 GitHub", "url": "https://gist.github.com/mdamien/307331a96d5bba9622b1", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/mdamien/307331a96d5bba9622b1", "snippet": "<b>Google publi</b>. GitHub Gist: instantly share code, notes, and <b>snippets</b>.", "dateLastCrawled": "2022-01-04T19:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "CS379C 2019 Class Discussion Notes", "url": "https://web.stanford.edu/class/cs379c/archive/2019/class_messages_listing/index.html", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/cs379c/archive/2019/class_messages_listing/index.html", "snippet": "scripted base \u2014 employ a scripting <b>language</b> <b>like</b> python and hierarchical network to generate data; developmental \u2014 recapitulate child development by building <b>language</b> facility from the bottom up; curriculum \u2014 leverage multiple objective functions and combine intrinsic and extrinsic rewards; I highly recommend that you read, listen to or watch Andy Clark&#39;s Edge Talk on &quot;Perception As Controlled Hallucination: Predictive Processing and the Nature of Conscious Experience&quot;. If you <b>only</b> ...", "dateLastCrawled": "2022-02-03T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>alina</b> stefanescu, writer", "url": "https://www.alinastefanescuwriter.com/blog", "isFamilyFriendly": true, "displayUrl": "https://www.<b>alina</b>stefanescuwriter.com/blog", "snippet": "The references aren&#39;t always identified in Moses&#39; poems\u2014there are cathedrals, landscape paintings, city streets\u2014and the reader senses them indirectly through the fleshing out of context, almost <b>like</b> <b>learning</b> to read, where you glean the meaning of <b>a new</b> word from what surrounds it. This indirect description is an interesting poetic strategy in Moses&#39; work.", "dateLastCrawled": "2022-01-31T00:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Hardware Architectures for Deep Learning 1785617680, 9781785617683</b> ...", "url": "https://dokumen.pub/hardware-architectures-for-deep-learning-1785617680-9781785617683.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>hardware-architectures-for-deep-learning-1785617680-9781785617683</b>.html", "snippet": "Smart text and <b>language</b> processing is another field that has been revolutionized by deep <b>learning</b>. Google Translate service now supports text-to-text and <b>spoken</b>-tospoken translation for more than 100 pairs of languages. Online subtitle generation for video streams is another capability that is now viable by deep <b>learning</b>. This rapid growth of the server, desktop, and embedded applications/services based on deep <b>learning</b> has brought about a renaissance in the practical and theoretical aspects ...", "dateLastCrawled": "2022-01-30T13:08:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Deep <b>Learning for NLP and Speech Recognition</b> | William Jacome ...", "url": "https://www.academia.edu/43190210/Deep_Learning_for_NLP_and_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43190210/Deep_<b>Learning_for_NLP_and_Speech_Recognition</b>", "snippet": "Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome. Download PDF. Download Full PDF Package. This paper. A short summary of this paper. 37 Full PDFs related to this paper. READ PAPER. Deep <b>Learning for NLP and Speech Recognition</b> . Download. Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Adversarial Multi-Task Learning of</b> Deep Neural Networks for Robust ...", "url": "https://www.researchgate.net/publication/307889496_Adversarial_Multi-Task_Learning_of_Deep_Neural_Networks_for_Robust_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/307889496_<b>Adversarial_Multi-Task_Learning_of</b>...", "snippet": "There has Figure 1: Automatic <b>spoken</b> <b>language</b> assessment system. been work on <b>learning</b> domain invariant feature representations [16, 17, 18,19], but few, if any, has done so at the front-end ...", "dateLastCrawled": "2022-01-19T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A <b>Brief History of Neural Nets and Deep Learning</b> \u2013 Skynet Today", "url": "https://www.skynettoday.com/overviews/neural-net-history", "isFamilyFriendly": true, "displayUrl": "https://www.skynettoday.com/overviews/neural-net-history", "snippet": "Let\u2019s start with a <b>brief</b> primer on what Machine <b>Learning</b> is. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general function that can map any input value to an output value. This is known as linear regression, and it is a wonderful little 200 year old technique for extrapolating a general function from some set of input-output pairs. And ...", "dateLastCrawled": "2022-02-03T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "On the Opportunities and Risks of Foundation Models \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2108.07258/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2108.07258", "snippet": "Though there are many differing theories about what types of theoretical abstractions the human <b>language</b> system makes (e.g., Comrie, 1989; Chomsky, 2014; Croft, 2001; Jackendoff, 2011), it is generally agreed that humans learn <b>language</b> in a way that allows them to easily slot <b>new</b> knowledge into existing abstractions, and productively create <b>new</b> grammatical sentences. For example, a ten-year-old child has acquired a lot of the abstractions about how their <b>language</b> works, though the actual ...", "dateLastCrawled": "2022-01-27T21:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "NLP-Project/text_val at master \u00b7 jiangxinyang227/NLP-Project \u00b7 GitHub", "url": "https://github.com/jiangxinyang227/NLP-Project/blob/master/multi_label_classifier/data/AAPD/text_val", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/jiangxinyang227/NLP-Project/blob/master/multi_label_classifier/data/...", "snippet": "the dialogue model <b>learning</b> environment supports an engineering oriented approach towards dialogue modelling for a <b>spoken</b> <b>language</b> interface major steps towards dialogue models is to know about the basic units that are used to construct a dialogue model and possible sequences in difference to many other approaches a set of dialogue acts is not predefined by any theory or manually during the engineering process , but is learned from data that are available in an avised <b>spoken</b> dialogue system ...", "dateLastCrawled": "2022-01-30T23:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Proceedings of the <b>Ninth International Conference on Language Resources</b> ...", "url": "https://aclanthology.org/volumes/L14-1/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/volumes/L14-1", "snippet": "This paper presents the first release of the KiezDeutsch Korpus (KiDKo), <b>a new</b> <b>language</b> resource with multiparty <b>spoken</b> dialogues of Kiezdeutsch, a newly emerging <b>language</b> variety <b>spoken</b> by adolescents from multiethnic urban areas in Germany. The first release of the corpus includes the transcriptions of the data as well as a normalisation layer and part-of-speech annotations. In the paper, we describe the main features of the <b>new</b> resource and then focus on automatic POS tagging of informal ...", "dateLastCrawled": "2022-01-30T03:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Linguistics and Pop Culture</b> \u2013 The LINGUIST List", "url": "https://blog.linguistlist.org/category/linguistics-and-pop-culture/", "isFamilyFriendly": true, "displayUrl": "https://blog.linguistlist.org/category/<b>linguistics-and-pop-culture</b>", "snippet": "The Yiddish <b>language</b> has undergone seriously decline in recent decades but the creators of the <b>new</b> version hope that having such an iconic musical entirely in Yiddish will encourage an improved image for the <b>language</b>. Much of the Yiddish-speaking population now resides in the <b>New</b> York City area. With the production of \u201cFiddler of the Roof\u201d happening nearby, it is hoped that increased exposure will strengthen the <b>language</b>\u2019s vitality in the region and encourage the rising generation to ...", "dateLastCrawled": "2021-12-31T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Natural <b>Language</b> Processing Fundamentals for Developers [1&amp;nbsp;ed ...", "url": "https://dokumen.pub/natural-language-processing-fundamentals-for-developers-1nbsped-9781683926573-2021939603.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/natural-<b>language</b>-processing-fundamentals-for-developers-1nbsped...", "snippet": "Since the majority of the values in the <b>new</b> columns equal 0, this can increase the <b>sparsity</b> of the dataset, which in turn can result in more overfitting and hence adversely affect the accuracy of machine <b>learning</b> algorithms that you adopt during the training process. Another solution is to use a sequence-based solution in which N categories are mapped to the integers 1, 2, . . . , N. Another solution involves examining the row frequency of each categorical value. For example, suppose that N ...", "dateLastCrawled": "2022-01-03T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Google publi</b> \u00b7 GitHub", "url": "https://gist.github.com/mdamien/307331a96d5bba9622b1", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/mdamien/307331a96d5bba9622b1", "snippet": "<b>Google publi</b>. GitHub Gist: instantly share code, notes, and <b>snippets</b>.", "dateLastCrawled": "2022-01-04T19:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "CS379C 2019 Class Discussion Notes", "url": "https://web.stanford.edu/class/cs379c/archive/2019/class_messages_listing/index.html", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/cs379c/archive/2019/class_messages_listing/index.html", "snippet": "Class Discussions. Welcome to the 2019 class discussion list. Preparatory notes posted prior to the first day of classes are available here.Introductory lecture material for the first day of classes is available here, a sample of final project suggestions here and last year&#39;s calendar of invited talks here.Since the class content for this year builds on that of last year, you may find it useful to search the material from the 2018 class discussions available here.Several of the invited talks ...", "dateLastCrawled": "2022-02-03T14:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>Brief History of Neural Nets and Deep Learning</b> \u2013 Skynet Today", "url": "https://www.skynettoday.com/overviews/neural-net-history", "isFamilyFriendly": true, "displayUrl": "https://www.skynettoday.com/overviews/neural-net-history", "snippet": "In the years leading up to this point <b>sparsity</b> was shown to be beneficial for deep <b>learning</b>, both because it represents information in a more robust manner and because it leads to significant computational efficiency (if most of your neurons are outputting zero, you <b>can</b> in effect ignore most of them and compute things much faster). Incidentally, researchers in computational neuroscience first introduced the importance of sparse computation in the context of the brain\u2019s visual system, a ...", "dateLastCrawled": "2022-02-03T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Deep <b>Learning for NLP and Speech Recognition</b> | William Jacome ...", "url": "https://www.academia.edu/43190210/Deep_Learning_for_NLP_and_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43190210/Deep_<b>Learning_for_NLP_and_Speech_Recognition</b>", "snippet": "Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome. Download PDF. Download Full PDF Package. This paper. A short summary of this paper. 37 Full PDFs related to this paper. READ PAPER. Deep <b>Learning for NLP and Speech Recognition</b> . Download. Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The development of children\u2019s ability to track and predict turn ...", "url": "https://www.sciencedirect.com/science/article/pii/S0749596X16300596", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0749596X16300596", "snippet": "Spontaneous conversation is a universal context for using and <b>learning</b> <b>language</b>. Like other types of human interaction, it is organized at its core by the roles and goals of its participants. But what sets conversation apart is its structure: sequences of interconnected, communicative actions that take place across alternating turns at talk. Sequential, turn-based structures in conversation are strikingly uniform across <b>language</b> communities and linguistic modalities. Turn-taking behaviors ...", "dateLastCrawled": "2021-10-16T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Linguistics and Pop Culture</b> \u2013 The LINGUIST List", "url": "https://blog.linguistlist.org/category/linguistics-and-pop-culture/", "isFamilyFriendly": true, "displayUrl": "https://blog.linguistlist.org/category/<b>linguistics-and-pop-culture</b>", "snippet": "Although J.R.R. Tolkien was not the first person to attempt constructing a <b>language</b>\u2014that honor goes to the ancients, who constructed languages not for fictional speakers but for the purposes of philosophy, cross-linguistic communication, and aesthetics\u2014his groundbreaking ConLangs <b>can</b> be credited with beginning the rich <b>new</b> era of 20th and 21st century <b>language</b>-creation. Tolkien was a philologist and a professor, who spent much of his time immersed in the same kinds of texts that ...", "dateLastCrawled": "2021-12-31T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Natural Language Processing Using Semantic Frames</b> | Diana ...", "url": "https://www.academia.edu/3097767/Natural_Language_Processing_Using_Semantic_Frames", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/3097767/<b>Natural_Language_Processing_Using_Semantic_Frames</b>", "snippet": "<b>Natural Language Processing Using Semantic Frames</b>. Diana Trandabat. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 37 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package. Translate PDF ...", "dateLastCrawled": "2022-01-27T07:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Other Workshops and Events (2019) - ACL Anthology", "url": "https://aclanthology.org/events/ws-2019/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/events/ws-2019", "snippet": "In this paper we describe a multilingual grounded <b>language</b> <b>learning</b> system adapted from an English-<b>only</b> system. This system learns the meaning of words used in crowd-sourced descriptions by grounding them in the physical representations of the objects they are describing. Our work presents a framework to compare the performance of the system when applied to <b>a new</b> <b>language</b> and to identify modifications necessary to attain equal performance, with the goal of enhancing the ability of robots to ...", "dateLastCrawled": "2022-02-03T11:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "North American Chapter of <b>the Association for Computational Linguistics</b> ...", "url": "https://aclanthology.org/events/naacl-2018/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/events/naacl-2018", "snippet": "Some <b>learning</b> models <b>can</b> be incorporated with prior knowledge using a Bayesian setup, but these <b>learning</b> models do not have the ability to access any organized world knowledge on demand. In this work, we propose to enhance <b>learning</b> models with world knowledge in the form of Knowledge Graph (KG) fact triples for Natural <b>Language</b> Processing (NLP) tasks. Our aim is to develop a deep <b>learning</b> model that <b>can</b> extract relevant prior support facts from knowledge graphs depending on the task using ...", "dateLastCrawled": "2022-01-27T17:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "On the Opportunities and Risks of Foundation Models \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2108.07258/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2108.07258", "snippet": "For example, GPT-3 (Brown et al., 2020), with 175 billion parameters compared to GPT-2\u2019s 1.5 billion, permits in-context <b>learning</b>, in which the <b>language</b> model <b>can</b> be adapted to a downstream task simply by providing it with a prompt (a natural <b>language</b> description of the task), an emergent property that is was neither specifically trained for nor anticipated to arise. Homogenization and emergence interact in a potentially unsettling way. Homogenization could potentially provide enormous ...", "dateLastCrawled": "2022-01-27T21:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "NLP-Project/text_val at master \u00b7 jiangxinyang227/NLP-Project \u00b7 GitHub", "url": "https://github.com/jiangxinyang227/NLP-Project/blob/master/multi_label_classifier/data/AAPD/text_val", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/jiangxinyang227/NLP-Project/blob/master/multi_label_classifier/data/...", "snippet": "the dialogue model <b>learning</b> environment supports an engineering oriented approach towards dialogue modelling for a <b>spoken</b> <b>language</b> interface major steps towards dialogue models is to know about the basic units that are used to construct a dialogue model and possible sequences in difference to many other approaches a set of dialogue acts is not predefined by any theory or manually during the engineering process , but is learned from data that are available in an avised <b>spoken</b> dialogue system ...", "dateLastCrawled": "2022-01-30T23:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>News</b> - Sanghani Center for Artificial Intelligence and Data Analytics", "url": "https://dac.cs.vt.edu/news/news-person/", "isFamilyFriendly": true, "displayUrl": "https://dac.cs.vt.edu/<b>news</b>/<b>news</b>-person", "snippet": "One of the goals in clinical question answering is to develop machine <b>learning</b> methods that <b>can</b> automatically seek answers from relational tables of the EHR database for human-<b>language</b> questions, she said. Traditionally, doctors interact with EHR via searching and filtering functions available in rule-based systems that first turn predefined-rules (user interface) to SQL queries, which will be executed on the database to retrieve patient information.", "dateLastCrawled": "2022-01-18T22:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>Brief History of Neural Nets and Deep Learning</b> \u2013 Skynet Today", "url": "https://www.skynettoday.com/overviews/neural-net-history", "isFamilyFriendly": true, "displayUrl": "https://www.skynettoday.com/overviews/neural-net-history", "snippet": "In the years leading up to this point <b>sparsity</b> was shown to be beneficial for deep <b>learning</b>, both because it represents information in a more robust manner and because it leads to significant computational efficiency (if most of your neurons are outputting zero, you <b>can</b> in effect ignore most of them and compute things much faster). Incidentally, researchers in computational neuroscience first introduced the importance of sparse computation in the context of the brain\u2019s visual system, a ...", "dateLastCrawled": "2022-02-03T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Deep <b>Learning for NLP and Speech Recognition</b> | William Jacome ...", "url": "https://www.academia.edu/43190210/Deep_Learning_for_NLP_and_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43190210/Deep_<b>Learning_for_NLP_and_Speech_Recognition</b>", "snippet": "Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome. Download PDF. Download Full PDF Package. This paper. A short summary of this paper. 37 Full PDFs related to this paper. READ PAPER. Deep <b>Learning for NLP and Speech Recognition</b> . Download. Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Adversarial Multi-Task Learning of</b> Deep Neural Networks for Robust ...", "url": "https://www.researchgate.net/publication/307889496_Adversarial_Multi-Task_Learning_of_Deep_Neural_Networks_for_Robust_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/307889496_<b>Adversarial_Multi-Task_Learning_of</b>...", "snippet": "There has Figure 1: Automatic <b>spoken</b> <b>language</b> assessment system. been work on <b>learning</b> domain invariant feature representations [16, 17, 18,19], but few, if any, has done so at the front-end ...", "dateLastCrawled": "2022-01-19T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "On the Opportunities and Risks of Foundation Models \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2108.07258/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2108.07258", "snippet": "For example, GPT-3 (Brown et al., 2020), with 175 billion parameters <b>compared</b> to GPT-2\u2019s 1.5 billion, permits in-context <b>learning</b>, in which the <b>language</b> model <b>can</b> be adapted to a downstream task simply by providing it with a prompt (a natural <b>language</b> description of the task), an emergent property that is was neither specifically trained for nor anticipated to arise. Homogenization and emergence interact in a potentially unsettling way. Homogenization could potentially provide enormous ...", "dateLastCrawled": "2022-01-27T21:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Natural Language Processing Using Semantic Frames</b> | Diana ...", "url": "https://www.academia.edu/3097767/Natural_Language_Processing_Using_Semantic_Frames", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/3097767/<b>Natural_Language_Processing_Using_Semantic_Frames</b>", "snippet": "<b>Natural Language Processing Using Semantic Frames</b>. Diana Trandabat. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 37 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package. Translate PDF ...", "dateLastCrawled": "2022-01-27T07:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "CS379C 2019 Class Discussion Notes", "url": "https://web.stanford.edu/class/cs379c/archive/2019/class_messages_listing/index.html", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/cs379c/archive/2019/class_messages_listing/index.html", "snippet": "Item 6: <b>language</b> and communication \u2014 despite decades of academic study in the fields of computational linguistics, natural <b>language</b> processing and developmental psychology, we appear to be at a loss for developing theories that <b>can</b> be used to formulate robust, practical <b>language</b> <b>learning</b>. Delving into the background literature is not for the faint of heart, and the acrimonious debates that played out within and between the various communities with a stake in this endeavor are difficult to ...", "dateLastCrawled": "2022-02-03T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "NLP-Project/text_val at master \u00b7 jiangxinyang227/NLP-Project \u00b7 GitHub", "url": "https://github.com/jiangxinyang227/NLP-Project/blob/master/multi_label_classifier/data/AAPD/text_val", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/jiangxinyang227/NLP-Project/blob/master/multi_label_classifier/data/...", "snippet": "the dialogue model <b>learning</b> environment supports an engineering oriented approach towards dialogue modelling for a <b>spoken</b> <b>language</b> interface major steps towards dialogue models is to know about the basic units that are used to construct a dialogue model and possible sequences in difference to many other approaches a set of dialogue acts is not predefined by any theory or manually during the engineering process , but is learned from data that are available in an avised <b>spoken</b> dialogue system ...", "dateLastCrawled": "2022-01-30T23:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Proceedings of the <b>Tenth International Conference on Language Resources</b> ...", "url": "https://aclanthology.org/volumes/L16-1/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/volumes/L16-1", "snippet": "The key idea is to <b>only</b> augment the <b>language</b> model to cover the most frequent cases of phrase sequences, as counted over a TL-side corpus, in order to maximize the cases covered by the <b>new</b> <b>language</b> model entries. Experiments presented in the article show that substantial improvements in translation accuracy are achieved via the proposed method, when integrating the grown <b>language</b> model to the corpus-based MT system.", "dateLastCrawled": "2022-01-30T02:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Multimodal Learning with Deep Boltzmann Machines</b> | Request PDF", "url": "https://www.researchgate.net/publication/267554204_Multimodal_Learning_with_Deep_Boltzmann_Machines", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/267554204_Multimodal_<b>Learning</b>_with_Deep...", "snippet": "A Deep Boltzmann Machine is described for <b>learning</b> a generative model of data that consists of multiple and diverse input modalities. The model <b>can</b> be used to extract a unified representation that ...", "dateLastCrawled": "2021-12-08T22:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Proceedings of the Seventh International Conference on Language</b> ...", "url": "https://aclanthology.org/volumes/L10-1/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/volumes/L10-1", "snippet": "The method <b>can</b> be applied to any <b>language</b> pair with Wikipedia presence, independently of the writing systems involved, and requires <b>only</b> a single simple resource that <b>can</b> be provided by any literate bilingual speaker. It was successfully applied to extract a Hebrew-English transliteration dictionary which, when incorporated in a machine translation system, indeed improved its performance.", "dateLastCrawled": "2022-01-14T20:54:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Sparsity</b> is an essential feature of many contemporary data problems. Remote sensing, various forms of automated screening and other high throughput measurement devices collect a large amount of ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Regularization \u2014 Understanding L1 and L2 regularization for Deep <b>Learning</b>", "url": "https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2-regularization-for-deep-learning-a7b9e4a409bf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2...", "snippet": "The <b>sparsity</b> feature used in L1 regularization has been used extensively as a feature selection mechanism in <b>machine</b> <b>learning</b>. Feature selection is a mechanism which inherently simplifies a ...", "dateLastCrawled": "2022-02-01T00:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "An E\ufb03cient Sparse Metric <b>Learning</b> in High ... - <b>Machine</b> <b>Learning</b>", "url": "http://machinelearning.org/archive/icml2009/papers/46.pdf", "isFamilyFriendly": true, "displayUrl": "<b>machinelearning</b>.org/archive/icml2009/papers/46.pdf", "snippet": "This <b>sparsity</b> prior of <b>learning</b> distance metric serves to regularize the com-plexity of the distance model especially in the \u201cless example number p and high dimension d\u201d setting. Theoretically, by <b>analogy</b> to the covariance estimation problem, we \ufb01nd the proposed distance <b>learning</b> algorithm has a consistent result at rate O!&quot;# m2 logd $% n &amp; to the target distance matrix with at most m nonzeros per row. Moreover, from the imple-mentation perspective, this! 1-penalized log-determinant ...", "dateLastCrawled": "2021-11-19T11:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Discovering governing equations from data</b> by sparse identification of ...", "url": "https://www.pnas.org/content/pnas/113/15/3932.full.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/<b>pnas</b>/113/15/3932.full.pdf", "snippet": "examples. In this work, we combin e <b>sparsity</b>-promoting techniques and <b>machine</b> <b>learning</b> with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only as-sumption about the structureof the model is that there are onlya few important terms that govern the dy namics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to ...", "dateLastCrawled": "2022-01-20T20:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> in Medical Imaging", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4220564/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4220564", "snippet": "SUPERVISED <b>LEARNING</b>. In <b>machine</b> <b>learning</b>, one often seeks to predict an output variable y based on a vector x of input variables. To accomplish this, it is assumed that the input and output approximately obey a functional relationship y=f (x), called the predictive model, as shown in Figure 1.In supervised <b>learning</b>, the predictive model is discovered with the benefit of training data consisting of examples for which both x and y are known. We will denote these available pairs of examples as ...", "dateLastCrawled": "2022-02-03T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "What are the <b>basic concepts in machine learning</b>? I found that the best way to discover and get a handle on the <b>basic concepts in machine learning</b> is to review the introduction chapters to <b>machine learning</b> textbooks and to watch the videos from the first model in online courses. Pedro Domingos is a lecturer and professor on <b>machine learning</b> at the University of Washing and", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Dynamical <b>machine</b> <b>learning</b> volumetric reconstruction of objects ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8027224/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8027224", "snippet": "The sequence index in the angle of illumination plays the role of discrete time in the dynamical system <b>analogy</b>. Thus, the imaging problem turns into a problem of nonlinear system identification, which also suggests dynamical <b>learning</b> as a better fit to regularize the reconstructions. We devised a Recurrent Neural Network (RNN) architecture with a novel Separable-Convolution Gated Recurrent Unit (SC-GRU) as the fundamental building block. Through a comprehensive comparison of several ...", "dateLastCrawled": "2022-01-08T19:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Dynamical machine learning volumetric reconstruction of</b> objects ...", "url": "https://www.nature.com/articles/s41377-021-00512-x", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41377-021-00512-x", "snippet": "Recently, thanks to a ground-breaking observation from 2010 that <b>sparsity</b> can be learnt by a deep neural network 48, the idea of using <b>machine</b> <b>learning</b> to approximate solutions to inverse problems ...", "dateLastCrawled": "2022-02-02T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "regression - Why L1 norm for sparse models - Cross Validated", "url": "https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/45643", "snippet": "There are many norms that lead to <b>sparsity</b> (e.g., as you mentioned, any Lp norm with p &lt;= 1). In general, any norm with a sharp corner at zero induces <b>sparsity</b>. So, going back to the original question - the L1 norm induces <b>sparsity</b> by having a discontinuous gradient at zero (and any other penalty with this property will do so too). $\\endgroup$", "dateLastCrawled": "2022-01-26T23:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>What Are Word Embeddings</b> for Text? - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/what-are-word-embeddings/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>what-are-word-embeddings</b>", "snippet": "The result is a <b>learning</b> model that may result in generally better word embeddings. GloVe, is a new global log-bilinear regression model for the unsupervised <b>learning</b> of word representations that outperforms other models on word <b>analogy</b>, word similarity, and named entity recognition tasks. \u2014 GloVe: Global Vectors for Word Representation, 2014.", "dateLastCrawled": "2022-01-30T18:50:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Learning Neural Representations for Network Anomaly Detection</b>", "url": "https://www.researchgate.net/publication/325797465_Learning_Neural_Representations_for_Network_Anomaly_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/325797465_<b>Learning</b>_Neural_Representations_for...", "snippet": "Many <b>machine</b> <b>learning</b> algorithms have been. Manuscript received December 22, 2017; revised March 13, 2018. This. work is funded by Vietnam International Education De velopment (VIED) and. by ...", "dateLastCrawled": "2021-12-06T22:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Self-representation based dual-graph regularized <b>feature selection</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231215010759", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231215010759", "snippet": "<b>Just as sparsity</b> leads to sparse representation, self-similarity results in self-representation ... Her current research interests include pattern recognition and <b>machine</b> <b>learning</b>. Licheng Jiao (SM\u05f389) received the B.S. degree from Shanghai Jiaotong University, Shanghai, China, in 1982, the M.S. and Ph.D. degrees from Xi\u05f3an Jiaotong University, Xi\u05f3an, China, in 1984 and 1990, respectively. From 1990 to 1991, he was a postdoctoral Fellow in the National Key Laboratory for Radar Signal ...", "dateLastCrawled": "2021-11-22T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Self-representation based dual-graph regularized feature selection ...", "url": "https://web.xidian.edu.cn/rhshang/files/20160516_172953.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.xidian.edu.cn/rhshang/files/20160516_172953.pdf", "snippet": "<b>machine</b> <b>learning</b> and computer vision \ufb01elds [41]. <b>Just as sparsity</b> leads to sparse representation, self-similarity results in self-representation [41]. Taking into account of manifold <b>learning</b> and feature selection, and inspired by the self-representation property and the idea of dual-regularization <b>learning</b> [44,45], we propose a novel feature selection algorithm for clustering, named self-representation based dual-graph regularized feature selection clustering (DFSC). This algorithm ...", "dateLastCrawled": "2022-02-02T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Unsupervised feature selection</b> by <b>regularized self-representation</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0031320314002970", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320314002970", "snippet": "<b>Just as sparsity</b> leads to sparse representation, self-similarity results in self-representation. With the above considerations, in this paper we propose a simple yet very effective <b>unsupervised feature selection</b> method by exploiting the self-representation ability of features. The feature matrix is represented over itself to find the representative feature components. The representation residual is minimized by L 2, 1-norm loss to reduce the effect of outlier samples. Different from the ...", "dateLastCrawled": "2022-01-24T12:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Talk <b>Archive</b> - Research on Algorithms and Incentives in Networks", "url": "https://rain.stanford.edu/schedule/archive.shtml", "isFamilyFriendly": true, "displayUrl": "https://rain.stanford.edu/schedule/<b>archive</b>.shtml", "snippet": "McFowland\u2019s research interests\u2014which lie at the intersection of Information Systems, <b>Machine</b> <b>Learning</b>, and Public Policy\u2014include the development of computationally efficient algorithms for large-scale statistical <b>machine</b> <b>learning</b> and \u201cbig data\u201d analytics. More specifically, his research seeks to demonstrate that many real-world problems faced by organizations, and society more broadly, can be reduced to the tasks of anomalous pattern detection and discovery. As a data and ...", "dateLastCrawled": "2022-01-20T11:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Talks - <b>sites.google.com</b>", "url": "https://sites.google.com/view/dssseminarseries/talks", "isFamilyFriendly": true, "displayUrl": "https://<b>sites.google.com</b>/view/dssseminarseries/talks", "snippet": "Abstracts &amp; Bios for upcoming talks", "dateLastCrawled": "2022-01-27T14:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Sparse representations for text categorization</b>", "url": "https://www.researchgate.net/publication/221479613_Sparse_representations_for_text_categorization", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221479613_Sparse_representations_for_text...", "snippet": "<b>Machine</b> <b>learning</b> for text classification is the cornerstone of document categorization, news filtering, document routing, and personalization. In text domains, effective feature selection is ...", "dateLastCrawled": "2021-12-10T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Continual Learning via Neural Pruning</b> | DeepAI", "url": "https://deepai.org/publication/continual-learning-via-neural-pruning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>continual-learning-via-neural-pruning</b>", "snippet": "Continual <b>learning</b>, the ability of models to learn to solve new tasks beyond what has previously been trained, has garnered much attention from the <b>machine</b> <b>learning</b> community in recent years. This is driven in part by the practical advantages promised by continual <b>learning</b> schemes such as improved performance on subsequent tasks as well as a more efficient use of resources in machines with memory constraints.", "dateLastCrawled": "2021-12-30T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Non-negative data-<b>driven mapping of structural connections</b> with ...", "url": "https://www.sciencedirect.com/science/article/pii/S105381192030759X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S105381192030759X", "snippet": "For ICA, <b>sparsity can be thought of as</b> a proxy for independence. 3.5. In-vivo data decompositions. For real data, we decomposed group-average tractography matrices, using independent component analysis (ICA) and non-negative matrix factorisation (NMF), with a range of model orders K. ICA was initialised with regular PCA, in which the first 500 components were retained (explaining 97% of the total variance). ICA was applied to the reduced dataset using the FastICA algorithm (Hyv\u00e4rinen and ...", "dateLastCrawled": "2021-10-11T05:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Sparse Representations for Text Categorization</b> | Dimitri Kanevsky ...", "url": "https://www.academia.edu/2738730/Sparse_Representations_for_Text_Categorization", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2738730/<b>Sparse_Representations_for_Text_Categorization</b>", "snippet": "A Comparative Study of <b>Machine</b> <b>Learning</b> Methods for Verbal Autopsy Text Classification. By Eric S Atwell and Samuel Danso. CSC435 book proposal. By Russell Frith. Higher-Order Smoothing: A Novel Semantic Smoothing Method for Text Classification. By Murat C Ganiz, Mitat Poyraz, and Zeynep Kilimci. INFORMATION RETRIEVAL. By febi k. Introduction to information retrieval. By Valeria Mesi. Download pdf. \u00d7 Close Log In. Log In with Facebook Log In with Google. Sign Up with Apple. or. Email ...", "dateLastCrawled": "2021-10-13T23:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Continual <b>Learning</b> via Neural Pruning \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1903.04476/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1903.04476", "snippet": "We introduce Continual <b>Learning</b> via Neural Pruning (CLNP), a new method aimed at lifelong <b>learning</b> in fixed capacity models based on neuronal model sparsification. In this method, subsequent tasks are trained using the inactive neurons and filters of the sparsified network and cause zero deterioration to the performance of previous tasks. In order to deal with the possible compromise between model sparsity and performance, we formalize and incorporate the concept of graceful forgetting: the ...", "dateLastCrawled": "2021-11-07T10:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Continual <b>Learning</b> via Neural Pruning", "url": "https://openreview.net/pdf?id=Hyl_XXYLIB", "isFamilyFriendly": true, "displayUrl": "https://openreview.net/pdf?id=Hyl_XXYLIB", "snippet": "Continual <b>learning</b>, the ability of models to learn to solve new tasks beyond what has previously been trained, has garnered much at-tention from the <b>machine</b> <b>learning</b> community in recent years. The main obstacle for effective continual <b>learning</b> is the problem of cata-strophic forgetting: machines trained on new problems forget about", "dateLastCrawled": "2022-01-05T02:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Abstract - arXiv.org e-Print archive", "url": "https://arxiv.org/pdf/1903.04476", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/1903.04476", "snippet": "Continual <b>learning</b>, the ability of models to learn to solve new tasks beyond what has previously been trained, has garnered much attention from the <b>machine</b> <b>learning</b> community in recent years. This is driven in part by the practical advantages promised by continual <b>learning</b> schemes such as improved performance on subsequent tasks as well as a more ef\ufb01cient use of resources in machines with memory constraints. There is also great interest in continual <b>learning</b> from a more long term ...", "dateLastCrawled": "2021-10-25T14:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Introduction to compressed sensing</b>", "url": "https://www.researchgate.net/publication/220043734_Introduction_to_compressed_sensing", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220043734_<b>Introduction_to_compressed_sensing</b>", "snippet": "systems control, clustering, and <b>machine</b> <b>learning</b> [14, 15, 58, 61, 89, 193, 217, 240, 244]. Low-dimensional manifolds hav e also been prop osed as approximate mod-", "dateLastCrawled": "2022-01-14T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Introduction to compressed sensing</b> | Marco Duarte - Academia.edu", "url": "https://www.academia.edu/1443164/Introduction_to_compressed_sensing", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/1443164/<b>Introduction_to_compressed_sensing</b>", "snippet": "<b>Introduction to Compressed Sensing</b> For any x \u2208 \u03a3k , we can associate a k-face of C n with the support and sign pattern of x. One can show that the number of k-faces of AC n is precisely the number of index sets of size k for which signals supported on them can be recovered by (1.12) with B (y) = {z : Az = y}.", "dateLastCrawled": "2022-01-21T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Compressed Sensing : Theory and Applications</b> | Kutyniok, Gitta Eldar ...", "url": "https://b-ok.africa/book/2086657/84a688", "isFamilyFriendly": true, "displayUrl": "https://b-ok.africa/book/2086657/84a688", "snippet": "You can write a book review and share your experiences. Other readers will always be interested in your opinion of the books you&#39;ve read. Whether you&#39;ve loved the book or not, if you give your honest and detailed thoughts then people will find new books that are right for them.", "dateLastCrawled": "2021-12-26T07:22:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(sparsity)  is like +(learning a new language by only hearing it spoken in brief snippets)", "+(sparsity) is similar to +(learning a new language by only hearing it spoken in brief snippets)", "+(sparsity) can be thought of as +(learning a new language by only hearing it spoken in brief snippets)", "+(sparsity) can be compared to +(learning a new language by only hearing it spoken in brief snippets)", "machine learning +(sparsity AND analogy)", "machine learning +(\"sparsity is like\")", "machine learning +(\"sparsity is similar\")", "machine learning +(\"just as sparsity\")", "machine learning +(\"sparsity can be thought of as\")", "machine learning +(\"sparsity can be compared to\")"]}