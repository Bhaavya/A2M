{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Towards Memory Friendly Long-Short Term Memory Networks (LSTMs</b> ...", "url": "https://www.researchgate.net/publication/329648612_Towards_Memory_Friendly_Long-Short_Term_Memory_Networks_LSTMs_on_Mobile_GPUs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/329648612_<b>Towards_Memory_Friendly_Long-Short</b>...", "snippet": "propose two level optimizations to hierarchically explore the. <b>memory</b> friendly <b>LSTM</b> on mobile GPUs, thus, achieving the. substantial improvements on both performance and power. At the inter-cell ...", "dateLastCrawled": "2022-01-21T21:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Hybrid CNN-<b>LSTM</b> approaches for identification of type and locations of ...", "url": "https://www.sciencedirect.com/science/article/pii/S0142061521007973", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0142061521007973", "snippet": "Convolutional <b>long short term memory</b> (C-<b>LSTM</b>) as a hybrid structure of CNN and <b>long short term memory</b> (<b>LSTM</b>) proposed in this paper as a powerful tool for extracting features of FRCs related to transmission line faults. In addition, this paper identifies high impedance faults to achieve the goal of early fault detection. Thus, the ability of the proposed procedure to early fault detection (high impedance faults) can be expressed as one of its most important advantages over other reviewed ...", "dateLastCrawled": "2022-01-11T18:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Tuning Recurrent Neural Networks with <b>Reinforcement</b> Learning", "url": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-<b>reinforcement</b>...", "snippet": "As you may remember from previous posts, these models typically consist of a <b>Long Short-Term Memory</b> (<b>LSTM</b>) network trained on monophonic melodies. This means that melodies are fed into the network one note at a time, and it is trained to predict the next note in the sequence. The figure on the left shows a simplified version of this type of network unrolled over time, in which it is being trained on the first 6 notes of \u201cTwinkle Twinkle Little Star\u201d. From now on, I\u2019ll refer to this ...", "dateLastCrawled": "2022-02-03T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Detection of <b>High Impedance</b> Fault using Machine Learning Techniques ...", "url": "https://ieeexplore.ieee.org/document/8929365/", "isFamilyFriendly": true, "displayUrl": "https://ieeexplore.ieee.org/document/8929365", "snippet": "It uses discrete wavelet transform to monitor high frequency components and a deep learning technique called <b>Long Short Term Memory</b> (<b>LSTM</b>) to detect HIF accurately. Further, the approximate location of fault occurrence is also identified by dividing the distribution network into several monitoring zones. The location identification is done using SVM, neural networks and <b>LSTM</b> with the <b>LSTM</b> model exhibiting the highest accuracy.", "dateLastCrawled": "2021-06-03T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Deep Learning-based Car-overtaking-truck Prediction ...", "url": "https://ccat.umtri.umich.edu/wp-content/uploads/sites/497/2021/05/A-Deep-Learning-based-Car-overtaking-truck-Prediction-Model-When-Considering-Individual-Driving-Styles-Poster.pdf", "isFamilyFriendly": true, "displayUrl": "https://ccat.umtri.umich.edu/wp-content/uploads/sites/497/2021/05/A-Deep-Learning...", "snippet": "\u2022 Combined Empirical mode decomposition with <b>Long short-term memory</b> (EMD-<b>LSTM</b>), a variant of the basic <b>LSTM</b> algorithm, were used to predict real-time overtaking features; \u2022 EMD-<b>LSTM</b> alleviates the time lag issue by decomposing the time-series signals into Intrinsic mode functions (IMF), avoiding misleading local optimums and singular values. 2. Procedure \u2022 Time shift was introduced to measure the time lag between the predicted and target values; \u2022 Different lead time steps for ...", "dateLastCrawled": "2022-01-01T23:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Sentiment-Analysis-using</b>-PyTorch - GitHub Pages", "url": "https://sofiadutta.github.io/datascience-ipynbs/pytorch/Sentiment-Analysis-using-PyTorch.html", "isFamilyFriendly": true, "displayUrl": "https://sofiadutta.github.io/datascience-ipynbs/pytorch/<b>Sentiment-Analysis-using</b>-Py...", "snippet": "The tried-and-true option that seems to always work well with sequence data is called a <b>Long Short Term Memory</b> (<b>LSTM</b>) network.<b>LSTM</b> using the gate functionality can decide which information to keep track of or forget. It uses forget gate to control whether or not the old context should be forgotten. It uses an input gate to control whether or not to add to the current context. It uses an output gate to control the next hidden state based on the current context. In this way, it can capture the ...", "dateLastCrawled": "2022-02-03T17:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Accelerating Deep Neural Networks with Analog <b>Memory</b> Devices", "url": "https://www.techtarget.com/searchstorage/post/Accelerating-Deep-Neural-Networks-with-Analog-Memory-Devices", "isFamilyFriendly": true, "displayUrl": "https://www.techtarget.com/searchstorage/post/Accelerating-Deep-Neural-Networks-with...", "snippet": "The RNN that is met with the most success is called <b>LSTM</b>, <b>long short-term memory</b>, because it uses a complicated series of gates to try and learn what to remember from each token and what it can afford to forget as it goes through a sequence. 07:56 GB: Another popular network for NLP applications are transformer-based networks. Rather than recurrence, these networks go through the tokens in a sequence and try to build up an attention matrix which the network uses to decide which tokens within ...", "dateLastCrawled": "2022-02-02T04:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Forecasting Photovoltaic Electricity Generation at a Private Dwelling ...", "url": "https://www.ijsr.net/archive/v9i9/SR20910193846.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijsr.net/archive/v9i9/SR20910193846.pdf", "snippet": "regression and <b>Long Short Term Memory</b> (<b>LSTM</b>) models were used to assess their ability to forecast PV electricity generation. The potential PV electricity to be generated for the previous five years was then calculated using historical weather data. Based on the assumption that the next five years would have similar weather patterns, the PV electricity forecasted was calculated. The savings potential and break-even time for the installation were then calculated based on the forecasted PV ...", "dateLastCrawled": "2022-01-27T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep learning for Turkish makam music composition", "url": "https://journals.tubitak.gov.tr/elektrik/issues/elk-21-29-7/elk-29-7-13-2101-44.pdf", "isFamilyFriendly": true, "displayUrl": "https://journals.tubitak.gov.tr/elektrik/issues/elk-21-29-7/elk-29-7-13-2101-44.pdf", "snippet": "The backbone of the composer system consists of multilayered <b>long short-term memory</b> (<b>LSTM</b>) networks. ATMMC can create pieces in Hicaz and Nihavent makams in \u015eark\u0131 form, which can be viewed and played with Mus2, a notation software for microtonal music. Statistical analysis shows that pieces composed by ATMMC are approximately 84% similar to training data. ATMMC is an open-source project and can assist Turkish makam music enthusiasts with creating new pieces for professional, educational ...", "dateLastCrawled": "2022-01-03T20:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Machine Learning of Molecular Classification and Quantum Mechanical ...", "url": "https://www.sciencedirect.com/science/article/pii/B9780128186343501326", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/B9780128186343501326", "snippet": "The high dimensional output of are then used as input into a <b>Long short-term memory</b> (<b>LSTM</b>), which is commonly used in nature language recognition is used (), with hyperbolic tangent activation function and 4-layer back-propagation network with rectified linear unit (RELU) activation function. It is trained with 1096 compounds while 279 were used as test data. The overall network structure is shown in Figure 1. Download : Download high-res image (71KB) Download : Download full-size image ...", "dateLastCrawled": "2021-10-26T02:11:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Long short-term memory recurrent neural network architectures for</b> large ...", "url": "https://www.researchgate.net/publication/279714069_Long_short-term_memory_recurrent_neural_network_architectures_for_large_scale_acoustic_modeling", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/279714069_<b>Long_short-term_memory</b>_recurrent...", "snippet": "<b>Long Short-Term Memory</b> (<b>LSTM</b>) is a kind of RNN that is composed of recurrently connected <b>memory</b> blocks that contain <b>memory</b> cells with self-connections to store the temporal states of the network.", "dateLastCrawled": "2022-01-30T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Data-Driven <b>Long</b> Time-Series Electrical Line Trip Fault Prediction ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8272100/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8272100", "snippet": "Many studies such as recurrent neural network (RNN) and <b>long short-term memory</b> (<b>LSTM</b>) network have shown an outstanding ability in increasing the prediction accuracy. However, there still exist some limitations preventing those methods from predicting <b>long</b> time-series sequences in real-world applications. To address these issues, a data-driven method using an improved stacked-Informer network is proposed, and it is used for electrical line trip faults sequence prediction in this paper. This ...", "dateLastCrawled": "2022-01-04T17:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Partial <b>discharge detection on aerial covered conductors</b> using time ...", "url": "https://www.sciencedirect.com/science/article/pii/S0378779620301243", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0378779620301243", "snippet": "A method using <b>Long Short-Term Memory</b> Network (<b>LSTM</b>) to analyze feature variations at different quarter cycles in the waveform. \u2022 A method developed and tested successfully on the ENET public dataset. Abstract. Nowadays, aerial covered conductors (CC) are increasingly used in many places of the world due to their higher operational reliability, reduced construction space and effective protection for wildlife animals. In spite of these advantages, a major challenge of using CC is that the ...", "dateLastCrawled": "2021-12-07T15:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Tuning Recurrent Neural Networks with <b>Reinforcement</b> Learning", "url": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-<b>reinforcement</b>...", "snippet": "As you may remember from previous posts, these models typically consist of a <b>Long Short-Term Memory</b> (<b>LSTM</b>) network trained on monophonic melodies. This means that melodies are fed into the network one note at a time, and it is trained to predict the next note in the sequence. The figure on the left shows a simplified version of this type of network unrolled over time, in which it is being trained on the first 6 notes of \u201cTwinkle Twinkle Little Star\u201d. From now on, I\u2019ll refer to this ...", "dateLastCrawled": "2022-02-03T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Long short-term memory networks in memristor crossbars</b> | Request PDF", "url": "https://www.researchgate.net/publication/325464355_Long_short-term_memory_networks_in_memristor_crossbars", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/325464355_<b>Long_short-term_memory</b>_networks_in...", "snippet": "<b>Long-short term memory</b> (<b>LSTM</b>) is a cognitive architecture that aims to mimic the sequence temporal <b>memory</b> processes in human brain. The state and time-dependent based processing of events is ...", "dateLastCrawled": "2021-11-12T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Towards Memory Friendly Long-Short Term Memory Networks (LSTMs</b> ...", "url": "https://www.researchgate.net/publication/329648612_Towards_Memory_Friendly_Long-Short_Term_Memory_Networks_LSTMs_on_Mobile_GPUs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/329648612_<b>Towards_Memory_Friendly_Long-Short</b>...", "snippet": "propose two level optimizations to hierarchically explore the. <b>memory</b> friendly <b>LSTM</b> on mobile GPUs, thus, achieving the. substantial improvements on both performance and power. At the inter-cell ...", "dateLastCrawled": "2022-01-21T21:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Partial Discharge Detection on Aerial Covered Conductors Using Time ...", "url": "https://ui.adsabs.harvard.edu/abs/2019arXiv190703378D/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2019arXiv190703378D/abstract", "snippet": "In response, we developed a unique method based on time-series decomposition and <b>Long Short-Term Memory</b> Network (<b>LSTM</b>) in addition to unique feature engineering process to recognize PD activities on CC. The proposed method is tested on the ENET public dataset and compared to various traditional classification methods. It demonstrated superior performance and great practicality.", "dateLastCrawled": "2020-11-05T19:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Forecasting Photovoltaic Electricity Generation at a Private Dwelling ...", "url": "https://researchspace.csir.co.za/dspace/bitstream/handle/10204/11677/Smit_2020.pdf?sequence=1", "isFamilyFriendly": true, "displayUrl": "https://researchspace.csir.co.za/dspace/bitstream/handle/10204/11677/Smit_2020.pdf?...", "snippet": "regression and <b>Long Short Term Memory</b> (<b>LSTM</b>) models were used to assess their ability to forecast PV electricity generation. The potential PV electricity to be generated for the previous five years was then calculated using historical weather data. Based on the assumption that the next five years would have <b>similar</b> weather patterns, the PV electricity forecasted was calculated. The savings potential and break-even time for the installation were then calculated based on the forecasted PV ...", "dateLastCrawled": "2022-01-23T06:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Sensors | Free Full-Text | Partial Discharge Recognition with a Multi ...", "url": "https://www.mdpi.com/1424-8220/18/10/3512/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/18/10/3512/htm", "snippet": "Then, a <b>long short-term memory</b> (<b>LSTM</b>) network is utilized for fusing the embedded multi-sensor information. Furthermore, to alleviate the risk of overfitting, a transfer learning approach inspired by manifold learning is also present for model training. To demonstrate, 13 modes of defects considering both the defect types and their relative positions were well designed for a simulated GIS tank. A detailed analysis of the performance reveals the clear superiority of the proposed method ...", "dateLastCrawled": "2021-10-10T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The consequence of failure-<b>Conductor</b> fallen on the ground. | Download ...", "url": "https://www.researchgate.net/figure/The-consequence-of-failure-Conductor-fallen-on-the-ground_fig6_268411010", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/The-consequence-of-failure-<b>Conductor</b>-fallen-on-the...", "snippet": "In response, we developed a unique pattern recognition method based on time-series decomposition and <b>Long Short-Term Memory</b> Network (<b>LSTM</b>) in addition to unique feature engineering process to ...", "dateLastCrawled": "2022-01-31T16:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Towards Memory Friendly Long-Short Term Memory Networks (LSTMs</b> ...", "url": "https://www.researchgate.net/publication/329648612_Towards_Memory_Friendly_Long-Short_Term_Memory_Networks_LSTMs_on_Mobile_GPUs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/329648612_<b>Towards_Memory_Friendly_Long-Short</b>...", "snippet": "propose two level optimizations to hierarchically explore the. <b>memory</b> friendly <b>LSTM</b> on mobile GPUs, thus, achieving the. substantial improvements on both performance and power. At the inter-cell ...", "dateLastCrawled": "2022-01-21T21:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A fault diagnosis method of double-layer <b>LSTM</b> for 10 kV single-core ...", "url": "https://link.springer.com/article/10.1007/s00202-021-01324-3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00202-021-01324-3", "snippet": "Then a Double-Layer <b>Long Short Term Memory</b> (D-<b>LSTM</b>) network is built to process the sequenced input and the fault diagnosis is achieved accurately. The structure of this paper is as follows. Section 2 describes the correlations among observable electrical quantities and constructs the characteristic matrix of combined time series. Section 3 introduces the standard module of <b>LSTM</b> network and establishes the D-<b>LSTM</b> network. The fault diagnosis method for a 10 kV single-core cable is shown in ...", "dateLastCrawled": "2022-01-29T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Generation of <b>music pieces using machine learning: long</b> <b>short-term</b> ...", "url": "https://www.tandfonline.com/doi/full/10.1080/25765299.2019.1649972", "isFamilyFriendly": true, "displayUrl": "https://www.tandfonline.com/doi/full/10.1080/25765299.2019.1649972", "snippet": "This article to implement a piano music generator based on Bach\u2019s style using a <b>long-short term memory</b> (<b>LSTM</b>) NN. We limit ourselves to Bach\u2019s musical style because Bach\u2019s style is a well-known and famous style. Considering more than one style will make the learning process more complicated and the NN might lose a style or part of it during learning another style, this might happen because of the big variations in different musical styles. The obtained results will be later presented ...", "dateLastCrawled": "2022-01-23T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "ECT-<b>LSTM</b>-RNN: <b>An Electrical Capacitance Tomography Model-based</b> <b>Long</b> ...", "url": "https://www.researchgate.net/publication/351542554_ECT-LSTM-RNN_An_Electrical_Capacitance_Tomography_Model-based_Long_Short-Term_Memory_Recurrent_Neural_Networks_for_Conductive_Materials", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/351542554_ECT-<b>LSTM</b>-RNN_An_Electrical...", "snippet": "ECT-<b>LSTM</b>-RNN: <b>An Electrical Capacitance Tomography Model-based</b> <b>Long Short-Term Memory</b> Recurrent <b>Neural Networks for Conductive Materials</b> May 2021 IEEE Access PP(99):1-1", "dateLastCrawled": "2022-01-21T19:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Tuning Recurrent Neural Networks with <b>Reinforcement</b> Learning", "url": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-<b>reinforcement</b>...", "snippet": "As you may remember from previous posts, these models typically consist of a <b>Long Short-Term Memory</b> (<b>LSTM</b>) network trained on monophonic melodies. This means that melodies are fed into the network one note at a time, and it is trained to predict the next note in the sequence. The figure on the left shows a simplified version of this type of network unrolled over time, in which it is being trained on the first 6 notes of \u201cTwinkle Twinkle Little Star\u201d. From now on, I\u2019ll refer to this ...", "dateLastCrawled": "2022-02-03T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Sentiment-Analysis-using</b>-PyTorch - GitHub Pages", "url": "https://sofiadutta.github.io/datascience-ipynbs/pytorch/Sentiment-Analysis-using-PyTorch.html", "isFamilyFriendly": true, "displayUrl": "https://sofiadutta.github.io/datascience-ipynbs/pytorch/<b>Sentiment-Analysis-using</b>-Py...", "snippet": "The tried-and-true option that seems to always work well with sequence data is called a <b>Long Short Term Memory</b> (<b>LSTM</b>) network.<b>LSTM</b> using the gate functionality <b>can</b> decide which information to keep track of or forget. It uses forget gate to control whether or not the old context should be forgotten. It uses an input gate to control whether or not to add to the current context. It uses an output gate to control the next hidden state based on the current context. In this way, it <b>can</b> capture the ...", "dateLastCrawled": "2022-02-03T17:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Investigation and prediction of ethylene Glycol based ZnO nanofluidic ...", "url": "https://www.sciencedirect.com/science/article/pii/S2451904921001955", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2451904921001955", "snippet": "<b>Long-Short Term Memory</b> (<b>LSTM</b>) is a more developed version of recurrent neural networks (RNNs). RNN architectures have an approach based on previous knowledge usage. Therefore, RNNs do not only handle the input instances that have entered the network, but also the input instances within the input previously. In traditional neural networks, input data is given to the network independently. However, the situation is different in RNN architecture. Besides, in RNNs, the output of each data in the ...", "dateLastCrawled": "2021-11-19T10:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The <b>Cyborg Philharmonic: Synchronizing interactive musical performances</b> ...", "url": "https://www.nature.com/articles/s41599-021-00751-8", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41599-021-00751-8", "snippet": "<b>Long short-term memory</b> (<b>LSTM</b>), a variant of RNN with <b>memory</b> and feedback, were shown to be able to capture <b>long</b>-term interactions among a sequence of data points (Sepp and Schmidhuber, 1997 ...", "dateLastCrawled": "2022-01-23T23:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep learning models for <b>traffic flow prediction in autonomous vehicles</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S2214209619302311", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2214209619302311", "snippet": "On a negative side, for a high number of timesteps, BPTT <b>can</b> prove costly. The three most common variants of RNNs are <b>Long Short term Memory</b> (<b>LSTM</b>), Time Delay Neural Network (TDNN) and Gated recurrent unit (GRU) which are discussed as follows. (9) s t = f s (w i x t + w R s t \u2212 1 + b s) (10) y t = f t (w o s t + b y) Download : Download high ...", "dateLastCrawled": "2022-01-30T15:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Sara Adkins Is Jamming Out With Machines</b> | <b>Hackaday</b>", "url": "https://hackaday.com/2019/12/04/sara-adkins-is-jamming-out-with-machines/", "isFamilyFriendly": true, "displayUrl": "https://<b>hackaday.com</b>/2019/12/04/<b>sara-adkins-is-jamming-out-with-machines</b>", "snippet": "For another composition using recurrent neural networks, Sara used TensorFlow to train a 3-layer <b>long short-term memory</b> (<b>LSTM</b>) on a diet of 405 Bach chorales. A chorale is a short hymn-like piece ...", "dateLastCrawled": "2021-12-15T20:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Muscle Fatigue Classification Model Based on <b>LSTM</b> and Improved ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8512101/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8512101", "snippet": "Keywords: surface electromyography, wavelet packet, muscle fatigue, <b>long short-term memory</b>. 1. Introduction. The neuromuscular system consists of the nervous system and the muscular system. The main function of the human muscular system is to provide the energy needed by the human body to perform various actions. Exercise-induced muscle fatigue is a physiological phenomenon in which the maximum voluntary contraction (MVC) capacity and output power of the muscle decreases. The cause of ...", "dateLastCrawled": "2022-01-17T21:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Partial <b>discharge detection on aerial covered conductors</b> using time ...", "url": "https://www.sciencedirect.com/science/article/pii/S0378779620301243", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0378779620301243", "snippet": "A method using <b>Long Short-Term Memory</b> Network (<b>LSTM</b>) to analyze feature variations at different quarter cycles in the waveform. \u2022 A method developed and tested successfully on the ENET public dataset. Abstract. Nowadays, aerial covered conductors (CC) are increasingly used in many places of the world due to their higher operational reliability, reduced construction space and effective protection for wildlife animals. In spite of these advantages, a major challenge of using CC is that the ...", "dateLastCrawled": "2021-12-07T15:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Fault detection and classification on insulated overhead conductors ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/rpg2.12380", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/rpg2.12380", "snippet": "Insulated overhead <b>conductor</b> (IOC) faults are often accompanied by partial discharge (PD) phenomenon. Thus, PD monitoring and recognition plays an important role in evaluating the condition of insula-tion degradation or detecting power line faults. This paper presents a new approach based on a multi-channel CNN-<b>LSTM</b> (convolutional neural network, <b>long short term memory</b>) network for fault detection by determining whether there is local discharge phenomenon on the IOC, in which the three-phase ...", "dateLastCrawled": "2022-01-13T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Tuning Recurrent Neural Networks with <b>Reinforcement</b> Learning", "url": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-<b>reinforcement</b>...", "snippet": "As you may remember from previous posts, these models typically consist of a <b>Long Short-Term Memory</b> (<b>LSTM</b>) network trained on monophonic melodies. This means that melodies are fed into the network one note at a time, and it is trained to predict the next note in the sequence. The figure on the left shows a simplified version of this type of network unrolled over time, in which it is being trained on the first 6 notes of \u201cTwinkle Twinkle Little Star\u201d. From now on, I\u2019ll refer to this ...", "dateLastCrawled": "2022-02-03T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Fault Detection on Insulated Overhead Conductors Based on DWT-<b>LSTM</b> and ...", "url": "https://www.researchgate.net/publication/341198571_Fault_Detection_on_Insulated_Overhead_Conductors_Based_on_DWT-LSTM_and_Partial_Discharge", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341198571_Fault_Detection_on_Insulated...", "snippet": "Discrete Wavelet Transform (DWT) and <b>Long Short Term Memory</b> network (<b>LSTM</b>) for detecting of IOC. fault according to partial discharge, is presented. Firstly, the origina l signal is denoised by ...", "dateLastCrawled": "2022-02-01T04:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Data-Driven <b>Long</b> Time-Series Electrical Line Trip Fault Prediction ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8272100/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8272100", "snippet": "In recent years, many deep neural network (DNN) methods have been applied in power fault prediction [23,24]; the popularly used models are the recurrent neural network (RNN) [23,25] and <b>long short-term memory</b> (<b>LSTM</b>) network . However, these methods have the main drawback that the prediction accuracy will decrease when the <b>long</b> sequence time-series data including a large number of input temporal information is fed into models. In order to address these issues, a data-driven <b>long</b> time-series ...", "dateLastCrawled": "2022-01-04T17:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Fault Detection on Insulated Overhead Conductors Based on DWT-<b>LSTM</b> and ...", "url": "https://ieeexplore.ieee.org/document/9087854/", "isFamilyFriendly": true, "displayUrl": "https://ieeexplore.ieee.org/document/9087854", "snippet": "Insulated conductors <b>can</b> improve the stability of power transmission and reduce the construction space <b>compared</b> with traditional bare conductors. Therefore, insulated conductors are used more and more in overhead power transmission. However, a major challenge of using insulated overhead conductors (IOC) is that the ordinary protection devices are not able to detect the phase-to-ground faults and something, such as tree branch, hitting <b>conductor</b> events. This may cause an accident such as ...", "dateLastCrawled": "2021-09-11T19:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A fault diagnosis method of double-layer <b>LSTM</b> for 10 kV single-core ...", "url": "https://link.springer.com/article/10.1007/s00202-021-01324-3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00202-021-01324-3", "snippet": "Then a Double-Layer <b>Long Short Term Memory</b> (D-<b>LSTM</b>) network is built to process the sequenced input and the fault diagnosis is achieved accurately. The structure of this paper is as follows. Section 2 describes the correlations among observable electrical quantities and constructs the characteristic matrix of combined time series. Section 3 introduces the standard module of <b>LSTM</b> network and establishes the D-<b>LSTM</b> network. The fault diagnosis method for a 10 kV single-core cable is shown in ...", "dateLastCrawled": "2022-01-29T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "ECT-<b>LSTM</b>-RNN: <b>An Electrical Capacitance Tomography Model-based</b> <b>Long</b> ...", "url": "https://www.researchgate.net/publication/351542554_ECT-LSTM-RNN_An_Electrical_Capacitance_Tomography_Model-based_Long_Short-Term_Memory_Recurrent_Neural_Networks_for_Conductive_Materials", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/351542554_ECT-<b>LSTM</b>-RNN_An_Electrical...", "snippet": "ECT-<b>LSTM</b>-RNN: <b>An Electrical Capacitance Tomography Model-based</b> <b>Long Short-Term Memory</b> Recurrent <b>Neural Networks for Conductive Materials</b> May 2021 IEEE Access PP(99):1-1", "dateLastCrawled": "2022-01-21T19:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Sensors | Free Full-Text | Partial Discharge Recognition with a Multi ...", "url": "https://www.mdpi.com/1424-8220/18/10/3512/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/18/10/3512/htm", "snippet": "Then, a <b>long short-term memory</b> (<b>LSTM</b>) network is utilized for fusing the embedded multi-sensor information. Furthermore, to alleviate the risk of overfitting, a transfer learning approach inspired by manifold learning is also present for model training. To demonstrate, 13 modes of defects considering both the defect types and their relative positions were well designed for a simulated GIS tank. A detailed analysis of the performance reveals the clear superiority of the proposed method ...", "dateLastCrawled": "2021-10-10T00:10:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>Learning</b> : Intro to <b>LSTM</b> (<b>Long Short Term Memory</b>) | by HIMANSHU ...", "url": "https://medium.com/@himanshunpatel01/deep-learning-intro-to-lstm-long-short-term-memory-ce504dc6e585", "isFamilyFriendly": true, "displayUrl": "https://medium.com/.../deep-<b>learning</b>-intro-to-<b>lstm</b>-<b>long-short-term-memory</b>-ce504dc6e585", "snippet": "A simple <b>machine</b> <b>learning</b> model or an Artificial Neural Network may learn to predict the stock prices based on a number of features: the volume of the stock, the opening value etc. While the price ...", "dateLastCrawled": "2022-01-27T16:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Gentle Introduction to <b>Long Short-Term Memory</b> Networks by the Experts", "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>long-short-term-memory</b>-networks...", "snippet": "<b>Long Short-Term Memory</b> (<b>LSTM</b>) networks are a type of recurrent neural network capable of <b>learning</b> order dependence in sequence prediction problems. This is a behavior required in complex problem domains like <b>machine</b> translation, speech recognition, and more. LSTMs are a complex area of deep <b>learning</b>. It can be hard to get your hands around what LSTMs are, and how terms like bidirectional", "dateLastCrawled": "2022-01-31T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Long Short Term Memory</b>(<b>LSTM</b>) and <b>Gated Recurrent</b> Units(GRU) | by ...", "url": "https://prvnk10.medium.com/long-short-term-memory-lstm-and-gated-recurrent-units-gru-240d8a62db9", "isFamilyFriendly": true, "displayUrl": "https://prvnk10.medium.com/<b>long-short-term-memory</b>-<b>lstm</b>-and-<b>gated-recurrent</b>-units-gru...", "snippet": "<b>Long Short Term Memory</b> (<b>LSTM</b>) and <b>Gated Recurrent</b> Units (GRU) This article covers the content discussed in the LSTMs and GRU module of the Deep <b>Learning</b> course offered on the website: https://padhai.onefourthlabs.in. The problem with the RNN is that we want the output at every time step to b e dependent on the previous input and the way we do ...", "dateLastCrawled": "2022-01-30T07:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "9.2. <b>Long Short-Term Memory</b> (<b>LSTM</b>) \u2014 Dive into Deep <b>Learning</b> 0.17.2 ...", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_recurrent-modern/<b>lstm</b>.html", "snippet": "The challenge to address <b>long</b>-term information preservation and <b>short-term</b> input skipping in latent variable models has existed for a <b>long</b> time. One of the earliest approaches to address this was the <b>long short-term memory</b> (<b>LSTM</b>) [Hochreiter &amp; Schmidhuber, 1997]. It shares many of the properties of the GRU. Interestingly, LSTMs have a slightly more complex design than GRUs but predates GRUs by almost two decades. 9.2.1. Gated <b>Memory</b> Cell\u00b6 Arguably <b>LSTM</b>\u2019s design is inspired by logic gates ...", "dateLastCrawled": "2022-02-02T23:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>CPSC 540: Machine Learning</b>", "url": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W20/L32.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W20/L32.pdf", "snippet": "<b>CPSC 540: Machine Learning</b> <b>Long Short Term Memory</b> Winter 2020. Previously: Sequence-to-Sequence \u2022Sequence-to-sequence: \u2013Recurrent neural network for sequences of different lengths. \u2022 ^Encoding phase that takes an input at each time. \u2022 ^Decoding phase that makes an output at each time. \u2013Encoding ends with BOS, decoding ends with EOS. x 1 z 1 x 2 z 2 x 3 z 0 z 3 z 4 z 5 y 1 y 2. Variations on Recurrent Neural Networks \u2022Bi-directional RNNs: feedforward from past and future ...", "dateLastCrawled": "2021-11-08T22:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Model Reduction with Memory and</b> <b>the Machine Learning of Dynamical</b> ...", "url": "https://deepai.org/publication/model-reduction-with-memory-and-the-machine-learning-of-dynamical-systems", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>model-reduction-with-memory-and</b>-the-<b>machine</b>-<b>learning</b>-of...", "snippet": "2.2 <b>Long short-term memory</b> networks. Theoretically, RNNs is capable of <b>learning</b> <b>long</b>-term <b>memory</b> effects in the time series. However, in practice it is hard for RNN to catch such dependencies, because of the exploding or shrinking gradient effects , . The <b>Long Short-Term Memory</b> (<b>LSTM</b>) network is designed to solve this problem. Proposed by Hochreiter et al. , the <b>LSTM</b> introduces a new group of hidden units called states, and uses gates to control the information flow through the states. Since ...", "dateLastCrawled": "2022-01-17T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Long Short Term Memory and Gated Recurrent Unit</b>\u2019s Explained \u2014 ELI5 Way ...", "url": "https://towardsdatascience.com/long-short-term-memory-and-gated-recurrent-units-explained-eli5-way-eff3d44f50dd", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>long-short-term-memory-and-gated-recurrent</b>-units...", "snippet": "Hi All, welcome to my blog \u201c<b>Long Short Term Memory and Gated Recurrent Unit</b>\u2019s Explained \u2014 ELI5 Way\u201d this is my last blog of the year 2019.My name is Niranjan Kumar and I\u2019m a Senior Consultant Data Science at Allstate India.. Recurrent Neural Networks(RNN) are a type of Neural Network where the output from the previous step is fed as input to the current step.", "dateLastCrawled": "2022-01-24T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "NPTEL :: Computer Science and Engineering - NOC:Deep <b>Learning</b>- Part 1", "url": "https://www.nptel.ac.in/courses/106/106/106106184/", "isFamilyFriendly": true, "displayUrl": "https://www.nptel.ac.in/courses/106/106/106106184", "snippet": "Selective Read, Selective Write, Selective Forget - The Whiteboard <b>Analogy</b>: Download: 109: <b>Long Short Term Memory</b>(<b>LSTM</b>) and Gated Recurrent Units(GRUs) Download: 110: How LSTMs avoid the problem of vanishing gradients: Download: 111: How LSTMs avoid the problem of vanishing gradients (Contd.) Download: 112: Introduction to Encoder Decoder ...", "dateLastCrawled": "2022-01-25T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Multistep Time Series Forecasting with</b> LSTMs in Python", "url": "https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>multi-step-time-series-forecasting</b>-<b>long</b>-<b>short-term</b>...", "snippet": "The <b>Long Short-Term Memory</b> network or <b>LSTM</b> is a recurrent neural network that can learn and forecast <b>long</b> sequences. A benefit of LSTMs in addition to <b>learning</b> <b>long</b> sequences is that they can learn to make a one-shot multi-step forecast which may be useful for <b>time series forecasting</b>. A difficulty with LSTMs is that they can be tricky to configure and it", "dateLastCrawled": "2022-02-02T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Introduction to Transformers in Machine Learning</b>", "url": "https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/.../12/28/<b>introduction-to-transformers-in-machine-learning</b>", "snippet": "Fortunately, in the 2010s, <b>Long Short-Term Memory</b> networks (LSTMs, top right) and Gated Recurrent Units (GRUs, bottom) were researched and applied to resolve many of the three issues above. LSTMs in particular, through the cell like structure where <b>memory</b> is retained, are robust to the vanishing gradients problem. What\u2019s more, because <b>memory</b> is now maintained separately from the previous cell output (the \\(c_{t}\\) flow in the", "dateLastCrawled": "2022-02-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>learning</b> hybrid model with Boruta-Random forest optimiser ...", "url": "https://www.sciencedirect.com/science/article/pii/S0022169421003978", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0022169421003978", "snippet": "The <b>long short-term memory (LSTM) is like</b> the recurrent neural network (RNN), popularly used in the deep <b>learning</b> field. Likewise, the RNN architecture, LSTM, has a feedback connection with the layers, which can establish the complete sequences of the inputs. The description of LSTM networks can be found different from researches Britz, 2015, Chollet, 2016, Ghimire et al., 2019c, Graves, 2012, Olah, 2015). The LSTM networks are introduced to solve the problems associated with conventional ...", "dateLastCrawled": "2022-01-26T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep <b>Learning</b> Approach for Aggressive Driving Behaviour Detection", "url": "https://arxiv.org/pdf/2111.04794v1", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/2111.04794v1", "snippet": "ML = <b>Machine</b> <b>Learning</b> DL = Deep <b>Learning</b> RNN = Recurrent Neural Network GRU = Gated Recurrent Unit LSTM = Long Short-Term Memory Introduction With the number of automobile accidents, fuel economy, and determining the level of driving talent, the DBA (Driving Behaviour Analysis) becomes a critical subject to be calculated. Depending on the types of car sensors, the inputs . and outputs can then be examined to establish if the DBC (Driving Behaviour Classification) is normal or deviant ...", "dateLastCrawled": "2021-12-09T07:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>Learning</b> Methods Cancer Diagnosis", "url": "https://www.linkedin.com/pulse/deep-learning-methods-cancer-diagnosis-jims-vasant-kunj-ii", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/deep-<b>learning</b>-methods-cancer-diagnosis-jims-vasant-kunj-ii", "snippet": "Classifiers in <b>Machine</b> <b>Learning</b> and its Application: ... <b>Long Short-Term Memory (LSTM) is similar</b> to RNN. It is used for <b>learning</b> order dependence in sequential prediction problems. Conclusion ...", "dateLastCrawled": "2022-01-13T06:31:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(long short-term memory (lstm))  is like +(conductor)", "+(long short-term memory (lstm)) is similar to +(conductor)", "+(long short-term memory (lstm)) can be thought of as +(conductor)", "+(long short-term memory (lstm)) can be compared to +(conductor)", "machine learning +(long short-term memory (lstm) AND analogy)", "machine learning +(\"long short-term memory (lstm) is like\")", "machine learning +(\"long short-term memory (lstm) is similar\")", "machine learning +(\"just as long short-term memory (lstm)\")", "machine learning +(\"long short-term memory (lstm) can be thought of as\")", "machine learning +(\"long short-term memory (lstm) can be compared to\")"]}