{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Exploring <b>Convolutional</b> <b>Neural Network</b> Architectures with fast.ai | by ...", "url": "https://towardsdatascience.com/exploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/exploring-<b>convolutional</b>-<b>neural-network</b>-architectures...", "snippet": "<b>Rearranging</b> this expression, we get F(x) ... the resolution and hence, the number of <b>pixels</b>. This allos the network to extract finer patterns from the additional <b>image</b> detail. <b>Like</b> the other scaling dimensions, this too provides limited accuracy gains on its own. Network scaling methods. <b>Image</b> by author. The researchers found that balancing the amount of scaling in each of the dimensions of network width, depth, and resolution was necessary to extract the most amount of benefit with minimal ...", "dateLastCrawled": "2022-02-01T03:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Convolutional neural networks</b>. - Jeremy Jordan", "url": "https://www.jeremyjordan.me/convolutional-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.jeremyjordan.me/<b>convolutional-neural-networks</b>", "snippet": "Note: The convolution <b>operation</b> may be more accurately describing as calculating the cross correlation between the <b>image</b> input and a given filter. In pure mathematical terms, a convolution involves flipping the kernel matrix, but since we&#39;re simply learning parameter values, this <b>operation</b> doesn&#39;t add any value. Deep <b>convolutional</b> networks", "dateLastCrawled": "2021-03-28T23:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Deep Learning (4/5): <b>Convolutional</b> Neural Networks", "url": "https://tiefenauer.github.io/ml/deep-learning/4", "isFamilyFriendly": true, "displayUrl": "https://tiefenauer.github.io/ml/deep-learning/4", "snippet": "A <b>convolution</b> <b>operation</b> reduces an <b>image</b> (or generally: a previous layer) by applying a filter (a.k.a. kernel). This filter is a matrix that is being moved step by step over the <b>image</b>. In each step, all the elements of the <b>image</b> matrix that are being covered by the filter are multiplied with the corresnponding elements in the filter matrix. The products are then added up and the filter is moved into the next position. This process is repeated until all <b>the pixels</b> have been captured. A ...", "dateLastCrawled": "2021-11-25T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "part of Course 193 - Library for End-to-End Machine Learning", "url": "https://e2eml.school/how_convolutional_neural_networks_work.html", "isFamilyFriendly": true, "displayUrl": "https://e2eml.school/how_<b>convolutional_neural_networks</b>_work.html", "snippet": "To a computer, an <b>image</b> looks <b>like</b> a two-dimensional array of <b>pixels</b> (think giant checkerboard) with a number in each position. In our example a pixel value of 1 is white, and -1 is black. When comparing two images, if any pixel values don\u2019t match, then the images don\u2019t match, at least to the computer. Ideally, we would <b>like</b> to be able to see X\u2019s and O\u2019s even if they\u2019re shifted, shrunken, rotated or deformed. This is where CNNs come in.", "dateLastCrawled": "2022-01-29T17:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Kernel Convolution</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/kernel-convolution", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>kernel-convolution</b>", "snippet": "The complete output <b>image</b> g(m, n) is obtained by repeating the same <b>operation</b> on all <b>pixels</b> of the original <b>image</b> [4, 5, 13]. A convolution kernel can be applied to an <b>image</b> in order to effect a specific enhancement <b>operation</b> or change in the <b>image</b> characteristics. This typically results in desirable attributes being amplified and undesirable attributes being suppressed. The specific values of the kernel coefficients depend on the different types of enhancement that may be desired.", "dateLastCrawled": "2022-01-26T00:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Mesin Belajar: <b>How do Convolutional Neural Networks work</b>?", "url": "https://mesin-belajar.blogspot.com/2016/09/how-do-convolutional-neural-networks.html", "isFamilyFriendly": true, "displayUrl": "https://mesin-belajar.blogspot.com/2016/09/<b>how-do-convolutional-neural-networks</b>.html", "snippet": "To a computer, an <b>image</b> looks <b>like</b> a two-dimensional array of <b>pixels</b> (think giant checkerboard) with a number in each position. In our example a pixel value of 1 is white, and -1 is black. When comparing two images, if any pixel values don\u2019t match, then the images don\u2019t match, at least to the computer. Ideally, we would <b>like</b> to be able to see X\u2019s and O\u2019s even if they\u2019re shifted, shrunken, rotated or deformed. This is where CNNs come in.", "dateLastCrawled": "2022-02-01T17:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>A convolutional neural networks approach using</b> X-Ray absorption images ...", "url": "https://link.springer.com/article/10.1007/s42452-020-03835-3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42452-020-03835-3", "snippet": "The last layer (h) provides two outputs that could be interpreted as the probability in which the original <b>image</b> (64 \u00d7 64 <b>pixels</b>) can be classified as an <b>image</b> from an exhausted or virgin GAC. Probability values can be used to have an idea of the exhaustion degree of a GAC. Typical CNN2D classifiers always expect an input of the same size. Taking this into account, modification in original images dimensions were applied in order to evaluate XRA-2D network performance by reducing its ...", "dateLastCrawled": "2022-01-23T22:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deep learning <b>for remote sensing image classification: A survey</b> - Li ...", "url": "https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1264", "isFamilyFriendly": true, "displayUrl": "https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1264", "snippet": "Recently, another DL architecture, of <b>convolutional</b> neural networks (CNNs) (Lecun, Bottou, Bengio, ... As the computation process of pooling <b>operation</b> takes neighboring <b>pixels</b> into account, a pooling layer is translation invariant. Apart from average and max pooling, there are several other pooling operations, including spatial pyramid pooling (He et al., 2014), stochastic pooling (Zeiler &amp; Fergus, 2013) and def-pooling (Ouyang et al., 2014). Figure 2. Open in figure viewer PowerPoint. Two ...", "dateLastCrawled": "2022-01-27T15:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>How do Neural Networks work</b>? - Tale of a Zombie", "url": "https://nirjhor.wordpress.com/2016/09/28/how-do-neural-networks-work/", "isFamilyFriendly": true, "displayUrl": "https://nirjhor.wordpress.com/2016/09/28/<b>how-do-neural-networks-work</b>", "snippet": "To a computer, an <b>image</b> looks <b>like</b> a two-dimensional array of <b>pixels</b> (think giant chequerboard) with a number in each position. In our example a pixel value of 1 is white, and -1 is black. When comparing two images, if any pixel values don\u2019t match, then the images don\u2019t match, at least to the computer. Ideally, we would <b>like</b> to be able to see X\u2019s and O\u2019s even if they\u2019re shifted, shrunken, rotated or deformed. This is where CNNs come in.", "dateLastCrawled": "2022-01-17T09:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "FRD-CNN: Object detection based on small-scale <b>convolutional</b> neural ...", "url": "https://www.nature.com/articles/s41598-019-52580-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-019-52580-0", "snippet": "As shown in Fig. 6, the FRD-CNN takes an <b>image</b> as input, and the fire-FR-CNN is responsible for feature extraction from the <b>image</b>. Then, the feature map is passed to the object detection network ...", "dateLastCrawled": "2022-01-25T17:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep Learning (4/5): <b>Convolutional</b> Neural Networks", "url": "https://tiefenauer.github.io/ml/deep-learning/4", "isFamilyFriendly": true, "displayUrl": "https://tiefenauer.github.io/ml/deep-learning/4", "snippet": "A <b>convolution</b> <b>operation</b> reduces an <b>image</b> (or generally: a previous layer) by applying a filter (a.k.a. kernel). This filter is a matrix that is being moved step by step over the <b>image</b>. In each step, all the elements of the <b>image</b> matrix that are being covered by the filter are multiplied with the corresnponding elements in the filter matrix. The products are then added up and the filter is moved into the next position. This process is repeated until all <b>the pixels</b> have been captured. A ...", "dateLastCrawled": "2021-11-25T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Exploring <b>Convolutional</b> <b>Neural Network</b> Architectures with fast.ai | by ...", "url": "https://towardsdatascience.com/exploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/exploring-<b>convolutional</b>-<b>neural-network</b>-architectures...", "snippet": "All <b>convolutional</b> neural networks (CNNs) have three dimensions: width, depth, and resolution. Depth refers to the number of layers, width refers to the number of channels (e.g. 3 channels in RGB) and the resolution refers to the number of <b>pixels</b> <b>in an image</b>. Each of these dimensions can be scaled, and each raise the accuracy of the CNN up to a ...", "dateLastCrawled": "2022-02-01T03:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Converting tabular data into images for deep learning with ...", "url": "https://www.nature.com/articles/s41598-021-90923-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-90923-y", "snippet": "<b>Convolutional</b> neural networks (CNNs) have been successfully used in numerous applications, such as <b>image</b> and video recognition 1,2,3,4, medical <b>image</b> analysis 5,6, natural language processing 7 ...", "dateLastCrawled": "2022-02-03T17:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Convolutional neural networks</b>. - Jeremy Jordan", "url": "https://www.jeremyjordan.me/convolutional-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.jeremyjordan.me/<b>convolutional-neural-networks</b>", "snippet": "You can also pad the edges of your images with 0-valued <b>pixels</b> as to fully scan the original <b>image</b> and preserve its complete dimensions. <b>Image</b> credit. As an example, I took an <b>image</b> of myself sailing and applied four filters, each of which look for a certain type of edge in the photo. You can see the resulting output below. As shown in the example above, a typical <b>convolutional</b> layer will apply multiple filters, each of which output a feature mapping of the input signifying the (spatial ...", "dateLastCrawled": "2021-03-28T23:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Kernel Convolution</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/kernel-convolution", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>kernel-convolution</b>", "snippet": "The complete output <b>image</b> g(m, n) is obtained by repeating the same <b>operation</b> on all <b>pixels</b> of the original <b>image</b> [4, 5, 13]. A convolution kernel can be applied to an <b>image</b> in order to effect a specific enhancement <b>operation</b> or change in the <b>image</b> characteristics. This typically results in desirable attributes being amplified and undesirable attributes being suppressed. The specific values of the kernel coefficients depend on the different types of enhancement that may be desired.", "dateLastCrawled": "2022-01-26T00:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>A convolutional neural networks approach using</b> X-Ray absorption images ...", "url": "https://link.springer.com/article/10.1007/s42452-020-03835-3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42452-020-03835-3", "snippet": "The last layer (h) provides two outputs that could be interpreted as the probability in which the original <b>image</b> (64 \u00d7 64 <b>pixels</b>) can be classified as an <b>image</b> from an exhausted or virgin GAC. Probability values can be used to have an idea of the exhaustion degree of a GAC. Typical CNN2D classifiers always expect an input of the same size. Taking this into account, modification in original images dimensions were applied in order to evaluate XRA-2D network performance by reducing its ...", "dateLastCrawled": "2022-01-23T22:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning Super-Resolution</b> - An Introduction to AI Upsampling", "url": "https://artoriuz.github.io/blog/super_resolution.html", "isFamilyFriendly": true, "displayUrl": "https://artoriuz.github.io/blog/super_resolution.html", "snippet": "ESPCN [5] stands for Efficient Sub-Pixel <b>Convolutional</b> Neural Network, and it came as a novel alternative to the transposed convolution layer introduced before. The key difference this time is that this network reconstructs the high-resolution <b>image</b> <b>rearranging</b> several channels into a single larger channel in a \u201cdepth-to-space\u201d <b>operation</b>.", "dateLastCrawled": "2022-02-03T01:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Interpolation based Single-path Sub-pixel Convolution for Super ...", "url": "http://203.250.218.22/article/JAKO202102565120224.pdf", "isFamilyFriendly": true, "displayUrl": "203.250.218.22/article/JAKO202102565120224.pdf", "snippet": "<b>Image</b> super-resolution (SR) is an important task in computer vision to increase or recover the size of a low-resolution (LR) <b>image</b>, generating a high-resolution (HR) output. This is usually referred to as single <b>image</b> super-resolution (SISR). SISR is an ill-posed problem, as there are various solutions for any LR <b>image</b>. Applications on SISR in recent years can be found in surveillance imaging [1], medical imaging [2], High-definition television, and more. One of the traditional <b>image</b> ...", "dateLastCrawled": "2022-01-31T09:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "FRD-CNN: Object detection based on small-scale <b>convolutional</b> neural ...", "url": "https://www.nature.com/articles/s41598-019-52580-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-019-52580-0", "snippet": "As shown in Fig. 6, the FRD-CNN takes an <b>image</b> as input, and the fire-FR-CNN is responsible for feature extraction from the <b>image</b>. Then, the feature map is passed to the object detection network ...", "dateLastCrawled": "2022-01-25T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Deep learning <b>for remote sensing image classification: A survey</b> - Li ...", "url": "https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1264", "isFamilyFriendly": true, "displayUrl": "https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1264", "snippet": "Here, a scene <b>image</b> usually refers to a local <b>image</b> patch manually extracted from large-scale high-resolution aerial or satellite images that contain explicit semantic classes (e.g., residential area, commercial area, etc.). Due to high resolutions in such data, different scene images may contain the same types of objects or share <b>similar</b> ...", "dateLastCrawled": "2022-01-27T15:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Uncertainty-Aware <b>Convolutional</b> Neural Networks for Vision Tasks ...", "url": "https://www.researchgate.net/publication/352520655_Uncertainty-Aware_Convolutional_Neural_Networks_for_Vision_Tasks_on_Sparse_Data", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/352520655_Uncertainty-Aware_<b>Convolutional</b>...", "snippet": "Convolution operator <b>can</b> not discriminate between missing <b>pixels</b> and zerovalued <b>pixels</b> leading to artifacts in the output. (a) The original <b>image</b>, (b) 65% of <b>the pixels</b> were randomly removed from ...", "dateLastCrawled": "2022-02-02T12:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Studying and Analysing the Effect of Weight Norm Penalties and Dropout ...", "url": "https://www.ijert.org/research/studying-and-analysing-the-effect-of-weight-norm-penalties-and-dropout-as-regularizers-for-small-convolutional-neural-networks-IJERTV10IS010025.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijert.org/research/studying-and-analysing-the-effect-of-weight-norm...", "snippet": "<b>image</b> datasets. These artificial neural networks give unrivalled results on data that <b>can</b> be structured to have a grid-like topology. This is the reason why <b>convolutional</b> networks are chosen for computer vision applications as the feature images <b>can</b> be reduced to form either a 2D or 3D grid of <b>pixels</b>. The success of these modern gradient-based networks is associated with the fact that this type of network architecture makes use of sparse interactions wherein, each convolution <b>operation</b> is ...", "dateLastCrawled": "2022-01-30T21:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Transporter Networks: <b>Rearranging</b> the Visual World for Robotic ...", "url": "https://www.arxiv-vanity.com/papers/2010.14406/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2010.14406", "snippet": "Manipulation involves <b>rearranging</b> things, which <b>can</b> <b>be thought</b> of as executing a sequence of spatial displacements: where the space being moved (i.e., transported) <b>can</b> encompass an object(s), part of an object, or end effector. We formulate vision for manipulation as estimating these displacements. Transporter Networks directly optimize for this by learning to 1) attend to a local region, and 2) predict its target spatial displacement via deep feature template matching \u2013 which then ...", "dateLastCrawled": "2022-01-24T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The Ancient Secrets of Computer Vision 4 by Joseph Redmon ...", "url": "https://heartbeat.comet.ml/the-ancient-secrets-of-computer-vision-4-by-joseph-redmon-convolutions-546f4032f335", "isFamilyFriendly": true, "displayUrl": "https://heartbeat.comet.ml/the-ancient-secrets-of-computer-vision-4-by-joseph-redmon...", "snippet": "<b>Rearranging</b> equation (A) we get: (A) c = 0.5m - 0.5. Subbing into (B) we get: 6.5m + 0.5m - 0.5 = 3.5. Which simplifies to find that: m = 4/7 c = -3/14 (we get this by simply subbing m into either (A) or (B) above) Finally, we find our linear mapping by subbing our values into Y=mX+c. Y = (4/7)X - (3/14) We <b>can</b> now iterate over each point in the desired 7x7 <b>image</b> to map back to the old coordinates in the 4x4 <b>image</b>. Example: (1, 3) in the new 7x7 <b>image</b> was (5/14, 1.5) in the old 4x4 <b>image</b> ...", "dateLastCrawled": "2022-01-15T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Remote Sensing | Free Full-Text | An End-to-End Local-Global-Fusion ...", "url": "https://www.mdpi.com/2072-4292/11/24/3006/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/11/24/3006/htm", "snippet": "The <b>rearranging</b> local features proposed in Reference cannot be trained end-to-end. The process of <b>rearranging</b> is complex and computationally intensive. The attention recurrent <b>convolutional</b> network in Reference <b>can</b> be trained end-to-end, but the attention map is generated to reweigh the importance of every element in the high-level feature map, and not different regions. Based on the above discussions and aforementioned limitations, this paper proposes an end-to-end local-global-fusion ...", "dateLastCrawled": "2022-01-08T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Studying and Analysing the Effect of Weight Norm Penalties and ... - IJERT", "url": "https://www.ijert.org/studying-and-analysing-the-effect-of-weight-norm-penalties-and-dropout-as-regularizers-for-small-convolutional-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://www.ijert.org/studying-and-analysing-the-effect-of-weight-norm-penalties-and...", "snippet": "Modern <b>Convolutional</b> Neural Networks (CNNs) [1] trained using the backpropagation algorithm [2] are predominantly suited for this task and has achieved state-of-the-art results in several <b>image</b> datasets. These artificial neural networks give unrivalled results on data that <b>can</b> be structured to have a grid-like topology. This is the reason why <b>convolutional</b> networks are chosen for computer vision applications as the feature images <b>can</b> be reduced to form either a 2D or 3D grid of <b>pixels</b>. The ...", "dateLastCrawled": "2022-01-22T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Reinforcement Learning and DQN</b>, learning to play from <b>pixels</b> - Ruben ...", "url": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-Reinforcement-Learning-and-DQN.html", "isFamilyFriendly": true, "displayUrl": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-<b>Reinforcement-Learning-and-DQN</b>.html", "snippet": "<b>Convolutional</b> layers and <b>image</b> preprocessing <b>Convolutional</b> layers . <b>Convolutional</b> layer Source. <b>Convolutional</b> layers are layers that are excellent to detect local patterns in images. For <b>pixels</b>, it is used as a processor that is required to reduce the dimension of the input into its real manifold. Given the proper manifold of observations, the decision becomes much easier. <b>Image</b> processing. You could feed the neural network with the RGB directly, but then the network would have to also learn ...", "dateLastCrawled": "2022-01-31T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A comparative study <b>of convolutional neural network</b> models for wind ...", "url": "https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.1961", "isFamilyFriendly": true, "displayUrl": "https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.1961", "snippet": "The architecture of the low-resolution branch of LinearCNN <b>can</b> <b>be thought</b> of as an encoder\u2013decoder scheme. The standard convolution layer transforms the (5 \u00d7 5) -pixel input patch into a multi-dimensional (1 \u00d7 1) -pixel feature representation, whereas the transpose convolution decodes the features and expands the output to match the resolution of the target domain.", "dateLastCrawled": "2022-01-30T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning :: Cosine Similarity for Vector</b> Space Models (Part III ...", "url": "https://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/", "isFamilyFriendly": true, "displayUrl": "https://blog.christianperone.com/2013/09/machine-learning-", "snippet": "<b>Rearranging</b> the equation to understand it better using the commutative property, we have: So, ... The tfidf_matrix[0:1] is the Scipy <b>operation</b> to get the first row of the sparse matrix and the resulting array is the Cosine Similarity between the first document with all documents in the set. Note that the first value of the array is 1.0 because it is the Cosine Similarity between the first document with itself. Also note that due to the presence of similar words on the third document (\u201cThe ...", "dateLastCrawled": "2022-01-29T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>DNN Dataflow Choice Is Overrated</b> | DeepAI", "url": "https://deepai.org/publication/dnn-dataflow-choice-is-overrated", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>dnn-dataflow-choice-is-overrated</b>", "snippet": "The FC computation <b>can</b> <b>be thought</b> of as an . M \u00d7 N. matrix-vector multiplication, which maps . M input values to N output values. Unlike CONV layers, the M \u00d7 N unique weights have much larger dimensions than the layer inputs and outputs, and are only reused when applied to data batches. Note that FC layers <b>can</b> also be described similarly using the nested loops in Algorithm 1, but only with C, K, and B loops, while other loops bounds are all 1. DNNs also include other layer types such as ...", "dateLastCrawled": "2022-01-04T19:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep Learning (4/5): <b>Convolutional</b> Neural Networks", "url": "https://tiefenauer.github.io/ml/deep-learning/4", "isFamilyFriendly": true, "displayUrl": "https://tiefenauer.github.io/ml/deep-learning/4", "snippet": "A <b>convolution</b> <b>operation</b> reduces an <b>image</b> (or generally: a previous layer) by applying a filter (a.k.a. kernel). This filter is a matrix that is being moved step by step over the <b>image</b>. In each step, all the elements of the <b>image</b> matrix that are being covered by the filter are multiplied with the corresnponding elements in the filter matrix. The products are then added up and the filter is moved into the next position. This process is repeated until all <b>the pixels</b> have been captured. A ...", "dateLastCrawled": "2021-11-25T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Exploring <b>Convolutional</b> <b>Neural Network</b> Architectures with fast.ai | by ...", "url": "https://towardsdatascience.com/exploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/exploring-<b>convolutional</b>-<b>neural-network</b>-architectures...", "snippet": "All <b>convolutional</b> neural networks (CNNs) have three dimensions: width, depth, and resolution. Depth refers to the number of layers, width refers to the number of channels (e.g. 3 channels in RGB) and the resolution refers to the number of <b>pixels</b> <b>in an image</b>. Each of these dimensions <b>can</b> be scaled, and each raise the accuracy of the CNN up to a ...", "dateLastCrawled": "2022-02-01T03:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Converting tabular data into images for deep learning with ...", "url": "https://www.nature.com/articles/s41598-021-90923-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-90923-y", "snippet": "Fourth, the numbers of features and <b>image</b> <b>pixels</b> <b>can</b> be flexibly adjusted to match each other. If there are more features than <b>image</b> <b>pixels</b>, either larger images with more <b>pixels</b> <b>can</b> be used or a ...", "dateLastCrawled": "2022-02-03T17:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>A convolutional neural networks approach using</b> X-Ray absorption images ...", "url": "https://link.springer.com/article/10.1007/s42452-020-03835-3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42452-020-03835-3", "snippet": "Digitalized X-ray <b>image</b> is a grey-scale matrix that <b>can</b> be in different formats depending on the nature of the <b>image</b>. For binaries or intensity images, <b>image</b> histogram constitutes a useful tool for analysing the characteristics of the resultant <b>image</b>, providing important information about the intensity levels and the total of <b>pixels</b> in the <b>image</b> [ 7 , 8 , 9 ].", "dateLastCrawled": "2022-01-23T22:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Kernel Convolution</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/kernel-convolution", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>kernel-convolution</b>", "snippet": "The complete output <b>image</b> g(m, n) is obtained by repeating the same <b>operation</b> on all <b>pixels</b> of the original <b>image</b> [4, 5, 13]. A convolution kernel <b>can</b> be applied to an <b>image</b> in order to effect a specific enhancement <b>operation</b> or change in the <b>image</b> characteristics. This typically results in desirable attributes being amplified and undesirable attributes being suppressed. The specific values of the kernel coefficients depend on the different types of enhancement that may be desired.", "dateLastCrawled": "2022-01-26T00:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Interpolation based Single-path Sub-pixel Convolution for Super ...", "url": "http://203.250.218.22/article/JAKO202102565120224.pdf", "isFamilyFriendly": true, "displayUrl": "203.250.218.22/article/JAKO202102565120224.pdf", "snippet": "<b>Image</b> super-resolution (SR) is an important task in computer vision to increase or recover the size of a low-resolution (LR) <b>image</b>, generating a high-resolution (HR) output. This is usually referred to as single <b>image</b> super-resolution (SISR). SISR is an ill-posed problem, as there are various solutions for any LR <b>image</b>. Applications on SISR in recent years <b>can</b> be found in surveillance imaging [1], medical imaging [2], High-definition television, and more. One of the traditional <b>image</b> ...", "dateLastCrawled": "2022-01-31T09:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Deep learning <b>for remote sensing image classification: A survey</b>", "url": "https://www.researchgate.net/publication/325220792_Deep_learning_for_remote_sensing_image_classification_A_survey", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/325220792_Deep_learning_for_remote_sensing...", "snippet": "which is extracted from the input <b>image</b> by the <b>convolutional</b> network. The classification <b>operation</b> <b>can</b> be simply implemented by connecting this output to a learning classifier, such as Softmax ...", "dateLastCrawled": "2022-02-02T21:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deep learning <b>for remote sensing image classification: A survey</b> - Li ...", "url": "https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1264", "isFamilyFriendly": true, "displayUrl": "https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1264", "snippet": "The classification <b>operation</b> <b>can</b> be simply implemented by connecting this output to a learning classifier, such as Softmax (Krizhevsky et al., 2012). <b>Compared</b> to shallow learning, the advantage of DL is that it introduces deep network architectures to learn more abstract and effective features. However, the large amount of parameters introduced ...", "dateLastCrawled": "2022-01-27T15:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "FRD-CNN: Object detection based on small-scale <b>convolutional</b> neural ...", "url": "https://www.nature.com/articles/s41598-019-52580-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-019-52580-0", "snippet": "As we <b>can</b> see in the table, the fire-FRD-CNN achieves better AP values in 8 categories <b>compared</b> to the original SqueezeDet+ model. The number of parameters of FRD-CNN is one times larger than ...", "dateLastCrawled": "2022-01-25T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>lite convolutional neural network built</b> on permuted Xceptio-inception ...", "url": "https://link.springer.com/article/10.1007/s11042-020-10181-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11042-020-10181-4", "snippet": "The reason is simple, a facial <b>image</b> of 512 \u00d7 512 RGB images contains almost 1 million <b>pixels</b> from those most of them irrelevant, and processing these <b>pixels</b> is a waste of time, memory, and energy. So, it is necessary to extract the appropriate features in some meaningful way that makes the machine learning techniques much faster, reliable, and more accurate. The selection of features and its extraction is of two types, one is manual selection, which has mainly used in medical applications ...", "dateLastCrawled": "2021-10-10T01:52:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding \u201cconvolution\u201d operations in CNN | by aditi kothiya ...", "url": "https://medium.com/analytics-vidhya/convolution-operations-in-cnn-deep-learning-compter-vision-128906ece7d3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/convolution-<b>operations</b>-in-cnn-deep-<b>learning</b>...", "snippet": "Convolution neural network is the major building block of deep <b>learning</b>, which helps in image classification, object detection, image recognition, etc of computer vision tasks. We use many\u2026", "dateLastCrawled": "2022-01-27T14:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Graph Convolutions and <b>Machine</b> <b>Learning</b>", "url": "https://dash.harvard.edu/bitstream/handle/1/38811540/OTNESS-SENIORTHESIS-2018.pdf?sequence=1", "isFamilyFriendly": true, "displayUrl": "https://dash.harvard.edu/bitstream/handle/1/38811540/OTNESS-SENIORTHESIS-2018.pdf?...", "snippet": "of a standard <b>convolutional</b> neural network: locality and parameter reduction. However, the <b>operation</b> of convolution does not directly generalize to non-Euclidean domains and will require the development of a suitable <b>analogy</b>. Just as <b>convolutional</b> neural networks built on existing techniques in signal processing, there", "dateLastCrawled": "2022-01-09T08:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Complete Guide for Visualising <b>and Understanding Convolutional</b> ...", "url": "https://medium.com/analytics-vidhya/a-complete-guide-for-visualising-and-understanding-convolutional-networks-dc26f71c979f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/a-complete-guide-for-visualising-and-understanding...", "snippet": "There is a common <b>analogy</b> among practitioners that insights into the internal <b>operation</b> and behavior of these models or the reason how they achieve such good performance is a cumbersome task (if ...", "dateLastCrawled": "2022-01-07T00:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Convolutional Neural Networks (CNN): Step</b> 2 - <b>Machine</b> <b>Learning</b> | AI", "url": "https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-2-max-pooling/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>superdatascience</b>.com/blogs/<b>convolutional-neural-networks-cnn-step</b>-2-max...", "snippet": "The purpose of max pooling is enabling the <b>convolutional</b> neural network to detect the cheetah when presented with the image in any manner. This second example is more advanced. Here we have 6 different images of 6 different cheetahs (or 5, there is 1 that seems to appear in 2 photos) and they are each posing differently in different settings and from different angles. Again, max pooling is concerned with teaching your <b>convolutional</b> neural network to recognize that despite all of these ...", "dateLastCrawled": "2022-01-28T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Convolutional Neural Networks and their components for computer vision</b> ...", "url": "https://www.machinecurve.com/index.php/2018/12/07/convolutional-neural-networks-and-their-components-for-computer-vision/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2018/12/07/<b>convolutional</b>-neural-networks-and...", "snippet": "<b>Machine</b> <b>learning</b> (and consequently deep <b>learning</b>) can be used to train computers to see things. We know that <b>machine</b> <b>learning</b> is about feeding examples to machines, after which they derive the patterns in these examples themselves. Consequently, we can see that using <b>machine</b> <b>learning</b> for computer vision equals showing machines enough examples so that they can learn to recognize them on their own, for new data. In deep <b>learning</b>, we use deep neural networks to learn machines to recognize ...", "dateLastCrawled": "2022-01-30T13:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Convolution and cross-correlation in neural networks</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2021/05/14/convolution-and-cross-correlation-in-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/05/14/<b>convolution-and-cross-correlation-in</b>-neural...", "snippet": "All this math amounts to is a sign change in how we access the coordinates of the image I (i.e., we don\u2019t have to \u201cflip\u201d the kernel relative to the input when applying cross-correlation).. Again, many deep <b>learning</b> libraries use the simplified cross-correlation <b>operation</b> and call it convolution \u2014 we will use the same terminology here.For readers interested in <b>learning</b> more about the mathematics behind convolution vs. cross-correlation, please refer to Chapter 3 of Computer Vision ...", "dateLastCrawled": "2022-01-30T23:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is the best <b>analogy</b> <b>for a Convolutional Neural Network that you</b> ...", "url": "https://www.quora.com/What-is-the-best-analogy-for-a-Convolutional-Neural-Network-that-you-ever-read", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-<b>analogy</b>-<b>for-a-Convolutional-Neural-Network-that</b>...", "snippet": "Answer: The following intuition was given by Prof. Yann LeCun in one of his lectures: (He explained it at a very high level, I\u2019ve filled in the details for better exposition.) Suppose you have a set of hand-coded rules for a classification task. Then, you can rewrite them in terms of AND and OR...", "dateLastCrawled": "2022-01-14T13:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep <b>Learning</b>, <b>Convolutional</b> Neural Networks and Terminal Efficiency ...", "url": "https://www.camco.be/deep-learning-convolutional-neural-networks-and-terminal-efficiency/", "isFamilyFriendly": true, "displayUrl": "https://www.camco.be/deep-<b>learning</b>-<b>convolutional</b>-neural-networks-and-terminal-efficiency", "snippet": "DEEP <b>LEARNING</b> BASED IMAGE ANALYSIS. Deep <b>learning</b> is one of many, but perhaps the most popular domain within <b>Machine</b> <b>Learning</b> (ML) and includes several technologies. When working mostly with images, <b>Convolutional</b> Neural Networks (CNN) is one of those groundbreaking technologies. Their main use is to classify, detect or segment objects in an image.", "dateLastCrawled": "2022-01-26T22:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Do convolutional neural networks work the</b> same way as the networks in ...", "url": "https://www.quora.com/Do-convolutional-neural-networks-work-the-same-way-as-the-networks-in-our-brain", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Do-convolutional-neural-networks-work-the</b>-same-way-as-the...", "snippet": "Answer: NO. For starters, we don\u2019t completely know how the human brain works and therefore, we cannot possibly argue that <b>Convolutional</b> Networks (ConvNets) work the same way as the network of neurons in the human brain does. <b>Convolutional</b> Nets and other related architectures under the deep lear...", "dateLastCrawled": "2022-01-24T14:25:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "JOURNAL OF LA <b>Learning</b> Backtrackless Aligned-Spatial Graph ...", "url": "https://arxiv.org/pdf/1904.04238.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/1904.04238.pdf", "snippet": "representations where standard <b>machine</b> <b>learning</b> techniques can be directly employed for graph classi\ufb01cation or clustering. The aim of this paper is to develop a new Graph Convolu-tional Network (GCN) model to learn effective features for graph classi\ufb01cation. Our idea is to transform arbitrary-sized graphs into \ufb01xed-sized backtrackless aligned grid structures and de\ufb01ne a new backtrackless spatial graph convolution operation associated with the grid structures. We show that the ...", "dateLastCrawled": "2021-08-20T14:43:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(convolutional operation)  is like +(rearranging the pixels in an image)", "+(convolutional operation) is similar to +(rearranging the pixels in an image)", "+(convolutional operation) can be thought of as +(rearranging the pixels in an image)", "+(convolutional operation) can be compared to +(rearranging the pixels in an image)", "machine learning +(convolutional operation AND analogy)", "machine learning +(\"convolutional operation is like\")", "machine learning +(\"convolutional operation is similar\")", "machine learning +(\"just as convolutional operation\")", "machine learning +(\"convolutional operation can be thought of as\")", "machine learning +(\"convolutional operation can be compared to\")"]}