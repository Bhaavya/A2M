{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Face Mask Detection Using Convolution Neural Network | by Vignesh ...", "url": "https://medium.com/reconsubsea/face-mask-detection-using-convolution-neural-network-fcf156ecad84?source=post_internal_links---------5----------------------------", "isFamilyFriendly": true, "displayUrl": "https://medium.com/reconsubsea/face-mask-detection-using-convolution-neural-network...", "snippet": "tf.keras.layers.Conv2D is for defining the <b>convolutional</b> layer. The first parameter is the number of filters in the <b>convolutional</b> layer. Then comes the shape of the <b>filter</b>( generally 3x3 or 5x5 ...", "dateLastCrawled": "2021-12-03T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Applied Deep Learning - Part 4: <b>Convolutional</b> Neural Networks | by ...", "url": "https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/applied-deep-learning-part-4-<b>convolutional</b>-neural...", "snippet": "Let\u2019s say we have a 32x32x3 image and we use a <b>filter</b> of size 5x5x3 (note that the depth of the convolution <b>filter</b> matches the depth of the image, both being 3). When the <b>filter</b> is at a particular location it covers a small volume of the input, and we perform the convolution operation described above. The only difference is this time we do the sum of matrix multiply in 3D instead of 2D, but the result is still a scalar. We slide the <b>filter</b> over the input <b>like</b> above and perform the ...", "dateLastCrawled": "2022-01-31T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Image Classification Using Convolutional Neural Networks</b> (Lecture 04 ...", "url": "https://www.coursehero.com/blog/image-classification-using-convolutional-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/blog/<b>image-classification-using-convolutional-neural-networks</b>", "snippet": "Challenges with <b>convolutional</b> neural networks: Well, it will recognize both of these as a <b>person</b> primarily because of location equivariance. It doesn\u2019t understand this concept of invariance. In a face, it needs to have certain features. I mean, this is an exaggerated example, but as long as you have certain features, it\u2019s a face because of the way it aggregates the layers. This is one of the challenges with <b>convolutional</b> neural networks. This equivariance versus invariance is being ...", "dateLastCrawled": "2022-01-11T23:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "deeplearning-notes/readme.md at main \u00b7 <b>lijqhs/deeplearning-notes</b> - <b>GitHub</b>", "url": "https://github.com/lijqhs/deeplearning-notes/blob/main/C4-Convolutional-Neural-Networks/readme.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>lijqhs/deeplearning-notes</b>/blob/main/C4-<b>Convolutional</b>-Neural...", "snippet": "<b>Through</b> these two mechanisms, a neural network has a lot fewer parameters which allows it to be trained with smaller training cells and is less prone to be overfitting. <b>Convolutional</b> structure helps the neural network encode the fact that an image shifted a few pixels should result in pretty similar features and should probably be assigned the same output label. And the fact that you are applying the same <b>filter</b> in all the positions of the image, both in the early layers and in the late ...", "dateLastCrawled": "2021-09-01T01:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding the role of individual units in a deep neural network | <b>PNAS</b>", "url": "https://www.pnas.org/content/117/48/30071", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/117/48/30071", "snippet": "Fig. 1. The emergence of single-unit object detectors within a VGG-16 <b>scene</b> classifier. (A) VGG-16 consists of 13 <b>convolutional</b> layers, conv1_1 <b>through</b> conv5_3, followed by three fully connected layers: fc6, -7, -8.(B) The activation of a single <b>filter</b> on an input image can be visualized as the region where the <b>filter</b> activates beyond its top 1% quantile level.(C) Single units are scored by matching high-activating regions against a set of human-interpretable visual concepts; each unit is ...", "dateLastCrawled": "2021-12-22T19:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How does the <b>convolutional</b> neural network recognize objects from images ...", "url": "https://www.quora.com/How-does-the-convolutional-neural-network-recognize-objects-from-images-without-the-3D-perception-or-recognition", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-does-the-<b>convolutional</b>-neural-network-recognize-objects-from...", "snippet": "Answer: A <b>convolutional</b> neural network (CNN) is naturally for image classification not object detection. Image classification is about recognition or classification of a dominant object in a <b>scene</b>. It doesn&#39;t matter. * Where that object is in terms of location. * * Convolution operation was...", "dateLastCrawled": "2022-01-07T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Do semantic parts emerge in <b>Convolutional</b> Neural Networks? | DeepAI", "url": "https://deepai.org/publication/do-semantic-parts-emerge-in-convolutional-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/do-semantic-parts-emerge-in-<b>convolutional</b>-neural-networks", "snippet": "Let f i j be the j-th <b>convolutional</b> <b>filter</b> of the i-th layer, including also the ReLU. Each pixel in a feature map x i j = f i j (x i \u2212 1) is the activation value of <b>filter</b> f i j applied to a particular position in the feature maps x i \u2212 1 of the previous layer. The resolution of the feature map depends on the layer, decreasing as we advance <b>through</b> the network. Fig. 1 shows feature maps for layers 1, 2, and 5. When a <b>filter</b> responds to a particular stimulus in its input, the ...", "dateLastCrawled": "2021-12-30T09:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Image <b>forgery detection</b>. Using the power of CNN&#39;s to detect\u2026 | by ...", "url": "https://towardsdatascience.com/image-forgery-detection-2ee6f1a65442", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/image-<b>forgery-detection</b>-2ee6f1a65442", "snippet": "After <b>looking</b> at a few forged images, it was evident that locating the forged areas by human visual cortex is possible. CNN is thus the perfect deep learning model for this job. If a human visual cortex can detect it, certainly there is more power in a network which would be specifically designed for that task. Dataset. Before going into the dataset overview, the terminology used will be made clear. Fake image: An image that has been manipulated/doctored using the two most common ...", "dateLastCrawled": "2022-02-02T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Cross-dataset emotion recognition from facial expressions <b>through</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1047320321002637", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1047320321002637", "snippet": "By <b>looking</b> at a <b>person</b>\u2019s portrait, our method should be able to decipher the presented facial expressions and reveal which of the seven basic emotions \u2013 anger, disgust, fear, happiness, neutral, sadness, and surprise \u2013 the <b>person</b> is more likely to be communicating. Particularly, it is desirable that our model shows an appropriate level of generalization, by adapting to new, previously unseen data (i.e., portraits of different people, collected under different conditions), as opposed to ...", "dateLastCrawled": "2022-02-03T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Python Projects with Source Code</b> \u2013 Practice Top Projects ... - DataFlair", "url": "https://data-flair.training/blogs/python-projects-with-source-code/", "isFamilyFriendly": true, "displayUrl": "https://data-flair.training/blogs/python-projects-with-", "snippet": "This involves processes <b>like</b> object recognition, video tracking, motion estimation, and image restoration. It is exciting to be able to predict a <b>person</b>\u2019s gender and age from just a photograph. CNNs (<b>Convolutional</b> Neural Networks) are often the choice when we work with images. In this project, we\u2019ll use OpenCV (Open Source Computer Vision) and implement deep learning, using trained models on the Adience dataset.", "dateLastCrawled": "2022-02-02T23:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "A <b>convolutional</b> <b>filter</b> is a matrix having the same rank as the input matrix, but a smaller shape. For example, given a 28x28 input matrix, the <b>filter</b> could be any 2D matrix smaller than 28x28. In photographic manipulation, all the cells in a <b>convolutional</b> <b>filter</b> are typically set to a constant pattern of ones and zeroes. In <b>machine learning</b>, <b>convolutional</b> filters are typically seeded with random numbers and then the network trains the ideal values. <b>convolutional</b> layer. #image. A layer of a ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "deeplearning-notes/readme.md at main \u00b7 <b>lijqhs/deeplearning-notes</b> - <b>GitHub</b>", "url": "https://github.com/lijqhs/deeplearning-notes/blob/main/C4-Convolutional-Neural-Networks/readme.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>lijqhs/deeplearning-notes</b>/blob/main/C4-<b>Convolutional</b>-Neural...", "snippet": "<b>Through</b> these two mechanisms, a neural network has a lot fewer parameters which allows it to be trained with smaller training cells and is less prone to be overfitting. <b>Convolutional</b> structure helps the neural network encode the fact that an image shifted a few pixels should result in pretty <b>similar</b> features and should probably be assigned the same output label. And the fact that you are applying the same <b>filter</b> in all the positions of the image, both in the early layers and in the late ...", "dateLastCrawled": "2021-09-01T01:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding the role of individual units in a deep neural network | <b>PNAS</b>", "url": "https://www.pnas.org/content/117/48/30071", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/117/48/30071", "snippet": "Fig. 1. The emergence of single-unit object detectors within a VGG-16 <b>scene</b> classifier. (A) VGG-16 consists of 13 <b>convolutional</b> layers, conv1_1 <b>through</b> conv5_3, followed by three fully connected layers: fc6, -7, -8.(B) The activation of a single <b>filter</b> on an input image can be visualized as the region where the <b>filter</b> activates beyond its top 1% quantile level.(C) Single units are scored by matching high-activating regions against a set of human-interpretable visual concepts; each unit is ...", "dateLastCrawled": "2021-12-22T19:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Cross-dataset emotion recognition from facial expressions <b>through</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1047320321002637", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1047320321002637", "snippet": "By <b>looking</b> at a <b>person</b>\u2019s portrait, our method should be able to decipher the presented facial expressions and reveal which of the seven basic emotions \u2013 anger, disgust, fear, happiness, neutral, sadness, and surprise \u2013 the <b>person</b> is more likely to be communicating. Particularly, it is desirable that our model shows an appropriate level of generalization, by adapting to new, previously unseen data (i.e., portraits of different people, collected under different conditions), as opposed to ...", "dateLastCrawled": "2022-02-03T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Applied Deep Learning - Part 4: <b>Convolutional</b> Neural Networks | by ...", "url": "https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/applied-deep-learning-part-4-<b>convolutional</b>-neural...", "snippet": "Overview. Welcome to Part 4 of Applied Deep Learning series. Part 1 was a hands-on introduction to Artificial Neural Networks, covering both the theory and application with a lot of code examples and visualization. In Part 2 we applied deep learning to real-world datasets, covering the 3 most commonly encountered problems as case studies: binary classification, multiclass classification and regression. Part 3 explored a specific deep learning architecture: Autoencoders.. Now we will cover ...", "dateLastCrawled": "2022-01-31T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Deep <b>Learning Models for Human Activity Recognition</b>", "url": "https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/deep-<b>learning-models-for-human-activity-recognition</b>", "snippet": "Human activity recognition, or HAR, is a challenging time series classification task. It involves predicting the movement of a <b>person</b> based on sensor data and traditionally involves deep domain expertise and methods from signal processing to correctly engineer features from the raw data in order to fit a machine learning model. Recently, deep learning methods such as <b>convolutional</b> neural networks and recurrent", "dateLastCrawled": "2022-02-02T16:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Do <b>similar</b> images produce <b>similar</b> activations in a <b>convolutional</b> neural ...", "url": "https://www.quora.com/Do-similar-images-produce-similar-activations-in-a-convolutional-neural-network-If-so-can-the-activations-be-compared-to-check-if-an-image-is-similar-to-another-one", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Do-<b>similar</b>-images-produce-<b>similar</b>-activations-in-a-<b>convolutional</b>...", "snippet": "Answer: This is a very interesting question, the answer to which is, it depends. Say you have three images. The first is of a man in front of a building, the second is of a man in front of a forest, the third is of a cat in front of a building. You have two CNNs, one trained on animals, the other...", "dateLastCrawled": "2022-01-21T09:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Dynamic Filter Networks</b> - ResearchGate", "url": "https://www.researchgate.net/publication/303698513_Dynamic_Filter_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/303698513_<b>Dynamic_Filter_Networks</b>", "snippet": "MDFG is motivated by a line of research on <b>dynamic filter networks</b> (DFN) (Jia et al. 2016; Yang et al. 2019;Zhou et al. 2021), which have been mainly studied on <b>convolutional</b> kernels for image and ...", "dateLastCrawled": "2022-01-18T21:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>3D Human Pose Estimation Experiments</b> and Analysis - KDnuggets", "url": "https://www.kdnuggets.com/2020/08/3d-human-pose-estimation-experiments-analysis.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2020/08/<b>3d-human-pose-estimation-experiments</b>-analysis.html", "snippet": "Basically, there are two types of pose estimation: 2D and 3D. 2D estimation involves the extraction of X, Y coordinates for each joint from an RGB image, and 3D - XYZ coordinates from an RGB image. In this article, we explore how 3D human pose estimation works based on our research and experiments, which were part of the analysis of applying ...", "dateLastCrawled": "2022-01-26T01:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Python Projects with Source Code</b> \u2013 Practice Top Projects ... - DataFlair", "url": "https://data-flair.training/blogs/python-projects-with-source-code/", "isFamilyFriendly": true, "displayUrl": "https://data-flair.training/blogs/python-projects-with-", "snippet": "Social media algorithms often viralize these and create a <b>filter</b> bubble. In this, we will train on a news.csv dataset of shape 7796\u00d74. We\u2019ll mainly use two things- a TfidfVectorizer and a PassiveAggressiveClassifier. A TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features. And a PassiveAggressiveClassifier is an online learning algorithm that stays passive for a correct classification and becomes aggressive when there\u2019s a miscalculation. Please refer ...", "dateLastCrawled": "2022-02-02T23:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding the role of individual units in a deep neural network | <b>PNAS</b>", "url": "https://www.pnas.org/content/117/48/30071", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/117/48/30071", "snippet": "Fig. 1. The emergence of single-unit object detectors within a VGG-16 <b>scene</b> classifier. (A) VGG-16 consists of 13 <b>convolutional</b> layers, conv1_1 <b>through</b> conv5_3, followed by three fully connected layers: fc6, -7, -8.(B) The activation of a single <b>filter</b> on an input image <b>can</b> be visualized as the region where the <b>filter</b> activates beyond its top 1% quantile level.(C) Single units are scored by matching high-activating regions against a set of human-interpretable visual concepts; each unit is ...", "dateLastCrawled": "2021-12-22T19:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep <b>Learning Models for Human Activity Recognition</b>", "url": "https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/deep-<b>learning-models-for-human-activity-recognition</b>", "snippet": "The features <b>can</b> be learned automatically <b>through</b> the network instead of being manually designed. Besides, the deep neural network <b>can</b> also extract high-level representation in deep layer, which makes it more suitable for complex activity recognition tasks. \u2014 Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. There are two main approaches to neural networks that are appropriate for time series classification and that have been demonstrated to perform well on activity ...", "dateLastCrawled": "2022-02-02T16:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Semantic segmentation with OpenCV and</b> deep learning - You <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2018/09/03/<b>semantic-segmentation-with-opencv-and</b>-deep...", "snippet": "Figure 1: The ENet deep learning semantic segmentation architecture. This figure is a combination of Table 1 and Figure 2 of Paszke et al.. The semantic segmentation architecture we\u2019re using for this tutorial is ENet, which is based on Paszke et al.\u2019s 2016 publication, ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation. One of the primary benefits of ENet is that it\u2019s fast \u2014 up to 18x faster and requiring 79x fewer parameters with similar or better accuracy ...", "dateLastCrawled": "2022-02-03T14:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Video classification with Keras and Deep Learning - You <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2019/07/15/video-classification-with-keras-and-deep-learning", "snippet": "I was <b>looking</b> for a similar idea and <b>thought</b> to mail you regarding this last month but I didn\u2019t. Anyways, I have trained the model using your code. I cropped two video clips say, football and chess, and merged these clips into a single video to test model performance. Between these two video clips there is a <b>scene</b> of around 15 second were <b>person</b> is neither playing football nor chess still model predict those 15 second <b>scene</b> as football. I want to modify your code for my academic purpose in ...", "dateLastCrawled": "2022-02-03T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Attention in Psychology, Neuroscience, and Machine Learning", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7177153/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7177153", "snippet": "1. Introduction. Attention is a topic widely discussed publicly and widely studied scientifically. It has many definitions within and across multiple fields including psychology, neuroscience, and, most recently, machine learning (Chun et al., 2011; Cho et al., 2015).As William James wrote at the dawn of experimental psychology, \u201cEveryone knows what attention is.", "dateLastCrawled": "2021-12-27T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Capturing the objects of vision with neural networks | Nature Human ...", "url": "https://www.nature.com/articles/s41562-021-01194-6", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41562-021-01194-6", "snippet": "The individuation of an object is <b>thought</b> to precede the identification of its appearance, as famously captured by the observation of Kahneman et al. (p. 217 of ref. 85) that humans <b>can</b> conceive ...", "dateLastCrawled": "2022-01-30T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What are the computational functions of feedback to early visual cortex ...", "url": "https://cbmm.mit.edu/video/what-are-computational-functions-feedback-early-visual-cortex", "isFamilyFriendly": true, "displayUrl": "https://cbmm.mit.edu/video/what-are-computational-functions-feedback-early-visual-cortex", "snippet": "So it&#39;s like you&#39;re <b>looking</b> at this natural image <b>scene</b> <b>through</b> a set of holes. And if you adjust things right, and with little bit of practice, and [AUDIO OUT], you <b>can</b> see <b>through</b> the holes. So you&#39;ve got the holes there, and you <b>can</b> proceed to organize that whole <b>scene</b> behind the holes. And the experience is just like you&#39;re <b>looking</b> <b>through</b> a hole. So that&#39;s where you&#39;re well-organizing these patches that you see <b>through</b> the holes. But then you <b>can</b> take another <b>scene</b> and pick out patches ...", "dateLastCrawled": "2021-12-12T09:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "knowledge/lesson-12-gan.md at master \u00b7 cedrickchee/knowledge \u00b7 GitHub", "url": "https://github.com/cedrickchee/knowledge/blob/master/courses/fast.ai/deep-learning-part-2/2018-edition/lesson-12-gan.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/cedrickchee/knowledge/blob/master/courses/fast.ai/deep-learning...", "snippet": "Let&#39;s put it <b>through</b> a 3 by 3 kernel with a single output <b>filter</b>. So we have a single channel in, a single <b>filter</b> kernel, so if we don&#39;t add any padding, we are going to end up with 2 by 2. Remember, the convolution is just the sum of the product of the kernel and the appropriate grid cell [1:11:09]. So there is our standard 3 by 3 conv one channel one <b>filter</b>.", "dateLastCrawled": "2021-12-07T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Comprehensive survey of deep learning in remote sensing: theories</b> ...", "url": "https://www.spiedigitallibrary.org/journals/journal-of-applied-remote-sensing/volume-11/issue-04/042609/Comprehensive-survey-of-deep-learning-in-remote-sensing--theories/10.1117/1.JRS.11.042609.full", "isFamilyFriendly": true, "displayUrl": "https://www.spiedigitallibrary.org/journals/journal-of-applied-remote-sensing/volume...", "snippet": "A DBN <b>can</b> also <b>be thought</b> of as a type of deep NN. In Ref. ... They demonstrated that the same CNN <b>can</b> perform both <b>scene</b> recognition and object localization in a single forward pass, without having to explicitly learn the notion of objects. Images had their edges removed such that each edge removal produces the smallest change to the classification discriminant function. This process is repeated until the image is misclassified. The final product of that analysis is a set of simplified ...", "dateLastCrawled": "2022-01-16T00:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A generative vision model that trains with high data efficiency and ...", "url": "https://science.sciencemag.org/content/358/6368/eaag2612.full?ijkey=DmvGldXIEXVoQ&keytype=ref&siteid=sci", "isFamilyFriendly": true, "displayUrl": "https://science.sciencemag.org/content/358/6368/eaag2612.full?ijkey=DmvGldXIEXVoQ&amp;...", "snippet": "To parse a <b>scene</b>, RCN maintains hierarchical graphs for multiple object instances at multiple locations tiling the <b>scene</b>. The parse of a <b>scene</b> <b>can</b> be obtained via maximum a posteriori (MAP) inference on this complex graph, which recovers the best joint configuration, including object identities and their segmentations [section 4 of ].", "dateLastCrawled": "2021-04-30T01:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Infrared and visible image fusion via rolling guidance <b>filter</b> and ...", "url": "https://www.researchgate.net/publication/351597154_Infrared_and_visible_image_fusion_via_rolling_guidance_filter_and_convolutional_sparse_representation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/351597154_Infrared_and_visible_image_fusion...", "snippet": "The guided <b>filter</b> <b>can</b> be used as an edge-preserving smoothing operator like the popular bilateral <b>filter</b> [1], but it has better behaviors near edges. The guided <b>filter</b> is also a more generic ...", "dateLastCrawled": "2022-01-25T17:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Applied Deep Learning - Part 4: <b>Convolutional</b> Neural Networks | by ...", "url": "https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/applied-deep-learning-part-4-<b>convolutional</b>-neural...", "snippet": "Overview. Welcome to Part 4 of Applied Deep Learning series. Part 1 was a hands-on introduction to Artificial Neural Networks, covering both the theory and application with a lot of code examples and visualization. In Part 2 we applied deep learning to real-world datasets, covering the 3 most commonly encountered problems as case studies: binary classification, multiclass classification and regression. Part 3 explored a specific deep learning architecture: Autoencoders.. Now we will cover ...", "dateLastCrawled": "2022-01-31T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Understanding convolutional neural networks via discriminant</b> feature ...", "url": "https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/understanding-convolutional-neural-networks-via-discriminant-feature-analysis/724A0FF83ED539AA7FA41D77F77479A8", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information...", "snippet": "Fig. 1. None-GMC-like and GMC-like features are <b>compared</b> in the left and right subfigures. The first and third subfigures give the top nine activations for two conv 5 filters and the second and fourth subfigures show their Gaussian confusion plot, which reflects the distribution of a <b>filter</b>&#39;s response value (see discussion in Section A). In this example, the GMC <b>filter</b> (i.e., <b>filter</b> 142 in conv 5 of the fast-RCNN [Reference Girshick 9] CaffeNet model) is mainly activated by the dog class and ...", "dateLastCrawled": "2021-12-29T18:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Cross-dataset emotion recognition from facial expressions <b>through</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1047320321002637", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1047320321002637", "snippet": "By <b>looking</b> at a <b>person</b>\u2019s portrait, our method should be able to decipher the presented facial expressions and reveal which of the seven basic emotions \u2013 anger, disgust, fear, happiness, neutral, sadness, and surprise \u2013 the <b>person</b> is more likely to be communicating. Particularly, it is desirable that our model shows an appropriate level of generalization, by adapting to new, previously unseen data (i.e., portraits of different people, collected under different conditions), as opposed to ...", "dateLastCrawled": "2022-02-03T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Person</b> Identification by Footstep Sound Using <b>Convolutional</b> Neural Networks", "url": "https://www.mdpi.com/2673-3161/2/2/16/htm", "isFamilyFriendly": true, "displayUrl": "https://www.<b>mdpi</b>.com/2673-3161/2/2/16/htm", "snippet": "Comparable results <b>can</b> be achieved while using the acoustic signature of human footstep sounds. This acoustic solution offers the opportunity of less installation space and the use of cost-efficient microphones when <b>compared</b> to visual system. In this paper, a method for <b>person</b> identification based on footstep sounds is proposed. First, step sounds are isolated from microphone recordings and separated into 500 ms samples. The samples are transformed with a sliding <b>window</b> into mel-frequency ...", "dateLastCrawled": "2021-11-18T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Do similar images produce similar activations in a <b>convolutional</b> neural ...", "url": "https://www.quora.com/Do-similar-images-produce-similar-activations-in-a-convolutional-neural-network-If-so-can-the-activations-be-compared-to-check-if-an-image-is-similar-to-another-one", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Do-similar-images-produce-similar-activations-in-a-<b>convolutional</b>...", "snippet": "Answer: This is a very interesting question, the answer to which is, it depends. Say you have three images. The first is of a man in front of a building, the second is of a man in front of a forest, the third is of a cat in front of a building. You have two CNNs, one trained on animals, the other...", "dateLastCrawled": "2022-01-21T09:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Pedestrian intention prediction: A <b>convolutional</b> bottom-up multi-task ...", "url": "https://www.sciencedirect.com/science/article/pii/S0968090X21002710", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0968090X21002710", "snippet": "Intuitively, a sufficient number of <b>convolutional</b> layers stacked together has an effective receptive field that is similar to the size of the <b>scene</b>, enabling the model to look at the pedestrian\u2019s pose and his surroundings when generating the activity map. This lends our model an advantage over the other models that operate only the cropped pedestrian images. It is difficult to ascertain the state the pedestrian is in simply <b>through</b> his pose as evidenced by the precision scores attained by ...", "dateLastCrawled": "2022-01-09T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "deeplearning-notes/readme.md at main \u00b7 <b>lijqhs/deeplearning-notes</b> - <b>GitHub</b>", "url": "https://github.com/lijqhs/deeplearning-notes/blob/main/C4-Convolutional-Neural-Networks/readme.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>lijqhs/deeplearning-notes</b>/blob/main/C4-<b>Convolutional</b>-Neural...", "snippet": "<b>Through</b> these two mechanisms, a neural network has a lot fewer parameters which allows it to be trained with smaller training cells and is less prone to be overfitting. <b>Convolutional</b> structure helps the neural network encode the fact that an image shifted a few pixels should result in pretty similar features and should probably be assigned the same output label. And the fact that you are applying the same <b>filter</b> in all the positions of the image, both in the early layers and in the late ...", "dateLastCrawled": "2021-09-01T01:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Image <b>forgery detection</b>. Using the power of CNN&#39;s to detect\u2026 | by ...", "url": "https://towardsdatascience.com/image-forgery-detection-2ee6f1a65442", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/image-<b>forgery-detection</b>-2ee6f1a65442", "snippet": "After <b>looking</b> at a few forged images, it was evident that locating the forged areas by human visual cortex is possible. CNN is thus the perfect deep learning model for this job. If a human visual cortex <b>can</b> detect it, certainly there is more power in a network which would be specifically designed for that task. Dataset. Before going into the dataset overview, the terminology used will be made clear. Fake image: An image that has been manipulated/doctored using the two most common ...", "dateLastCrawled": "2022-02-02T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>3D Human Pose Estimation Experiments</b> and Analysis - KDnuggets", "url": "https://www.kdnuggets.com/2020/08/3d-human-pose-estimation-experiments-analysis.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2020/08/<b>3d-human-pose-estimation-experiments</b>-analysis.html", "snippet": "Basically, there are two types of pose estimation: 2D and 3D. 2D estimation involves the extraction of X, Y coordinates for each joint from an RGB image, and 3D - XYZ coordinates from an RGB image. In this article, we explore how 3D human pose estimation works based on our research and experiments, which were part of the analysis of applying ...", "dateLastCrawled": "2022-01-26T01:16:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Convolutional Neural Networks and their components for computer vision</b> ...", "url": "https://www.machinecurve.com/index.php/2018/12/07/convolutional-neural-networks-and-their-components-for-computer-vision/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2018/12/07/<b>convolutional</b>-neural-networks-and...", "snippet": "<b>Machine</b> <b>learning</b> (and consequently deep <b>learning</b>) can be used to train computers to see things. We know that <b>machine</b> <b>learning</b> is about feeding examples to machines, after which they derive the patterns in these examples themselves. Consequently, we can see that using <b>machine</b> <b>learning</b> for computer vision equals showing machines enough examples so that they can learn to recognize them on their own, for new data. In deep <b>learning</b>, we use deep neural networks to learn machines to recognize ...", "dateLastCrawled": "2022-01-30T13:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Visualizing How <b>Filters Work in Convolutional Neural Networks (CNNs</b> ...", "url": "https://towardsdatascience.com/visualizing-how-filters-work-in-convolutional-neural-networks-cnns-7383bd84ad2c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/visualizing-how-<b>filters-work-in-convolutional-neural</b>...", "snippet": "In Deep <b>Learning</b>, a <b>Convolutional</b> Neural Network (CNN) is a special type of neural network that is designed to process data through multiple layers of arrays. A CNN is well suited for applications like image recognition, and in particular is often used in face recognition software. In CNN, <b>convolutional</b> layers are the fundamental building blocks which make all the magic happens. In a typical image recognition application, a <b>convolutional</b> layer is made up of several filters to detect the ...", "dateLastCrawled": "2022-02-03T02:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> (ML) and Neural Networks (NN)\u2026 An Intuitive ...", "url": "https://medium.com/visionary-hub/machine-learning-ml-and-neural-networks-nn-an-intuitive-walkthrough-76bdaba8b0e3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/visionary-hub/<b>machine</b>-<b>learning</b>-ml-and-neural-networks-nn-an...", "snippet": "A better <b>analogy</b> for unsupervised <b>learning</b>, and one that\u2019s more commonly used, is separating a group of blocks by colour. Suppose we have 10 blocks, each with different coloured faces. In the ...", "dateLastCrawled": "2022-01-30T17:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Graph Convolutional</b> Networks \u2014Deep <b>Learning</b> on Graphs | by Francesco ...", "url": "https://towardsdatascience.com/graph-convolutional-networks-deep-99d7fee5706f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>graph-convolutional</b>-networks-deep-99d7fee5706f", "snippet": "<b>Machine</b> <b>Learning</b> tasks on graphs (image by author) Unfortunately, ... In this post we will see how the problem can be solved using <b>Graph Convolutional</b> Networks (GCN), which generalize classical <b>Convolutional</b> Neural Networks (CNN) to the case of graph-structured data. The main sources for this post are the works of Kipf et al. 2016, Defferrard et al. 2016, and Hammond et al. 2009. Why convolutions? <b>Convolutional</b> neural networks (CNNs) have proven incredibly efficient at extracting complex ...", "dateLastCrawled": "2022-02-02T02:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Convolutional</b> Neural Networks \u2014 Part 3: Convolutions Over <b>Volume</b> and ...", "url": "https://medium.com/swlh/convolutional-neural-networks-part-3-convolutions-over-volume-and-the-convnet-layer-91fb7c08e28b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>convolutional</b>-neural-networks-part-3-convolutions-over-<b>volume</b>...", "snippet": "<b>Convolutional</b> Neural Networks \u2014 Part 3: Convolutions Over <b>Volume</b> and the <b>Convolutional</b> Layer . Brighton Nkomo. Follow. Oct 5, 2020 \u00b7 7 min read. This is the third part of my blog post series on ...", "dateLastCrawled": "2022-01-29T19:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Convolution and cross-correlation in neural networks</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2021/05/14/convolution-and-cross-correlation-in-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/05/14/<b>convolution-and-cross-correlation-in</b>-neural...", "snippet": "For readers interested in <b>learning</b> more about the mathematics behind convolution vs. cross-correlation, please refer to Chapter 3 of Computer Vision: Algorithms and Applications by Szeliski (2011). The \u201cBig Matrix\u201d and \u201cTiny Matrix\u201d <b>Analogy</b> . An image is a multidimensional matrix. Our image has a width (# of columns) and height (# of ...", "dateLastCrawled": "2022-01-30T23:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is the best <b>analogy</b> <b>for a Convolutional Neural Network that you</b> ...", "url": "https://www.quora.com/What-is-the-best-analogy-for-a-Convolutional-Neural-Network-that-you-ever-read", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-<b>analogy</b>-<b>for-a-Convolutional-Neural-Network-that</b>...", "snippet": "Answer: The following intuition was given by Prof. Yann LeCun in one of his lectures: (He explained it at a very high level, I\u2019ve filled in the details for better exposition.) Suppose you have a set of hand-coded rules for a classification task. Then, you can rewrite them in terms of AND and OR...", "dateLastCrawled": "2022-01-14T13:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - Calculate the <b>Output</b> size in Convolution layer ...", "url": "https://stackoverflow.com/questions/53580088/calculate-the-output-size-in-convolution-layer", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/53580088", "snippet": "Now apply that <b>analogy</b> to convolution layers. Your <b>output</b> size will be: input size - <b>filter</b> size + 1. Because your <b>filter</b> can only have n-1 steps as fences I mentioned. Let&#39;s calculate your <b>output</b> with that idea. 128 - 5 + 1 = 124 Same for other dimension too. So now you have a 124 x 124 image. That is for one <b>filter</b>.", "dateLastCrawled": "2022-01-28T22:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Do convolutional neural networks work the</b> same way as the networks in ...", "url": "https://www.quora.com/Do-convolutional-neural-networks-work-the-same-way-as-the-networks-in-our-brain", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Do-convolutional-neural-networks-work-the</b>-same-way-as-the...", "snippet": "Answer: NO. For starters, we don\u2019t completely know how the human brain works and therefore, we cannot possibly argue that <b>Convolutional</b> Networks (ConvNets) work the same way as the network of neurons in the human brain does. <b>Convolutional</b> Nets and other related architectures under the deep lear...", "dateLastCrawled": "2022-01-24T14:25:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(convolutional filter)  is like +(person looking at a scene through a window)", "+(convolutional filter) is similar to +(person looking at a scene through a window)", "+(convolutional filter) can be thought of as +(person looking at a scene through a window)", "+(convolutional filter) can be compared to +(person looking at a scene through a window)", "machine learning +(convolutional filter AND analogy)", "machine learning +(\"convolutional filter is like\")", "machine learning +(\"convolutional filter is similar\")", "machine learning +(\"just as convolutional filter\")", "machine learning +(\"convolutional filter can be thought of as\")", "machine learning +(\"convolutional filter can be compared to\")"]}