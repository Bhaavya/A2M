{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Natural Actor-Critic</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0925231208000532", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231208000532", "snippet": "The <b>state-action</b> <b>value</b> <b>function</b> in any stable linear-quadratic Gaussian regulation problems can be shown to be a bowl (a). The advantage <b>function</b> is always a saddle as shown in (b); it is straightforward to show that the compatible <b>function</b> approximation can exactly represent the advantage <b>function</b>\u2014but projecting the <b>value</b> <b>function</b> onto the advantage <b>function</b> is non-trivial for continuous problems. This figure shows the <b>value</b> <b>function</b> and advantage <b>function</b> of the system described in the ...", "dateLastCrawled": "2022-01-04T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Applying the <b>episodic natural actor-critic architecture</b> to motor ...", "url": "https://www.academia.edu/2800268/Applying_the_episodic_natural_actor_critic_architecture_to_motor_primitive_learning", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2800268/Applying_the_episodic_natural_actor_critic...", "snippet": "For each considered policy \u03c0\u03b8 , a state-<b>value</b> <b>function</b> V \u03c0 (x), the <b>state-action</b> <b>value</b> <b>function</b> Q\u03c0 (x, u) exist and are given by ! &quot;\u221e t # $ \u03c0 ! &quot;\u221e t # $ V \u03c0 (x) = E\u03c4 # # t=0 \u03b3 rt x0 = x , Q (x, u) = E\u03c4 t=0 \u03b3 rt x0 = x, u0 = u , where \u03b3 \u2208 [0, 1[ denotes the discount factor, and \u03c4 a trajectory. It is assumed that some basis functions \u03c6(x) are given so that the state-<b>value</b> <b>function</b> can be approximated with linear <b>function</b> approximation V \u03c0 (x) = \u03c6(x)T v. The general goal is ...", "dateLastCrawled": "2022-01-22T00:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Reinforcement learning as a motion</b> planner\u2014a survey - Academia.edu", "url": "https://www.academia.edu/2438855/Reinforcement_learning_as_a_motion_planner_a_survey", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2438855/<b>Reinforcement_learning_as_a_motion</b>_planner_a_survey", "snippet": "(3) \u2032a <b>value</b> <b>function</b> in state s as a weighted <b>average</b> of the existing estimate and the new estimate: the sum The updated <b>value</b> of the <b>state-action</b> pair is a of observed reward and the current estimate of the weighted <b>average</b> of the current best knowledge and state-<b>value</b> in s\u2032 . The policy is an input to the al- the new estimate. The difference to the TD learning gorithm, and doesn\u2019t change for the duration of the is that the estimates are based on an action, rather episode. then a ...", "dateLastCrawled": "2022-01-15T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Affordance as general <b>value</b> <b>function</b>: A computational model \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2010.14289/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2010.14289", "snippet": "The <b>value</b> <b>function</b> of AlphaGo assesses a state of the game by predicting the win or loss of the agent\u2014the valence of that state for AlphaGo under its policy. The goal of AlphaGo training is to find a policy that maximizes the predicted valence and win the game. The purpose of the <b>value</b> <b>function</b> is to predict that valence accurately so as to facilitate the maximization. AlphaGo\u2019s <b>value</b> prediction is the", "dateLastCrawled": "2021-12-25T14:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Applying the Episodic Natural Actor-Critic Architecture to Motor ...", "url": "https://www.researchgate.net/publication/221165148_Applying_the_Episodic_Natural_Actor-Critic_Architecture_to_Motor_Primitive_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221165148_Applying_the_Episodic_Natural_Actor...", "snippet": "the <b>state-action</b> <b>value</b> <b>function</b> Q ... to high dimensional movement systems <b>like</b> humanoid robots remains an unsolved problem. In this pa- per, we discuss dieren t approaches of reinforcement ...", "dateLastCrawled": "2022-01-27T05:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Reinforcement learning of motor skills with policy gradients</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0893608008000701", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0893608008000701", "snippet": "In Section 3.3, we had realized that this <b>function</b> was hard to learn as it could only represent an impoverished version of the <b>state-action</b> <b>value</b> <b>function</b>. In order to remedy this situation we will derive more useful estimators from two different points of view, i.e., the <b>state-action</b> based point of view and the episodic roll-out based point of view. Both rely on the assumption of knowing an appropriate basis <b>function</b> representation of the critic\u2019s <b>value</b> <b>function</b>, although, as explained ...", "dateLastCrawled": "2022-01-27T05:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Affordance as general <b>value</b> <b>function</b>: A computational model", "url": "https://www.researchgate.net/publication/344910904_Affordance_as_general_value_function_A_computational_model", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344910904_Affordance_as_general_<b>value</b>...", "snippet": "T o meet a <b>baseball</b> trav elling at 100mph, for example, the batter must start swinging the bat when the ball is still only . halfway a way. Detailed studies show that instead of constantly ...", "dateLastCrawled": "2021-10-30T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "January | 2021 | <b>Statistical Odds &amp; Ends</b>", "url": "https://statisticaloddsandends.wordpress.com/2021/01/", "isFamilyFriendly": true, "displayUrl": "https://statisticaloddsandends.wordpress.com/2021/01", "snippet": "The Mendoza Line is a term from <b>baseball</b>. Named after Mario Mendoza, it refers to the threshold of incompetent hitting.It is frequently taken to be a <b>batting</b> <b>average</b> of .200, although all the sources I looked at made sure to note that Mendoza\u2019s career <b>average</b> was actually a little better: .215.. This post explores a few questions related to the Mendoza line: Was Mario Mendoza really so bad as to warrant the expression being named after him?", "dateLastCrawled": "2021-12-02T11:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Background Ops #7: Universal Principles | by Sebastian Marshall | The ...", "url": "https://medium.com/the-strategic-review/background-ops-7-universal-principles-89587e27316", "isFamilyFriendly": true, "displayUrl": "https://medium.com/the-strategic-review/background-ops-7-universal-principles-89587e27316", "snippet": "\u201cI began making \u201c<b>Baseball</b> Cards\u201d for employees that listed their \u201cstats\u201d [\u2026] Just as you wouldn\u2019t have a great fielder who a .160 <b>batting</b> <b>average</b> bat third, you wouldn\u2019t assign a ...", "dateLastCrawled": "2022-01-28T23:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Parents, <b>individualism</b> and education: three paradigms and four ...", "url": "https://bera-journals.onlinelibrary.wiley.com/doi/full/10.1002/rev3.3204", "isFamilyFriendly": true, "displayUrl": "https://bera-journals.onlinelibrary.wiley.com/doi/full/10.1002/rev3.3204", "snippet": "coach all my <b>baseball</b> teams, he&#39;d take me down for <b>batting</b> practice and stuff and he&#39;d throw me, I mean, he&#39;d throw \u2026 there was an occasion when there wasn&#39;t a machine, and he&#39;d have to throw the balls. He&#39;d throw <b>like</b> a hundred and fifty balls to get me better, and he really enjoyed that too, <b>baseball</b> was a big thing for him so [unclear 10:47]. I mean, really anything I ever wanted to do, my parents would support me 100 per cent.", "dateLastCrawled": "2022-01-24T10:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Natural Actor-Critic</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0925231208000532", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231208000532", "snippet": "The <b>state-action</b> <b>value</b> <b>function</b> in any stable linear-quadratic Gaussian regulation problems can be shown to be a bowl (a). The advantage <b>function</b> is always a saddle as shown in (b); it is straightforward to show that the compatible <b>function</b> approximation can exactly represent the advantage <b>function</b>\u2014but projecting the <b>value</b> <b>function</b> onto the advantage <b>function</b> is non-trivial for continuous problems. This figure shows the <b>value</b> <b>function</b> and advantage <b>function</b> of the system described in the ...", "dateLastCrawled": "2022-01-04T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Applying the Episodic Natural Actor-Critic Architecture to Motor ...", "url": "https://www.researchgate.net/publication/221165148_Applying_the_Episodic_Natural_Actor-Critic_Architecture_to_Motor_Primitive_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221165148_Applying_the_Episodic_Natural_Actor...", "snippet": "the <b>state-action</b> <b>value</b> <b>function</b> Q ... A <b>similar</b> approach has been defined in 625 [143]. In [144], a mechanical ventilation system is controlled by means of an RL approach. ... Reinforcement ...", "dateLastCrawled": "2022-01-27T05:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Affordance as general <b>value</b> <b>function</b>: A computational model \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2010.14289/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2010.14289", "snippet": "Whereas a <b>value</b> <b>function</b> predicts about future reward, which is a specific scalar, a general <b>value</b> <b>function</b> predicts about arbitrary scalars (White, 2017). GVFs could be used to evaluate outcomes of policies on any aspect that could be adequately represented as a scalar, such as the robot\u2019s sensor data. Because the GVF prediction is a straightforward generalization of <b>value</b> <b>function</b> prediction, the comparison summarized in Table", "dateLastCrawled": "2021-12-25T14:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Reinforcement learning of motor skills with policy gradients</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0893608008000701", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0893608008000701", "snippet": "In Section 3.3, we had realized that this <b>function</b> was hard to learn as it could only represent an impoverished version of the <b>state-action</b> <b>value</b> <b>function</b>. In order to remedy this situation we will derive more useful estimators from two different points of view, i.e., the <b>state-action</b> based point of view and the episodic roll-out based point of view. Both rely on the assumption of knowing an appropriate basis <b>function</b> representation of the critic\u2019s <b>value</b> <b>function</b>, although, as explained ...", "dateLastCrawled": "2022-01-27T05:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Applying the <b>episodic natural actor-critic architecture</b> to motor ...", "url": "https://www.academia.edu/2800268/Applying_the_episodic_natural_actor_critic_architecture_to_motor_primitive_learning", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2800268/Applying_the_episodic_natural_actor_critic...", "snippet": "For each considered policy \u03c0\u03b8 , a state-<b>value</b> <b>function</b> V \u03c0 (x), the <b>state-action</b> <b>value</b> <b>function</b> Q\u03c0 (x, u) exist and are given by ! &quot;\u221e t # $ \u03c0 ! &quot;\u221e t # $ V \u03c0 (x) = E\u03c4 # # t=0 \u03b3 rt x0 = x , Q (x, u) = E\u03c4 t=0 \u03b3 rt x0 = x, u0 = u , where \u03b3 \u2208 [0, 1[ denotes the discount factor, and \u03c4 a trajectory. It is assumed that some basis functions \u03c6(x) are given so that the state-<b>value</b> <b>function</b> can be approximated with linear <b>function</b> approximation V \u03c0 (x) = \u03c6(x)T v. The general goal is ...", "dateLastCrawled": "2022-01-22T00:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Affordance as general <b>value</b> <b>function</b>: A computational model", "url": "https://www.researchgate.net/publication/344910904_Affordance_as_general_value_function_A_computational_model", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344910904_Affordance_as_general_<b>value</b>...", "snippet": "T o meet a <b>baseball</b> trav elling at 100mph, for example, the batter must start swinging the bat when the ball is still only . halfway a way. Detailed studies show that instead of constantly ...", "dateLastCrawled": "2021-10-30T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Reinforcement learning as a motion</b> planner\u2014a survey - Academia.edu", "url": "https://www.academia.edu/2438855/Reinforcement_learning_as_a_motion_planner_a_survey", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2438855/<b>Reinforcement_learning_as_a_motion</b>_planner_a_survey", "snippet": "(3) \u2032a <b>value</b> <b>function</b> in state s as a weighted <b>average</b> of the existing estimate and the new estimate: the sum The updated <b>value</b> of the <b>state-action</b> pair is a of observed reward and the current estimate of the weighted <b>average</b> of the current best knowledge and state-<b>value</b> in s\u2032 . The policy is an input to the al- the new estimate. The difference to the TD learning gorithm, and doesn\u2019t change for the duration of the is that the estimates are based on an action, rather episode. then a ...", "dateLastCrawled": "2022-01-15T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Background Ops #7: Universal Principles | by Sebastian Marshall | The ...", "url": "https://medium.com/the-strategic-review/background-ops-7-universal-principles-89587e27316", "isFamilyFriendly": true, "displayUrl": "https://medium.com/the-strategic-review/background-ops-7-universal-principles-89587e27316", "snippet": "\u201cI began making \u201c<b>Baseball</b> Cards\u201d for employees that listed their \u201cstats\u201d [\u2026] Just as you wouldn\u2019t have a great fielder who a .160 <b>batting</b> <b>average</b> bat third, you wouldn\u2019t assign a ...", "dateLastCrawled": "2022-01-28T23:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "January | 2021 | <b>Statistical Odds &amp; Ends</b>", "url": "https://statisticaloddsandends.wordpress.com/2021/01/", "isFamilyFriendly": true, "displayUrl": "https://statisticaloddsandends.wordpress.com/2021/01", "snippet": "The Mendoza Line is a term from <b>baseball</b>. Named after Mario Mendoza, it refers to the threshold of incompetent hitting.It is frequently taken to be a <b>batting</b> <b>average</b> of .200, although all the sources I looked at made sure to note that Mendoza\u2019s career <b>average</b> was actually a little better: .215.. This post explores a few questions related to the Mendoza line: Was Mario Mendoza really so bad as to warrant the expression being named after him?", "dateLastCrawled": "2021-12-02T11:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Action Network: Sports Betting Odds, News, Insights, &amp; Analysis", "url": "https://www.actionnetwork.com/", "isFamilyFriendly": true, "displayUrl": "https://www.actionnetwork.com", "snippet": "Nuggets vs. Jazz Preview: Denver Has <b>Value</b> as Road Underdog. Tyler Schmidt (February 2) Perry&#39;s AT&amp;T Pebble Beach Pro-Am Betting Card. Joshua Perry (February 2) Sobel&#39;s AT&amp;T Pebble Beach Pro-Am Preview. Jason Sobel (February 2) The Super Bowl 56 Model Edge to Bet Right Now. PJ Walsh (January 31) NBA Explains Role in Stat-Keeping Accuracy as Props Go Mainstream: &#39;Our System is Constructed to Catch Everything&#39; Darren Rovell (February 2) Jaren Jackson Jr. Rockets From 150-1 to 6-1 to Win NBA ...", "dateLastCrawled": "2022-02-02T22:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Background Ops #7: Universal Principles | by Sebastian Marshall | The ...", "url": "https://medium.com/the-strategic-review/background-ops-7-universal-principles-89587e27316", "isFamilyFriendly": true, "displayUrl": "https://medium.com/the-strategic-review/background-ops-7-universal-principles-89587e27316", "snippet": "\u201cI began making \u201c<b>Baseball</b> Cards\u201d for employees that listed their \u201cstats\u201d [\u2026] Just as you wouldn\u2019t have a great fielder who a .160 <b>batting</b> <b>average</b> bat third, you wouldn\u2019t assign a ...", "dateLastCrawled": "2022-01-28T23:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "January | 2021 | <b>Statistical Odds &amp; Ends</b>", "url": "https://statisticaloddsandends.wordpress.com/2021/01/", "isFamilyFriendly": true, "displayUrl": "https://statisticaloddsandends.wordpress.com/2021/01", "snippet": "The Mendoza Line is a term from <b>baseball</b>. Named after Mario Mendoza, it refers to the threshold of incompetent hitting.It is frequently taken to be a <b>batting</b> <b>average</b> of .200, although all the sources I looked at made sure to note that Mendoza\u2019s career <b>average</b> was actually a little better: .215.. This post explores a few questions related to the Mendoza line: Was Mario Mendoza really so bad as to warrant the expression being named after him?", "dateLastCrawled": "2021-12-02T11:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Artificial Intelligence A Modern Approach</b> | madhumita shet ...", "url": "https://www.academia.edu/39196290/Artificial_Intelligence_A_Modern_Approach", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/39196290/<b>Artificial_Intelligence_A_Modern_Approach</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-03T02:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Multiresolution Stochastic Process Model for Predicting Basketball ...", "url": "https://www.researchgate.net/publication/264497953_A_Multiresolution_Stochastic_Process_Model_for_Predicting_Basketball_Possession_Outcomes", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/264497953_A_Multiresolution_Stochastic...", "snippet": "According to the results, the predictive model <b>can</b> be used in modern basketball. The most efficient ends of the ball possession are the 2-point field goals on the fast break (78.2%), cuts (64.8% ...", "dateLastCrawled": "2022-01-12T05:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Parents, <b>individualism</b> and education: three paradigms and four ...", "url": "https://bera-journals.onlinelibrary.wiley.com/doi/full/10.1002/rev3.3204", "isFamilyFriendly": true, "displayUrl": "https://bera-journals.onlinelibrary.wiley.com/doi/full/10.1002/rev3.3204", "snippet": "Parsons [ 1991] <b>thought</b> that the differences in <b>value</b>-orientation between different personalities played an important part in distributing people to these alternative roles. In other words, Parsons <b>thought</b> that the personalities formed in families, for example\u2014subtle differences in the type of achievement values which were transmitted\u2014were critical to individuation. In addition, Parsons was convinced that families in different social classes approached the job of socialisation in ...", "dateLastCrawled": "2022-01-24T10:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(DOC) <b>The Vagaries of Vagueness: An Essay on &quot;Cultural</b> | Stephen Givens ...", "url": "https://www.academia.edu/8590889/The_Vagaries_of_Vagueness_An_Essay_on_Cultural", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/8590889/<b>The_Vagaries_of_Vagueness_An_Essay_on_Cultural</b>", "snippet": "Ramseyer and Nakazato point out the obvious correlation in both countries between a player\u2018s statistics and salary: the higher the <b>batting</b> <b>average</b>, the higher the salary. To jump from that obvious correlation to the conclusion that game is played the same in both countries (or more mincingly, \u2015Japanese and American fans prize the same game\u2016) will strike most knowledgeable <b>baseball</b> fans as risible. Minoru Nakazato &amp; J. Mark Ramseyer, Bonuses and Biases in Japanese <b>Baseball</b> (Discussion ...", "dateLastCrawled": "2021-08-13T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Katsunari SHIBATA</b> | Dr. Eng., The University of Tokyo", "url": "https://www.researchgate.net/profile/Katsunari-Shibata", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/profile/<b>Katsunari-Shibata</b>", "snippet": "<b>Katsunari Shibata</b> currently works at the Department of Electrical and Electronic Engineering, Oita University. Katsunari does research in Emergence of Intelligence (Functions) in Artificial ...", "dateLastCrawled": "2021-08-05T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "C.B.C. Distribution v. Major League <b>Baseball</b>, 443 F. Supp. 2d 1077 ...", "url": "https://casetext.com/case/cbc-distribution-v-major-league-baseball-2", "isFamilyFriendly": true, "displayUrl": "https://casetext.com/case/cbc-distribution-v-major-league-<b>baseball</b>-2", "snippet": "CBC&#39;s use of the <b>baseball</b> players&#39; names and playing records in the circumstances of this case, moreover, does not involve the character, personality, reputation, or physical appearance of the players; it simply involves historical facts about the <b>baseball</b> players such as their <b>batting</b> averages, home runs, doubles, triples, etc. CBC&#39;s use of players&#39; names in conjunction with their playing records, therefore, does not involve the persona or identity of any player.", "dateLastCrawled": "2021-04-07T17:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Taiwan Question Mark</b>", "url": "https://taiwanquestionmark.blogspot.com/#!", "isFamilyFriendly": true, "displayUrl": "https://<b>taiwanquestionmark</b>.blogspot.com", "snippet": "Take <b>baseball</b> as an example, statistics such as stolen bases, runs batted in, and <b>batting</b> <b>average</b>, are typically used to gauge players from the19th century. That&#39;s why when big league scouts road-test a group of elite amateur prospects, food speed is the first item they check. &quot;Tools&quot; is what they called the talents they are checking for in a kid. There are five tools: the abilities to run, throw, field , hit, and hit with power. From the list, it is not too hard to imagine what kind of ...", "dateLastCrawled": "2022-01-22T09:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Baseball</b> Crank: September 2002 Archives", "url": "http://baseballcrank.com/archives2/2002/09/", "isFamilyFriendly": true, "displayUrl": "<b>baseball</b>crank.com/archives2/2002/09", "snippet": "Glove work is usually <b>thought</b> of as a constant <b>in baseball</b>, and certainly not something a team <b>can</b> turn around in mid-season -- but Baseballjunkie.net points out that the A&#39;s have done just that, rocketing from 12th to 2nd in... Cal Thomas points out that . Following up on my point about Federalism&#39;s Edge -- the tipping point at which a state&#39;s assertion of power threatens other states&#39; autonomy -- take a look at this Michael Barone piece on the Supreme Court&#39;s upcoming look at punitive ...", "dateLastCrawled": "2021-12-14T14:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Affordance as general <b>value</b> <b>function</b>: A computational model", "url": "https://www.researchgate.net/publication/344910904_Affordance_as_general_value_function_A_computational_model", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344910904_Affordance_as_general_<b>value</b>...", "snippet": "T o meet a <b>baseball</b> trav elling at 100mph, for example, the batter must start swinging the bat when the ball is still only. halfway a way. Detailed studies show that instead of constantly ...", "dateLastCrawled": "2021-10-30T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Reinforcement learning as a motion</b> planner\u2014a survey - Academia.edu", "url": "https://www.academia.edu/2438855/Reinforcement_learning_as_a_motion_planner_a_survey", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2438855/<b>Reinforcement_learning_as_a_motion</b>_planner_a_survey", "snippet": "(3) \u2032a <b>value</b> <b>function</b> in state s as a weighted <b>average</b> of the existing estimate and the new estimate: the sum The updated <b>value</b> of the <b>state-action</b> pair is a of observed reward and the current estimate of the weighted <b>average</b> of the current best knowledge and state-<b>value</b> in s\u2032 . The policy is an input to the al- the new estimate. The difference to the TD learning gorithm, and doesn\u2019t change for the duration of the is that the estimates are based on an action, rather episode. then a ...", "dateLastCrawled": "2022-01-15T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Analysis Technology of Tennis Sports Match</b> Based on Data Mining and ...", "url": "https://www.hindawi.com/journals/complexity/2020/8877161/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/complexity/2020/8877161", "snippet": "The reward <b>function</b> <b>can</b> be related to the subsequent state, that is, . Under this definition, ... instant evaluation of a certain state (or action), but the <b>value</b> <b>function</b> considers the quality of a certain state (or <b>state-action</b> pair) from a long-term perspective, so the <b>value</b> <b>function</b> is usually called evaluation <b>function</b>. The expectation of accumulative rewards obtained by executing action and subsequent strategy in state is denoted as ; that is, Among them, is the immediate reward of the ...", "dateLastCrawled": "2022-01-30T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Affordance as general <b>value</b> <b>function</b>: A computational model \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2010.14289/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2010.14289", "snippet": "Whereas a <b>value</b> <b>function</b> predicts about future reward, which is a specific scalar, a general <b>value</b> <b>function</b> predicts about arbitrary scalars (White, 2017). GVFs could be used to evaluate outcomes of policies on any aspect that could be adequately represented as a scalar, such as the robot\u2019s sensor data. Because the GVF prediction is a straightforward generalization of <b>value</b> <b>function</b> prediction, the comparison summarized in Table", "dateLastCrawled": "2021-12-25T14:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Generalized Model Learning for Reinforcement Learning on</b> a Humanoid ...", "url": "https://www.researchgate.net/publication/221067840_Generalized_Model_Learning_for_Reinforcement_Learning_on_a_Humanoid_Robot", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221067840_Generalized_Model_Learning_for...", "snippet": "DT-like models have been used to represent the transition model (Strehl, Diuk, and Littman 2007), reward <b>function</b> (Degris, Sigaud, and Wuillemin 2006), <b>value</b> <b>function</b> (Pyeatt and Howe 2001;Tuyls ...", "dateLastCrawled": "2021-09-23T18:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "C.B.C. Distribution v. Major League <b>Baseball</b>, 443 F. Supp. 2d 1077 ...", "url": "https://casetext.com/case/cbc-distribution-v-major-league-baseball-2", "isFamilyFriendly": true, "displayUrl": "https://casetext.com/case/cbc-distribution-v-major-league-<b>baseball</b>-2", "snippet": "CBC&#39;s use of the <b>baseball</b> players&#39; names and playing records in the circumstances of this case, moreover, does not involve the character, personality, reputation, or physical appearance of the players; it simply involves historical facts about the <b>baseball</b> players such as their <b>batting</b> averages, home runs, doubles, triples, etc. CBC&#39;s use of players&#39; names in conjunction with their playing records, therefore, does not involve the persona or identity of any player.", "dateLastCrawled": "2021-04-07T17:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Parents, <b>individualism</b> and education: three paradigms and four ...", "url": "https://bera-journals.onlinelibrary.wiley.com/doi/full/10.1002/rev3.3204", "isFamilyFriendly": true, "displayUrl": "https://bera-journals.onlinelibrary.wiley.com/doi/full/10.1002/rev3.3204", "snippet": "coach all my <b>baseball</b> teams, he&#39;d take me down for <b>batting</b> practice and stuff and he&#39;d throw me, I mean, he&#39;d throw \u2026 there was an occasion when there wasn&#39;t a machine, and he&#39;d have to throw the balls. He&#39;d throw like a hundred and fifty balls to get me better, and he really enjoyed that too, <b>baseball</b> was a big thing for him so [unclear 10 ...", "dateLastCrawled": "2022-01-24T10:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Bar Prep Flashcards | Quizlet", "url": "https://quizlet.com/410698730/bar-prep-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/410698730/bar-prep-flash-cards", "snippet": "In this case, the school is a private institution performing a <b>function</b>\u2014education\u2014that has never been considered to be an exclusively public <b>function</b>. [See Pierce v. Society of Sisters (1925)] Furthermore, its licensing by the state and receipt of state funds do not constitute significant state involvement with regard to its personnel matters; thus, the teacher cannot establish that the school exercised <b>state action</b>. [See Rendell-Baker v. Kohn (1982)] (A) is incorrect because ...", "dateLastCrawled": "2021-12-24T12:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "CBC <b>DISTRIBUTION v. Major League Baseball</b>, 443 F. Supp. 2d 1077 ...", "url": "https://www.courtlistener.com/opinion/2578684/cbc-distribution-v-major-league-baseball/", "isFamilyFriendly": true, "displayUrl": "https://www.courtlistener.com/opinion/2578684/cbc-<b>distribution-v-major-league-baseball</b>", "snippet": "Opinion for CBC <b>DISTRIBUTION v. Major League Baseball</b>, 443 F. Supp. 2d 1077 \u2014 Brought to you by Free Law Project, a non-profit dedicated to creating high quality open legal information.", "dateLastCrawled": "2021-09-24T13:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Civil Rights Act of 1964 by Jane Runyon Answers - Jerry Whaeld", "url": "https://jerrywhaeld.blogspot.com/2021/11/civil-rights-act-of-1964-by-jane-runyon.html", "isFamilyFriendly": true, "displayUrl": "https://jerrywhaeld.blogspot.com/2021/11/civil-rights-act-of-1964-by-jane-runyon.html", "snippet": "Well, I <b>can</b>&#39;t see my chart over there, but I believe the first thing we have up is a six-point litmus test. What I fear is going on here is an effort to establish a litmus test where you have to support judicial activism, restrict First Amendment rights of political speech and association, oppose Second Amendment rights for law-abiding citizens, support partial-birth abortion, support racial preferences, and expand the Federal Government or, put another way, diminish the role of the States ...", "dateLastCrawled": "2022-01-20T00:28:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Relationship between state (V) and action(Q) <b>value</b> <b>function</b> in ...", "url": "https://medium.com/intro-to-artificial-intelligence/relationship-between-state-v-and-action-q-value-function-in-reinforcement-learning-bb9a988c0127", "isFamilyFriendly": true, "displayUrl": "https://medium.com/intro-to-artificial-intelligence/relationship-between-state-v-and...", "snippet": "<b>Value</b> <b>function</b> can be defined as the expected <b>value</b> of an agent in a certain state. There are two types of <b>value</b> functions in RL: State-<b>value</b> and action-<b>value</b>. It is important to understand the\u2026", "dateLastCrawled": "2022-02-03T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "<b>Value</b>. State-<b>value</b> <b>function</b> v_\u03c0: gives us the <b>value</b> of a state under \u03c0; Action-<b>value</b> <b>function</b> q_\u03c0: gives us the <b>value</b> of an action under \u03c0. q_\u03c0 is referred to as the Q-<b>function</b>, and the output from the <b>function</b> for any given <b>state-action</b> pair is called a Q-<b>value</b>.", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Teaching machines to behave: Reinforcement <b>Learning</b> | by Diego Gomez ...", "url": "https://towardsdatascience.com/rl-4-all-1-3edac941fe37", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/rl-4-all-1-3edac941fe37", "snippet": "Notice that, as in all <b>machine</b> <b>learning</b> sub-fields, RL programs are not coded explicitly to perform optimally in some given task. ... Similarly, a* is the optimal <b>state-action</b>-<b>value</b> <b>function</b>, obtained if followed an optimal policy \u03c0*. Optimal <b>value</b> functions: Obtained when following a policy \u03c0 that maximizes v(s) and a(s,a) Assuming that the optimal <b>value</b> functions v* and a* are known, but the optimal policy is not, it is possible to build an optimal policy in the following ways: When v*(s ...", "dateLastCrawled": "2022-01-08T13:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Value</b>-<b>Function</b>-<b>Based Transfer for Reinforcement Learning</b> Using ...", "url": "https://www.researchgate.net/publication/221604435_Value-Function-Based_Transfer_for_Reinforcement_Learning_Using_Structure_Mapping", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221604435_<b>Value</b>-<b>Function</b>-Based_Transfer_for...", "snippet": "chological and computational theory about <b>analogy</b> making, ... the form of a <b>state-action</b> <b>value</b> <b>function</b>, or a q-<b>functio n</b>. A. q-<b>function</b> q: S \u00d7 A 7\u2192 R maps from <b>state-action</b> pairs to. real ...", "dateLastCrawled": "2021-10-16T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine learning for biochemical engineering: A</b> review - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1369703X21001303", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1369703X21001303", "snippet": "<b>Value</b>-based algorithms, typically represented by Q-<b>learning</b>, explicitly learn and optimise the <b>state-action</b> <b>value</b> <b>function</b> and generate the optimal policy by acting greedily with respect to it i.e. choosing the control corresponding to the maximum Q \u03c0 x, u <b>value</b> (<b>state-action</b> <b>value</b>). There are also hybrid algorithms, such as actor-critic methods, which combine policy optimisation methods and <b>value</b>-based methods. Although RL has shown success in game-based control benchmarks, such as AlphaGo", "dateLastCrawled": "2022-01-26T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "AI and Reinforcement <b>Learning</b> \u2014 Machines that Learn through Experience ...", "url": "https://www.cantorsparadise.com/ai-and-reinforcement-learning-machines-that-learn-through-experience-e7eea7bb6765", "isFamilyFriendly": true, "displayUrl": "https://www.cantorsparadise.com/ai-and-reinforcement-<b>learning</b>-<b>machines</b>-that-learn...", "snippet": "To align the policy with the updated <b>value</b> <b>function</b>, the algorithm modifies the policy so it would greedily follow the <b>value</b> <b>function</b> (meaning, choosing to perform actions that has the highest <b>value</b>). The algorithm continues by generating a new episode, now under the improved policy, which, in turn, derives a more accurate <b>value</b> estimation and so on. In this process, both the policy and the <b>value</b> <b>function</b> converge to their optimal values, until sufficient accuracy is reached, or when no more ...", "dateLastCrawled": "2022-01-25T17:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>SARSA</b> vs Q - <b>learning</b>", "url": "https://tcnguyen.github.io/reinforcement_learning/sarsa_vs_q_learning.html", "isFamilyFriendly": true, "displayUrl": "https://tcnguyen.github.io/reinforcement_<b>learning</b>/<b>sarsa</b>_vs_q_<b>learning</b>.html", "snippet": "<b>SARSA</b> will learn the optimal $\\epsilon$-greedy policy, i.e, the Q-<b>value</b> <b>function</b> will converge to a optimal Q-<b>value</b> <b>function</b> but in the space of $\\epsilon$-greedy policy only (as long as each <b>state action</b> pair will be visited infinitely). We expect that in the limit of $\\epsilon$ decaying to $0$, <b>SARSA</b> will converge to the overall optimal policy. I quote here a paragraph from", "dateLastCrawled": "2022-01-30T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Learning Analogy for Meditation (illustrated</b>) - LessWrong 2.0 ...", "url": "https://www.greaterwrong.com/posts/chHhuCvmZqYLM32gz/machine-learning-analogy-for-meditation-illustrated", "isFamilyFriendly": true, "displayUrl": "https://www.greaterwrong.com/posts/chHhuCvmZqYLM32gz/<b>machine</b>-<b>learning</b>-<b>analogy</b>-for...", "snippet": "<b>Machine Learning Analogy for Meditation (illustrated</b>) ... and the algorithm we use includes a <b>value</b> table: [picture: table, actions on x-axis, states on y-axis, cells of table are estimated values of taking actions in states] A <b>value</b> isn\u2019t just the learned estimate of the immediate reward which you get by taking an action in a state, but rather, the estimate of the eventual rewards, in total, from that action. This makes the values difficult to estimate. An estimate is improved by <b>value</b> it", "dateLastCrawled": "2022-01-17T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Reinforcement Learning: Prediction, Control and</b> <b>Value</b> <b>Function</b> ...", "url": "https://deepai.org/publication/reinforcement-learning-prediction-control-and-value-function-approximation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>reinforcement-learning-prediction-control-and</b>-<b>value</b>...", "snippet": "<b>Reinforcement Learning: Prediction, Control and Value Function Approximation</b>. With the increasing power of computers and the rapid development of self-<b>learning</b> methodologies such as <b>machine</b> <b>learning</b> and artificial intelligence, the problem of constructing an automatic Financial Trading Systems (FTFs) becomes an increasingly attractive research ...", "dateLastCrawled": "2022-01-16T03:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>value</b> of a <b>function</b>?", "url": "https://psichologyanswers.com/library/lecture/read/57841-what-is-value-of-a-function", "isFamilyFriendly": true, "displayUrl": "https://psichologyanswers.com/library/lecture/read/57841-what-is-<b>value</b>-of-a-<b>function</b>", "snippet": "What is a <b>value</b> <b>function</b> reinforcement <b>learning</b>? <b>Value</b> <b>function</b> Many reinforcement <b>learning</b> introduce the notion of `<b>value</b>-<b>function</b>` which often denoted as V(s) . The <b>value</b> <b>function</b> represent how good is a state for an agent to be in. It is equal to expected total reward for an agent starting from state s . What is optimal <b>value</b> <b>function</b>? The optimal <b>Value</b> <b>function</b> is one which yields maximum <b>value</b> compared to all other <b>value</b> <b>function</b>. When we say we are solving an MDP it actually means we ...", "dateLastCrawled": "2022-01-15T22:23:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(state-action value function)  is like +(batting average in baseball)", "+(state-action value function) is similar to +(batting average in baseball)", "+(state-action value function) can be thought of as +(batting average in baseball)", "+(state-action value function) can be compared to +(batting average in baseball)", "machine learning +(state-action value function AND analogy)", "machine learning +(\"state-action value function is like\")", "machine learning +(\"state-action value function is similar\")", "machine learning +(\"just as state-action value function\")", "machine learning +(\"state-action value function can be thought of as\")", "machine learning +(\"state-action value function can be compared to\")"]}