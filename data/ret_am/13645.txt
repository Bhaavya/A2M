{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Flipping coins in continuous time: The Poisson process</b> - Systematic ...", "url": "https://juliohm.github.io/science/coin-flipping/", "isFamilyFriendly": true, "displayUrl": "https://juliohm.github.io/science/<b>coin</b>-<b>flip</b>ping", "snippet": "Discrete-time <b>coin</b> <b>flip</b> process. Suppose that I ask you to simulate a sequence of <b>i.i.d</b>. (independent and identically distributed) <b>coin</b> flips in a computer where the probability of flipping a <b>coin</b> and observing a head is \\(p\\) and the probability of flipping a <b>coin</b> and observing a tail is \\(1-p\\):, , , , , , \\(\\cdots\\),", "dateLastCrawled": "2022-01-29T17:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Independent and Identically Distributed Data</b> (<b>IID</b> ... - Statistics By Jim", "url": "https://statisticsbyjim.com/basics/independent-identically-distributed-data/", "isFamilyFriendly": true, "displayUrl": "https://statisticsbyjim.com/basics/independent-identically-distributed-data", "snippet": "As you <b>flip</b> the <b>coin</b>, one result does not influence or predict the next outcome at all. Even if you get five heads in a row, the next <b>coin</b> <b>flip</b> still has a 50 percent chance of being heads. You can apply the same thinking to other characteristics. For example, in our IQ study, if we measure an individual\u2019s IQ, it shouldn\u2019t provide any information about the next subject we assess. If we\u2019re selecting subjects randomly, that should be true. However, if we\u2019re not using random selection ...", "dateLastCrawled": "2022-02-02T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 2, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Independent and identically distributed</b> random variables - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Independent_and_identically_distributed</b>_random_variables", "snippet": "A sequence of fair or loaded dice rolls is <b>i.i.d</b>. A sequence of fair or unfair <b>coin</b> flips is <b>i.i.d</b>. In signal processing and image processing the notion of transformation to <b>i.i.d</b>. implies two specifications, the &quot;i.d.&quot;part and the &quot;i.&quot; part: (i.d.) the signal level must be balanced on the time axis; (i.) the signal spectrum must be flattened, i.e. transformed by filtering (such as deconvolution) to a white noise signal (i.e. a signal where all frequencies are equally present). Example 2 ...", "dateLastCrawled": "2022-02-03T02:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "intuition - What are <b>i.i.d</b>. random variables? - Cross Validated", "url": "https://stats.stackexchange.com/questions/17391/what-are-i-i-d-random-variables", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/17391", "snippet": "Lets say X represents Obama about to <b>flip</b> a <b>coin</b> 100 times. Now let&#39;s say Y represents a Priest about to <b>flip</b> a <b>coin</b> 100 times. If Obama and the Priest <b>flip</b> coins with the same probability of landing on heads, then X and Y are considered identically distributed. If we sample repeatedly from either the Priest or Obama, then the samples are ...", "dateLastCrawled": "2022-02-02T20:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Maximum Likelihood Estimate (MLE) Bayes Classifier", "url": "https://www.cs.cmu.edu/~aarti/Class/10315_Fall20/lecs/Lecture3_inked.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~aarti/Class/10315_Fall20/lecs/Lecture3_inked.pdf", "snippet": "<b>Like</b> a <b>coin</b> <b>flip</b> No Stress Stress X, average brain activity in \u201cAmygdala\u201d low high f(X) Test subject = Bernoulli(q) How to learn parameters from data? MLE (Discrete case) 16. Learning parameters in distributions 17 = q = 1 -q Learning \u03b8is equivalent to learning probability of head in <b>coin</b> <b>flip</b>. \u00d8How do you learn that? Data = Answer: 3/5 \u00d8Why?? Bernoulli distribution 18 Data, D = \u2022P(Heads) = q, P(Tails) = 1-q \u2022Flips are <b>i.i.d</b>.: \u2013Independentevents \u2013Identically distributed ...", "dateLastCrawled": "2022-01-15T18:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Introduction to MLE and MAP</b> | Machine Learning Tutorial", "url": "https://sci2lab.github.io/ml_tutorial/mle_map/", "isFamilyFriendly": true, "displayUrl": "https://sci2lab.github.io/ml_tutorial/mle_map", "snippet": "<b>flip</b>_<b>coin</b>. <b>flip</b>_<b>coin</b>(num_of_experiments=1000, num_of_flips=30) <b>Flip</b> the <b>coin</b> num_of_flips times and repeat this experiment num_of_experiments times. And return the number of heads grouped together in all the experiments.", "dateLastCrawled": "2022-02-02T07:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Machine Learning Warmup: Maximum Likelihood Estimation", "url": "https://courses.cs.washington.edu/courses/csep546/21au/schedule/lecture02/lecture_2_annotated.pdf", "isFamilyFriendly": true, "displayUrl": "https://courses.cs.washington.edu/courses/csep546/21au/schedule/lecture02/lecture_2...", "snippet": "Machine Learning design process often looks <b>like</b> this: ... \u2022 You: <b>flip</b> the <b>coin</b> 5 times. Billionaire: I got 3 heads. \u2022 You: <b>flip</b> the <b>coin</b> 50 times. Billionaire: I got 20 heads. \u2022 Billionaire: Which one is right? Why? \u2022 For n flips and k heads the MLE is unbiased for true \u03b8*: \u2022 Expectation describes how the estimator behaves on average. \u2022 For any \u03b5&gt;0 can we bound ? \u2022 Exercise: Apply Markov\u2019s inequality to obtain bound. (Hint: set ) Expectation b MLE = k n E[ b MLE]= \u21e4 P(| ", "dateLastCrawled": "2022-01-21T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "probability - Expectation of 500 <b>coin</b> flips after 500 realizations ...", "url": "https://stats.stackexchange.com/questions/440004/expectation-of-500-coin-flips-after-500-realizations", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/440004/expectation-of-500-<b>coin</b>-<b>flips</b>-after...", "snippet": "A million heads in a row still looks <b>like</b> zero to infinity. If you were to &quot;<b>flip</b> the <b>coin</b> an infinite number of times&quot;--which you can&#39;t do, but what we really mean is &quot;keep flipping&quot;--then a run of a million heads eventually becomes a near certainty. But infinity is a tricky concept, and we have to work hard to make sure we know what we&#39;re ...", "dateLastCrawled": "2022-01-27T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Parameter Inference \u2014 Maximum Aposteriori</b> | by Rahul Bohare | Towards ...", "url": "https://towardsdatascience.com/parameter-inference-maximum-aposteriori-estimate-49f3cd98267a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>parameter-inference-maximum-aposteriori</b>-estimate-49f3cd...", "snippet": "This result tells us that the probability of next <b>flip</b> being Tails is 0 (i.e., it predicts that no <b>flip</b> is ever gonna turn up Tails =&gt; the <b>coin</b> is always going to show Heads), and it is glaringly obvious that this is not the case (barring the extreme case where the <b>coin</b> is heavily loaded). Now, this poses a big problem in the Parameter Estimation process because it does not give us the accurate probability of the next <b>flip</b>. We know that even a fair <b>coin</b> has a 25% chance of showing two", "dateLastCrawled": "2022-02-01T09:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Nicholas Ruozzi University of Texas at Dallas", "url": "https://personal.utdallas.edu/~nrr150130/cs7301/2016fa/lects/Lecture_14_Bayes.pdf", "isFamilyFriendly": true, "displayUrl": "https://personal.utdallas.edu/~nrr150130/cs7301/2016fa/lects/Lecture_14_Bayes.pdf", "snippet": "\u2022Suppose that we have a <b>coin</b>, and we would <b>like</b> to figure out what the probability is that it will <b>flip</b> up heads \u2013How should we estimate the bias? 5. Estimating the Bias of a <b>Coin</b> \u2022Suppose that we have a <b>coin</b>, and we would <b>like</b> to figure out what the probability is that it will <b>flip</b> up heads \u2013How should we estimate the bias? \u2013With these <b>coin</b> flips, our estimate of the bias is: ? 6. Estimating the Bias of a <b>Coin</b> \u2022Suppose that we have a <b>coin</b>, and we would <b>like</b> to figure out what th", "dateLastCrawled": "2022-01-31T18:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Naive Bayes and Text Classification - Dr. Sebastian Raschka", "url": "https://sebastianraschka.com/Articles/2014_naive_bayes_1.html", "isFamilyFriendly": true, "displayUrl": "https://sebastianraschka.com/Articles/2014_naive_bayes_1.html", "snippet": "One popular example of <b>i.i.d</b>. variables is the classic <b>coin</b> tossing: The first <b>coin</b> <b>flip</b> does not affect the outcome of a second <b>coin</b> <b>flip</b> and so forth. Given a fair <b>coin</b>, the probability of the <b>coin</b> landing on \u201cheads\u201d is always 0.5 no matter of how often the <b>coin</b> if flipped. An additional assumption of naive Bayes classifiers is the conditional independence of features. Under this naive assumption, the class-conditional probabilities or (likelihoods) of the samples can be directly ...", "dateLastCrawled": "2022-01-31T01:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Independent and Identically Distributed Data</b> (<b>IID</b> ... - Statistics By Jim", "url": "https://statisticsbyjim.com/basics/independent-identically-distributed-data/", "isFamilyFriendly": true, "displayUrl": "https://statisticsbyjim.com/basics/independent-identically-distributed-data", "snippet": "The results of a <b>coin</b> toss represent independent binary data. The classic example of independent events is flipping a <b>coin</b>. As you <b>flip</b> the <b>coin</b>, one result does not influence or predict the next outcome at all. Even if you get five heads in a row, the next <b>coin</b> <b>flip</b> still has a 50 percent chance of being heads. You can apply the same thinking to other characteristics. For example, in our IQ study, if we measure an individual\u2019s IQ, it shouldn\u2019t provide any information about the next ...", "dateLastCrawled": "2022-02-02T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 2, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Independent and identically distributed</b> random variables - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Independent_and_identically_distributed</b>_random_variables", "snippet": "A sequence of fair or loaded dice rolls is <b>i.i.d</b>. A sequence of fair or unfair <b>coin</b> flips is <b>i.i.d</b>. In signal processing and image processing the notion of transformation to <b>i.i.d</b>. implies two specifications, the &quot;i.d.&quot;part and the &quot;i.&quot; part: (i.d.) the signal level must be balanced on the time axis; (i.) the signal spectrum must be flattened, i.e. transformed by filtering (such as deconvolution) to a white noise signal (i.e. a signal where all frequencies are equally present). Example 2 ...", "dateLastCrawled": "2022-02-03T02:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Optimal Coin Flipping</b> - Cornell University", "url": "https://www.cs.cornell.edu/~kozen/Papers/Coinflip.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cornell.edu/~kozen/Papers/<b>Coinflip</b>.pdf", "snippet": "the output is a sequence of <b>i.i.d</b>. bias-q <b>coin</b> \ufb02ips, 0 \u2264 q \u2264 1. We call this a p,q-simulation protocol. For such protocols, the e\ufb03ciency is H(q) \u00b7 E prod H(p) \u00b7 E cons, where H is the Shannon entropy H(p)=\u2212plogp \u2212 (1 \u2212 p)log(1 \u2212 p) F. van Breugel et al. (Eds.): Panangaden Festschrift, LNCS 8464, pp. 407\u2013426, 2014. \u20ddc Springer International Publishing Switzerland 2014 kozen@cs.cornell.edu. 408 D. Kozen and E prod and E cons are, respectively, the expected number of ...", "dateLastCrawled": "2022-01-29T20:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bayesian</b> Inference of a Binomial Proportion - The Analytical <b>Approach</b> ...", "url": "https://www.quantstart.com/articles/Bayesian-Inference-of-a-Binomial-Proportion-The-Analytical-Approach/", "isFamilyFriendly": true, "displayUrl": "https://www.quantstart.com/articles/<b>Bayesian</b>-Inference-of-a-Binomial-Proportion-The...", "snippet": "Each <b>flip</b> of the <b>coin</b> is completely independent of the others, i.e. we have independent and identically distributed (<b>i.i.d</b>.) <b>coin</b> flips; The fairness of the <b>coin</b> does not change in time, that is it is stationary. With these assumptions in mind, we can now begin discussing the <b>Bayesian</b> procedure. Recalling Bayes&#39; Rule", "dateLastCrawled": "2022-02-02T18:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Are Returns Independent <b>and Identically Distributed</b> (<b>i.i.d</b>.)?", "url": "https://marcosammon.com/2016/07/14/iidret.html", "isFamilyFriendly": true, "displayUrl": "https://marcosammon.com/2016/07/14/<b>iid</b>ret.html", "snippet": "An example is a sequence of <b>coin</b> flips - the realization of each <b>flip</b> does not depend on any of the previous flips, nor will it affect future flips. If a <b>coin</b> comes up heads 100 times in a row, the probability of heads on the next <b>flip</b> is still 1/2 (assuming the <b>coin</b> is fair, but even if it isn\u2019t, the sequence of flips will still be \\(<b>i.i.d</b>.\\)!).", "dateLastCrawled": "2022-01-29T17:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "stochastic processes - Why are independent identically distributed ...", "url": "https://math.stackexchange.com/questions/4359384/why-are-independent-identically-distributed-sequences-on-a-discrete-probability", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/4359384/why-are-independent-identically...", "snippet": "While any single <b>coin</b> <b>flip</b> (or finitely many <b>coin</b> flips) can be formulated on a finite discrete probability space $\\{0,1\\}^n$, ... the theorem does imply that a sequence of <b>i.i.d</b>. <b>coin</b> flips cannot be formulated on a countable discrete probability space. Share. Cite. Follow edited Jan 18 at 1:14. answered Jan 17 at 21:47. angryavian angryavian. 77.5k 5 5 gold badges 56 56 silver badges 120 120 bronze badges $\\endgroup$ 13 $\\begingroup$ Thank you for your answer! It helps clarify some of my ...", "dateLastCrawled": "2022-01-28T23:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "probability - Expectation of 500 <b>coin</b> flips after 500 realizations ...", "url": "https://stats.stackexchange.com/questions/440004/expectation-of-500-coin-flips-after-500-realizations", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/440004/expectation-of-500-<b>coin</b>-<b>flips</b>-after...", "snippet": "So, here is my question/confusion: I understand that each <b>coin</b> <b>flip</b> is independent and that any single individual <b>coin</b> <b>flip</b> has a probability of $\\frac{1}{2}$ coming up heads. However, based on the law of large numbers we know that the (if we value tails as 0 and heads as 1) mean of the tosses will approach $0.5$ as the number of tosses approaches $\\infty$ .", "dateLastCrawled": "2022-01-27T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Gambler&#39;s and Hot-Hand Fallacies: Theory and Applications | The Review ...", "url": "https://academic.oup.com/restud/article-abstract/77/2/730/1581352", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/restud/article-abstract/77/2/730/1581352", "snippet": "When the state is constant, and so signals are <b>i.i.d</b>., the individual can predict that long streaks of <b>similar</b> signals will continue\u2014a <b>hot-hand fallacy</b>. When signals are serially correlated, the individual typically under-reacts to short streaks, over-reacts to longer ones, and under-reacts to very long ones. Our model has implications for a number of puzzles in finance, e.g. the active-fund and fund-flow puzzles, and the presence of momentum and reversal in asset returns.", "dateLastCrawled": "2022-01-06T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Martingale Theory Problem set 3, with solutions Martingales</b>", "url": "https://people.maths.bris.ac.uk/~mabat/MARTINGALE_THEORY_2016/MT_SOL_03.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.maths.bris.ac.uk/~mabat/MARTINGALE_THEORY_2016/MT_SOL_03.pdf", "snippet": "3.3HW Gambler&#39;s Ruin, 2 Answer the same questions as in problem 2 when the probability of winning or loosing one pound in each round is p, respectively, q:= 1 p, with p2(0;1).", "dateLastCrawled": "2022-02-02T16:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Independent and identically distributed</b> random variables - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Independent_and_identically_distributed</b>_random_variables", "snippet": "A sequence of fair or loaded dice rolls is <b>i.i.d</b>. A sequence of fair or unfair <b>coin</b> flips is <b>i.i.d</b>. In signal processing and image processing the notion of transformation to <b>i.i.d</b>. implies two specifications, the &quot;i.d.&quot;part and the &quot;i.&quot; part: (i.d.) the signal level must be balanced on the time axis; (i.) the signal spectrum must be flattened, i.e. transformed by filtering (such as deconvolution) to a white noise signal (i.e. a signal where all frequencies are equally present). Example 2 ...", "dateLastCrawled": "2022-02-03T02:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Independent and Identically Distributed Data</b> (<b>IID</b> ... - Statistics By Jim", "url": "https://statisticsbyjim.com/basics/independent-identically-distributed-data/", "isFamilyFriendly": true, "displayUrl": "https://statisticsbyjim.com/basics/independent-identically-distributed-data", "snippet": "As you <b>flip</b> the <b>coin</b>, one result does not influence or predict the next outcome at all. Even if you get five heads in a row, the next <b>coin</b> <b>flip</b> still has a 50 percent chance of being heads. You <b>can</b> apply the same thinking to other characteristics. For example, in our IQ study, if we measure an individual\u2019s IQ, it shouldn\u2019t provide any information about the next subject we assess. If we\u2019re selecting subjects randomly, that should be true. However, if we\u2019re not using random selection ...", "dateLastCrawled": "2022-02-02T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>1 Discrete-time Markov chains</b> - <b>Columbia University</b>", "url": "http://www.columbia.edu/~ks20/stochastic-I/stochastic-I-MCI.pdf", "isFamilyFriendly": true, "displayUrl": "<b>www.columbia.edu</b>/~ks20/stochastic-I/stochastic-I-MCI.pdf", "snippet": "As a very simple example, consider the sequential tossing of a \\fair&quot; <b>coin</b>. We let X n denote the outcome of the nth toss. We <b>can</b> take the X n as p= 0:5 Bernoulli rvs, P(X n = 0) = P(X n = 1) = 0:5, with X n = 1 denoting that the nth ip landed heads, and X n = 0 denoting that it landed tails. We also would assume that the sequence of rvs are independent. This then yields an example of an independent and identically distributed (<b>iid</b>) sequence of rvs. Such sequences are easy to deal with for ...", "dateLastCrawled": "2022-02-03T04:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 9 Limit Theorems and <b>Conditional Expectation</b> | bookdown-demo.knit", "url": "https://bookdown.org/probability/beta/limit-theorems-and-conditional-expectation.html", "isFamilyFriendly": true, "displayUrl": "https://bookdown.org/probability/beta/limit-theorems-and-<b>conditional-expectation</b>.html", "snippet": "Consider <b>i.i.d</b>. random variables \\(X_1, X_2 ... essentially. First, you randomly select how many times you <b>flip</b> the <b>coin</b> (since we have a Binomial with probability parameter .5, this is essentially flipping a <b>coin</b> and counting heads), and then you actually have to <b>flip</b> the <b>coin</b> that specified number of times. We know using Adam\u2019s law that: \\[E(Y) = E\\big(E(Y|X)\\big)\\] And we know that \\(E(Y|X) = \\frac{X}{2}\\), so we are left with: \\[E(Y) = E(\\frac{X}{2}) = \\frac{E(X)}{2}\\] We know that \\(E", "dateLastCrawled": "2022-01-31T10:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "stat slides.pdf - Statistics 2020 Gabor Revesz Random variables <b>coin</b> ...", "url": "https://www.coursehero.com/file/107054762/stat-slidespdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/107054762/stat-slidespdf", "snippet": "Random variables <b>coin</b> <b>flip</b> number of passengers turning up at the gate stock price tomorrow All <b>can</b> <b>be thought</b> of as an experiment \u2013 exact outcome not known beforehand, but we have some information about it. <b>Can</b> be described as a random variable. Notation: X, Y, Z, ...", "dateLastCrawled": "2022-02-03T10:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "probability - Expectation of 500 <b>coin</b> flips after 500 realizations ...", "url": "https://stats.stackexchange.com/questions/440004/expectation-of-500-coin-flips-after-500-realizations", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/440004/expectation-of-500-<b>coin</b>-<b>flips</b>-after...", "snippet": "So, here is my question/confusion: I understand that each <b>coin</b> <b>flip</b> is independent and that any single individual <b>coin</b> <b>flip</b> has a probability of $\\frac{1}{2}$ coming up heads. However, based on the law of large numbers we know that the (if we value tails as 0 and heads as 1) mean of the tosses will approach $0.5$ as the number of tosses approaches $\\infty$ .", "dateLastCrawled": "2022-01-27T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bernoulli trials</b> - <b>Columbia University</b>", "url": "http://www.columbia.edu/~kr2248/4109/chapter5.pdf", "isFamilyFriendly": true, "displayUrl": "<b>www.columbia.edu</b>/~kr2248/4109/chapter5.pdf", "snippet": "Ex. <b>Flip</b> a fair <b>coin</b>. Let X = number of heads. Then X is a Bernoulli random variable with p=1/2. E(X) = 1/2 Var(X) = 1/4 . Binomial random variables Consider that n independent <b>Bernoulli trials</b> are performed. Each of these trials has probability p of success and probability (1-p) of failure. Let X = number of successes in the n trials. p(0) = P(0 successes in n trials) = (1-p)n {FFFFFFF} p(1) = P(1 success in n trials) = (n 1)p(1-p)n-1 {FSFFFFF} p(2) = P(2 successes in n trials) = (n 2)p2(1 ...", "dateLastCrawled": "2022-02-02T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Gambler&#39;s and Hot-Hand Fallacies: Theory and Applications | The Review ...", "url": "https://academic.oup.com/restud/article-abstract/77/2/730/1581352", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/restud/article-abstract/77/2/730/1581352", "snippet": "Thus, a manager&#39;s returns are <b>i.i.d</b>. conditional on ability, and the manager <b>can</b> be viewed as a \u201c<b>coin</b>\u201d with the probability of H and T corresponding to ability. To ensure that aggregate variables are stochastic despite the continuum assumption, we assume that ability and luck are identical within the cohort of managers who enter the fund in a given period. 14", "dateLastCrawled": "2022-01-06T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Hey\u2014guess <b>what? There really is a hot</b> hand! | Statistical Modeling ...", "url": "https://statmodeling.stat.columbia.edu/2015/07/09/hey-guess-what-there-really-is-a-hot-hand/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2015/07/09/hey-guess-<b>what-there-really-is-a-hot</b>...", "snippet": "Jack takes a <b>coin</b> from his pocket and decides that he will <b>flip</b> it 4 times in a row, writing down the outcome of each <b>flip</b> on a scrap of paper. After he is done flipping, he will look at the flips that immediately followed an outcome of heads, and compute the relative frequency of heads on those flips. Because the <b>coin</b> is fair, Jack of course expects this conditional relative frequency to be equal to the probability of flipping a heads: 0.5. Shockingly, Jack is wrong. If he were to sample 1 ...", "dateLastCrawled": "2021-11-22T12:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "But the first 20 did die : mathmemes", "url": "https://www.reddit.com/r/mathmemes/comments/sdkb5q/but_the_first_20_did_die/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/mathmemes/comments/sdkb5q/but_the_first_20_did_die", "snippet": "if you <b>flip</b> a <b>coin</b> 5 times and you get 5 heads in a row, the probability that the 6th <b>flip</b> is heads is 50%. if you <b>flip</b> a <b>coin</b> 10 times and you get 10 heads in a row, the probability that the 11th <b>flip</b> is heads is 50%. if you <b>flip</b> a <b>coin</b> 100 times and you get 100 heads in a row, the probability that the 101st <b>flip</b> is heads is ~100%. the <b>coin</b> is rigged. 75. Reply. Share. Report Save Follow. level 2 \u00b7 2 hr. ago \u00b7 edited 1 hr. ago. Might not be. The probability that 20 patients survive in a ...", "dateLastCrawled": "2022-01-27T06:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Independent and identically distributed</b> random variables - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Independent_and_identically_distributed</b>_random_variables", "snippet": "A sequence of fair or loaded dice rolls is <b>i.i.d</b>. A sequence of fair or unfair <b>coin</b> flips is <b>i.i.d</b>. In signal processing and image processing the notion of transformation to <b>i.i.d</b>. implies two specifications, the &quot;i.d.&quot;part and the &quot;i.&quot; part: (i.d.) the signal level must be balanced on the time axis; (i.) the signal spectrum must be flattened, i.e. transformed by filtering (such as deconvolution) to a white noise signal (i.e. a signal where all frequencies are equally present). Example 2 ...", "dateLastCrawled": "2022-02-03T02:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Naive Bayes and Text Classification - Dr. Sebastian Raschka", "url": "https://sebastianraschka.com/Articles/2014_naive_bayes_1.html", "isFamilyFriendly": true, "displayUrl": "https://sebastianraschka.com/Articles/2014_naive_bayes_1.html", "snippet": "One popular example of <b>i.i.d</b>. variables is the classic <b>coin</b> tossing: The first <b>coin</b> <b>flip</b> does not affect the outcome of a second <b>coin</b> <b>flip</b> and so forth. Given a fair <b>coin</b>, the probability of the <b>coin</b> landing on \u201cheads\u201d is always 0.5 no matter of how often the <b>coin</b> if flipped. An additional assumption of naive Bayes classifiers is the conditional independence of features. Under this naive assumption, the class-conditional probabilities or (likelihoods) of the samples <b>can</b> be directly ...", "dateLastCrawled": "2022-01-31T01:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Optimal Coin Flipping</b> - Cornell University", "url": "https://www.cs.cornell.edu/~kozen/Papers/Coinflip.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cornell.edu/~kozen/Papers/<b>Coinflip</b>.pdf", "snippet": "the output is a sequence of <b>i.i.d</b>. bias-q <b>coin</b> \ufb02ips, 0 \u2264 q \u2264 1. We call this a p,q-simulation protocol. For such protocols, the e\ufb03ciency is H(q) \u00b7 E prod H(p) \u00b7 E cons, where H is the Shannon entropy H(p)=\u2212plogp \u2212 (1 \u2212 p)log(1 \u2212 p) F. van Breugel et al. (Eds.): Panangaden Festschrift, LNCS 8464, pp. 407\u2013426, 2014. \u20ddc Springer International Publishing Switzerland 2014 kozen@cs.cornell.edu. 408 D. Kozen and E prod and E cons are, respectively, the expected number of ...", "dateLastCrawled": "2022-01-29T20:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "regression - What is the difference between <b>deterministic</b> and ...", "url": "https://stats.stackexchange.com/questions/273161/what-is-the-difference-between-deterministic-and-stochastic-model", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/273161/what-is-the-difference-between...", "snippet": "A simpler example of a stochastic model is flipping a fair <b>coin</b> (heads or tails), which <b>can</b> be modeled stochastically as an <b>i.i.d</b>. uniformly distributed binary random variable, or a Bernoulli process. You <b>can</b> also consider the <b>coin</b> <b>flip</b> as a physical system and come up with a <b>deterministic</b> model (in an idealized setting) if you take into account the shape of the <b>coin</b>, angle and force of impact, distance to the surface, etc. If the latter (physical) model of the <b>coin</b> <b>flip</b> has no random ...", "dateLastCrawled": "2022-01-19T06:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Maximum Likelihood</b> vs. Bayesian Estimation | by Lulu Ricketts | Towards ...", "url": "https://towardsdatascience.com/maximum-likelihood-vs-bayesian-estimation-dd2eb4dfda8a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>maximum-likelihood</b>-vs-bayesian-estimation-dd2eb4dfda8a", "snippet": "Thanks to the wonderful <b>i.i.d</b>. assumption, ... data, is notorious for becoming easily biased when the data is minimal. Consider an experiment where you <b>flip</b> a fair <b>coin</b> 3 times, and each <b>flip</b> comes up heads. While you know a fair <b>coin</b> will come up heads 50% of the time, the <b>maximum likelihood</b> estimate tells you that P(heads) = 1, and P(tails) = 0. In situations where observed data is sparse, Bayesian estimation\u2019s incorporation of prior knowledge, for instance knowing a fair <b>coin</b> is 50/50 ...", "dateLastCrawled": "2022-02-02T05:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "probability - Expectation of 500 <b>coin</b> flips after 500 realizations ...", "url": "https://stats.stackexchange.com/questions/440004/expectation-of-500-coin-flips-after-500-realizations", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/440004/expectation-of-500-<b>coin</b>-<b>flips</b>-after...", "snippet": "So, here is my question/confusion: I understand that each <b>coin</b> <b>flip</b> is independent and that any single individual <b>coin</b> <b>flip</b> has a probability of $\\frac{1}{2}$ coming up heads. However, based on the law of large numbers we know that the (if we value tails as 0 and heads as 1) mean of the tosses will approach $0.5$ as the number of tosses approaches $\\infty$ .", "dateLastCrawled": "2022-01-27T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Reading 10b: <b>Maximum Likelihood Estimates</b>", "url": "https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading10b.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/courses/mathematics/18-05-introduction-to-probability-and...", "snippet": "Example 1. A <b>coin</b> is ipped 100 times. Given that there were 55 heads, nd the maximum likelihood estimate for the probability pof heads on a single toss. Before actually solving the problem, let\u2019s establish some notation and terms. We <b>can</b> think of counting the number of heads in 100 tosses as an experiment. For a given value of p, the probability of getting 55 heads in this experiment is the binomial probability P(55 heads) = 100 p55(1 p 55)45: The probability of getting 55 heads depends on ...", "dateLastCrawled": "2022-02-02T10:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Chapter 8 Analytical Statistical Assessment | Data Analysis and ...", "url": "https://gagneurlab.github.io/dataviz/analytical-stat.html", "isFamilyFriendly": true, "displayUrl": "https://gagneurlab.github.io/dataviz/analytical-stat.html", "snippet": "TODO This book introduces concepts and skills that <b>can</b> help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown.", "dateLastCrawled": "2022-01-29T16:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Chapter 9 Simulation by Markov Chain Monte</b> Carlo | Probability and ...", "url": "https://bayesball.github.io/BOOK/simulation-by-markov-chain-monte-carlo.html", "isFamilyFriendly": true, "displayUrl": "https://bayesball.github.io/BOOK/<b>simulation-by-markov-chain-monte</b>-carlo.html", "snippet": "In Figure 9.5 a histogram of the simulated values from the random walk is <b>compared</b> with the actual probability distribution. Note that the collection of simulated draws appears to be a close match to the true probabilities. Figure 9.5: Histogram of simulated draws from the random walk <b>compared</b> with the actual probabilities of the distribution. 9.3.2 The general algorithm. A popular way of simulating from a general continuous posterior distribution is by using a generalization of the discrete ...", "dateLastCrawled": "2022-02-02T20:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "NMR (nuclear Magnetic Resonance) - SlideShare", "url": "https://www.slideshare.net/RawatDAGreatt/nmr-40157983", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/RawatDAGreatt/nmr-40157983", "snippet": "139 Spin-Spin Interactions give rise to relaxation of the magnetization Scalar or J \u2013 coupling (through bond) Most bonds are characterized by antiparallel orientation of electron spins (bonding orbital) The nuclear spins are oriented antiparallel to \u201c their \u201c bond electron A B The nuclear spins mA and mB are coupled, independent of the direction of the external field; Interaction energy: DE = a mA . mB Energy to <b>flip</b> eg spin B A B NB: In polyatomic molecules the J-coupling <b>can</b> also be ...", "dateLastCrawled": "2022-02-02T23:23:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Learning</b>? <b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "<b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b> Chapter 18.1, 18.2, 18.8.1 and \u201cIntroduction to Statistical <b>Machine</b> <b>Learning</b>\u201d 1 What is <b>Learning</b>? \u2022\u201c<b>Learning</b> is making useful changes in our minds\u201d \u2013Marvin Minsky \u2022\u201c<b>Learning</b> is constructing or modifying representations of what is being experienced\u201c \u2013RyszardMichalski \u2022\u201c<b>Learning</b> denotes changes in a system that ... enable a system to do the same task more efficiently the next time\u201d \u2013Herbert Simon 3 Why do Mach", "dateLastCrawled": "2022-02-03T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~bgibson/cs540/handouts/learning_intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~bgibson/cs540/handouts/<b>learning</b>_intro.pdf", "snippet": "<b>learning</b> process \u2022x i = (x i1, . . . , x iD) \u2022Assume these instances are sampled independently from an unknown (population) distribution, P(x) \u2022We denote this by x i \u223c P(x), where <b>i.i.d</b>. stands for independent and identically distributed <b>i.i.d</b>. Training Sample \u2022A training sample is the \u201cexperience\u201d given to a <b>learning</b> algorithm", "dateLastCrawled": "2021-08-25T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> for Drug <b>Discovery</b> in a Nutshell \u2014 Part I | by Stefan ...", "url": "https://medium.com/atomwise/machine-learning-for-drug-discovery-in-a-nutshell-part-i-24ae3f65c135", "isFamilyFriendly": true, "displayUrl": "https://medium.com/atomwise/<b>machine</b>-<b>learning</b>-for-drug-<b>discovery</b>-in-a-nutshell-part-i...", "snippet": "Classical <b>machine</b> <b>learning</b> literature spends little attention to this aspect. Most often, the underlying assumption is that training and test examples are drawn <b>i.i.d</b>. from the same distribution ...", "dateLastCrawled": "2022-01-26T14:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "11._Intro_to_<b>Machine</b>_<b>Learning</b>.pdf - CMPSC 442 Artificial Intelligence ...", "url": "https://www.coursehero.com/file/121916721/11-Intro-to-Machine-Learningpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/121916721/11-Intro-to-<b>Machine</b>-<b>Learning</b>pdf", "snippet": "Outline Data-Driven Problem Solving Types of <b>Machine</b> <b>Learning</b> <b>I.I.D</b> Assumption and Generalization The Fundamental Tradeoff between Bias and Variance Bias and Variance Overfitting and Underfitting Regularization Hyperparameters, Three-fold split, Cross-Validation Example of Polynomial Regression 2. Minimum Spanning Tree A classical problem in algorithm design: Minimum Spanning Tree Input: A graph with cost for edges Output: A spanning tree with minimum cost Prim&#39;s algorithm, Kruskal&#39;s ...", "dateLastCrawled": "2022-01-15T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Lecture 16: Reinforcement <b>Learning</b>, Part 1 | Lecture Videos | <b>Machine</b> ...", "url": "https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s897-machine-learning-for-healthcare-spring-2019/lecture-videos/lecture-16-reinforcement-learning-part-1/", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/courses/electrical-engineering-and-computer-science/6-s897-<b>machine</b>...", "snippet": "So that S0, 1, et cetera, up to St are all <b>i.i.d</b>. draws of the same distribution. Then we have, essentially, a model for t different patients with a single time step or single action, instead of them being dependent in some way. So we can see that by going backwards through my slides, this is essentially what we had last week.", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Shortcut <b>learning</b> in deep neural networks | Nature <b>Machine</b> Intelligence", "url": "https://www.nature.com/articles/s42256-020-00257-z", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42256-020-00257-z", "snippet": "In <b>analogy</b> to <b>machine</b> <b>learning</b>, we have a striking discrepancy between intended and actual <b>learning</b> outcome. Shortcut <b>learning</b> in education (surface <b>learning</b>) Alice loves history\u2014but at this ...", "dateLastCrawled": "2022-02-03T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Time Series Forecasting as Supervised Learning</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/time-series-forecasting-supervised-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/time-series-forecasting-su", "snippet": "Time series forecasting can be framed as a supervised <b>learning</b> problem. This re-framing of your time series data allows you access to the suite of standard linear and nonlinear <b>machine</b> <b>learning</b> algorithms on your problem. In this post, you will discover how you can re-frame your time series problem as a supervised <b>learning</b> problem for <b>machine</b> <b>learning</b>. After reading this post, you", "dateLastCrawled": "2022-02-02T19:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Overcoming Forgetting in Federated <b>Learning</b> on Non-<b>IID</b> Data - <b>NASA/ADS</b>", "url": "https://ui.adsabs.harvard.edu/abs/2019arXiv191007796S/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2019arXiv191007796S/abstract", "snippet": "We tackle the problem of Federated <b>Learning</b> in the non <b>i.i.d</b>. case, in which local models drift apart, inhibiting <b>learning</b>. Building on an <b>analogy</b> with Lifelong <b>Learning</b>, we adapt a solution for catastrophic forgetting to Federated <b>Learning</b>. We add a penalty term to the loss function, compelling all local models to converge to a shared optimum. We show that this can be done efficiently for communication (adding no further privacy risks), scaling with the number of nodes in the distributed ...", "dateLastCrawled": "2022-01-03T20:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "4.4. Model Selection, <b>Underfitting</b>, and Overfitting \u2014 Dive into Deep ...", "url": "https://d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html", "snippet": "As <b>machine</b> <b>learning</b> scientists, our goal is to discover patterns.But how can we be sure that we have truly discovered a general pattern and not simply memorized our data? For example, imagine that we wanted to hunt for patterns among genetic markers linking patients to their dementia status, where the labels are drawn from the set \\(\\{\\text{dementia}, \\text{mild cognitive impairment}, \\text{healthy}\\}\\).Because each person\u2019s genes identify them uniquely (ignoring identical siblings), it is ...", "dateLastCrawled": "2022-01-30T17:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[1910.07796] Overcoming Forgetting in <b>Federated Learning</b> on Non-<b>IID</b> Data", "url": "https://arxiv.org/abs/1910.07796", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1910.07796", "snippet": "We tackle the problem of <b>Federated Learning</b> in the non <b>i.i.d</b>. case, in which local models drift apart, inhibiting <b>learning</b>. Building on an <b>analogy</b> with Lifelong <b>Learning</b>, we adapt a solution for catastrophic forgetting to <b>Federated Learning</b>. We add a penalty term to the loss function, compelling all local models to converge to a shared optimum. We show that this can be done efficiently for communication (adding no further privacy risks), scaling with the number of nodes in the distributed ...", "dateLastCrawled": "2022-01-28T12:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Pearson\u2019s Correlation, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black-swans-in-your-market-neutral-portfolios-part-1-e17fc18a42a7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum ...", "dateLastCrawled": "2021-05-27T10:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Pearson\u2019s <b>Correlation</b>, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part-i-7521683a7317", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum-entropy problem , which aims at finding among all probability distributions that are consistent with observed empirical evidence, the one the is the most ignorant about everything else.", "dateLastCrawled": "2022-02-02T09:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(i.i.d.)  is like +(coin flip)", "+(i.i.d.) is similar to +(coin flip)", "+(i.i.d.) can be thought of as +(coin flip)", "+(i.i.d.) can be compared to +(coin flip)", "machine learning +(i.i.d. AND analogy)", "machine learning +(\"i.i.d. is like\")", "machine learning +(\"i.i.d. is similar\")", "machine learning +(\"just as i.i.d.\")", "machine learning +(\"i.i.d. can be thought of as\")", "machine learning +(\"i.i.d. can be compared to\")"]}