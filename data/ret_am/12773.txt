{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Guide to Different Evaluation Metrics for Time Series Forecasting Models", "url": "https://analyticsindiamag.com/a-guide-to-different-evaluation-metrics-for-time-series-forecasting-models/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/a-guide-to-different-evaluation-<b>metrics</b>-for-time-series...", "snippet": "MSE also takes into account variance (the difference <b>between</b> anticipated values) and <b>bias</b> (the <b>distance</b> of <b>predicted</b> <b>value</b> from its true <b>value</b>). Where y\u2019 denotes <b>the predicted</b> <b>value</b> and y denotes the <b>actual</b> <b>value</b>. The number n refers to the total number of values in the test set. MSE is almost always positive, and lower values are preferable. This measure penalizes large errors or outliers more than minor errors due to the square term (as seen in the formula above). The closer MSE is to ...", "dateLastCrawled": "2022-02-03T04:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Evaluation metrics &amp; Model Selection in <b>Linear Regression</b> | by NVS ...", "url": "https://towardsdatascience.com/evaluation-metrics-model-selection-in-linear-regression-73c7573208be", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/evaluation-<b>metrics</b>-model-selection-in-<b>linear-regression</b>...", "snippet": "Residual = <b>actual</b> <b>value</b> \u2014 <b>predicted</b> <b>value</b>. e = y \u2014 \u0177. It is important to n ote that, before assessing or evaluating our model with evaluation metrics <b>like</b> R-squared, we must make use of residual plots. Residual plots expose a biased model than any other evaluation <b>metric</b>. If your residual plots look normal, go ahead, and evaluate your ...", "dateLastCrawled": "2022-02-03T12:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "First, in both datasets the <b>bias</b> mitigation approach is successful in increasing fairness according to the specific target <b>metric</b>;i.e.,<b>value</b>-based <b>bias</b> mitigation reduces <b>value</b> unfairness, parity-based adjustment reduces parity in the empirical MovieLens dataset. Second, the effects of the <b>bias</b> mitigation on other metrics is complex, and thus representative of the complexity of using and comparing different definitions of fairness. In general, while the target fairness <b>metric</b> can be improved ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bias</b> and Discrimination in AI: A Cross-Disciplinary Perspective - IEEE ...", "url": "https://technologyandsociety.org/bias-and-discrimination-in-ai-a-cross-disciplinary-perspective/", "isFamilyFriendly": true, "displayUrl": "https://technologyandsociety.org/<b>bias</b>-and-discrimination-in-ai-a-cross-disciplinary...", "snippet": "Similarity measures, on the other hand, focus on defining a similarity <b>value</b> <b>between</b> individuals. Causal discrimination is an example of such measures, stating that a classifier is not biased if it produces the same classification for any two subjects with the same nonprotected attributes. A more complex <b>bias</b> <b>metric</b> based on a similarity measure <b>between</b> individuals is fairness through awareness [17], which states that, for fairness to hold, the <b>distance</b> <b>between</b> the distributions of outputs ...", "dateLastCrawled": "2022-01-30T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Mean <b>Square Error &amp; R2 Score Clearly Explained</b> \u2013 BMC Software | Blogs", "url": "https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/mean-squared-error-r2-and-variance-in-regression-analysis", "snippet": "(Learn more in <b>Bias</b> and Variance in Machine Learning.) To provide examples, let\u2019s use ... is a measure of how far observed values differ from the average of <b>predicted</b> values, i.e., their difference from <b>the predicted</b> <b>value</b> mean. The goal is to have a <b>value</b> that is low. What low means is quantified by the r2 score (explained below). In the code below, this is np.var(err), where err is an array of the differences <b>between</b> observed and <b>predicted</b> values and np.var() is the numpy array variance ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "3.3. Metrics and scoring: quantifying the quality of predictions ...", "url": "https://scikit-learn.org/stable/modules/model_evaluation.html", "isFamilyFriendly": true, "displayUrl": "https://scikit-learn.org/stable/modules/model_evaluation.html", "snippet": "The hamming_loss computes the average Hamming loss or Hamming <b>distance</b> <b>between</b> two sets of samples. If \\(\\hat{y}_j\\) is <b>the predicted</b> <b>value</b> for the \\(j\\)-th label of a given sample, \\(y_j\\) is the corresponding true <b>value</b>, and \\(n_\\text{labels}\\) is the number of classes or labels, then the Hamming loss \\(L_{Hamming}\\) <b>between</b> two samples is ...", "dateLastCrawled": "2022-02-03T06:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Overview of Machine Learning Algorithms: Regression - StrataScratch", "url": "https://www.stratascratch.com/blog/overview-of-machine-learning-algorithms-regression/", "isFamilyFriendly": true, "displayUrl": "https://www.stratascratch.com/blog/overview-of-machine-learning-algorithms-regression", "snippet": "The taxi fare as <b>the predicted</b> <b>value</b> (\u0177) The <b>distance</b> <b>between</b> your house and the airport as the predictor <b>value</b> (x\u2081) You can imagine the intercept as the initial price that you need to pay as soon as you get in the taxi. If you notice, the taxi fare wouldn\u2019t start at 0 whenever you get in the taxi, but at some price, let\u2019s say $5. This $5 is the intercept (\u03b8\u2080). You can imagine the weight of the predictor as the amount of money that you need to pay as soon as the <b>distance</b> traveled ...", "dateLastCrawled": "2022-02-02T13:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Model Validation, KS Test and Lorenz</b> Curve \u2013 KDAG", "url": "https://kgpdag.wordpress.com/2016/03/14/model-validation-ks-test-and-lorenz-curve/", "isFamilyFriendly": true, "displayUrl": "https://kgpdag.wordpress.com/2016/03/14/<b>model-validation-ks-test-and-lorenz</b>-curve", "snippet": "RMSE is the most commonly used <b>metric</b> for regression tasks. It is a <b>distance</b> measure <b>between</b> <b>the predicted</b> numeric target <b>and the actual</b> numeric answer (ground truth). The smaller the <b>value</b> of the RMSE, the better is the predictive accuracy of the model. A model with perfectly correct predictions would have an RMSE of 0. Mathematically, it is ...", "dateLastCrawled": "2022-02-02T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Definition of <b>Difference Between The Actual Value And Predicted Value</b> ...", "url": "https://www.chegg.com/homework-help/definitions/difference-between-the-actual-value-and-predicted-value-31", "isFamilyFriendly": true, "displayUrl": "https://www.chegg.com/.../<b>difference-between-the-actual-value-and-predicted-value</b>-31", "snippet": "If the <b>difference between the actual value</b> and <b>the predicted</b> <b>value</b> is negative, then the data points are below the regression line. If the difference is zero, then that data points lie on the regression line. If the line of best fit is the best fit then the sum of the <b>difference between the actual value</b> and <b>the predicted</b> values is always zero. The residuals play a vital role to validate the obtained regression model. Residuals are represented graphically by means of a residual plot. If the ...", "dateLastCrawled": "2022-02-03T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Regression</b> - Ai Quiz Questions", "url": "https://www.aionlinecourse.com/ai-quiz-questions/machine-learning/regression", "isFamilyFriendly": true, "displayUrl": "https://www.aionlinecourse.com/ai-quiz-questions/machine-learning/<b>regression</b>", "snippet": "B. <b>predicted</b> y\u2010coordinate <b>value</b> - <b>actual</b> y coordinate <b>value</b>. C. <b>actual</b> y\u2010coordinate <b>value</b> / <b>predicted</b> y\u2010coordinate <b>value</b>. D. None. view answer: A. <b>actual</b> y\u2010coordinate <b>value</b> - <b>predicted</b> y\u2010coordinate <b>value</b>. 4. How to see the <b>value</b> of residuals geometrically. A. The perpendicular <b>distance</b> <b>between</b> a data point and the <b>regression</b> line. B. The euclidian <b>distance</b> <b>between</b> a data point and the <b>regression</b> line. C. The horizontal <b>distance</b> <b>between</b> a data point and the <b>regression</b> line. D. The ...", "dateLastCrawled": "2022-01-31T03:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Guide to Different Evaluation Metrics for Time Series Forecasting Models", "url": "https://analyticsindiamag.com/a-guide-to-different-evaluation-metrics-for-time-series-forecasting-models/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/a-guide-to-different-evaluation-<b>metrics</b>-for-time-series...", "snippet": "MSE also takes into account variance (the difference <b>between</b> anticipated values) and <b>bias</b> (the <b>distance</b> of <b>predicted</b> <b>value</b> from its true <b>value</b>). Where y\u2019 denotes <b>the predicted</b> <b>value</b> and y denotes the <b>actual</b> <b>value</b>. The number n refers to the total number of values in the test set. MSE is almost always positive, and lower values are preferable. This measure penalizes large errors or outliers more than minor errors due to the square term (as seen in the formula above). The closer MSE is to ...", "dateLastCrawled": "2022-02-03T04:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "First, in both datasets the <b>bias</b> mitigation approach is successful in increasing fairness according to the specific target <b>metric</b>;i.e.,<b>value</b>-based <b>bias</b> mitigation reduces <b>value</b> unfairness, parity-based adjustment reduces parity in the empirical MovieLens dataset. Second, the effects of the <b>bias</b> mitigation on other metrics is complex, and thus representative of the complexity of using and comparing different definitions of fairness. In general, while the target fairness <b>metric</b> can be improved ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Evaluation Metrics for Machine Learning Models: Part 1", "url": "https://blog.paperspace.com/ml-evaluation-metrics-part-1/", "isFamilyFriendly": true, "displayUrl": "https://blog.paperspace.com/ml-evaluation-<b>metrics</b>-part-1", "snippet": "It\u2019s better to compute both the metrics because RMSE calculates the <b>distance</b> <b>between</b> <b>predicted</b> and observed values, whereas, R-squared tells how well the predictor variables (the data attributes) can explain the variation in the target variable. Limitations. R-squared doesn\u2019t always present an accurate <b>value</b> to conclude if the model is good ...", "dateLastCrawled": "2022-02-01T13:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Common Evaluation Metrics for <b>Regression</b> Analysis | by Scott Duda | Medium", "url": "https://scottmduda.medium.com/common-evaluation-metrics-for-regression-analysis-4b62726f1aad", "isFamilyFriendly": true, "displayUrl": "https://scottmduda.medium.com/common-evaluation-<b>metrics</b>-for-<b>regression</b>-analysis-4b...", "snippet": "The resulting <b>value</b> represents the mean absolute error, or the average vertical <b>distance</b> <b>between</b> each pair of <b>predicted</b> and <b>actual</b> values when graphed. Interpreting MAE is straightforward since it is represented in the same units as our original data. A perfect model produces an MAE of zero, and the closer the observed MAE is to zero the better the model fits the data. Calculation of MAE treats all penalties equally, regardless of whether <b>the predicted</b> <b>value</b> is smaller or larger than the ...", "dateLastCrawled": "2022-01-30T13:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Mean <b>Square Error &amp; R2 Score Clearly Explained</b> \u2013 BMC Software | Blogs", "url": "https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/mean-squared-error-r2-and-variance-in-regression-analysis", "snippet": "The goal is to have a <b>value</b> that is low. What low means is quantified by the r2 score (explained below). In the code below, this is np.var(err), where err is an array of the differences <b>between</b> observed and <b>predicted</b> values and np.var() is the numpy array variance function. What is r2 score? The r2 score varies <b>between</b> 0 and 100%", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "3.3. Metrics and scoring: quantifying the quality of predictions ...", "url": "https://scikit-learn.org/stable/modules/model_evaluation.html", "isFamilyFriendly": true, "displayUrl": "https://scikit-learn.org/stable/modules/model_evaluation.html", "snippet": "In multiclass classification, the Hamming loss corresponds to the Hamming <b>distance</b> <b>between</b> y_true and y_pred which <b>is similar</b> to the Zero one loss function. However, while zero-one loss penalizes prediction sets that do not strictly match true sets, the Hamming loss penalizes individual labels. Thus the Hamming loss, upper bounded by the zero-one loss, is always <b>between</b> zero and one, inclusive; and predicting a proper subset or superset of the true labels will give a Hamming loss <b>between</b> ...", "dateLastCrawled": "2022-02-03T06:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Ways to Evaluate Regression Models | by ... - Towards Data Science", "url": "https://towardsdatascience.com/ways-to-evaluate-regression-models-77a3ff45ba70", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/ways-to-evaluate-regression-models-77a3ff45ba70", "snippet": "We can understand the <b>bias</b> in prediction <b>between</b> two models using the arithmetic mean of <b>the predicted</b> values. For example, The mean of <b>predicted</b> values of 0.5 API is calculated by taking the sum of <b>the predicted</b> values for 0.5 API divided by the total number of samples having 0.5 API. np.mean(predictedArray) In Fig.1, We can understand how PLS and SVR have performed wrt mean. SVR <b>predicted</b> 0.0 API much better than PLS, whereas, PLS <b>predicted</b> 3.0 API better than SVR. We can choose the models ...", "dateLastCrawled": "2022-02-02T07:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Definition of <b>Difference Between The Actual Value And Predicted Value</b> ...", "url": "https://www.chegg.com/homework-help/definitions/difference-between-the-actual-value-and-predicted-value-31", "isFamilyFriendly": true, "displayUrl": "https://www.chegg.com/.../<b>difference-between-the-actual-value-and-predicted-value</b>-31", "snippet": "If the <b>difference between the actual value</b> and <b>the predicted</b> <b>value</b> is negative, then the data points are below the regression line. If the difference is zero, then that data points lie on the regression line. If the line of best fit is the best fit then the sum of the <b>difference between the actual value</b> and <b>the predicted</b> values is always zero. The residuals play a vital role to validate the obtained regression model. Residuals are represented graphically by means of a residual plot. If the ...", "dateLastCrawled": "2022-02-03T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "K-<b>Means Clustering Algorithm from Scratch</b> - Machine Learning Plus", "url": "https://www.machinelearningplus.com/predictive-modeling/k-means-clustering/", "isFamilyFriendly": true, "displayUrl": "https://www.machinelearningplus.com/predictive-modeling/k-means-clustering", "snippet": "Use a good <b>distance</b> <b>metric</b> to compute the <b>distance</b> <b>between</b> a point and every other point. The points that have less <b>distance</b> are more <b>similar</b>. Euclidean <b>distance</b> is the most common <b>metric</b>. The formula for Euclidean <b>distance</b> is given by: Clustering algorithms are generally used in network traffic classification, customer, and market segmentation ...", "dateLastCrawled": "2022-02-02T18:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "4. Regression and Prediction - <b>Practical Statistics for Data Scientists</b> ...", "url": "https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/ch04.html", "snippet": "The intercept of the regression line\u2014that is, <b>the predicted</b> <b>value</b> when X = 0. Synonyms . b 0, \u03b2 0. Regression coefficient. The slope of the regression line. Synonyms. slope, b 1, \u03b2 1, parameter estimates, weights. Fitted values. The estimates Y ^ i obtained from the regression line. Synonyms. <b>predicted</b> values. Residuals. The difference <b>between</b> the observed values and the fitted values. Synonyms. errors. Least squares. The method of fitting a regression by minimizing the sum of squared ...", "dateLastCrawled": "2022-02-03T02:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "Considering <b>bias</b> mitigation of <b>value</b> unfairness, we see that <b>value</b> unfairness <b>can</b> be (slightly) lowered when using the <b>value</b> adjustment <b>bias</b> mitigation strategy. The improvements for the other two version of <b>bias</b> mitigation are more noticeable. For parity adjustment, the results indicate that almost perfect parity (and respectively, almost perfect score for disparate impact) <b>can</b> be achieved. However, this slightly increases the <b>value</b> and overestimation unfairness measures.", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What does RMSE really mean?. Root <b>Mean Square</b> Error (RMSE) is a\u2026 | by ...", "url": "https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e", "snippet": "This tells us heuristically that RMSE <b>can</b> <b>be thought</b> of as some kind of (normalized) <b>distance</b> <b>between</b> the vector of <b>predicted</b> values and the vector of observed values. B u t why are we dividing by n under the square root here? If we keep n (the number of observations) fixed, all it does is rescale the Euclidean <b>distance</b> by a factor of \u221a(1/n). It\u2019s a bit tricky to see why this is the right thing to do, so let\u2019s delve in a bit deeper. Imagine that our observed values are determined by ...", "dateLastCrawled": "2022-02-02T23:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Mean <b>Square Error &amp; R2 Score Clearly Explained</b> \u2013 BMC Software | Blogs", "url": "https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/mean-squared-error-r2-and-variance-in-regression-analysis", "snippet": "The goal is to have a <b>value</b> that is low. What low means is quantified by the r2 score (explained below). In the code below, this is np.var(err), where err is an array of the differences <b>between</b> observed and <b>predicted</b> values and np.var() is the numpy array variance function. What is r2 score? The r2 score varies <b>between</b> 0 and 100%", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Making Predictions with Regression Analysis</b> - Statistics By Jim", "url": "https://statisticsbyjim.com/regression/predictions-regression/", "isFamilyFriendly": true, "displayUrl": "https://statisticsbyjim.com/regression/predictions-regression", "snippet": "While this process involves more work than the psychic approach, it provides valuable benefits. With regression, we <b>can</b> evaluate the <b>bias</b> and precision of our predictions: <b>Bias</b> in a statistical model indicates that the predictions are systematically too high or too low. Precision represents how close the predictions are to the observed values.", "dateLastCrawled": "2022-02-03T00:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "It is also called the Positive Predictive <b>Value</b> (PPV). Precision <b>can</b> <b>be thought</b> of as a measure of a classifiers exactness. A low precision <b>can</b> also indicate a large number of False Positives. Recall: A measure of a classifiers completeness. Recall is the number of True Positives divided by the number of True Positives and the number of False Negatives. Put another way it is the number of positive predictions divided by the number of positive class values in the test data. It is also called ...", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpreting the Root Mean Squared</b> Error of a Linear Regression Model ...", "url": "https://tiaplagata.medium.com/interpreting-the-root-mean-squared-error-of-a-linear-regression-model-5166e6b10db8", "isFamilyFriendly": true, "displayUrl": "https://tiaplagata.medium.com/<b>interpreting-the-root-mean-squared</b>-error-of-a-linear...", "snippet": "The first time I ever built a Linear Regression model, I <b>thought</b> two things: Wow! I built something that <b>can</b> actually predict housing prices! Ok, but how good are these predictions? I had learned to check all of the assumptions of a Linear Regression model (residuals s hould have a normal distribution, features are linearly correlated with the target, there\u2019s no multi-collinearity, etc.). I learned to scale and sometimes even log-scale my features and target. I even learned about mean ...", "dateLastCrawled": "2022-01-29T23:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Cutting Your Losses: Loss Functions &amp; the Sum of <b>Squared</b> Errors Loss ...", "url": "https://dustinstansbury.github.io/theclevermachine/cutting-your-losses", "isFamilyFriendly": true, "displayUrl": "https://dustinstansbury.github.io/theclevermachine/cutting-your-losses", "snippet": "The difference <b>between</b> <b>the predicted</b> and <b>actual</b> <b>value</b> is often referred to as the model \u201cerror\u201d or \u201cresidual\u201d \\(e_i\\) for the datapoint. The semantics here being that small errors correspond to small distances. Each of the \\(M\\) distances are then aggregated across the entire dataset through addition, giving a single number indicating how well (or badly) the current model <b>function</b> captures the structure of the entire dataset. The \u201cbest\u201d model will minimize the SSE and is called the", "dateLastCrawled": "2022-01-31T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>machine learning MCQ</b> - Warning: TT: undefined function: 32 ... - StuDocu", "url": "https://www.studocu.com/in/document/savitribai-phule-pune-university/machine-learning/machine-learning-mcq/9702021", "isFamilyFriendly": true, "displayUrl": "https://www.studocu.com/in/document/savitribai-phule-pune-university/machine-learning/...", "snippet": "b) As the <b>value</b> of one attribute increases the <b>value</b> of the second attribute also increases. c) As the <b>value</b> of one attribute decreases the <b>value</b> of the second attribute increases. d) The attributes show a curvilinear relationship. Ans : Solution C 35. The average squared difference <b>between</b> classifier <b>predicted</b> output and <b>actual</b> output.", "dateLastCrawled": "2022-02-03T10:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "4. Regression and Prediction - <b>Practical Statistics for Data Scientists</b> ...", "url": "https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/ch04.html", "snippet": "The intercept of the regression line\u2014that is, <b>the predicted</b> <b>value</b> when X = 0. Synonyms . b 0, \u03b2 0. Regression coefficient. The slope of the regression line. Synonyms. slope, b 1, \u03b2 1, parameter estimates, weights. Fitted values. The estimates Y ^ i obtained from the regression line. Synonyms. <b>predicted</b> values. Residuals. The difference <b>between</b> the observed values and the fitted values. Synonyms. errors. Least squares. The method of fitting a regression by minimizing the sum of squared ...", "dateLastCrawled": "2022-02-03T02:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "200 Practice <b>Questions</b> For Azure <b>AI-900</b> Fundamentals Exam | by Bhargav ...", "url": "https://medium.com/bb-tutorials-and-thoughts/200-practice-questions-for-azure-ai-900-fundamentals-exam-e981d28ce91d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/bb-tutorials-and-<b>thoughts</b>/200-practice-<b>questions</b>-for-azure-<b>ai-900</b>...", "snippet": "A relative <b>metric</b> <b>between</b> 0 and 1 based on the absolute differences <b>between</b> <b>predicted</b> and true values. The closer to 0 this <b>metric</b> is, the better the model is performing. Like RSE, this <b>metric</b> <b>can</b> ...", "dateLastCrawled": "2022-01-30T17:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b> and Discrimination in AI: A Cross-Disciplinary Perspective - IEEE ...", "url": "https://technologyandsociety.org/bias-and-discrimination-in-ai-a-cross-disciplinary-perspective/", "isFamilyFriendly": true, "displayUrl": "https://technologyandsociety.org/<b>bias</b>-and-discrimination-in-ai-a-cross-disciplinary...", "snippet": "Similarity measures, on the other hand, focus on defining a similarity <b>value</b> <b>between</b> individuals. Causal discrimination is an example of such measures, stating that a classifier is not biased if it produces the same classification for any two subjects with the same nonprotected attributes. A more complex <b>bias</b> <b>metric</b> based on a similarity measure <b>between</b> individuals is fairness through awareness [17], which states that, for fairness to hold, the <b>distance</b> <b>between</b> the distributions of outputs ...", "dateLastCrawled": "2022-01-30T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "First, in both datasets the <b>bias</b> mitigation approach is successful in increasing fairness according to the specific target <b>metric</b>;i.e.,<b>value</b>-based <b>bias</b> mitigation reduces <b>value</b> unfairness, parity-based adjustment reduces parity in the empirical MovieLens dataset. Second, the effects of the <b>bias</b> mitigation on other metrics is complex, and thus representative of the complexity of using and comparing different definitions of fairness. In general, while the target fairness <b>metric</b> <b>can</b> be improved ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Assessing the performance of prediction models: a framework for some ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3575184/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3575184", "snippet": "Overall performance measures. The <b>distance</b> <b>between</b> <b>the predicted</b> outcome and <b>actual</b> outcome is central to quantify overall model performance from a statistical modeler\u2019s perspective 32 p, and for survival outcomes it is <b>the predicted</b> event probability at a given time (or as a function of time). These distances <b>between</b> observed and <b>predicted</b> outcomes are related to the concept of \u2018goodness-of-fit\u2019 of a model, with better models having smaller distances <b>between</b> <b>predicted</b> and observed ...", "dateLastCrawled": "2022-02-03T05:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Guide to Different Evaluation Metrics for Time Series Forecasting Models", "url": "https://analyticsindiamag.com/a-guide-to-different-evaluation-metrics-for-time-series-forecasting-models/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/a-guide-to-different-evaluation-<b>metrics</b>-for-time-series...", "snippet": "The fact that the future is wholly unknown and <b>can</b> only be <b>predicted</b> from what has already occurred is a significant distinction in forecasting. The ability of a time series forecasting model to predict the future is defined by its performance. This is frequently at the expense of being able to explain why a particular prediction was made, confidence intervals, and even a greater grasp of the problem\u2019s underlying causes. Time series prediction performance measurements provide a summary of ...", "dateLastCrawled": "2022-02-03T04:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "<b>Bias</b> is how far removed a model&#39;s predictions are from correctness, while variance is the degree to which these predictions vary <b>between</b> model iterations. <b>Bias</b> is generally the <b>distance</b> <b>between</b> the model that you build on the training data (the best model that your model space <b>can</b> provide) and the \u201creal model\u201d (which generates data).", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Common Evaluation Metrics for <b>Regression</b> Analysis | by Scott Duda | Medium", "url": "https://scottmduda.medium.com/common-evaluation-metrics-for-regression-analysis-4b62726f1aad", "isFamilyFriendly": true, "displayUrl": "https://scottmduda.medium.com/common-evaluation-<b>metrics</b>-for-<b>regression</b>-analysis-4b...", "snippet": "Choosing an evaluation <b>metric</b> to assess model performance is an important element of the data analysis pipeline. By properly selecting an evaluation <b>metric</b>, or equation used to objectively assess a model\u2019s performance, we <b>can</b> get a good idea how closely the results produced by our model match real-world observations.We <b>can</b> use the evaluation <b>metric</b> to determine if improvements should be made to model parameters or if another modeling method should be considered.", "dateLastCrawled": "2022-01-30T13:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Ways to Evaluate Regression Models | by ... - Towards Data Science", "url": "https://towardsdatascience.com/ways-to-evaluate-regression-models-77a3ff45ba70", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/ways-to-evaluate-regression-models-77a3ff45ba70", "snippet": "It <b>can</b> <b>be compared</b> <b>between</b> models whose errors are measured in the different units. Mathematically, ... MSE of 1 point is a difference of 1 point of <b>actual</b> <b>between</b> <b>predicted</b> and <b>actual</b>). In RAE and Relative RSE, you divide those differences by the variation of <b>actual</b>, so they have a scale from 0 to 1, and if you multiply this <b>value</b> by 100, you get similarity in 0\u2013100 scale (i.e. percentage). The values of \u2211(MeanofActual \u2014 <b>actual</b>)\u00b2 or \u2211|MeanofActual \u2014 <b>actual</b>| tell you how much ...", "dateLastCrawled": "2022-02-02T07:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Confusion Matrix</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/engineering/confusion-matrix", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/engineering/<b>confusion-matrix</b>", "snippet": "<b>Predicted</b> <b>value</b>; <b>Actual</b> <b>value</b>: Malignant: Benign: Malignant: TP: FN: Benign : FP: TN: The <b>confusion matrix</b> consists of four basic characteristics (numbers) that are used to define the measurement metrics of the classifier. These four numbers are: 1. TP (True Positive): TP represents the number of patients who have been properly classified to have malignant nodes, meaning they have the disease. 2. TN (True Negative): TN represents the number of correctly classified patients who are healthy. 3 ...", "dateLastCrawled": "2022-02-02T21:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Definition of <b>Difference Between The Actual Value And Predicted Value</b> ...", "url": "https://www.chegg.com/homework-help/definitions/difference-between-the-actual-value-and-predicted-value-31", "isFamilyFriendly": true, "displayUrl": "https://www.chegg.com/.../<b>difference-between-the-actual-value-and-predicted-value</b>-31", "snippet": "If the <b>difference between the actual value</b> and <b>the predicted</b> <b>value</b> is negative, then the data points are below the regression line. If the difference is zero, then that data points lie on the regression line. If the line of best fit is the best fit then the sum of the <b>difference between the actual value</b> and <b>the predicted</b> values is always zero. The residuals play a vital role to validate the obtained regression model. Residuals are represented graphically by means of a residual plot. If the ...", "dateLastCrawled": "2022-02-03T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning - Performance Metrics</b> - <b>Tutorialspoint</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_algorithms_performance_metrics.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/.../machine_learning_algorithms_performance_<b>metrics</b>.htm", "snippet": "As we know that accuracy is the count of predictions (<b>predicted</b> <b>value</b> = <b>actual</b> <b>value</b>) in our model whereas Log Loss is the amount of uncertainty of our prediction based on how much it varies from the <b>actual</b> label. With the help of Log Loss <b>value</b>, we <b>can</b> have more accurate view of the performance of our model. We <b>can</b> use log_loss function of sklearn.metrics to compute Log Loss.", "dateLastCrawled": "2022-02-02T08:38:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b>, Variance, and <b>Overfitting</b> Explained, Step by Step", "url": "https://machinelearningcompass.com/model_optimization/bias_and_variance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>compass.com/model_optimization/<b>bias</b>_and_variance", "snippet": "The <b>bias</b> of a specific <b>machine learning</b> model trained on a specific dataset describes how well this <b>machine learning</b> model can capture the relationship between the features and the targets. So for our example, the <b>bias</b> of any one model would tell us how well this particular model can predict the exam points received for any number of hours studied in our specific dataset. That seems like a reasonable definition. Practical Examples (<b>Bias</b>) Let\u2019s take a look at three of the above models and ...", "dateLastCrawled": "2022-01-31T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Short Discussion On <b>Bias</b> In <b>Machine</b> <b>Learning</b>", "url": "https://www.encora.com/insights/a-short-discussion-on-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.encora.com/insights/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "A typical <b>machine</b> <b>learning</b> lifecycle might start with a Scoping stage. At this point, an important decision to be made by the analysts regards the level of performance the <b>machine</b> <b>learning</b> system should have. The <b>machine</b> <b>learning</b> team, along with the stakeholders involved, should decide on a <b>metric</b> to be used as a measure of success. This ...", "dateLastCrawled": "2022-02-03T02:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Short Discussion on <b>Bias</b> in <b>Machine</b> <b>Learning</b> | by Daitan | Daitan ...", "url": "https://medium.com/daitan-tech/a-short-discussion-on-bias-in-machine-learning-5bb2066afabc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/daitan-tech/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>-5bb2066afabc", "snippet": "The problem of <b>bias</b> in <b>machine</b> <b>learning</b> is very serious. Moreover, though it seems to be a \u201cdata related\u201d problem, one might think that it can be solved by simply curating datasets so that ...", "dateLastCrawled": "2021-08-05T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Short Discussion on <b>Bias</b> in <b>Machine</b> <b>Learning</b> - Adolfo Eliaz\u00e0t ...", "url": "https://adolfoeliazat.com/2021/06/16/a-short-discussion-on-bias-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://adolfoeliazat.com/2021/06/16/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "The problem of <b>bias</b> in <b>machine</b> <b>learning</b> is very serious. Moreover, though it seems to be a \u201cdata related\u201d problem, one might think that it can be solved by simply curating datasets so that classes and ethical groups are well represented. This line of thinking is a trap and must be avoided. Overall, <b>bias</b> in technology can happen anywhere or anytime a decision must be taken by a human. In such situations, it is very common to consider aspects that make sense from a marketing or profit ...", "dateLastCrawled": "2022-01-16T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Fairness Metrics - Data Analytics - Data Science, <b>Machine</b> <b>Learning</b>, AI", "url": "https://vitalflux.com/fairness-metrics-ml-model-sensitivity-bias-detection/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>fairness-metrics-ml-model-sensitivity</b>-<b>bias</b>-detection", "snippet": "There are many different ways in which <b>machine</b> <b>learning</b> (ML) models\u2019 fairness could be determined. Some of them are statistical parity, the relative significance of features, model sensitivity etc. In this post, you would learn about how model sensitivity could be used to determine model fairness or <b>bias</b> of model towards the privileged or unprivileged group.The following are some of the topics covered in this post:", "dateLastCrawled": "2022-01-20T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A New <b>Metric for Quantifying Machine Learning Fairness in</b> Healthcare ...", "url": "https://towardsdatascience.com/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare-closedloop-ai-fc07b9c83487?source=post_internal_links---------3----------------------------", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-new-<b>metric-for-quantifying-machine-learning-fairness</b>...", "snippet": "The <b>analogy</b> would be the difference between a Pearson correlation or a residual sum of squared errors in regression. While both quantify the models performance, the former is significantly easier to understand and explain; unsurprisingly, it is the <b>metric</b> most individuals use to describe a regression model. In order to achieve this effect, many fairness metrics are presented as the quotient of a protected subgroup to a base subgroup[2]. As the goal of healthcare is to deliver interventions ...", "dateLastCrawled": "2022-01-19T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "CS 540 Lecture Notes: <b>Machine</b> <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/learning.html", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/<b>learning</b>.html", "snippet": "Inductive <b>Bias</b>. Inductive <b>learning</b> is an inherently conjectural process because any knowledge created by generalization from specific facts cannot be proven true; it can only be proven false. Hence, inductive inference is falsity preserving, not truth preserving. To generalize beyond the specific training examples, we need constraints or biases on what f is best. That is, <b>learning</b> can be viewed as searching the Hypothesis Space H of possible f functions. A <b>bias</b> allows us to choose one f over ...", "dateLastCrawled": "2022-02-03T15:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A New <b>Metric</b> for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare", "url": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/a-new-<b>metric</b>-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "A New <b>Metric</b> for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare. Joseph Gartner. March 2, 2020. Background. Several recent, high profile cases of unfair AI algorithms have highlighted the vital need to address <b>bias</b> early in the development of any AI system. For the most part, <b>bias</b> does not come into algorithms due to malicious intent by the individual creating the algorithm. <b>Bias</b> comes from a lack of diligence in ensuring that the AI system is fair for everyone. In order to combat <b>bias</b> ...", "dateLastCrawled": "2022-02-01T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Bias</b> -Variance &amp; <b>Precision</b>-Recall Trade-offs: How to aim for the sweet ...", "url": "https://towardsdatascience.com/tradeoffs-how-to-aim-for-the-sweet-spot-c20b40d5e6b6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/tradeoffs-how-to-aim-for-the-sweet-spot-c20b40d5e6b6", "snippet": "Enoug h with the \u2018Bookish\u2019 definition, let us understand it by more relatable <b>analogy</b> with the real world. \u2192 In simple English, \u201cThe inability of <b>machine</b> <b>learning</b> techniques to capture the true relationship is <b>Bias</b>\u201d. Low <b>Bias</b>: Predicted data points are close to the target. Also, the model suggests less assumptions about the form of the target function. High-<b>Bias</b>: Predicted data points are far from the target. Also, the model suggests more assumptions about the form of the target ...", "dateLastCrawled": "2022-01-30T08:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Solutions to the exercises for <b>Machine</b> <b>Learning</b>", "url": "http://www.perfmath.com/ml/ml_liu_text_solutions.pdf", "isFamilyFriendly": true, "displayUrl": "www.perfmath.com/ml/ml_liu_text_solutions.pdf", "snippet": "2 <b>Machine</b> <b>Learning</b> Fundamentals Illustrated with Regression 2.1 Try to find a publicly available <b>machine</b> <b>learning</b> dataset and apply an end-to-end procedure similar to the one we used with the fuel economy dataset to come up with your own first linear regression <b>machine</b> <b>learning</b> project. Summarize how you explored the data, pre-processed the", "dateLastCrawled": "2022-01-18T07:21:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bias metric)  is like +(distance between the predicted value and the actual value)", "+(bias metric) is similar to +(distance between the predicted value and the actual value)", "+(bias metric) can be thought of as +(distance between the predicted value and the actual value)", "+(bias metric) can be compared to +(distance between the predicted value and the actual value)", "machine learning +(bias metric AND analogy)", "machine learning +(\"bias metric is like\")", "machine learning +(\"bias metric is similar\")", "machine learning +(\"just as bias metric\")", "machine learning +(\"bias metric can be thought of as\")", "machine learning +(\"bias metric can be compared to\")"]}