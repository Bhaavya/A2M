{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Performance</b> Metrics in <b>Machine Learning</b> [Complete Guide] - neptune.ai", "url": "https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/<b>performance</b>-metrics-in-<b>machine-learning</b>-complete-guide", "snippet": "It makes use of <b>true</b> <b>positive</b> rates(<b>TPR</b>) and false <b>positive</b> rates(FPR). ... (&#39;False <b>Positive</b> <b>Rate</b>&#39;) pyplot.ylabel(&#39;<b>True</b> <b>Positive</b> <b>Rate</b>&#39;) pyplot.legend() pyplot.show() No Skill: ROC AUC=0.500 Logistic: ROC AUC=0.996. A no-skill classifier is one that can\u2019t discriminate between the classes, and would predict a random class or a constant class in <b>all</b> cases. The no-skill line changes based on the distribution of <b>the positive</b> to negative classes. It\u2019s a horizontal line with the value of the ...", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Survey on <b>deep learning</b> with class <b>imbalance</b> | Journal of Big Data ...", "url": "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0192-5", "isFamilyFriendly": true, "displayUrl": "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0192-5", "snippet": "5), or the <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>), measures the percentage of <b>the positive</b> group that was <b>correctly</b> predicted to be <b>positive</b> by the model. Recall is not affected by <b>imbalance</b> because it is only dependent on <b>the positive</b> group. Recall does not consider the <b>number</b> of negative samples that are misclassified as <b>positive</b>, which can be problematic in problems containing class imbalanced data with many negative samples. There is a trade-off between precision and recall, and the metric of greater ...", "dateLastCrawled": "2022-01-31T15:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Wikizero - Sensitivity and specificity", "url": "https://wikizero.com/m/True_positive_rate", "isFamilyFriendly": true, "displayUrl": "https://wikizero.com/m/<b>True</b>_<b>positive</b>_<b>rate</b>", "snippet": "Sensitivity and specificity mathematically describe the accuracy of a test which reports the presence or absence of a condition, in comparison to a \u2018Gold Standard\u2019 or definition.. Sensitivity (<b>True</b> <b>Positive</b> <b>Rate</b>) refers to the proportion of those who received a <b>positive</b> result on this test <b>out</b> of those who <b>actually</b> have the condition (when judged by the \u2018Gold Standard\u2019).; Specificity (<b>True</b> Negative <b>Rate</b>) refers to the proportion of those who received a negative result on this test ...", "dateLastCrawled": "2021-11-09T17:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The impact of using biased performance metrics on software defect ...", "url": "https://www.sciencedirect.com/science/article/pii/S0950584921001270", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0950584921001270", "snippet": "also referred to as sensitivity or the <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>). It is the proportion of <b>positive</b> cases <b>that are correctly</b> predicted <b>positive</b> (defect-prone) <b>out</b> <b>of all</b> <b>positive</b> cases. Specificity: or the <b>true</b> negative <b>rate</b> (TNR) is defined as the proportion of negative cases <b>that are correctly</b> considered as negative from <b>all</b> negative cases. Specificity and Recall are inversely proportional to each other. When we increase Specificity, Recall decreases and vice versa. False <b>positive</b> <b>rate</b> (FPR ...", "dateLastCrawled": "2021-10-15T20:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 4, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Sensitivity and specificity</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Sensitivity_and_specificity", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Sensitivity_and_specificity</b>", "snippet": "The <b>true</b> <b>positive</b> in this figure is 6, and false negatives of 0 (because <b>all</b> <b>positive</b> condition is <b>correctly</b> predicted as <b>positive</b>). Therefore the sensitivity is 100% (from 6 / (6 + 0) ). This situation is also illustrated in the previous figure where the dotted line is at position A (the left-hand side is predicted as negative by the model, the right-hand side is predicted as <b>positive</b> by the model).", "dateLastCrawled": "2022-02-02T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to Data Science : How to NOT Get Confused by the Confusion Matrix ...", "url": "https://jeppbautista.wordpress.com/2019/02/09/how-to-not-get-confused-by-the-confusion-matrix/", "isFamilyFriendly": true, "displayUrl": "https://jeppbautista.wordpress.com/2019/02/09/how-to-not-get-confused-by-the-confusion...", "snippet": "Measures the <b>number</b> <b>of actual</b> positives <b>that are correctly</b> <b>identified</b> as <b>positive</b>. Basically answers to the question: ... (FP) and the total <b>number</b> <b>of actual</b> negative <b>instances</b>. It answers the question: \u201cHow often does the classifier predict <b>positive</b> when it\u2019s <b>actually</b> negative?\u201d. <b>Like</b> the <b>TPR</b>, go try to compute the FPR of our previous example. 0.857142857 is the score of our classifier. Looks good. <b>True</b> Negative <b>Rate</b> / Specificity . <b>True</b> Negative <b>Rate</b> is the measure <b>of actual</b> ...", "dateLastCrawled": "2022-01-07T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Top 70+ <b>Data Science Interview Questions and Answers</b> for 2022 - Intellipaat", "url": "https://intellipaat.com/blog/interview-question/data-science-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-question/data-science-interview-", "snippet": "<b>True</b> <b>positive</b> <b>rate</b>: In Machine Learning, <b>true</b>-<b>positive</b> rates, which are also referred to as sensitivity or recall, are used to measure the percentage <b>of actual</b> positives which are <b>correctly</b> <b>identified</b>. Formula: <b>True</b> <b>Positive</b> <b>Rate</b> = <b>True</b> Positives/Positives False <b>positive</b> <b>rate</b>: False <b>positive</b> <b>rate</b> is basically the probability of falsely rejecting the null hypothesis for a particular test. The false-<b>positive</b> <b>rate</b> is calculated as the ratio between the <b>number</b> of negative events wrongly ...", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Further Thoughts on Precision</b>", "url": "https://www.researchgate.net/publication/235271424_Further_Thoughts_on_Precision", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/235271424_<b>Further_Thoughts_on_Precision</b>", "snippet": "of <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>) = 1 and false <b>positive</b> <b>rate</b> (FPR) ... FPR have a large ef fect on the <b>actual</b> <b>number</b> of false positives. Thus if classi\ufb01er performance changes to <b>TPR</b> = 1 and FPR = 0 ...", "dateLastCrawled": "2021-12-21T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts <b>the positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts <b>the positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "Recall is the <b>number</b> of <b>True</b> Positives divided by the <b>number</b> of <b>True</b> Positives and the <b>number</b> of False Negatives. Put another way it is the <b>number</b> of <b>positive</b> predictions divided by the <b>number</b> of <b>positive</b> class values in the test data. It is also called Sensitivity or the <b>True</b> <b>Positive</b> <b>Rate</b>. Recall can be thought of as a measure of a classifiers completeness. A low recall indicates many False Negatives.", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Wikizero - Sensitivity and specificity", "url": "https://wikizero.com/m/True_positive_rate", "isFamilyFriendly": true, "displayUrl": "https://wikizero.com/m/<b>True</b>_<b>positive</b>_<b>rate</b>", "snippet": "Sensitivity and specificity mathematically describe the accuracy of a test which reports the presence or absence of a condition, in comparison to a \u2018Gold Standard\u2019 or definition.. Sensitivity (<b>True</b> <b>Positive</b> <b>Rate</b>) refers to the proportion of those who received a <b>positive</b> result on this test <b>out</b> of those who <b>actually</b> have the condition (when judged by the \u2018Gold Standard\u2019).; Specificity (<b>True</b> Negative <b>Rate</b>) refers to the proportion of those who received a negative result on this test ...", "dateLastCrawled": "2021-11-09T17:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Performance</b> Metrics in <b>Machine Learning</b> [Complete Guide] - neptune.ai", "url": "https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/<b>performance</b>-metrics-in-<b>machine-learning</b>-complete-guide", "snippet": "It makes use of <b>true</b> <b>positive</b> rates(<b>TPR</b>) and false <b>positive</b> rates(FPR). ... (&#39;False <b>Positive</b> <b>Rate</b>&#39;) pyplot.ylabel(&#39;<b>True</b> <b>Positive</b> <b>Rate</b>&#39;) pyplot.legend() pyplot.show() No Skill: ROC AUC=0.500 Logistic: ROC AUC=0.996. A no-skill classifier is one that can\u2019t discriminate between the classes, and would predict a random class or a constant class in <b>all</b> cases. The no-skill line changes based on the distribution of <b>the positive</b> to negative classes. It\u2019s a horizontal line with the value of the ...", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Top 70+ <b>Data Science Interview Questions and Answers</b> for 2022 - Intellipaat", "url": "https://intellipaat.com/blog/interview-question/data-science-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-question/data-science-interview-", "snippet": "<b>True</b> <b>positive</b> <b>rate</b>: In Machine Learning, <b>true</b>-<b>positive</b> rates, which are also referred to as sensitivity or recall, are used to measure the percentage <b>of actual</b> positives which are <b>correctly</b> <b>identified</b>. Formula: <b>True</b> <b>Positive</b> <b>Rate</b> = <b>True</b> Positives/Positives False <b>positive</b> <b>rate</b>: False <b>positive</b> <b>rate</b> is basically the probability of falsely rejecting the null hypothesis for a particular test. The false-<b>positive</b> <b>rate</b> is calculated as the ratio between the <b>number</b> of negative events wrongly ...", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts <b>the positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts <b>the positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Multimodal human eye blink recognition method using feature level ...", "url": "https://link.springer.com/article/10.1007/s00500-020-04979-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00500-020-04979-5", "snippet": "A particular instance of percentages per <b>true</b> class including <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>) and false negative <b>rate</b> (FNR) (Confusion Matrix) of individual classifiers for EFR (unimodal), EE B FR and EE BG FR (multimodal) methods is relegated to \u201cAppendix C\u201d (Tables 6, 7, 8). A total of 3454 (30% of 11516) <b>instances</b> are tested where element [1,1] denotes <b>number</b> of blinks accepted as blinks, element [1,0] is <b>number</b> of blinks accepted as non-blinks. Similarly, element [0,0] is <b>number</b> of non ...", "dateLastCrawled": "2022-01-11T18:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "Recall is the <b>number</b> of <b>True</b> Positives divided by the <b>number</b> of <b>True</b> Positives and the <b>number</b> of False Negatives. Put another way it is the <b>number</b> of <b>positive</b> predictions divided by the <b>number</b> of <b>positive</b> class values in the test data. It is also called Sensitivity or the <b>True</b> <b>Positive</b> <b>Rate</b>. Recall can be thought of as a measure of a classifiers completeness. A low recall indicates many False Negatives.", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How To Deal With Imbalanced <b>Classification</b>, Without Re-balancing the ...", "url": "https://towardsdatascience.com/how-to-deal-with-imbalanced-classification-without-re-balancing-the-data-8a3c02353fe3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-deal-with-imbalanced-<b>classification</b>-with<b>out</b>-re...", "snippet": "We have reduced our False Negative <b>Rate</b> from 28.38% down to 9.46% (i.e. <b>identified</b> and denied 90.54% of our <b>true</b> frauds as our new Recall or Sensitivity or <b>True</b> <b>Positive</b> <b>Rate</b> or <b>TPR</b>), while our False <b>Positive</b> <b>Rate</b> (FPR) has increased from 0.01% to 5.75% (i.e. still approved 94.25% of our legitimate transactions). It might well be worth the trade-off to us of denying about 6% of the legitimate transactions as the price we pay in order to approve only less than 10% of the fraudulent ...", "dateLastCrawled": "2022-02-03T01:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 7, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Sensitivity and specificity</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Sensitivity_and_specificity", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Sensitivity_and_specificity</b>", "snippet": "The <b>true</b> <b>positive</b> in this figure is 6, and false negatives of 0 (because <b>all</b> <b>positive</b> condition is <b>correctly</b> predicted as <b>positive</b>). Therefore the sensitivity is 100% (from 6 / (6 + 0) ). This situation is also illustrated in the previous figure where the dotted line is at position A (the left-hand side is predicted as negative by the model, the right-hand side is predicted as <b>positive</b> by the model).", "dateLastCrawled": "2022-02-02T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Data Science Interview Q&amp;A | Obviously Awesome", "url": "https://bjpcjp.github.io/2021/10/01/Data-Science-Interview-Questions.html", "isFamilyFriendly": true, "displayUrl": "https://bjpcjp.github.io/2021/10/01/Data-Science-Interview-Questions.html", "snippet": "Data Science Interview Q&amp;A Explain Logistic Regression. Logistic Regression is a popular method for classification. It models the probability of the default class. It uses the sigmoid function to map any real-valued <b>number</b> to a probability 0\u2013&gt;1 to predict the output class. Two types: Binary (2 categories) and Multinomial (3+ categories). Assumptions: Binary logistic regression requires the dependent variable to be binary. Variables should be independent of each other. (the model should ...", "dateLastCrawled": "2022-01-04T18:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Classification</b> - GitHub Pages", "url": "https://sherbold.github.io/intro-to-data-science/07_Classification.html", "isFamilyFriendly": true, "displayUrl": "https://sherbold.github.io/intro-to-data-science/07_<b>Classification</b>.html", "snippet": "Thus, it takes the ratio of of <b>positive</b> <b>instances</b> <b>that are correctly</b> <b>identified</b> and the ratio of <b>positive</b> predictions that <b>actually</b> should be <b>positive</b> into account. The harmonic mean is often used instead of the arithmetic mean for the comparison of rates. The F1 measure works well even in case of imbalanced data, because there is usually a trade-off between precision and recall assuming that a perfect prediction is impossible. To increase the recall, more <b>positive</b> predictions are required ...", "dateLastCrawled": "2021-12-29T10:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Performance</b> Metrics in <b>Machine Learning</b> [Complete Guide] - neptune.ai", "url": "https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/<b>performance</b>-metrics-in-<b>machine-learning</b>-complete-guide", "snippet": "It makes use of <b>true</b> <b>positive</b> rates(<b>TPR</b>) and false <b>positive</b> rates(FPR). ... (&#39;False <b>Positive</b> <b>Rate</b>&#39;) pyplot.ylabel(&#39;<b>True</b> <b>Positive</b> <b>Rate</b>&#39;) pyplot.legend() pyplot.show() No Skill: ROC AUC=0.500 Logistic: ROC AUC=0.996. A no-skill classifier is one that <b>can</b>\u2019t discriminate between the classes, and would predict a random class or a constant class in <b>all</b> cases. The no-skill line changes based on the distribution of <b>the positive</b> to negative classes. It\u2019s a horizontal line with the value of the ...", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "Recall is the <b>number</b> of <b>True</b> Positives divided by the <b>number</b> of <b>True</b> Positives and the <b>number</b> of False Negatives. Put another way it is the <b>number</b> of <b>positive</b> predictions divided by the <b>number</b> of <b>positive</b> class values in the test data. It is also called Sensitivity or the <b>True</b> <b>Positive</b> <b>Rate</b>. Recall <b>can</b> <b>be thought</b> of as a measure of a classifiers completeness. A low recall indicates many False Negatives.", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Top 70+ <b>Data Science Interview Questions and Answers</b> for 2022 - Intellipaat", "url": "https://intellipaat.com/blog/interview-question/data-science-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-question/data-science-interview-", "snippet": "<b>True</b> <b>positive</b> <b>rate</b>: In Machine Learning, <b>true</b>-<b>positive</b> rates, which are also referred to as sensitivity or recall, are used to measure the percentage <b>of actual</b> positives which are <b>correctly</b> <b>identified</b>. Formula: <b>True</b> <b>Positive</b> <b>Rate</b> = <b>True</b> Positives/Positives False <b>positive</b> <b>rate</b>: False <b>positive</b> <b>rate</b> is basically the probability of falsely rejecting the null hypothesis for a particular test. The false-<b>positive</b> <b>rate</b> is calculated as the ratio between the <b>number</b> of negative events wrongly ...", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to Data Science : How to NOT Get Confused by the Confusion Matrix ...", "url": "https://jeppbautista.wordpress.com/2019/02/09/how-to-not-get-confused-by-the-confusion-matrix/", "isFamilyFriendly": true, "displayUrl": "https://jeppbautista.wordpress.com/2019/02/09/how-to-not-get-confused-by-the-confusion...", "snippet": "Measures the <b>number</b> <b>of actual</b> positives <b>that are correctly</b> <b>identified</b> as <b>positive</b>. Basically answers to the question: ... (FP) and the total <b>number</b> <b>of actual</b> negative <b>instances</b>. It answers the question: \u201cHow often does the classifier predict <b>positive</b> when it\u2019s <b>actually</b> negative?\u201d. Like the <b>TPR</b>, go try to compute the FPR of our previous example. 0.857142857 is the score of our classifier. Looks good. <b>True</b> Negative <b>Rate</b> / Specificity. <b>True</b> Negative <b>Rate</b> is the measure <b>of actual</b> negatives ...", "dateLastCrawled": "2022-01-07T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A survey <b>on computational intelligence</b> approaches for predictive ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417416306297", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417416306297", "snippet": "The <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>, Sensitivity) measures the proportion <b>of actual</b> positives which are <b>correctly</b> <b>identified</b> as such (e.g. the percentage of cancer patients who were <b>correctly</b> <b>identified</b> as cancer patients), and the False <b>Positive</b> <b>Rate</b> (FPR, measured as 1-Specificity) measures the proportion <b>of actual</b> negatives which are incorrectly <b>identified</b> as positives (e.g. the percentage of benign patients who were incorrectly <b>identified</b> as cancer patients). The aim is to identify the optimal ...", "dateLastCrawled": "2021-10-13T07:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "AdvancedEvaluations1.pdf - FUNDAMENTALS OF DATA SCIENCE ADVANCED ...", "url": "https://www.coursehero.com/file/125786657/AdvancedEvaluations1pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/125786657/AdvancedEvaluations1pdf", "snippet": "RECEIVER OPERATING CHARACTERISTIC (ROC) CURVES x-axis: the false <b>positive</b> <b>rate</b> (FPR) is also referred to as the inverted specificity y-axis: sensitivity, recall, also <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>) describes how good the model is at predicting <b>the positive</b> class when the <b>actual</b> outcome is <b>positive</b> FPR and the <b>TPR</b> are calculated for different probability thresholds The perfect classifier will have a ROC curve that passes through the upper left corner (corresponding to 100 % sensitivity and 100 % ...", "dateLastCrawled": "2022-01-18T14:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Receiver operating characteristic</b> - WikiMili, The Best Wikipedia Reader", "url": "https://wikimili.com/en/Receiver_operating_characteristic", "isFamilyFriendly": true, "displayUrl": "https://wikimili.com/en/<b>Receiver_operating_characteristic</b>", "snippet": "In statistical analysis of binary classification, the F-score or F-measure is a measure of a test&#39;s accuracy. It is calculated from the precision and recall of the test, where the precision is the <b>number</b> of <b>true</b> <b>positive</b> results divided by the <b>number</b> <b>of all</b> <b>positive</b> results, including those not <b>identified</b> <b>correctly</b>, and the recall is the <b>number</b> of <b>true</b> <b>positive</b> results divided by the <b>number</b> <b>of all</b> samples that should have been <b>identified</b> as <b>positive</b>.", "dateLastCrawled": "2021-05-29T18:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How <b>to Classify Photos of Dogs and Cats</b> (with 97% accuracy)", "url": "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to...", "snippet": "We <b>present</b> Asirra, a CAPTCHA that asks users to identify cats <b>out</b> of a set of 12 photographs of both cats and dogs. Asirra is easy for users; user studies indicate it <b>can</b> be solved by humans 99.6% of the time in under 30 seconds. Barring a major advance in machine vision, we expect computers will have no better than a 1/54,000 chance of solving it. \u2014 Asirra: A CAPTCHA that Exploits Interest-Aligned Manual Image Categorization, 2007. At the time that the competition was posted, the state-of ...", "dateLastCrawled": "2022-02-03T02:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "DeepLearning-500-questions/Chapter 2_TheBasisOfMachineLearning.md at ...", "url": "https://github.com/scutan90/DeepLearning-500-questions/blob/master/English%20version/ch02_MachineLearningFoundation/Chapter%202_TheBasisOfMachineLearning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/scutan90/DeepLearning-500-questions/blob/master/English version/ch02...", "snippet": "P = TP + FN represents the <b>number</b> of samples <b>that are actually</b> <b>positive</b> examples. <b>True</b>, False describes whether the classifier is correct. <b>Positive</b> and Negative are the classification results of the classifier. If <b>the positive</b> example is 1, the negative example is -1, ie <b>positive</b>=1, negative=-1. Use 1 for <b>True</b>, -1 for False, then the <b>actual</b> ...", "dateLastCrawled": "2022-01-13T17:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "199 questions with answers in <b>ROC CURVE | Science topic</b>", "url": "https://www.researchgate.net/topic/ROC-Curve", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>ROC-Curve</b>", "snippet": "But we don&#39;t know what we should enter for the <b>number</b> of <b>actually</b> negative and <b>actually</b> <b>positive</b> cases. There are only 8 ideas, 3 good and 5 bad, so maybe those numbers should be 3 and 5.", "dateLastCrawled": "2022-02-02T03:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness definitions explained", "url": "https://www.slideshare.net/juanes8/fairness-definitions-explained", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/juanes8/fairness-definitions-explained", "snippet": "<b>True</b> <b>positive</b> <b>rate</b> (<b>TPR</b>): the fraction of <b>positive</b> cases <b>correctly</b> predicted to be in <b>the positive</b> class <b>out</b> <b>of all</b> <b>actual</b> <b>positive</b> cases, T P T P+F N . <b>TPR</b> is often referred to as sensitivity or recall; it represents the probability of the truly <b>positive</b> subject to be <b>identified</b> as such, P(d = 1|Y = 1). In our example, it is the probability of an applicant with a good credit score to be <b>correctly</b> assigned with such score. 10. False <b>positive</b> <b>rate</b> (FPR): the fraction of negative cases incor ...", "dateLastCrawled": "2022-01-23T15:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Survey on <b>deep learning</b> with class <b>imbalance</b> | Journal of Big Data ...", "url": "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0192-5", "isFamilyFriendly": true, "displayUrl": "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0192-5", "snippet": "Since the <b>actual</b> <b>number</b> of samples may prove more important than the ratio, ... (Eq. 5), or the <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>), measures the percentage of <b>the positive</b> group that was <b>correctly</b> predicted to be <b>positive</b> by the model. Recall is not affected by <b>imbalance</b> because it is only dependent on <b>the positive</b> group. Recall does not consider the <b>number</b> of negative samples that are misclassified as <b>positive</b>, which <b>can</b> be problematic in problems containing class imbalanced data with many negative ...", "dateLastCrawled": "2022-01-31T15:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts <b>the positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts <b>the positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Wikizero - Sensitivity and specificity", "url": "https://wikizero.com/m/True_positive_rate", "isFamilyFriendly": true, "displayUrl": "https://wikizero.com/m/<b>True</b>_<b>positive</b>_<b>rate</b>", "snippet": "Sensitivity and specificity mathematically describe the accuracy of a test which reports the presence or absence of a condition, in comparison to a \u2018Gold Standard\u2019 or definition.. Sensitivity (<b>True</b> <b>Positive</b> <b>Rate</b>) refers to the proportion of those who received a <b>positive</b> result on this test <b>out</b> of those who <b>actually</b> have the condition (when judged by the \u2018Gold Standard\u2019).; Specificity (<b>True</b> Negative <b>Rate</b>) refers to the proportion of those who received a negative result on this test ...", "dateLastCrawled": "2021-11-09T17:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 4, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Sensitivity and specificity</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Sensitivity_and_specificity", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Sensitivity_and_specificity</b>", "snippet": "The <b>true</b> <b>positive</b> in this figure is 6, and false negatives of 0 (because <b>all</b> <b>positive</b> condition is <b>correctly</b> predicted as <b>positive</b>). Therefore the sensitivity is 100% (from 6 / (6 + 0) ). This situation is also illustrated in the previous figure where the dotted line is at position A (the left-hand side is predicted as negative by the model, the right-hand side is predicted as <b>positive</b> by the model).", "dateLastCrawled": "2022-02-02T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Detection of phishing website using machine learning approach</b>", "url": "https://www.researchgate.net/publication/332573776_Detection_of_phishing_website_using_machine_learning_approach", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/332573776_<b>Detection_of_phishing_website_using</b>...", "snippet": "<b>positive</b> <b>rate</b> (<b>TPR</b>), <b>true</b> ne gative <b>rate</b> (TNR), Precision, F measure and f alse <b>positive</b> <b>rate</b>. T hese values have been calculated using formulas given in performance metrices and using confusion ...", "dateLastCrawled": "2022-01-24T00:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Data Science Interview Q&amp;A | Obviously Awesome", "url": "https://bjpcjp.github.io/2021/10/01/Data-Science-Interview-Questions.html", "isFamilyFriendly": true, "displayUrl": "https://bjpcjp.github.io/2021/10/01/Data-Science-Interview-Questions.html", "snippet": "Data Science Interview Q&amp;A Explain Logistic Regression. Logistic Regression is a popular method for classification. It models the probability of the default class. It uses the sigmoid function to map any real-valued <b>number</b> to a probability 0\u2013&gt;1 to predict the output class. Two types: Binary (2 categories) and Multinomial (3+ categories). Assumptions: Binary logistic regression requires the dependent variable to be binary. Variables should be independent of each other. (the model should ...", "dateLastCrawled": "2022-01-04T18:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "699 Mod 4 - <b>Timothy_H_Heaton resume</b> - <b>Google Search</b>", "url": "https://sites.google.com/site/timothyhheatonresume/699-mod-4", "isFamilyFriendly": true, "displayUrl": "https://<b>sites.google.com</b>/site/<b>timothyhheatonresume</b>/699-mod-4", "snippet": "An ROC curve is a tool that <b>can</b> be used to compare classifiers by visualizing the trade-off between the <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b> = TP / (TP + FN)) and the false <b>positive</b> <b>rate</b> (FPR = FP / (FP + TN)). If a class label has two values, yes and no for example, an ROC curve shows, for a given classifier model, the <b>rate</b> at which the model <b>correctly</b> predicts yes tuples against the <b>rate</b> at which the model incorrectly predicts no tuples as yes tuples.", "dateLastCrawled": "2022-01-01T16:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "Recall is the <b>number</b> of <b>True</b> Positives divided by the <b>number</b> of <b>True</b> Positives and the <b>number</b> of False Negatives. Put another way it is the <b>number</b> of <b>positive</b> predictions divided by the <b>number</b> of <b>positive</b> class values in the test data. It is also called Sensitivity or the <b>True</b> <b>Positive</b> <b>Rate</b>. Recall <b>can</b> be thought of as a measure of a classifiers completeness. A low recall indicates many False Negatives.", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Multimodal human eye blink recognition method using feature level ...", "url": "https://link.springer.com/article/10.1007/s00500-020-04979-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00500-020-04979-5", "snippet": "The performance <b>of all</b> classification algorithms used are <b>compared</b> using several parameters (where TP-<b>True</b> <b>Positive</b>, TN-<b>True</b> Negative, FP-False <b>positive</b>, and FN-False Negative) as shown below: 1. Sensitivity (Se) It is the ratio of the <b>correctly</b> classified <b>instances</b> of a class to the total no. of <b>instances</b> of that class.", "dateLastCrawled": "2022-01-11T18:33:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "It essentially shows the <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>) against the False <b>Positive</b> <b>Rate</b> (FPR) for various threshold values. AUC The Area Under the Curve (AUC), is an aggregated measure of performance of a binary classifier on all possible threshold values (and therefore it is threshold invariant). AUC calculates the area under the ROC curve, and therefore it is between 0 and 1. One way of interpreting AUC is the probability that the model ranks a random <b>positive</b> example more highly than a random ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) A Comparison of Various <b>Machine</b> <b>Learning</b> Algorithms in a ...", "url": "https://www.academia.edu/68902781/A_Comparison_of_Various_Machine_Learning_Algorithms_in_a_Distributed_Denial_of_Service_Intrusion", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/68902781/A_Comparison_of_Various_<b>Machine</b>_<b>Learning</b>_Algorithms...", "snippet": "2) <b>True</b> <b>Positive</b> <b>Rate</b> (<b>TPR</b>) 4) Decision Tree (DT) This metric calculates how often the model is able to predict a This algorithm uses a tree structure <b>analogy</b> to represent a <b>positive</b> result correctly. Similar to Accuracy, but difference is series of rules that lead to a class or value [16]. It starts with a it only takes <b>positive</b> observation. root node, which is the best predictor. Then, it progresses <b>TPR</b>:: \ud835\udc47\ud835\udc43 through branch nodes to other predictors. Ultimately it reaches \ud835\udc47\ud835\udc43 ...", "dateLastCrawled": "2022-02-05T20:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Evaluation Metric Special ROC-AUC Candra\u2019s blog", "url": "https://saltfarmer.github.io/blog/machine%20learning/Evaluation-Metrics-Special-ROCAUC/", "isFamilyFriendly": true, "displayUrl": "https://saltfarmer.github.io/blog/<b>machine</b> <b>learning</b>/Evaluation-Metrics-Special-ROCAUC", "snippet": "The ROC curve is created by plotting the <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>) against the false <b>positive</b> <b>rate</b> (FPR) at various threshold settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s ...", "dateLastCrawled": "2022-02-03T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "More Performance Evaluation Metrics for Classification Problems You ...", "url": "https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/04/performance-evaluation-metrics-classification.html", "snippet": "A ROC curve plots the <b>true</b> <b>positive</b> <b>rate</b> (<b>tpr</b>) versus the false <b>positive</b> <b>rate</b> (fpr) as a function of the model\u2019s threshold for classifying a <b>positive</b>. Given that c is a constant known as decision threshold, the below ROC curve suggests that by default c=0.5, when c=0.2, both <b>tpr</b> and fpr increase.", "dateLastCrawled": "2022-01-26T05:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning for Economists: Part 1 \u2013 Criterion Functions</b>", "url": "https://michalandrle.weebly.com/uploads/1/3/9/2/13921270/imf_ml_1_lossfun.pdf", "isFamilyFriendly": true, "displayUrl": "https://michalandrle.weebly.com/uploads/1/3/9/2/13921270/imf_ml_1_lossfun.pdf", "snippet": "ROC curve is a plot of <b>true</b> <b>positive</b> <b>rate</b> (<b>TPR</b>, sensitivity) against the false <b>positive</b> <b>rate</b> (FPR, 1-Speci\ufb01city) at various threshold values. For \ufb01xed accuracy of the model, there usually is a trade-off between sensitivity and speci\ufb01city. ROC curves map this trade-off.", "dateLastCrawled": "2021-11-18T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evaluation metric for Supervised <b>Learning</b>: | by Anuganti Suresh | Medium", "url": "https://anugantisuresh.medium.com/evaluation-metric-for-supervised-learning-ba063f1bb1af", "isFamilyFriendly": true, "displayUrl": "https://anugantisuresh.medium.com/evaluation-metric-for-supervised-<b>learning</b>-ba063f1bb1af", "snippet": "A higher <b>TPR</b> and a lower FNR is desirable since we want to correctly classify the <b>positive</b> class. The area under the curve represents the area under the curve when the false <b>positive</b> <b>rate</b> is plotted against the <b>True</b> <b>positive</b> <b>rate</b> as below. AUC ranges between 0 and 1. A value of 0 means 100% prediction of the model is incorrect. A value of 1 ...", "dateLastCrawled": "2022-01-06T20:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is the AUC \u2014 <b>ROC</b> Curve?. AUC-<b>ROC</b> CURVE | CONFUSION MATRIX |\u2026 | by ...", "url": "https://medium.com/computer-architecture-club/what-is-the-auc-roc-curve-47fbdcbf7a4a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/computer-architecture-club/what-is-the-auc-<b>roc</b>-curve-47fbdcbf7a4a", "snippet": "By <b>analogy</b>, Higher the AUC, ... Sensitivity / <b>TPR</b> (<b>True</b> <b>Positive</b> <b>Rate</b>) / Recall. Sensitivity tells us what proportion of the <b>positive</b> class got correctly classified. A simple example would be to ...", "dateLastCrawled": "2022-01-26T00:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Understanding <b>Classification</b> Thresholds Using Isocurves", "url": "https://druce.ai/2019/10/understanding-classification-thresholds-using-isocurves", "isFamilyFriendly": true, "displayUrl": "https://druce.ai/2019/10/understanding-<b>classification</b>-thresholds-using-isocurves", "snippet": "The <b>true</b>-<b>positive</b> <b>rate</b> (<b>TPR</b>) is the number of <b>true</b> positives / ground truth positives (also called recall or sensitivity). Ground truth positives = <b>true</b> positives + false negatives: \\[<b>TPR</b> = \\frac{tp}{tp+fn}\\] A false <b>positive</b> is a false observation incorrectly predicted to be <b>true</b>. The false-<b>positive</b> <b>rate</b> (FPR) is the number of false positives / ground truth negatives (1 \u2014 FPR is the specificity). Ground truth negatives = <b>true</b> negatives + false positives: \\[FPR = \\frac{fp}{tn + fp}\\] The ...", "dateLastCrawled": "2022-01-19T15:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Gini coefficient. From economics to <b>machine</b> <b>learning</b>", "url": "https://weekly-geekly.imtqy.com/articles/350440/index.html", "isFamilyFriendly": true, "displayUrl": "https://weekly-geekly.imtqy.com/articles/350440/index.html", "snippet": "T p - <b>True</b> <b>Positive</b> (the correct answer of the model on the <b>true</b> class &quot;1&quot; at a given threshold) F P - False <b>Positive</b> (incorrect response of the model on the <b>true</b> class &quot;0&quot; at a given threshold) <b>T P R</b> - <b>True</b> <b>Positive</b> <b>Rate</b> (ratio T p to n 1) F P R - False <b>Positive</b> <b>Rate</b> (ratio F P to n 0) i, j - the current index of the item. Parametric method", "dateLastCrawled": "2022-01-29T02:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - Why is ROC insensitive to class distributions ...", "url": "https://stats.stackexchange.com/questions/545273/why-is-roc-insensitive-to-class-distributions", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/545273/why-is-roc-insensitive-to-class...", "snippet": "Basically, ROC curve shows false <b>positive</b> (FP) <b>RATE</b> and <b>true</b> <b>positive</b> (TP) <b>RATE</b> for each threshold of the model (score you decided as being the limit between classification &#39;1&#39; and &#39;0&#39;). So at the start, if your threshold is 1 (max possible score for your model), you classify everything as 0 and then there&#39;s 0% FP and 0% TP. If threshold is 0 (min possible score for your model), everything is classified as 1 and so your TP and FP rates are 100%. Using a threshold strictly between 0 and 1 ...", "dateLastCrawled": "2022-01-29T03:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How <b>to calculate the image accuracy through ROC method</b>?", "url": "https://www.researchgate.net/post/How_to_calculate_the_image_accuracy_through_ROC_method", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/How_<b>to_calculate_the_image_accuracy_through_ROC_method</b>", "snippet": "<b>True Positive Rate (TPR) is like</b> a recall and is defined as mathematically . TPR = (TP/TP+FN) False Positive Rate (FPR) is defined as mathematically . FPR = (FP/FP+TN) An ROC curve plots TPR vs ...", "dateLastCrawled": "2022-01-17T03:34:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(true positive rate (tpr))  is like +(number of actual positive instances that are correctly identified as being positive out of all the positive instances that are actually present)", "+(true positive rate (tpr)) is similar to +(number of actual positive instances that are correctly identified as being positive out of all the positive instances that are actually present)", "+(true positive rate (tpr)) can be thought of as +(number of actual positive instances that are correctly identified as being positive out of all the positive instances that are actually present)", "+(true positive rate (tpr)) can be compared to +(number of actual positive instances that are correctly identified as being positive out of all the positive instances that are actually present)", "machine learning +(true positive rate (tpr) AND analogy)", "machine learning +(\"true positive rate (tpr) is like\")", "machine learning +(\"true positive rate (tpr) is similar\")", "machine learning +(\"just as true positive rate (tpr)\")", "machine learning +(\"true positive rate (tpr) can be thought of as\")", "machine learning +(\"true positive rate (tpr) can be compared to\")"]}