{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Books similar to An introduction to machine learning <b>interpretability</b>", "url": "https://www.goodreads.com/book/similar/61805828-an-introduction-to-machine-learning-interpretability", "isFamilyFriendly": true, "displayUrl": "https://<b>www.goodreads.com</b>/<b>book</b>/similar/61805828-an-introduction-to-machine-learning...", "snippet": "Find books <b>like</b> An introduction to machine learning <b>interpretability</b> from the world\u2019s largest community of readers. Goodreads members who liked An introd...", "dateLastCrawled": "2021-07-16T16:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Chapter 2 Introduction | <b>Interpretable</b> Machine Learning", "url": "https://christophm.github.io/interpretable-ml-book/intro.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/<b>interpretable</b>-ml-<b>book</b>/intro.html", "snippet": "This <b>book</b> starts with some (dystopian) short stories that are not needed to understand the <b>book</b>, but hopefully will entertain and make you think. Then the <b>book</b> explores the concepts of machine learning <b>interpretability</b>. We will discuss when <b>interpretability</b> is important and what different types of explanations there are.", "dateLastCrawled": "2022-02-03T08:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "An <b>introduction to machine learning interpretability</b> by Patrick Hall", "url": "https://www.goodreads.com/book/show/39928940-an-introduction-to-machine-learning-interpretability", "isFamilyFriendly": true, "displayUrl": "https://<b>www.goodreads.com</b>/<b>book</b>/show/39928940-an-introduction-to-machine-learning...", "snippet": "An <b>introduction to machine learning interpretability</b>. by. Patrick Hall, Navdeep Gill. 3.25 \u00b7 Rating details \u00b7 20 ratings \u00b7 2 reviews. An Applied Perspective on Fairness, Accountability, Transparency, and Explainable AI. Innovation and competition are driving analysts and data scientists toward increasingly complex predictive modeling and ...", "dateLastCrawled": "2021-10-29T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Explainable AI and Interpretation of Models | AltexSoft", "url": "https://www.altexsoft.com/blog/interpretability-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.altexsoft.com/blog/<b>interpretability</b>-<b>machine-learning</b>", "snippet": "But justification and <b>interpretability</b> factors are inversely related. The more accurate and advanced the model is, the less interpretable it is, the more it looks <b>like</b> a black box. As soon as ML became a household technology and developed enough, the problem of <b>interpretability</b> (or explainability, both used interchangeably) emerged.", "dateLastCrawled": "2022-01-30T01:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Teaching Machines to Read <b>Movie Reviews: Thinking About Interpretability</b>", "url": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about-interpretability-63c12248b8e5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about...", "snippet": "Note: plenty of people in ML don\u2019t think we need to understand the \u201chow\u201d of human tasks <b>like</b> <b>reading</b>. They argue we need better algorithms, more/better compute power, and (more than anything) more data. Regardless, I\u2019m still interested in answering \u201chow\u201d questions <b>like</b> this, partly because I\u2019m a scientist: I want insight that could help solve problems. But also partly because I\u2019m a scientist: I just want to know how things work.", "dateLastCrawled": "2022-01-19T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretable Machine Learning</b>.pdf - Free download books", "url": "https://www.dbooks.org/interpretable-machine-learning-0244768528/", "isFamilyFriendly": true, "displayUrl": "https://www.d<b>books</b>.org/<b>interpretable-machine-learning</b>-0244768528", "snippet": "<b>Book</b> Description This <b>book</b> is about making machine learning models and their decisions interpretable. After exploring the concepts of <b>interpretability</b>, you will learn about simple, interpretable models such as decision trees, decision rules and linear regression.", "dateLastCrawled": "2022-01-30T06:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretable Machine Learning with Python</b> [<b>Book</b>]", "url": "https://www.oreilly.com/library/view/interpretable-machine-learning/9781800203907/", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/interpretable-machine-learning/9781800203907", "snippet": "The first section of the <b>book</b> is a beginner&#39;s guide to <b>interpretability</b>, covering its relevance in business and exploring its key aspects and challenges. You&#39;ll focus on how white-box models work, compare them to black-box and glass-box models, and examine their trade-off. The second section will get you up to speed with a vast array of interpretation methods, also known as Explainable AI (XAI) methods, and how to apply them to different use cases, be it for classification or regression, for ...", "dateLastCrawled": "2022-01-26T12:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How important is <b>interpretability</b> for a model in Machine Learning ...", "url": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-<b>interpretability</b>-for...", "snippet": "Hofstadter\u2019s first <b>book</b>, and in my opinion, still his best, was an utter revelation to me. It opened up a whole new world of imagination of what deep links there are between art, music and abstract math, realized by the three central characters \u2014 Johann Sebastian Bach, Maurice Escher, Kurt G\u00f6del \u2014 and computing, including of course AI and ML.", "dateLastCrawled": "2022-01-10T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>How important is interpretability for a</b> model in Machine Learning? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-model-in-Machine-Learning", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Packt is searching for authors like you</b> | Interpretable Machine ...", "url": "https://subscription.packtpub.com/book/data/9781800203907/18/ch18lvl1sec72/packt-is-searching-for-authors-like-you", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/<b>book</b>/data/9781800203907/18/ch18lvl1sec72/packt-is...", "snippet": "Speculating on the future of ML <b>interpretability</b>; Further <b>reading</b>; Why subscribe? 18. Other Books You May Enjoy. Other Books You May Enjoy; <b>Packt is searching for authors like you</b>; Leave a review - let other readers know what you think; You&#39;re currently viewing a free sample. Unlock with a FREE trial to access the full title and Packt library. <b>Packt is searching for authors like you</b>. If you&#39;re interested in becoming an author for Packt, please visit authors.packtpub.com and apply today. We ...", "dateLastCrawled": "2021-12-30T15:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Books <b>similar</b> to An introduction to machine learning <b>interpretability</b>", "url": "https://www.goodreads.com/book/similar/61805828-an-introduction-to-machine-learning-interpretability", "isFamilyFriendly": true, "displayUrl": "https://<b>www.goodreads.com</b>/<b>book</b>/<b>similar</b>/61805828-an-introduction-to-machine-learning...", "snippet": "Patrick Hall An introduction to machine learning <b>interpretability</b> <b>Similar</b> books. Books <b>similar</b> to An introduction to machine learning <b>interpretability</b> An introduction to machine learning <b>interpretability</b> . by Patrick Hall. 3.26 avg. rating \u00b7 19 Ratings. An Applied Perspective on Fairness, Accountability, Transparency, and Explainable AI Innovation and competition are driving analysts and data scientists toward increasingly complex predictive modeling \u2026 More. Want to Read. Shelving menu ...", "dateLastCrawled": "2021-07-16T16:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) On <b>Interpretability</b> and Similarity in Concept-Based Machine ...", "url": "https://www.academia.edu/65430713/On_Interpretability_and_Similarity_in_Concept_Based_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/65430713/On_<b>Interpretability</b>_and_<b>Similar</b>ity_in_Concept_Based...", "snippet": "Machine Learning (ML) provides important techniques for classification and predictions. Most of these are black-box models for users and do not provide decision-makers with an explanation. For the sake of transparency or more validity of decisions,", "dateLastCrawled": "2022-01-18T01:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to measure <b>interpretability</b>?. Today almost everyone uses ...", "url": "https://towardsdatascience.com/how-to-measure-interpretability-d93237b23cd3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-measure-<b>interpretability</b>-d93237b23cd3", "snippet": "Then the question of <b>interpretability</b> arises. ... I recommend the <b>reading</b> of the <b>book</b> [5]). I am not an exception to the rule, and I have had the mission of designing an interpretable predictive algorithm for management of financial assets. So, I\u2019ve started to do some research. After a few readings, I have found several algorithms presented as interpretable but I have also realized that everyone agrees that there is not yet a definition of <b>interpretability</b> and that this notion is difficult ...", "dateLastCrawled": "2022-02-01T06:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretability Methods in Machine Learning</b>: A Brief Survey - Two Sigma", "url": "https://www.twosigma.com/articles/interpretability-methods-in-machine-learning-a-brief-survey/", "isFamilyFriendly": true, "displayUrl": "https://www.twosigma.com/articles/<b>interpretability-methods-in-machine-learning</b>-a-brief...", "snippet": "Individual Conditional Expectation or ICE, is very <b>similar</b> to PDP, but instead of plotting an average, ... For further <b>reading</b> on <b>interpretability</b>, see the References section below. Click if you learned something new. Tags. artificial intelligence / <b>Interpretability</b> / machine learning / neural networks / Shapley Value. References. Sources: Doshi-Velez, Finale, and Been Kim. \u201cTowards A Rigorous Science of Interpretable Machine Learning\u201d. Molnar, Christoph. &quot;Interpretable machine learning ...", "dateLastCrawled": "2022-02-02T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretable Machine Learning</b> by Christoph Molnar", "url": "https://www.goodreads.com/book/show/37843167-interpretable-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://<b>www.goodreads.com</b>/<b>book</b>/show/37843167-<b>interpretable-machine-learning</b>", "snippet": "This <b>book</b> is a worthy endeavour to map <b>interpretability</b> in Machine learning. I read the <b>book</b> still as a work in progress, and one can notice that some parts still need a lot of finetuning (if I have some spare time I will try to help by submitting my suggestions). However, even if you would look at it now, I would consider it a little wordy but extensive insight into <b>interpretable machine learning</b>. Its writing style is as if a friendly co-academic or co-developer created a thorough guide for you", "dateLastCrawled": "2022-01-31T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Study on <b>Interpretability</b> Conditions for Fuzzy Rule-Based Classifiers", "url": "https://www.infona.pl/resource/bwmeta1.element.ieee-art-000005364909", "isFamilyFriendly": true, "displayUrl": "https://www.infona.pl/resource/bwmeta1.element.ieee-art-000005364909", "snippet": "<b>Interpretability</b> represents the most important driving force behind the implementation of fuzzy logic-based systems. It can be directly related to the system&#39;s knowledge base, with reference to the human user&#39;s easiness experienced while <b>reading</b> and understanding the embedded pieces of information. In this paper, we present a preliminary study on <b>interpretability</b> conditions for fuzzy rule-based classifiers on the basis of an innovative approach that relies on the concept of semantic cointension.", "dateLastCrawled": "2021-10-03T03:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>How important is interpretability for a</b> model in Machine Learning? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-model-in-Machine-Learning", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "9.6 <b>SHAP</b> (SHapley Additive exPlanations) | Interpretable Machine Learning", "url": "https://christophm.github.io/interpretable-ml-book/shap.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-<b>book</b>/<b>shap</b>.html", "snippet": "9.6 <b>SHAP</b> (SHapley Additive exPlanations). This chapter is currently only available in this web version. ebook and print will follow. <b>SHAP</b> (SHapley Additive exPlanations) by Lundberg and Lee (2017) 69 is a method to explain individual predictions. <b>SHAP</b> is based on the game theoretically optimal Shapley values.. There are two reasons why <b>SHAP</b> got its own chapter and is not a subchapter of Shapley values.First, the <b>SHAP</b> authors proposed KernelSHAP, an alternative, kernel-based estimation ...", "dateLastCrawled": "2022-02-03T01:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning vs. Deep Learning</b> - scrapbook", "url": "https://stephanosterburg.gitbook.io/scrapbook/freenome/machine-learning-vs.-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://stephanosterburg.git<b>book</b>.io/scrap<b>book</b>/freenome/<b>machine-learning-vs.-deep-learning</b>", "snippet": "Another machine learning algorithm with high <b>interpretability</b> is k-Nearest Neighbors. This is not a parametric learning algorithm but still falls under the category of machine learning algorithms. It is very <b>interpretability</b> because you easily reason about <b>similar</b> instances for yourself. Conclusion In Conclusion, the image above is the best summary of the difference between deep learning and machine learning. A concrete anecdote would be to consider raw data forms such as pixels in images or ...", "dateLastCrawled": "2021-12-29T20:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Chapter 10 <b>Neural Network</b> Interpretation | Interpretable Machine Learning", "url": "https://christophm.github.io/interpretable-ml-book/neural-networks.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-<b>book</b>/neural-networks.html", "snippet": "Chapter 10. <b>Neural Network</b> Interpretation. This chapter is currently only available in this web version. ebook and print will follow. The following chapters focus on interpretation methods for neural networks. The methods visualize features and concepts learned by a <b>neural network</b>, explain individual predictions and simplify neural networks.", "dateLastCrawled": "2022-02-02T02:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>The Indefinite Interpretability of the Bible</b> \u2013 Vridar", "url": "https://vridar.org/2020/09/14/the-indefinite-interpretability-of-the-bible/", "isFamilyFriendly": true, "displayUrl": "https://vridar.org/2020/09/14/<b>the-indefinite-interpretability-of-the-bible</b>", "snippet": "The tradition presents the Bible as <b>a book</b> to be studied, \u201cbut the goal of that hermeneutic activity is not so much to establish the meaning of the text as to establish transitivity between text and beliefs.\u201d The tradition stresses the fact of a connection between doctrines and the Bible rather than particular connections. \u201cThus a great deal of \u2018what the Bible says\u2019 may be transmitted quite apart from actual exegesis.\u201d Example: the Bible says both that all things are possible for ...", "dateLastCrawled": "2022-02-03T12:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) What is <b>Interpretability</b>?", "url": "https://www.researchgate.net/publication/345820069_What_is_Interpretability", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/345820069_What_is_<b>Interpretability</b>", "snippet": "ANN <b>can</b> <b>be thought</b> of as a highly non-linear function f(x). Approximating the Approximating the ANN predictions would entail providing a (more understandable 13 ) function g(x) ,", "dateLastCrawled": "2022-01-05T19:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Chapter <b>1: Interpretation, Interpretability, and Explainability; and</b> ...", "url": "https://subscription.packtpub.com/book/data/9781800203907/2", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/<b>book</b>/data/9781800203907/2", "snippet": "Hold on to that <b>thought</b> because, throughout this <b>book</b>, we will be learning the answers to these questions and many more! To interpret decisions made by a machine learning model is to find meaning in it, but furthermore, you <b>can</b> trace it back to its source and the process that transformed it. This chapter introduces machine learning ...", "dateLastCrawled": "2022-02-03T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to measure <b>interpretability</b>?. Today almost everyone uses ...", "url": "https://towardsdatascience.com/how-to-measure-interpretability-d93237b23cd3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-measure-<b>interpretability</b>-d93237b23cd3", "snippet": "Then the question of <b>interpretability</b> arises. I f you work in the fields of data science, machine learning or artificial intelligence, you have probably heard about <b>interpretability</b> (if not, I recommend the <b>reading</b> of the <b>book</b> [5]). I am not an exception to the rule, and I have had the mission of designing an interpretable predictive algorithm for management of financial assets. So, I\u2019ve started to do some research. After a few readings, I have found several algorithms presented as ...", "dateLastCrawled": "2022-02-01T06:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Clear Boxes over Black Boxes. When Exactly to Prioritize\u2026 | by Alexis ...", "url": "https://alexiskedo.medium.com/clear-boxes-vs-black-boxes-413b78f52dc9", "isFamilyFriendly": true, "displayUrl": "https://alexiskedo.medium.com/clear-boxes-vs-black-boxes-413b78f52dc9", "snippet": "The concept of <b>interpretability</b> <b>can</b> be a bit fuzzy, and <b>can</b> also be highly subjective. When I first learned of the concept, I ... After a bit more <b>reading</b> and experience, I\u2019ve come to realize that in the real world, and to most of the clients and stakeholders that you will serve as a real-world data scientist, <b>interpretability</b> should <b>be thought</b> of as less something to \u201cbalance\u201d against accuracy and as more something to simply prioritize. The call to prioritize <b>interpretability</b> is ...", "dateLastCrawled": "2022-01-25T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>interpretable-machine-learning.pdf - Interpretable Machine</b> Learning A ...", "url": "https://www.coursehero.com/file/73385309/interpretable-machine-learningpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/73385309/<b>interpretable-machine</b>-learningpdf", "snippet": "<b>Reading</b> the <b>book</b> is recommended for machine learning practitioners, data scientists, statisticians, ... Terms used through-out the <b>book</b> <b>can</b> be looked up in the Terminology chapter. Most of the models and methods explained are presented using real data examples which are described in the Data chapter. One way to make machine learning interpretable is to use interpretable models, such as linear models or decision trees. The other option is the use of model-agnostic interpretation tools that ...", "dateLastCrawled": "2021-12-24T20:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Nisha Improves the <b>Interpretability</b> of ... - Summer STEM Institute", "url": "https://www.summersteminstitute.org/post/nisha-project-spotlight", "isFamilyFriendly": true, "displayUrl": "https://www.summersteminstitute.org/post/nisha-project-spotlight", "snippet": "I <b>thought</b> I was going to become a cardiothoracic surgeon when I grew up, and I was really interested in medicine. In my childhood, I had a lot of experiences as a patient in a hospital, so doctors were my role models. As I grew older, I realized that I <b>can</b> reach a lot more people through technology. The scope of people you <b>can</b> reach if you make ...", "dateLastCrawled": "2022-01-29T04:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Best Machine Learning Books</b> (Updated for 2020)", "url": "https://blog.floydhub.com/best-machine-learning-books/", "isFamilyFriendly": true, "displayUrl": "https://blog.floydhub.com/<b>best-machine-learning-books</b>", "snippet": "Our hope is that the reader <b>can</b> learn all the fundamentals of the subject by <b>reading</b> the <b>book</b> cover to cover. Learning from data has distinct theoretical and practical tracks. In this <b>book</b>, we balance the theoretical and the practical, the mathematical and the heuristic. Theory that establishes the conceptual framework for learning is included, and so are heuristics that impact the performance of real learning systems. What we have emphasized are the necessary fundamentals that give any ...", "dateLastCrawled": "2022-02-02T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How important is <b>interpretability</b> for a model in Machine Learning ...", "url": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-<b>interpretability</b>-for...", "snippet": "Any code monkey <b>can</b> call some fancy libraries, stack a bunch of models together and keep beating the data until it surrenders the answers that we want. Model <b>interpretability</b> is the key to establish trust with Engineers / other data scientists who will be deploying, maintaining, updating your code. When it comes to production-ready models,", "dateLastCrawled": "2022-01-10T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Interpretable AI</b> by Ajay Thampi - <b>Goodreads</b>", "url": "https://www.goodreads.com/book/show/54263029-interpretable-ai", "isFamilyFriendly": true, "displayUrl": "https://<b>www.goodreads.com</b>/<b>book</b>/show/54263029-<b>interpretable-ai</b>", "snippet": "<b>Interpretable AI</b> is a hands-on guide to <b>interpretability</b> techniques that open up the black box of AI. This practical guide simplifies cutting-edge research into transparent and explainable AI, delivering practical methods you <b>can</b> easily implement with Python and open source libraries. With examples from all major machine learning approaches ...", "dateLastCrawled": "2022-01-07T02:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in the medical field: A systematic mapping and review ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "snippet": "<b>Interpretability</b> <b>can</b> be defined as the degree to which a human <b>can</b> understand the cause of a decision ... the first author extracted the relevant data for each selected study by <b>reading</b> the full text, and (2) the two other authors checked the extracted data. If a disagreement arose, it was treated by mutual discussion between researchers. After extracting the data, they were synthesized and tabulated in a manner consistent with the research questions addressed to aggregate evidence to answer ...", "dateLastCrawled": "2022-01-23T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Comparing good and poor readers a critique of the research", "url": "https://www.ideals.illinois.edu/bitstream/handle/2142/17753/ctrstreadtechrepv01982i00246_opt.pdf?sequence=1", "isFamilyFriendly": true, "displayUrl": "https://www.ideals.illinois.edu/bitstream/handle/2142/17753/ctrstreadtechrepv01982i...", "snippet": "Many studies of children&#39;s <b>reading</b> have <b>compared</b> <b>reading</b> ability groups on measures of cognitive performance. The primary aim of this work has been to identify the underlying causes of children&#39;s <b>reading</b> problems. A large variety of measures have been used, including tests of perceptual discrimination, visual scanning, within-modality and between-modality matching, vocabulary knowledge, decoding, whole word recognition, short-term memory, memory for sentences, deductive and inductive ...", "dateLastCrawled": "2022-01-30T04:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning vs. Deep Learning</b> - scrapbook", "url": "https://stephanosterburg.gitbook.io/scrapbook/freenome/machine-learning-vs.-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://stephanosterburg.git<b>book</b>.io/scrap<b>book</b>/freenome/<b>machine-learning-vs.-deep-learning</b>", "snippet": "This is due to the next topic of difference, <b>Interpretability</b>. <b>Interpretability</b>. A lot of the criticism of deep learning methods and machine learning algorithms such as Support Vector Machine or (maybe, because you <b>can</b> at least visualise the constituent probabilities making up the output), Naive Bayes, are due to their difficulty to interpret. For example, when a Convolutional Neural Network outputs \u2018cat\u2019 in a dog vs cat problem, nobody seems to know why it did that. In contrast, when ...", "dateLastCrawled": "2021-12-29T20:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Explainable AI and Interpretation of Models | AltexSoft", "url": "https://www.altexsoft.com/blog/interpretability-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.altexsoft.com/blog/<b>interpretability</b>-<b>machine-learning</b>", "snippet": "This taxonomy is in line with other sources who structure existing <b>interpretability</b> frameworks. By model: Intrinsic or Post hoc. A straightforward way to achieve <b>interpretability</b> is to use simpler models, those that <b>can</b> be easily understood by humans. This may be a viable option if simple and thus intrinsically interpretable models are enough ...", "dateLastCrawled": "2022-01-30T01:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "RuleFit: A Modeling Method for Automatically Extracting Interactions ...", "url": "https://hacarus.com/ai-lab/20211208-rulefit/", "isFamilyFriendly": true, "displayUrl": "https://hacarus.com/ai-lab/20211208-rulefit", "snippet": "With the <b>interpretability</b> of the model in mind, it is recommended to use three steps when training the decision tree. It is also recommended to use LASSO in order to perform feature selection to know if an interaction is intrinsically important in RuleFit. Next, we <b>can</b> move on to some use cases for RuleFit using real data. Use Cases. Christoph Molnar, the author of the previously mentioned <b>book</b>, Interpretable Machine Learning, released a Python package under the MIT license that has ...", "dateLastCrawled": "2022-01-30T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "ForceReader: a BERT-based Interactive Machine <b>Reading</b> Comprehension ...", "url": "https://aclanthology.org/2020.coling-main.241.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2020.coling-main.241.pdf", "snippet": "P: I know from the <b>book</b> that Bill Gates founded Microsoft. A: Bill Gates (1) In the example1, we <b>can</b> easily tell that when we try to understand the Q, we only need to pay attention to few words such as who, founder, and Microsoft. Words like I, know, <b>book</b>, in Pdo not play big roles in this particular Q&amp;A scenario. Therefore, a basic ...", "dateLastCrawled": "2021-12-26T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "9.6 <b>SHAP</b> (SHapley Additive exPlanations) | Interpretable Machine Learning", "url": "https://christophm.github.io/interpretable-ml-book/shap.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-<b>book</b>/<b>shap</b>.html", "snippet": "9.6 <b>SHAP</b> (SHapley Additive exPlanations). This chapter is currently only available in this web version. ebook and print will follow. <b>SHAP</b> (SHapley Additive exPlanations) by Lundberg and Lee (2017) 69 is a method to explain individual predictions. <b>SHAP</b> is based on the game theoretically optimal Shapley values.. There are two reasons why <b>SHAP</b> got its own chapter and is not a subchapter of Shapley values.First, the <b>SHAP</b> authors proposed KernelSHAP, an alternative, kernel-based estimation ...", "dateLastCrawled": "2022-02-03T01:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Deep Learning Objective Type Questions and Answers</b>", "url": "http://onlinemlquiz.com/ebooks/ebook_deep_learning_objective_type_questions.pdf", "isFamilyFriendly": true, "displayUrl": "onlinemlquiz.com/e<b>books</b>/e<b>book</b>_<b>deep_learning_objective_type_questions</b>.pdf", "snippet": "8. <b>Interpretability</b>: Machine Learning algorithms are more interpretable as <b>compared</b> to deep learning algorithms. Deep learning models mostly act as black box. For example, decision tree in machine learning <b>can</b> be easily interpreted by human beings and they <b>can</b> easily get to know how the final values are computed. On the other hand, it is very hard", "dateLastCrawled": "2022-02-02T12:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Explainable AI (XAI) and Interpretable Machine Learning (IML) models ...", "url": "https://ambiata.com/blog/2021-04-12-xai-part-1/", "isFamilyFriendly": true, "displayUrl": "https://ambiata.com/blog/2021-04-12-xai-part-1", "snippet": "<b>Interpretability</b> of modelling methods <b>compared</b>. Imagine we have a data-science task involving a very large dataset with hundreds of predictors and potentially many non-linear relationships with multi-way interactions. A simple linear model would not work well, and it would be infeasible to plot and inspect all the possible relationships in the data in an attempt to create features that capture the non-linear behaviours. The more powerful machine learning methods such as decision trees and ...", "dateLastCrawled": "2022-01-28T21:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How important is <b>interpretability</b> for a model in Machine Learning ...", "url": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-<b>interpretability</b>-for...", "snippet": "Any code monkey <b>can</b> call some fancy libraries, stack a bunch of models together and keep beating the data until it surrenders the answers that we want. Model <b>interpretability</b> is the key to establish trust with Engineers / other data scientists who will be deploying, maintaining, updating your code. When it comes to production-ready models,", "dateLastCrawled": "2022-01-10T11:14:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/<b>interpretability</b>-in-ml-a-broad-overview", "snippet": "First, <b>interpretability</b> in <b>machine</b> <b>learning</b> is useful because it can aid in trust. As humans, we may be reluctant to rely on <b>machine</b> <b>learning</b> models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in something opaque, which we see when people confront new technology, and this can slow down adoption. Approaches to <b>interpretability</b> that focus on transparency could help mitigate some of these fears.", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Figure 1: <b>Interpretability</b> for <b>machine</b> <b>learning</b> models bridges the concrete objectives models optimize for and the real-world (and less easy to define) desiderata that ML applications aim to achieve. Introduction . The objectives <b>machine</b> <b>learning</b> models optimize for do not always reflect the actual desiderata of the task at hand. <b>Interpretability</b> in models allows us to evaluate their decisions and obtain information that the objective alone cannot confer. <b>Interpretability</b> takes many forms ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "snippet": "This provides a novel <b>analogy</b> between data compression and regularization. Qualitative and quantitative state-of-the-art results on three datasets. 20 / 33. Interpretable Lens Variable Model (ILVM) 21 / 33. Interactive <b>Interpretability</b> via Active <b>Learning</b> Interactive \u2018human-in-the-loop\u2019 <b>interpretability</b> Choose the point with index j that maximizes : ^j = argmax jI(s ; ) = H(s ) E q \u02da(z js)[H(s jz j)] = Z p(s j)log p(s j)ds + E q \u02da(z js) Z p (s jjz)log p (s jjz)ds : (5) Choose the point ...", "dateLastCrawled": "2022-01-19T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-16T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://arxiv.org/abs/2005.12800", "isFamilyFriendly": true, "displayUrl": "https://<b>arxiv</b>.org/abs/2005.12800", "snippet": "Principles of analogical reasoning have recently been applied in the context of <b>machine</b> <b>learning</b>, for example to develop new methods for classification and preference <b>learning</b>. In this paper, we argue that, while analogical reasoning is certainly useful for constructing new <b>learning</b> algorithms with high predictive accuracy, is is arguably not less interesting from an <b>interpretability</b> and explainability point of view. More specifically, we take the view that an <b>analogy</b>-based approach is a ...", "dateLastCrawled": "2021-10-24T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Confusion Matrices</b> &amp; <b>Interpretable ML</b> | by andrea b | high stakes ...", "url": "https://medium.com/high-stakes-design/interpretability-techniques-explained-in-simple-terms-f5e1573674f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/high-stakes-design/<b>interpretability</b>-techniques-explained-in-simple...", "snippet": "The best [<b>analogy</b>] I can think of is an indicator light in your car \u2014 [and the] <b>machine</b> that you plug in to tell you more about the readout. ANDREA: Do you see <b>interpretability</b>, primarily, as ...", "dateLastCrawled": "2021-03-22T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Economic Methodology Meets Interpretable Machine Learning</b> - Part I ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. Intro - Part ...", "dateLastCrawled": "2022-01-22T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Economic Methodology Meets Interpretable <b>Machine</b> <b>Learning</b> ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. But first ...", "dateLastCrawled": "2022-01-05T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "Neuroscience \u2194 <b>Interpretability</b>. <b>Analogy</b>: model=brain. Artificial neural networks are historically inspired by neuroscience, but I used to be pretty skeptical that the connection was anything more than superficial. I&#39;ve since come around: I now think this is a very deep connection. The thing that personally persuaded me was that, in my own investigations of what goes on inside neural networks, we kept finding things that were previously discovered by neuroscientists. The most recent ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chris Olah on what the hell is going on inside neural networks - 80,000 ...", "url": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/", "isFamilyFriendly": true, "displayUrl": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research", "snippet": "Chris is a <b>machine</b> <b>learning</b> researcher currently focused on neural network interpretability. Until last December he led OpenAI\u2019s interpretability team but along with some colleagues he recently moved on to help start a new AI lab focussed on large models and safety called Anthropic. Rob Wiblin: Before OpenAI he spent 4 years at Google Brain developing tools to visualize what\u2019s going on in neural networks. Chris was hugely impactful at Google Brain. He was second author on the launch of ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Marketing AI: Interpretability and Explainability</b> - Christopher S. Penn ...", "url": "https://www.christopherspenn.com/2021/03/marketing-ai-interpretability-and-explainability/", "isFamilyFriendly": true, "displayUrl": "https://www.christopherspenn.com/2021/03/<b>marketing-ai-interpretability-and-explainability</b>", "snippet": "<b>Interpretability is like</b> inspecting the baker\u2019s recipe for the cake. We look at the list of ingredients and the steps taken to bake the cake, and we verify that the recipe makes sense and the ingredients were good. This is a much more rigorous way of validating our results, but it\u2019s the most complete \u2013 and if we\u2019re in a high-stakes situation where we need to remove all doubt, this is the approach we take. Interpretability in AI is like that \u2013 we step through the code itself that ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Causal <b>Learning</b> From Predictive Modeling for Observational Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931928/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7931928", "snippet": "Given the recent success of <b>machine</b> <b>learning</b>, specifically deep <b>learning</b>, in several applications (Goodfellow et al., ... This statistical <b>interpretability is similar</b> in spirit to traditional interpretability. This allows to answer questions, such as \u201cdoes BMI influence susceptibility to Covid?\u201d Moreover, it has been argued that developing an effective CBN for practical applications requires expert knowledge when data collection is cumbersome (Fenton and Neil, 2012). This applies to ...", "dateLastCrawled": "2021-12-09T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimal <b>Predictive Clustering</b> - Dimitris Bertsimas", "url": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-predictive-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-<b>predictive-clustering</b>.pdf", "snippet": "Table 1 Comparison of major <b>machine</b> <b>learning</b> methods relative to each other across the metrics of performance (out-of-sample R2), scalability and interpretability. 1 is the best, while 5 is the worst. Optimal <b>Predictive Clustering</b> 3 From Table 1, we observe all existing methods have weakness in at least one category. We therefore seek to design a method that has strong performance in all three categories at the same time. Optimal <b>Predictive Clustering</b> (OPC) is an algorithm that uses mixed ...", "dateLastCrawled": "2021-11-24T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reviewing Challenges of Predicting Protein Melting Temperature Change ...", "url": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "snippet": "Predicting the effects of mutations on protein stability is a key problem in fundamental and applied biology, still unsolved even for the relatively simple case of small, soluble, globular, monomeric, two-state-folder proteins. Many articles discuss the limitations of prediction methods and of the datasets used to train them, which result in low reliability for actual applications despite globally capturing trends. Here, we review these and other issues by analyzing one of the most detailed ...", "dateLastCrawled": "2022-02-03T02:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "In my view, a shor t coming of interpretable <b>machine</b> <b>learning</b> is that it assumes to a degree that the data being fed into the model is always going to be suitable for human interpretation. This is not necessarily the case. For instance, let\u2019s say that a company is trying to implement interpretable <b>machine</b> <b>learning</b> to devise a credit scoring model, whereby prospective credit card applications are classified as approved or rejected based on numerous features. It is often the case that such ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Breaking the interpretability barrier - a</b> method for interpreting deep ...", "url": "http://www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "isFamilyFriendly": true, "displayUrl": "www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o between performance and inter-pretability. Graph classi cation is normally a domain which requires the ap-plication of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to in-terpret complex models post-hoc (brie y reviewed in section2). However, most ...", "dateLastCrawled": "2021-09-22T17:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Discovering Discriminative Nodes for Classi\ufb01cation with Deep Graph ...", "url": "http://muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "isFamilyFriendly": true, "displayUrl": "muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o\ufb00 between performance and inter-pretability. Graph classi\ufb01cation is normally a domain which requires the appli-cation of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to interpret complex models post-hoc (brie\ufb02y reviewed in Sect.2). However ...", "dateLastCrawled": "2021-09-02T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Confronting Abusive Language Online: A Survey from the Ethical and ...", "url": "https://www.arxiv-vanity.com/papers/2012.12305/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2012.12305", "snippet": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this ...", "dateLastCrawled": "2021-10-13T19:21:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(interpretability)  is like +(reading a book)", "+(interpretability) is similar to +(reading a book)", "+(interpretability) can be thought of as +(reading a book)", "+(interpretability) can be compared to +(reading a book)", "machine learning +(interpretability AND analogy)", "machine learning +(\"interpretability is like\")", "machine learning +(\"interpretability is similar\")", "machine learning +(\"just as interpretability\")", "machine learning +(\"interpretability can be thought of as\")", "machine learning +(\"interpretability can be compared to\")"]}