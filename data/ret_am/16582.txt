{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Filtering <b>spam</b> with probabilities - The Tech Report", "url": "https://techreport.com/news/3970/filtering-spam-with-probabilities/", "isFamilyFriendly": true, "displayUrl": "https://techreport.com/news/3970", "snippet": "I mentioned baseline accuracy as what the dumbest <b>trigram</b> model would achieve, i.e. you were really dumb about picking the weights, selecting 1 for a <b>spam</b> word and 0 for a non-<b>spam</b> word. Anyways ...", "dateLastCrawled": "2022-01-13T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How do I Choose <b>the Best Linux\u00ae Spam Filter</b>?", "url": "https://www.easytechjunkie.com/how-do-i-choose-the-best-linux-spam-filter.htm", "isFamilyFriendly": true, "displayUrl": "https://www.easytechjunkie.com/how-do-i-choose-the-best-linux-<b>spam</b>-<b>filter</b>.htm", "snippet": "Bayesian <b>trigram</b> filters are employed by some <b>spam</b> filters, <b>like</b> the popular Linux\u00ae <b>spam</b> <b>filter</b> SpamAssassin, to analyze the structure of emails themselves. These filters use sophisticated algorithms to scrutinize the text of emails and determine if they exhibit patterns of sentence construction and word usage that are typically used by ...", "dateLastCrawled": "2021-12-22T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Email Privacy &amp; Anti-spam Law</b> - Legal Services India", "url": "http://www.legalservicesindia.com/article/107/Email-Privacy-&-Anti-spam-Law.html", "isFamilyFriendly": true, "displayUrl": "www.legalservicesindia.com/article/107/<b>Email-Privacy-&amp;-Anti-spam-Law</b>.html", "snippet": "Baysian <b>trigram</b> filters Disadvantage of the word model is that the number of &quot;words&quot; one encounters in email is logically unlimited.. Bayesian techniques[2] built on a word structure work . These all type of filters has already made in <b>spam</b> filtering techniques still lot many left to explain that we have not considered because it is not quite possible to defy each tool but these are the some specific <b>filter</b> techniques work on email clients so we have considered this as apart of our research ...", "dateLastCrawled": "2022-02-03T16:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Index-based Online Text Classification for SMS Spam Filtering</b>", "url": "https://www.researchgate.net/publication/273205753_Index-based_Online_Text_Classification_for_SMS_Spam_Filtering", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/273205753_Index-based_Online_Text...", "snippet": "<b>Like</b> email <b>spam</b>, the SMS <b>spam</b> problem can be approached with legal, economic or technical measures. Among the wide range of technical measures, Bayesian filters are playing a key role in stopping ...", "dateLastCrawled": "2021-12-11T20:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Fuzzy string matching with Trigram and Trigraphs</b> - Postgres OnLine Journal", "url": "https://www.postgresonline.com/journal/archives/169-Fuzzy-string-matching-with-Trigram-and-Trigraphs.html", "isFamilyFriendly": true, "displayUrl": "https://www.postgresonline.com/journal/archives/169-<b>Fuzzy-string-matching-with-Trigram</b>...", "snippet": "The % operator allows for using a GIST/GIN index and the similarity function allows for narrowing your <b>filter</b> similar to what levenshtein did for us in fuzzstrmatch. What do PostgreSQL trigrams look <b>like</b> . A text string is composed of n number of trigrams which in PostgreSQL is displayed as an array of 3 character text values stored which consist of all 3 character consecutive groups that can be formed from the text. You can inspect this with the show_trgm function. It&#39;s probably easiest to ...", "dateLastCrawled": "2022-02-03T10:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "N-<b>Gram Language Modelling with NLTK - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/n-gram-language-modelling-with-nltk/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/n-<b>gram-language-modelling-with-nltk</b>", "snippet": "<b>Like</b> Article. N-<b>Gram Language Modelling with NLTK</b>. Last Updated : 30 May, 2021. Language modeling is the way of determining the probability of any sequence of words. Language modeling is used in a wide variety of applications such as Speech Recognition, <b>Spam</b> filtering, etc. In fact, language modeling is the key aim behind the implementation of many state-of-the-art Natural Language Processing models. Methods of Language Modelings: Two types of Language Modelings: Statistical Language ...", "dateLastCrawled": "2022-01-30T17:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Spam</b> Filtering Techniques | BlogSpam.org", "url": "http://www.blogspam.org/spam-filtering-techniques/", "isFamilyFriendly": true, "displayUrl": "www.blog<b>spam</b>.org/<b>spam</b>-<b>filter</b>ing-techniques", "snippet": "At first blush, it would be reasonable to suppose that a set of hand-tuned and laboriously developed rules <b>like</b> those in SpamAssassin would predict <b>spam</b> more accurately than a scattershot automated approach. It turns out that this supposition is dead wrong. A statistical model basically just works better than a rule-based approach. As a side benefit, a Graham-style Bayesian <b>filter</b> is also simpler and faster than SpamAssassin.", "dateLastCrawled": "2021-12-20T15:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Python for <b>NLP: Developing an Automatic Text Filler using</b> N-Grams", "url": "https://stackabuse.com/python-for-nlp-developing-an-automatic-text-filler-using-n-grams/", "isFamilyFriendly": true, "displayUrl": "https://stackabuse.com/python-for-<b>nlp-developing-an-automatic-text-filler-using</b>-n-grams", "snippet": "Similarly, a sequence of 3 items is called a <b>trigram</b>, and so on. In order to understand N-Grams model, we first have to understand how the Markov chains work. Connection of N-Grams with Markov Chains. A Markov chain is a sequence of states. Consider a Markov system with 2 states, X and Y. In a Markov chain, you can either stay at one state or move to the other state. In our example, our states have the following behavior: The probability of moving from X to Y is 50% and similarly, the ...", "dateLastCrawled": "2022-01-28T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "artificial intelligence - What is the best way to <b>filter</b> <b>spam</b> with ...", "url": "https://stackoverflow.com/questions/3868643/what-is-the-best-way-to-filter-spam-with-javascript", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/3868643", "snippet": "In other words, I can&#39;t prevent <b>spam</b>; I can only <b>filter</b> it. Here is my attempt, so far, to compile a list of the various methods along with their shortcomings and benefits: Rule-based filters: What it does: &quot;Grades&quot; a message by assigning a point value to different criteria (i.e. all uppercase, all non-alphanumeric, etc.) Depending on the score, the message is discarded or kept. Benefits: Easy to implement; Mostly transparent; Shortcomings: Transparent- it&#39;s usually easy to reverse engineer ...", "dateLastCrawled": "2022-01-08T13:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Which language model would perform better for <b>spam</b> detection for a ...", "url": "https://www.quora.com/Which-language-model-would-perform-better-for-spam-detection-for-a-relatively-large-training-set-Smoothed-Unigram-or-Stupid-Backoff-with-unsmoothed-bigram-with-a-back-off-to-a-smoothed-unigram", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Which-language-model-would-perform-better-for-<b>spam</b>-detection-for...", "snippet": "Answer (1 of 3): The upsurge in the volume of unwanted emails called <b>spam</b> has created an intense need for the development of more dependable and robust antispam filters. Machine learning methods of recent are being used to successfully detect and <b>filter</b> <b>spam</b> emails. We present a systematic review...", "dateLastCrawled": "2022-01-24T16:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How do I Choose <b>the Best Linux\u00ae Spam Filter</b>?", "url": "https://www.easytechjunkie.com/how-do-i-choose-the-best-linux-spam-filter.htm", "isFamilyFriendly": true, "displayUrl": "https://www.easytechjunkie.com/how-do-i-choose-the-best-linux-<b>spam</b>-<b>filter</b>.htm", "snippet": "Bayesian <b>trigram</b> filters are employed by some <b>spam</b> filters, like the popular Linux\u00ae <b>spam</b> <b>filter</b> SpamAssassin, to analyze the structure of emails themselves. These filters use sophisticated algorithms to scrutinize the text of emails and determine if they exhibit patterns of sentence construction and word usage that are typically used by spammers. By eliminating the need for user-generated databases, this technique allows for a great deal more adaptability. Quite a few Linux\u00ae <b>spam</b> <b>filter</b> ...", "dateLastCrawled": "2021-12-22T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Filtering <b>spam</b> with probabilities - The Tech Report", "url": "https://techreport.com/news/3970/filtering-spam-with-probabilities/", "isFamilyFriendly": true, "displayUrl": "https://techreport.com/news/3970", "snippet": "I mentioned baseline accuracy as what the dumbest <b>trigram</b> model would achieve, i.e. you were really dumb about picking the weights, selecting 1 for a <b>spam</b> word and 0 for a non-<b>spam</b> word. Anyways ...", "dateLastCrawled": "2022-01-13T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "GitHub - avcourt/<b>spam</b>-<b>filter</b>: Naive Bayesian <b>spam</b> classifier", "url": "https://github.com/avcourt/spam-filter", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/avcourt/<b>spam</b>-<b>filter</b>", "snippet": "SpamFilter A naive Bayesian <b>spam</b> classifier in Ruby. This implementation is centred around a SpamFilter class which accepts a training directory path in its constructor. It is assumed that the training directory contains two sub-directories: <b>spam</b> and ham.The constructor also expects a string parameter (<b>trigram</b> or word-stem) to determine how to tokenize the messages.<b>trigram</b> uses all three-character consecutive sequences of each string contained in the message.word-stem uses suffix stripped ...", "dateLastCrawled": "2021-08-10T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "SpamED: A <b>Spam</b> E-<b>Mail Detection Approach Based on Phrase Similarity</b> ...", "url": "https://www.researchgate.net/publication/227728971_SpamED_A_Spam_E-Mail_Detection_Approach_Based_on_Phrase_Similarity", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/227728971_<b>Spam</b>ED_A_<b>Spam</b>_E-Mail_Detection...", "snippet": "The bigram and <b>trigram</b> phrase similarity between an incoming e-mail message and a previously marked <b>spam</b> were used in order to enhance the accuracy of <b>spam</b> detection in SpamED. 8 Most works on ...", "dateLastCrawled": "2021-10-13T13:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Fuzzy string matching with Trigram and Trigraphs</b> - Postgres OnLine Journal", "url": "https://www.postgresonline.com/journal/archives/169-Fuzzy-string-matching-with-Trigram-and-Trigraphs.html", "isFamilyFriendly": true, "displayUrl": "https://www.postgresonline.com/journal/archives/169-<b>Fuzzy-string-matching-with-Trigram</b>...", "snippet": "The % operator allows for using a GIST/GIN index and the similarity function allows for narrowing your <b>filter</b> <b>similar</b> to what levenshtein did for us in fuzzstrmatch. What do PostgreSQL trigrams look like . A text string is composed of n number of trigrams which in PostgreSQL is displayed as an array of 3 character text values stored which consist of all 3 character consecutive groups that can be formed from the text. You can inspect this with the show_trgm function. It&#39;s probably easiest to ...", "dateLastCrawled": "2022-02-03T10:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Detecting opinion spams and fake news using text classification - Ahmed ...", "url": "https://onlinelibrary.wiley.com/doi/10.1002/spy2.9", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1002/spy2.9", "snippet": "<b>Similar</b> to the results obtained in Experiment 1, linear-based classifiers (Linear SVM, SDG, and LR) achieved better results than nonlinear ones. However, nonlinear classifiers achieved good results too; DT achieved 89% accuracy. The highest accuracy was achieved using linear SVM, 92%. This classifier performs well no matter the number of feature values used. With the increase of n-gram (<b>trigram</b>, 4-gram), the accuracy of the algorithm also decreases.", "dateLastCrawled": "2021-12-10T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Spam</b> Filtering Techniques | BlogSpam.org", "url": "http://www.blogspam.org/spam-filtering-techniques/", "isFamilyFriendly": true, "displayUrl": "www.blog<b>spam</b>.org/<b>spam</b>-<b>filter</b>ing-techniques", "snippet": "When a message is received by an MTA, a distributed blacklist <b>filter</b> is called to determine whether the message is a known <b>spam</b>. These tools use clever statistical techniques for creating digests, so that spams with minor or automated mutations (or just different headers resulting from transport routes) do not prevent recognition of message identity. In addition, maintainers of distributed blacklist servers frequently create \u201choney-pot\u201d addresses specifically for the purpose of ...", "dateLastCrawled": "2021-12-20T15:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Python for <b>NLP: Developing an Automatic Text Filler using</b> N-Grams", "url": "https://stackabuse.com/python-for-nlp-developing-an-automatic-text-filler-using-n-grams/", "isFamilyFriendly": true, "displayUrl": "https://stackabuse.com/python-for-<b>nlp-developing-an-automatic-text-filler-using</b>-n-grams", "snippet": "In the script above, we create a Words <b>trigram</b> model. The process <b>is similar</b> to the one followed to use character trigrams. However, in the above script, we first tokenize our corpus into words. Next, we iterate through all the words and then join the current three words to form a <b>trigram</b>. After that, we check if the word <b>trigram</b> exists in the ngrams dictionary. If the <b>trigram</b> doesn&#39;t already exist, we simply insert it into the ngrams dictionary as a key. Finally, we append the list of words ...", "dateLastCrawled": "2022-01-28T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Which language model would perform better for <b>spam</b> detection for a ...", "url": "https://www.quora.com/Which-language-model-would-perform-better-for-spam-detection-for-a-relatively-large-training-set-Smoothed-Unigram-or-Stupid-Backoff-with-unsmoothed-bigram-with-a-back-off-to-a-smoothed-unigram", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Which-language-model-would-perform-better-for-<b>spam</b>-detection-for...", "snippet": "Answer (1 of 3): The upsurge in the volume of unwanted emails called <b>spam</b> has created an intense need for the development of more dependable and robust antispam filters. Machine learning methods of recent are being used to successfully detect and <b>filter</b> <b>spam</b> emails. We present a systematic review...", "dateLastCrawled": "2022-01-24T16:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Active Learning for Online Spam Filtering</b>", "url": "https://www.researchgate.net/publication/221055550_Active_Learning_for_Online_Spam_Filtering", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221055550_<b>Active_Learning_for_Online_Spam</b>...", "snippet": "<b>Spam</b> filtering is defined as a task trying to label emails with <b>spam</b> or ham in an online situation. The online feature requires the <b>spam</b> <b>filter</b> has a strong timely generalization and has a high ...", "dateLastCrawled": "2021-08-11T05:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Time-<b>efficient spam e-mail filtering using n-gram models</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0167865507002644", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167865507002644", "snippet": "Since <b>spam</b> filtering is <b>thought</b> as a kind of text classification, support ... (w i | C), otherwise As <b>can</b> be seen, <b>trigram</b> probabilities are favored when there is sufficient data in the training set. If this is not the case, bigram probabilities are used, and unigram probabilities are used only when no <b>trigram</b> and bigram <b>can</b> be found. It is still possible that the unigram probabilities may evaluate to zero for some words in the test data, which has the undesirable effect of making P(C\u2223E ...", "dateLastCrawled": "2021-11-05T05:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Cleaning up <b>SPAM</b> with NLP", "url": "http://meanmean.me/2020/12/21/Cleaning-Up-SPAM-with-NLP.html", "isFamilyFriendly": true, "displayUrl": "meanmean.me/2020/12/21/Cleaning-Up-<b>SPAM</b>-with-NLP.html", "snippet": "So I <b>thought</b> I would take a stab in creating a quick natural language processing (NLP) solution to see if I <b>can</b> do better. One way that I <b>can</b> do better is to not exclusively look at two different types of messages, <b>SPAM</b> and not <b>SPAM</b>. Instead, I <b>can</b> look at useful classes of messages that people <b>can</b> decided if they want to see or not. Content: Content Messages. RMT: Real Money Trade, messages for buying/selling items using real money. Merc: People offering to sell content using in-game ...", "dateLastCrawled": "2021-07-03T19:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) An Improved Machine Learning-Based Short Message Service <b>Spam</b> ...", "url": "https://www.researchgate.net/publication/342671564_An_Improved_Machine_Learning-Based_Short_Message_Service_Spam_Detection_System", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342671564_An_Improved_Machine_Learning-Based...", "snippet": "<b>spam</b> <b>filter</b> ha s been d eveloped and installed by mail . ... lowercase words, bigram and <b>trigram</b> of characters and . words bigra ms. Emai l filt ering algorit hms beca me . underperformed when us ...", "dateLastCrawled": "2021-12-04T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Sentiment analyzer using Convolutional Neural Network</b> - Digital Tesseract", "url": "https://digitaltesseract.com/sentiment-analyzer-using-convolutional-neural-network/", "isFamilyFriendly": true, "displayUrl": "https://digitaltesseract.com/<b>sentiment-analyzer-using-convolutional-neural-network</b>", "snippet": "Then 3 different kinds of 1D convolution of size two (bigram), three (<b>trigram</b>), and four (fourgram). 1D convolution is used because the width is the model and <b>filter</b> is applied along one dimension. We apply a certain number of each of them. After applying the activation function for each <b>filter</b>, the output is a vector. We will take the max of each of those vectors via Max pooling and concatenate. Apply a linear function (Dense layer). Finally, our classification task is done.", "dateLastCrawled": "2021-12-05T20:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Detecting opinion spams and fake news using text classification - Ahmed ...", "url": "https://onlinelibrary.wiley.com/doi/10.1002/spy2.9", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1002/spy2.9", "snippet": "They argued that a burst of reviews <b>can</b> be either due to the sudden popularity of the product or a <b>spam</b> attack. They built a network of reviewers that appear in different bursts and then represented it in a graph (Markov Random Field). Furthermore, using statistical methods, they classified reviewers as spammers or not. The authors relied on behavior features, such as the rating deviation and reviewer burstiness; all features were normalized to [0,1] for simplicity. They achieved 77.6% ...", "dateLastCrawled": "2021-12-10T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Cleaning up SPAM with NLP</b> | R-bloggers", "url": "https://www.r-bloggers.com/2020/12/cleaning-up-spam-with-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.r-bloggers.com/2020/12/<b>cleaning-up-spam-with-nlp</b>", "snippet": "So I <b>thought</b> I would take a stab in creating a quick natural language processing (NLP) solution to see if I <b>can</b> do better. One way that I <b>can</b> do better is to not exclusively look at two different types of messages, <b>SPAM</b> and not <b>SPAM</b>. Instead, I <b>can</b> look at useful classes of messages that people <b>can</b> decided if they want to see or not. Content: Content Messages. RMT: Real Money Trade, messages for buying/selling items using real money. Merc: People offering to sell content using in-game ...", "dateLastCrawled": "2021-08-12T13:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Dennis Merritt | Use of the</b> I <b>Ching in the Analytic Setting</b> ...", "url": "https://jungchicago.org/blog/dennis-merritt-use-of-the-i-ching-in-the-analytic-setting/", "isFamilyFriendly": true, "displayUrl": "https://jungchicago.org/blog/<b>dennis-merritt-use-of-the</b>-i-<b>ching-in-the-analytic-setting</b>", "snippet": "Jung <b>thought</b> of archetypes as forms of existence without time and space, ... within a <b>trigram</b>, its correspondences with other lines, etc.\u2013one gets closer to describing interactions of the basic energies of life and the natural world. In certain situations, the only connection I <b>can</b> make between the person\u2019s question and the answer from the I Ching is at the purely structural level as described in part III of Wilhelm. In such cases, every verbal description has a metaphoric base that ...", "dateLastCrawled": "2022-01-24T12:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "python - How do I build an efficient email <b>filter</b> against large ruleset ...", "url": "https://stackoverflow.com/questions/10214580/how-do-i-build-an-efficient-email-filter-against-large-ruleset-5000-and-growin", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/10214580", "snippet": "By finding similar emails we <b>can</b> then narrow down to a specific feature set to test on and get a positive match. Switching to a bayes <b>filter</b> which would also give us some machine learning capability to detect similar emails or changes to existing emails that would still match with a high enough probability to guess that they were the same thing ...", "dateLastCrawled": "2022-01-22T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "python - &#39;<b>Could not interpret input</b>&#39; error with Seaborn when plotting ...", "url": "https://stackoverflow.com/questions/32908315/could-not-interpret-input-error-with-seaborn-when-plotting-groupbys", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/32908315", "snippet": "The reason for the exception you are getting is that Program becomes an index of the dataframes df_mean and df_count after your group_by operation. If you wanted to get the factorplot from df_mean, an easy solution is to add the index as a column, In [7]: df_mean [&#39;Program&#39;] = df_mean.index In [8]: %matplotlib inline import seaborn as sns sns ...", "dateLastCrawled": "2022-01-27T15:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Why are CNNs used for NLP</b>? - Quora", "url": "https://www.quora.com/Why-are-CNNs-used-for-NLP", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Why-are-CNNs-used-for-NLP</b>", "snippet": "Answer (1 of 8): Text follow similar compositional structure as image i.e. characters form n-grams, stems, words, sentences etc. In this sense, CNNs <b>can</b> also be applied for text. Furthermore, research has proven that applying CNNs in NLP especially for text classification gives similar or better ...", "dateLastCrawled": "2022-01-22T05:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Applying Bayesian trigram filter model in spam identification</b> and its ...", "url": "https://www.researchgate.net/publication/252002052_Applying_Bayesian_trigram_filter_model_in_spam_identification_and_its_disposal", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/252002052_Applying_Bayesian_<b>trigram</b>_<b>filter</b>...", "snippet": "This paper introduces the <b>applying Bayesian trigram filter model in spam identification and its disposal</b>, the performance of the system basis on the new model is better than the system basis on ...", "dateLastCrawled": "2021-08-29T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Time-<b>efficient spam e-mail filtering using n-gram models</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0167865507002644", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167865507002644", "snippet": "A common n is three (hence the term <b>trigram</b>). ... ISP path, attached files, and so on. These data <b>can</b> be exploited by a <b>spam</b> <b>filter</b> to improve its final decision and are in fact used by current successful filters. There are various ways of incorporating such mechanisms within a content-based <b>filter</b> (Feinstein, 2004, Goodman, 2004, Haskins and Nielsen, 2005, Poteet, 2004). The earliest and still the most widely used mechanism is comparison of sender address with static lists: whitelists ...", "dateLastCrawled": "2021-11-05T05:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "SpamCop: A <b>Spam</b> Classification &amp; Organization Program", "url": "https://www.aaai.org/Papers/Workshops/1998/WS-98-05/WS98-05-017.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aaai.org/Papers/Workshops/1998/WS-98-05/WS98-05-017.pdf", "snippet": "determine whether or not a message is likely to be a <b>spam</b>. <b>Compared</b> with keyword-spotting rules, the probabilistic ap-proach taken in SpamCop not only offers high accuracy, but also overcomes the brittleness suffered by the keyword spot-ting approach. Introduction With the explosive growth of the Internet, so too comes the proliferation of spams. Spammers collect a plethora of e-mail addresses without the consent of the owners of these addresses. Then, unsolicited advertising or even of ...", "dateLastCrawled": "2021-10-28T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Simple <b>NLP in Python with TextBlob: N-Grams Detection</b>", "url": "https://stackabuse.com/simple-nlp-in-python-with-textblob-n-grams-detection/", "isFamilyFriendly": true, "displayUrl": "https://stackabuse.com/simple-<b>nlp-in-python-with-textblob-n-grams-detection</b>", "snippet": "For instance, a <b>trigram</b> model (with N = 3) will predict the next word in a string based on the preceding two words as N-1 = 2. The other cases of implementation of N-grams models in the industry <b>can</b> be detection of plagiarism, where N-grams obtained from two different texts are <b>compared</b> with each other to figure out the degree of similarity of the analysed documents.", "dateLastCrawled": "2022-01-31T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Detecting opinion spams and fake news using text classification - Ahmed ...", "url": "https://onlinelibrary.wiley.com/doi/10.1002/spy2.9", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1002/spy2.9", "snippet": "The opinion <b>spam</b> problem was formulated for the first time a few years ago, but it has quickly become a growing research area due to the abundance of user-generated content. It is now easy for anyone to either write fake reviews or write fake news on the web. The biggest challenge is the lack of an efficient way to tell the difference between a real review and a fake one; even humans are often unable to tell the difference. In this paper, we introduce a new n-gram model to detect ...", "dateLastCrawled": "2021-12-10T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Which language model would perform better for <b>spam</b> detection for a ...", "url": "https://www.quora.com/Which-language-model-would-perform-better-for-spam-detection-for-a-relatively-large-training-set-Smoothed-Unigram-or-Stupid-Backoff-with-unsmoothed-bigram-with-a-back-off-to-a-smoothed-unigram", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Which-language-model-would-perform-better-for-<b>spam</b>-detection-for...", "snippet": "Answer (1 of 3): The upsurge in the volume of unwanted emails called <b>spam</b> has created an intense need for the development of more dependable and robust antispam filters. Machine learning methods of recent are being used to successfully detect and <b>filter</b> <b>spam</b> emails. We present a systematic review...", "dateLastCrawled": "2022-01-24T16:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Cleaning up <b>SPAM</b> with NLP", "url": "http://meanmean.me/2020/12/21/Cleaning-Up-SPAM-with-NLP.html", "isFamilyFriendly": true, "displayUrl": "meanmean.me/2020/12/21/Cleaning-Up-<b>SPAM</b>-with-NLP.html", "snippet": "Cleaning up <b>SPAM</b> with NLP. Dec 21, 2020. Hey, it&#39;s the holidays. Time to take some PTO/Leave, hang out with family, relax, and work on some side projects. One of the many projects I finally have time for is removal of &#39;<b>SPAM</b>&#39; messages from one of the games I play from time-to-time. This allows me to play with some NLP and solve some fun problems, like how to score a model quickly while only using a few mb of RAM in the scripting language Lua. As someone new to Lua, and only vaguely familiar ...", "dateLastCrawled": "2021-07-03T19:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Cleaning up SPAM with NLP</b> | R-bloggers", "url": "https://www.r-bloggers.com/2020/12/cleaning-up-spam-with-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.r-bloggers.com/2020/12/<b>cleaning-up-spam-with-nlp</b>", "snippet": "Through this blog post we have gone through quite a journey. We started off with a problem of message <b>spam</b>, used our ML insights to come up with a quick model, and produced a meaningful solution. The model attains a 95% accuracy rate for all messages, and fairly good TPR and FPR rates on a per category basis.", "dateLastCrawled": "2021-08-12T13:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Modeling the Helpful Opinion Mining of Online Consumer Reviews as a ...", "url": "https://aclanthology.org/O14-3002.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/O14-3002.pdf", "snippet": "and to <b>filter</b> out the unhelpful reviews, no matter whether they are positive or negative. Figure 1. A clip image of an Amazon.com customer review. The paper is organized as follows. Section 2 describes the related works. Section 3 describes the features that <b>can</b> be used to classify the reviews as helpful or unhelpful. Section . Modeling the Helpful Opinion Mining of 19 Online Consumer Reviews as a Classification Problem 4 describes the data collection of this study. Section 5 reports and ...", "dateLastCrawled": "2021-09-30T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to do data integration, BRD example (part3) - DataPlatform Franchising", "url": "http://datapfranc.github.io/misc/brd_di_part3/", "isFamilyFriendly": true, "displayUrl": "datapfranc.github.io/misc/brd_di_part3", "snippet": "We <b>can</b> restrict comparison only among the m reviews done on same Work. Out of the mXm possible pairs, we ignore same review pair (r1,r1 --where review is <b>compared</b> to itself), and only keep one pair of the same pair (r1,r2 and r2,r1 --where only ordering changes). This results to m choose 2) pair combination.", "dateLastCrawled": "2021-11-01T07:37:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "N-gram language models. Part 1: The <b>unigram</b> model | by Khanh Nguyen ...", "url": "https://medium.com/mti-technology/n-gram-language-model-b7c2fc322799", "isFamilyFriendly": true, "displayUrl": "https://medium.com/mti-technology/n-gram-language-model-b7c2fc322799", "snippet": "For example, \u201cstatistics\u201d is a <b>unigram</b> (n = 1), \u201c<b>machine</b> <b>learning</b>\u201d is a bigram (n = 2), \u201cnatural language processing\u201d is a <b>trigram</b> (n = 3), and so on. For longer n-grams, people just ...", "dateLastCrawled": "2022-02-03T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b> Lecture 18 - Computer Vision", "url": "https://www.vision.rwth-aachen.de/media/course/WS/2019/machine-learning/ml19-part18-word-embeddings.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.vision.rwth-aachen.de/media/course/WS/2019/<b>machine</b>-<b>learning</b>/ml19-part18...", "snippet": "<b>Machine</b> <b>Learning</b> \u2013Lecture 18 Word Embeddings ... \u2022 Possible solution: The <b>trigram</b> (n-gram) method Take huge amount of text and count the frequencies of all triplets (n-tuples) of words. Use those frequencies to predict the relative probabilities of words given the two previous words State-of-the-art until not long ago... 15 Slide adapted from Geoff Hinton B. Leibe. gng 19 Problems with N-grams \u2022 Problem: Scalability We cannot easily scale this to large N. The number of possible ...", "dateLastCrawled": "2021-08-26T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> Lecture 18 - Computer Vision", "url": "https://www.vision.rwth-aachen.de/media/course/WS/2019/machine-learning/ml19-part18-word-embeddings-6on1.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.vision.rwth-aachen.de/media/course/WS/2019/<b>machine</b>-<b>learning</b>/ml19-part18...", "snippet": "<b>Machine</b> <b>Learning</b> \u2013Lecture 18 Word Embeddings ... \u2022 Possible solution: The <b>trigram</b> (n-gram) method Take huge amount of text and count the frequencies of all triplets (n-tuples) of words. Use those frequencies to predict the relative probabilities of words given the two previous words State-of-the-art until not long ago... 15 Slide adapted from Geoff Hinton B. Leibe ng \u201819 Problems with N-grams \u2022 Problem: Scalability We cannot easily scale this to large N. The number of possible ...", "dateLastCrawled": "2021-11-28T00:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Structuring Terminology using <b>Analogy</b>-Based <b>Machine</b> <b>learning</b>", "url": "https://www.researchgate.net/publication/266388912_Structuring_Terminology_using_Analogy-Based_Machine_learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/266388912_Structuring_Terminology_using...", "snippet": "PDF | On Jan 1, 2005, Vincent Claveau and others published Structuring Terminology using <b>Analogy</b>-Based <b>Machine</b> <b>learning</b> | Find, read and cite all the research you need on ResearchGate", "dateLastCrawled": "2021-12-13T18:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Improving sequence segmentation learning by predicting trigrams</b>", "url": "https://www.researchgate.net/publication/220799957_Improving_sequence_segmentation_learning_by_predicting_trigrams", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220799957_Improving_sequence_segmentation...", "snippet": "We present two <b>machine</b> <b>learning</b> ap-proaches to information extraction from semi-structured documents that can be used if no annotated training data are available but there does exist a database ...", "dateLastCrawled": "2021-11-08T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Gensim Tutorial - A Complete Beginners Guide - <b>Machine</b> <b>Learning</b> Plus", "url": "https://www.machinelearningplus.com/nlp/gensim-tutorial/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machinelearning</b>plus.com/nlp/gensim-tutorial", "snippet": "Gensim Tutorial \u2013 A Complete Beginners Guide. October 16, 2018. Selva Prabhakaran. Gensim is billed as a Natural Language Processing package that does \u2018Topic Modeling for Humans\u2019. But it is practically much more than that. It is a leading and a state-of-the-art package for processing texts, working with word vector models (such as ...", "dateLastCrawled": "2022-02-02T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "8.3. Language Models and the Dataset \u2014 Dive into Deep <b>Learning</b> 0.17.2 ...", "url": "http://d2l.ai/chapter_recurrent-neural-networks/language-models-and-dataset.html", "isFamilyFriendly": true, "displayUrl": "d2l.ai/chapter_recurrent-neural-networks/language-models-and-dataset.html", "snippet": "<b>Learning</b> a Language Model ... The probability formulae that involve one, two, and three variables are typically referred to as unigram, bigram, and <b>trigram</b> models, respectively. In the following, we will learn how to design better models. 8.3.3. Natural Language Statistics\u00b6 Let us see how this works on real data. We construct a vocabulary based on the time <b>machine</b> dataset as introduced in Section 8.2 and print the top 10 most frequent words. mxnet pytorch tensorflow. import random from ...", "dateLastCrawled": "2022-02-03T05:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Evaluation of an <b>NLP</b> model \u2014 latest benchmarks | by Ria Kulshrestha ...", "url": "https://towardsdatascience.com/evaluation-of-an-nlp-model-latest-benchmarks-90fd8ce6fae5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/evaluation-of-an-<b>nlp</b>-model-latest-benchmarks-90fd8ce6fae5", "snippet": "To penalize the last two scenarios, we use a combination of unigram, bigram, <b>trigram</b>, and n-gram by multiplying them. Using n-grams helps us in capturing the ordering of a sentence to some extent \u2014 S3 scenario. We also cap the number of times to count each word based on the highest number of times it appears in any reference sentence, which helps us avoid unnecessary repetition of words \u2014 S4 scenario.", "dateLastCrawled": "2022-01-28T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> <b>Learning</b> MCQ.pdf - CHAPTER 1 1. <b>Machine</b> <b>learning</b> is _ field. 1 ...", "url": "https://www.coursehero.com/file/88144926/Machine-Learning-MCQpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/88144926/<b>Machine</b>-<b>Learning</b>-MCQpdf", "snippet": "<b>Machine</b> <b>learning</b> is _ field. 1. Inter-disciplinary 2. Single 3. Multi-disciplinary 4. All of the above Ans: <b>Machine</b> <b>Learning</b> MCQ.pdf - CHAPTER 1 1. <b>Machine</b> <b>learning</b> is... School Assam Engineering College; Course Title CS 123; Uploaded By ElderCoyote1051. Pages 19 This preview shows page 1 - 5 out of 19 pages. Students who viewed this also studied. Dr. A.P.J. Abdul Kalam Technical University \u2022 CS 8. <b>Machine</b> <b>Learning</b> MCQ.pdf. <b>Machine</b> <b>Learning</b>; correct option; University Academy www ...", "dateLastCrawled": "2022-02-02T21:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How are N-<b>grams used in machine learning? - Quora</b>", "url": "https://www.quora.com/How-are-N-grams-used-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-are-N-<b>grams-used-in-machine-learning</b>", "snippet": "Answer (1 of 5): Consider a typical <b>Machine</b> <b>Learning</b> problem where you want classify documents (e.g. news documents) to their mian categories (sports, politics, media, etc.) Any classifier using a supervised approach will need features from a labeled training set to start <b>learning</b> the difference...", "dateLastCrawled": "2022-01-10T05:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>PostgreSQL: More performance for LIKE</b> and ILIKE statements", "url": "https://www.cybertec-postgresql.com/en/postgresql-more-performance-for-like-and-ilike-statements/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>cybertec</b>-postgresql.com/en/<b>postgresql-more-performance-for-like</b>-and-ilike...", "snippet": "<b>Machine</b> <b>Learning</b>; Big Data Analytics; Contact; <b>PostgreSQL: More performance for LIKE</b> and ILIKE statements. Posted on 2020-07-21 by Hans-J\u00fcrgen Sch\u00f6nig. LIKE and ILIKE are two fundamental SQL features. People use those things all over the place in their application and therefore it makes sense to approach the topic from a performance point of view. What can PostgreSQL do to speed up those operations and what can be done in general to first understand the problem and secondly to achieve ...", "dateLastCrawled": "2022-02-02T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "I Ching Book Of Changes [42m7xpr8l421]", "url": "https://vbook.pub/documents/i-ching-book-of-changes-42m7xpr8l421", "isFamilyFriendly": true, "displayUrl": "https://vbook.pub/documents/i-ching-book-of-changes-42m7xpr8l421", "snippet": "I Ching Book Of Changes [42m7xpr8l421]. THEBOOKOFCHANGESAND THEUNCHANGINGTRUTHBY WA-CHING/VISEVEN~TARCOMMUNICATIONSSANTA MONICA To obtain information about the ...", "dateLastCrawled": "2022-01-16T19:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Incredible Shared Dream Synchronicity</b>! | Divine Cosmos", "url": "https://divinecosmos.com/davids-blog/520-shared-dream/comment-page-1/", "isFamilyFriendly": true, "displayUrl": "https://divinecosmos.com/davids-blog/520-shared-dream/comment-page-1", "snippet": "Obviously, the greater message was about an opening of the heart. <b>Learning</b> to respect each other and live together, in peace, on the planet. It very much is geared towards the Illuminati \u2014 or at least certain elements of them who are able to realize that all biological human life should stick together. We all share a common lineage. We are One. All that karma, pending in future lifetimes and already well on its way as the old systems crumble to dust, can be alleviated by making this shift ...", "dateLastCrawled": "2022-01-21T23:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "I Ching Book Of Changes [j1w9ez5x58op]", "url": "https://vbook.pub/documents/i-ching-book-of-changes-j1w9ez5x58op", "isFamilyFriendly": true, "displayUrl": "https://vbook.pub/documents/i-ching-book-of-changes-j1w9ez5x58op", "snippet": "i ching book of changes [j1w9ez5x58op]. i1 1i ii i1 11 ii ii ii 1 thebookofchanges and the unchanging truthby wa-ching /viseven~tar communicationssanta monica t...", "dateLastCrawled": "2021-12-28T11:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Word Prediction Techniques for User Adaptation and Sparse Data ...", "url": "https://www.academia.edu/6371572/Word_Prediction_Techniques_for_User_Adaptation_and_Sparse_Data", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/6371572/Word_Prediction_Techniques_for_User_Adaptation_and...", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-22T01:23:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(trigram)  is like +(spam filter)", "+(trigram) is similar to +(spam filter)", "+(trigram) can be thought of as +(spam filter)", "+(trigram) can be compared to +(spam filter)", "machine learning +(trigram AND analogy)", "machine learning +(\"trigram is like\")", "machine learning +(\"trigram is similar\")", "machine learning +(\"just as trigram\")", "machine learning +(\"trigram can be thought of as\")", "machine learning +(\"trigram can be compared to\")"]}