{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding <b>Knowledge Distillation</b> - Ramesh&#39;s Blog", "url": "https://ramesharvind.github.io/posts/deep-learning/knowledge-distillation/", "isFamilyFriendly": true, "displayUrl": "https://ramesharvind.github.io/posts/deep-learning/<b>knowledge-distillation</b>", "snippet": "An <b>Analogy</b>. This training procedure also has a nice <b>analogy</b> of student-teacher relationship between the two models. If you consider a textbook, the student trying to understand it by themselves might prove too difficult. A teacher who has digested the contents of the textbook better will have an easier time explaining the nuances of the textbook to a student. Here the textbook represents the dataset and the student/teacher to be the smaller/larger models respectively. The additional <b>loss</b> ...", "dateLastCrawled": "2022-01-19T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Exploring quantum perceptron and quantum neural network structures with ...", "url": "https://link.springer.com/article/10.1007/s42484-021-00058-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42484-021-00058-6", "snippet": "The solid lines in the \u201c<b>Loss</b> curve\u201d n Fig. 2 show the <b>loss</b> of the two students that correspond to these particular prediction maps, where Student - Re-uploading achieves a much lower <b>loss</b>. If we use the binary labels of the teacher and train again the students we reach the accuracy score approximately equal to 0.9 compared to 0.8 for the QP. Both students have a high accuracy score, since the topology of the prediction maps of the students and the teacher with binary labels are very ...", "dateLastCrawled": "2022-02-03T05:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is a <b>teacher student model in a Convolutional neural network</b>? - Quora", "url": "https://www.quora.com/What-is-a-teacher-student-model-in-a-Convolutional-neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-a-<b>teacher-student-model-in-a-Convolutional-neural-network</b>", "snippet": "Answer (1 of 3): Not a model, but a training method, and not limited to CNNs. Suppose that someone trains a classifier on lots of labelled data, and that the resulting model is too large for your purposes; you can feed the teacher and student some data and train the student on the output of the t...", "dateLastCrawled": "2022-02-03T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The impact of the teachers\u2019 non-verbal communication on success in teaching", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5346168/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5346168", "snippet": "This study, <b>like</b> any other research, had some limitations as follows: - Lack of sufficient studies focusing on the effect and dimensions of non-verbal communication; hence, we could not generalize their methods and results. It seems that this lies in the lack of awareness about the positive impact of non-verbal communication as used by the instructors. - Lack of enough research on the non-verbal communication skills and practice in teaching. Recommendations for further research: Considering ...", "dateLastCrawled": "2022-02-02T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "29 Inspiring Similes &amp; Metaphors about Learning that Pop!", "url": "https://helpfulprofessor.com/metaphors-for-learning/", "isFamilyFriendly": true, "displayUrl": "https://helpfulprofessor.com/metaphors-for-learning", "snippet": "Related: 19 Metaphors about Teaching and Teachers Related: 12 Metaphors about Students Related: 23 Metaphors about School and Education Inspiring Metaphors for Learning 1. A journey of 1000 miles starts with a single step. This metaphor means that a student who wants to learn something big (<b>like</b> a new language, or getting a degree) must start somewhere: so go out and start learning.", "dateLastCrawled": "2022-02-02T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>A Different Kind of Covenant</b> | <b>Political Theology Network</b>", "url": "https://politicaltheology.com/a-different-kind-of-covenant/", "isFamilyFriendly": true, "displayUrl": "https://politicaltheology.com/<b>a-different-kind-of-covenant</b>", "snippet": "The <b>analogy</b> of husband-wife is in connection to the old covenant, while the <b>teacher-student</b> <b>analogy</b> is borrowed from wisdom traditions to refer to the covenant relationship in the new covenant. The newness in the covenant does not presuppose a new heart or new spirit, as envisioned in Ezekiel 11:19-20; 18:31; and Isaiah 42:9.", "dateLastCrawled": "2022-01-25T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[Knowledge Distillation] <b>Distilling the Knowledge</b> in a Neural Network ...", "url": "https://towardsdatascience.com/paper-summary-distilling-the-knowledge-in-a-neural-network-dc8efd9813cc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/paper-summary-<b>distilling-the-knowledge</b>-in-a-neural...", "snippet": "The <b>analogy</b> given is that of a larva and\u2026 Get started. Open in app. Sign in. Get started. Follow. 617K Followers \u00b7 Editors&#39; Picks Features Deep Dives Grow Contribute. About. Get started. Open in app [Knowledge Distillation] <b>Distilling the Knowledge</b> in a Neural Network. Kapil Sachdeva. Jun 30, 2020 \u00b7 7 min read. Photo by Aw Creative on Unsplash. Note \u2014 There is also a YouTube video explaining this paper. Problem(s) addressed. The authors start the paper with a very interesting <b>analogy</b> ...", "dateLastCrawled": "2022-01-30T21:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Distilling the <b>Knowledge</b> in a Neural Network | by Kelvin | Towards Data ...", "url": "https://towardsdatascience.com/distilling-knowledge-in-neural-network-d8991faa2cdc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/distilling-<b>knowledge</b>-in-neural-network-d8991faa2cdc", "snippet": "SOTA models <b>like</b> VGG16/19, ResNet50 have 138+ million and 23+ million parameters respectively. Deploying these models on the edge is infeasible. Edge devices such as smartphones and I o T sensors are resource-constrained devices where it is not possible to perform training or real-time inference without impacting the device performance. Hence, research has been focused on compressing large models into a small and compact model with minimal to zero performance <b>loss</b> when deploying on the edge ...", "dateLastCrawled": "2022-01-29T16:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>The Old Man and the Sea</b> pages 1-18 <b>Summary and Analysis</b> | GradeSaver", "url": "https://www.gradesaver.com/the-old-man-and-the-sea/study-guide/summary-pages-1-18", "isFamilyFriendly": true, "displayUrl": "https://www.gradesaver.com/<b>the-old-man-and-the-sea</b>/study-guide/summary-pages-1-18", "snippet": "But he knew he had attained it and he knew it was not disgraceful and it carried no <b>loss</b> of true pride&quot; (14). The two gather Santiago&#39;s things from his boat and go to the old man&#39;s house. His house is a very simple shack with a bed, table, and chair on a dirt floor. There are also religious pictures and a tinted photograph on the wall, relics of his wife. The picture that used to hang on the wall of Santiago&#39;s wife had been taken down, since it made him too lonely to look at it. At the house ...", "dateLastCrawled": "2022-01-31T12:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "21 <b>Quotes</b> about Planting Seeds for Spiritual Growth ... - Healing Brave", "url": "https://healingbrave.com/blogs/all/quotes-about-planting-seeds-growth-beginnings", "isFamilyFriendly": true, "displayUrl": "https://healingbrave.com/blogs/all/<b>quotes</b>-about-planting-seeds-growth-beginnings", "snippet": "I <b>like</b> your version of similar sentiment; \u201cYou never know what part of your story will be part of someone else\u2019s healing.\u201d \u2013 Thank you. \u201cLife doesn\u2019t accommodate you; it shatters you.\u201d \u2013 So we pick up the pieces and try some more. \u201cA seed knows how to wait\u2026a seed is alive while it waits.\u201d We must give the seeds time and patience and some care. They will bloom eventually.", "dateLastCrawled": "2022-02-02T05:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding <b>Knowledge Distillation</b> - Ramesh&#39;s Blog", "url": "https://ramesharvind.github.io/posts/deep-learning/knowledge-distillation/", "isFamilyFriendly": true, "displayUrl": "https://ramesharvind.github.io/posts/deep-learning/<b>knowledge-distillation</b>", "snippet": "The student\u2019s <b>loss</b> function would also be the cross entropy <b>loss</b> with the aforementioned KL-divergence <b>loss</b> between the students outputs and the teacher\u2019s outputs. A simple description of the KL-divergence is that it measures the distance between two distributions (here the distributions being the class probabilities of the student/teacher). By minimizing the KL-div <b>loss</b>, we are teaching the student to make <b>similar</b> predictions to the teacher.", "dateLastCrawled": "2022-01-19T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Madhya Pradesh 2020-21 NTSE Stage 1 <b>Answer Key &amp; Question Paper With</b> ...", "url": "https://byjus.com/jee/ntse-madhya-pradesh-2020-21-stage-1-answer-key-and-question-paper-with-solutions/", "isFamilyFriendly": true, "displayUrl": "https://byjus.com/jee/ntse-madhya-pradesh-2020-21-stage-1-answer-key-and-question...", "snippet": "Answer: (a) Arrange the data set in the ascending order: 14, 14, 14, 14, 17, 18, 18, 18, 22, 23, 25, 28. There are a total of 12 numbers. So, the average of the numbers in 12 / 2 = 6 th and 12 / 2 + 1 = 7 th rank will be the median. Median = 18 + 18 / 2 = 18. The number 14 has the highest frequency of occurrence.", "dateLastCrawled": "2022-01-30T09:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Distilling the <b>Knowledge</b> in a Neural Network | by Kelvin | Towards Data ...", "url": "https://towardsdatascience.com/distilling-knowledge-in-neural-network-d8991faa2cdc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/distilling-<b>knowledge</b>-in-neural-network-d8991faa2cdc", "snippet": "A simple <b>analogy</b> is that a student with a small and compact brain studying for an exam tries to absorb as much information as possible from the teacher. However the teacher just teaches everything, the student not knowing which questions will come out in the exam tries its best to absorb everything. This is where the compression takes place by distilling the <b>knowledge</b> from the teacher into the student. Fig 1. Teacher model distilling <b>knowledge</b> to Student model. Before distilling <b>knowledge</b> ...", "dateLastCrawled": "2022-01-29T16:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Student-Teacher Oneness: A Storage-Efficient Approach That Improves ...", "url": "https://openaccess.thecvf.com/content/ICCV2021W/HTCV/papers/Zheng_Student-Teacher_Oneness_A_Storage-Efficient_Approach_That_Improves_Facial_Expression_Recognition_ICCVW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021W/HTCV/papers/Zheng_Student-Teacher...", "snippet": "The <b>analogy</b> is that the students and teacher are Oneness, where students are the smaller individual and to-gether form a more powerful larger collection. Individual (student) absorbs knowledge from the collection (teacher), and the teacher grows out from students. The student network is sampled by randomly skipping some portions of the full network during the forward pass. In this case, there can be exponentially many student net-works to be generated. By exploiting the dynamic archi-tecture ...", "dateLastCrawled": "2022-01-29T09:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "[Knowledge Distillation] <b>Distilling the Knowledge</b> in a Neural Network ...", "url": "https://towardsdatascience.com/paper-summary-distilling-the-knowledge-in-a-neural-network-dc8efd9813cc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/paper-summary-<b>distilling-the-knowledge</b>-in-a-neural...", "snippet": "The authors start the paper with a very interesting <b>analogy</b> to explain the notion that the requirements for the training &amp; inference could be very different. The <b>analogy</b> given is that of a larva and\u2026 Get started. Open in app. Sign in. Get started. Follow. 617K Followers \u00b7 Editors&#39; Picks Features Deep Dives Grow Contribute. About. Get started. Open in app [Knowledge Distillation] <b>Distilling the Knowledge</b> in a Neural Network. Kapil Sachdeva. Jun 30, 2020 \u00b7 7 min read. Photo by Aw Creative ...", "dateLastCrawled": "2022-01-30T21:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Relationships Between Student Perception of Teacher-Student Relations</b> ...", "url": "https://link.springer.com/article/10.1007/s10763-015-9669-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10763-015-9669-7", "snippet": "<b>Teacher-student</b> relations have a significant correlation with student motivation, academic performance and discipline. For example, the meta-analysis by Hattie (2009) revealed an effect size of d = 0.72 for the effect of relations on achievement, and the meta-analysis by Finn, Schrodt, Witt, Elledge, Jernberg &amp; Larson (Communication Education, 58(4), 516\u2013537, 2009) showed a correlation of 0.55 between the perceived care by teachers and student achievement. These were established by ...", "dateLastCrawled": "2022-02-03T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Knowledge Distillation and Student-Teacher Learning</b> for Visual ...", "url": "https://www.researchgate.net/publication/340618239_Knowledge_Distillation_and_Student-Teacher_Learning_for_Visual_Intelligence_A_Review_and_New_Outlooks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/340618239_Knowledge_Distillation_and_Student...", "snippet": "<b>Similar</b> information <b>loss</b> happens in. IRG [18], where the teacher\u2019s feature space is transformed. to a graph representation with vertices and edges where. the relationship matrices are calculated ...", "dateLastCrawled": "2022-01-04T02:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Analogous Pair Selection Questions and Answers: Online MCQs", "url": "https://careericons.com/verbal-reasoning/analogy/analogous-pair-selection/5-1/", "isFamilyFriendly": true, "displayUrl": "https://careericons.com/verbal-reasoning/<b>analogy</b>/analogous-pair-selection/5-1", "snippet": "Type 1: Analogous Pair Selection questions based problems on <b>Analogy</b>, In such type of problems, a pair of words is given, followed by four pairs of words as option. The candidate is required to pick the pair in which the words bear the same relationship to each other as the words of the given pair do. Examples given below will give you a better ...", "dateLastCrawled": "2022-01-18T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Letter : word - <b>Analogy</b> Quiz..", "url": "https://careericons.com/verbal-quiz/analogous-pair-selection/shortcuts-discussed-13/", "isFamilyFriendly": true, "displayUrl": "https://careericons.com/verbal-quiz/analogous-pair-selection/shortcuts-discussed-13", "snippet": "type 5 <b>similar</b> <b>analogy</b>. type 6 double <b>analogy</b>. type 7 multiple <b>analogy</b>. type 1 analogous pair selection Shortcuts \u00bb type 1 analogous pair selection Online Quiz \u00bb Discuss Form. Enter your ideas. First name* Valid first name is required. Email (Optional) Please enter a valid email address. Submit Your Shortcut. Your genuine shortcut will be useful for all users! Each and every shortcut will be uploaded to the question after approval. Some Example Questions and Answers for analogous pair ...", "dateLastCrawled": "2022-01-27T16:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "29 Inspiring Similes &amp; Metaphors about Learning that Pop!", "url": "https://helpfulprofessor.com/metaphors-for-learning/", "isFamilyFriendly": true, "displayUrl": "https://helpfulprofessor.com/metaphors-for-learning", "snippet": "<b>Similar</b> to the \u2018journey of 1000 miles\u2019 metaphor, this one shows that learning happens one step (or in this case, brick) at a time. I like in this metaphor that you get something at the end: a strong, sturdy building built on solid foundations of knowledge. 3. A new idea is the spark that lights an eternal flame.", "dateLastCrawled": "2022-02-02T03:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Improving students&#39; relationships with teachers</b>", "url": "https://www.apa.org/education-career/k12/relationships", "isFamilyFriendly": true, "displayUrl": "https://<b>www.apa.org</b>/education-career/k12/relationships", "snippet": "Negative <b>teacher-student</b> relationships <b>can</b> amplify when teachers show irritability and anger toward several or many of the students in the classroom. In these types of classrooms, teachers may find themselves resorting to yelling and harsh punitive control. <b>Teacher-student</b> communications may appear sarcastic or disrespectful. Student victimization or bullying may be common occurrences in such negative classrooms (Pianta, La Paro, &amp; Hamre, 2006). Negative <b>teacher-student</b> relationships are ...", "dateLastCrawled": "2022-02-02T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Relationships Between Student Perception of Teacher-Student Relations</b> ...", "url": "https://link.springer.com/article/10.1007/s10763-015-9669-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10763-015-9669-7", "snippet": "<b>Teacher-student</b> relations have a significant correlation with student motivation, academic performance and discipline. For example, the meta-analysis by Hattie (2009) revealed an effect size of d = 0.72 for the effect of relations on achievement, and the meta-analysis by Finn, Schrodt, Witt, Elledge, Jernberg &amp; Larson (Communication Education, 58(4), 516\u2013537, 2009) showed a correlation of 0.55 between the perceived care by teachers and student achievement. These were established by ...", "dateLastCrawled": "2022-02-03T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "85 <b>The Principle of Trust &amp; Honesty</b> \u2013 Freeread", "url": "https://freeread.com/85-the-principle-of-trust-honesty/", "isFamilyFriendly": true, "displayUrl": "https://freeread.com/85-<b>the-principle-of-trust-honesty</b>", "snippet": "The Principle of <b>Analogy</b> or The Law of Correspondences. The Oneness Principle; The <b>Teacher-Student</b> Relationship; The Name of Christ; The Ring Pass Not; Good and Evil; Principles 11 &amp; 12 ; Initiation; Crystallization; Relative Perfection; The Principle of Correction; Principle 18: Decision; The Principle of the Journey; Principles of Joy and Peace; Judgment and/or Discernment; The Two Paths; Energy Follows <b>Thought</b>; The Satellite Principle; Principles 26 &amp; 27; Principle 28: The Observer ...", "dateLastCrawled": "2022-02-01T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>24 Rambling Thoughts - Cognitive Behavior</b>", "url": "https://cognitivebehaviormanagement.com/theory/rambling-thoughts/", "isFamilyFriendly": true, "displayUrl": "https://cognitivebehaviormanagement.com/theory/<b>rambling-thoughts</b>", "snippet": "Since the Cognitive Structures consist of relatively stable belief themes, different but similar components reoccur with people who are in a continuous relationship [e.g., parent \u2013 child. man \u2013 woman, <b>teacher \u2013 student</b>, etc. The above if read from left to right and then down, shows how a dance <b>can</b> get out of hand based on the \u2018inner logic\u2019 of the partners.", "dateLastCrawled": "2022-02-02T18:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How Teachers Build Great <b>Relationships With Students</b>", "url": "https://www.thoughtco.com/develop-positive-relationships-with-students-3194339", "isFamilyFriendly": true, "displayUrl": "https://www.<b>thought</b>co.com/develop-positive-<b>relationships-with-students</b>-3194339", "snippet": "Those things will lead to a <b>loss</b> of respect from the entire class. Teachers should handle situations professionally. You should deal with problems individually, in a respectful, yet direct and authoritative manner. Teachers must treat each student the same. You cannot play favorites. The same set of rules must apply to all students. It is also vital that a teacher is fair and consistent when dealing with students. Go the Extra Mile . Some students need teachers who will go that extra mile to ...", "dateLastCrawled": "2022-02-03T05:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Parent\u2019s Reflection on the Driver\u2019s Test <b>Analogy</b> - My WordPress", "url": "https://envisionlearning.org/blog/a-parents-reflection-on-the-drivers-test-analogy/", "isFamilyFriendly": true, "displayUrl": "https://envisionlearning.org/blog/a-parents-reflection-on-the-drivers-test-<b>analogy</b>", "snippet": "Here at Envision, we frequently use the Driver\u2019s License Test <b>analogy</b> to talk about Performance Assessment: it is a clear and familiar example of showing you are ready for a momentous next step by demonstrating what you are able to do (drive) with what you know (driving rules and regulations). As a mom, I recently had a chance to consider this <b>analogy</b> from a distinct vantage point: the passenger seat. Helping my daughter learn to drive has given me the opportunity to expand on this beloved ...", "dateLastCrawled": "2022-01-18T04:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "21 <b>Quotes</b> about Planting Seeds for Spiritual Growth ... - Healing Brave", "url": "https://healingbrave.com/blogs/all/quotes-about-planting-seeds-growth-beginnings", "isFamilyFriendly": true, "displayUrl": "https://healingbrave.com/blogs/all/<b>quotes</b>-about-planting-seeds-growth-beginnings", "snippet": "I <b>can</b> send you a copy of both &quot; Illumination for the Heart, Soul, and Spirit&quot; and Reflections if you wish. I have been a Christian for 48 years and married for 51 years to the same great women God gave me. Chuck \u2014 Chuck Paradis. Mar 27, 2021. Seeds, seeds The tiniest of things Through love, Patience, And nurture, Will often grow Into the most Beautiful of things \u2014 Nancy Sullenberger . Feb 23, 2021. Elra, you\u2019re very welcome to quote with credit, thank you for asking and for sharing ...", "dateLastCrawled": "2022-02-02T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) Perceptual Similarity and <b>Analogy</b> in Creativity and Cognitive ...", "url": "https://www.researchgate.net/publication/288575520_Perceptual_Similarity_and_Analogy_in_Creativity_and_Cognitive_Development", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/288575520_Perceptual_Similarity_and_<b>Analogy</b>...", "snippet": "Perceptual Similarity and <b>Analogy</b> in Creativity and Cognitive Development. March 2014. Studies in Computational Intelligence 548:371-395. DOI: 10.1007/978-3-642-54516-0_15.", "dateLastCrawled": "2022-01-27T10:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Behaviour language scripts for Teachers</b>", "url": "https://www.researchgate.net/publication/271832972_Behaviour_language_scripts_for_Teachers", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/271832972_<b>Behaviour_language_scripts_for_Teachers</b>", "snippet": "want you to turn to face me and listen\u2019 (using a lowering tone of voice). The deepening is a countdown \u20185, 4, 3, 2, 1\u2019 (using the same lowering of tone of voice). Th e praise coming when the ...", "dateLastCrawled": "2022-02-03T06:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>can</b> any human being predict or control the next <b>thought</b> that will ...", "url": "https://www.quora.com/How-can-any-human-being-predict-or-control-the-next-thought-that-will-come-into-their-Mind", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>can</b>-any-human-being-predict-or-control-the-next-<b>thought</b>-that...", "snippet": "Answer (1 of 5): I came across this question while looking for something similar on the internet. I was reading my old notes, then I came across my concept of higher consciousness, which I achieved during meditation. Experiencing higher consciousness is like understanding a verbal <b>thought</b> before ...", "dateLastCrawled": "2022-01-07T18:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Distilling the <b>Knowledge</b> in a Neural Network | by Kelvin | Towards Data ...", "url": "https://towardsdatascience.com/distilling-knowledge-in-neural-network-d8991faa2cdc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/distilling-<b>knowledge</b>-in-neural-network-d8991faa2cdc", "snippet": "The following Table 1. are results from paper [1] which shows the performance of using a <b>teacher, student</b>, and distilled model trained on the MNIST dataset with 60,000 training cases. All model is a two layer neural network with 1200, 800, and 800 neurons for the <b>teacher, student</b>, and distilled model respectively. When using the distilled model <b>compared</b> to the student model, the test errors are comparable between the teacher and the distilled model with the temperature set at 20. However ...", "dateLastCrawled": "2022-01-29T16:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding <b>Knowledge Distillation</b> - Ramesh&#39;s Blog", "url": "https://ramesharvind.github.io/posts/deep-learning/knowledge-distillation/", "isFamilyFriendly": true, "displayUrl": "https://ramesharvind.github.io/posts/deep-learning/<b>knowledge-distillation</b>", "snippet": "The concept provides us an answer to the question if . a smaller model <b>can</b> be made to perform as good as a large model on classification tasks . This question <b>can</b> be rephrased to distilling the knowledge of a larger model into a smaller model. The approach is outlined by the paper titled \u201cDistilling the Knowledge in a Neural Network\u201d 1. The above image outlines the different models and the <b>loss</b> function components that usually comprise KD. The image is taken from a paper titled \u201cOn the ...", "dateLastCrawled": "2022-01-19T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The impact of the teachers\u2019 non-verbal communication on success in teaching", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5346168/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5346168", "snippet": "For example, friends stand closer <b>compared</b> to strangers. Language of space <b>can</b> be divided into intimate space, personal space, social space, and public space. Language of Touch: Touch is the first sense of our body that a child learns after birth, and the first experience of his relationships with others arises trough touching. Language of Objects: Clothing and appearance are often the basis for initial judgments about people and have a significant impact on the others\u2019 judgment about us ...", "dateLastCrawled": "2022-02-02T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Compressing GANs using Knowledge Distillation</b> | DeepAI", "url": "https://deepai.org/publication/compressing-gans-using-knowledge-distillation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>compressing-gans-using-knowledge-distillation</b>", "snippet": "A mathematical <b>analogy</b> is shown (4). (4) ... to qualitatively review the results. In Figures 8, 8, and 8, we are able to see a direct comparison between the <b>teacher, student</b>, and a regular GAN of comparable size to the student. A visual review shows that the student is able to approximate the teacher without compromising the visual integrity of the image despite having a high compression ratio. One drawback however, is the presence of blur in the outputs from the student generator. This blur ...", "dateLastCrawled": "2022-01-18T12:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Relationships Between Student Perception of Teacher-Student Relations</b> ...", "url": "https://link.springer.com/article/10.1007/s10763-015-9669-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10763-015-9669-7", "snippet": "For example, correlations between <b>teacher-student</b> relations and student achievement <b>can</b> be calculated using individual student data, or using average values of the variables for schools, or average values for countries. As a rule, the three correlation coefficients are different. This phenomenon is known as the ecological fallacy: relationships found on one level cannot be carried over to another level (Brewer &amp; Venaik,", "dateLastCrawled": "2022-02-03T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is a <b>teacher student model in a Convolutional neural network</b>? - Quora", "url": "https://www.quora.com/What-is-a-teacher-student-model-in-a-Convolutional-neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-a-<b>teacher-student-model-in-a-Convolutional-neural-network</b>", "snippet": "Answer (1 of 3): Not a model, but a training method, and not limited to CNNs. Suppose that someone trains a classifier on lots of labelled data, and that the resulting model is too large for your purposes; you <b>can</b> feed the teacher and student some data and train the student on the output of the t...", "dateLastCrawled": "2022-02-03T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Improving students&#39; relationships with teachers</b>", "url": "https://www.apa.org/education-career/k12/relationships", "isFamilyFriendly": true, "displayUrl": "https://<b>www.apa.org</b>/education-career/k12/relationships", "snippet": "Negative <b>teacher-student</b> relationships <b>can</b> amplify when teachers show irritability and anger toward several or many of the students in the classroom. In these types of classrooms, teachers may find themselves resorting to yelling and harsh punitive control. <b>Teacher-student</b> communications may appear sarcastic or disrespectful. Student victimization or bullying may be common occurrences in such negative classrooms (Pianta, La Paro, &amp; Hamre, 2006). Negative <b>teacher-student</b> relationships are ...", "dateLastCrawled": "2022-02-02T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Knowledge Distillation and Student-Teacher Learning</b> for Visual ...", "url": "https://www.researchgate.net/publication/340618239_Knowledge_Distillation_and_Student-Teacher_Learning_for_Visual_Intelligence_A_Review_and_New_Outlooks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/340618239_Knowledge_Distillation_and_Student...", "snippet": "where H is the <b>loss</b> function, y is the ground truth label, \u03c3 is the softmax function parameterized by the temperature \u03c1 ( \u03c1 6 = 1 for distillation <b>loss</b>), and \u03b1 and \u03b2 are coef\ufb01cients.", "dateLastCrawled": "2022-01-04T02:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>24 Rambling Thoughts - Cognitive Behavior</b>", "url": "https://cognitivebehaviormanagement.com/theory/rambling-thoughts/", "isFamilyFriendly": true, "displayUrl": "https://cognitivebehaviormanagement.com/theory/<b>rambling-thoughts</b>", "snippet": "These processes <b>can</b> <b>be compared</b> to Structures in the same manner that thinking is <b>compared</b> to thought. We have thoughts, but we do thinking. We are constantly thinking and this thinking is coherent with our stored thoughts [Structure]. Based on dissonance theory, if we discover that our thoughts are not coherent, we are energized to change. Piaget called this ongoing change process assimilation and accommodation. In assimilation, we modify the novel thought to fit into the structure and in ...", "dateLastCrawled": "2022-02-02T18:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "21 <b>Quotes</b> about Planting Seeds for Spiritual Growth ... - Healing Brave", "url": "https://healingbrave.com/blogs/all/quotes-about-planting-seeds-growth-beginnings", "isFamilyFriendly": true, "displayUrl": "https://healingbrave.com/blogs/all/<b>quotes</b>-about-planting-seeds-growth-beginnings", "snippet": "Sometimes we need to just do the best we <b>can</b> and then trust in an unfolding we <b>can</b>&#39;t design or ordain.\u201d \u2014 Sharon Salzberg \u201cWe <b>can</b>\u2019t change people, but we <b>can</b> plant seeds that may one day bloom in them.\u201d \u2014 Mary Davis; Cultivate Resilience in the Hard Seasons \u201cThe tiny seed knew that in order to grow it needed to be dropped in dirt, covered in darkness, and struggle to reach the light.\u201d \u2014 Sandra Kring \u201cFor a seed to achieve its greatest expression, it must come completely ...", "dateLastCrawled": "2022-02-02T05:48:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> fundamentals I: An <b>analogy</b> | Finn Rietz.dev", "url": "http://www.finnrietz.dev/machine%20learning/part-1-analogy/", "isFamilyFriendly": true, "displayUrl": "www.finnrietz.dev/<b>machine</b> <b>learning</b>/part-1-<b>analogy</b>", "snippet": "And this is what the <b>loss</b> function does, so the <b>loss</b> function for a <b>Machine</b> <b>learning</b> algorithm is like the teacher for the real-world dermatologist in-training. In mathematical terms, the <b>loss</b> function could look something like this: \\(L = (y_i - \\hat{y_i})^2\\), where \\(y_i\\) is the actual output value (the one that the teacher has written down) and \\(\\hat{y_i}\\) is the one our <b>learning</b> algorithm produced.", "dateLastCrawled": "2022-01-16T09:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "Minimize a <b>loss</b> function in ... and it has been used for conducting research and for deploying <b>machine</b> <b>learning</b> systems into production across more than a dozen areas of computer science and other ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Human learning as an analogy of machine learning</b> - Weina Jin, MD", "url": "https://weina.me/ml-vs-human-learning/", "isFamilyFriendly": true, "displayUrl": "https://weina.me/ml-vs-human-<b>learning</b>", "snippet": "<b>Human learning as an analogy of machine learning</b>. 5 minute read. Published: July 24, 2018. These days, during my reading of computer vision papers, I discover a recurrent theme: to orient CNN-based network to a specific CV task, most papers focus on designing new architectures of the network and/or <b>loss</b> functions. This approach seems obvious.", "dateLastCrawled": "2020-07-13T08:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Is training <b>a neural network</b> like forming a habit? | Blog", "url": "https://jmsbrdy.com/blog/habit-formation-as-analogy-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://jmsbrdy.com/blog/habit-formation-as-<b>analogy</b>-for-<b>machine</b>-<b>learning</b>", "snippet": "Reward: during backpropagation, update our input weights according to the <b>loss</b> function; In fact, the <b>analogy</b> also works at the level of the network as a whole: Cue: transform our input example and input it into the first layer of the network; Routine: the network processes the input through its layers to produce a result; Reward: calculate how accurate the result is \u2013 compared to the labeling of the input example \u2013 and backpropagate; So, from a process perspective there do seem to broad ...", "dateLastCrawled": "2021-12-29T12:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Why <b>Machine Learning Is A Metaphor For</b> Life \u2013 Adit Deshpande ...", "url": "https://adeshpande3.github.io/Why-Machine-Learning-is-a-Metaphor-For-Life", "isFamilyFriendly": true, "displayUrl": "https://adeshpande3.github.io/Why-<b>Machine-Learning-is-a-Metaphor-For</b>-Life", "snippet": "Another cool <b>analogy</b> is that of the epsilon greedy policy. This is a term used in reinforcement <b>learning</b> to fight the problem of exploration vs exploitation. The basic idea is that the RL agent will take a random action (instead of the optimal action according to its current policy) with probability \u03b5, in hope of searching a larger area of the state space, and eventually getting a better reward.", "dateLastCrawled": "2022-01-31T13:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Scaling up <b>Analogy</b> with Crowdsourcing and <b>Machine</b> <b>Learning</b>", "url": "https://www.cs.huji.ac.il/~dshahaf/crowd-machine-learning16.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.huji.ac.il/~dshahaf/crowd-<b>machine</b>-<b>learning</b>16.pdf", "snippet": "Scaling up <b>Analogy</b> with Crowdsourcing and <b>Machine</b> <b>Learning</b> JoelChan 1,TomHope 2,DafnaShahaf andAniketKittur 1 Human-ComputerInteractionInstitute CarnegieMellonUniversity,PittsburghPA15213,USA joelchuc@cs.cmu.edu, nkittur@cs.cmu.edu,", "dateLastCrawled": "2021-11-01T13:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The intuition of <b>Triplet Loss</b>. Getting an essence of how <b>loss</b> is\u2026 | by ...", "url": "https://medium.com/analytics-vidhya/triplet-loss-b9da35be21b8", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>triplet-loss</b>-b9da35be21b8", "snippet": "Many of us feel <b>Machine</b> <b>learning</b> is a black box that takes some input and gives out some fantastic output. In recent years, this same Black box has been creating wonders by acting as a mimic of\u2026", "dateLastCrawled": "2022-01-23T03:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>About loss and loss functions</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2019/10/04/about-loss-and-loss-functions/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2019/10/04/<b>about-loss-and-loss-functions</b>", "snippet": "The high-level supervised <b>learning</b> process. Before we can actually introduce the concept of loss, we\u2019ll have to take a look at the high-level supervised <b>machine</b> <b>learning</b> process.All supervised training approaches fall under this process, which means that it is equal for deep neural networks such as MLPs or ConvNets, but also for SVMs.. Let\u2019s take a look at this training process, which is cyclical in nature.", "dateLastCrawled": "2022-01-25T13:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>machine</b> <b>learning</b> - Why there is sudden drop in loss after every epoch ...", "url": "https://stackoverflow.com/questions/57248723/why-there-is-sudden-drop-in-loss-after-every-epoch", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/57248723", "snippet": "<b>machine</b>-<b>learning</b> keras deep-<b>learning</b> loss-function. Share. Follow edited Jul 29 &#39;19 at 12:40. Community Bot. 1 1 1 silver badge. asked Jul 29 &#39;19 at 7:09. Rahul Anand Rahul Anand. 389 1 1 gold badge 3 3 silver badges 15 15 bronze badges. Add a comment | 2 Answers Active Oldest Votes. 11 Note: This answer is assuming you are using Keras -- you might want to add this information to your post or at least add a relevant tag. ...", "dateLastCrawled": "2022-01-21T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>machine</b> <b>learning</b> - In training a triplet network, I first have a solid ...", "url": "https://stats.stackexchange.com/questions/475655/in-training-a-triplet-network-i-first-have-a-solid-drop-in-loss-but-eventually", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/475655/in-training-a-triplet-network-i-first...", "snippet": "Changing the losses changes the tasks, so comparing the value of semi-hard loss to batch hard <b>loss is like</b> comparing apples to oranges. Because of how semi-hard loss is defined, its value will always be smaller than ordinary triplet loss. But we still want to achieve the inequality $(*)$! To make a consistent comparison as training progresses, you should measure the loss on the hardest task throughout training to confirm that the model is, indeed, improving as you change tasks during ...", "dateLastCrawled": "2022-02-03T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Comparing images in frequency domain. \u201cSpectral loss\u201d \u2013 does it make ...", "url": "https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss-does-it-make-sense/", "isFamilyFriendly": true, "displayUrl": "https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss...", "snippet": "I\u2019ve touched upon loss functions in my previous <b>machine</b> <b>learning</b> oriented posts (I\u2019ll highlight the separable filter optimization and generating blue noise through optimization, where in both I discuss some properties of a good loss), but for a fast recap \u2013 in <b>machine</b> <b>learning</b>, loss function is a \u201ccost\u201d that the optimization process tries to minimize. Loss functions are designed to capture aspects of the process / function that we want to \u201cimprove\u201d or solve. They can be also ...", "dateLastCrawled": "2022-01-28T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "neural networks - Explanation of <b>Spikes</b> in training loss vs. iterations ...", "url": "https://stats.stackexchange.com/questions/303857/explanation-of-spikes-in-training-loss-vs-iterations-with-adam-optimizer", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/303857/explanation-of-<b>spikes</b>-in-training...", "snippet": "Cross Validated is a question and answer site for people interested in statistics, <b>machine</b> <b>learning</b>, data analysis, data mining, and data visualization. It only takes a minute to sign up. Sign up to join this community. Anybody can ask a question Anybody can answer The best answers are voted up and rise to the top Home Public; Questions; Tags Users Unanswered Teams. Stack Overflow for Teams \u2013 Collaborate and share knowledge with a private group. Create a free Team What is Teams? Teams ...", "dateLastCrawled": "2022-01-27T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>machine</b> <b>learning</b> - <b>how to classify Iris flowers</b> - Data Science Stack ...", "url": "https://datascience.stackexchange.com/questions/43057/how-to-classify-iris-flowers", "isFamilyFriendly": true, "displayUrl": "https://<b>datascience.stackexchange</b>.com/questions/43057/<b>how-to-classify-iris-flowers</b>", "snippet": "<b>machine</b>-<b>learning</b> neural-network ai. Share. Improve this question. Follow asked Dec 23 &#39;18 at 10:21. Fahd Fahd. 9 1 1 bronze badge $\\endgroup$ 5 $\\begingroup$ If you did that what would be your loss? $\\endgroup$ \u2013 Robin Nicole. Dec 23 &#39;18 at 10:44 ...", "dateLastCrawled": "2022-01-11T15:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[D] Looking for papers on treating regression as classification vs ...", "url": "https://www.reddit.com/r/MachineLearning/comments/7gun87/d_looking_for_papers_on_treating_regression_as/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/7gun87/d_looking_for_papers_on...", "snippet": "Doing the L2 <b>loss is like</b> doing maximum likelihood on a gaussian with a fixed variance - so the bad regression here is largely coming from the gaussian being mis-specified. I think the richer question would involve comparing approaches that consider the ordering vs. approaches that don t consider the ordering but where both have flexible enough distributions.", "dateLastCrawled": "2021-01-17T22:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Alan-D-Chen</b> (<b>Alan D Chen</b>) \u00b7 <b>GitHub</b>", "url": "https://github.com/Alan-D-Chen", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>Alan-D-Chen</b>", "snippet": "\ud83d\udd25 CDIoU and CDIoU <b>loss is like</b> a convenient plug-in that can be used in multiple models. CDIoU and CDIoU loss have different excellent performances in several models such as Faster R-CNN, YOLOv4, Re\u2026 Python 22 6 PCA_ICA_DEMO Public. Demo for PCA(Principal Component Analysis) &amp; ICA(Independent Component Analysis) in data analysis in Python and image separation written in MATLAB Python 8 2 meachine_<b>learning</b> Public. \u7b80\u5355\u7ebf\u6027\u56de\u5f52\uff0c\u591a\u5143\u7ebf\u6027\u56de\u5f52\uff0c\u975e\u7ebf\u6027\u56de\u5f52\uff0cKmeans\u7b97\u6cd5 ...", "dateLastCrawled": "2021-12-29T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Hearing Loss Simulator</b> - Find Out What <b>Hearing Loss is Like</b>", "url": "https://www.starkey.com/hearing-loss-simulator", "isFamilyFriendly": true, "displayUrl": "https://www.starkey.com/<b>hearing-loss-simulator</b>", "snippet": "Find out what they&#39;re experiencing with our <b>Hearing Loss Simulator</b>. Choose a situation. Select the <b>hearing loss</b> level you want to hear. Click Play. Set your computer volume to 50% for the best experience. Start.", "dateLastCrawled": "2022-02-02T08:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "7 <b>Things I\u2019ve Learned Since the Loss of</b> My Child", "url": "https://abedformyheart.com/7-things-since-loss-of-child/", "isFamilyFriendly": true, "displayUrl": "https://abedformyheart.com/7-things-since-loss-of-child", "snippet": "It is no worse than any loss of a child it is just different. I just want a time <b>machine</b> to go back and stop him to hold him and never let him go. It didn\u2019t have to happen I guess that\u2019s why the grief or denial or hope they will walk through the door is felt because you feel you could have stopped it. Maybe we could maybe they would have done it another time. Their are so many questions and no answers X . Reply. foreversadmom says. January 11, 2016 at 4:15 am. Sorry for your loss. I too ...", "dateLastCrawled": "2022-02-03T01:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What\u2019s considered a good Log <b>Loss</b> in <b>Machine</b> <b>Learning</b> ? | by Federico ...", "url": "https://medium.com/@fzammito/whats-considered-a-good-log-loss-in-machine-learning-a529d400632d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@fzammito/whats-considered-a-good-log-<b>loss</b>-in-<b>machine</b>-<b>learning</b>-a529...", "snippet": "Log <b>Loss is similar</b> to the Accuracy, but it will favor models that distinguish more strongly the classes. Log <b>Loss</b> it useful to compare models not only on their output but on their probabilistic ...", "dateLastCrawled": "2022-01-30T14:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Key techniques for Evaluating <b>Machine</b> <b>Learning</b> models - Data Analytics", "url": "https://vitalflux.com/key-techniques-evaluating-machine-learning-models-performance/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/key-techniques-evaluating-<b>machine</b>-<b>learning</b>-models-performance", "snippet": "Log loss is used to evaluate the performance of classification <b>machine</b> <b>learning</b> models that are built using classification algorithms such as logistic regression, support vector <b>machine</b> (SVM), random forest, and gradient boosting. The idea behind the use of Log <b>loss is similar</b> to taking a base-e exponential or natural logarithm in order to compare model scores from high-value functions which may indicate poor <b>machine</b> <b>learning</b> model performance. The logarithmic loss value is defined as ...", "dateLastCrawled": "2022-01-31T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> Cats and Dogs\u2019 Breeds Classifier | by Mariana Santos ...", "url": "https://towardsdatascience.com/machine-learning-cats-and-dogs-breeds-classifier-b26a9df45000", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-cats-and-dogs-breeds-classifier-b26a9...", "snippet": "The accuracy of both the training and validation show similar curves and values, and even the train <b>loss is similar</b>, even though it is somewhat lower with the lower <b>learning</b> rate. The biggest difference is in the validation loss. With the larger <b>learning</b> rate, this curve did not converge to a value, probably because it was \u201chopping\u201d through the local minimum, due to the larger step. In this experience, we concluded that 0.001 is the best <b>learning</b> of all compared.", "dateLastCrawled": "2022-01-30T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Faster R-CNN step by step, Part II</b> | Notes for <b>machine</b> <b>learning</b>", "url": "https://dongjk.github.io/code/object+detection/keras/2018/06/10/Faster_R-CNN_step_by_step,_Part_II.html", "isFamilyFriendly": true, "displayUrl": "https://dongjk.github.io/code/object+detection/keras/2018/06/10/<b>Faster_R-CNN_step_by</b>...", "snippet": "regression <b>loss is similar</b> to RPN, using smooth l1 loss. there have 800 values but only 4 values are participant the gradient calculation. Summary. In this two posts, we have learnt how to implement <b>Faster R-CNN step by</b> step, how to prepare training data.", "dateLastCrawled": "2022-01-29T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Tabular Playground Series \u2013 June 2021 (Part 3) \u2013 <b>MACHINE</b> <b>LEARNING</b> CONCEPTS", "url": "https://srirangatarun.wordpress.com/2021/11/14/tabular-playground-series-june-2021-part-3/", "isFamilyFriendly": true, "displayUrl": "https://srirangatarun.wordpress.com/2021/11/14/tabular-playground-series-june-2021-part-3", "snippet": "The gap between the training and validation <b>loss is similar</b> to that of lightgbm, and lower than that of xgboost. So overfitting is not a major concern here. Additionally, catboost shows a strong LB performance with a score of 1.76 (very close to that of xgboost). catboost\u2019s CPU implementation is very fast compared to that of xgboost. catboost trains 20 estimators in just 6 seconds, compared to xgboost\u2019s 30. catboost, like xgboost, shows an impressive speed-up on GPU, going from 5.780 to ...", "dateLastCrawled": "2022-01-01T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>machine</b> <b>learning</b> - <b>hinge loss</b> vs logistic loss advantages and ...", "url": "https://stats.stackexchange.com/questions/146277/hinge-loss-vs-logistic-loss-advantages-and-disadvantages-limitations", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/146277/<b>hinge-loss</b>-vs-logistic-loss...", "snippet": "<b>machine</b>-<b>learning</b> svm loss-functions computer-vision. Share. Cite. Improve this question. Follow edited Jul 23 &#39;18 at 15:41. DHW. 644 3 3 silver badges 13 13 bronze badges. asked Apr 14 &#39;15 at 11:18. user570593 user570593. 1,059 2 2 gold badges 12 12 silver badges 19 19 bronze badges $\\endgroup$ Add a comment | 3 Answers Active Oldest Votes. 31 $\\begingroup$ Logarithmic loss minimization leads to well-behaved probabilistic outputs. <b>Hinge loss</b> leads to some (not guaranteed) sparsity on the ...", "dateLastCrawled": "2022-01-26T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Best <b>Artificial Intelligence</b> Course (AIML) by UT Austin", "url": "https://www.mygreatlearning.com/pg-program-artificial-intelligence-course", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/pg-program-<b>artificial-intelligence</b>-course", "snippet": "In <b>learning</b> a projection where the inputs can be distinguished, the triplet <b>loss is similar</b> to metric <b>learning</b>. The triplet loss is used for understanding the score vectors for the images. You can use the score vectors of face descriptors for verifying the faces in Euclidean Space. Natural Language Processing 4 Quizzes 2 Projects 4 Quizzes 2 Projects Learn how to work with natural language processing with Python using traditional <b>machine</b> <b>learning</b> methods. Then, deep dive into the realm of ...", "dateLastCrawled": "2022-02-01T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Generative Adversarial <b>Imitation Learning</b> | by Sanket Gujar | Medium", "url": "https://medium.com/@sanketgujar95/generative-adversarial-imitation-learning-266f45634e60", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@sanketgujar95/generative-adversarial-<b>imitation-learning</b>-266f45634e60", "snippet": "Generative Adversarial <b>Imitation Learning</b>. Sanket Gujar. Apr 20, 2018 \u00b7 8 min read. <b>Learning</b> from demonstrations will play a very important role in the age of robotics. If the robots or humans ...", "dateLastCrawled": "2022-01-11T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What is an intuitive explanation for the log</b> loss function? - Quora", "url": "https://www.quora.com/What-is-an-intuitive-explanation-for-the-log-loss-function", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-an-intuitive-explanation-for-the-log</b>-loss-function", "snippet": "Answer (1 of 8): To me an intuitive explanation is that minimizing the log loss equals minimizing the Kullback-Leibler divergence (Kullback\u2013Leibler divergence - Wikipedia) between the function you want to optimize (for example a neural network) and the true function that generates the data (from ...", "dateLastCrawled": "2022-01-30T02:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Deep <b>Domain Adaptation</b> In Computer Vision | by Branislav Holl\u00e4nder ...", "url": "https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/deep-<b>domain-adaptation</b>-in-computer-vision-8da398d3167f", "snippet": "<b>Domain adaptation</b> is a sub-discipline of <b>machine</b> <b>learning</b> which deals with scenarios in which a model trained on a source distribution is used in the context of a different (but related) target distribution. In general, <b>domain adaptation</b> uses labeled data in one or more source domains to solve new tasks in a target domain. The level of relatedness between the source and target domains hereby usually determines how successful the adaptation will be.", "dateLastCrawled": "2022-01-30T21:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>learning</b> for metal additive manufacturing: Towards a physics ...", "url": "https://www.sciencedirect.com/science/article/pii/S0278612521002259", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0278612521002259", "snippet": "<b>Machine</b> <b>learning</b> (ML) has shown to be an effective alternative to physical models for quality prediction and process optimization of metal additive manufacturing (AM). However, the inherent \u201cblack box\u201d nature of ML techniques such as those represented by artificial neural networks has often presented a challenge to interpret ML outcomes in the framework of the complex thermodynamics that govern AM. While the practical benefits of ML provide an adequate justification, its utility as a ...", "dateLastCrawled": "2022-01-27T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "commonplace book redux \u2013 a diary of quotations", "url": "https://quotables.github.io/", "isFamilyFriendly": true, "displayUrl": "https://quotables.github.io", "snippet": "English-<b>learning</b> infants under the age of six months distinguish phonemes used in Czech, Hindi, and Inslekampx (a Native American language), but English-speaking adults cannot, even with five hundred trials of training or a year of university coursework. Adult ears can tell the sounds apart, though, when the consonants are stripped from the syllables and presented alone as chirpy sounds; they just cannot tell them apart as phonemes. [\u2026]", "dateLastCrawled": "2022-02-01T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Full text of &quot;91288819 Tosh Pursuit Of History 5th Ed&quot;", "url": "https://archive.org/stream/91288819ToshPursuitOfHistory5thEd/91288819-Tosh-Pursuit-of-History-5th-Ed_djvu.txt", "isFamilyFriendly": true, "displayUrl": "https://archive.org/stream/91288819ToshPursuitOfHistory5thEd/91288819-Tosh-Pursuit-of...", "snippet": "An illustration of a computer application window Wayback <b>Machine</b>. An illustration of an open book. Books. An illustration of two cells of a film strip. Video. An illustration of an audio speaker. Audio. An illustration of a 3.5&quot; floppy disk. Software. An illustration of two photographs. Images. An illustration of a heart shape Donate. An illustration of text ellipses. More. An icon used to represent a menu that can be toggled by interacting with this icon. ...", "dateLastCrawled": "2022-01-31T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Read <b>Mushoku Tensei</b> (WN),Free online novel online reading, online book ...", "url": "https://readnovelfreeonline.com/mushoku-tensei-wn/volume-5-h", "isFamilyFriendly": true, "displayUrl": "https://readnovelfreeonline.com/<b>mushoku-tensei</b>-wn/volume-5-h", "snippet": "If I remember correctly, I was <b>learning</b> swordsmanship at my house. It was an everyday life of being scolded by my father. Even when I put in a bit of work, he would complain about everything and hit me. &quot;Do you think the you of that time could have survived on the Magic Continent?&quot; &quot;Hah, Gisu, that entire premise is strange. Rudi you know, had ...", "dateLastCrawled": "2022-01-29T13:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Notes on <b>Machine</b> <b>Learning</b> 3: <b>Decision theory</b>", "url": "https://cveai.github.io/notes/2018/03/27/mm-ml-3.html", "isFamilyFriendly": true, "displayUrl": "https://cveai.github.io/notes/2018/03/27/mm-ml-3.html", "snippet": "(ML 3.6) The Big Picture (part 2) Core ideas &amp; methods of ML: (not necessarily disjoint) Exact inference (usually not possible) Multivariate Gaussian (very nice) / Conjugate priors / Graphical models (use DP)", "dateLastCrawled": "2022-01-02T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What\u2019s My Line? <b>Next Sentence Prediction</b> in RunwayML with BERT | by ...", "url": "https://medium.com/runwayml/whats-my-line-next-sentence-prediction-in-runway-ad76cbf28c86", "isFamilyFriendly": true, "displayUrl": "https://medium.com/runwayml/whats-my-line-<b>next-sentence-prediction</b>-in-runway-ad76cbf28c86", "snippet": "The <b>loss can be thought of as</b> how much the model is surprised by the sequence. The lower the loss, the more likely it judges the sequence to be. Results: I\u2019m not sure what a score of 4.0966539 ...", "dateLastCrawled": "2022-01-31T03:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Defect <b>Detection</b> in Products using Image Segmentation | by Vinithavn ...", "url": "https://medium.com/analytics-vidhya/defect-detection-in-products-using-image-segmentation-a87a8863a9e5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/defect-<b>detection</b>-in-products-using-image...", "snippet": "Dice <b>loss can be thought of as</b> 1-Dice coefficient where Dice coefficient is defined as, Dice coefficient=2* area of overlap area of intersection. You can read more about these metrics here. 5 ...", "dateLastCrawled": "2022-02-03T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Decision-Theoretic Approximations for Machine Learning</b>", "url": "https://www.ijcai.org/Proceedings/13/Papers/487.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/Proceedings/13/Papers/487.pdf", "snippet": "<b>Decision-Theoretic Approximations for Machine Learning</b> M. Ehsan Abbasnejad Abstract Decision theory focuses on the problem of mak-ing decisions under uncertainty. This uncertainty arises from the unknown aspects of the state of the world the decision maker is in or the unknown util- ity function of performing actions. The uncertainty can be modeled as a probability distribution captur-ing our belief about the world the decision maker is in. Upon making new observations, the decision maker ...", "dateLastCrawled": "2022-02-02T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Automatic Di\ufb00erentiation and <b>Neural Networks</b> 1 Introduction", "url": "https://people.cs.umass.edu/~domke/courses/sml2010/07autodiff_nnets.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.umass.edu/~domke/courses/sml2010/07autodiff_nnets.pdf", "snippet": "Statistical <b>Machine</b> <b>Learning</b> Notes 7 Automatic Di\ufb00erentiation and <b>Neural Networks</b> Instructor: Justin Domke 1 Introduction The name \u201cneuralnetwork\u201d is sometimes used torefer tomany things (e.g. Hop\ufb01eld networks, self-organizing maps). In these notes, we are only interested in the most common type of neural network, the multi-layer perceptron. A basic problem in <b>machine</b> <b>learning</b> is function approximation. We have some inputs x\u02c6 and some outputs y\u02c6, and we want to \ufb01t some function f ...", "dateLastCrawled": "2022-01-28T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Automatic Di\ufb00erentiation and Neural Networks</b>", "url": "https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf", "snippet": "Statistical <b>Machine</b> <b>Learning</b> Notes 8 <b>Automatic Di\ufb00erentiation and Neural Networks</b> Instructor: Justin Domke Contents 1 Introduction 1 2 Automatic Di\ufb00erentiation 2 3 Multi-Layer Perceptrons 5 4 MNIST 7 5 Backpropagation 10 6 Discussion 13 1 Introduction The name \u201cneuralnetwork\u201d is sometimes used torefer tomany things (e.g. Hop\ufb01eld networks, self-organizing maps). In these notes, we are only interested in the most common type of neural network, the multi-layer perceptron. A basic ...", "dateLastCrawled": "2022-01-28T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A cascaded fully convolutional network framework for dilated pancreatic ...", "url": "https://link.springer.com/article/10.1007/s11548-021-02530-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11548-021-02530-x", "snippet": "Deep-<b>learning</b>-base methods have successfully solved many challenging tasks in image processing, such as classification [8, 25], ... The Dice <b>loss can be thought of as</b> the minimization of the Dice score subtracted by one, which is minimized toward 0 to achieve optimal segmentation performance. Focal loss is proposed to dynamically rescale cross entropy loss and is conducive to imbalance problems . The voxel-wise Focal loss function is expressed as $$\\begin{aligned} {\\mathcal {L}}_F = -\\frac{1 ...", "dateLastCrawled": "2022-01-30T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Exploring deep neural networks via layer-peeled model: Minority ...", "url": "https://www.pnas.org/content/118/43/e2103091118", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/118/43/e2103091118", "snippet": "The remarkable development of deep <b>learning</b> over the past decade relies heavily on sophisticated heuristics and tricks. To better exploit its potential in the coming decade, perhaps a rigorous framework for reasoning about deep <b>learning</b> is needed, which, however, is not easy to build due to the intricate details of neural networks. For near-term purposes, a practical alternative is to develop a mathematically tractable surrogate model, yet maintaining many characteristics of neural networks.", "dateLastCrawled": "2021-12-30T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Adversarial Examples are Just Bugs</b>, Too - Latest articles about <b>machine</b> ...", "url": "https://distill.pub/2019/advex-bugs-discussion/response-5/", "isFamilyFriendly": true, "displayUrl": "https://distill.pub/2019/advex-bugs-discussion/response-5", "snippet": "Adversarial Examples With No Features. Using the above, we can construct adversarial examples which do not suffice for <b>learning</b>. Here, we replicate the Ilyas et al. experiment that \u201cNon-robust features suffice for standard classification\u201d (Section 3.2 of ), but show that it fails for our construction of adversarial examples.. To review, the Ilyas et al. non-robust experiment was:", "dateLastCrawled": "2022-01-31T12:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Network Traffic Anomaly Detection Using Recurrent Neural Networks", "url": "https://www.researchgate.net/publication/324104291_Network_Traffic_Anomaly_Detection_Using_Recurrent_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324104291_Network_Traffic_Anomaly_Detection...", "snippet": "Next, a supervised <b>machine</b> <b>learning</b> algorithm one-class SVM is trained to generalize the behavior model in order to predict user behavior anomalies. Results show that One-Class SVM is the most ...", "dateLastCrawled": "2022-01-26T23:23:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(loss)  is like +(teacher-student analogy)", "+(loss) is similar to +(teacher-student analogy)", "+(loss) can be thought of as +(teacher-student analogy)", "+(loss) can be compared to +(teacher-student analogy)", "machine learning +(loss AND analogy)", "machine learning +(\"loss is like\")", "machine learning +(\"loss is similar\")", "machine learning +(\"just as loss\")", "machine learning +(\"loss can be thought of as\")", "machine learning +(\"loss can be compared to\")"]}