{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Epoch in Machine Learning</b>: A Simple Introduction (2021)", "url": "https://www.jigsawacademy.com/blogs/ai-ml/epoch-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.jigsawacademy.com/blogs/ai-ml/<b>epoch-in-machine-learning</b>", "snippet": "Both <b>batch</b> <b>size</b> and <b>epoch in machine learning</b> of <b>learning</b> algorithms are hyper-parameters with integers as values used by the training model. These values are not found by a <b>learning</b> process since they are not internal parameters of the model and must be specified for the process when training an <b>algorithm</b> on the training dataset. These numbers are also not fixed values and, depending on the <b>algorithm</b>, may require trying various integer values before finding the most suitable values for the ...", "dateLastCrawled": "2022-02-02T20:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Difference Between a Batch and</b> an Epoch in a Neural Network", "url": "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>difference-between-a-batch-and</b>-an-epoch", "snippet": "Stochastic gradient descent is a <b>learning</b> <b>algorithm</b> that has a number of hyperparameters. Two hyperparameters that often confuse beginners are the <b>batch</b> <b>size</b> and number of epochs. They are both integer values and seem to do the same thing. In this post, you will discover the difference between batches and epochs in stochastic gradient descent. After reading this post, you will know: Stochastic", "dateLastCrawled": "2022-02-02T11:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> with Spark Streaming - cloud-computing-big-<b>data</b>.github.io", "url": "https://cloud-computing-big-data.github.io/mlss.html", "isFamilyFriendly": true, "displayUrl": "https://cloud-computing-big-<b>data</b>.github.io/mlss.html", "snippet": "UE19CS322 Big <b>Data</b> Project 2 <b>Machine</b> <b>Learning</b> with Spark MLlib. <b>Machine</b> ... you may be required to adjust the <b>batch</b> <b>size</b> to a smaller value since there is a limit on how much <b>data</b> can be <b>sent</b> over a TCP connection. If your <b>batch</b> <b>size</b> is larger than what can be <b>sent</b>, the streaming file will display a logging message. The value of the maximum <b>batch</b> <b>size</b> for your dataset can be found out experimentally. Processing Stream. The <b>size</b> of each <b>batch</b> will be known to you at runtime. This value will ...", "dateLastCrawled": "2022-02-01T10:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What should the <b>batch</b> <b>size</b> of a neural network be at evaluation time ...", "url": "https://www.quora.com/What-should-the-batch-size-of-a-neural-network-be-at-evaluation-time-Does-it-depend-on-the-loss-function-or-can-it-be-simply-one", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-should-the-<b>batch</b>-<b>size</b>-of-a-neural-network-be-at-evaluation...", "snippet": "Answer (1 of 3): The <b>batch</b> <b>size</b> at inference (using the network after you&#39;ve trained) should be however many inputs you want to process simultaneously. The results are totally unaffected by the other inputs. Having a <b>batch</b> <b>size</b> for inference is just a way of parallelizing the computation. If you...", "dateLastCrawled": "2022-01-18T11:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Handling Big Datasets for <b>Machine Learning</b> - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/machine-learning-with-big-data-86bcb39f2f0b", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/<b>machine-learning</b>-with-big-<b>data</b>-86bcb39f2f0b", "snippet": "[1] Dynamic task scheduling optimized for computation <b>like</b> Airflow. [2] \u201cBig <b>Data</b>\u201d collections <b>like</b> parallel (Numpy) arrays, (Pandas) dataframes, and lists. Dask has only been around for a couple of years but is gradually growing momentum due to the popularity of Python for <b>machine learning</b> applications. Dask allows scaling up (1000 core ...", "dateLastCrawled": "2022-02-02T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Five Popular Data Augmentation Techniques In Deep Learning</b>", "url": "https://dataaspirant.com/data-augmentation-techniques-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>data</b>aspirant.com/<b>data</b>-augmentation-techniques-deep-<b>learning</b>", "snippet": "If we are not able to feed the right <b>amount</b> <b>of data</b> the deep <b>learning</b> models we build face the underfitting issue, ... The ImageDataGenerator needs the input in the shape of (<b>batch</b>_<b>size</b>, height, width, channels) but the shape of our image is ( height, width, channels). So , let&#39;s reshape our image into the desired shape. We have to create an instance for the ImageDataGenerator and pass these transformations as parameters. Replace the above code cell with the respective code cells from the ...", "dateLastCrawled": "2022-02-03T01:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Mastering AWS Kinesis Data Streams</b>, Part 1 - /dev/solita", "url": "https://dev.solita.fi/2020/05/28/kinesis-streams-part-1.html", "isFamilyFriendly": true, "displayUrl": "https://dev.solita.fi/2020/05/28/kinesis-streams-part-1.html", "snippet": "putRecords supports a <b>batch</b> of up to 500 records or up to 5 MiB. Here is a simple example demonstrating one of the reasons why you should probably seldom use the putRecord and prefer the <b>batch</b> operation when possible: Three `putRecord` requests vs a single `putRecords` request with three records. Those are the HTTP requests being <b>sent</b> to AWS when each of the put requests is made. On the left, we write three separate records, while on the right we write the three records in the same request ...", "dateLastCrawled": "2022-01-29T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Top 100 Hadoop Interview Questions and Answers</b> - DataFlair", "url": "https://data-flair.training/blogs/top-100-hadoop-interview-questions-and-answers/", "isFamilyFriendly": true, "displayUrl": "https://<b>data</b>-flair.training/blogs/top", "snippet": "So, when any <b>machine</b> in the cluster goes down, then the client can easily access their <b>data</b> from another <b>machine</b>. And this <b>machine</b> contains the same copy <b>of data</b> blocks. Learn: Automatic Failover in Hadoop 8) How is indexing done in HDFS? Hadoop has a unique way of indexing. <b>Once</b> Hadoop framework store the <b>data</b> as per the block <b>size</b>. HDFS will ...", "dateLastCrawled": "2022-02-03T15:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Azure</b> subscription limits and quotas - <b>Azure</b> Resource Manager ...", "url": "https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits", "isFamilyFriendly": true, "displayUrl": "https://docs.microsoft.com/en-us/<b>azure</b>/<b>azure</b>-resource-manager/management/<b>azure</b>...", "snippet": "In this article. This document lists some of the most common Microsoft <b>Azure</b> limits, which are also sometimes called quotas. To learn more about <b>Azure</b> pricing, see <b>Azure</b> pricing overview.There, you can estimate your costs by using the pricing calculator.You also can go to the pricing details page for a particular service, for example, Windows VMs.For tips to help manage your costs, see Prevent unexpected costs with <b>Azure</b> billing and cost management.. Managing limits", "dateLastCrawled": "2022-02-03T06:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "RNN (Recurrent Neural Network) Tutorial: TensorFlow Example", "url": "https://www.guru99.com/rnn-tutorial.html", "isFamilyFriendly": true, "displayUrl": "https://www.guru99.com/rnn-tutorial.html", "snippet": "With an RNN, this output is <b>sent</b> back to itself number of time. We call timestep <b>the amount</b> of time the output becomes the input of the next matrice multiplication. For instance, in the picture below, you can see the network is composed of one neuron. The network computes the matrices multiplication between the input and the weight and adds non-linearity with the activation function. It becomes the output at t-1. This output is the input of the second matrix multiplication. Recurrent Neural ...", "dateLastCrawled": "2022-02-02T21:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Epoch in Machine Learning</b>: A Simple Introduction (2021)", "url": "https://www.jigsawacademy.com/blogs/ai-ml/epoch-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.jigsawacademy.com/blogs/ai-ml/<b>epoch-in-machine-learning</b>", "snippet": "Both <b>batch</b> <b>size</b> and <b>epoch in machine learning</b> of <b>learning</b> algorithms are hyper-parameters with integers as values used by the training model. These values are not found by a <b>learning</b> process since they are not internal parameters of the model and must be specified for the process when training an <b>algorithm</b> on the training dataset. These numbers are also not fixed values and, depending on the <b>algorithm</b>, may require trying various integer values before finding the most suitable values for the ...", "dateLastCrawled": "2022-02-02T20:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Difference Between a Batch and</b> an Epoch in a Neural Network", "url": "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>difference-between-a-batch-and</b>-an-epoch", "snippet": "Stochastic gradient descent is a <b>learning</b> <b>algorithm</b> that has a number of hyperparameters. Two hyperparameters that often confuse beginners are the <b>batch</b> <b>size</b> and number of epochs. They are both integer values and seem to do the same thing. In this post, you will discover the difference between batches and epochs in stochastic gradient descent. After reading this post, you will know: Stochastic", "dateLastCrawled": "2022-02-02T11:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Optimization \u2014 ML Compiled", "url": "https://ml-compiled.readthedocs.io/en/latest/optimizers.html", "isFamilyFriendly": true, "displayUrl": "https://ml-compiled.readthedocs.io/en/latest/optimizers.html", "snippet": "<b>Batch</b> <b>size</b> \u00b6 Pros of large <b>batch</b> sizes: ... Smaller number of updates for processing the same <b>amount</b> <b>of data</b>, slowing training. Hypothesized by Keskar et al. (2016) to have worse generalization performance since they result in sharper local minima being reached. Further reading . On Large-<b>Batch</b> Training for Deep <b>Learning</b>: Generalization Gap and Sharp Minima, Keskar et al. (2016) Coupling Adaptive <b>Batch</b> Sizes with <b>Learning</b> Rates, Balles et al. (2016) Big <b>Batch</b> SGD: Automated Inference using ...", "dateLastCrawled": "2021-12-03T15:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> with Spark Streaming - cloud-computing-big-<b>data</b>.github.io", "url": "https://cloud-computing-big-data.github.io/mlss.html", "isFamilyFriendly": true, "displayUrl": "https://cloud-computing-big-<b>data</b>.github.io/mlss.html", "snippet": "<b>Machine</b> <b>Learning</b> with Spark MLlib is one of the project titles that can be taken up as a part of the UE19CS322 Big <b>Data</b> course at PES University. This simulates a real world scenario where you will be required to handle an enormous <b>amount</b> <b>of data</b> for predictive modelling. The <b>data</b> source is a stream and your application faces the constraint of only being able to handle batches of a stream at any given point in time. With this project, you will learn more about how applications in the real ...", "dateLastCrawled": "2022-02-01T10:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to process streams <b>of data</b> with Apache Kafka and Spark", "url": "https://cloudblogs.microsoft.com/opensource/2018/07/09/how-to-data-processing-apache-kafka-spark/", "isFamilyFriendly": true, "displayUrl": "https://cloudblogs.microsoft.com/opensource/2018/07/09/how-to-<b>data</b>-processing-apache...", "snippet": "We can use Spark SQL and do <b>batch</b> processing, stream processing with Spark Streaming and Structured Streaming, <b>machine</b> <b>learning</b> with Mllib, and graph computations with GraphX. How Spark works. We can submit jobs to run on Spark. On a high level, when we submit a job, Spark creates an operator graph from the code, submits it to the scheduler ...", "dateLastCrawled": "2022-01-30T02:15:00.0000000Z", "searchTags": [{"name": "search.title", "content": "&quot;How to process streams of data with Apache Kafka and Spark&quot;; how; to; process; streams; of; data; with; apache; kafka; and; spark"}, {"name": "search.network", "content": "&quot;ceblognetwork&quot;; ceblognetwork"}, {"name": "search.excerpt", "content": "&quot;Data is produced every second, it comes from millions of sources and is constantly growing. Have you ever thought how much data you personally are generating every day? Data: direct result of our actions There\u2019s data generated as a direct result of our actions and activities: Browsing twitter Using mobile apps Performing financial transactions Using&quot;; data; is; produced; every; second; it; comes; from; millions; of; sources; and; is; constantly; growing; have; you; ever; thought; how; much; data; you; personally; are; generating; every; day; data; direct; result; of; our; actions; there; s; data; generated; as; a; direct; result; of; our; actions; and; activities; browsing; twitter; using; mobile; apps; performing; financial; transactions; using"}, {"name": "search.tags", "content": "&quot;Apache, HDInsight, Kubernetes, Microsoft Azure, Spark, Storm&quot;; apache; hdinsight; kubernetes; microsoft; azure; spark; storm"}, {"name": "search.categories", "content": "&quot;Big Data, Cloud, Containers, English&quot;; big; data; cloud; containers; english"}, {"name": "search.publisheddate", "content": "&quot;July 9, 2018&quot;; july; 9; 2018"}], "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "PPML Series #2 - Federated Optimization Algorithms - FedSGD and FedAvg ...", "url": "https://shreyansh26.github.io/post/2021-12-18_federated_optimization_fedavg/", "isFamilyFriendly": true, "displayUrl": "https://shreyansh26.github.io/post/2021-12-18_federated_optimization_fedavg", "snippet": "There was a paper, Communication-Efficient <b>Learning</b> of Deep Networks from Decentralized <b>Data</b> by Google (3637 citations!!!), in which the authors had proposed a federated optimization <b>algorithm</b> called FedAvg and compared it with a naive baseline, FedSGD.. FedSGD. Stochastic Gradient Descent (SGD) had shown great results in deep <b>learning</b>. So, as a baseline, the researchers decided to base the Federated <b>Learning</b> training <b>algorithm</b> on SGD as well.", "dateLastCrawled": "2022-02-03T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What should the <b>batch</b> <b>size</b> of a neural network be at evaluation time ...", "url": "https://www.quora.com/What-should-the-batch-size-of-a-neural-network-be-at-evaluation-time-Does-it-depend-on-the-loss-function-or-can-it-be-simply-one", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-should-the-<b>batch</b>-<b>size</b>-of-a-neural-network-be-at-evaluation...", "snippet": "Answer (1 of 3): The <b>batch</b> <b>size</b> at inference (using the network after you&#39;ve trained) should be however many inputs you want to process simultaneously. The results are totally unaffected by the other inputs. Having a <b>batch</b> <b>size</b> for inference is just a way of parallelizing the computation. If you...", "dateLastCrawled": "2022-01-18T11:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Guide to <b>Classification</b> on Imbalanced Datasets - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/guide-to-classification-on-imbalanced-datasets-d6653aa5fa23", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/guide-to-<b>classification</b>-on-imbalanced-<b>dataset</b>s-d6653aa5fa23", "snippet": "<b>Machine</b> <b>learning</b> algorithms by default assume that <b>data</b> is balanced. In <b>classification</b>, this corresponds to a comparative number of instances of each class. Classifiers learn better from a balanced distribution. It is up to the <b>data</b> scientist to correct for imbalances, which can be done in multiple ways. Different Types of Imbalance. We have clearly shown that imbalanced datasets have some additional challenges to standard datasets. To further complicate matters, there are different types of ...", "dateLastCrawled": "2022-02-03T01:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Classification on imbalanced data</b> | TensorFlow Core", "url": "https://www.tensorflow.org/tutorials/structured_data/imbalanced_data", "isFamilyFriendly": true, "displayUrl": "https://www.tensorflow.org/tutorials/structured_<b>data</b>/imbalanced_<b>data</b>", "snippet": "<b>Classification on imbalanced data</b>. Optional: Set the correct initial bias. This tutorial demonstrates how to classify a highly imbalanced dataset in which the number of examples in one class greatly outnumbers the examples in another. You will work with the Credit Card Fraud Detection dataset hosted on Kaggle.", "dateLastCrawled": "2022-02-02T04:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "RNN (Recurrent Neural Network) Tutorial: TensorFlow Example", "url": "https://www.guru99.com/rnn-tutorial.html", "isFamilyFriendly": true, "displayUrl": "https://www.guru99.com/rnn-tutorial.html", "snippet": "It also helps to produce predictive results for sequential <b>data</b> by delivering <b>similar</b> behavior as a human brain. The structure of an Artificial Neural Network is relatively simple and is mainly about matrix multiplication. During the first step, inputs are multiplied by initially random weights, and bias, transformed with an activation function and the output values are used to make a prediction. This step gives an idea of how far the network is from the reality. The metric applied is the ...", "dateLastCrawled": "2022-02-02T21:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Epoch in Machine Learning</b>: A Simple Introduction (2021)", "url": "https://www.jigsawacademy.com/blogs/ai-ml/epoch-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.jigsawacademy.com/blogs/ai-ml/<b>epoch-in-machine-learning</b>", "snippet": "Both <b>batch</b> <b>size</b> and <b>epoch in machine learning</b> of <b>learning</b> algorithms are hyper-parameters with integers as values used by the training model. These values are not found by a <b>learning</b> process since they are not internal parameters of the model and must be specified for the process when training an <b>algorithm</b> on the training dataset. These numbers are also not fixed values and, depending on the <b>algorithm</b>, may require trying various integer values before finding the most suitable values for the ...", "dateLastCrawled": "2022-02-02T20:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Difference Between a Batch and</b> an Epoch in a Neural Network", "url": "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>difference-between-a-batch-and</b>-an-epoch", "snippet": "Stochastic gradient descent is a <b>learning</b> <b>algorithm</b> that has a number of hyperparameters. Two hyperparameters that often confuse beginners are the <b>batch</b> <b>size</b> and number of epochs. They are both integer values and seem to do the same thing. In this post, you will discover the difference between batches and epochs in stochastic gradient descent. After reading this post, you will know: Stochastic", "dateLastCrawled": "2022-02-02T11:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What <b>is the difference between iterations and epochs</b> in Convolution ...", "url": "https://www.quora.com/What-is-the-difference-between-iterations-and-epochs-in-Convolution-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-<b>is-the-difference-between-iterations-and-epochs</b>-in...", "snippet": "Answer (1 of 5): From Epoch vs iteration when training neural networks : In the neural network terminology: * one epoch = one forward pass and one backward pass of all the training examples * <b>batch</b> <b>size</b> = the number of training examples in one forward/backward pass. The higher the <b>batch</b> <b>size</b>,...", "dateLastCrawled": "2022-01-26T15:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 3, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Artificial neural network</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Artificial_neural_network", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Artificial_neural_network</b>", "snippet": "Artificial neural networks (ANNs), usually simply called neural networks (NNs), are computing systems inspired by the biological neural networks that constitute animal brains.. An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, <b>can</b> transmit a signal to other neurons. An artificial neuron receives a signal then processes it and <b>can</b> signal neurons ...", "dateLastCrawled": "2022-02-07T09:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Convolutional Neural Networks - Learn <b>Data</b> Sci", "url": "https://www.learndatasci.com/tutorials/convolutional-neural-networks-image-classification/", "isFamilyFriendly": true, "displayUrl": "https://www.learn<b>data</b>sci.com/tutorials/<b>convolutional-neural-networks-image-classification</b>", "snippet": "It is a supervised <b>learning</b> problem, wherein a set of pre-labeled training <b>data</b> is fed <b>to a machine</b> <b>learning</b> <b>algorithm</b>. This <b>algorithm</b> attempts| to learn the visual features contained in the training images associated with each label, and classify unlabelled images accordingly. It is a very popular task that we will be exploring today using the Keras Open-Source Library for Deep <b>Learning</b>.", "dateLastCrawled": "2022-02-01T08:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Batch processing of network packets</b> [LWN.net]", "url": "https://lwn.net/Articles/763056/", "isFamilyFriendly": true, "displayUrl": "https://lwn.net/Articles/763056", "snippet": "It has been understood for years that kernel performance <b>can</b> be improved by doing things in batches. Whether the task is freeing memory pages, initializing <b>data</b> structures, or performing I/O, things go faster if the work is done on many objects <b>at once</b>; many kernel subsystems have been reworked to take advantage of the efficiency of batching. It turns out, though, that there was a piece of relatively low-hanging fruit at the core of the kernel&#39;s network stack. The 4.19 kernel will feature ...", "dateLastCrawled": "2022-01-18T08:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Mastering AWS <b>Kinesis</b> <b>Data</b> Streams, Part 2 - /dev/solita", "url": "https://dev.solita.fi/2020/12/21/kinesis-streams-part-2.html", "isFamilyFriendly": true, "displayUrl": "https://dev.solita.fi/2020/12/21/<b>kinesis</b>-streams-part-2.html", "snippet": "You will pay for both the <b>amount</b> <b>of data</b> consumed, as well as the number of consumers per shard. So, your highway turns out to be a toll road. Too many consumers are barely enough. Finally, you don\u2019t need to choose one way of consuming the stream over the other. In the same way that you <b>can</b> mix and match different types of consumers (direct service integrations with <b>Kinesis</b> Firehose and Analytics, Lambda functions, etc.), you <b>can</b> also use both shared throughput and enhanced fan-out with ...", "dateLastCrawled": "2022-01-29T00:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Multi-Layer Neural Networks with <b>Sigmoid</b> Function\u2014 Deep <b>Learning</b> for ...", "url": "https://towardsdatascience.com/multi-layer-neural-networks-with-sigmoid-function-deep-learning-for-rookies-2-bf464f09eb7f", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/multi-layer-neural-networks-with-<b>sigmoid</b>-function-deep...", "snippet": "After training the neural network with rounds and rounds of labeled <b>data</b> in supervised <b>learning</b>, assume the first 4 hidden neurons learned to recognize the patterns above in the left side of Graph 14. Then, if we feed the neural network an array of a handwritten digit zero, the network should correctly trigger the top 4 hidden neurons in the hidden layer while the other hidden neurons are silent, and then again trigger the first output neuron while the rest are silent.", "dateLastCrawled": "2022-01-29T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Explaining data science&#39;s ROI problem</b> | Automated <b>Machine</b> <b>Learning</b> with ...", "url": "https://subscription.packtpub.com/book/data/9781800565319/2/ch02lvl1sec03/explaining-data-science-s-roi-problem", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/book/<b>data</b>/9781800565319/2/ch02lvl1sec03/explaining...", "snippet": "<b>Once</b> you have an easily understandable, cleansed dataset, the next step is transforming <b>data</b> for <b>machine</b> <b>learning</b>, which is called feature engineering. Feature engineering is the process of altering <b>data</b> for <b>machine</b> <b>learning</b> algorithms. Some features are necessary for the <b>algorithm</b> to work, while other features make it easier for the <b>algorithm</b> to find patterns. Common feature engineering techniques include one-hot encoding categorical variables, scaling numeric values, removing outliers, and ...", "dateLastCrawled": "2021-12-27T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Practice | GeeksforGeeks | A computer science portal for geeks", "url": "https://practice.geeksforgeeks.org/answers/vaishali+bhatia/", "isFamilyFriendly": true, "displayUrl": "https://practice.geeksforgeeks.org/answers/vaishali+bhatia", "snippet": "As the microprocessor processes <b>data</b>, it looks first in the cache memory and if it finds the <b>data</b> there (from a previous reading <b>of data</b>), it does not have to do the more time-consuming reading <b>of data</b> from larger memory.Cache memory is a high speed memory in the CPU that is used for faster access to <b>data</b>. It provides the processor with the most frequently requested <b>data</b>. Cache memory increases performance and allows faster retrieval <b>of data</b>.", "dateLastCrawled": "2022-02-02T11:06:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Difference Between a Batch and</b> an Epoch in a Neural Network", "url": "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>difference-between-a-batch-and</b>-an-epoch", "snippet": "Stochastic gradient descent is a <b>learning</b> <b>algorithm</b> that has a number of hyperparameters. Two hyperparameters that often confuse beginners are the <b>batch</b> <b>size</b> and number of epochs. They are both integer values and seem to do the same thing. In this post, you will discover the difference between batches and epochs in stochastic gradient descent. After reading this post, you will know: Stochastic", "dateLastCrawled": "2022-02-02T11:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimization \u2014 ML Compiled", "url": "https://ml-compiled.readthedocs.io/en/latest/optimizers.html", "isFamilyFriendly": true, "displayUrl": "https://ml-compiled.readthedocs.io/en/latest/optimizers.html", "snippet": "<b>Batch</b> <b>size</b> \u00b6 Pros of large <b>batch</b> sizes: ... Smaller number of updates for processing the same <b>amount</b> <b>of data</b>, slowing training. Hypothesized by Keskar et al. (2016) to have worse generalization performance since they result in sharper local minima being reached. Further reading. On Large-<b>Batch</b> Training for Deep <b>Learning</b>: Generalization Gap and Sharp Minima, Keskar et al. (2016) Coupling Adaptive <b>Batch</b> Sizes with <b>Learning</b> Rates, Balles et al. (2016) Big <b>Batch</b> SGD: Automated Inference using ...", "dateLastCrawled": "2021-12-03T15:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A comparison on scalability for <b>batch</b> <b>big data</b> processing on Apache ...", "url": "https://bdataanalytics.biomedcentral.com/articles/10.1186/s41044-016-0020-2", "isFamilyFriendly": true, "displayUrl": "https://b<b>data</b>analytics.biomedcentral.com/articles/10.1186/s41044-016-0020-2", "snippet": "The large amounts <b>of data</b> have created a need for new frameworks for processing. The MapReduce model is a framework for processing and generating large-scale datasets with parallel and distributed algorithms. Apache Spark is a fast and general engine for large-scale <b>data</b> processing based on the MapReduce model. The main feature of Spark is the in-memory computation. Recently a novel framework called Apache Flink has emerged, focused on distributed stream and <b>batch</b> <b>data</b> processing. In this ...", "dateLastCrawled": "2022-02-02T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "An <b>empirical approach to speedup your</b> BERT ... - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/an-empirical-approach-to-speedup-your-bert-inference-with-onnx-torchscript-91da336b3a41", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/an-<b>empirical-approach-to-speedup-your</b>-bert-inference...", "snippet": "Trace: An input is <b>sent</b> through the model and all operations are recorded in a graph that will define your torchscript model. ... this gives a ~12x speedup <b>compared</b> to <b>batch</b> <b>size</b> 1 on pytorch; For the V100 with batches of 32 or 64 we <b>can</b> achieve up to a ~28x speedup <b>compared</b> to the baseline for GPU and ~90x for baseline on CPU. Overall, we find that choosing an appropriate format has a significant impact for smaller <b>batch</b> sizes, but that impact narrows down as batches get larger, with ...", "dateLastCrawled": "2022-02-03T02:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning</b> in production - A guide to model evaluation and retraining", "url": "https://nanonets.com/blog/machine-learning-production-retraining/", "isFamilyFriendly": true, "displayUrl": "https://nanonets.com/blog/<b>machine-learning</b>-production-retraining", "snippet": "Yes, that <b>amount</b> of money to train a <b>Machine Learning</b> model. Most likely you won\u2019t use that <b>amount</b> of computation power, but training model on cloud GPUs/TPUs <b>can</b> be very expensive. If the model has a <b>size</b> in GBs, storing it <b>can</b> also bear significant cost. Freezing a portion of the model is possible in deep <b>learning</b>. It is hard to implement ...", "dateLastCrawled": "2022-02-02T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "PPML Series #2 - Federated Optimization Algorithms - FedSGD and FedAvg ...", "url": "https://shreyansh26.github.io/post/2021-12-18_federated_optimization_fedavg/", "isFamilyFriendly": true, "displayUrl": "https://shreyansh26.github.io/post/2021-12-18_federated_optimization_fedavg", "snippet": "There was a paper, Communication-Efficient <b>Learning</b> of Deep Networks from Decentralized <b>Data</b> by Google (3637 citations!!!), in which the authors had proposed a federated optimization <b>algorithm</b> called FedAvg and <b>compared</b> it with a naive baseline, FedSGD.. FedSGD. Stochastic Gradient Descent (SGD) had shown great results in deep <b>learning</b>. So, as a baseline, the researchers decided to base the Federated <b>Learning</b> training <b>algorithm</b> on SGD as well.", "dateLastCrawled": "2022-02-03T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Handling Big Datasets for <b>Machine Learning</b> - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/machine-learning-with-big-data-86bcb39f2f0b", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/<b>machine-learning</b>-with-big-<b>data</b>-86bcb39f2f0b", "snippet": "All of the commands required for setting up the <b>machine learning</b> platform on the cloud <b>can</b> be found in the markdown file here. ... <b>Once</b> you are in the cluster, you <b>can</b> clone the GitHub repository and watch Dask go! Kaggle Rossman Competition. I recommend that <b>once</b> you have got the Dask cloud deployment up and running you try running the rossman_kaggle.ipynb. This is example code from the Kaggle Rossman competition, which allowed users to use any <b>data</b> they wanted to try and predict pharmacy ...", "dateLastCrawled": "2022-02-02T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>What Is Data: Types of Data</b>, <b>and How to Analyze Data</b>?", "url": "https://www.simplilearn.com/what-is-data-article", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/what-is-<b>data</b>-article", "snippet": "The term Big <b>Data</b> is used in the <b>data</b> definition to describe the <b>data</b> that is in the petabyte range or higher. Big <b>Data</b> is also described as 5Vs: variety, volume, value, veracity, and velocity. Nowadays, web-based eCommerce has spread vastly, business models based on Big <b>Data</b> have evolved, and they treat <b>data</b> as an asset itself.", "dateLastCrawled": "2022-02-02T06:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Chapter 10: Batch Processing</b> Flashcards | Quizlet", "url": "https://quizlet.com/342531719/chapter-10-batch-processing-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/342531719/<b>chapter-10-batch-processing</b>-flash-cards", "snippet": "A _____ system (offline systems) takes a large <b>amount</b> of input <b>data</b>, runs a job to process it, and produces some output <b>data</b>. Jobs often take a while (from a few minutes to several days), so there normally isn&#39;t a user waiting for the job to finish. Instead, <b>batch</b> jobs are often scheduled to run periodically (for example, <b>once</b> a day). <b>Batch</b> processing _____ is usually the primary measure of performance of a service system, and availability is often very important (if the client <b>can</b>&#39;t reach ...", "dateLastCrawled": "2020-02-08T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "170 <b>Machine</b> <b>Learning</b> Interview Question and Answers in 2022", "url": "https://www.mygreatlearning.com/blog/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>machine-learning-interview-questions</b>", "snippet": "6. There are many <b>machine</b> <b>learning</b> algorithms till now. If given a <b>data</b> set, how <b>can</b> one determine which <b>algorithm</b> to be used for that? <b>Machine</b> <b>Learning</b> <b>algorithm</b> to be used purely depends on the type <b>of data</b> in a given dataset. If <b>data</b> is linear then, we use linear regression. If <b>data</b> shows non-linearity then, the bagging <b>algorithm</b> would do ...", "dateLastCrawled": "2022-02-03T05:58:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "The <b>analogy</b> is many low-level features are coalesce into fewer high-level features. A simple approach is to pick a complex model with early stopping to prevent from overfitting. References: [1] Hands on <b>machine</b> <b>learning</b> with Scikit-Learn and TensorFlow p271. 4.5 How does <b>batch</b> <b>size</b> influence training speed and model accuracy ? <b>Batch</b> gradient ...", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Batch</b>, Mini <b>Batch</b> &amp; Stochastic <b>Gradient Descent</b> | by Sushant Patrikar ...", "url": "https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>batch</b>-mini-<b>batch</b>-stochastic-<b>gradient-descent</b>-7a62ecba642a", "snippet": "<b>Machine</b> <b>Learning</b> behind the scenes (Source ... <b>Batch</b> <b>Gradient Descent</b> converges directly to minima. SGD converges faster for larger datasets. But, since in SGD we use only one example at a time, we cannot implement the vectorized implementation on it. This can slow down the computations. To tackle this problem, a mixture of <b>Batch</b> <b>Gradient Descent</b> and SGD is used. Neither we use all the dataset all at once nor we use the single example at a time. We use a <b>batch</b> of a fixed number of training ...", "dateLastCrawled": "2022-02-02T11:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Gradient</b> Descent: A Quick, Simple Introduction | Built In", "url": "https://builtin.com/data-science/gradient-descent", "isFamilyFriendly": true, "displayUrl": "https://builtin.com/data-science/<b>gradient</b>-descent", "snippet": "Common mini-<b>batch</b> sizes range between 50 and 256, but like any other <b>machine</b> <b>learning</b> technique, there is no clear rule because it varies for different applications. This is the go-to algorithm when training a neural network and it is the most common type of <b>gradient</b> descent within deep <b>learning</b>.", "dateLastCrawled": "2022-02-02T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "<b>Machine</b> <b>learning</b> terminology for model building and validation There seems to be an <b>analogy</b> between statistical modeling and <b>machine</b> <b>learning</b> that we will cover in subsequent chapters in depth. However, a quick view has been provided as follows: in statistical modeling, linear regression with two independent variables is trying to fit the best plane with\u2026", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Types of Artificial Intelligence: An <b>Analogy</b> | by OCRology | OCRology ...", "url": "https://medium.com/ocrology/types-of-artificial-intelligence-an-analogy-d351b2fb7156", "isFamilyFriendly": true, "displayUrl": "https://medium.com/ocrology/types-of-artificial-intelligence-an-<b>analogy</b>-d351b2fb7156", "snippet": "<b>Machine</b> <b>learning</b> is a way to achieve artificial intelligence. It includes the ability of a computer to utilise a feedback loop to make better decisions in the future. <b>Machine</b> <b>learning</b> also relies ...", "dateLastCrawled": "2022-01-28T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "What are the <b>basic concepts in machine learning</b>? I found that the best way to discover and get a handle on the <b>basic concepts in machine learning</b> is to review the introduction chapters to <b>machine learning</b> textbooks and to watch the videos from the first model in online courses. Pedro Domingos is a lecturer and professor on <b>machine learning</b> at the University of Washing and", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Role of the <b>batch</b> <b>size</b> in prediction() : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/s37ere/role_of_the_batch_size_in_prediction/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/s37ere/role_of_the_<b>batch</b>_<b>size</b>...", "snippet": "The meaning of the <b>batch</b> <b>size</b> is clear for the training process: for <b>batch</b>_<b>size</b> =10, ... simple optimization algorithm, gradient descent (and its variants) has found an irreplaceable place in the heart of <b>machine</b> <b>learning</b>. This is majorly due to the fact that it has shown itself to be quite handy when optimizing deep neural networks and other models. The models behind the latest advances in ML and computer vision are majorly optimized using gradient descent and its variants like Adam and ...", "dateLastCrawled": "2022-01-17T14:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "GitHub - arxaqapi/<b>analogy</b>-classifier: ML approach to <b>analogy</b> classification", "url": "https://github.com/arxaqapi/analogy-classifier", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/arxaqapi/<b>analogy</b>-classifier", "snippet": "<b>analogy</b>-classifier. This repository contains a minified version of the word <b>analogy</b> classifier described in the following paper: Lim S., Prade H., Richard G. (2019) Solving Word Analogies: A <b>Machine</b> <b>Learning</b> Perspective. In: Kern-Isberner G., Ognjanovi\u0107 Z. (eds) Symbolic and Quantitative Approaches to Reasoning with Uncertainty. ECSQARU 2019 ...", "dateLastCrawled": "2021-09-03T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Confused about RNN batch sizes</b> : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/3rqgvp/confused_about_rnn_batch_sizes/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/3rqgvp/<b>confused_about_rnn_batch_sizes</b>", "snippet": "finding a smaller <b>batch</b> <b>size</b> that could &quot;make sense&quot;, e.g. each customer goes to the bathroom every 15 minutes, but I couldn&#39;t observe anything vaguely periodic. deciding on an arbitrary <b>batch</b> <b>size</b>. For instance, with a <b>batch</b> <b>size</b> of 20 minutes, the first customer&#39;s 60 minutes then appear like three customers visiting for 20 minutes. For now, I ...", "dateLastCrawled": "2021-03-04T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Word similarity and analogy with Skip</b>-Gram \u2013 KejiTech", "url": "https://davideliu.com/2020/03/16/word-similarity-and-analogy-with-skip-gram/", "isFamilyFriendly": true, "displayUrl": "https://davideliu.com/2020/03/16/<b>word-similarity-and-analogy-with-skip</b>-gram", "snippet": "<b>Machine</b> <b>Learning</b>, NLP. <b>Word similarity and analogy with Skip</b>-Gram. In this post, we are going to show words similarities and words analogies learned by 3 Skip-Gram models trained to learn words embedding from a 3GB corpus <b>size</b> taken scraping text from Wikipedia pages. Skip-Gram is unsupervised <b>learning</b> used to find the context words of given a target word. During its training process, Skip-Gram will learn a powerful vector representation for all of its vocabulary words called embedding whose ...", "dateLastCrawled": "2022-01-16T05:04:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "MLPerfTM HPC: A Holistic Benchmark Suite for Scientific <b>Machine</b> ...", "url": "https://deepai.org/publication/mlperftm-hpc-a-holistic-benchmark-suite-for-scientific-machine-learning-on-hpc-systems", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/mlperftm-hpc-a-holistic-benchmark-suite-for-scientific...", "snippet": "Scientific communities are increasingly adopting <b>machine</b> <b>learning</b> and deep <b>learning</b> models in their applications to accelerate scientific insights. High performance computing systems are pushing the frontiers of performance with a rich diversity of hardware resources and massive scale-out capabilities. There is a critical need to understand fair and effective benchmarking of <b>machine</b> <b>learning</b> applications that are representative of real-world scientific use cases. MLPerfTM is a community ...", "dateLastCrawled": "2022-01-21T06:55:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(batch size)  is like +(the amount of data that is sent to a machine learning algorithm at once)", "+(batch size) is similar to +(the amount of data that is sent to a machine learning algorithm at once)", "+(batch size) can be thought of as +(the amount of data that is sent to a machine learning algorithm at once)", "+(batch size) can be compared to +(the amount of data that is sent to a machine learning algorithm at once)", "machine learning +(batch size AND analogy)", "machine learning +(\"batch size is like\")", "machine learning +(\"batch size is similar\")", "machine learning +(\"just as batch size\")", "machine learning +(\"batch size can be thought of as\")", "machine learning +(\"batch size can be compared to\")"]}