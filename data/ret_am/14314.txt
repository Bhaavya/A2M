{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Support received by family members before, at and after an ill person\u2019s ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8228910/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8228910", "snippet": "In this study, the results <b>show</b> appreciative reports about the support family members received during the last three months of an ill person\u2019s life, at the time of the death, and after the death. However, the results also <b>show</b> that the support was not optimal for all \u2014 about a third reported that they had not received enough help and support during the illness and only a quarter had a follow-<b>up</b> conversation after the death. Around half of the family members reported having had enough ...", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 1, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Pareto principle</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Pareto_principle", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Pareto_principle</b>", "snippet": "There is no need for the two numbers to add <b>up</b> to <b>the number</b> 100, as they are measures of different things, (e.g., &#39;<b>number</b> of customers&#39; vs &#39;amount spent&#39;). However, each case in which they do not add <b>up</b> to 100%, is equivalent to one in which they do. For example, as noted above, the &quot;64/4 law&quot; (in which the two numbers do not add <b>up</b> to 100%) is equivalent to the &quot;80/20 law&quot; (in which they do add <b>up</b> to 100%). Thus, specifying two percentages independently does not lead to a broader class of ...", "dateLastCrawled": "2022-02-03T06:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "R <b>Market Basket Analysis</b> using Apriori Examples - DataCamp", "url": "https://www.datacamp.com/community/tutorials/market-basket-analysis-r", "isFamilyFriendly": true, "displayUrl": "https://www.datacamp.com/community/tutorials/<b>market-basket-analysis</b>-r", "snippet": "Sparse Matrix: A sparse matrix or sparse array is a matrix in which most of the elements are zero. By contrast, if most of the elements are nonzero, then the matrix is considered dense. <b>The number</b> of zero-valued elements divided by the total <b>number</b> of elements is called the <b>sparsity</b> of the matrix (which is equal to 1 minus the density of the ...", "dateLastCrawled": "2022-02-02T06:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "DeepSpeed: Accelerating large-scale model inference and training via ...", "url": "https://www.microsoft.com/en-us/research/blog/deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.microsoft.com</b>/en-us/research/blog/deepspeed-accelerating-large-scale-model...", "snippet": "1-bit LAMB: 4.6x communication volume reduction and <b>up</b> to 2.8x end-to-end speedup. Communication is a major bottleneck for training large models (<b>like</b> BERT and GPT-3) with hundreds or even thousands of GPUs. This is especially true on commodity systems with limited-bandwidth TCP interconnect networks. The two approaches that address this include:", "dateLastCrawled": "2022-01-28T04:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Statistical Learning with <b>Sparsity</b> Monographs on Statistics and ...", "url": "https://www.academia.edu/35754432/Statistical_Learning_with_Sparsity_Monographs_on_Statistics_and_Applied_Probability_143", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/35754432/Statistical_Learning_with_<b>Sparsity</b>_Monographs_on...", "snippet": "Statistical Learning with <b>Sparsity</b> Monographs on Statistics and Applied Probability 143", "dateLastCrawled": "2022-01-20T14:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "matlab - When should I be using `sparse`? - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/29783809/when-should-i-be-using-sparse", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/29783809", "snippet": "You could make use of <b>sparsity</b> for general neural networks (<b>like</b>. fast forward, extreme learning machine or echo state network) if you always multiply a row stored matrix by a column vector, but avoid multiplying matrices. And, you will &quot;always&quot; get an advantage by using sparse matrices if you follow the rule of thumb - it holds for finite element and convolution networks, but fails for reservoir computing.", "dateLastCrawled": "2022-01-12T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Visualizing Covid-19 Over Time</b> Using React | by Neeraj Shah | Towards ...", "url": "https://towardsdatascience.com/visualizing-covid-19-over-time-using-react-92ccf9a3354e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>visualizing-covid-19-over-time</b>-using-react-92ccf9a3354e", "snippet": "The size of the circles on our map represents <b>the number</b> <b>of people</b> who were part of the infected, recovered, or dead populations. We can control the size of a Circle component by specifying a radius. Since increasing radius causes the area of a circle to increase quadratically, we need to be careful not map populations directly to radius. Instead, we calculate the radius by taking the square root of each population and multiplying it by some constant.", "dateLastCrawled": "2022-01-31T17:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The important characteristics of structured data are", "url": "https://helpdice.com/mcq/viw2su0j7c2tsrhdra6pk36omd8bgtxmfkjiihlxcendnn7euk/?page=1034", "isFamilyFriendly": true, "displayUrl": "https://helpdice.com/mcq/viw2su0j7c2tsrhdra6pk36omd8bgtxmfkjiihlxcendnn7euk/?page=1034", "snippet": "The important characteristics of structured data are S Data Mining. A <b>Sparsity</b>, Resolution, Distribution, Tuples B <b>Sparsity</b>, Centroid, Distribution , Dimensionality C Resolution, Distribution, Dimensionality ,Objects D Dimensionality, <b>Sparsity</b>, Resolution, Distribution E 1, 2 and 4. <b>Show</b> Answer. The standard line length given by scientists for ...", "dateLastCrawled": "2022-01-27T04:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "optimization - Is there a high quality nonlinear programming solver for ...", "url": "https://scicomp.stackexchange.com/questions/83/is-there-a-high-quality-nonlinear-programming-solver-for-python", "isFamilyFriendly": true, "displayUrl": "https://scicomp.stackexchange.com/questions/83", "snippet": "A <b>number</b> of rational inequality constraints equal to about twice <b>the number</b> of decision variables; The objective function is one of the decision variables ; The Jacobian of the equality constraints is dense, as is the Jacobian of the inequality constraints. <b>python</b> optimization nonlinear-programming. Share. Cite. Improve this question. Follow edited Dec 13 &#39;11 at 5:49. David Ketcheson. asked Nov 30 &#39;11 at 15:10. David Ketcheson David Ketcheson. 16k 3 3 gold badges 49 49 silver badges 104 104 ...", "dateLastCrawled": "2022-02-03T05:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "M1 Pro First Impressions: 2 Core management and CPU performance \u2013 The ...", "url": "https://eclecticlight.co/2021/11/04/m1-pro-first-impressions-2-core-management-and-cpu-performance/", "isFamilyFriendly": true, "displayUrl": "https://eclecticlight.co/2021/11/04/m1-pro-first-impressions-2-core-management-and-cpu...", "snippet": "Ideally there would be a way for a high-QoS process blocking on a system service to bump it <b>up</b> to a P-core. <b>Like</b> Liked by 1 person. 17. hoakley on November 5, 2021 at 2:12 pm . Reply. Thank you. I wasn\u2019t aware that Mail waited for indexing to complete. That seems a strange behaviour, given that on any Mac, such indexing is a background activity which could take a long time to complete. Howard. <b>Like</b> <b>Like</b>. 18. name99 on November 6, 2021 at 6:42 pm . Reply. Certainly this is acknowledged and ...", "dateLastCrawled": "2022-01-31T00:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Pareto principle</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Pareto_principle", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Pareto_principle</b>", "snippet": "There is no need for the two numbers to add <b>up</b> <b>to the number</b> 100, as they are measures of different things, (e.g., &#39;<b>number</b> of customers&#39; vs &#39;amount spent&#39;). However, each case in which they do not add <b>up</b> to 100%, is equivalent to one in which they do. For example, as noted above, the &quot;64/4 law&quot; (in which the two numbers do not add <b>up</b> to 100%) is equivalent to the &quot;80/20 law&quot; (in which they do add <b>up</b> to 100%). Thus, specifying two percentages independently does not lead to a broader class of ...", "dateLastCrawled": "2022-02-03T06:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Statistical Learning with <b>Sparsity</b> Monographs on Statistics and ...", "url": "https://www.academia.edu/35754432/Statistical_Learning_with_Sparsity_Monographs_on_Statistics_and_Applied_Probability_143", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/35754432/Statistical_Learning_with_<b>Sparsity</b>_Monographs_on...", "snippet": "Statistical Learning with <b>Sparsity</b> Monographs on Statistics and Applied Probability 143", "dateLastCrawled": "2022-01-20T14:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Deep neural network models for identifying incident dementia using ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0236400", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0236400", "snippet": "Introduction. Over 50 million <b>people</b> lived with dementia worldwide in 2019, and those numbers are expected to increase to 152 million by 2050 [].Within the United States, an estimated 5.8 million <b>people</b> of all ages are living with the most common form of dementia, Alzheimer\u2019s disease (AD), and this <b>number</b> is expected by rise to 13.8 million by the year 2050 [].The total health care and long-term care costs associated with AD and related dementias were $277 billion in the US in 2018 ...", "dateLastCrawled": "2020-12-13T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>ERWIN Intermediate Quiz</b> - Trenovision", "url": "https://trenovision.com/erwin-intermediate-quiz/", "isFamilyFriendly": true, "displayUrl": "https://trenovision.com/<b>erwin-intermediate-quiz</b>", "snippet": "Data <b>sparsity</b>; <b>Show</b> Answer. Answer : C 4) Causal dimensions can be used. As a helper table; For explaining why a record exists in a fact table ; For integrating data marts into a data warehouse; For handling changes to the data. <b>Show</b> Answer. Answer : B 5) Dimension table may NOT be populated from. Look <b>up</b> data; Transaction data; Master data; Reference Data; <b>Show</b> Answer. Answer : B 6) Dimension where data quality cannot be guaranteed is. Conformed dimension; Dirty Dimension; Big Dimension ...", "dateLastCrawled": "2021-12-19T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "CS 70 Discrete Mathematics and Probability Theory Spring 2021 HW 4", "url": "http://www.sp21.eecs70.org/static/homeworks/hw4.pdf", "isFamilyFriendly": true, "displayUrl": "www.sp21.eecs70.org/static/homeworks/hw4.pdf", "snippet": "<b>number</b> of students celebrating, the chief organizer lined the students <b>up</b> in columns of different length. If the students are arranged in columns of 3, 5, and 7, then 2, 3, and 4 <b>people</b> are left out, respectively. What is the minimum <b>number</b> of students present? Solve it with Chinese Remainder Theorem. (b)Prove that for n 1, if 935 =5 11 17 divides n80 1, then 5, 11, and 17 do not divide n. 2 Advanced Chinese Remainder Theorem Constructions In this question we will see some very interesting ...", "dateLastCrawled": "2022-01-09T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Nuit Blanche: CS:OLS/ROLS/StOLS, Group <b>sparsity</b>, Poisson CS, CS of ...", "url": "https://nuit-blanche.blogspot.com/2009/01/csolsrolsstols-group-sparsity-poisson.html", "isFamilyFriendly": true, "displayUrl": "https://nuit-blanche.blogspot.com/2009/01/csolsrolsstols-group-<b>sparsity</b>-poisson.html", "snippet": "Moreover, the choice of the linear samples does not depend on the <b>sparsity</b> domain. In this paper, we will <b>show</b> that the replacement of random linear samples with deterministic functions of the signal (not necessarily linear) will not result in unique reconstruction of k-sparse signals except for k=1. We will <b>show</b> that there exist deterministic nonlinear sampling functions for unique reconstruction of 1- sparse signals while deterministic linear samples fail to do so. Minimax risk for Poisson ...", "dateLastCrawled": "2022-01-31T13:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 6, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Recommender system</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Recommender_system", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Recommender_system</b>", "snippet": "Collaborative filtering is based on the assumption that <b>people</b> who agreed in the past will agree in the future, and that they will like <b>similar</b> kinds of items as they liked in the past. The system generates recommendations using only information about rating profiles for different users or items. By locating peer users/items with a rating history <b>similar</b> to the current user or item, they generate recommendations using this neighborhood. Collaborative filtering methods are classified as ...", "dateLastCrawled": "2022-02-03T04:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "matlab - When should I be using `sparse`? - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/29783809/when-should-i-be-using-sparse", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/29783809", "snippet": "The computational complexity of sparse operations is proportional to nnz, the <b>number</b> of nonzero elements in the matrix. Computational complexity also depends linearly on the row size m and column size n of the matrix, but is independent of the product m*n, the total <b>number</b> of zero and nonzero elements. This is difficult to compare to a full matrix without knowing more details. Scipy&#39;s <b>sparse matrix</b> library explains pros and cons of each sparse format. For example for the csc_matrix ...", "dateLastCrawled": "2022-01-12T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Build a Recommendation Engine With <b>Collaborative Filtering</b> \u2013 Real Python", "url": "https://realpython.com/build-recommendation-engine-collaborative-filtering/", "isFamilyFriendly": true, "displayUrl": "https://realpython.com/build-recommendation-engine-<b>collaborative-filtering</b>", "snippet": "It works by searching a large group <b>of people</b> and finding a smaller set of users with tastes <b>similar</b> to a particular user. It looks at the items they like and combines them to create a ranked list of suggestions. There are many ways to decide which users are <b>similar</b> and combine their choices to create a list of recommendations. This article will <b>show</b> you how to do that with Python. Remove ads. The Dataset. To experiment with recommendation algorithms, you\u2019ll need data that contains a set ...", "dateLastCrawled": "2022-02-02T15:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "optimization - Is there a high quality nonlinear programming solver for ...", "url": "https://scicomp.stackexchange.com/questions/83/is-there-a-high-quality-nonlinear-programming-solver-for-python", "isFamilyFriendly": true, "displayUrl": "https://scicomp.stackexchange.com/questions/83", "snippet": "A <b>number</b> of rational inequality constraints equal to about twice the <b>number</b> of decision variables; The objective function is one of the decision variables ; The Jacobian of the equality constraints is dense, as is the Jacobian of the inequality constraints. <b>python</b> optimization nonlinear-programming. Share. Cite. Improve this question. Follow edited Dec 13 &#39;11 at 5:49. David Ketcheson. asked Nov 30 &#39;11 at 15:10. David Ketcheson David Ketcheson. 16k 3 3 gold badges 49 49 silver badges 104 104 ...", "dateLastCrawled": "2022-02-03T05:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Pareto principle</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Pareto_principle", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Pareto_principle</b>", "snippet": "There is no need for the two numbers to add <b>up</b> to the <b>number</b> 100, as they are measures of different things, (e.g., &#39;<b>number</b> of customers&#39; vs &#39;amount spent&#39;). However, each case in which they do not add <b>up</b> to 100%, is equivalent to one in which they do. For example, as noted above, the &quot;64/4 law&quot; (in which the two numbers do not add <b>up</b> to 100%) is equivalent to the &quot;80/20 law&quot; (in which they do add <b>up</b> to 100%). Thus, specifying two percentages independently does not lead to a broader class of ...", "dateLastCrawled": "2022-02-03T06:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Support received by family members before, at and after an ill person\u2019s ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8228910/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8228910", "snippet": "However, the results also <b>show</b> that the support was not optimal for all \u2014 about a third reported that they had not received enough help and support during the illness and only a quarter had a follow-<b>up</b> conversation after the death. Around half of the family members reported having had enough support at the time of the ill person\u2019s death. In addition, the imminence of death was not clear for about 15% of family members, which was also described as having affected the opportunity for them ...", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Forecasting influenza-like illness trends in Cameroon using Google ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7991669/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7991669", "snippet": "Introduction. Influenza and other respiratory tract infections remain a global public health issue in spite of vaccine availability 1.Every year, there are about 650,000 deaths globally and three to five million respiratory illnesses due to the influenza virus 2.In Africa, acute respiratory infections are <b>thought</b> to be a major cause of morbidity and mortality 3, 4, despite considerable under-reporting and <b>sparsity</b> of precise assessments of the total health and economic burden across the ...", "dateLastCrawled": "2021-06-03T09:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 3, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>History of mathematics</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/History_of_mathematics", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>History_of_mathematics</b>", "snippet": "The <b>history of mathematics</b> deals with the origin of discoveries in mathematics and the mathematical methods and notation of the past.Before the modern age and the worldwide spread of knowledge, written examples of new mathematical developments have come to light only in a few locales. From 3000 BC the Mesopotamian states of Sumer, Akkad and Assyria, followed closely by Ancient Egypt and the Levantine state of Ebla began using arithmetic, algebra and geometry for purposes of taxation ...", "dateLastCrawled": "2022-01-29T06:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How <b>Smart And Successful People Think And Act</b>", "url": "https://www.linkedin.com/pulse/how-smartest-most-successful-people-think-act-andreas-von-der-heydt", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/how-smartest-most-successful-<b>people</b>-think-act-andreas...", "snippet": "Dunbar&#39;s <b>number</b> is a suggested cognitive limit to the <b>number</b> <b>of people</b> with whom one <b>can</b> maintain stable social relationships\u2014relationships in which an individual knows who each person is and ...", "dateLastCrawled": "2021-11-24T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Sparse</b> Definition &amp; Meaning - <b>Merriam-Webster</b>", "url": "https://www.merriam-webster.com/dictionary/sparse", "isFamilyFriendly": true, "displayUrl": "https://<b>www.merriam-webster.com</b>/dictionary/<b>sparse</b>", "snippet": "The meaning of <b>SPARSE</b> is of few and scattered elements; especially : not thickly grown or settled. How to use <b>sparse</b> in a sentence. Synonym Discussion of <b>Sparse</b>.", "dateLastCrawled": "2022-02-02T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Clustering User Histograms: A novel idea for grouping demographics ...", "url": "https://leyankoh.wordpress.com/2019/02/11/clustering-user-histograms-a-novel-idea-for-grouping-demographics-part-3/", "isFamilyFriendly": true, "displayUrl": "https://leyankoh.wordpress.com/2019/02/11/clustering-user-histograms-a-novel-idea-for...", "snippet": "User cluster 2 <b>can</b> be interpreted as commuting working professions who spend a lot of time on transport, between their residence and work place. User cluster 3 are like user clusters 0 and 1, except with a more <b>party</b>-like twist. They\u2019re less likely to be visiting the high street (or whatever the New York equivalent is!) and hitting <b>up</b> the ...", "dateLastCrawled": "2022-01-08T09:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>google-research</b>/newstest2014.en at master - <b>GitHub</b>", "url": "https://github.com/google-research/google-research/blob/master/state_of_sparsity/sparse_transformer/decode/newstest2014.en", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>google-research/google-research</b>/blob/master/state_of_<b>sparsity</b>/...", "snippet": "Unfortunately, in the event of unfavourable wind, they <b>can</b> be heard from far away - and as a result there have already been a <b>number</b> of complaints from <b>people</b> from the north of the town. The 40-year-old said that he is taking the complaints very seriously and has therefore been in touch with those affected.", "dateLastCrawled": "2021-09-22T08:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep Learning vs Machine Learning Challenger Models for Default Risk ...", "url": "https://developer.nvidia.com/blog/deep-learning-vs-machine-learning-challenger-models-for-default-risk-with-explainability/", "isFamilyFriendly": true, "displayUrl": "https://developer.nvidia.com/blog/deep-learning-vs-machine-learning-challenger-models...", "snippet": "We also <b>show</b> the simple speedups obtained by an NVTabular data loader for model training. This same example could be extended to credit underwriting, credit card delinquency, or a host of other important class-imbalance binary classification problems. A common theme in all financial credit risk modeling is the concern for the expected loss. Whether the transaction is a trading agreement between two counter parties where one <b>party</b> owes the other <b>party</b> some amount, or is a loan agreement with ...", "dateLastCrawled": "2022-01-29T09:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>MS Business Analytics Capstone Projects | Lindner College</b> of Business ...", "url": "https://business.uc.edu/academics/specialized-masters/business-analytics/capstone.html", "isFamilyFriendly": true, "displayUrl": "https://business.uc.edu/academics/specialized-masters/business-analytics/capstone.html", "snippet": "<b>People</b> <b>show</b> their appreciation as well as frustration towards a product through social media. If there is a way to understand the sentiments expressed about a product, it <b>can</b> be very useful. This project analyzes the tweets to understand their sentiment over time. This analysis will help Great American Insurance in their underwriting decisions. Anjali Gautam, Prioritization of Calls, August 2020, (Michael Fry, Siddharth Krishnamurthi) For a Collections Team in a bank, contacting customers ...", "dateLastCrawled": "2022-02-03T06:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "DeepSpeed: Accelerating large-scale model inference and training via ...", "url": "https://www.microsoft.com/en-us/research/blog/deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.microsoft.com</b>/en-us/research/blog/deepspeed-accelerating-large-scale-model...", "snippet": "<b>Compared</b> with PyTorch, DeepSpeed achieves 2.3x faster inference speed using the same <b>number</b> of GPUs. DeepSpeed reduces the <b>number</b> of GPUs for serving this model to 2 in FP16 with 1.9x faster latency. With MoQ and inference-adapted parallelism, DeepSpeed is able to serve this model on a single GPU in INT8 with 1.7x latency reduction and 6.2x cost savings.", "dateLastCrawled": "2022-01-28T04:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Cities through the Prism <b>of People</b>\u2019s Spending Behavior", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0146291", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0146291", "snippet": "As <b>can</b> be seen, entertaining activities like traveling, going out for a drink, diner or a <b>party</b> are strongly boosted by city size, with a scaling exponent over 1.1. In bigger cities, <b>people</b> seem to engage more easily in social activities, which confirms the suggestion of . Similarly, categories such as wellness, beauty, and fashion also possess ...", "dateLastCrawled": "2021-10-11T01:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>google-research</b>/newstest2014.en at master - <b>GitHub</b>", "url": "https://github.com/google-research/google-research/blob/master/state_of_sparsity/sparse_transformer/decode/newstest2014.en", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>google-research/google-research</b>/blob/master/state_of_<b>sparsity</b>/...", "snippet": "Unfortunately, in the event of unfavourable wind, they <b>can</b> be heard from far away - and as a result there have already been a <b>number</b> of complaints from <b>people</b> from the north of the town. The 40-year-old said that he is taking the complaints very seriously and has therefore been in touch with those affected.", "dateLastCrawled": "2021-09-22T08:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Update of transmission modelling and projections of gambiense human ...", "url": "https://idpjournal.biomedcentral.com/articles/10.1186/s40249-022-00934-8", "isFamilyFriendly": true, "displayUrl": "https://idpjournal.biomedcentral.com/articles/10.1186/s40249-022-00934-8", "snippet": "Large differences between assumed screening levels and actual screening levels <b>can</b> have a substantial impact on model projections\u2014if there is no screening there would be no active cases, whereas there could be a high <b>number</b> of cases if large proportions of the population were screened. In Mahamat et al., it was assumed that the screening numbers for 2016\u20132019 would be 27,265 each year (the same as in 2015), whereas new data from the WHO HAT Atlas and PNLTHA-Chad are somewhat lower\u201422 ...", "dateLastCrawled": "2022-02-01T00:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How <b>Smart And Successful People Think And Act</b>", "url": "https://www.linkedin.com/pulse/how-smartest-most-successful-people-think-act-andreas-von-der-heydt", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/how-smartest-most-successful-<b>people</b>-think-act-andreas...", "snippet": "Dunbar&#39;s <b>number</b> is a suggested cognitive limit <b>to the number</b> <b>of people</b> with whom one <b>can</b> maintain stable social relationships\u2014relationships in which an individual knows who each person is and ...", "dateLastCrawled": "2021-11-24T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Deep Learning vs Machine Learning Challenger Models for Default Risk ...", "url": "https://developer.nvidia.com/blog/deep-learning-vs-machine-learning-challenger-models-for-default-risk-with-explainability/", "isFamilyFriendly": true, "displayUrl": "https://developer.nvidia.com/blog/deep-learning-vs-machine-learning-challenger-models...", "snippet": "We also <b>show</b> the simple speedups obtained by an NVTabular data loader for model training. This same example could be extended to credit underwriting, credit card delinquency, or a host of other important class-imbalance binary classification problems. A common theme in all financial credit risk modeling is the concern for the expected loss. Whether the transaction is a trading agreement between two counter parties where one <b>party</b> owes the other <b>party</b> some amount, or is a loan agreement with ...", "dateLastCrawled": "2022-01-29T09:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Bayesian multiple <b>logistic</b> regression for <b>case-control</b> GWAS", "url": "https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1007856", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1007856", "snippet": "Author summary In recent years, genome wide association studies (GWAS) have become the primary approach for identifying genetic variants associated with the origination of complex diseases. In <b>case-control</b> GWAS, the genotypes of roughly equal <b>number</b> of diseased (\u201ccases\u201d) and healthy (\u201ccontrols\u201d) <b>people</b> are <b>compared</b> to determine which genetic variants are significantly more frequent among cases. From the disease-associated variants we hope to get insights into how the disease develops.", "dateLastCrawled": "2021-11-16T20:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>MS Business Analytics Capstone Projects | Lindner College</b> of Business ...", "url": "https://business.uc.edu/academics/specialized-masters/business-analytics/capstone.html", "isFamilyFriendly": true, "displayUrl": "https://business.uc.edu/academics/specialized-masters/business-analytics/capstone.html", "snippet": "<b>People</b> <b>show</b> their appreciation as well as frustration towards a product through social media. If there is a way to understand the sentiments expressed about a product, it <b>can</b> be very useful. This project analyzes the tweets to understand their sentiment over time. This analysis will help Great American Insurance in their underwriting decisions. Anjali Gautam, Prioritization of Calls, August 2020, (Michael Fry, Siddharth Krishnamurthi) For a Collections Team in a bank, contacting customers ...", "dateLastCrawled": "2022-02-03T06:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 8, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>LinkedIn</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/LinkedIn", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>LinkedIn</b>", "snippet": "<b>LinkedIn</b> (/ l \u026a \u014b k t \u02c8 \u026a n /) is an American business- and employment-oriented online service that operates via websites and mobile apps.Launched on May 5, 2003, the platform is primarily used for professional networking and career development, and allows job seekers to post their CVs and employers to post jobs.As of 2015, most of the company&#39;s revenue came from selling access to information about its members to recruiters and sales professionals. Since December 2016, it has been a ...", "dateLastCrawled": "2022-02-06T14:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Hurricanes in the North Atlantic are increasing in frequency, says study", "url": "https://www.yahoo.com/entertainment/hurricanes-north-atlantic-increasing-frequency-190815969.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.yahoo.com</b>/entertainment/hurri<b>can</b>es-north-atlantic-increasing-frequency...", "snippet": "New research confirms what historical records have been telling us \u2014 that hurricane activity in the North Atlantic has been increasing over the past 150 years. Today, with the array of ...", "dateLastCrawled": "2022-01-23T08:10:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Sparsity</b> is an essential feature of many contemporary data problems. Remote sensing, various forms of automated screening and other high throughput measurement devices collect a large amount of ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Regularization \u2014 Understanding L1 and L2 regularization for Deep <b>Learning</b>", "url": "https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2-regularization-for-deep-learning-a7b9e4a409bf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2...", "snippet": "The <b>sparsity</b> feature used in L1 regularization has been used extensively as a feature selection mechanism in <b>machine</b> <b>learning</b>. Feature selection is a mechanism which inherently simplifies a ...", "dateLastCrawled": "2022-02-01T00:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "An E\ufb03cient Sparse Metric <b>Learning</b> in High ... - <b>Machine</b> <b>Learning</b>", "url": "http://machinelearning.org/archive/icml2009/papers/46.pdf", "isFamilyFriendly": true, "displayUrl": "<b>machinelearning</b>.org/archive/icml2009/papers/46.pdf", "snippet": "This <b>sparsity</b> prior of <b>learning</b> distance metric serves to regularize the com-plexity of the distance model especially in the \u201cless example number p and high dimension d\u201d setting. Theoretically, by <b>analogy</b> to the covariance estimation problem, we \ufb01nd the proposed distance <b>learning</b> algorithm has a consistent result at rate O!&quot;# m2 logd $% n &amp; to the target distance matrix with at most m nonzeros per row. Moreover, from the imple-mentation perspective, this! 1-penalized log-determinant ...", "dateLastCrawled": "2021-11-19T11:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Dynamical <b>machine</b> <b>learning</b> volumetric reconstruction of objects ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8027224/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8027224", "snippet": "The sequence index in the angle of illumination plays the role of discrete time in the dynamical system <b>analogy</b>. Thus, the imaging problem turns into a problem of nonlinear system identification, which also suggests dynamical <b>learning</b> as a better fit to regularize the reconstructions. We devised a Recurrent Neural Network (RNN) architecture with a novel Separable-Convolution Gated Recurrent Unit (SC-GRU) as the fundamental building block. Through a comprehensive comparison of several ...", "dateLastCrawled": "2022-01-08T19:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Discovering governing equations from data</b> by sparse identification of ...", "url": "https://www.pnas.org/content/pnas/113/15/3932.full.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/<b>pnas</b>/113/15/3932.full.pdf", "snippet": "examples. In this work, we combin e <b>sparsity</b>-promoting techniques and <b>machine</b> <b>learning</b> with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only as-sumption about the structureof the model is that there are onlya few important terms that govern the dy namics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to ...", "dateLastCrawled": "2022-01-20T20:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Dynamical machine learning volumetric reconstruction of</b> objects ...", "url": "https://www.nature.com/articles/s41377-021-00512-x", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41377-021-00512-x", "snippet": "Recently, thanks to a ground-breaking observation from 2010 that <b>sparsity</b> can be learnt by a deep neural network 48, the idea of using <b>machine</b> <b>learning</b> to approximate solutions to inverse problems ...", "dateLastCrawled": "2022-02-02T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Regularization : What? Why? and How? (Part -1) | by Siddhant Rai ...", "url": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "isFamilyFriendly": true, "displayUrl": "https://medium.com/m<b>learning</b>-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "snippet": "In general <b>machine</b> <b>learning</b> sense, it is solving an objective function to perform maximum or minimum evaluation. In reality, optimization is lot more profound in usage. Then we have two terms ...", "dateLastCrawled": "2022-01-28T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Controversies in Predictive Modeling, <b>Machine</b> <b>Learning</b>, and Validation", "url": "http://hbiostat.org/talks/stratos19.pdf", "isFamilyFriendly": true, "displayUrl": "hbiostat.org/talks/stratos19.pdf", "snippet": "<b>Sparsity</b> priors (e.g. horseshoe) are chosen to match biological knowledge and performance goals not because of availability of analytic results and fast software Easy to handle ordinal predictors (categorical with prior tilting towards monotonicity) D.f. for nonlinear e ects can be data-determined and still preserve Bayesian operating characteristics. Controversies in Predictive Modeling, <b>Machine</b> <b>Learning</b>, and Validation Model Validation Bayesian Modeling Variable Selection ML and SM ...", "dateLastCrawled": "2021-11-01T20:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "regression - Why L1 norm for sparse models - Cross Validated", "url": "https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/45643", "snippet": "There are many norms that lead to <b>sparsity</b> (e.g., as you mentioned, any Lp norm with p &lt;= 1). In general, any norm with a sharp corner at zero induces <b>sparsity</b>. So, going back to the original question - the L1 norm induces <b>sparsity</b> by having a discontinuous gradient at zero (and any other penalty with this property will do so too). $\\endgroup$", "dateLastCrawled": "2022-01-26T23:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[2009.11697] <b>Compressed imitation learning</b>", "url": "https://arxiv.org/abs/2009.11697", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2009.11697", "snippet": "In <b>analogy</b> to compressed sensing, which allows sample-efficient signal reconstruction given prior knowledge of its <b>sparsity</b> in frequency domain, we propose to utilize policy simplicity (Occam&#39;s Razor) as a prior to enable sample-efficient imitation <b>learning</b>. We first demonstrated the feasibility of this scheme on linear case where state-value function can be sampled directly. We also extended the scheme to scenarios where only actions are visible and scenarios where the policy is obtained ...", "dateLastCrawled": "2022-01-29T01:56:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Learning Neural Representations for Network Anomaly Detection</b>", "url": "https://www.researchgate.net/publication/325797465_Learning_Neural_Representations_for_Network_Anomaly_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/325797465_<b>Learning</b>_Neural_Representations_for...", "snippet": "Many <b>machine</b> <b>learning</b> algorithms have been. Manuscript received December 22, 2017; revised March 13, 2018. This. work is funded by Vietnam International Education De velopment (VIED) and. by ...", "dateLastCrawled": "2021-12-06T22:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Self-representation based dual-graph regularized <b>feature selection</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231215010759", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231215010759", "snippet": "<b>Just as sparsity</b> leads to sparse representation, self-similarity results in self-representation ... Her current research interests include pattern recognition and <b>machine</b> <b>learning</b>. Licheng Jiao (SM\u05f389) received the B.S. degree from Shanghai Jiaotong University, Shanghai, China, in 1982, the M.S. and Ph.D. degrees from Xi\u05f3an Jiaotong University, Xi\u05f3an, China, in 1984 and 1990, respectively. From 1990 to 1991, he was a postdoctoral Fellow in the National Key Laboratory for Radar Signal ...", "dateLastCrawled": "2021-11-22T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Self-representation based dual-graph regularized feature selection ...", "url": "https://web.xidian.edu.cn/rhshang/files/20160516_172953.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.xidian.edu.cn/rhshang/files/20160516_172953.pdf", "snippet": "<b>machine</b> <b>learning</b> and computer vision \ufb01elds [41]. <b>Just as sparsity</b> leads to sparse representation, self-similarity results in self-representation [41]. Taking into account of manifold <b>learning</b> and feature selection, and inspired by the self-representation property and the idea of dual-regularization <b>learning</b> [44,45], we propose a novel feature selection algorithm for clustering, named self-representation based dual-graph regularized feature selection clustering (DFSC). This algorithm ...", "dateLastCrawled": "2022-02-02T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Unsupervised feature selection</b> by <b>regularized self-representation</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0031320314002970", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320314002970", "snippet": "<b>Just as sparsity</b> leads to sparse representation, self-similarity results in self-representation. With the above considerations, in this paper we propose a simple yet very effective <b>unsupervised feature selection</b> method by exploiting the self-representation ability of features. The feature matrix is represented over itself to find the representative feature components. The representation residual is minimized by L 2, 1-norm loss to reduce the effect of outlier samples. Different from the ...", "dateLastCrawled": "2022-01-24T12:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Talk <b>Archive</b> - Research on Algorithms and Incentives in Networks", "url": "https://rain.stanford.edu/schedule/archive.shtml", "isFamilyFriendly": true, "displayUrl": "https://rain.stanford.edu/schedule/<b>archive</b>.shtml", "snippet": "McFowland\u2019s research interests\u2014which lie at the intersection of Information Systems, <b>Machine</b> <b>Learning</b>, and Public Policy\u2014include the development of computationally efficient algorithms for large-scale statistical <b>machine</b> <b>learning</b> and \u201cbig data\u201d analytics. More specifically, his research seeks to demonstrate that many real-world problems faced by organizations, and society more broadly, can be reduced to the tasks of anomalous pattern detection and discovery. As a data and ...", "dateLastCrawled": "2022-01-20T11:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Talks - <b>sites.google.com</b>", "url": "https://sites.google.com/view/dssseminarseries/talks", "isFamilyFriendly": true, "displayUrl": "https://<b>sites.google.com</b>/view/dssseminarseries/talks", "snippet": "Abstracts &amp; Bios for upcoming talks", "dateLastCrawled": "2022-01-27T14:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Sparse representations for text categorization</b>", "url": "https://www.researchgate.net/publication/221479613_Sparse_representations_for_text_categorization", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221479613_Sparse_representations_for_text...", "snippet": "<b>Machine</b> <b>learning</b> for text classification is the cornerstone of document categorization, news filtering, document routing, and personalization. In text domains, effective feature selection is ...", "dateLastCrawled": "2021-12-10T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Continual Learning via Neural Pruning</b> | DeepAI", "url": "https://deepai.org/publication/continual-learning-via-neural-pruning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>continual-learning-via-neural-pruning</b>", "snippet": "Continual <b>learning</b>, the ability of models to learn to solve new tasks beyond what has previously been trained, has garnered much attention from the <b>machine</b> <b>learning</b> community in recent years. This is driven in part by the practical advantages promised by continual <b>learning</b> schemes such as improved performance on subsequent tasks as well as a more efficient use of resources in machines with memory constraints.", "dateLastCrawled": "2021-12-30T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Non-negative data-<b>driven mapping of structural connections</b> with ...", "url": "https://www.sciencedirect.com/science/article/pii/S105381192030759X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S105381192030759X", "snippet": "For ICA, <b>sparsity can be thought of as</b> a proxy for independence. 3.5. In-vivo data decompositions. For real data, we decomposed group-average tractography matrices, using independent component analysis (ICA) and non-negative matrix factorisation (NMF), with a range of model orders K. ICA was initialised with regular PCA, in which the first 500 components were retained (explaining 97% of the total variance). ICA was applied to the reduced dataset using the FastICA algorithm (Hyv\u00e4rinen and ...", "dateLastCrawled": "2021-10-11T05:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Sparse Representations for Text Categorization</b> | Dimitri Kanevsky ...", "url": "https://www.academia.edu/2738730/Sparse_Representations_for_Text_Categorization", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2738730/<b>Sparse_Representations_for_Text_Categorization</b>", "snippet": "A Comparative Study of <b>Machine</b> <b>Learning</b> Methods for Verbal Autopsy Text Classification. By Eric S Atwell and Samuel Danso. CSC435 book proposal. By Russell Frith. Higher-Order Smoothing: A Novel Semantic Smoothing Method for Text Classification. By Murat C Ganiz, Mitat Poyraz, and Zeynep Kilimci. INFORMATION RETRIEVAL. By febi k. Introduction to information retrieval. By Valeria Mesi. Download pdf. \u00d7 Close Log In. Log In with Facebook Log In with Google. Sign Up with Apple. or. Email ...", "dateLastCrawled": "2021-10-13T23:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Continual <b>Learning</b> via Neural Pruning \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1903.04476/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1903.04476", "snippet": "We introduce Continual <b>Learning</b> via Neural Pruning (CLNP), a new method aimed at lifelong <b>learning</b> in fixed capacity models based on neuronal model sparsification. In this method, subsequent tasks are trained using the inactive neurons and filters of the sparsified network and cause zero deterioration to the performance of previous tasks. In order to deal with the possible compromise between model sparsity and performance, we formalize and incorporate the concept of graceful forgetting: the ...", "dateLastCrawled": "2021-11-07T10:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Continual <b>Learning</b> via Neural Pruning", "url": "https://openreview.net/pdf?id=Hyl_XXYLIB", "isFamilyFriendly": true, "displayUrl": "https://openreview.net/pdf?id=Hyl_XXYLIB", "snippet": "Continual <b>learning</b>, the ability of models to learn to solve new tasks beyond what has previously been trained, has garnered much at-tention from the <b>machine</b> <b>learning</b> community in recent years. The main obstacle for effective continual <b>learning</b> is the problem of cata-strophic forgetting: machines trained on new problems forget about", "dateLastCrawled": "2022-01-05T02:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Abstract - arXiv.org e-Print archive", "url": "https://arxiv.org/pdf/1903.04476", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/1903.04476", "snippet": "Continual <b>learning</b>, the ability of models to learn to solve new tasks beyond what has previously been trained, has garnered much attention from the <b>machine</b> <b>learning</b> community in recent years. This is driven in part by the practical advantages promised by continual <b>learning</b> schemes such as improved performance on subsequent tasks as well as a more ef\ufb01cient use of resources in machines with memory constraints. There is also great interest in continual <b>learning</b> from a more long term ...", "dateLastCrawled": "2021-10-25T14:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Introduction to compressed sensing</b>", "url": "https://www.researchgate.net/publication/220043734_Introduction_to_compressed_sensing", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220043734_<b>Introduction_to_compressed_sensing</b>", "snippet": "systems control, clustering, and <b>machine</b> <b>learning</b> [14, 15, 58, 61, 89, 193, 217, 240, 244]. Low-dimensional manifolds hav e also been prop osed as approximate mod-", "dateLastCrawled": "2022-01-14T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Introduction to compressed sensing</b> | Marco Duarte - Academia.edu", "url": "https://www.academia.edu/1443164/Introduction_to_compressed_sensing", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/1443164/<b>Introduction_to_compressed_sensing</b>", "snippet": "<b>Introduction to Compressed Sensing</b> For any x \u2208 \u03a3k , we can associate a k-face of C n with the support and sign pattern of x. One can show that the number of k-faces of AC n is precisely the number of index sets of size k for which signals supported on them can be recovered by (1.12) with B (y) = {z : Az = y}.", "dateLastCrawled": "2022-01-21T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Compressed Sensing : Theory and Applications</b> | Kutyniok, Gitta Eldar ...", "url": "https://b-ok.africa/book/2086657/84a688", "isFamilyFriendly": true, "displayUrl": "https://b-ok.africa/book/2086657/84a688", "snippet": "You can write a book review and share your experiences. Other readers will always be interested in your opinion of the books you&#39;ve read. Whether you&#39;ve loved the book or not, if you give your honest and detailed thoughts then people will find new books that are right for them.", "dateLastCrawled": "2021-12-26T07:22:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(sparsity)  is like +(the number of people who show up to a party)", "+(sparsity) is similar to +(the number of people who show up to a party)", "+(sparsity) can be thought of as +(the number of people who show up to a party)", "+(sparsity) can be compared to +(the number of people who show up to a party)", "machine learning +(sparsity AND analogy)", "machine learning +(\"sparsity is like\")", "machine learning +(\"sparsity is similar\")", "machine learning +(\"just as sparsity\")", "machine learning +(\"sparsity can be thought of as\")", "machine learning +(\"sparsity can be compared to\")"]}