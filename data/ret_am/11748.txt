{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Reinforcement and deep reinforcement <b>learning</b> for wireless Internet of ...", "url": "https://www.sciencedirect.com/science/article/pii/S0140366421002681", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0140366421002681", "snippet": "Over the last five years, <b>Machine</b> <b>Learning</b> ... deep Q-<b>learning</b>, and <b>greedy</b> <b>policy</b> RL <b>algorithm</b>. Simulations show that the proposed AC-FNBRF outperforms the others with a gain that reaches 25% on power consumption and 35% on transmission delay when the packet arrival rates are high. 4.2.3. Time slot scheduling. Time slot scheduling algorithms dynamically allocate a unit of time for a set of devices to communicate, collect or transfer data to another device in order to improve throughput and ...", "dateLastCrawled": "2022-01-27T03:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b> (Deep <b>Learning</b>) Algorithms \u2013 DeepAI.space", "url": "https://deepai.space/machine-learning-deep-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://deepai.space/<b>machine</b>-<b>learning</b>-deep-<b>learning</b>-<b>algorithms</b>", "snippet": "Decision Tree . A decision tree is a decision support tool that uses a tree-<b>like</b> model of decisions and their <b>possible</b> consequences, including chance event outcomes, resource costs, and <b>utility</b>.It is one way to display an <b>algorithm</b> that only contains conditional control statements.. Decision trees are commonly used in <b>operations research</b>, specifically in decision analysis, to help identify a strategy most likely to reach a goal, but are also a popular tool in <b>machine</b> <b>learning</b>.. A decision ...", "dateLastCrawled": "2022-01-28T15:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "MITx_6.86x/Unit 05 - Reinforcement <b>Learning</b>.md at master - <b>GitHub</b>", "url": "https://github.com/sylvaticus/MITx_6.86x/blob/master/Unit%2005%20-%20Reinforcement%20Learning/Unit%2005%20-%20Reinforcement%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/sylvaticus/MITx_6.86x/blob/master/Unit 05 - Reinforcement <b>Learning</b>...", "snippet": "17.4. <b>Utility</b> <b>Function</b>. The main problem for MDPs is to optimize the agent&#39;s behavior. To do so, we first need to specify the criterion that we are trying <b>to maximize</b> in terms of accumulated rewards. We will define a <b>utility</b> <b>function</b> and <b>maximize</b> <b>its</b> expectation. Note that this should be a finite number, in order to compare different <b>possible</b> ...", "dateLastCrawled": "2021-11-21T01:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Incentivizing Exploration In Reinforcement <b>Learning</b> With Deep ...", "url": "https://deepai.org/publication/incentivizing-exploration-in-reinforcement-learning-with-deep-predictive-models", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/incentivizing-exploration-in-reinforcement-<b>learning</b>...", "snippet": "The reinforcement <b>learning</b> <b>algorithm</b> must use this tuple to update <b>its</b> <b>policy</b> and <b>maximize</b> long-term <b>reward</b> and then choose the new action a t + 1. It is often insufficient to simply choose the best action based on previous experience, since this strategy can <b>quickly</b> fall into a local optimum. Instead, the <b>learning</b> <b>algorithm</b> must perform exploration. Prior work has suggested methods that address the exploration problem by acting with \u201coptimism under uncertainty.\u201d If one assumes that the ...", "dateLastCrawled": "2021-12-14T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "When <b>Machine</b> <b>Learning</b> Meets Spectrum Sharing Security: Methodologies ...", "url": "https://deepai.org/publication/when-machine-learning-meets-spectrum-sharing-security-methodologies-and-challenges", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/when-<b>machine</b>-<b>learning</b>-meets-spectrum-sharing-security...", "snippet": "<b>To maximize</b> the long-term discount <b>reward</b>, an offloading <b>policy</b> optimization problem was formulated by considering both task completion profit and task completion delay. Category 4 channel access scheme (LBT with random back-off and a contention window of variable size) was adopted in the LTE-U network to sense and occupy the unlicensed spectrum resources. The DQN <b>algorithm</b> was applied to solve the offloading problem by considering each device\u2019s stochastic task arrival process and the Wi ...", "dateLastCrawled": "2022-01-21T20:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Brief History of Neural Nets and Deep Learning</b> \u2013 Skynet Today", "url": "https://www.skynettoday.com/overviews/neural-net-history", "isFamilyFriendly": true, "displayUrl": "https://www.skynettoday.com/overviews/neural-net-history", "snippet": "The Centuries Old <b>Machine</b> <b>Learning</b> <b>Algorithm</b> Linear regression Let\u2019s start with a brief primer on what <b>Machine</b> <b>Learning</b> is. Take some points on a 2D graph, and draw a line that fits them as well <b>as possible</b>. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general <b>function</b> that can map any input value to an output value. This is known as linear regression, and it is a wonderful little ...", "dateLastCrawled": "2022-02-03T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "An <b>Active Learning Algorithm for Ranking from Pairwise Preferences with</b> ...", "url": "https://www.researchgate.net/publication/47637732_An_Active_Learning_Algorithm_for_Ranking_from_Pairwise_Preferences_withan_Almost_Optimal_Query_Complexity", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/47637732_An_Active_<b>Learning</b>_<b>Algorithm</b>_for...", "snippet": "To learn the <b>utility</b> <b>function</b> in as few trials <b>as possible</b>, we select actions <b>to maximize</b> the mutual information between the <b>utility</b> <b>function</b> and the preference-based and ordinal human feedback.", "dateLastCrawled": "2021-11-28T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) A <b>Reinforcement Learning Method for Maximizing Undiscounted Rewards</b>", "url": "https://www.researchgate.net/publication/221346025_A_Reinforcement_Learning_Method_for_Maximizing_Undiscounted_Rewards", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221346025_A_Reinforcement_<b>Learning</b>_Method_for...", "snippet": "R-<b>learning</b> is an RL <b>algorithm</b> proposed by Schwartz (1993) which takes into consideration the average <b>reward</b>. R-<b>learning</b> considers the best <b>possible</b> action to update the Q-values same as in the Q ...", "dateLastCrawled": "2022-01-11T05:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Reinforcement learning puzzle solving</b> with a &quot;Deep Q-<b>Learning</b>&quot; neural ...", "url": "https://ben.land/post/2021/02/15/reinforcement-learning-puzzle-solving/", "isFamilyFriendly": true, "displayUrl": "https://ben.land/post/2021/02/15/<b>reinforcement-learning-puzzle-solving</b>", "snippet": "Reinforcement <b>learning</b>, where the <b>machine</b> \u201ctags\u201d input data subject to some <b>reward</b> <b>function</b> (which need not be a <b>function</b> of the input data or tags), and <b>seeks</b> <b>to maximize</b> that <b>reward</b>. Reinforcement <b>learning</b> has been demonstrated effective at finding solutions to other games, as AlphaGo demonstrated with the game Go.", "dateLastCrawled": "2022-01-29T19:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Reinforcement <b>learning</b> for cyber-physical systems with cybersecurity ...", "url": "https://dokumen.pub/reinforcement-learning-for-cyber-physical-systems-with-cybersecurity-case-studies-9781351006590-1351006592-9781351006606-1351006606-9781351006613-1351006614-9781351006620-1351006622-9781138543539.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/reinforcement-<b>learning</b>-for-cyber-physical-systems-with-cyber...", "snippet": "<b>Like</b> -<b>greedy</b>, the softmax <b>algorithm</b> is agnostic to each arm\u2019s <b>reward</b> distribution family. 3. Once again though, we must choose the hyper-parameter, \u03c4 , to balance exploration and exploitation. Again, one can start with a large \u03c4 . Setting \u03c4 to infinity would amount to uniform exploration with zero exploitation. Decaying \u03c4 to zero would transition the <b>algorithm</b> to be completely exploitative (<b>greedy</b>). 3.1.3 UCB <b>Algorithm</b> So far, the algorithms we presented for the MAB problem balance ...", "dateLastCrawled": "2022-01-23T02:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "MITx_6.86x/Unit 05 - Reinforcement <b>Learning</b>.md at master - <b>GitHub</b>", "url": "https://github.com/sylvaticus/MITx_6.86x/blob/master/Unit%2005%20-%20Reinforcement%20Learning/Unit%2005%20-%20Reinforcement%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/sylvaticus/MITx_6.86x/blob/master/Unit 05 - Reinforcement <b>Learning</b>...", "snippet": "17.4. <b>Utility</b> <b>Function</b>. The main problem for MDPs is to optimize the agent&#39;s behavior. To do so, we first need to specify the criterion that we are trying <b>to maximize</b> in terms of accumulated rewards. We will define a <b>utility</b> <b>function</b> and <b>maximize</b> <b>its</b> expectation. Note that this should be a finite number, in order to compare different <b>possible</b> ...", "dateLastCrawled": "2021-11-21T01:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning</b> to be Fair: A Consequentialist Approach to Equitable Decision ...", "url": "https://deepai.org/publication/learning-to-be-fair-a-consequentialist-approach-to-equitable-decision-making", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>learning</b>-to-be-fair-a-consequentialist-approach-to...", "snippet": "Next, given these preferences, we show how to learn a decision-making <b>policy</b> with the largest expected <b>utility</b> given budget constraints. Starting from a historical dataset of decisions and outcomes, we demonstrate that this optimization problem can be written as a linear program (LP) to efficiently identify optimal policies for a large and expressive family of <b>utility</b> functions. These <b>utility</b>-maximizing policies can differ considerably from those suggested by traditional approaches to ...", "dateLastCrawled": "2022-01-23T13:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "ICML 2010, the 27th International Conference on <b>Machine</b> <b>Learning</b>", "url": "https://icml.cc/Conferences/2010/abstracts.html", "isFamilyFriendly": true, "displayUrl": "https://icml.cc/Conferences/<b>2010/abstracts</b>.html", "snippet": "Our <b>algorithm</b>, text it {<b>Greedy</b>-GQ}, is an extension of recent work on gradient temporal-difference <b>learning</b>, which has hitherto been restricted to a prediction (<b>policy</b> evaluation) setting, to a control setting in which the target <b>policy</b> is <b>greedy</b> with respect to a linear approximation to the optimal action-value <b>function</b>. A limitation of our control setting is that we require the behavior <b>policy</b> to be stationary. We call this setting text it {latent <b>learning</b>} because the optimal <b>policy</b> ...", "dateLastCrawled": "2022-02-02T09:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> (Deep <b>Learning</b>) Algorithms \u2013 DeepAI.space", "url": "https://deepai.space/machine-learning-deep-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://deepai.space/<b>machine</b>-<b>learning</b>-deep-<b>learning</b>-<b>algorithms</b>", "snippet": "Decision Tree . A decision tree is a decision support tool that uses a tree-like model of decisions and their <b>possible</b> consequences, including chance event outcomes, resource costs, and <b>utility</b>.It is one way to display an <b>algorithm</b> that only contains conditional control statements.. Decision trees are commonly used in <b>operations research</b>, specifically in decision analysis, to help identify a strategy most likely to reach a goal, but are also a popular tool in <b>machine</b> <b>learning</b>.. A decision ...", "dateLastCrawled": "2022-01-28T15:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Reinforcement Learning of a Morphing Airfoil-Policy and Discrete</b> ...", "url": "https://www.researchgate.net/publication/228825744_Reinforcement_Learning_of_a_Morphing_Airfoil-Policy_and_Discrete_Learning_Analysis", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228825744_Reinforcement_<b>Learning</b>_of_a...", "snippet": "Reinforcement <b>learning</b> methods specify how the agent changes <b>its</b> <b>policy</b> as a result of <b>its</b> experiences. The agent\u2019s goal is <b>to maximize</b> the total amount of <b>reward</b> it receives o ver the long run.", "dateLastCrawled": "2022-01-15T20:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>learning</b> and AI <b>in marketing \u2013 Connecting computing power to</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0167811620300410", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167811620300410", "snippet": "Originally using the PageRank <b>algorithm</b>, Google now processes a significant number of searches using the deep <b>learning</b>-based RankBrain <b>algorithm</b>, which helps improve the relevance and robustness of search results. 12 For marketers, search engine optimization is also conducted using <b>machine</b> <b>learning</b>-based tools such as Can I Rank or Alli AI. While keyword has been the dominant form of online search, <b>machine</b> <b>learning</b> methods are making searches based on other content types within reach. With ...", "dateLastCrawled": "2022-01-12T18:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) A <b>Reinforcement Learning Method for Maximizing Undiscounted Rewards</b>", "url": "https://www.researchgate.net/publication/221346025_A_Reinforcement_Learning_Method_for_Maximizing_Undiscounted_Rewards", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221346025_A_Reinforcement_<b>Learning</b>_Method_for...", "snippet": "R-<b>learning</b> is an RL <b>algorithm</b> proposed by Schwartz (1993) which takes into consideration the average <b>reward</b>. R-<b>learning</b> considers the best <b>possible</b> action to update the Q-values same as in the Q ...", "dateLastCrawled": "2022-01-11T05:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A <b>Brief History of Neural Nets and Deep Learning</b> \u2013 Skynet Today", "url": "https://www.skynettoday.com/overviews/neural-net-history", "isFamilyFriendly": true, "displayUrl": "https://www.skynettoday.com/overviews/neural-net-history", "snippet": "The Centuries Old <b>Machine</b> <b>Learning</b> <b>Algorithm</b> Linear regression Let\u2019s start with a brief primer on what <b>Machine</b> <b>Learning</b> is. Take some points on a 2D graph, and draw a line that fits them as well <b>as possible</b>. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general <b>function</b> that can map any input value to an output value. This is known as linear regression, and it is a wonderful little ...", "dateLastCrawled": "2022-02-03T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Reinforcement learning puzzle solving</b> with a &quot;Deep Q-<b>Learning</b>&quot; neural ...", "url": "https://ben.land/post/2021/02/15/reinforcement-learning-puzzle-solving/", "isFamilyFriendly": true, "displayUrl": "https://ben.land/post/2021/02/15/<b>reinforcement-learning-puzzle-solving</b>", "snippet": "Reinforcement <b>learning</b>, where the <b>machine</b> \u201ctags\u201d input data subject to some <b>reward</b> <b>function</b> (which need not be a <b>function</b> of the input data or tags), and <b>seeks</b> <b>to maximize</b> that <b>reward</b>. Reinforcement <b>learning</b> has been demonstrated effective at finding solutions to other games, as AlphaGo demonstrated with the game Go.", "dateLastCrawled": "2022-01-29T19:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Reinforcement <b>learning</b> for cyber-physical systems with cybersecurity ...", "url": "https://dokumen.pub/reinforcement-learning-for-cyber-physical-systems-with-cybersecurity-case-studies-9781351006590-1351006592-9781351006606-1351006606-9781351006613-1351006614-9781351006620-1351006622-9781138543539.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/reinforcement-<b>learning</b>-for-cyber-physical-systems-with-cyber...", "snippet": "After observing the <b>reward</b>, the <b>algorithm</b> updates <b>its</b> expected <b>reward</b> for the recently played arm. Note that we use the iterative update for the expected <b>reward</b> estimate from Equation (3.7) in <b>Algorithm</b> 1. Reinforcement <b>Learning</b> Problems 49 <b>Algorithm</b> 1 -<b>greedy</b> <b>Algorithm</b> for MAB Initialize estimates: \u00b5j := 0 for j = 1, . . . , k Initialize play counters: Nj := 0 for j = 1, . . . , k for t = 1 to T do maxSelected = false for j = 1 to k do if \u00b5j = max(\u00b51 , . . . , \u00b5k ) and maxSelected ...", "dateLastCrawled": "2022-01-23T02:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> for Sustainable Energy Systems | Annual Review of ...", "url": "https://www.annualreviews.org/doi/full/10.1146/annurev-environ-020220-061831", "isFamilyFriendly": true, "displayUrl": "https://www.annualreviews.org/doi/full/10.1146/annurev-environ-020220-061831", "snippet": "A third major paradigm is reinforcement <b>learning</b> (RL), a setting where an agent must learn how to act in a sequential environment <b>to maximize</b> some <b>reward</b> . Unlike the paradigms of supervised and unsupervised <b>learning</b>, RL algorithms do not operate over a fixed dataset but rather within a setting where the <b>algorithm</b> <b>can</b> take an action that affects future states of some system. This setting is similar to that considered in adaptive control, and indeed these fields have a great degree of shared ...", "dateLastCrawled": "2022-01-24T11:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b> (Deep <b>Learning</b>) Algorithms \u2013 DeepAI.space", "url": "https://deepai.space/machine-learning-deep-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://deepai.space/<b>machine</b>-<b>learning</b>-deep-<b>learning</b>-<b>algorithms</b>", "snippet": "Decision Tree . A decision tree is a decision support tool that uses a tree-like model of decisions and their <b>possible</b> consequences, including chance event outcomes, resource costs, and <b>utility</b>.It is one way to display an <b>algorithm</b> that only contains conditional control statements.. Decision trees are commonly used in <b>operations research</b>, specifically in decision analysis, to help identify a strategy most likely to reach a goal, but are also a popular tool in <b>machine</b> <b>learning</b>.. A decision ...", "dateLastCrawled": "2022-01-28T15:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Automated Machine Learning - Methods, Systems, Challenges</b> | Request PDF", "url": "https://www.researchgate.net/publication/338681645_Automated_Machine_Learning_-_Methods_Systems_Challenges", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338681645_Automated_<b>Machine</b>_<b>Learning</b>...", "snippet": "At any <b>policy</b> update step, the <b>policy</b> learner refers to the stored experiences, and adaptively reconfigures <b>its</b> <b>learning</b> <b>algorithm</b> with the new hyperparameters determined by the memory. This ...", "dateLastCrawled": "2022-01-02T20:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>Brief History of Neural Nets and Deep Learning</b> \u2013 Skynet Today", "url": "https://www.skynettoday.com/overviews/neural-net-history", "isFamilyFriendly": true, "displayUrl": "https://www.skynettoday.com/overviews/neural-net-history", "snippet": "The Centuries Old <b>Machine</b> <b>Learning</b> <b>Algorithm</b> Linear regression Let\u2019s start with a brief primer on what <b>Machine</b> <b>Learning</b> is. Take some points on a 2D graph, and draw a line that fits them as well <b>as possible</b>. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general <b>function</b> that <b>can</b> map any input value to an output value. This is known as linear regression, and it is a wonderful little ...", "dateLastCrawled": "2022-02-03T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Publications \u2013 Neural Network and <b>Machine</b> <b>Learning</b> Laboratory", "url": "https://axon.cs.byu.edu/?page_id=91", "isFamilyFriendly": true, "displayUrl": "https://axon.cs.byu.edu/?page_id=91", "snippet": "Though the k-nearest neighbor (k-NN) pattern classifier is an effective <b>learning</b> <b>algorithm</b>, it <b>can</b> result in large model sizes. To compensate, a number of variant algorithms have been developed that condense the model size of the k-NN classifier at the expense of accuracy. To increase the accuracy of these condensed models, we present a direct boosting <b>algorithm</b> for the k-NN classifier that creates an ensemble of models with locally modified distance weighting. An empirical study conducted ...", "dateLastCrawled": "2021-12-22T23:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Deep <b>Learning for NLP and Speech Recognition</b> | William Jacome ...", "url": "https://www.academia.edu/43190210/Deep_Learning_for_NLP_and_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43190210/Deep_<b>Learning_for_NLP_and_Speech_Recognition</b>", "snippet": "Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome. Download PDF. Download Full PDF Package. This paper. A short summary of this paper. 37 Full PDFs related to this paper. READ PAPER. Deep <b>Learning for NLP and Speech Recognition</b> . Download. Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>VICTORIA&#39;s MACHINE LEARNING NOTES</b> - Persagen Consulting", "url": "https://persagen.com/files/ml.html", "isFamilyFriendly": true, "displayUrl": "https://persagen.com/files/ml.html", "snippet": "One approach is to recover the expert&#39;s cost <b>function</b> with inverse reinforcement <b>learning</b>, then extract a <b>policy</b> from that cost <b>function</b> with reinforcement <b>learning</b>. This approach is indirect and <b>can</b> be slow. We propose a new general framework for directly extracting a <b>policy</b> from data, as if it were obtained by reinforcement <b>learning</b> following inverse reinforcement <b>learning</b>. We show that a certain instantiation of our framework draws an analogy between imitation <b>learning</b> and generative ...", "dateLastCrawled": "2022-02-01T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>The Algorithm Design Manual - Steven S</b>. Skiena | \u00d6zlem Ekici ...", "url": "https://www.academia.edu/48943214/The_Algorithm_Design_Manual_Steven_S_Skiena", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/48943214/<b>The_Algorithm_Design_Manual_Steven_S</b>_Skiena", "snippet": "Second Edition - Springer This book is intended as a manual on <b>algorithm</b> design, providing access to combinatorial <b>algorithm</b> technology for both students and computer professionals. It is divided into two parts: Techniques and Resources. The former", "dateLastCrawled": "2022-02-03T07:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Dyna-H: A <b>heuristic planning reinforcement learning algorithm</b> ...", "url": "https://www.researchgate.net/publication/48192108_Dyna-H_A_heuristic_planning_reinforcement_learning_algorithm_applied_to_role-playing_game_strategy_decision_systems", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/48192108_Dyna-H_A_heuristic_planning...", "snippet": "The control system consists of a state estimator, a <b>reward</b> strategy, a <b>policy</b> table, and a <b>policy</b> update <b>algorithm</b>. Novel <b>reward</b> strategies related to the energy deviation from the rated power are ...", "dateLastCrawled": "2022-01-04T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "notes-1/Deep <b>Learning</b>.md at master \u00b7 kirk86/notes-1 \u00b7 <b>GitHub</b>", "url": "https://github.com/kirk86/notes-1/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/kirk86/notes-1/blob/master/Deep <b>Learning</b>.md", "snippet": "In reinforcement <b>learning</b>, fitted Q-functions obtained by estimating the expected return of a given <b>policy</b> \u03c0\u03b8 summarize all future costs, and a good Q-<b>function</b> <b>can</b> greatly simplify the temporal credit assignment problem. Combining MuProp with such fitted Q-functions could greatly reduce the variance of the estimator and make it better suited for very deep computational graphs, such as long recurrent neural networks and applications in reinforcement <b>learning</b>. The second extension is to make ...", "dateLastCrawled": "2021-12-24T03:06:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Reinforcement and deep reinforcement <b>learning</b> for wireless Internet of ...", "url": "https://www.sciencedirect.com/science/article/pii/S0140366421002681", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0140366421002681", "snippet": "Over the last five years, <b>Machine</b> <b>Learning</b> ... existing scheduling solutions and it <b>can</b> provide better throughput and is more robust with an additional dynamic \u03b5-<b>greedy</b> <b>policy</b>. The authors in have addressed the transmission scheduling optimization in a maritime communications network based on Software Defined Network (SDN) architecture. A deep Q-<b>learning</b> approach combined with a softmax classifier (S-DQN) has been implemented to replace the traditional <b>algorithm</b> in the SDN controller. The ...", "dateLastCrawled": "2022-01-27T03:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Reinforcement learning puzzle solving</b> with a &quot;Deep Q-<b>Learning</b>&quot; neural ...", "url": "https://ben.land/post/2021/02/15/reinforcement-learning-puzzle-solving/", "isFamilyFriendly": true, "displayUrl": "https://ben.land/post/2021/02/15/<b>reinforcement-learning-puzzle-solving</b>", "snippet": "Reinforcement <b>Learning</b>. <b>Machine</b> <b>learning</b> <b>can</b> roughly be broken down into three paradigms: Supervised <b>learning</b>, like the NN method referenced above, where the <b>machine</b> is shown correct/tagged input data, and generalizes to other input data. Unsupervised <b>learning</b>, where the <b>machine</b> categorizes/encodes untagged input data based on learned correlations within the dataset. Reinforcement <b>learning</b>, where the <b>machine</b> \u201ctags\u201d input data subject to some <b>reward</b> <b>function</b> (which need not be a <b>function</b> ...", "dateLastCrawled": "2022-01-29T19:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "MITx_6.86x/Unit 05 - Reinforcement <b>Learning</b>.md at master - <b>GitHub</b>", "url": "https://github.com/sylvaticus/MITx_6.86x/blob/master/Unit%2005%20-%20Reinforcement%20Learning/Unit%2005%20-%20Reinforcement%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/sylvaticus/MITx_6.86x/blob/master/Unit 05 - Reinforcement <b>Learning</b>...", "snippet": "17.4. <b>Utility</b> <b>Function</b>. The main problem for MDPs is to optimize the agent&#39;s behavior. To do so, we first need to specify the criterion that we are trying <b>to maximize</b> in terms of accumulated rewards. We will define a <b>utility</b> <b>function</b> and <b>maximize</b> <b>its</b> expectation. Note that this should be a finite number, in order to compare different <b>possible</b> ...", "dateLastCrawled": "2021-11-21T01:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>learning</b> and AI <b>in marketing \u2013 Connecting computing power to</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0167811620300410", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167811620300410", "snippet": "Originally using the PageRank <b>algorithm</b>, Google now processes a significant number of searches using the deep <b>learning</b>-based RankBrain <b>algorithm</b>, which helps improve the relevance and robustness of search results. 12 For marketers, search engine optimization is also conducted using <b>machine</b> <b>learning</b>-based tools such as <b>Can</b> I Rank or Alli AI. While keyword has been the dominant form of online search, <b>machine</b> <b>learning</b> methods are making searches based on other content types within reach. With ...", "dateLastCrawled": "2022-01-12T18:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Reinforcement Learning of a Morphing Airfoil-Policy and Discrete</b> ...", "url": "https://www.researchgate.net/publication/228825744_Reinforcement_Learning_of_a_Morphing_Airfoil-Policy_and_Discrete_Learning_Analysis", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228825744_Reinforcement_<b>Learning</b>_of_a...", "snippet": "An episodic unsupervised <b>learning</b> <b>algorithm</b> using the Q-<b>Learning</b> method is developed to learn the optimal shape and shape change <b>policy</b> of a morphing airfoil. Optimality is addressed by <b>reward</b> ...", "dateLastCrawled": "2022-01-15T20:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How <b>can</b> Big Data and <b>machine learning</b> benefit environment and water ...", "url": "https://iopscience.iop.org/article/10.1088/1748-9326/ab1b7d", "isFamilyFriendly": true, "displayUrl": "https://iopscience.iop.org/article/10.1088/1748-9326/ab1b7d", "snippet": "Batch normalization makes it <b>possible</b> to use larger <b>learning</b> rate (<b>learning</b> rate is a hyperparameter that controls the step size in gradient descent algorithms) and in some cases even eliminate the need for dropout. The third key change is the incorporation of shared weights and biases in each hidden layer. Weight sharing drastically reduces the number of unknown parameters resulting from each pair of connected layers, with many units in the input connecting to the same units (or local ...", "dateLastCrawled": "2021-12-08T22:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A <b>Brief History of Neural Nets and Deep Learning</b> \u2013 Skynet Today", "url": "https://www.skynettoday.com/overviews/neural-net-history", "isFamilyFriendly": true, "displayUrl": "https://www.skynettoday.com/overviews/neural-net-history", "snippet": "The Centuries Old <b>Machine</b> <b>Learning</b> <b>Algorithm</b> Linear regression Let\u2019s start with a brief primer on what <b>Machine</b> <b>Learning</b> is. Take some points on a 2D graph, and draw a line that fits them as well <b>as possible</b>. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general <b>function</b> that <b>can</b> map any input value to an output value. This is known as linear regression, and it is a wonderful little ...", "dateLastCrawled": "2022-02-03T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) Deep <b>Learning for NLP and Speech Recognition</b> | William Jacome ...", "url": "https://www.academia.edu/43190210/Deep_Learning_for_NLP_and_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43190210/Deep_<b>Learning_for_NLP_and_Speech_Recognition</b>", "snippet": "Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome. Download PDF. Download Full PDF Package. This paper. A short summary of this paper. 37 Full PDFs related to this paper. READ PAPER. Deep <b>Learning for NLP and Speech Recognition</b> . Download. Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) A <b>Reinforcement Learning Method for Maximizing Undiscounted Rewards</b>", "url": "https://www.researchgate.net/publication/221346025_A_Reinforcement_Learning_Method_for_Maximizing_Undiscounted_Rewards", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221346025_A_Reinforcement_<b>Learning</b>_Method_for...", "snippet": "R-<b>learning</b> is an RL <b>algorithm</b> proposed by Schwartz (1993) which takes into consideration the average <b>reward</b>. R-<b>learning</b> considers the best <b>possible</b> action to update the Q-values same as in the Q ...", "dateLastCrawled": "2022-01-11T05:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is a simple iterative example of how on-<b>policy</b> and off-<b>policy</b> ...", "url": "https://www.quora.com/What-is-a-simple-iterative-example-of-how-on-policy-and-off-policy-algorithms-differ-in-reinforcement-learning-I-really-need-to-see-it-working-for-at-least-3-steps", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-a-simple-iterative-example-of-how-on-<b>policy</b>-and-off...", "snippet": "Answer: The basic example to show the difference between on-<b>policy</b> and off-<b>policy</b> is with the Cliff MDP: the agent has to go from A to B which goes along a cliff. The shortest path is right beside the cliff where you <b>can</b> fall off and incur a huge penalty. It is also <b>possible</b> to stay clear by walk...", "dateLastCrawled": "2022-01-18T16:58:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Why <b>Machine Learning Is A Metaphor For</b> Life \u2013 Adit Deshpande ...", "url": "https://adeshpande3.github.io/Why-Machine-Learning-is-a-Metaphor-For-Life", "isFamilyFriendly": true, "displayUrl": "https://adeshpande3.github.io/Why-<b>Machine-Learning-is-a-Metaphor-For</b>-Life", "snippet": "Another cool <b>analogy</b> is that of the epsilon <b>greedy</b> <b>policy</b>. This is a term used in reinforcement <b>learning</b> to fight the problem of exploration vs exploitation. The basic idea is that the RL agent will take a random action (instead of the optimal action according to its current <b>policy</b>) with probability \u03b5, in hope of searching a larger area of the state space, and eventually getting a better reward.", "dateLastCrawled": "2022-01-31T13:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "AI and Reinforcement <b>Learning</b> \u2014 Machines that Learn through Experience ...", "url": "https://www.cantorsparadise.com/ai-and-reinforcement-learning-machines-that-learn-through-experience-e7eea7bb6765", "isFamilyFriendly": true, "displayUrl": "https://www.cantorsparadise.com/ai-and-reinforcement-<b>learning</b>-<b>machines</b>-that-learn...", "snippet": "This tactic, where two simultaneous, interacting processes, one making the value function consistent with the current <b>policy</b> (<b>policy</b> evaluation), and the other making the <b>policy</b> <b>greedy</b> with respect to the current value function (<b>policy</b> improvement) is known as general <b>policy</b> iteration (GPI) and is not exclusive for Monte Carlo methods. In fact, almost all reinforcement <b>learning</b> methods are well described as GPI.", "dateLastCrawled": "2022-01-25T17:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reinforcement <b>Learning</b> | Ioannis Anifantakis | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/reinforcement-learning-basic-understanding-4fcb91ba4e4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/reinforcement-<b>learning</b>-basic-understanding-4fcb91ba4e4", "snippet": "Reinforcement <b>Learning</b> (RL) is a <b>Machine</b> <b>Learning</b> field which gained much attention since 2015 after Google\u2019s Deep Mind team demonstrated self-taught DQN agents <b>learning</b> to walk, mastering Atari ...", "dateLastCrawled": "2021-08-02T19:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Finding the Word <b>Analogy</b> from given words using Word2Vec embeddings ...", "url": "https://www.geeksforgeeks.org/finding-the-word-analogy-from-given-words-using-word2vec-embeddings/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/finding-the-word-<b>analogy</b>-from-given-words-using-word2vec...", "snippet": "In the word <b>analogy</b> task, we complete the sentence ... What if we can use a <b>Machine</b> <b>Learning</b> algorithm to automate this task of finding the word <b>analogy</b>. In this tutorial, we will be using Word2Vec model and a pre-trained model named \u2018GoogleNews-vectors-negative300.bin\u2018 which is trained on over 50 Billion words by Google. Each word inside the pre-trained dataset is embedded in a 300-dimensional space and the words which are similar in context/meaning are placed closer to each other in ...", "dateLastCrawled": "2022-01-26T14:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "[1912.10329] Can Agents Learn by <b>Analogy</b>? An Inferable Model for PAC ...", "url": "https://arxiv.org/abs/1912.10329", "isFamilyFriendly": true, "displayUrl": "https://<b>arxiv</b>.org/abs/1912.10329", "snippet": "Model-based reinforcement <b>learning</b> algorithms make decisions by building and utilizing a model of the environment. However, none of the existing algorithms attempts to infer the dynamics of any state-action pair from known state-action pairs before meeting it for sufficient times. We propose a new model-based method called <b>Greedy</b> Inference Model (GIM) that infers the unknown dynamics from known dynamics based on the internal spectral properties of the environment. In other words, GIM can ...", "dateLastCrawled": "2021-10-26T15:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Artificial Intelligence</b> and <b>Machine Learning</b>", "url": "https://content.kopykitab.com/ebooks/2016/06/7780/sample/sample_7780.pdf", "isFamilyFriendly": true, "displayUrl": "https://content.kopykitab.com/ebooks/2016/06/7780/sample/sample_7780.pdf", "snippet": "10. REINFORCEMENT <b>LEARNING</b> 186\u2013200 10.1 Markov Decision Problem188 10.2 Q-<b>learning</b> 191 10.2.1 Q-<b>Learning</b> Algorithm191 10.3 Temporal Difference Learning194 10.3.1 On-<b>policy</b> and Off-<b>policy</b> Learning195 10.3.2 Advantages of TD Prediction Methods195 10.4 <b>Learning</b> Automata196 10.5 Case Studies198 10.5.1 Super Mario: Reinforced Learning198 10.6 ...", "dateLastCrawled": "2022-02-02T20:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning</b> - SlideShare", "url": "https://www.slideshare.net/darshanharry/machine-learning-46440299", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/darshanharry/<b>machine-learning</b>-46440299", "snippet": "<b>Machine learning</b> and data mining <b>MACHINE LEARNING</b> DATA MINING Focuses on prediction, based on known properties learned from the training data. Focuses on the discovery of (previously) unknown properties on the data. Performance is usually evaluated with respect to the ability to reproduce known knowledge. The key task is the discovery of previously unknown knowledge . Evaluated with respect to known knowledge This is the algorithm part of the data mining process Application of algorithms to ...", "dateLastCrawled": "2022-02-02T23:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>All Unit MCQ questions of ML</b> \u2013 TheCodingShef", "url": "https://thecodingshef.com/all-unit-mcq-questions-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://thecodingshef.com/<b>all-unit-mcq-questions-of</b>-<b>machine</b>-<b>learning</b>", "snippet": "Correct option is C. Choose the correct option regarding <b>machine</b> <b>learning</b> (ML) and artificial intelligence (AI) ML is a set of techniques that turns a dataset into a software. AI is a software that can emulate the human mind. ML is an alternate way of programming intelligent machines. All of the above. Correct option is D.", "dateLastCrawled": "2022-01-30T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Instance-based learning - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/instance-based-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/instance-based-<b>learning</b>", "snippet": "The <b>Machine</b> <b>Learning</b> systems which are categorized as instance-based <b>learning</b> are the systems that learn the training examples by heart and then generalizes to new instances based on some similarity measure. It is called instance-based because it builds the hypotheses from the training instances. It is also known as memory-based <b>learning</b> or lazy-<b>learning</b>.The time complexity of this algorithm depends upon the size of training data.", "dateLastCrawled": "2022-02-03T08:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Reinforcement Learning</b> For Mice. An Anology Between Animals And\u2026 | by ...", "url": "https://towardsdatascience.com/reinforcement-learning-3f87a0290ba2", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>reinforcement-learning</b>-3f87a0290ba2", "snippet": "RL and Animal <b>Learning</b>. Below is an <b>analogy</b> between the mouse-maze experiment and RL concepts. Image by Author. Agent: The component that makes the decision of what action to take. Our agent is the mouse in this case. Environment: Physical world in which the agent operates. The maze is the environment. Actions: The agent\u2019s methods that allow it to interact and change its environment, and thus transfer between states. In this case, the mouse\u2019s motions to the right, left, forward, and ...", "dateLastCrawled": "2022-01-31T10:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Reinforcement <b>Learning</b> | Ioannis Anifantakis | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/reinforcement-learning-basic-understanding-4fcb91ba4e4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/reinforcement-<b>learning</b>-basic-understanding-4fcb91ba4e4", "snippet": "Reinforcement <b>Learning</b> (RL) is a <b>Machine</b> <b>Learning</b> field which gained much attention since 2015 after Google\u2019s Deep Mind team demonstrated self-taught DQN agents <b>learning</b> to walk, mastering Atari ...", "dateLastCrawled": "2021-08-02T19:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Traveling Salesman Problem Theory and Applications</b> | Mikhil Raj ...", "url": "https://www.academia.edu/4409399/Traveling_Salesman_Problem_Theory_and_Applications", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/4409399/<b>Traveling_Salesman_Problem_Theory_and_Applications</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-30T12:57:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(greedy policy)  is like +(machine learning algorithm that seeks to maximize its reward or utility function as quickly as possible)", "+(greedy policy) is similar to +(machine learning algorithm that seeks to maximize its reward or utility function as quickly as possible)", "+(greedy policy) can be thought of as +(machine learning algorithm that seeks to maximize its reward or utility function as quickly as possible)", "+(greedy policy) can be compared to +(machine learning algorithm that seeks to maximize its reward or utility function as quickly as possible)", "machine learning +(greedy policy AND analogy)", "machine learning +(\"greedy policy is like\")", "machine learning +(\"greedy policy is similar\")", "machine learning +(\"just as greedy policy\")", "machine learning +(\"greedy policy can be thought of as\")", "machine learning +(\"greedy policy can be compared to\")"]}