{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>High-Resolution</b>, Pixel-<b>Dense</b> Displays: Why Megapixels are Important", "url": "https://www.azosensors.com/article.aspx?ArticleID=2346", "isFamilyFriendly": true, "displayUrl": "https://www.azosensors.com/article.aspx?ArticleID=2346", "snippet": "Simply put, to measure a <b>high-resolution</b> display, a <b>high-resolution</b> system is needed. <b>High resolution</b> is important not only for big screens <b>like</b> televisions but also for small displays such as smartphones and smartwatches that are viewed close up. Users expect a crystal-clear <b>image</b>. Shown here: the Apple Watch 5 and iPhone 11 Pro.", "dateLastCrawled": "2022-01-27T17:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>High resolution non-rigid</b> <b>dense</b> matching based on optimized sampling ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231217302485", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231217302485", "snippet": "A <b>high resolution</b> <b>dense</b> matching algorithm is presented for non-rigid <b>image</b> <b>feature</b> matching in the paper. For <b>high resolution non-rigid</b> images, telephoto lens is helpful in capturing fine scale features <b>like</b> cloth fold, pigmentation and skin pores. It brings us serious <b>image</b> noises which are less texture and bokeh, respectively. In order to avoid mismatch and non-uniform matching, we propose an optimized sampling method based on Gibbs <b>dense</b> sampling considering both texture <b>feature</b> ...", "dateLastCrawled": "2021-12-06T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>HIGH-RESOLUTION IMAGE CLASSIFICATION WITH CONVOLUTIONAL NETWORKS</b>", "url": "https://www.lri.fr/~gcharpia/highres_igarss2017.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.lri.fr/~gcharpia/highres_igarss2017.pdf", "snippet": "<b>Dense</b> <b>image</b> classi\ufb01cation, or semantic labeling, is the prob-lem of assigning a semantic class to every pixel in an <b>image</b>. In certain application domains, such as urban mapping, it is important to provide \ufb01ne-grained classi\ufb01cation maps where object boundaries are precisely located. Over the last few years, deep learning and more speci\ufb01cally convolutional neural networks (CNNs) have gained signi\ufb01cant attention in the community. In particular, fully convolutional networks (FCNs) [1 ...", "dateLastCrawled": "2021-08-29T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Dense</b> <b>matching in high resolution oblique airborne images</b>", "url": "https://www.researchgate.net/publication/228338400_Dense_matching_in_high_resolution_oblique_airborne_images", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228338400_<b>Dense</b>_matching_in_<b>high_resolution</b>...", "snippet": "<b>Dense</b> <b>image</b> matching results in <b>dense</b> point cloud data by exploiting forward intersection of maximum corresponding <b>feature</b> points in object space (Gerke, 2009). Semi-Global matching (SGM ...", "dateLastCrawled": "2021-10-18T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>High Resolution Image Correspondences for Video Post-Production</b> \u2014 JVRB ...", "url": "https://www.jvrb.org/past-issues/9.2012/3554", "isFamilyFriendly": true, "displayUrl": "https://www.jvrb.org/past-issues/9.2012/3554", "snippet": "Establishing <b>dense</b> <b>image</b> correspondences between images is still a challenging problem, especially when the input images <b>feature</b> long-range motion and large occluded areas. With the increasing availability of <b>high-resolution</b> content, the requirements for correspondence estimation between images are further increased. <b>High resolution</b> images often exhibit many ambiguous details in places where their low resolution predecessors only show uniformly colored areas, thus the need for smarter and ...", "dateLastCrawled": "2021-12-26T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Generic Object Detection with <b>Dense</b> Neural Patterns and Regionlets", "url": "https://ai.stanford.edu/~wzou/bmvc2014_ZouWangSunLin.pdf", "isFamilyFriendly": true, "displayUrl": "https://ai.stanford.edu/~wzou/bmvc2014_ZouWangSunLin.pdf", "snippet": "After the deep CNN training on large-scale <b>image</b> classi\ufb01cation, the recognition module is employed to produce <b>dense</b> <b>feature</b> maps on <b>high-resolution</b> detection images. We call the combination of this technique and the resulting <b>feature</b> set <b>Dense</b> Neural Patterns (DNPs).", "dateLastCrawled": "2022-01-07T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Object Detection in Very <b>High-Resolution</b> Aerial Images Using One-Stage ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6210269/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6210269", "snippet": "The <b>feature</b> map C7 is calculated by first applying ReLU activation function on the <b>feature</b> map C6 then convolving the resultant output by 256 kernels with kernel sizes equal to (3, 3) and strides equal to (2, 2) on vertical and horizontal directions. Thus, the bottom-up pathway produces <b>feature</b> maps {C3, C4, C5, C6, and C7} where the strides are {8, 16, 32, 64, and 128} for each <b>feature</b> map, respectively. Top-down pathway is obtained by constructing densely connected <b>feature</b> pyramid network ...", "dateLastCrawled": "2022-01-07T07:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Efficient Object Detection for <b>High Resolution</b> Images", "url": "http://acsweb.ucsd.edu/~yol070/Allerton2015_v3.pptx", "isFamilyFriendly": true, "displayUrl": "acsweb.ucsd.edu/~yol070/Allerton2015_v3.pptx", "snippet": "<b>Image</b>. DCNN <b>feature</b> <b>image</b>. <b>Dense</b> sliding. Region specific features. Classifier. Recall Runtime (seconds) <b>Dense</b> sliding 0.5 0.6 0.7 0.75 0.8 0.80700000000000005 1.173 27.577000000000002 SC-Net (<b>dense</b>-sliding) 0.5 0.6 0.7 0.75 0.8 2.9039999999999999 3.0009999999999999 3.2679999999999998 3.5939999999999999 3.9689999999999999 SC-Net (coarse-sliding ...", "dateLastCrawled": "2021-11-19T00:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "RefineNet: Multi-Path Refinement <b>Networks for High-Resolution Semantic</b> ...", "url": "https://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_RefineNet_Multi-Path_Refinement_CVPR_2017_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_RefineNet_Multi-Path...", "snippet": "crease in the initial <b>image</b> resolution. Here, we present Re\ufb01neNet, a generic multi-path re\ufb01nement network that explicitly exploits all the information available along the down-sampling process to enable <b>high-resolution</b> predic-tion using long-range residual connections. In this way, the deeper layers that capture high-level semantic features can be directly re\ufb01ned using \ufb01ne-grained features from ear-lier convolutions. The individual components of Re\ufb01neNet employ residual connections ...", "dateLastCrawled": "2022-02-01T13:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Remote Sensing | Free Full-Text | Classification for <b>High Resolution</b> ...", "url": "https://www.mdpi.com/2072-4292/9/5/498/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/9/5/498/htm", "snippet": "The most significant <b>feature</b> of the FCN model is: on the one hand, FCN inherits the high accuracy <b>feature</b> for <b>image</b>-label classification from standard CNN. On the other hand, it maintains the 2-D spatial information of the input <b>image</b>, thus achieving <b>dense</b> class prediction. However, pooling operations cause serious reduction of the resolution. The output is not fine enough, which will result in the loss of valuable detail information. As can be seen from", "dateLastCrawled": "2022-01-28T16:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Single <b>Image</b> Super-Resolution Based on Global <b>Dense</b> <b>Feature</b> Fusion ...", "url": "https://res.mdpi.com/sensors/sensors-19-00316/article_deploy/sensors-19-00316-v2.pdf", "isFamilyFriendly": true, "displayUrl": "https://res.mdpi.com/sensors/sensors-19-00316/article_deploy/sensors-19-00316-v2.pdf", "snippet": "It aims to reconstruct a visually pleasing <b>high resolution</b> (HR) <b>image</b> from the degraded low resolution (LR) one. SISR has been applied in various \ufb01elds, such as facial recognition, medical imaging, and surveillance systems [1,2]. The relationship between HR <b>image</b> and LR <b>image</b> is based on the situation, thus, SISR is a highly ill-posed inverse problem. A common assumption is that the LR <b>image</b> is a bicubic downsampled version of the HR <b>image</b> but, in practical application, there are so many ...", "dateLastCrawled": "2022-01-26T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Single <b>Image</b> Super-Resolution Based on Global <b>Dense</b> <b>Feature</b> Fusion ...", "url": "https://europepmc.org/article/PMC/PMC6359588", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC6359588", "snippet": "Single <b>Image</b> Super-Resolution Based on Global <b>Dense</b> <b>Feature</b> Fusion Convolutional Network. ... It is essential to extract <b>image</b> features and perform non-linear representation to achieve <b>high resolution</b> <b>image</b> restoration. Recently, deep learning-based methods [12,13,14,15,16,17,18,19,20,21,22] have achieved superior performance over conventional methods in SISR. SRCNN firstly end-to-end learns the mapping between LR <b>image</b> and HR <b>image</b>. However, there are still existing problems, like lack of ...", "dateLastCrawled": "2022-01-27T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Reference guided image super-resolution via efficient dense warping</b> and ...", "url": "https://www.sciencedirect.com/science/article/pii/S092359652030196X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S092359652030196X", "snippet": "Due to the limited improvement of single-<b>image</b> based super-resolution (SR) methods in recent years, the reference based <b>image</b> SR (RefSR) methods, which super-resolve the low-resolution (LR) input with the guidance of <b>similar</b> <b>high-resolution</b> (HR) reference images are emerging. There are two main challenges in RefSR, i.e. reference <b>image</b> warping and exploring the guidance information from the warped references. For reference warping, we propose an efficient <b>dense</b> warping method to deal with ...", "dateLastCrawled": "2021-12-28T19:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "FaPN: <b>Feature</b>-Aligned Pyramid Network for <b>Dense</b> <b>Image</b> Prediction", "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_FaPN_Feature-Aligned_Pyramid_Network_for_Dense_Image_Prediction_ICCV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_FaPN_<b>Feature</b>-Aligned...", "snippet": "FaPN: <b>Feature</b>-aligned Pyramid Network for <b>Dense</b> <b>Image</b> Prediction ... aggregate multi-scale context from <b>high-resolution</b> <b>feature</b> maps. Building upon ASPP, a family of methods [4\u20136] were 865. developed. However, the lack of the ability to generate <b>fea-ture</b> maps at multiple scales restricts the application of this type of methods to other <b>dense</b> prediction tasks beyond se-mantic segmentation. The second group of methods focuses on building an encoder-decoder network, i.e. bottom-up and top ...", "dateLastCrawled": "2022-02-03T06:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>High Resolution Image Correspondences for Video Post-Production</b> \u2014 JVRB ...", "url": "https://www.jvrb.org/past-issues/9.2012/3554", "isFamilyFriendly": true, "displayUrl": "https://www.jvrb.org/past-issues/9.2012/3554", "snippet": "Establishing <b>dense</b> <b>image</b> correspondences between images is still a challenging problem, especially when the input images <b>feature</b> long-range motion and large occluded areas. With the increasing availability of <b>high-resolution</b> content, the requirements for correspondence estimation between images are further increased. <b>High resolution</b> images often exhibit many ambiguous details in places where their low resolution predecessors only show uniformly colored areas, thus the need for smarter and ...", "dateLastCrawled": "2021-12-26T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Review: MSDNet \u2014 Multi-<b>Scale Dense Networks (Image Classification</b>) | by ...", "url": "https://towardsdatascience.com/review-msdnet-multi-scale-dense-networks-image-classification-4d949955f6d5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/review-msdnet-multi-scale-<b>dense</b>-networks-<b>image</b>...", "snippet": "The horizontal connections preserve and progress <b>high-resolution</b> information, ... An MSDNet with six intermediate classifiers are used, and the three main components, multi-scale <b>feature</b> maps, <b>dense</b> connectivity, and intermediate classifiers, are removed one at a time. If all the three components in an MSDNet are removed, a regular VGG-like convolutional network is obtained. To make our comparisons fair, we keep the computational costs of the full networks <b>similar</b>, at around 3.0\u00d710\u2078 FLOPs ...", "dateLastCrawled": "2022-01-30T15:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Generic Object Detection with <b>Dense</b> Neural Patterns and Regionlets", "url": "https://ai.stanford.edu/~wzou/bmvc2014_ZouWangSunLin.pdf", "isFamilyFriendly": true, "displayUrl": "https://ai.stanford.edu/~wzou/bmvc2014_ZouWangSunLin.pdf", "snippet": "This <b>is similar</b> to a HOG <b>feature</b> extractor, which produces the same histograms for <b>image</b> patches with the same appearance. Other architectures such as local re- ceptive \ufb01eld networks with untied weights (Le et al., 2012) o r fully-connected networks1 do not have these properties. Not only are these properties valid for a one-layer CNN, they are also valid for a deep CNN with many stacked layers and all dimensions of its <b>feature</b> maps2. By virtue of these desirable properties, we employ the ...", "dateLastCrawled": "2022-01-07T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Semantic Segmentation of Very-<b>High-Resolution</b> Remote Sensing Images via ...", "url": "https://www.mdpi.com/2072-4292/14/3/533/html", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/14/3/533/html", "snippet": "Consequently, we design a scheme of <b>dense</b> <b>feature</b> aggregation in order to fully exploit the strengths of each <b>feature</b>, to acquire valuable information and enhance the segmentation performance. First of all, con . feat F c o n and dis . feat F d i s are concatenated together and passed through a 1 \u00d7 1 convolutional layer to generate the resulting <b>feature</b> F c .", "dateLastCrawled": "2022-02-03T11:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What Is It Like Down There? Generating <b>Dense</b> Ground-Level Views and ...", "url": "https://dl.acm.org/doi/pdf/10.1145/3274895.3274969", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/pdf/10.1145/3274895.3274969", "snippet": "images to produce <b>dense</b> <b>feature</b> maps. This is the approach taken by Workman et al. in [33] to fuse VGG-16 features extracted from Google Street View images with <b>high-resolution</b> satellite imagery for <b>dense</b> land-use classification. However, as we showed in previ-ous work [5], this interpolate-then-classify approach assumes that", "dateLastCrawled": "2021-07-10T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Remote Sensing | Free Full-Text | Classification for <b>High Resolution</b> ...", "url": "https://www.mdpi.com/2072-4292/9/5/498/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/9/5/498/htm", "snippet": "The most significant <b>feature</b> of the FCN model is: on the one hand, FCN inherits the high accuracy <b>feature</b> for <b>image</b>-label classification from standard CNN. On the other hand, it maintains the 2-D spatial information of the input <b>image</b>, thus achieving <b>dense</b> class prediction. However, pooling operations cause serious reduction of the resolution. The output is not fine enough, which will result in the loss of valuable detail information. As can be seen from", "dateLastCrawled": "2022-01-28T16:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>High-Resolution Semantic Labeling with Convolutional Neural Networks</b> ...", "url": "https://deepai.org/publication/high-resolution-semantic-labeling-with-convolutional-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>high-resolution-semantic-labeling-with-convolutional</b>...", "snippet": "The <b>dense</b> semantic labeling problem <b>can</b> be seen as classifying the central pixel of an <b>image</b> patch, the size of the input patch being the receptive field used to classify it. To label the whole <b>image</b> the prediction must thus be performed on many overlapping <b>image</b> patches, which requires a huge amount of redundant operations.", "dateLastCrawled": "2021-12-20T22:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Semantic Segmentation using Fully Convolutional Networks</b> over the years", "url": "https://www.meetshah.dev/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html", "isFamilyFriendly": true, "displayUrl": "https://www.meetshah.dev/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/...", "snippet": "A general semantic segmentation architecture <b>can</b> be broadly <b>thought</b> of as an encoder network followed by a decoder network. The encoder is usually is a pre-trained classification network like VGG/ResNet followed by a decoder network. The decoder network/mechanism is mostly where these architectures differ. The task of the decoder is to semantically project the discriminative features (lower resolution) learnt by the encoder onto the pixel space (higher resolution) to get a <b>dense</b> ...", "dateLastCrawled": "2022-02-01T00:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Responsive Images</b> Revisited\u2014<b>High Resolution Images</b>", "url": "https://vanseodesign.com/web-design/responsive-images-revisitedhigh-resolution-images/", "isFamilyFriendly": true, "displayUrl": "https://vanseodesign.com/web-design/<b>responsive-images</b>-revisited<b>high-resolution-images</b>", "snippet": "What makes for a <b>high resolution</b> <b>image</b>? Is it the pixels per inch (ppi)? Is it the dots per inch (dpi)? What distinguishes an <b>image</b> as @1x, @2x, or @3x? If we\u2019re going to create pixel <b>dense</b> images for <b>high resolution</b> devices, it probably makes sense to understand a little about what is a <b>high resolution</b> <b>image</b>. For the last couple of weeks I\u2019ve been talking about <b>responsive images</b>, specifically how the spec is stabilizing around the srcset attribute and the picture element. As part of the ...", "dateLastCrawled": "2021-11-28T06:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Remote Sensing | Free Full-Text | Residual <b>Dense</b> Network Based on ...", "url": "https://www.mdpi.com/2072-4292/12/11/1887/html", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/12/11/1887/html", "snippet": "The scene classification of a remote sensing <b>image</b> has been widely used in various fields as an important task of understanding the content of a remote sensing <b>image</b>. Specially, a <b>high-resolution</b> remote sensing scene contains rich information and complex content. Considering that the scene content in a remote sensing <b>image</b> is very tight to the spatial relationship characteristics, how to design an effective <b>feature</b> extraction network directly decides the quality of classification by fully ...", "dateLastCrawled": "2022-01-27T22:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Densely Based Multi-Scale and Multi-Modal Fully Convolutional Networks ...", "url": "https://www.researchgate.net/publication/335960161_Densely_Based_Multi-Scale_and_Multi-Modal_Fully_Convolutional_Networks_for_High-Resolution_Remote-Sensing_Image_Semantic_Segmentation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335960161_<b>Dense</b>ly_Based_Multi-Scale_and_Multi...", "snippet": "A Y-shaped convolutional network <b>can</b> effectively segment multi-scale roads from <b>high-resolution</b> images . A <b>dense</b> FCN <b>can</b> provide fine-grained semantic segmentation maps (Peng et al. 2019). These ...", "dateLastCrawled": "2021-12-23T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Convolutional Neural Networks \u2014 Image Classification</b> w. Keras ...", "url": "https://www.learndatasci.com/tutorials/convolutional-neural-networks-image-classification/", "isFamilyFriendly": true, "displayUrl": "https://www.learndatasci.com/tutorials/<b>convolutional-neural-networks-image-classification</b>", "snippet": "The outputted <b>feature</b> maps <b>can</b> <b>be thought</b> of as a <b>feature</b> stack. Fig 4. The yellow box is a filter, which is a matrix of 0s and 1s that defines a transformation, and the green box is an <b>image</b> matrix.", "dateLastCrawled": "2022-02-01T08:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Review of <b>Image Super-Resolution</b> | Paperspace Blog", "url": "https://blog.paperspace.com/image-super-resolution/", "isFamilyFriendly": true, "displayUrl": "https://blog.paperspace.com/<b>image-super-resolution</b>", "snippet": "The output learned is a residual <b>image</b> which is added to the interpolated input to get the <b>high resolution</b> <b>image</b>. The output of the <b>Feature</b> Upsampling Block is also passed to the next stage, which is used for refining the <b>high resolution</b> output of this stage and scaling it to the next level. Since lower-resolution outputs are used in refining further stages, there is shared learning which helps the network to perform better.", "dateLastCrawled": "2022-02-03T00:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[D] <b>Convolutional Networks for High Resolution</b> Images", "url": "https://www.reddit.com/r/MachineLearning/comments/6r5zqb/d_convolutional_networks_for_high_resolution/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/6r5zqb/d_<b>convolutional_networks_for_high_resolution</b>", "snippet": "I had a <b>thought</b> of possibly breaking the <b>image</b> into sub patches and feeding each patch into an LSTM, so that the patches are fed in as if they were frames of a video and each prediction feeds into the next. Not sure if it would work as I imagine it might. 23 comments. share. save. hide. report. 74% Upvoted. This thread is archived. New comments cannot be posted and votes cannot be cast. Sort by. best. level 1. 12 points \u00b7 3 years ago. Only downsampling or cropping <b>can</b> save you from the ...", "dateLastCrawled": "2021-01-14T03:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Image</b> quality enhancement using hybrid attention networks", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/ipr2.12368", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/ipr2.12368", "snippet": "(HAUM). Speci\ufb01cally, multi-scale <b>feature</b> maps are fully interacted with each other with the help of nested subnetworks so that both <b>high-resolution</b> spatial details and high-level contextual information <b>can</b> be combined to improve the representation ability of the network. Further, a hybrid attention network (HAN) is proposed and evaluations on three separate subtasks demonstrate its good performance. Extensive experiments on the authors\u2019 synthetic dataset, a more complex version, show ...", "dateLastCrawled": "2022-01-21T18:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Change input shape dimensions for fine-tuning with Keras - PyImageSearch", "url": "https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/", "isFamilyFriendly": true, "displayUrl": "https://www.py<b>image</b>search.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning...", "snippet": "More importantly, you now know how to change the input <b>image</b> shape dimensions of a pre-trained network and then apply <b>feature</b> extraction/fine-tuning using Keras! Be sure to use this tutorial as a template for whenever you need to apply transfer learning to a pre-trained network with different <b>image</b> dimensions than what it was originally trained on.", "dateLastCrawled": "2022-02-01T06:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>High resolution non-rigid</b> <b>dense</b> matching based on optimized sampling ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231217302485", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231217302485", "snippet": "<b>Compared</b> with rigid <b>dense</b> matching research , , , non ... <b>Feature</b> noise and dokeh in <b>high resolution non-rigid</b> <b>image</b> pairs: number 1 and 2 mean the two matching images; Fig. a shows us the slight differences between <b>image</b> pairs, and Fig. b shows us the less texture and dokeh in <b>image</b> pairs. In order to avoid mismatch caused by <b>feature</b> noise and non-uniform matching caused by less texture and dokeh, we propose an optimized sampling method based on Gibbs <b>dense</b> sampling considering both texture ...", "dateLastCrawled": "2021-12-06T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>High-Resolution Aerial Imagery Semantic Labeling with</b> <b>Dense</b> Pyramid Network", "url": "https://pubmed.ncbi.nlm.nih.gov/30400591/", "isFamilyFriendly": true, "displayUrl": "https://pubmed.ncbi.nlm.nih.gov/30400591", "snippet": "Semantic segmentation of <b>high-resolution</b> aerial images is of great importance in certain fields, but the increasing spatial resolution brings large intra-class variance and small inter-class differences that <b>can</b> lead to classification ambiguities. Based on high-level contextual features, the deep convolutional neural network (DCNN) is an effective method to deal with semantic segmentation of <b>high-resolution</b> aerial imagery. In this work, a novel <b>dense</b> pyramid network (DPN) is proposed for ...", "dateLastCrawled": "2021-02-09T19:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Dual-<b>Dense</b> Convolution Network for Change Detection of <b>High-Resolution</b> ...", "url": "https://pdfs.semanticscholar.org/b043/5d8c4770a7645796058748da31ef9fd2d913.pdf", "isFamilyFriendly": true, "displayUrl": "https://pdfs.semanticscholar.org/b043/5d8c4770a7645796058748da31ef9fd2d913.pdf", "snippet": "The DCNN <b>can</b> achieve superior performance <b>compared</b> to conventional classi\ufb01cation algorithms with handcrafted features. Recently, several change detection methods using deep learning algorithms have been proposed [18\u201320]. A difference <b>image</b> is fed into the deep neural networks as input data [18]. In addition, the neighboring features on each pixel on the difference <b>image</b> are taken as inputs. The restricted Boltzmann machine (RBM) is used for pre-training and is then unrolled in order to ...", "dateLastCrawled": "2022-02-01T07:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Building Extraction in Very <b>High Resolution</b> Imagery by <b>Dense</b>-Attention ...", "url": "https://www.researchgate.net/publication/328833342_Building_Extraction_in_Very_High_Resolution_Imagery_by_Dense-Attention_Networks/fulltext/5be585ef4585150b2ba95f54/Building-Extraction-in-Very-High-Resolution-Imagery-by-Dense-Attention-Networks.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/328833342_Building_Extraction_in_Very_High...", "snippet": "Building Extraction in Very <b>High Resolution</b> Imagery by <b>Dense</b>-Attention Networks Hui Yang 1,2, Penghai Wu 2,3,4,* , Xuedong Yao 2, Yanlan Wu 2,3,4,*, Biao Wang 2,4 and Yongyang Xu 5 1 School of ...", "dateLastCrawled": "2022-01-14T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Dense</b> <b>feature</b> pyramid network for ship detection in SAR images - NASA/ADS", "url": "https://ui.adsabs.harvard.edu/abs/2020SPIE11584E..1EH/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2020SPIE11584E..1EH/abstract", "snippet": "In this paper, we present <b>Dense</b> <b>Feature</b> Pyramid Network (DenseFPN). Based on the hierarchy of backbone network, the cross-scale connections and lateral connections, the shallow features and deep features are processed differently in DenseFPN. <b>Compared</b> with conventional FPN, we integrate DenseFPN into Faster R-CNN framework and thus form a novel detector. Experiments on <b>high-resolution</b> SAR images dataset (HRSID) have verified the effectiveness of the enhanced hierarchical <b>feature</b> in the ...", "dateLastCrawled": "2021-12-06T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Single <b>Image</b> Super-Resolution Based on Global <b>Dense</b> <b>Feature</b> Fusion ...", "url": "https://europepmc.org/article/PMC/PMC6359588", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC6359588", "snippet": "DFFNet <b>can</b> extract <b>dense</b> features from an original LR <b>image</b> to reconstruct a HR <b>image</b> directly, without any <b>image</b> scaling preprocessing. For an extremely deep network, it is not practical to extract every single layer\u2019s output <b>feature</b>. A <b>feature</b> fusion block (FFblock) is introduced as the basic module of DFFNet. FFblock consists of a global <b>feature</b> fusion (GFF) unit and a <b>feature</b> reduction and learning (FRL) unit, which <b>can</b> make full use of global features, learning the <b>feature</b> spatial ...", "dateLastCrawled": "2022-01-27T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Dense</b> Deformation Network for <b>High Resolution</b> Tissue Cleared <b>Image</b> ...", "url": "https://deepai.org/publication/dense-deformation-network-for-high-resolution-tissue-cleared-image-registration", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>dense</b>-deformation-network-for-<b>high-resolution</b>-tissue...", "snippet": "For <b>high resolution</b> images, a deformable <b>image</b> registration algorithm takes very long runtime which makes them inapplicable for quick analysis of biological data in the processing pipeline. Recently, a bio-chemical process named Tissue clearing is emerged that <b>can</b> remove light obstructing elements from soft-tissues and enable biologist to take images with very <b>high resolution</b>. The pixel spacing of these images are extremely small. Thus, the 3D images obtained from tissue clearing are ...", "dateLastCrawled": "2021-12-10T18:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Remote Sensing | Free Full-Text | Residual <b>Dense</b> Network Based on ...", "url": "https://www.mdpi.com/2072-4292/12/11/1887/html", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/12/11/1887/html", "snippet": "Our designed method <b>can</b> enable the network to capture the <b>feature</b> information of each convolutional layer of the <b>high-resolution</b> remote sensing <b>image</b> and merge the local features of RDB to improve the <b>feature</b> propagation efficiency and the features utilization rate. That is to say, it is possible to extract more detailed features as a result of improving the overall performance of scene classification.", "dateLastCrawled": "2022-01-27T22:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "BlockCopy: <b>High-Resolution</b> Video Processing With Block-Sparse <b>Feature</b> ...", "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Verelst_BlockCopy_High-Resolution_Video_Processing_With_Block-Sparse_Feature_Propagation_and_Online_ICCV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021/papers/Verelst_BlockCopy_High...", "snippet": "BlockCopy: <b>High-Resolution</b> Video Processing with Block-Sparse <b>Feature</b> Propagation and Online Policies Thomas Verelst Tinne Tuytelaars ESAT-PSI, KU Leuven Leuven, Belgium fthomas.verelst, tinne.tuytelaarsg@esat.kuleuven.be Abstract In this paper we propose BlockCopy, a scheme that ac-celerates pretrained frame-based CNNs to process video more ef\ufb01ciently, <b>compared</b> to standard frame-by-frame pro-cessing. To this end, a lightweight policy network deter-mines important regions in an <b>image</b>, and ...", "dateLastCrawled": "2022-02-01T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "FaPN: <b>Feature</b>-aligned Pyramid Network for <b>Dense</b> <b>Image</b> Prediction | DeepAI", "url": "https://deepai.org/publication/fapn-feature-aligned-pyramid-network-for-dense-image-prediction", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/fapn-<b>feature</b>-aligned-pyramid-network-for-<b>dense</b>-<b>image</b>...", "snippet": "<b>Feature</b> Pyramid Network Backbone: The existing <b>dense</b> <b>image</b> prediction methods <b>can</b> be broadly divided into two groups. The first group utilizes atrous convolutions to enlarge the receptive field of convolutional filters for capturing long-range information without reducing resolutions spatially. DeepLab is one of the earliest method that adopt atrous convolution for semantic segmentation. It introduced an Atrous Spatial Pyramid Pooling module (ASPP) comprised of atrous convolutions with ...", "dateLastCrawled": "2021-12-22T00:35:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Modern <b>Machine Learning</b> Algorithms: Strengths and Weaknesses", "url": "https://elitedatascience.com/machine-learning-algorithms", "isFamilyFriendly": true, "displayUrl": "https://elitedatascience.com/mac", "snippet": "Of course, the algorithms you try must be appropriate for your problem, which is where picking the right <b>machine learning</b> task comes in. As an <b>analogy</b>, if you need to clean your house, you might use a vacuum, a broom, or a mop, but you wouldn&#39;t bust out a shovel and start digging. <b>Machine Learning</b> Tasks. This is Part 1 of this series. In this ...", "dateLastCrawled": "2022-02-03T00:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "An <b>analogy</b> between various <b>machine</b>-<b>learning</b> techniques for detecting ...", "url": "https://link.springer.com/article/10.1007/s12205-015-0726-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12205-015-0726-0", "snippet": "In this paper, the authors conducted a comparison study to evaluate the performance of different <b>machine</b> <b>learning</b> techniques for detection of three common categorists of building materials: Concrete, red brick, and OSB boards. The employed classifiers in this research are: Multilayer Perceptron (MLP), Radial Basis Function (RBF), and Support Vector <b>Machine</b> (SVM). To achieve this goal, the <b>feature</b> vectors extracted from image blocks are classified to perform a comparison between the ...", "dateLastCrawled": "2022-01-29T09:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> With Spark. A distributed <b>Machine Learning</b>\u2026 | by MA ...", "url": "https://towardsdatascience.com/machine-learning-with-spark-f1dbc1363986", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine-learning</b>-with-spark-f1dbc1363986", "snippet": "This section covers the basic steps involved in transformations of input <b>feature</b> data into the format <b>Machine Learning</b> algorithms accept. We will be covering the transformations coming with the SparkML library. To understand or read more about the available spark transformations in 3.0.3, follow the below link. Extracting, transforming and selecting features. This section covers algorithms for working with features, roughly divided into these groups: Extraction: Extracting\u2026 spark.apache ...", "dateLastCrawled": "2022-02-02T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Using Deep <b>Learning</b> for Image Analogies | by Tomer Amit | Towards Data ...", "url": "https://towardsdatascience.com/using-deep-learning-for-image-analogies-aa2e7d7af337", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-deep-<b>learning</b>-for-image-analogies-aa2e7d7af337", "snippet": "(diagram taken from deeplearning.ai course by Andrew Ng, \u201cConvolutional Neural Networks\u201d). At the end of the network we have an additional flattening layer, two fully connected <b>dense</b> layers, and a softmax layer, which outputs a probability P(x\u2208i), that the image belongs to the i th label, for i=1,\u2026,1000 (number of labels).. Word Embeddings and Analogies. Another concept, related to language processing and deep <b>learning</b>, is Word Embeddings.Given a large corpus of text, say with ...", "dateLastCrawled": "2022-01-19T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Neural Networks as <b>Feature</b> extractors | by Yemane Yohannes | Medium", "url": "https://yemaney.medium.com/neural-networks-as-feature-extractors-b202857e07f7?source=post_internal_links---------1----------------------------", "isFamilyFriendly": true, "displayUrl": "https://yemaney.medium.com/neural-networks-as-<b>feature</b>-extractors-b202857e07f7?source=...", "snippet": "One theory consistent with the brain <b>analogy</b> is the idea of manifold unwinding(1). Even though an object can vary in many ways (perspective, lighting, distance etc.), people still have an easy time in classification. The insight from this? The identity of an image can encompass many variations, but there must be a way to identify uniqueness. For example, suppose we were to plot a face with axis representing each <b>feature</b> it contains. A person\u2019s face can have many different variations. But ...", "dateLastCrawled": "2022-01-18T12:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Transfer <b>Learning</b>: The Highest Leverage Deep <b>Learning</b> Skill You Can Learn", "url": "https://www.the-analytics.club/transfer-learning", "isFamilyFriendly": true, "displayUrl": "https://www.the-analytics.club/transfer-<b>learning</b>", "snippet": "<b>Feature</b> Extraction: If you want to transfer knowledge from one <b>machine</b> <b>learning</b> model to another but don\u2019t want to re-train the second, larger model on your data set, then <b>feature</b> extraction is the best way to do this. This is possible because you can take the learned features from one model and train another, much smaller model. Used in conjunction with fine-tuning, this process can give you outstanding results in a short amount of time.", "dateLastCrawled": "2022-01-29T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>MLP for regression with TensorFlow 2 and</b> Keras \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2019/07/30/creating-an-mlp-for-regression-with-keras/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2019/07/30/creating-an-mlp-for-regression-with...", "snippet": "<b>Machine</b> <b>learning</b> is a wide field and <b>machine</b> <b>learning</b> problems come in many flavors. If, say, ... We next split the data into <b>feature</b> vectors and targets: # Separate features and targets X = dataset[:, 0: 3] Y = dataset[:, 3] Code language: PHP (php) The assumption that I make here is that the water levels at one reservoir can be predicted from the other three. Specifically, I use the first three (0:3, a.k.a. zero to but excluding three) columns in the dataset as predictor variables, while I ...", "dateLastCrawled": "2022-02-03T02:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Difference between scikit-learn and <b>tensorflow</b> | by Shiv Bajpai | Medium", "url": "https://medium.com/@shvbajpai/difference-between-scikit-learn-and-tensorflow-b6ad2f7b840c", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@shvbajpai/difference-between-scikit-learn-and-<b>tensorflow</b>-b6ad2f7b840c", "snippet": "Traditional <b>machine</b> <b>learning</b>: use <b>feature</b> engineering to artificially refine and clean the data ; Deep <b>learning</b>: using representation <b>learning</b>, the <b>machine</b> <b>learning</b> model itself refines the data ...", "dateLastCrawled": "2022-02-03T18:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Perception and <b>Learning</b> in Machines: DTAM: <b>Dense Tracking and Mapping</b>", "url": "https://ahumaninmachinesworld.blogspot.com/2015/07/dtam-dense-tracking-and-mapping.html", "isFamilyFriendly": true, "displayUrl": "https://ahumanin<b>machines</b>world.blogspot.com/2015/07/dtam-<b>dense-tracking-and-mapping</b>.html", "snippet": "<b>Dense</b> Visual SLAM approach of Richard Newcombe Perception and <b>Learning</b> in Machines ... A video for the same submission is available here. While most VSLAM systems live off robust <b>feature</b> detection and tracking, DTAM is a novel pixel-wise approach which uses the availability of many low baseline frames to its advantage in both creating <b>dense</b> maps and using them for robust camera pose estimation. The original paper by Richard Newcombe can be found here. The following video shows the depth maps ...", "dateLastCrawled": "2022-01-16T15:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Prediction of Chronic Kidney Disease - A Machine Learning Perspective</b>", "url": "https://www.researchgate.net/publication/348697674_Prediction_of_Chronic_Kidney_Disease_-_A_Machine_Learning_Perspective", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/348697674_Prediction_of_Chronic_Kidney...", "snippet": "On the other hand, Chittora et. al carried out six different methods of <b>feature</b> selection and implemented seven <b>machine</b> <b>learning</b> algorithms where 99.6% accuracy was attained by deep <b>learning</b> ...", "dateLastCrawled": "2022-02-03T01:52:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Information | Free Full-Text | <b>Image Aesthetic Assessment Based on</b> ...", "url": "https://www.mdpi.com/2078-2489/11/4/223/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2078-2489/11/4/223/htm", "snippet": "Through <b>machine</b> <b>learning</b>, the classification accuracy rate reached 82.4%. Aesthetic assessment is subjective and difficult accurately model and quantify in engineering because the image aesthetics are ever-changing. Therefore, manual features often have an insufficient representation of aesthetic information, and it is difficult to fully express the aesthetics of images, but it is an approximate representation of aesthetic rules. Liu", "dateLastCrawled": "2021-12-06T06:09:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(dense feature)  is like +(high-resolution image)", "+(dense feature) is similar to +(high-resolution image)", "+(dense feature) can be thought of as +(high-resolution image)", "+(dense feature) can be compared to +(high-resolution image)", "machine learning +(dense feature AND analogy)", "machine learning +(\"dense feature is like\")", "machine learning +(\"dense feature is similar\")", "machine learning +(\"just as dense feature\")", "machine learning +(\"dense feature can be thought of as\")", "machine learning +(\"dense feature can be compared to\")"]}