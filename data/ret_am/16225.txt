{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "U-net <b>model</b> for brain extraction: Trained on humans for transfer to non ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8529630/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8529630", "snippet": "3.1. The convergence of <b>human</b> U-net <b>model</b>. To acquire a <b>pre-trained</b> <b>model</b> for macaque samples, we first trained a U-Net <b>model</b> using the <b>human</b> samples. Fig. S4 demonstrates the sum of loss on the training set and the mean Dice coefficients across <b>human</b> participants on the validation set for each epoch. After the first epoch, the loss decreased ...", "dateLastCrawled": "2021-12-30T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep <b>Learning based Human Pose Estimation using OpenCV</b>", "url": "https://learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/", "isFamilyFriendly": true, "displayUrl": "https://learnopencv.com/deep-<b>learning-based-human-pose-estimation-using-opencv</b>-cpp-python", "snippet": "2.2 <b>Pre-trained</b> models for <b>Human</b> Pose Estimation. The authors of the paper have shared two models \u2013 one is trained on the Multi-Person Dataset ( MPII ) and the other is trained on the COCO dataset. The COCO <b>model</b> produces 18 points, while the MPII <b>model</b> outputs 15 points. The outputs plotted on a person is shown in the image below.", "dateLastCrawled": "2022-02-01T20:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Frontiers</b> | What Does Social Support Sound <b>Like</b>? Challenges and ...", "url": "https://www.frontiersin.org/articles/10.3389/fpubh.2021.633606/full", "isFamilyFriendly": true, "displayUrl": "https://www.<b>frontiers</b>in.org/articles/10.3389/fpubh.2021.633606", "snippet": "The major limitation of our current study was the accuracy of the <b>pre-trained</b> <b>model</b>. One of the major challenges to accurately collecting passive sensing data was inaccuracy of YouTube trained machine learning. The social and cultural environment of adolescent and young adult mothers are not universally consistent, so prior to the passive audio data collection, it is integral to record and train some of these culturally relevant sounds from the study setting to train the machine. Similarly ...", "dateLastCrawled": "2022-01-27T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What Does Social Support Sound <b>Like</b>? Challenges and Opportunities for ...", "url": "https://pubmed.ncbi.nlm.nih.gov/33855008/", "isFamilyFriendly": true, "displayUrl": "https://<b>pubmed</b>.ncbi.nlm.nih.gov/33855008", "snippet": "However, a <b>pre-trained</b> <b>model</b> had the limited accuracy for identifying speech and lacked categories allowing distinction between positive and negative social interactions. To improve the contribution of passive audio collection to understanding the social environment, future work should improve the accuracy of audio categorization, code for constellations of sounds, and combine audio with other smartphone data collection such as location and activity.", "dateLastCrawled": "2021-04-16T21:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Medical image analysis based on deep learning approach", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023554/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8023554", "snippet": "DBNs are generative models constructed by stacking multiple RBMs. DBN is a hybrid <b>model</b>, the first two layers are <b>like</b> RBM, and the rest of the layers form a directed generative <b>model</b>. A DBN has one visible layer v and a series of hidden layers h (1), h (2), \u2026, h (l) as shown in Fig. Fig.4c. 4c. The DBN <b>model</b> joint distribution between the observed units v and the l hidden layers h k ( k = 1, \u2026l) as (9) P v h 1 \u2026 h l = \u220f k = 0 l \u2212 2 P h k h k + 1 P h l \u2212 1 h l. 9. where v = h (0 ...", "dateLastCrawled": "2022-01-30T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "U-net <b>model for brain extraction: Trained on humans for</b> transfer to non ...", "url": "https://www.sciencedirect.com/science/article/pii/S1053811921002780", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1053811921002780", "snippet": "To acquire a <b>pre-trained</b> <b>model</b> for macaque samples, we first trained a U-Net <b>model</b> using the <b>human</b> samples. Fig. S4 demonstrates the sum of loss on the training set and the mean Dice coefficients across <b>human</b> participants on the validation set for each epoch. After the first epoch, the loss decreased steeply and the mean Dice coefficient reached above 0.985. After that, the mean Dice coefficient gradually improved, showing its highest value (0.9916\u00b10.0012) after the 9th epoch. To avoid over ...", "dateLastCrawled": "2022-01-27T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Are Convolutional Neural Networks or Transformers more <b>like</b> <b>human</b> ...", "url": "https://www.arxiv-vanity.com/papers/2105.07197/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2105.07197", "snippet": "Modern machine learning models for computer vision exceed humans in accuracy on specific visual recognition tasks, notably on datasets <b>like</b> ImageNet. However, high accuracy can be achieved in many ways. The particular decision function found by a machine learning system is determined not only by the data to which the system is exposed, but also the inductive biases of the <b>model</b>, which are typically harder to characterize. In this work, we follow a recent trend of in-depth behavioral analyses ...", "dateLastCrawled": "2021-12-02T23:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Artificial General Intelligence (AGI) and the Real Existential ...", "url": "https://www.shunlongwei.com/the-artificial-general-intelligence-agi-and-the-real-existential-threat-hypothesis/", "isFamilyFriendly": true, "displayUrl": "https://www.shunlongwei.com/the-artificial-general-intelligence-agi-and-the-real...", "snippet": "GPT-3 is a deep learning algorithm that produces <b>human</b>-<b>like</b> text. It is the third generation language prediction <b>model</b> created by San Francisco start-up \u201cOpenAI\u201d, which was co-founded by Elon Musk. This programme is better than any prior programme at producing text which could have been written by a <b>human</b>. It is a quantum leap because it may prove useful to many companies and has great potential in automating tasks.", "dateLastCrawled": "2022-01-26T22:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Novel AI <b>driven approach to classify infant motor functions</b> ...", "url": "https://www.nature.com/articles/s41598-021-89347-5", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-89347-5", "snippet": "<b>Like</b> all man-powered assessments, GMA is vulnerable to <b>human</b> factors (e.g., fatigue and other physical influences, limited skills or experience, biases and subjectivity) and environmental influences.", "dateLastCrawled": "2022-02-01T16:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why does transfer learning works? Is it because the source and ... - Quora", "url": "https://www.quora.com/Why-does-transfer-learning-works-Is-it-because-the-source-and-the-target-task-are-similar-Or-is-it-because-the-dataset-used-in-source-task-is-good-enough-that-its-representation-can-be-used-to-discover-patterns-from", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-does-transfer-learning-works-Is-it-because-the-source-and...", "snippet": "Answer (1 of 2): It is not right answer as respective to question but there is some intuitive knowledge of some concept \u2026\u2026. Transfer learning is a popular ...", "dateLastCrawled": "2022-01-03T08:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "U-net <b>model</b> for brain extraction: Trained on humans for transfer to non ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8529630/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8529630", "snippet": "3.1. The convergence of <b>human</b> U-net <b>model</b>. To acquire a <b>pre-trained</b> <b>model</b> for macaque samples, we first trained a U-Net <b>model</b> using the <b>human</b> samples. Fig. S4 demonstrates the sum of loss on the training set and the mean Dice coefficients across <b>human</b> participants on the validation set for each epoch. After the first epoch, the loss decreased ...", "dateLastCrawled": "2021-12-30T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) A transfer-learning approach for first-year developmental <b>infant</b> ...", "url": "https://www.researchgate.net/publication/341644458_A_transfer-learning_approach_for_first-year_developmental_infant_brain_segmentation_using_deep_neural_networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341644458_A_transfer-learning_approach_for...", "snippet": "3.3 Experiment 3: Transfer <b>pre-trained</b> baseline <b>model</b> to Dataset III To test our proposed ap proach on se gmenting <b>infant</b> brai n struct ures across differenc e ages, we", "dateLastCrawled": "2022-01-22T07:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Medical image analysis based on deep learning approach", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023554/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8023554", "snippet": "ANN is a computational <b>model</b> structure that has some performance characteristics <b>similar</b> to biological neural networks. ANN comprises simple processing units called neurons or nodes that are interconnected by weighted links. A biological neuron can be described mathematically in Eq. . Figure Figure3 3 shows the simplest artificial neural <b>model</b> known as the perceptron. y = f w x T + b. 1. Open in a separate window. Fig. 3. Perceptron . Let be the vector of inputs (features), be the weight ...", "dateLastCrawled": "2022-01-30T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Image Recognition with</b> Transfer Learning (98.5%)", "url": "https://thedatafrog.com/en/articles/image-recognition-transfer-learning/", "isFamilyFriendly": true, "displayUrl": "https://thedatafrog.com/en/articles/image-recognition-transfer-learning", "snippet": "What we&#39;re going to do, for VGG16 and the other <b>pre-trained</b> models, is to download the <b>model</b> with the weights resulting from the training on ImageNet. Then, we will replace the classifier part by our own simple classifier, adapted to our problem. For instance, this classifier will have only two output neurons in the last layer, one for dog and one for cat. Finally, we will freeze all the layers of the convolutional part, so that we only have to train the parameters of our classifier on our ...", "dateLastCrawled": "2022-01-29T07:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "U-net <b>model for brain extraction: Trained on humans for</b> transfer to non ...", "url": "https://www.sciencedirect.com/science/article/pii/S1053811921002780", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1053811921002780", "snippet": "To acquire a <b>pre-trained</b> <b>model</b> for macaque samples, we first trained a U-Net <b>model</b> using the <b>human</b> samples. Fig. S4 demonstrates the sum of loss on the training set and the mean Dice coefficients across <b>human</b> participants on the validation set for each epoch. After the first epoch, the loss decreased steeply and the mean Dice coefficient reached above 0.985. After that, the mean Dice coefficient gradually improved, showing its highest value (0.9916\u00b10.0012) after the 9th epoch. To avoid over ...", "dateLastCrawled": "2022-01-27T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Section-4 of Mastering spaCy by Duygu Altinok - Data Science Portfolio", "url": "https://shreyash1811.github.io/python/mastering_SpaCy_sec4/", "isFamilyFriendly": true, "displayUrl": "https://shreyash1811.github.io/python/mastering_SpaCy_sec4", "snippet": "Is there a <b>pre-trained</b> <b>model</b>/application in GitHub or elsewhere already? (We wouldn\u2019t want to reinvent the wheel) ... Neural networks are <b>human</b> brain-inspired algorithms that contain connected layers, which are made from neurons. Each neuron is a mathematical operation that takes its input, multiplies it by its weights, and then passes the sum through the activation function to the other neurons. TensorFlow is an end-to-end open source platform for machine learning. TensorFlow might be the ...", "dateLastCrawled": "2022-02-03T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Frontiers | Longitudinal Prediction of <b>Infant</b> MR Images With Multi ...", "url": "https://www.frontiersin.org/articles/10.3389/fnins.2021.653213/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fnins.2021.653213", "snippet": "We propose to utilize <b>Model</b> Genesis (Zhou et al., 2019), which is a <b>pre-trained</b> <b>model</b> for 3D medical images, for this feature extraction. Finally, in order to tackle the reduced tissue contrast during the first year of life, particularly at about 6 months of age, we propose a multi-contrast framework, so that the complementary information of different contrasts (T1w and T2w images) can be exploited. The source code of our method will be released to the public upon acceptance of this ...", "dateLastCrawled": "2021-11-24T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Word Acquisition in Neural Language Models | Transactions of the ...", "url": "https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00444/109271/Word-Acquisition-in-Neural-Language-Models", "isFamilyFriendly": true, "displayUrl": "https://direct.mit.edu/.../tacl_a_00444/109271/Word-Acquisition-in-Neural-Language-<b>Models</b>", "snippet": "Learning curves for the word \u201cwalk\u201d in a BERT language <b>model</b> and <b>human</b> children. Blue horizontal lines indicate age of acquisition cutoffs. The blue curve represents the fitted sigmoid function based on the language <b>model</b> surprisals during training (black). Child data obtained from Frank et al. . Figure 2: View large Download slide. Learning curves for the word \u201ceat\u201d for all four language <b>model</b> architectures. Blue horizontal lines indicate age of acquisition cutoffs, and blue curves ...", "dateLastCrawled": "2022-02-02T10:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "baby-cry-detector/README.md at master \u00b7 navjotts/baby-cry-detector \u00b7 GitHub", "url": "https://github.com/navjotts/baby-cry-detector/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/navjotts/baby-cry-detector/blob/master/README.md", "snippet": "having different animal cries which could be <b>similar</b> to a <b>human</b> baby cry; having silence as some of the training samples ; No effort was put into trying to differentiate between a baby laugh v/s a baby cry \u2013 as the need was to detect whether a sleeping <b>infant</b> is up (babies normally cry once up), and even a laughing (or any sound) baby should trigger the alarm for parents (if needed, this could be attempted, and would be the real test for the <b>model</b>) Data Preprocessing The audio files are ...", "dateLastCrawled": "2021-11-28T16:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why does transfer learning works? Is it because the source and ... - Quora", "url": "https://www.quora.com/Why-does-transfer-learning-works-Is-it-because-the-source-and-the-target-task-are-similar-Or-is-it-because-the-dataset-used-in-source-task-is-good-enough-that-its-representation-can-be-used-to-discover-patterns-from", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-does-transfer-learning-works-Is-it-because-the-source-and...", "snippet": "Answer (1 of 2): It is not right answer as respective to question but there is some intuitive knowledge of some concept \u2026\u2026. Transfer learning is a popular ...", "dateLastCrawled": "2022-01-03T08:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Artificial General Intelligence and the Real Existential Threat Hypothesis", "url": "https://indiaai.gov.in/article/artificial-general-intelligence-and-the-real-existential-threat-hypothesis", "isFamilyFriendly": true, "displayUrl": "https://indiaai.gov.in/article/artificial-general-intelligence-and-the-real...", "snippet": "And if not regulated, this <b>can</b> be checkmate on <b>human</b> intelligence. GPT-3 (Generative <b>Pre-Trained</b> Transformer 3) is arousing tremors across the Silicon Valley . Just imagine an AI that <b>can</b> write anything. You feed it poems from a particular poet and it will write a new one with the same rhythm and genre. Or it <b>can</b> write a news article (guardian has already done that). It <b>can</b> read an article, answer questions from the information in the article and even summarize the article for you and not to ...", "dateLastCrawled": "2021-12-26T10:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A New Look at <b>Infant</b> Problem-Solving: Using DeepLabCut to Investigate ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606407/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8606407", "snippet": "DLC relies on a specialized algorithm which is <b>pre-trained</b> (Deng et al., 2009) ... On the other hand, we <b>thought</b> that our measure of imitative similarity could be sensitive to the effort and success of the adult <b>model</b>, as infants received varying information about the success of the modeled solution, and to firsthand evidence, as failure would suggest a necessity for strategy diversification. Our <b>model</b> of imitative similarity revealed a significant main effect of trial such that infants ...", "dateLastCrawled": "2022-01-25T06:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Mindful Machines: Neuroscience &amp; Critical Theory for Ethical AI | by ...", "url": "https://towardsdatascience.com/mindful-machines-neuroscience-critical-theory-for-ethical-ai-4162ebdcc334", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/mindful-machines-neuroscience-critical-theory-for...", "snippet": "<b>Human</b> learning relies on the biological process of neural backpropagation, which <b>can</b> be described as the backpropagation of action potentials after a neuron has fired an impulse (voltage spike) in communication with another neuron. The function of these backward-directioned action potentials is currently a controversial research topic, and computational neuroscience literature is concerned with trying to prove existing hypotheses. For the purpose of this article, I strictly focus on how ...", "dateLastCrawled": "2022-01-29T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The Artificial General Intelligence (AGI) and the Real Existential ...", "url": "https://www.shunlongwei.com/the-artificial-general-intelligence-agi-and-the-real-existential-threat-hypothesis/", "isFamilyFriendly": true, "displayUrl": "https://www.shunlongwei.com/the-artificial-general-intelligence-agi-and-the-real...", "snippet": "GPT-3 (Generative <b>Pre-Trained</b> Transformer 3) is arousing tremors across the Silicon Valley . Just imagine an AI that <b>can</b> write anything. You feed it poems from a particular poet and it will write a new one with the same rhythm and genre. Or it <b>can</b> write a news article (guardian has already done that). It <b>can</b> read an article, answer questions ...", "dateLastCrawled": "2022-01-26T22:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Frontiers</b> | Early Prediction of Cognitive Deficit in Very Preterm ...", "url": "https://www.frontiersin.org/articles/10.3389/fnins.2020.00858/full", "isFamilyFriendly": true, "displayUrl": "https://www.<b>frontiers</b>in.org/articles/10.3389/fnins.2020.00858", "snippet": "The DNN <b>model</b> was <b>pre-trained</b> using a large number of brain connectome data in an unsupervised fashion and then fine-tuned with brain connectome data from very preterm infants. In this study, we proposed a TL-enhanced deep CNN (TL-CNN) <b>model</b> for early prediction of cognitive deficit at 2 years of age in very preterm infants using brain structural connectome derived from at term DTI data.", "dateLastCrawled": "2021-12-04T22:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Neonatal cry signal prediction and classification via dense convolution ...", "url": "https://content.iospress.com/articles/journal-of-intelligent-and-fuzzy-systems/ifs212473", "isFamilyFriendly": true, "displayUrl": "https://content.iospress.com/articles/journal-of-intelligent-and-fuzzy-systems/ifs212473", "snippet": "The transfer learning with <b>pre-trained</b> SVM, CNN of ResNet50 is used for the classification process. The spectrogram images were chosen to classify the audio signals that use MFCC features. It combined deep learning models to improve the result of the technique. ResNet and SVM models were chosen for their simplicity and efficient performance. This technique mainly focuses on reducing false positives. It does on classify the reason for <b>infant</b> cry . In 2019 Severini et al., developed a deep ...", "dateLastCrawled": "2022-02-03T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The development of category specificity in infancy \u2013 What <b>can</b> we learn ...", "url": "https://www.sciencedirect.com/science/article/pii/S0028393215301378", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0028393215301378", "snippet": "The computational <b>model</b> was <b>pre-trained</b> with more or less experiences in order to simulate differences between 4- and 7-month-olds. The models were then subjected to the oddball task from the ERP study and different hypotheses were tested. When the <b>model</b> was <b>pre-trained</b> with random dot patterns, the oddball effect arose gradually during test. When the pre-training involved different pictures of the same categories (animals and furniture), oddball effects were observed in both halves of the ...", "dateLastCrawled": "2021-10-24T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>A Benchmark of Computational Models of</b> Saliency to Predict <b>Human</b> ...", "url": "https://www.researchgate.net/publication/279843693_A_Benchmark_of_Computational_Models_of_Saliency_to_Predict_Human_Fixations", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/279843693_<b>A_Benchmark_of_Computational_Models</b>...", "snippet": "However, a benchmark <b>can</b> also be defined to measure how close a <b>model</b> comes to emulating <b>human</b> patterns of success and failure across different stimuli and contexts 29,273,[287] [288] [289][290 ...", "dateLastCrawled": "2022-01-02T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Does the visual cortex <b>contain pre-trained synaptic weights</b> to ...", "url": "https://www.quora.com/Does-the-visual-cortex-contain-pre-trained-synaptic-weights-to-recognize-objects-at-birth", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Does-the-visual-cortex-<b>contain-pre-trained-synaptic-weights</b>-to...", "snippet": "Answer (1 of 3): First off, there is no such thing as \u201c<b>pre-trained</b>\u201d weights in the brain since there is no ground truth data set available in advanced to train on. Pre-training is an artificial neural network concept, not a neuroscience one. That said, the initial connections between neurons cou...", "dateLastCrawled": "2022-01-22T02:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Crossmodal Language Grounding in an Embodied Neurocognitive Model</b>", "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2020.00052/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fnbot.2020.00052", "snippet": "This <b>model</b> <b>can</b> also provide the basis for further crossmodal integration of perceptually grounded cognitive representations. 1. Introduction . While research in natural language processing has advanced in specific disciplines such as parsing and classifying large amounts of text, <b>human</b>-computer communication is still a major challenge, due to multiple aspects: speech recognition is limited to good signal-to-noise conditions or well-adapted models, dialogue systems depend on a well-defined ...", "dateLastCrawled": "2021-12-29T17:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "U-net <b>model</b> for brain extraction: Trained on humans for transfer to non ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8529630/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8529630", "snippet": "When the results from the current <b>model</b> need improvement, users <b>can</b> upgrade the U-Net using our current generalized <b>model</b> as a <b>pre-trained</b> <b>model</b> and expect a stabilized solution after several training epochs (N&lt;10 epochs) without validation datasets. The <b>model</b>-upgrading module takes about 1\u20135 h on a single CPU, or 15\u201320 min on a GPU. In addition, we released our manually skull-stripped masks (40 macaques across 7 sites) which <b>can</b> be used as \u2018gold standards\u2019 for other deep-learning ...", "dateLastCrawled": "2021-12-30T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Can</b> <b>Pre-Trained Convolutional Neural Networks be</b> used as Feature ...", "url": "https://www.researchgate.net/publication/345373637_Can_Pre-Trained_Convolutional_Neural_Networks_be_used_as_Feature_Extractors_for_Video-based_Neonatal_Sleep_and_Wake_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/345373637_<b>Can</b>_<b>Pre-Trained</b>_Convolutional...", "snippet": "modest accuracy of 65.3% f rom <b>pre-trained</b> A lexNet at FCL7, <b>compared</b> with VEEG annotated data by a. neurologist f or sle ep and wake states. In the future, the transfer learning approach/dedicate ...", "dateLastCrawled": "2021-08-09T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "U-net <b>model for brain extraction: Trained on humans for</b> transfer to non ...", "url": "https://www.sciencedirect.com/science/article/pii/S1053811921002780", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1053811921002780", "snippet": "To acquire a <b>pre-trained</b> <b>model</b> for macaque samples, we first trained a U-Net <b>model</b> using the <b>human</b> samples. Fig. S4 demonstrates the sum of loss on the training set and the mean Dice coefficients across <b>human</b> participants on the validation set for each epoch. After the first epoch, the loss decreased steeply and the mean Dice coefficient reached above 0.985. After that, the mean Dice coefficient gradually improved, showing its highest value (0.9916\u00b10.0012) after the 9th epoch. To avoid over ...", "dateLastCrawled": "2022-01-27T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Deep Transfer Learning for <b>Human</b> Identification Based on ...", "url": "https://www.academia.edu/66599864/Deep_Transfer_Learning_for_Human_Identification_Based_on_Footprint_A_Comparative_Study", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/66599864/Deep_Transfer_Learning_for_<b>Human</b>_Identification...", "snippet": "It consists of 8 <b>pre-trained</b> layers, 5 of these layers are of the type of convolutional layers and other 3 layers are so called fully-connected layers. The last fully-connected layer is designed to classify 1000 object and the remaining layers work to extract features from the image. Alexnet generates feature vector of size 4096-dimensional for each image. The feature vector includes details about the activations of all the layers immediately before the output layer. Alexnet <b>model</b> receives ...", "dateLastCrawled": "2022-01-24T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A multi-task, multi-stage deep transfer learning <b>model</b> for early ...", "url": "https://www.nature.com/articles/s41598-020-71914-x", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-020-71914-x", "snippet": "Finally, we fine-tuned and validated the <b>pre-trained</b> <b>model</b> using 33 preterm infants. Our proposed <b>model</b> identified very preterm infants at high-risk for cognitive, language, and motor deficits at ...", "dateLastCrawled": "2022-01-21T23:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Fearful but not happy expressions boost face detection in <b>human</b> infants ...", "url": "https://royalsocietypublishing.org/doi/10.1098/rspb.2017.1054", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rspb.2017.1054", "snippet": "If an <b>infant</b>&#39;s looking behaviour <b>can</b> be used to locate the side of the face (left or right), that is strong evidence that the <b>infant</b> detected the face , regardless of whether the <b>infant</b> showed a reliable visual preference during the entire trial as measured by PTLT. We introduced a multivariate measure of face detection evidence by using a classifier to locate the side of the face (i.e. discriminating face from noise) based on PTLT and other characteristics of looking behaviour (see Method ...", "dateLastCrawled": "2021-12-04T09:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Medical image analysis based on deep learning approach", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023554/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8023554", "snippet": "The Deep Belief Networks (DBN) proposed by Hinton et al. is a non-convolution <b>model</b> that <b>can</b> extract features and learn a deep hierarchical representation of training data. DBNs are generative models constructed by stacking multiple RBMs. DBN is a hybrid <b>model</b>, the first two layers are like RBM, and the rest of the layers form a directed generative <b>model</b>. A DBN has one visible layer", "dateLastCrawled": "2022-01-30T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>UNet-VGG16 with transfer learning for</b> MRI-based brain tumor ...", "url": "https://www.researchgate.net/publication/342126824_UNet-VGG16_with_transfer_learning_for_MRI-based_brain_tumor_segmentation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342126824_<b>UNet-VGG16_with_transfer_learning</b>...", "snippet": "The MRI brain tumor image will be trained using the UNet-VGG16 <b>model</b> with the Transfer. Learning method. This method freezes the contraction layer in UNet-VGG16 so that the weighted layer is not ...", "dateLastCrawled": "2022-02-02T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Face Detection</b> Models: Which to Use and Why? | by Vardan Agarwal ...", "url": "https://towardsdatascience.com/face-detection-models-which-to-use-and-why-d263e82c302c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>face-detection</b>-<b>models</b>-which-to-use-and-why-d263e82c302c", "snippet": "Let\u2019s give credit where it\u2019s due as only Haar cascade was the only <b>model</b> able to detect the face in the dark in a couple of frames, while the DNN <b>model</b> provided a false positive during that time. When the light was switched on the DNN module was the back at its work providing completely accurate predictions. Dlib\u2019s output was a little shaky but better than Haar cascade which was able to predict even fewer frames and gave some false positives as well. The real surprise was MTCNN. It ...", "dateLastCrawled": "2022-02-02T22:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Image Recognition with</b> Transfer Learning (98.5%)", "url": "https://thedatafrog.com/en/articles/image-recognition-transfer-learning/", "isFamilyFriendly": true, "displayUrl": "https://thedatafrog.com/en/articles/image-recognition-transfer-learning", "snippet": "This function should be adapted to the <b>pre-trained</b> <b>model</b> in use, and is passed to the generators function as an argument. Indeed, in python, a function is an object, that <b>can</b> happily be passed around to other functions). it keeps 90% of the images for training, reserving 10% of the images for validation. Since we have about 25 000 images in our ...", "dateLastCrawled": "2022-01-29T07:40:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Pre-trained</b> Models - Value <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> Technology", "url": "https://valueml.com/transfer-learning-approach-pre-trained-models-classifying-imagenet-classes-with-resnet50-in-python/", "isFamilyFriendly": true, "displayUrl": "https://valueml.com/transfer-<b>learning</b>-<b>approach-pre-trained-models-classifying</b>-imagenet...", "snippet": "Transfer <b>Learning</b> enables us to use the <b>pre-trained</b> models from other people by making small relevant changes. Basically, Transfer <b>Learning</b> (TL) is a <b>Machine</b> <b>Learning</b> technique that trains a new <b>model</b> for a particular problem based on the knowledge gained by solving some other problem. For example, the knowledge gained while <b>learning</b> to recognize trucks could be applied to recognize cars.", "dateLastCrawled": "2022-01-21T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Finding the Word <b>Analogy</b> from given words using Word2Vec embeddings ...", "url": "https://www.geeksforgeeks.org/finding-the-word-analogy-from-given-words-using-word2vec-embeddings/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/finding-the-word-<b>analogy</b>-from-given-words-using-word2vec...", "snippet": "In the word <b>analogy</b> task, we complete the sentence ... What if we can use a <b>Machine</b> <b>Learning</b> algorithm to automate this task of finding the word <b>analogy</b>. In this tutorial, we will be using Word2Vec <b>model</b> and a <b>pre-trained</b> <b>model</b> named \u2018GoogleNews-vectors-negative300.bin\u2018 which is trained on over 50 Billion words by Google. Each word inside the <b>pre-trained</b> dataset is embedded in a 300-dimensional space and the words which are similar in context/meaning are placed closer to each other in ...", "dateLastCrawled": "2022-01-26T14:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Should I Learn Machine Learning</b>? | GenUI", "url": "https://www.genui.com/resources/ml-for-developers", "isFamilyFriendly": true, "displayUrl": "https://www.genui.com/resources/ml-for-developers", "snippet": "But it will almost always be best to start with a <b>pre-trained</b> <b>model</b>, from a more general dataset, and then fine-tune it to fit your specific domain. For example, most image recognition models are based on <b>pre-trained</b> models from ImageNet, a dataset of more than 14 million, hand-labeled images divided into over 20,000 classes (like \u201cbicycle\u201d, \u201cstrawberry\u201d, \u201csky\u201d).", "dateLastCrawled": "2022-01-30T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "SE3M: A <b>Model</b> for Software Effort Estimation Using <b>Pre-trained</b> ...", "url": "https://deepai.org/publication/se3m-a-model-for-software-effort-estimation-using-pre-trained-embedding-models", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/se3m-a-<b>model</b>-for-software-effort-estimation-using-pre...", "snippet": "Idri and Abran (Idri et al., 2016b) also classify a technique by <b>analogy</b> as a <b>machine</b> <b>learning</b> technique. These authors further point out that <b>machine</b> <b>learning</b> models have also gained significant attention for effort estimation purposes, as they can <b>model</b> the complex relationship between effort and software attributes (cost factors), especially when this relationship is not linear, and it does not appear to have any predetermined form. Analog-based reasoning approaches have proven to be ...", "dateLastCrawled": "2021-12-25T16:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Word2Vec in Gensim Explained for Creating Word Embedding Models ...", "url": "https://machinelearningknowledge.ai/word2vec-in-gensim-explained-for-creating-word-embedding-models-pretrained-and-custom/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>knowledge.ai/word2vec-in-gensim-explained-for-creating-word...", "snippet": "<b>Machine</b> <b>learning</b> and ... This is another way putting that word2vec can draw the <b>analogy</b> that if Man is to Woman then Kind is to Queen! The publicly released <b>model</b> of word2vec by Google consists of 300 features and the <b>model</b> is trained in the Google news dataset. The vocabulary size of the <b>model</b> is around 1.6 billion words. However, this might have taken a huge time for the <b>model</b> to be trained on but they have applied a method of simple subsampling approach to optimize the time. Word2Vec ...", "dateLastCrawled": "2022-02-02T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Using Deep <b>Learning</b> for Image Analogies | by Tomer Amit | Towards Data ...", "url": "https://towardsdatascience.com/using-deep-learning-for-image-analogies-aa2e7d7af337", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-deep-<b>learning</b>-for-image-analogies-aa2e7d7af337", "snippet": "I will use the <b>pre-trained</b> VGG16 image classification <b>model</b>. The <b>model</b> consists of CNN layers stacked one after another, connected by max pooling layers. The input of the network is a 244\u00d7244\u00d73 image (i.e image width and length are 244 pixels, and 3 channels), and after applying all the convolutional layers, we get a 7\u00d77\u00d7512 array. (diagram taken from deeplearning.ai course by Andrew Ng, \u201cConvolutional Neural Networks\u201d) At the end of the network we have an additional flattening layer ...", "dateLastCrawled": "2022-01-19T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Transfer <b>Learning</b>: The Highest Leverage Deep <b>Learning</b> Skill You Can Learn", "url": "https://www.the-analytics.club/transfer-learning", "isFamilyFriendly": true, "displayUrl": "https://www.the-analytics.club/transfer-<b>learning</b>", "snippet": "Transfer <b>learning</b> is a <b>machine</b> <b>learning</b> technique in which a <b>model</b> trained on a specific task is reused as part of the training process for another, different task. Here is a simple <b>analogy</b> to help you understand how transfer <b>learning</b> works: imagine that one person has learned everything there is to know about dogs. In contrast, another person has learned everything about cats. If both people are asked, \u201cWhat\u2019s an animal with four legs, a tail, and barks?\u201d The person who knows all ...", "dateLastCrawled": "2022-01-29T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Classifying and completing word analogies by <b>machine</b> <b>learning</b> | Request PDF", "url": "https://www.researchgate.net/publication/349152012_Classifying_and_completing_word_analogies_by_machine_learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/349152012_Classifying_and_completing_word...", "snippet": "In this paper, we depart from this assumption to adopt a <b>machine</b> <b>learning</b> approach, i.e., <b>learning</b> a substitute of the parallelogram <b>model</b>. To achieve our goal, we first review the formal modeling ...", "dateLastCrawled": "2021-11-11T17:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Transfer <b>Learning to solve a Classification Problem</b> :: InBlog", "url": "https://inblog.in/Transfer-Learning-to-solve-a-Classification-Problem-9bihoVsKsV", "isFamilyFriendly": true, "displayUrl": "https://inblog.in/Transfer-<b>Learning-to-solve-a-Classification-Problem</b>-9bihoVsKsV", "snippet": "Why we need <b>pre-Trained</b> <b>Model</b>? Transfer <b>Learning</b> via VGG16; Building a <b>Model</b>; Code Walk Through; Result and Evaluation; Introduction: Neural networks are very different type of the <b>model</b> as compared to the Supervised <b>Learning</b>,. The most important things about deep <b>learning</b> <b>model</b> is it is very hard to train. It requires lots of the resources that a small company can\u2019t bear. RAM on a <b>machine</b> is cheap and is available in plenty. You need hundreds of GB\u2019s of RAM to run a super complex ...", "dateLastCrawled": "2021-11-25T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - <b>Merging pretrained models in Word2Vec</b>? - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/30482669/merging-pretrained-models-in-word2vec", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/30482669", "snippet": "How do i merge these two huge <b>pre-trained</b> vectors? or how do i train a new <b>model</b> and update vectors on top of another? I see that C based word2vec does not support batch training. I am looking to compute word <b>analogy</b> from these two models. I believe that vectors learned from these two sources will produce pretty good results. <b>machine</b>-<b>learning</b> word2vec. Share. Follow edited May 28 &#39;15 at 14:04. pbu. asked May 27 &#39;15 at 12:37. pbu pbu. 2,706 7 7 gold badges 37 37 silver badges 62 62 bronze ...", "dateLastCrawled": "2022-01-22T22:47:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(pre-trained model)  is like +(human infant)", "+(pre-trained model) is similar to +(human infant)", "+(pre-trained model) can be thought of as +(human infant)", "+(pre-trained model) can be compared to +(human infant)", "machine learning +(pre-trained model AND analogy)", "machine learning +(\"pre-trained model is like\")", "machine learning +(\"pre-trained model is similar\")", "machine learning +(\"just as pre-trained model\")", "machine learning +(\"pre-trained model can be thought of as\")", "machine learning +(\"pre-trained model can be compared to\")"]}