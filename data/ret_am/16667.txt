{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Text Classification Using <b>Scikit-learn</b>, <b>PyTorch</b>, and TensorFlow | by ...", "url": "https://medium.com/swlh/text-classification-using-scikit-learn-pytorch-and-tensorflow-a3350808f9f7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/text-classification-using-<b>scikit-learn</b>-<b>pytorch</b>-and-tensorflow...", "snippet": "<b>Rosetta</b> <b>Stone</b>. Text Classification Using <b>Scikit-learn</b>, <b>PyTorch</b>, and TensorFlow . Text classification has been widely used in real-world business processes <b>like</b> email spam detection, support ticket ...", "dateLastCrawled": "2022-01-26T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(<b>Machine</b>) <b>Learning</b> log.", "url": "https://adamoudad.github.io/posts/keras_torch_comparison/sentiment_classification/", "isFamilyFriendly": true, "displayUrl": "https://adamoudad.github.io/posts/keras_torch_comparison/<b>sentiment_classification</b>", "snippet": "Yet both frameworks are meant to do the same, that is training deep neural networks. The number of resources of &quot;<b>rosetta</b> <b>stone</b>&quot; style tutorials is very limited on internet, especially resources demonstrating practical examples, so I hope this will help demistifying the differences and similarities between the two frameworks. Now let&#39;s get started! Dataset of IMDB movie reviews We will use IMDB dataset, a popular toy dataset in <b>machine</b> <b>learning</b>, which consists of movie reviews from the IMDB ...", "dateLastCrawled": "2022-01-21T03:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "8.pdf - SE4050 \\u2013 Deep <b>Learning</b> Introduction to NLP Natural ...", "url": "https://www.coursehero.com/file/120993404/8pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/120993404/8pdf", "snippet": "\u2022 To load a pre-trained <b>word</b> <b>embedding</b> model. 3. SE4050 | Deep <b>Learning</b> | Introduction to DL | Dharshana Kasthurirathna <b>Embedding</b> Layer - Arguments \u2022 <b>Embedding</b> layer is the first hidden layer of the network. \u2022 There are 3 arguments to be defined: \u2022 input_dim: size of the vocabulary. If the data is integer encoded to values from 0-6, then the vocabulary size will be 7 words. \u2022 output_dim: size of the vector space in which words will be embedded. Eg. 32, 64, 128, etc. \u2022 input ...", "dateLastCrawled": "2022-01-14T14:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "[1710.04087] <b>Word Translation Without Parallel Data</b> - arXiv", "url": "https://arxiv.org/abs/1710.04087", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1710.04087", "snippet": "In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual <b>word</b> <b>embedding</b> spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, <b>like</b> English-Russian or English-Chinese. We finally describe ...", "dateLastCrawled": "2022-01-12T11:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Word translation without parallel data</b> | OpenReview", "url": "https://openreview.net/forum?id=H196sainb", "isFamilyFriendly": true, "displayUrl": "https://openreview.net/forum?id=H196sainb", "snippet": "In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual <b>word</b> <b>embedding</b> spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, <b>like</b> English-Russian or English-Chinese. We finally describe ...", "dateLastCrawled": "2022-01-29T22:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Physics, Topology, Logic and Computation: a <b>Rosetta</b> <b>Stone</b> | The n ...", "url": "https://classes.golem.ph.utexas.edu/category/2008/03/physics_topology_logic_and_com.html", "isFamilyFriendly": true, "displayUrl": "https://classes.golem.ph.utexas.edu/category/2008/03/physics_topology_logic_and_com.html", "snippet": "* <b>Rosetta</b> <b>Stone</b> is a very good metaphor for this approach. However, categorical analysis of the situation shows: the <b>Rosetta</b> <b>Stone</b> contains a description of the same thing in different languages, while the categorical approach describes different things in the same language. Consequently, these situations are dual. Thus, in terms of category theory, you are creating/describing a co-<b>Rosetta</b> <b>Stone</b>.", "dateLastCrawled": "2022-01-12T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "project/ai.md at main \u00b7 earthspecies/project \u00b7 <b>GitHub</b>", "url": "https://github.com/earthspecies/project/blob/main/roadmaps/ai.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>earthspecies/project</b>/blob/main/roadmaps/ai.md", "snippet": "This mapping of the words in a language to a geometric structure is known as a &#39;<b>word</b> <b>embedding</b>\u2019. An example of a geometric representation, an \u2018<b>embedding</b>,\u2019 of the top 10,000 most spoken words in English. While each <b>word</b> is actually represented by a point in hundreds of dimensions, here it is projected down to three for visualization. The hundreds of axes are semantically meaningful but hard to interpret. The ability to represent words in a physical space sparked an explosion in the ...", "dateLastCrawled": "2022-01-15T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>PuzzLing Machines: A Challenge on Learning From Small</b> Data | DeepAI", "url": "https://deepai.org/publication/puzzling-machines-a-challenge-on-learning-from-small-data", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>puzzling-machines-a-challenge-on-learning-from-small</b>-data", "snippet": "To expose this problem in a new light, we introduce a <b>challenge on learning from small</b> data, PuzzLing Machines, which consists of <b>Rosetta</b> <b>Stone</b> puzzles from Linguistic Olympiads for high school students. These puzzles are carefully designed to contain only the minimal amount of parallel text necessary to deduce the form of unseen expressions. Solving them does not require external information (e.g., knowledge bases, visual signals) or linguistic expertise, but meta-linguistic awareness and ...", "dateLastCrawled": "2022-01-23T03:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "6_SMT.pdf - <b>CSC401\\/2511 \\u2013 Spring 2021</b> 1 The <b>Rosetta</b> <b>Stone</b> \\u2022 ...", "url": "https://www.coursehero.com/file/89199469/6-SMTpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/89199469/6-SMTpdf", "snippet": "View 6_SMT.pdf from FINA 401 at Centennial College. CSC401/2511 \u2013 Spring 2021 1 The <b>Rosetta</b> <b>Stone</b> \u2022 The <b>Rosetta</b> <b>Stone</b> dates from 196 BCE. \u2022 It was re-discovered by French soldiers", "dateLastCrawled": "2022-01-23T21:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "ling | <b>The Physics of Language</b>", "url": "https://quasiphysics.wordpress.com/tag/ling/", "isFamilyFriendly": true, "displayUrl": "https://quasiphysics.<b>word</b>press.com/tag/ling", "snippet": "The <b>learning</b> of new words <b>is like</b> the duplication of genes during reproduction. <b>Word</b> changes in the new generation are <b>like</b> gene mutations. The use of a <b>word</b> in an expression <b>is like</b> the expression of a gene in a biological function. Words are communal: they never act alone, but rather in concert with other words to form meaningful expressions. This <b>is like</b> the simultaneous expression of multiple genes to perform a single function. Words are subject to selection <b>like</b> the natural selection of ...", "dateLastCrawled": "2022-01-18T00:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Text Classification Using <b>Scikit-learn</b>, <b>PyTorch</b>, and TensorFlow | by ...", "url": "https://medium.com/swlh/text-classification-using-scikit-learn-pytorch-and-tensorflow-a3350808f9f7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/text-classification-using-<b>scikit-learn</b>-<b>pytorch</b>-and-tensorflow...", "snippet": "<b>Rosetta</b> <b>Stone</b>. Text Classification Using <b>Scikit-learn</b>, <b>PyTorch</b>, and TensorFlow . Text classification has been widely used in real-world business processes like email spam detection, support ticket ...", "dateLastCrawled": "2022-01-26T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "APPLIED MEDICAL CODE MAPPING WITH CHARACTER-BASED DEEP <b>LEARNING</b> MODELS ...", "url": "https://typo.uni-konstanz.de/naloma20/wp-content/uploads/2020/07/SrihasamLangton.pdf", "isFamilyFriendly": true, "displayUrl": "https://typo.uni-konstanz.de/naloma20/wp-content/uploads/2020/07/SrihasamLangton.pdf", "snippet": "<b>Rosetta</b> <b>Stone</b>. STANDARD MEDICAL CODES \u2022Medical codes are used to record, analyze, and communicate patient information for diagnosis, treatment, billing and more \u2022Healthcare providers often use custom codes that are not interoperable with other organizations\u2019 systems \u2022Mapping from custom codes to standard codes is necessary for information exchange and analytics. MULTIPLE USE CASES REQUIRE CODE MAPPINGS Code Set Description Use Case SNOMED Clinical terminology polyarchy used primarily ...", "dateLastCrawled": "2021-08-30T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Rui Wang and Hai Zhao</b> - EACL 2021", "url": "https://2021.eacl.org/downloads/tutorials/Advances-in-UNMT.pdf", "isFamilyFriendly": true, "displayUrl": "https://2021.eacl.org/downloads/tutorials/Advances-in-UNMT.pdf", "snippet": "<b>Rosetta</b> <b>Stone</b> (196 BC) Ancient Egyptian (hieroglyphic) Ancient Egyptian (Demotic) Ancient Greek MT is a typical text generation task. \u00be x: source sentence; y: target sentence. \u00be maximum likelihood estimation (MLE): MT has a standard evaluation metric: \u00be n-gram: contiguous sequence of n words. MT: from ML aspect He goes to school &lt;EOS&gt; |c _ / C Page 8 |c _ / C &lt;EOS&gt; \u00db / \u00db / Menu Page 9 About Us Towards Unsupervised Neural <b>Machine</b> Translation (UNMT) \u00be Background of <b>Machine</b> Translation ...", "dateLastCrawled": "2022-02-02T08:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(<b>Machine</b>) <b>Learning</b> log.", "url": "https://adamoudad.github.io/posts/keras_torch_comparison/sentiment_classification/", "isFamilyFriendly": true, "displayUrl": "https://adamoudad.github.io/posts/keras_torch_comparison/<b>sentiment_classification</b>", "snippet": "Yet both frameworks are meant to do the same, that is training deep neural networks. The number of resources of &quot;<b>rosetta</b> <b>stone</b>&quot; style tutorials is very limited on internet, especially resources demonstrating practical examples, so I hope this will help demistifying the differences and similarities between the two frameworks. Now let&#39;s get started! Dataset of IMDB movie reviews We will use IMDB dataset, a popular toy dataset in <b>machine</b> <b>learning</b>, which consists of movie reviews from the IMDB ...", "dateLastCrawled": "2022-01-21T03:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "An <b>Iterative Closest Point Method for Unsupervised Word Translation</b> ...", "url": "https://deepai.org/publication/an-iterative-closest-point-method-for-unsupervised-word-translation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/an-<b>iterative-closest-point-method-for-unsupervised</b>-<b>word</b>...", "snippet": "An early example of this approach is the translation achieved using the <b>Rosetta</b> <b>stone</b>. However, if most languages share the same expressive power and are used to describe <b>similar</b> human experiences across cultures, they should share <b>similar</b> statistical properties. Exploiting statistical properties of letters has been successfully employed by substitution crypto-analysis since at least the 9th century. It seems likely that one can learn to map between languages statistically, by considering ...", "dateLastCrawled": "2021-12-18T22:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Restoring Eroded Text in Plate Inscriptions\u2019 Images using Deep <b>Learning</b> ...", "url": "https://halzouma.medium.com/restoring-eroded-text-in-plate-inscriptions-images-using-deep-learning-4d0e7b6d53e7", "isFamilyFriendly": true, "displayUrl": "https://halzouma.medium.com/restoring-eroded-text-in-plate-inscriptions-images-using...", "snippet": "Also, the <b>word</b> <b>embedding</b> list for BERT has 30,000 tokens, and the maximum length of input sentence should be 512 tokens. BERT has two main unsupervised pre-training tasks. Masked Language Model is the first one and it is used to predict a masked (missing) <b>word</b> in a sentence through deep bi- directional architecture. The second task is Next Sentence Prediction. It is based on two input sentences, and the model will predict whether one sentence is immediately after another one. Depending on ...", "dateLastCrawled": "2022-01-17T17:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>GitHub</b> - <b>ilkarman/DeepLearningFrameworks</b>: Demo of running NNs across ...", "url": "https://github.com/ilkarman/DeepLearningFrameworks", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ilkarman/Deep<b>Learning</b>Frameworks", "snippet": "Create a <b>Rosetta</b> <b>Stone</b> of deep-<b>learning</b> frameworks to allow data-scientists to easily leverage their expertise from one framework to another; Optimised GPU code with using the most up-to-date highest-level APIs. Common setup for comparisons across GPUs (potentially CUDA versions and precision) Common setup for comparisons across languages (Python, Julia, R) Possibility to verify expected performance of own installation; Collaboration between different open-source communities; The notebooks ...", "dateLastCrawled": "2022-02-01T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ling | <b>The Physics of Language</b>", "url": "https://quasiphysics.wordpress.com/tag/ling/", "isFamilyFriendly": true, "displayUrl": "https://quasiphysics.<b>word</b>press.com/tag/ling", "snippet": "In comparison to <b>Rosetta</b> <b>Stone</b>, Pimsleur has three major advantages: (1) your pronunciation will be better, because you have no script to misguide you, (2) you are forced to be more creative (i.e., generative), because of the \u201canticipation\u201d aspect of Pimsleur\u2019s method, (3) you learn more function words that are needed for everyday communication, and (4) because of the audio-only format, it may be more convenient.", "dateLastCrawled": "2022-01-18T00:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "6_SMT.pdf - <b>CSC401\\/2511 \\u2013 Spring 2021</b> 1 The <b>Rosetta</b> <b>Stone</b> \\u2022 ...", "url": "https://www.coursehero.com/file/89199469/6-SMTpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/89199469/6-SMTpdf", "snippet": "View 6_SMT.pdf from FINA 401 at Centennial College. CSC401/2511 \u2013 Spring 2021 1 The <b>Rosetta</b> <b>Stone</b> \u2022 The <b>Rosetta</b> <b>Stone</b> dates from 196 BCE. \u2022 It was re-discovered by French soldiers", "dateLastCrawled": "2022-01-23T21:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Physics, Topology, Logic and Computation</b>: a <b>Rosetta</b> <b>Stone</b> | The n ...", "url": "https://golem.ph.utexas.edu/category/2008/03/physics_topology_logic_and_com.html", "isFamilyFriendly": true, "displayUrl": "https://golem.ph.utexas.edu/category/2008/03/physics_topology_logic_and_com.html", "snippet": "* <b>Rosetta</b> <b>Stone</b> is a very good metaphor for this approach. However, categorical analysis of the situation shows: the <b>Rosetta</b> <b>Stone</b> contains a description of the same thing in different languages, while the categorical approach describes different things in the same language. Consequently, these situations are dual. Thus, in terms of category theory, you are creating/describing a co-<b>Rosetta</b> <b>Stone</b>.", "dateLastCrawled": "2022-01-27T23:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Could We Chat With Whales? | Innovation | Smithsonian Magazine", "url": "https://www.smithsonianmag.com/innovation/could-we-chat-with-whales-180978956/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.smithsonianmag.com</b>/innovation/could-we-chat-with-whales-180978956", "snippet": "<b>Learning</b> an unknown language is easier if there is something like the famous <b>Rosetta</b> <b>Stone</b>. This stele, discovered in 1799, contains the same text in three languages and was the key to deciphering ...", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Physics, Topology, Logic and Computation: a <b>Rosetta</b> <b>Stone</b> | The n ...", "url": "https://classes.golem.ph.utexas.edu/category/2008/03/physics_topology_logic_and_com.html", "isFamilyFriendly": true, "displayUrl": "https://classes.golem.ph.utexas.edu/category/2008/03/physics_topology_logic_and_com.html", "snippet": "A prefix-free Turing <b>machine</b> <b>can</b> be considered as a pair of communicating systems: the listening end will wait forever until it gets enough bits for a code <b>word</b> and then will stop reading, while the sending end will wait forever until all the bits it sends have been read. So unless the sender sends exactly one code <b>word</b>, the message (program) is invalid and the computer goes into an infinite loop.", "dateLastCrawled": "2022-01-12T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 2, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Text segmentation</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Text_segmentation", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Text_segmentation</b>", "snippet": "<b>Text segmentation</b> is the process of dividing written text into meaningful units, such as words, sentences, or topics.The term applies both to mental processes used by humans when reading text, and to artificial processes implemented in computers, which are the subject of natural language processing.The problem is non-trivial, because while some written languages have explicit <b>word</b> boundary markers, such as the <b>word</b> spaces of written English and the distinctive initial, medial and final ...", "dateLastCrawled": "2022-01-27T12:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>Transdisciplinary Review of Deep Learning Research and Its Relevance</b> ...", "url": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2018WR022643", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2018WR022643", "snippet": "After a <b>machine</b> <b>learning</b> algorithm is trained, it <b>can</b> be used to make inference, meaning forward runs that make a prediction when given new instances. When there are multiple prediction targets, for example, simultaneously predicting groundwater level and soil moisture, the network is said to do multitask <b>learning</b>. It is worth mentioning that while deep networks are also ANNs, the term ANN now appears to be more often reserved for nondeep networks, and such meaning is used in this paper.", "dateLastCrawled": "2022-02-01T02:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Exploring wild west of natural language generation \u2014 from <b>n-gram</b> and ...", "url": "https://towardsdatascience.com/exploring-wild-west-of-natural-language-generation-from-n-gram-and-rnns-to-seq2seq-2e816edd89c6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/exploring-wild-west-of-natural-language-generation-from...", "snippet": "The <b>Rosetta</b> <b>Stone</b>: First parallel language dataset. The architecture of Seq2Seq is a single neural network model comprised of two RNNs: An encoder: Creates a fixed-length encoding (a vector of real numbers) that encapsulates information about the input. In <b>machine</b> translation, the encoder extracts all of the pertinent information from the source sentence to produce an encoding. A decoder (essentially a conditional LM): A language model that generates the target sequence conditioned with the ...", "dateLastCrawled": "2022-01-25T09:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Iryna Gurevych</b> - ACL Anthology", "url": "https://aclanthology.org/people/i/iryna-gurevych/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/people/i/<b>iryna-gurevych</b>", "snippet": "To expose this problem in a new light, we introduce a challenge on <b>learning</b> from small data, PuzzLing Machines, which consists of <b>Rosetta</b> <b>Stone</b> puzzles from Linguistic Olympiads for high school students. These puzzles are carefully designed to contain only the minimal amount of parallel text necessary to deduce the form of unseen expressions. Solving them does not require external information (e.g., knowledge bases, visual signals) or linguistic expertise, but meta-linguistic awareness and ...", "dateLastCrawled": "2022-01-05T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Annual Meeting of <b>the Association for Computational Linguistics (2020</b> ...", "url": "https://aclanthology.org/events/acl-2020/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/events/acl-2020", "snippet": "To expose this problem in a new light, we introduce a challenge on <b>learning</b> from small data, PuzzLing Machines, which consists of <b>Rosetta</b> <b>Stone</b> puzzles from Linguistic Olympiads for high school students. These puzzles are carefully designed to contain only the minimal amount of parallel text necessary to deduce the form of unseen expressions. Solving them does not require external information (e.g., knowledge bases, visual signals) or linguistic expertise, but meta-linguistic awareness and ...", "dateLastCrawled": "2022-01-25T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Someday, We Might Really Be Able to Talk to Whales - The Atlantic", "url": "https://www.theatlantic.com/science/archive/2021/10/someday-we-might-really-be-able-talk-whales/620552/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.theatlantic.com</b>/science/archive/2021/10/someday-we-might-really-be-able...", "snippet": "<b>Learning</b> an unknown language is easier with something like the famous <b>Rosetta</b> <b>Stone</b>. This stele, discovered in 1799, contains the same text in three languages and was the key to deciphering ...", "dateLastCrawled": "2022-02-01T08:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Are we on the verge of chatting with whales? - The Round Up", "url": "https://www.tapatalk.com/groups/thetreadmill/are-we-on-the-verge-of-chatting-with-whales-t30510.html", "isFamilyFriendly": true, "displayUrl": "https://www.tapatalk.com/groups/thetreadmill/are-we-on-the-verge-of-chatting-with...", "snippet": "<b>Learning</b> an unknown language is easier if there is something like the famous <b>Rosetta</b> <b>Stone</b>. This stele, discovered in 1799, contains the same text in three languages and was the key to deciphering Egyptian hieroglyphics. Of course, there is no such thing for the animal kingdom. We have neither a human-whale dictionary nor a book with grammatical rules of the sperm whale language. But there are ways around that. Obviously, children learn their native language without these tools, just by ...", "dateLastCrawled": "2021-12-01T18:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Most Controversial Saturday Night Live Scenes | <b>ScreenRant</b>", "url": "https://screenrant.com/saturday-night-live-most-controversial-sketches-inappropriate/", "isFamilyFriendly": true, "displayUrl": "https://<b>screenrant.com</b>/saturday-night-live-most-controversial-sketches-inappropriate", "snippet": "10 <b>Rosetta</b> <b>Stone</b>: Thai \u201c<b>Rosetta</b> <b>Stone</b>: Thai\u201d starts as a fairly straight take on a <b>Rosetta</b> <b>Stone</b> ad, as people talk about why they\u2019re using the product to learn a new language, such as trading recipes with foreign relatives or communicating better with co-workers. Things take a turn when Bill Hader\u2019s creepy character says he\u2019s <b>learning</b> Thai so he <b>can</b> go to Thailand to \u201c do a thing.\u201d What follows is a deeply uncomfortable line of gross men who are clearly <b>learning</b> Thai so that ...", "dateLastCrawled": "2022-01-29T09:25:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Graph representation <b>learning</b> in bioinformatics: trends, methods and ...", "url": "https://academic.oup.com/bib/article-abstract/23/1/bbab340/6361044", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/bib/article-abstract/23/1/bbab340/6361044", "snippet": "Graph <b>embedding</b> methods generate node representations that <b>can</b> be combined with <b>machine</b> <b>learning</b> models to preform downstream tasks, whereas graph neural networks fuse graph topology and attributes to perform end-to-end graph tasks. Figure 2. Open in new tab Download slide. Comparison of graph <b>embedding</b> methods and graph neural networks. Graph <b>embedding</b> methods generate node representations that <b>can</b> be combined with <b>machine</b> <b>learning</b> models to preform downstream tasks, whereas graph neural ...", "dateLastCrawled": "2022-01-23T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>PuzzLing Machines: A Challenge on Learning From Small</b> Data | DeepAI", "url": "https://deepai.org/publication/puzzling-machines-a-challenge-on-learning-from-small-data", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>puzzling-machines-a-challenge-on-learning-from-small</b>-data", "snippet": "To expose this problem in a new light, we introduce a <b>challenge on learning from small</b> data, PuzzLing Machines, which consists of <b>Rosetta</b> <b>Stone</b> puzzles from Linguistic Olympiads for high school students. These puzzles are carefully designed to contain only the minimal amount of parallel text necessary to deduce the form of unseen expressions. Solving them does not require external information (e.g., knowledge bases, visual signals) or linguistic expertise, but meta-linguistic awareness and ...", "dateLastCrawled": "2022-01-23T03:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>GitHub</b> - <b>ilkarman/DeepLearningFrameworks</b>: Demo of running NNs across ...", "url": "https://github.com/ilkarman/DeepLearningFrameworks", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ilkarman/Deep<b>Learning</b>Frameworks", "snippet": "Create a <b>Rosetta</b> <b>Stone</b> of deep-<b>learning</b> frameworks to allow data-scientists to easily leverage their expertise from one framework to another; Optimised GPU code with using the most up-to-date highest-level APIs. Common setup for comparisons across GPUs (potentially CUDA versions and precision) Common setup for comparisons across languages (Python, Julia, R) Possibility to verify expected performance of own installation; Collaboration between different open-source communities; The notebooks ...", "dateLastCrawled": "2022-02-01T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Improving mispronunciation detection using adaptive frequency scale ...", "url": "https://www.sciencedirect.com/science/article/abs/pii/S0045790612002431", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/abs/pii/S0045790612002431", "snippet": "Software like <b>Rosetta</b> <b>Stone</b> and TellMeMore, <b>can</b> help address instructor access limitations by providing learners with visual aids such as waveform displays, plots of pitch contours, and spectrograms. However, all fall short of having an instructor point out mispronunciations and having the student repeat the utterances until he or she pronounces them correctly. The challenge for a DSP algorithm is attempting to recognize mispronunciations and provide feedback to the learners, just as a ...", "dateLastCrawled": "2022-01-28T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Vision as an Interlingua: <b>Learning</b> Multilingual Semantic ...", "url": "https://www.researchgate.net/publication/327808667_Vision_as_an_Interlingua_Learning_Multilingual_Semantic_Embeddings_of_Untranscribed_Speech", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/327808667_Vision_as_an_Interlingua_<b>Learning</b>...", "snippet": "We also <b>compared</b> our results to the adaptor grammar trained on force-aligned phones and another image-to-audio <b>word</b> discovery system, DAVENet [13] trained on the much larger Places 400k dataset ...", "dateLastCrawled": "2021-12-07T08:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Ahmed Abdelali</b> - ACL Anthology", "url": "https://aclanthology.org/people/a/ahmed-abdelali/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/people/a/<b>ahmed-abdelali</b>", "snippet": "For evaluation, we <b>compared</b> different recurrent neural network (RNN) <b>word</b> embeddings based baseline models, namely: LSTM, BI-LSTM, GRU and BI-GRU, with a transformer-based model. Our new transfer-<b>learning</b> model has obtained an accuracy up to 98%. To the best of our knowledge, this work is the first study where ARABERT and GPT2 were combined to detect and classify the Arabic auto-generated texts.", "dateLastCrawled": "2021-12-09T09:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Iryna Gurevych</b> - ACL Anthology", "url": "https://aclanthology.org/people/i/iryna-gurevych/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/people/i/<b>iryna-gurevych</b>", "snippet": "To expose this problem in a new light, we introduce a challenge on <b>learning</b> from small data, PuzzLing Machines, which consists of <b>Rosetta</b> <b>Stone</b> puzzles from Linguistic Olympiads for high school students. These puzzles are carefully designed to contain only the minimal amount of parallel text necessary to deduce the form of unseen expressions. Solving them does not require external information (e.g., knowledge bases, visual signals) or linguistic expertise, but meta-linguistic awareness and ...", "dateLastCrawled": "2022-01-05T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "XNMT: <b>The eXtensible Neural Machine Translation Toolkit</b> | DeepAI", "url": "https://deepai.org/publication/xnmt-the-extensible-neural-machine-translation-toolkit", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/xnmt-<b>the-extensible-neural-machine-translation-toolkit</b>", "snippet": "This paper describes XNMT, <b>the eXtensible Neural Machine Translation toolkit</b>. XNMT distin- guishes itself from other open-source NMT toolkits by its focus on modular code design, with the purpose of enabling fast iteration in research and replicable, reliable results. In this paper we describe the design of XNMT and its experiment configuration system, and demonstrate its utility on the tasks of <b>machine</b> translation, speech recognition, and multi-tasked <b>machine</b> translation/parsing.", "dateLastCrawled": "2021-12-27T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Information | Free Full-Text | Multi-Task <b>Learning</b> for Sentiment ...", "url": "https://www.mdpi.com/2078-2489/12/5/207/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2078-2489/12/5/207/htm", "snippet": "In the era of big data, multi-task <b>learning</b> has become one of the crucial technologies for sentiment analysis and classification. Most of the existing multi-task <b>learning</b> models for sentiment analysis are developed based on the soft-sharing mechanism that has less interference between different tasks than the hard-sharing mechanism. However, there are also fewer essential features that the model <b>can</b> extract with the soft-sharing method, resulting in unsatisfactory classification performance.", "dateLastCrawled": "2021-10-23T11:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "German <b>Word</b> For Receipt", "url": "https://groups.google.com/g/yadvx6w0w/c/1CvuIHCTDZg", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/yadvx6w0w/c/1CvuIHCTDZg", "snippet": "Such information extraction facility that sounds associated terms in advance ten most common words inside and <b>word</b>, keep it <b>can</b> a compound <b>word</b> for creating complex compound nouns. You donate your standard reversal gl dates in receipt german <b>word</b> for too long for working properly. Vienna bronzes are bronze sculptures made provide a Viennese handcraft tradition that incorporates artistic finishes. <b>Learning</b> a new language may take at different time depending on many factors like this prior ...", "dateLastCrawled": "2022-01-24T00:45:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond king - man ...", "url": "https://aclanthology.org/C16-1332.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/C16-1332.pdf", "snippet": "<b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond King - Man + Woman = Queen Aleksandr Drozd y, Anna Gladkova z, Satoshi Matsuoka y yTokyo Institute of Technology, Meguro-ku, Tokyo 152-8550, Japan alex@smg.is.titech.ac.jp, matsu@is.titech.ac.jp z The University of Tokyo, Meguro-ku, Tokyo 153-8902 Japan gladkova@phiz.c.u-tokyo.ac.jp Abstract Solving <b>word</b> analogies became one of the most popular benchmarks for <b>word</b> embeddings on the assumption that linear relations between <b>word</b> pairs ...", "dateLastCrawled": "2022-01-20T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond king - man ...", "url": "https://aclanthology.org/C16-1332/", "isFamilyFriendly": true, "displayUrl": "https://acl<b>anthology</b>.org/C16-1332", "snippet": "\ufeff%0 Conference Proceedings %T <b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond king - man + woman = queen %A Drozd, Aleksandr %A Gladkova, Anna %A Matsuoka, Satoshi %S Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers %D 2016 %8 dec %I The COLING 2016 Organizing Committee %C Osaka, Japan %F drozd-etal-2016-<b>word</b> %X Solving <b>word</b> analogies became one of the most popular benchmarks for <b>word</b> embeddings on the assumption that ...", "dateLastCrawled": "2022-01-17T09:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond King ...", "url": "https://www.researchgate.net/publication/311843169_Word_Embeddings_Analogies_and_Machine_Learning_Beyond_King_-_Man_Woman_Queen", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/311843169_<b>Word</b>_<b>Embeddings</b>_Analogies_and...", "snippet": "<b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond King - Man+ Woman= Queen December 2016 Conference: Proceedings of COLING 2016, the 26th International Conference on Computational ...", "dateLastCrawled": "2021-11-25T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Finding the <b>Word</b> <b>Analogy</b> from given words using Word2Vec embeddings ...", "url": "https://www.geeksforgeeks.org/finding-the-word-analogy-from-given-words-using-word2vec-embeddings/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/finding-the-<b>word</b>-<b>analogy</b>-from-given-<b>words</b>-using-<b>word</b>2vec...", "snippet": "What if we can use a <b>Machine</b> <b>Learning</b> algorithm to automate this task of finding the <b>word</b> <b>analogy</b>. In ... Overview of <b>Word</b> <b>Embedding</b> using Embeddings from Language Models (ELMo) 16, Mar 21. <b>Word</b> Embeddings in NLP. 11, Oct 20. Implement your own word2vec(skip-gram) model in Python. 18, Jan 19. Scraping And Finding Ordered Words In A Dictionary using Python. 23, Jul 17 . Python - Replace all words except the given <b>word</b>. 25, Sep 20. Python | Finding &#39;n&#39; Character Words in a Text File. 15, Oct ...", "dateLastCrawled": "2022-01-26T14:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Word Embeddings in NLP - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/word-embeddings-in-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>word</b>-<b>embeddings</b>-in-nlp", "snippet": "<b>Word</b> Embeddings are a method of extracting features out of text so that we can input those features into a <b>machine</b> <b>learning</b> model to work with text data. They try to preserve syntactical and semantic information. The methods such as Bag of Words(BOW), CountVectorizer and TFIDF rely on the <b>word</b> count in a sentence but do not save any syntactical or semantic information. In these algorithms, the size of the vector is the number of elements in the vocabulary. We can get a sparse matrix if most ...", "dateLastCrawled": "2022-01-30T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "GitHub - jungsoh/<b>word</b>-embeddings-<b>word</b>-<b>analogy</b>-by-document-similarity ...", "url": "https://github.com/jungsoh/word-embeddings-word-analogy-by-document-similarity", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/jungsoh/<b>word</b>-<b>embeddings</b>-<b>word</b>-<b>analogy</b>-by-document-similarity", "snippet": "An example of a <b>word</b> <b>analogy</b> problem is to fill in the blank: Man is to Woman as King is to _____`. Because <b>word</b> embeddings are very computationally expensive to train, most <b>machine</b> <b>learning</b> practitioners will load a pre-trained set of embeddings. We will load a collection of pre-trained embeddings and measure similarity between <b>word</b> embeddings ...", "dateLastCrawled": "2022-01-25T02:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to Solve <b>Analogies</b> with Word2Vec | by Khuyen Tran | Towards Data ...", "url": "https://towardsdatascience.com/how-to-solve-analogies-with-word2vec-6ebaf2354009", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-solve-<b>analogies</b>-with-<b>word</b>2vec-6ebaf2354009", "snippet": "To make words understood by <b>machine</b> <b>learning</b> algorithms, <b>word</b> <b>embedding</b> is used to map words into vectors of real numbers. There are various <b>word</b> <b>embedding</b> models and word2vec is one of them. In simple words, word2vec is a group of related models that are used to produce <b>word</b> embeddings. These models are trained to construct the linguistic contexts of words. Word2vec takes a large corpus of text and produces a vector space, with each unique <b>word</b> in the corpus being assigned to a ...", "dateLastCrawled": "2022-01-30T16:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Word2Vec in Gensim Explained for Creating <b>Word</b> <b>Embedding</b> Models ...", "url": "https://machinelearningknowledge.ai/word2vec-in-gensim-explained-for-creating-word-embedding-models-pretrained-and-custom/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>knowledge.ai/<b>word</b>2vec-in-gensim-explained-for-creating-<b>word</b>...", "snippet": "What is <b>Word</b> Embeddings? <b>Machine</b> <b>learning</b> and ... This is another way putting that word2vec can draw the <b>analogy</b> that if Man is to Woman then Kind is to Queen! The publicly released model of word2vec by Google consists of 300 features and the model is trained in the Google news dataset. The vocabulary size of the model is around 1.6 billion words. However, this might have taken a huge time for the model to be trained on but they have applied a method of simple subsampling approach to ...", "dateLastCrawled": "2022-02-02T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "DeepLearning <b>series: Natural Language Processing and Word Embeddings</b> ...", "url": "https://medium.com/machine-learning-bites/deeplearning-series-natural-language-processing-and-word-embeddings-70599080efc9", "isFamilyFriendly": true, "displayUrl": "https://medium.com/<b>machine</b>-<b>learning</b>-bites/deep<b>learning</b>-series-natural-language...", "snippet": "<b>Learning</b> <b>word</b> embeddings: When we implement an algorithm to learn <b>word</b> embeddings, what we end up <b>learning</b> is an <b>embedding</b> matrix. For a 300-feature <b>embedding</b> and a 10,000-<b>word</b> vocabulary, the ...", "dateLastCrawled": "2021-10-27T13:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Introduction to <b>Word Embeddings</b>. What is a <b>word</b> <b>embedding</b>? | by Hunter ...", "url": "https://towardsdatascience.com/introduction-to-word-embeddings-4cf857b12edc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-<b>word-embeddings</b>-4cf857b12edc", "snippet": "A very basic definition of a <b>word</b> <b>embedding</b> is a real number, vector representation of a <b>word</b>. Typically, these days, words with similar meaning will have vector representations that are close together in the <b>embedding</b> space (though this hasn\u2019t always been the case). When constructing a <b>word</b> <b>embedding</b> space, typically the goal is to capture some sort of relationship in that space, be it meaning, morphology, context, or some other kind of relationship. By encoding <b>word embeddings</b> in a ...", "dateLastCrawled": "2022-01-30T04:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Word Embeddings Explained. What is <b>Word Embedding</b> ? | by Ashwin Prasad ...", "url": "https://medium.com/analytics-vidhya/word-embeddings-explained-62c046f7c79e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/word-<b>embedding</b>s-explained-62c046f7c79e", "snippet": "<b>Word Embedding</b> is a technique in Natural Language Processing which is used to represent words in a Deep <b>Learning</b> environment. The main advantage of using <b>word embedding</b> is that it allows words of\u2026", "dateLastCrawled": "2022-01-24T11:15:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Survey and challenges of story generation models - A multimodal ...", "url": "https://www.sciencedirect.com/science/article/pii/S156625352030378X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S156625352030378X", "snippet": "Pang et al. used the deep Bolzmann <b>machine</b> (DBM), which is a joint density model for the visual, auditory, and textual modalities, for <b>learning</b> highly non-linear relations between low-level features across different modalities for emotional prediction. It is trained using joint representation over multimodal inputs; thus, it can handle training samples, which is absent from certain modality. It can be used for emotional prediction and retrieval on any combination of modalities.", "dateLastCrawled": "2022-01-24T04:42:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(word embedding)  is like +(machine learning Rosetta Stone)", "+(word embedding) is similar to +(machine learning Rosetta Stone)", "+(word embedding) can be thought of as +(machine learning Rosetta Stone)", "+(word embedding) can be compared to +(machine learning Rosetta Stone)", "machine learning +(word embedding AND analogy)", "machine learning +(\"word embedding is like\")", "machine learning +(\"word embedding is similar\")", "machine learning +(\"just as word embedding\")", "machine learning +(\"word embedding can be thought of as\")", "machine learning +(\"word embedding can be compared to\")"]}