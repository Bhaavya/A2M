{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Ethical Implications of Bias in Machine</b> Learning", "url": "https://www.researchgate.net/publication/323378868_Ethical_Implications_of_Bias_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323378868_<b>Ethical_Implications_of_Bias_in</b>...", "snippet": "Biases in AI and <b>machine</b> learning algorithms are. presented and analyzed through two issues. management frameworks with the aim of showing h ow. ethical problems a nd dilemmas can evolve. While ...", "dateLastCrawled": "2022-01-16T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Data <b>bias</b> is another important consideration; learn more in practices on AI and <b>fairness</b>. Understand the limitations of your dataset and model . A model trained to detect correlations should not be used to make causal inferences, or imply that it can. E.g., your model may learn that people who buy basketball shoes are taller on average, but this does not mean that a user who buys basketball shoes will become taller as a result. <b>Machine</b> learning models today are largely a reflection of the ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "CMSC 25900: <b>Ethics, Fairness, Responsibility, and Privacy in</b> Data Science", "url": "https://classes.cs.uchicago.edu/archive/2020/spring/25900-1/index.html", "isFamilyFriendly": true, "displayUrl": "https://classes.cs.uchicago.edu/archive/2020/spring/25900-1/index.html", "snippet": "This course takes a technical approach to exploring societal issues of <b>ethics, fairness, responsibility, and privacy</b> related to the collection, use, and generalization of data. The course introduces fundamental techniques related to data acquisition, data cleaning, sampling, statistical modeling, experimental design, feature engineering, and modeling with <b>machine</b> learning. It then explores the problems that arise in different ways of performing those tasks, the fairness and <b>bias</b> of <b>machine</b> ...", "dateLastCrawled": "2022-01-12T10:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "AI Ethics, Open Data, and Recommendations Fairness with ... - <b>James Le</b>", "url": "https://jameskle.com/writes/jessie-smith", "isFamilyFriendly": true, "displayUrl": "https://jameskle.com/writes/jessie-smith", "snippet": "The 48th episode of Datacast is my conversation with Jessie Smith \u2014 a Ph.D. student at The University of Colorado Boulder researching <b>machine</b> learning and AI ethics with an emphasis on algorithmic fairness and transparency. Give it a listen to hear about her foray into Computer Science Ethics, her involvement with the open data movement, her research on <b>bias</b> and fairness for recommendation systems, her public scholarship via Radical AI and SciFi For Real Life, and more.", "dateLastCrawled": "2022-01-31T08:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Linguistics 575: Ethics in NLP</b> - <b>University of Washington</b>", "url": "https://faculty.washington.edu/ebender/2019_575/", "isFamilyFriendly": true, "displayUrl": "https://<b>faculty.washington.edu</b>/ebender/2019_575", "snippet": "<b>Bias</b> in ML, and <b>teaching</b> AI. (Blog post, accessed 1/17/17) Emspak, J. (Dec 29, 2016). How <b>a machine</b> learns prejudice: Artificial intelligence picks up <b>bias</b> from human creators--not from hard, cold logic. Scientific American. Friedman, B., &amp; Nissenbaum, H. (1996). <b>Bias</b> in computer systems. ACM Transactions on Information Systems (TOIS), 14(3 ...", "dateLastCrawled": "2022-01-29T04:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Ethics of AI <b>in Education</b>: Towards a Community-Wide Framework ...", "url": "https://link.springer.com/article/10.1007/s40593-021-00239-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s40593-021-00239-1", "snippet": "While <b>Artificial Intelligence in Education</b> (AIED) research has at its core the desire to support student learning, experience from other AI domains suggest that such ethical intentions are not by themselves sufficient. There is also the need to consider explicitly issues such as fairness, accountability, transparency, <b>bias</b>, autonomy, agency, and inclusion. At a more general level, there is also a need to differentiate between doing ethical things and doing things ethically, to understand and ...", "dateLastCrawled": "2022-01-30T23:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Bot Ethics: Considering How Bots Should Behave | <b>botnerds</b>.com", "url": "http://botnerds.com/ethics-of-bots/", "isFamilyFriendly": true, "displayUrl": "<b>botnerds</b>.com/ethics-of-bots", "snippet": "4.3 Case Study 3: <b>Bias</b> in <b>Machine</b> Learning. 5.0 <b>Teaching</b> Ethics in AI Classes. 5.1 Ethical Issues. 5.2 Case Studies. 5.3 <b>Teaching</b> Resources. The paper has copious references, notes and links to external resources. It\u2019s a fantastic starting point for educators.", "dateLastCrawled": "2022-02-03T01:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>The Coded Bias within Neurotechnology</b>", "url": "http://www.theneuroethicsblog.com/2021/04/the-coded-bias-within-neurotechnology.html", "isFamilyFriendly": true, "displayUrl": "www.theneuroethicsblog.com/2021/04/<b>the-coded-bias-within-neurotechnology</b>.html", "snippet": "In 2020, director and producer Shalini Kantayya released Coded <b>Bias</b>, a documentary following leaders such as Boulamwini who are fighting for algorithmic justice in a world blatantly employing racially-biased datasets in facial recognition systems.The film premiered at Sundance Film Festival and garnered international acclaim and recognition for uncovering the harsh truth that improperly trained algorithms are being deployed to make decisions that affect the lives of individuals every day.", "dateLastCrawled": "2021-12-13T05:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>5 Ways to Apply Ethics to AI</b> - KDnuggets", "url": "https://www.kdnuggets.com/2019/12/5-ways-apply-ethics-ai.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2019/12/5-ways-apply-ethics-ai.html", "snippet": "<b>5 Ways to Apply Ethics to AI</b>. Here are six more lessons based on real life examples that I think we should all remember as people working in <b>machine</b> learning, whether you\u2019re a researcher, engineer, or a decision-maker. In a previous post, I expressed my happiness that I got to present at ML in PL in Warsaw. I had the opportunity to take a ...", "dateLastCrawled": "2022-01-26T00:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Free From <b>Stanford: Ethical and Social Issues</b> in Natural ... - KDnuggets", "url": "https://www.kdnuggets.com/2020/07/ethical-social-issues-natural-language-processing.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2020/07/ethical-social-issues-natural-language-processing.html", "snippet": "<b>Like</b> a number of other Stanford CS courses (including those mentioned above), the learning materials for this course \u2014 including a few class slides, but mostly an impressive collection of relevant academic papers (sadly, videos for this course are not publicly available) \u2014 are freely-available to anyone interested in using them. Taught by professor Dan Jurafsky, along with <b>teaching</b> assistants Peter Henderson and Hang Jiang, one can expect the following from the course (taken directly ...", "dateLastCrawled": "2022-01-31T13:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Ethical <b>Bias</b> Meaning and <b>Similar</b> Products and Services List ...", "url": "https://www.listalternatives.com/ethical-bias-meaning", "isFamilyFriendly": true, "displayUrl": "https://www.listalternatives.com/ethical-<b>bias</b>-meaning", "snippet": "<b>Bias</b> and ethical issues in <b>machine</b>-learning models [LWN.net] Visit site . <b>Bias</b> and Discrimination in AI: A Cross-Disciplinary ... best technologyandsociety.org. <b>Bias</b> and discrimination have a different ontological status: while the former may seem easy to define in terms of programmatic solutions, the latter involves a host of social and ethical issues that are challenging to resolve from a positivist framework. See more result \u203a\u203a See also : 10 Ethical Topics In Nursing , Stray Kids <b>Bias</b> ...", "dateLastCrawled": "2022-01-27T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Data <b>bias</b> is another important consideration; learn more in practices on AI and <b>fairness</b>. Understand the limitations of your dataset and model . A model trained to detect correlations should not be used to make causal inferences, or imply that it can. E.g., your model may learn that people who buy basketball shoes are taller on average, but this does not mean that a user who buys basketball shoes will become taller as a result. <b>Machine</b> learning models today are largely a reflection of the ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "CMSC 25900: <b>Ethics, Fairness, Responsibility, and Privacy in</b> Data Science", "url": "https://classes.cs.uchicago.edu/archive/2020/spring/25900-1/index.html", "isFamilyFriendly": true, "displayUrl": "https://classes.cs.uchicago.edu/archive/2020/spring/25900-1/index.html", "snippet": "This course takes a technical approach to exploring societal issues of <b>ethics, fairness, responsibility, and privacy</b> related to the collection, use, and generalization of data. The course introduces fundamental techniques related to data acquisition, data cleaning, sampling, statistical modeling, experimental design, feature engineering, and modeling with <b>machine</b> learning. It then explores the problems that arise in different ways of performing those tasks, the fairness and <b>bias</b> of <b>machine</b> ...", "dateLastCrawled": "2022-01-12T10:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Conservative AI</b> and social inequality: conceptualizing alternatives to ...", "url": "https://link.springer.com/article/10.1007/s00146-021-01153-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00146-021-01153-9", "snippet": "When authors specify forms of <b>bias</b>, these are typically differentiated by their source: human <b>bias</b>, <b>machine</b> <b>bias</b>, systemic <b>bias</b>, societal <b>bias</b>, historical <b>bias</b>, sampling <b>bias</b>, observation <b>bias</b>, and so on (for example, Shah et al. 2019a). There is considerable conceptual confusion and overlap with these terms, but they are used to distinguish, where the <b>bias</b> is supposedly \u2018coming from\u2019; whether an individual decision maker\u2019s unconscious <b>bias</b>, historically entrenched distributions, or ...", "dateLastCrawled": "2022-01-30T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Ethics of AI <b>in Education</b>: Towards a Community-Wide Framework ...", "url": "https://link.springer.com/article/10.1007/s40593-021-00239-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s40593-021-00239-1", "snippet": "While <b>Artificial Intelligence in Education</b> (AIED) research has at its core the desire to support student learning, experience from other AI domains suggest that such ethical intentions are not by themselves sufficient. There is also the need to consider explicitly issues such as fairness, accountability, transparency, <b>bias</b>, autonomy, agency, and inclusion. At a more general level, there is also a need to differentiate between doing ethical things and doing things ethically, to understand and ...", "dateLastCrawled": "2022-01-30T23:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Linguistics 575: Ethics in NLP</b> - <b>University of Washington</b>", "url": "https://faculty.washington.edu/ebender/2019_575/", "isFamilyFriendly": true, "displayUrl": "https://<b>faculty.washington.edu</b>/ebender/2019_575", "snippet": "<b>Bias</b> in ML, and <b>teaching</b> AI. (Blog post, accessed 1/17/17) Emspak, J. (Dec 29, 2016). How <b>a machine</b> learns prejudice: Artificial intelligence picks up <b>bias</b> from human creators--not from hard, cold logic. Scientific American. Friedman, B., &amp; Nissenbaum, H. (1996). <b>Bias</b> in computer systems. ACM Transactions on Information Systems (TOIS), 14(3), 330-347. Guynn, J. (Jun 10, 2016). `Three black teenagers&#39; Google search sparks outrage. USA Today. Hardt, M. (Sep 26, 2014). How big data is unfair ...", "dateLastCrawled": "2022-01-29T04:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Using Artificial Intelligence and Algorithms</b> \u2013 Explore AI Ethics", "url": "https://exploreaiethics.com/guidelines/using-artificial-intelligence-and-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://exploreaiethics.com/guidelines/<b>using-artificial-intelligence-and-algorithms</b>", "snippet": "The good news is that, while the sophistication of AI and <b>machine</b> learning technology is new, automated decision-making is not, and we at the FTC have long experience dealing with the challenges presented by the use of data and algorithms to make decisions about consumers. Over the years, the FTC has brought many cases alleging violations of the laws we enforce involving AI and automated decision-making, and have investigated numerous companies in this space. For example, the Fair Credit ...", "dateLastCrawled": "2021-12-26T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 7, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Journalism ethics and standards</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Journalism_ethics_and_standards", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Journalism_ethics_and_standards</b>", "snippet": "Journalistic ethics and standards comprise principles of ethics and good practice applicable to journalists. This subset of media ethics is known as journalism&#39;s professional &quot;code of ethics&quot; and the &quot;canons of journalism&quot;. The basic codes and canons commonly appear in statements by professional journalism associations and individual print, broadcast, and online news organizations.. So while various codes may have some differences, most share common elements including the principles of ...", "dateLastCrawled": "2022-02-03T02:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Ethics and Fairness in Assessing Learning Outcomes in Higher Education ...", "url": "https://www.researchgate.net/publication/334493079_Ethics_and_Fairness_in_Assessing_Learning_Outcomes_in_Higher_Education", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334493079_Ethics_and_Fairness_in_Assessing...", "snippet": "In <b>teaching</b> economics, <b>similar</b> <b>teaching</b> and learning methods are used worldwide (e.g., Hoyt &amp; McGoldrick, 2012), and, for example, many economics textbooks are translated into various languages ...", "dateLastCrawled": "2021-12-22T04:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Ethics | AI Strategy &amp; Policy Blog", "url": "https://aistrategyblog.com/category/ethics/", "isFamilyFriendly": true, "displayUrl": "https://aistrategyblog.com/category/ethics", "snippet": "The question is whether the untrusting of a human-<b>machine</b> trust bond <b>is similar</b> to untrusting of a human-human trust bond. Moreover, are there a difference between an inanimate <b>machine</b>, simpler human-operated automated systems and an AI-based application that humans may even anthropomorphize to various degrees. Are your trust and untrust process different for Siri or Alexa or than it is for Microsoft Clippy, assuming anyone ever really trusted that wicked steely fellow. How valid is it to ...", "dateLastCrawled": "2022-02-01T11:11:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Ethical Implications of Bias in Machine</b> Learning", "url": "https://www.researchgate.net/publication/323378868_Ethical_Implications_of_Bias_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323378868_<b>Ethical_Implications_of_Bias_in</b>...", "snippet": "Biases in AI and <b>machine</b> learning algorithms are. presented and analyzed through two issues. management frameworks with the aim of showing h ow. ethical problems a nd dilemmas <b>can</b> evolve. While ...", "dateLastCrawled": "2022-01-16T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>The Coded Bias within Neurotechnology</b>", "url": "http://www.theneuroethicsblog.com/2021/04/the-coded-bias-within-neurotechnology.html", "isFamilyFriendly": true, "displayUrl": "www.theneuroethicsblog.com/2021/04/<b>the-coded-bias-within-neurotechnology</b>.html", "snippet": "Underneath the coded gaze is a system rampant with explicit and implicit <b>bias</b>. How <b>can</b> data be so destructive, and how <b>can</b> we expect machines to be unbiased if we <b>can</b>\u2019t be? Artificial intelligence (AI) and its subset, <b>machine</b>-learning (ML), harness data to make decisions. Artificial intelligence is employed when \u201c<b>a machine</b> mimics \u2018cognitive functions,\u2019\u201d such as learning. You <b>can</b> think of ML algorithms like a feedback loop; they learn from the data that is fed to them and <b>can</b> then ...", "dateLastCrawled": "2021-12-13T05:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Ethics of AI <b>in Education</b>: Towards a Community-Wide Framework ...", "url": "https://link.springer.com/article/10.1007/s40593-021-00239-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s40593-021-00239-1", "snippet": "While <b>Artificial Intelligence in Education</b> (AIED) research has at its core the desire to support student learning, experience from other AI domains suggest that such ethical intentions are not by themselves sufficient. There is also the need to consider explicitly issues such as fairness, accountability, transparency, <b>bias</b>, autonomy, agency, and inclusion. At a more general level, there is also a need to differentiate between doing ethical things and doing things ethically, to understand and ...", "dateLastCrawled": "2022-01-30T23:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>bias</b> \u2013 paulvanderlaken.com", "url": "https://paulvanderlaken.com/tag/bias/", "isFamilyFriendly": true, "displayUrl": "https://paulvanderlaken.com/tag/<b>bias</b>", "snippet": "Tag: <b>bias</b>. Vox: Are We Automating Racism? In Glad You Asked, Vox dives deep into timely questions around the impact of systemic racism on our communities and in our daily lives. In this video, they look into the role of tech in societal discrimination. People assume that tech and data are neutral, and we have turned to tech as a way to replace biased human decision-making. But as data-driven systems become a bigger and bigger part of our lives, we see more and more cases where they fail. And ...", "dateLastCrawled": "2022-01-20T17:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Justice and Fairness - Markkula Center for Applied Ethics", "url": "https://www.scu.edu/ethics/ethics-resources/ethical-decision-making/justice-and-fairness/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.scu.edu</b>/ethics/ethics-resources/ethical-decision-making/justice-and-fairness", "snippet": "The foundations of justice <b>can</b> be traced to the notions of social stability, interdependence, and equal dignity. As the ethicist John Rawls has pointed out, the stability of a society\u2014or any group, for that matter\u2014depends upon the extent to which the members of that society feel that they are being treated justly. When some of society&#39;s members come to feel that they are subject to unequal treatment, the foundations have been laid for social unrest, disturbances, and strife. The members ...", "dateLastCrawled": "2022-02-03T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Ethics | AI Strategy &amp; Policy Blog", "url": "https://aistrategyblog.com/category/ethics/", "isFamilyFriendly": true, "displayUrl": "https://aistrategyblog.com/category/ethics", "snippet": "<b>Bias</b> and unfairness <b>can</b> be present (or introduced) at many stages of <b>a machine</b> learning process. Much of the data we use for our <b>machine</b> learning models reflect society\u2019s good, bad and ugly sides. For example, data being used to train a given algorithmic model could be biased (or unfair) either because it reflect a fundamentally biased or unfair partition of subject matter under study or because in the data preparation process the data have become biased (intentionally or un-intentionally ...", "dateLastCrawled": "2022-02-01T11:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Ethics and Psychology: <b>The Ethics of Ceding More Power To Machines</b>", "url": "https://www.ethicalpsychology.com/2018/06/the-ethics-of-ceding-more-power-to.html", "isFamilyFriendly": true, "displayUrl": "https://www.ethicalpsychology.com/2018/06/<b>the-ethics-of-ceding-more-power</b>-to.html", "snippet": "Brhmie Balaram www.theRSA.org Originally posted May 31, 2018 Here is an excerpt: This gets to the crux of people\u2019s fears about AI \u2013 there is a perception that we may be ceding too much power to AI, regardless of the reality.", "dateLastCrawled": "2022-01-11T02:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Best K-12 Resources to Teach AI Ethics", "url": "https://www.fairbytes.org/post/best-k-12-resources-to-teach-ai-ethics", "isFamilyFriendly": true, "displayUrl": "https://www.fairbytes.org/post/best-k-12-resources-to-teach-ai-ethics", "snippet": "Learn about AI, <b>machine</b> learning, training data, and <b>bias</b>, while exploring ethical issues and how AI <b>can</b> be used to address world problems. Enjoy Code.org\u2019s first step in a new journey to teach more about AI. When you use the AI for Oceans activity you are training real <b>machine</b> learning models. How Do You Create Moral Robots? By Mark Riedl. A guide to teach robot morality with media resources, worksheets, &amp; writing prompts (grades 6\u201312) In this excerpt from Science Friday, Mark Riedl ...", "dateLastCrawled": "2021-12-28T16:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Training the next generation of ethical techies</b> - Ethan Zuckerman", "url": "https://ethanzuckerman.com/2019/08/14/training-the-next-generation-of-ethical-techies/", "isFamilyFriendly": true, "displayUrl": "https://ethanzuckerman.com/2019/08/14/<b>training-the-next-generation-of-ethical-techies</b>", "snippet": "Where the heck are all of these people with real technical chops who are also deeply knowledgeable about <b>ethics/fairness</b> going to come from\u2026 since we don\u2019t train people that way in the first place.\u201d Christian goes on to point out that it\u2019s exceedingly rare for someone with PhD-level experience in <b>machine</b> learning to have a strong background in critical theory, intersectionality, gender studies and ethics. We\u2019re likely to see a string of CS PhDs lost in humanities departments and ...", "dateLastCrawled": "2021-12-21T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A call to action: a systematic review of ethical and regulatory issues ...", "url": "https://largescaleassessmentsineducation.springeropen.com/articles/10.1186/s40536-021-00115-3", "isFamilyFriendly": true, "displayUrl": "https://largescaleassessmentsineducation.springeropen.com/articles/10.1186/s40536-021...", "snippet": "Techniques originating in data mining and <b>machine</b> learning <b>can</b> provide more detailed information about student learning, and how this <b>can</b> be improved (Wong, 2017), representing an attempt to enhance the utility of assessments by adding value to interpretations of student responses. With this increasing interest in use of process data, the focus on ethical use of personal data and data protection has also increased. However, there is a lack of knowledge on how ethical and legal issues are ...", "dateLastCrawled": "2022-01-30T01:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Addressing <b>fairness</b> and inclusion in AI is an active area of research, from fostering an inclusive workforce that embodies critical and diverse knowledge, to assessing training datasets for potential sources of <b>bias</b>, to training models to remove or correct problematic biases, to evaluating <b>machine</b> learning models for disparities in performance, to continued testing of final systems for unfair outcomes. In fact, ML models <b>can</b> even be used to identify some of the conscious and unconscious ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Ethical <b>Bias</b> Meaning and Similar Products and Services List ...", "url": "https://www.listalternatives.com/ethical-bias-meaning", "isFamilyFriendly": true, "displayUrl": "https://www.listalternatives.com/ethical-<b>bias</b>-meaning", "snippet": "<b>Bias</b>. <b>Bias</b> is a prejudice toward one thing, person, or group <b>compared</b> with another. <b>Bias</b> is part of human evolutionary wiring designed to originally keep us safe and secure in unknown and harmful environments. However, while the world has evolved some of our biases - conscious or unconscious - have not, and thus <b>can</b> result in harmful ...", "dateLastCrawled": "2022-01-27T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Ethics and Fairness in Assessing Learning Outcomes in Higher Education ...", "url": "https://www.researchgate.net/publication/334493079_Ethics_and_Fairness_in_Assessing_Learning_Outcomes_in_Higher_Education", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334493079_Ethics_and_Fairness_in_Assessing...", "snippet": "Nevertheless, each of these steps <b>can</b> introduce additional <b>bias</b> to the system if not appropriately performed. Most large-scale and nationally representative education data sets suffer from a ...", "dateLastCrawled": "2021-12-22T04:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Public Artificial Intelligence</b>: A Crash Course for Politicians and ...", "url": "https://institute.global/policy/public-artificial-intelligence-crash-course-politicians-and-policy-professionals", "isFamilyFriendly": true, "displayUrl": "https://institute.global/policy/<b>public-artificial-intelligence</b>-crash-course...", "snippet": "Take responsibility for <b>ethics, fairness</b> and transparency. Algorithmic <b>bias</b> and fairness are serious concerns when it comes to deploying AI for social causes. Governments must provide further support for research in this area, help coordinate industry ethics codes, be transparent about how data are used so users understand these technologies, and help develop standard dispute-resolution procedures for citizens and businesses that need protection from AI. Start small but think big. AI <b>can</b> ...", "dateLastCrawled": "2022-02-01T01:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Ethics | AI Strategy &amp; Policy Blog", "url": "https://aistrategyblog.com/category/ethics/", "isFamilyFriendly": true, "displayUrl": "https://aistrategyblog.com/category/ethics", "snippet": "<b>Bias</b> and unfairness <b>can</b> be present (or introduced) at many stages of <b>a machine</b> learning process. Much of the data we use for our <b>machine</b> learning models reflect society\u2019s good, bad and ugly sides. For example, data being used to train a given algorithmic model could be biased (or unfair) either because it reflect a fundamentally biased or unfair partition of subject matter under study or because in the data preparation process the data have become biased (intentionally or un-intentionally ...", "dateLastCrawled": "2022-02-01T11:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>5 Ways to Apply Ethics to AI</b> - KDnuggets", "url": "https://www.kdnuggets.com/2019/12/5-ways-apply-ethics-ai.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2019/12/5-ways-apply-ethics-ai.html", "snippet": "Rachel Thomas <b>compared</b> two reactions from Facebook. One is for Myanmar, where Facebook boasted that they added \u201cdozens\u201d of content reviewers for Burmese. During the same year, they hired 1,500 content reviewers in Germany. Why is that? Because Germany threatened Facebook (and others) with a $50M fine if they didn\u2019t comply with the Hate Speech law. This is an example of how regulations <b>can</b> help, because it makes managers who are mostly focused on profit to treat risks seriously.", "dateLastCrawled": "2022-01-26T00:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>bias</b> \u2013 paulvanderlaken.com", "url": "https://paulvanderlaken.com/tag/bias/", "isFamilyFriendly": true, "displayUrl": "https://paulvanderlaken.com/tag/<b>bias</b>", "snippet": "Tag: <b>bias</b>. Vox: Are We Automating Racism? In Glad You Asked, Vox dives deep into timely questions around the impact of systemic racism on our communities and in our daily lives. In this video, they look into the role of tech in societal discrimination. People assume that tech and data are neutral, and we have turned to tech as a way to replace biased human decision-making. But as data-driven systems become a bigger and bigger part of our lives, we see more and more cases where they fail. And ...", "dateLastCrawled": "2022-01-20T17:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Justice and Fairness - Markkula Center for Applied Ethics", "url": "https://www.scu.edu/ethics/ethics-resources/ethical-decision-making/justice-and-fairness/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.scu.edu</b>/ethics/ethics-resources/ethical-decision-making/justice-and-fairness", "snippet": "The foundations of justice <b>can</b> be traced to the notions of social stability, interdependence, and equal dignity. As the ethicist John Rawls has pointed out, the stability of a society\u2014or any group, for that matter\u2014depends upon the extent to which the members of that society feel that they are being treated justly. When some of society&#39;s members come to feel that they are subject to unequal treatment, the foundations have been laid for social unrest, disturbances, and strife. The members ...", "dateLastCrawled": "2022-02-03T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 8, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Journalism ethics and standards</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Journalism_ethics_and_standards", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Journalism_ethics_and_standards</b>", "snippet": "Journalistic ethics and standards comprise principles of ethics and good practice applicable to journalists. This subset of media ethics is known as journalism&#39;s professional &quot;code of ethics&quot; and the &quot;canons of journalism&quot;. The basic codes and canons commonly appear in statements by professional journalism associations and individual print, broadcast, and online news organizations.. So while various codes may have some differences, most share common elements including the principles of ...", "dateLastCrawled": "2022-02-03T02:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A call to action: a systematic review of ethical and regulatory issues ...", "url": "https://largescaleassessmentsineducation.springeropen.com/articles/10.1186/s40536-021-00115-3", "isFamilyFriendly": true, "displayUrl": "https://largescaleassessmentsineducation.springeropen.com/articles/10.1186/s40536-021...", "snippet": "Techniques originating in data mining and <b>machine</b> learning <b>can</b> provide more detailed information about student learning, and how this <b>can</b> be improved (Wong, 2017), representing an attempt to enhance the utility of assessments by adding value to interpretations of student responses. With this increasing interest in use of process data, the focus on ethical use of personal data and data protection has also increased. However, there is a lack of knowledge on how ethical and legal issues are ...", "dateLastCrawled": "2022-01-30T01:40:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Is Bias in Machine Learning all Bad</b>? - KDnuggets", "url": "https://www.kdnuggets.com/2019/07/bias-machine-learning-bad.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2019/07/<b>bias</b>-<b>machine</b>-<b>learning</b>-bad.html", "snippet": "<b>Analogy</b> with previously learned generalizations; If a system is <b>learning</b> a collection of related concepts, or generalizations, then a possible constraint on generalizing any one of them is to consider successful generalization of others. For example, consider a task of <b>learning</b> structural descriptions of blocks-world objects, such as \u201darch\u201d, \u201dtower\u201d, etc. After <b>learning</b> several concepts, the learned descriptions may reveal that certain features are more significant for describing ...", "dateLastCrawled": "2022-01-22T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Is it really fair or did you automate it?", "url": "https://deep1401.github.io/data-ethics-2", "isFamilyFriendly": true, "displayUrl": "https://deep1401.github.io/data-ethics-2", "snippet": "<b>Machine</b> <b>learning</b> can amplify <b>bias</b>. As proposed by (De-Arteaga et al.,2019) ,it was observed that the algorithms were clearly amplifying <b>bias</b> in an already biased dataset. For example, the proportion of females in an occupation dataset who were surgeons was 14.6%.", "dateLastCrawled": "2022-01-14T15:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Data <b>bias</b> is another important consideration; learn more in practices on AI and <b>fairness</b>. Understand the limitations of your dataset and model . A model trained to detect correlations should not be used to make causal inferences, or imply that it can. E.g., your model may learn that people who buy basketball shoes are taller on average, but this does not mean that a user who buys basketball shoes will become taller as a result. <b>Machine</b> <b>learning</b> models today are largely a reflection of the ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Algorithmic injustice: a relational ethics approach", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7892355/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7892355", "snippet": "<b>Machine</b> classification and prediction are practices that act directly upon the world and result in tangible impact.64 Various companies, institutes, and governments use <b>machine</b>-<b>learning</b> systems across a variety of areas. These systems process people&#39;s behaviors, actions, and the social world at large. The <b>machine</b>-detected patterns often provide \u201canswers\u201d to fuzzy, contingent, and open-ended questions. These \u201canswers\u201d neither reveal any causal relations nor provide explanation on why ...", "dateLastCrawled": "2022-01-26T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Algorithmic injustice: a relational ethics approach</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S2666389921000155", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2666389921000155", "snippet": "<b>Machine</b> classification and prediction are practices that act directly upon the world and result in tangible impact. 64 Various companies, institutes, and governments use <b>machine</b>-<b>learning</b> systems across a variety of areas. These systems process people&#39;s behaviors, actions, and the social world at large. The <b>machine</b>-detected patterns often provide \u201canswers\u201d to fuzzy, contingent, and open-ended questions. These \u201canswers\u201d neither reveal any causal relations nor provide explanation on why ...", "dateLastCrawled": "2022-01-29T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Human-centric Approach to Fairness in AI", "url": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "isFamilyFriendly": true, "displayUrl": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "snippet": "A lot of what is discussed in the <b>machine</b> <b>learning</b> literature touches on fairness (or rather equivalence in certain outcomes) between groups, yet this narrowly constricts fairness to the notion of equality. Of course, we should think about fairness in the context of prejudiced groups, but we should also ask whether it is fair to an individual. Adding constraints in models might lead to worse outcomes for other individuals. If the decision making processs has serious consequences e.g. a fraud ...", "dateLastCrawled": "2022-02-03T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) A review of some techniques for inclusion of domain-knowledge ...", "url": "https://www.researchgate.net/publication/357983755_A_review_of_some_techniques_for_inclusion_of_domain-knowledge_into_deep_neural_networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357983755_A_review_of_some_techniques_for...", "snippet": "The <b>machine</b> <b>learning</b> system then conveys its explanations to the biologist. ... <b>ethics, fairness</b>, and explainability o ... <b>Analogy</b> Model 75 RNN. Transf orming Model. KBANN 86 MLP. Cascade-ARTMAP ...", "dateLastCrawled": "2022-01-21T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Algorithmic injustice: <b>a relational ethics approach</b>: <b>Patterns</b>", "url": "https://www.cell.com/patterns/fulltext/S2666-3899(21)00015-5", "isFamilyFriendly": true, "displayUrl": "https://www.cell.com/<b>patterns</b>/fulltext/S2666-3899(21)00015-5", "snippet": "Data science and <b>machine</b>-<b>learning</b> systems sit firmly within the rationalist tradition. The core of what <b>machine</b>-<b>learning</b> systems do can be exemplified as clustering similarities and differences, abstracting commonalities, and detecting <b>patterns</b>. <b>Machine</b>-<b>learning</b> systems \u201cwork\u201d by identifying <b>patterns</b> in vast amounts of data. Given immense, messy, and complex data, a <b>machine</b>-<b>learning</b> system can sort, classify, and cluster similarities based on seemingly shared features. Feed a neural ...", "dateLastCrawled": "2022-01-31T12:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>MATHEMATICS FOR MACHINE LEARNING</b> | g t - Academia.edu", "url": "https://www.academia.edu/41334219/MATHEMATICS_FOR_MACHINE_LEARNING", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/41334219", "snippet": "<b>MATHEMATICS FOR MACHINE LEARNING</b>. g t. Kong Yao Chee. fabio baca. book P D F services. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 37 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package ...", "dateLastCrawled": "2022-02-02T23:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Data Is the New What? Popular Metaphors &amp; Professional Ethics in ...", "url": "https://www.researchgate.net/publication/332828046_Data_Is_the_New_What_Popular_Metaphors_Professional_Ethics_in_Emerging_Data_Culture", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/332828046_Data_Is_the_New_What_Popular...", "snippet": "PDF | On Jan 1, 2019, Luke Stark and others published Data Is the New What? Popular Metaphors &amp; Professional Ethics in Emerging Data Culture | Find, read and cite all the research you need on ...", "dateLastCrawled": "2022-01-19T14:44:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bias (ethics/fairness))  is like +(teaching a machine)", "+(bias (ethics/fairness)) is similar to +(teaching a machine)", "+(bias (ethics/fairness)) can be thought of as +(teaching a machine)", "+(bias (ethics/fairness)) can be compared to +(teaching a machine)", "machine learning +(bias (ethics/fairness) AND analogy)", "machine learning +(\"bias (ethics/fairness) is like\")", "machine learning +(\"bias (ethics/fairness) is similar\")", "machine learning +(\"just as bias (ethics/fairness)\")", "machine learning +(\"bias (ethics/fairness) can be thought of as\")", "machine learning +(\"bias (ethics/fairness) can be compared to\")"]}