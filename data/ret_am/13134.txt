{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian</b> vs <b>Neural</b> Networks \u2013 Ehud Reiter&#39;s Blog", "url": "https://ehudreiter.com/2021/07/05/bayesian-vs-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://ehudreiter.com/2021/07/05/<b>bayesian</b>-vs-<b>neural</b>-<b>networks</b>", "snippet": "We have a small <b>group</b> that meets monthly to discuss this, and last week we ended up also talking about why <b>people</b> would use <b>Bayesian</b> models instead of <b>neural</b> networks, focusing on medical decision support (not NLP). Which I found very interesting and thought-provoking. One relatively obvious reason to avoid black-box <b>neural</b> models is justifiability (which relates to explanation). Ie, if I build a medical diagnosis system as a <b>Bayesian</b> model, I can explain to doctors (and regulators) exactly ...", "dateLastCrawled": "2022-02-01T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "The paper &quot;What Are <b>Bayesian</b> <b>Neural</b> <b>Network</b> Posteriors Really <b>Like</b>?&quot; by P. Izmailov, S. Vikram, M. Hoffman and A. Wilson addresses ideas to improve the predictive accuracy of <b>Bayesian</b> <b>neural</b> networks. The beginning of the abstract is: &quot;The posterior over <b>Bayesian</b> <b>neural</b> <b>network</b> (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as mean-field variational inference or ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Adaptive behavior and different thermal experiences of real <b>people</b>: A ...", "url": "https://www.sciencedirect.com/science/article/pii/S036013232100281X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S036013232100281X", "snippet": "In this study, we aim to extend the application of <b>Bayesian</b> <b>neural</b> networks (BNN) in predicting the thermal preference of a large <b>group</b> of individuals. Here we refer BNN to a <b>neural</b> <b>network</b> that is trained to fit observed data using <b>Bayesian</b> inference by considering that the <b>network</b>\u2019s parameters (i.e., its weights and biases) are random according to a prior probability distribution [ 39 ].", "dateLastCrawled": "2022-01-07T06:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Comprehensive Introduction to <b>Bayesian</b> Deep Learning - Joris Baan", "url": "https://jorisbaan.nl/2021/03/02/introduction-to-bayesian-deep-learning.html", "isFamilyFriendly": true, "displayUrl": "https://jorisbaan.nl/2021/03/02/introduction-to-<b>bayesian</b>-deep-learning.html", "snippet": "A <b>Bayesian</b> <b>Neural</b> <b>Network</b> (BNN) is simply posterior inference applied to a <b>neural</b> <b>network</b> architecture. To be precise, a prior distribution is specified for each weight and bias. Because of their huge parameter space, however, inferring the posterior is even more difficult than usual. So why do <b>Bayesian</b> DL at all? The classic answer is to obtain a realistic expression of uncertainty, or calibration. A classifier is considered calibrated if the probability (confidence) of a class prediction ...", "dateLastCrawled": "2022-02-03T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What&#39;s the likelihood in <b>Bayesian</b> <b>Neural</b> Networks? - Artificial ...", "url": "https://ai.stackexchange.com/questions/26864/whats-the-likelihood-in-bayesian-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/.../26864/whats-the-<b>like</b>lihood-in-<b>bayesian</b>-<b>neural</b>-<b>networks</b>", "snippet": "The likelihood depends on the task that you are solving, so this is similar to traditional <b>neural</b> networks (in fact, even these <b>neural</b> networks have a probabilistic/<b>Bayesian</b> interpretation!).. For binary classification, you should probably use a Bernoulli, which, in practice, corresponds to using a sigmoid with a binary cross-entropy (you can show that the minimization of the cross-entropy is equivalent to the maximization of Bernoulli p.m.f.)", "dateLastCrawled": "2022-01-17T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "[2104.14421] What Are <b>Bayesian</b> <b>Neural</b> <b>Network</b> Posteriors Really <b>Like</b> ...", "url": "https://www.reddit.com/r/MachineLearning/comments/n1w1aq/210414421_what_are_bayesian_neural_network/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/n1w1aq/210414421_what_are_<b>bayesian</b>_<b>neural</b>_<b>network</b>", "snippet": "Abstract: The posterior over <b>Bayesian</b> <b>neural</b> <b>network</b> (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as mean-field variational inference or stochastic-gradient Markov chain Monte Carlo (SGMCMC). To investigate foundational questions in <b>Bayesian</b> deep learning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern architectures. We show that (1) BNNs can ...", "dateLastCrawled": "2021-06-24T13:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bayesian</b> <b>neural</b> networks and out-of-distribution data? - Cross Validated", "url": "https://stats.stackexchange.com/questions/511864/bayesian-neural-networks-and-out-of-distribution-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/511864/<b>bayesian</b>-<b>neural</b>-<b>networks</b>-and-out-of...", "snippet": "In a <b>Bayesian</b> <b>neural</b> <b>network</b> (for classification) the posterior predictive distribution is $$ P(y=c \\mid {\\bf x}, \\mathcal D_{train}) = \\int P(y=c \\mid {\\bf x}, \\theta) p(\\theta \\mid \\mathcal D_{train}) d\\theta $$ Let&#39;s assume that we have enough training data $\\mathcal D_{train}$ such that if $\\bf x$ is quite similar to the training data the uncertainty in the posterior (predictive) prediction is low. So, we assume that in this region we have low aleatoric uncertainty and due to the amount ...", "dateLastCrawled": "2022-01-28T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "GitHub - mainkoon81/<b>Study-09-MachineLearning-D</b>: **DeepLearning** (CNN ...", "url": "https://github.com/mainkoon81/Study-09-MachineLearning-D", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/mainkoon81/<b>Study-09-MachineLearning-D</b>", "snippet": "<b>Bayesian</b> <b>Neural</b> <b>Network</b>. 10 years ago, <b>people</b> used to think that <b>Bayesian</b> methods are mostly suited for small datasets because it&#39;s computationally expensive. In the era of Big data, our <b>Bayesian</b> methods met deep learning, and <b>people</b> started to make some mixture models that has <b>neural</b> networks inside of a probabilistic model.", "dateLastCrawled": "2021-10-29T10:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep|Bayes \u2013 Summer school on Deep Learning and <b>Bayesian</b> Methods", "url": "https://deepbayes.ru/", "isFamilyFriendly": true, "displayUrl": "https://deepbayes.ru", "snippet": "You will learn modern techniques in deep learning and discover benefits of <b>Bayesian</b> approach for <b>neural</b> networks. Topics discussed during the School will help you understand modern research papers. And, of course, the School provides an excellent opportunity to meet <b>like</b>-minded <b>people</b> and form new professional connections with speakers, tutors and fellow school participants.", "dateLastCrawled": "2022-01-28T22:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Hyperparameter optimization for <b>Neural</b> Networks \u2014 NeuPy", "url": "http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html", "isFamilyFriendly": true, "displayUrl": "neupy.com/2016/12/17/hyperparameter_optimization_for_<b>neural</b>_<b>networks</b>.html", "snippet": "<b>Neural Network</b> usually involves randomization (<b>like</b> weight initialization and dropout) during the training process which influences a final score. Running <b>neural network</b> with the same parameters can lead to different scores. Which means that our best score can be just lucky output for the specific set of parameters. It can be difficult to select right hyperparameters for Gaussian Process. Gaussian Process has lots of different kernel types. In addition you can construct more complicated ...", "dateLastCrawled": "2022-02-02T18:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian</b> vs <b>Neural</b> Networks \u2013 Ehud Reiter&#39;s Blog", "url": "https://ehudreiter.com/2021/07/05/bayesian-vs-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://ehudreiter.com/2021/07/05/<b>bayesian</b>-vs-<b>neural</b>-<b>networks</b>", "snippet": "We have a small <b>group</b> that meets monthly to discuss this, and last week we ended up also talking about why <b>people</b> would use <b>Bayesian</b> models instead of <b>neural</b> networks, focusing on medical decision support (not NLP). Which I found very interesting and thought-provoking. One relatively obvious reason to avoid black-box <b>neural</b> models is justifiability (which relates to explanation). Ie, if I build a medical diagnosis system as a <b>Bayesian</b> model, I can explain to doctors (and regulators) exactly ...", "dateLastCrawled": "2022-02-01T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian</b> Fully Convolutional Networks for Brain Image Registration", "url": "https://www.hindawi.com/journals/jhe/2021/5528160/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/jhe/2021/5528160", "snippet": "Moreover, the proposed method introduces <b>group</b> normalization, which is conducive to the <b>network</b> convergence of the <b>Bayesian</b> <b>neural</b> <b>network</b>. Some representative learning-based image registration methods are compared with the proposed method on different image datasets. Experimental results show that the registration accuracy of the proposed method is better than that of the methods, and its antifolding performance is comparable to that of fast image registration and VoxelMorph. Furthermore ...", "dateLastCrawled": "2022-01-29T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian</b> <b>neural</b> networks and out-of-distribution data? - Cross Validated", "url": "https://stats.stackexchange.com/questions/511864/bayesian-neural-networks-and-out-of-distribution-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/511864/<b>bayesian</b>-<b>neural</b>-<b>networks</b>-and-out-of...", "snippet": "In a <b>Bayesian</b> <b>neural</b> <b>network</b> (for classification) the posterior predictive distribution is $$ P(y=c \\mid {\\bf x}, \\mathcal D_{train}) = \\int P(y=c \\mid {\\bf x}, \\theta) p(\\theta \\mid \\mathcal D_{train}) d\\theta $$ Let&#39;s assume that we have enough training data $\\mathcal D_{train}$ such that if $\\bf x$ is quite <b>similar</b> to the training data the uncertainty in the posterior (predictive) prediction is low. So, we assume that in this region we have low aleatoric uncertainty and due to the amount ...", "dateLastCrawled": "2022-01-28T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Adaptive behavior and different thermal experiences of real <b>people</b>: A ...", "url": "https://www.sciencedirect.com/science/article/pii/S036013232100281X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S036013232100281X", "snippet": "In this study, we aim to extend the application of <b>Bayesian</b> <b>neural</b> networks (BNN) in predicting the thermal preference of a large <b>group</b> of individuals. Here we refer BNN to a <b>neural</b> <b>network</b> that is trained to fit observed data using <b>Bayesian</b> inference by considering that the <b>network</b>\u2019s parameters (i.e., its weights and biases) are random according to a prior probability distribution [ 39 ].", "dateLastCrawled": "2022-01-07T06:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Dynamic Bayesian network modeling of</b> fMRI: A comparison of <b>group</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1053811908001195", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1053811908001195", "snippet": "<b>Bayesian</b> <b>network</b> (BN) modeling has recently been introduced as a tool for determining the dependencies between brain regions from functional-magnetic-resonance-imaging (fMRI) data. However, studies to date have yet to explore the optimum way for meaningfully combining individually determined BN models to make <b>group</b> inferences. We contrasted the results from three broad approaches: the \u201cvirtual-typical- subject\u201d (VTS) approach which pools or averages <b>group</b> data as if they are sampled from ...", "dateLastCrawled": "2021-11-27T17:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What&#39;s the likelihood in <b>Bayesian</b> <b>Neural</b> Networks? - Artificial ...", "url": "https://ai.stackexchange.com/questions/26864/whats-the-likelihood-in-bayesian-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/.../26864/whats-the-likelihood-in-<b>bayesian</b>-<b>neural</b>-<b>networks</b>", "snippet": "The likelihood depends on the task that you are solving, so this <b>is similar</b> to traditional <b>neural</b> networks (in fact, even these <b>neural</b> networks have a probabilistic/<b>Bayesian</b> interpretation!).. For binary classification, you should probably use a Bernoulli, which, in practice, corresponds to using a sigmoid with a binary cross-entropy (you can show that the minimization of the cross-entropy is equivalent to the maximization of Bernoulli p.m.f.)", "dateLastCrawled": "2022-01-17T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Comprehensive Introduction to <b>Bayesian</b> Deep Learning - Joris Baan", "url": "https://jorisbaan.nl/2021/03/02/introduction-to-bayesian-deep-learning.html", "isFamilyFriendly": true, "displayUrl": "https://jorisbaan.nl/2021/03/02/introduction-to-<b>bayesian</b>-deep-learning.html", "snippet": "A <b>Bayesian</b> <b>Neural</b> <b>Network</b> (BNN) is simply posterior inference applied to a <b>neural</b> <b>network</b> architecture. To be precise, a prior distribution is specified for each weight and bias. Because of their huge parameter space, however, inferring the posterior is even more difficult than usual. So why do <b>Bayesian</b> DL at all? The classic answer is to obtain a realistic expression of uncertainty, or calibration. A classifier is considered calibrated if the probability (confidence) of a class prediction ...", "dateLastCrawled": "2022-02-03T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Bayesian</b> <b>Neural</b> <b>Network</b> Classification of Head Movement Direction ...", "url": "https://www.researchgate.net/publication/224634487_Bayesian_Neural_Network_Classification_of_Head_Movement_Direction_using_Various_Advanced_Optimisation_Training_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/224634487_<b>Bayesian</b>_<b>Neural</b>_<b>Network</b>...", "snippet": "<b>Bayesian</b> <b>Neural</b> <b>Network</b> Classification of Head Movement <b>Direction using Various Advanced Optimisation Training Algorithms</b> March 2006 DOI: 10.1109/BIOROB.2006.1639224", "dateLastCrawled": "2021-08-09T14:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How do <b>bayesian networks, MDPs and neural networks relate</b> to each other ...", "url": "https://www.quora.com/How-do-bayesian-networks-MDPs-and-neural-networks-relate-to-each-other-How-are-they-used", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-do-<b>bayesian-networks-MDPs-and-neural-networks-relate</b>-to-each...", "snippet": "Answer: - Artificial <b>neural</b> networks ANN try to estimate the answer to a problem. For example, they can answer classification problems. The ANN will return a probability for each class. The class with the highest probability is the most probable answer. In the same way, a yes/no problem is a prob...", "dateLastCrawled": "2022-01-14T18:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[2104.14421] What Are <b>Bayesian</b> <b>Neural</b> <b>Network</b> Posteriors Really Like ...", "url": "https://www.reddit.com/r/MachineLearning/comments/n1w1aq/210414421_what_are_bayesian_neural_network/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/n1w1aq/210414421_what_are_<b>bayesian</b>_<b>neural</b>_<b>network</b>", "snippet": "Abstract: The posterior over <b>Bayesian</b> <b>neural</b> <b>network</b> (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as mean-field variational inference or stochastic-gradient Markov chain Monte Carlo (SGMCMC). To investigate foundational questions in <b>Bayesian</b> deep learning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern architectures. We show that (1) BNNs can ...", "dateLastCrawled": "2021-06-24T13:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "At first <b>thought</b>, <b>Bayesian</b> <b>neural</b> networks don&#39;t seem to make much sense. However, BNNs have two advantages over standard <b>neural</b> networks. First, the built-in variability in BNNs makes them resistant to model overfitting. Model overfitting occurs when a <b>neural</b> <b>network</b> is trained too well. Even though the trained model predicts with high accuracy on the training data, when presented with new previously unseen data, the overfitted model predicts poorly. A second advantage of <b>Bayesian</b> <b>neural</b> ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian</b> vs <b>Neural</b> Networks \u2013 Ehud Reiter&#39;s Blog", "url": "https://ehudreiter.com/2021/07/05/bayesian-vs-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://ehudreiter.com/2021/07/05/<b>bayesian</b>-vs-<b>neural</b>-<b>networks</b>", "snippet": "We have a small <b>group</b> that meets monthly to discuss this, and last week we ended up also talking about why <b>people</b> would use <b>Bayesian</b> models instead of <b>neural</b> networks, focusing on medical decision support (not NLP). Which I found very interesting and <b>thought</b>-provoking. One relatively obvious reason to avoid black-box <b>neural</b> models is justifiability (which relates to explanation). Ie, if I build a medical diagnosis system as a <b>Bayesian</b> model, I <b>can</b> explain to doctors (and regulators) exactly ...", "dateLastCrawled": "2022-02-01T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian Network - The Decision Lab</b>", "url": "https://thedecisionlab.com/reference-guide/statistics/bayesian-network/", "isFamilyFriendly": true, "displayUrl": "https://thedecisionlab.com/reference-guide/statistics/<b>bayesian-network</b>", "snippet": "Silver collected data months prior to voting on how <b>people</b> <b>thought</b> they would vote. Of course, there <b>can</b> always be discrepancies between how <b>people</b> think they will vote and how they actually vote. Luckily, that did not pose an issue for Silver, because Bayes\u2019 theorem allows shifts in hypothesis depending on new information collected. Silver started off with a \u2018nowcast\u2019, which determined the probability of the outcome of each state if voting was to happen on any given day. Various ...", "dateLastCrawled": "2022-01-30T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bayesian</b> <b>Network</b> as a Decision Tool for Predicting ALS Disease", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7912628/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7912628", "snippet": "<b>Bayesian</b> <b>network</b> has produced more successful results than other methods according to all comparison criteria for the Neurological Control <b>group</b>, as in the ALS <b>group</b>. For this <b>group</b>, the <b>Bayesian</b> <b>Network</b>\u2019s ACC value has been found as (0.902). The Kappa values of other methods indicate that the results obtained are random, while the Kappa value (0.677) was found for <b>Bayesian</b> <b>network</b>.", "dateLastCrawled": "2022-01-11T04:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Comprehensive Introduction to <b>Bayesian</b> Deep Learning - Joris Baan", "url": "https://jorisbaan.nl/2021/03/02/introduction-to-bayesian-deep-learning.html", "isFamilyFriendly": true, "displayUrl": "https://jorisbaan.nl/2021/03/02/introduction-to-<b>bayesian</b>-deep-learning.html", "snippet": "\u201cA <b>neural</b> <b>network</b> <b>can</b> represent many models that are consistent with our observations. By selecting only one, in a classical procedure, we lose uncertainty when the models disagree for a test point.\u201d Recent Approaches To (Approximate) <b>Bayesian</b> Deep Learning . A number <b>of people</b> have recently been trying to combine the advantages of a traditional <b>neural</b> <b>network</b> (e.g. computationally efficient training using SGD &amp; back propagation) with the advantages of a <b>Bayesian</b> approach (e.g ...", "dateLastCrawled": "2022-02-03T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "machine learning - What are the <b>downsides of bayesian neural networks</b> ...", "url": "https://stats.stackexchange.com/questions/311008/what-are-the-downsides-of-bayesian-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/311008", "snippet": "<b>Bayesian</b> <b>neural</b> nets (BNN) are very popular topic. With development of variational approximation it became possible to train such models much faster then with Monte Carlo sampling. BNNs allow such interesting features as natural regularisation and even uncertainty estimation. So, the question is: why haven&#39;t we still completely migrated on BNNs? I <b>can</b> assume that variational inference does not provide enough accuracy. Is it the only reason? machine-learning deep-learning <b>bayesian</b>-<b>network</b> ...", "dateLastCrawled": "2022-01-07T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Brief <b>Introduction to Graphical Models and Bayesian Networks</b>", "url": "https://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html", "snippet": "<b>Neural</b> Computation 11(2) (1999) pp.305-345 Temporal models Dynamic <b>Bayesian</b> Networks (DBNs) are directed graphical models of stochastic processes. They generalise hidden Markov models (HMMs) and linear dynamical systems (LDSs) by representing the hidden (and observed) state in terms of state variables, which <b>can</b> have complex interdependencies. The graphical structure provides an easy way to specify these conditional independencies, and hence to provide a compact parameterization of the model ...", "dateLastCrawled": "2022-02-01T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Why hasn&#39;t the <b>Bayesian network been as successful</b> as the Deep <b>Neural</b> ...", "url": "https://www.quora.com/Why-hasnt-the-Bayesian-network-been-as-successful-as-the-Deep-Neural-Network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-hasnt-the-<b>Bayesian-network-been-as-successful</b>-as-the-Deep...", "snippet": "Answer (1 of 5): Well, the definition of \u201csuccessful\u201d is important, here. <b>Bayesian</b> networks are arguably more successful than deep <b>neural</b> networks to date. They are widely applied across industries and <b>can</b> readily be used for inference, modelling, and prediction. Presumably your question is real...", "dateLastCrawled": "2022-01-15T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "machine learning - <b>Bayesian</b> Perceptron: Why to marginalize over neuron ...", "url": "https://ai.stackexchange.com/questions/26950/bayesian-perceptron-why-to-marginalize-over-neurons-output-instead-of-its-wei", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/26950/<b>bayesian</b>-perceptron-why-to-marginalize...", "snippet": "I found a very interesting paper on the internet that tries to apply <b>Bayesian</b> inference with a gradient-free online-learning approach: <b>Bayesian</b> Perceptron: Towards fully <b>Bayesian</b> <b>Neural</b> Networks. I would love to understand this work, but unfortunately I am reaching my limits with my <b>Bayesian</b> knowledge.", "dateLastCrawled": "2022-01-21T16:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Bayesian</b> Dark Knowledge &lt;paper by Kevin Murphy&#39;s <b>group</b> at Google ...", "url": "https://www.reddit.com/r/MachineLearning/comments/3a2crl/bayesian_dark_knowledge_paper_by_kevin_murphys/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/MachineLearning/comments/3a2crl/<b>bayesian</b>_dark_knowledge_paper...", "snippet": "e.g. if you make your <b>neural</b> <b>network</b> 1 layer then it should be able to match the performance of a linear regression baseline, if it doesn\u2019t then you have a bug! e.g. if adding a feature improves the performance of linear regression then it should probably also improve the performance of your <b>neural</b> net unless you have a bug! Hyperparameter optimisation <b>can</b> help a bit (especially for the learning rate) but in general there are default hyperparameters that <b>can</b> do quite well and so closely ...", "dateLastCrawled": "2021-03-24T12:01:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Dynamic Bayesian network modeling of</b> fMRI: A comparison of <b>group</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1053811908001195", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1053811908001195", "snippet": "The three approaches are <b>compared</b> from the aspects of their statistical goodness-of-fit to the data, and more importantly their sensitivity in detecting the effect of the L-dopa medication on the disease. To the best of our knowledge, this is the first study specifically devoted <b>to group</b>-analysis on fMRI with BN modeling. Materials and methods fMRI data. The fMRI data were collected from ten healthy <b>people</b> and ten Parkinson&#39;s disease (PD) patients, each of whom was asked to squeeze a rubber ...", "dateLastCrawled": "2021-11-27T17:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian</b> <b>Network</b> as a Decision Tool for Predicting ALS Disease", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7912628/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7912628", "snippet": "<b>Bayesian</b> <b>network</b> has produced more successful results than other methods according to all comparison criteria for the Neurological Control <b>group</b>, as in the ALS <b>group</b>. For this <b>group</b>, the <b>Bayesian</b> <b>Network</b>\u2019s ACC value has been found as (0.902). The Kappa values of other methods indicate that the results obtained are random, while the Kappa value (0.677) was found for <b>Bayesian</b> <b>network</b>.", "dateLastCrawled": "2022-01-11T04:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian</b> Fully Convolutional Networks for Brain Image Registration", "url": "https://www.hindawi.com/journals/jhe/2021/5528160/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/jhe/2021/5528160", "snippet": "Moreover, the proposed method introduces <b>group</b> normalization, which is conducive to the <b>network</b> convergence of the <b>Bayesian</b> <b>neural</b> <b>network</b>. Some representative learning-based image registration methods are <b>compared</b> with the proposed method on different image datasets. Experimental results show that the registration accuracy of the proposed method is better than that of the methods, and its antifolding performance is comparable to that of fast image registration and VoxelMorph. Furthermore ...", "dateLastCrawled": "2022-01-29T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bayesian Belief Networks</b>: An Introduction In 6 Easy Points", "url": "https://www.jigsawacademy.com/blogs/data-science/bayesian-belief-network", "isFamilyFriendly": true, "displayUrl": "https://www.<b>jigsawacademy</b>.com/blogs/data-science/<b>bayesian</b>-belief-<b>network</b>", "snippet": "Hence, only the person creating the <b>network</b> <b>can</b> exploit causal influences. <b>Neural</b> networks are an advantage <b>compared</b> to this, as they learn different patterns and aren\u2019t limited to only the creator. The <b>Bayesian</b> <b>network</b> fails to define cyclic relationships\u2014for example, deflection of airplane wings and fluid pressure field around it. The ...", "dateLastCrawled": "2022-02-03T06:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "machine learning - What are the <b>downsides of bayesian neural networks</b> ...", "url": "https://stats.stackexchange.com/questions/311008/what-are-the-downsides-of-bayesian-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/311008", "snippet": "<b>Bayesian</b> <b>neural</b> nets (BNN) are very popular topic. With development of variational approximation it became possible to train such models much faster then with Monte Carlo sampling. BNNs allow such interesting features as natural regularisation and even uncertainty estimation. So, the question is: why haven&#39;t we still completely migrated on BNNs? I <b>can</b> assume that variational inference does not provide enough accuracy. Is it the only reason? machine-learning deep-learning <b>bayesian</b>-<b>network</b> ...", "dateLastCrawled": "2022-01-07T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "machine learning - Difference between Bayes <b>network</b>, <b>neural</b> <b>network</b> ...", "url": "https://stats.stackexchange.com/questions/94511/difference-between-bayes-network-neural-network-decision-tree-and-petri-nets", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/94511", "snippet": "<b>Bayesian</b> <b>Network</b>: The <b>Bayesian</b> <b>Network</b> is a directed acyclic graph, which more like the flowchart, only that the flow chart <b>can</b> have cyclic loops. The <b>Bayesian</b> <b>network</b> unlike the flow chart <b>can</b> have multiple start points. It basically traces the propagation of events across multiple ambiguous points, where the event diverges probabilistically between pathways. Obviously, at any given point in the <b>network</b>, the probability of that node being visited is dependent on the joint probability of the ...", "dateLastCrawled": "2022-01-28T22:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Bayesian</b> <b>Neural</b> <b>Network</b> Classification of Head Movement Direction ...", "url": "https://www.researchgate.net/publication/224634487_Bayesian_Neural_Network_Classification_of_Head_Movement_Direction_using_Various_Advanced_Optimisation_Training_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/224634487_<b>Bayesian</b>_<b>Neural</b>_<b>Network</b>...", "snippet": "<b>Bayesian</b> <b>Neural</b> <b>Network</b> Classification of Head Movement <b>Direction using Various Advanced Optimisation Training Algorithms</b> March 2006 DOI: 10.1109/BIOROB.2006.1639224", "dateLastCrawled": "2021-08-09T14:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "applications - What are the main benefits of using <b>Bayesian</b> networks ...", "url": "https://ai.stackexchange.com/questions/10649/what-are-the-main-benefits-of-using-bayesian-networks", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/.../what-are-the-main-benefits-of-using-<b>bayesian</b>-<b>networks</b>", "snippet": "$\\begingroup$ One other thing that comes to mind is markov blankets and other conditional independences, so local information is sufficient and other nodes are conditionally independent. I am not experienced enough to say how this is applied, but you <b>can</b> search for that. Having a <b>Bayesian</b> <b>network</b> feels to me like when I&#39;m happy when I <b>can</b> use a Markov chain as a model, because of the structure and simplified dependencies.", "dateLastCrawled": "2022-01-12T06:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How do <b>bayesian networks, MDPs and neural networks relate</b> to each other ...", "url": "https://www.quora.com/How-do-bayesian-networks-MDPs-and-neural-networks-relate-to-each-other-How-are-they-used", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-do-<b>bayesian-networks-MDPs-and-neural-networks-relate</b>-to-each...", "snippet": "Answer: - Artificial <b>neural</b> networks ANN try to estimate the answer to a problem. For example, they <b>can</b> answer classification problems. The ANN will return a probability for each class. The class with the highest probability is the most probable answer. In the same way, a yes/no problem is a prob...", "dateLastCrawled": "2022-01-14T18:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>can</b> we use <b>neural</b> networks in decision making instead of <b>Bayesian</b> ...", "url": "https://www.quora.com/How-can-we-use-neural-networks-in-decision-making-instead-of-Bayesian-networks-or-decision-trees", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>can</b>-we-use-<b>neural</b>-<b>networks</b>-in-decision-making-instead-of...", "snippet": "Answer: From the top of my head I <b>can</b> think of a few ways to tackle this issue. * CRF layers. CRF (Conditional Random Field) are a somewhat new approach to combining Markov chains and <b>neural</b> networks. The basic idea is to use the layers of a <b>neural</b> <b>network</b> to simulate a Markov model. * Monte C...", "dateLastCrawled": "2022-01-13T20:50:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>machine</b> <b>learning</b> approach to <b>Bayesian</b> parameter estimation | npj ...", "url": "https://www.nature.com/articles/s41534-021-00497-w", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-021-00497-w", "snippet": "The parameter estimation discussed in this manuscript is divided in two parts: i) a <b>neural</b> <b>network</b> is trained and ii) <b>Bayesian</b> estimation performed on a test set, which we detail below.", "dateLastCrawled": "2022-02-03T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "9.7. <b>Bayesian</b> <b>neural</b> networks \u2014 <b>Learning</b> from data", "url": "https://furnstahl.github.io/Physics-8820/notebooks/Machine_learning/Bayesian_neural_networks_tif285.html", "isFamilyFriendly": true, "displayUrl": "https://furnstahl.github.io/.../<b>Machine</b>_<b>learning</b>/<b>Bayesian</b>_<b>neural</b>_<b>networks</b>_tif285.html", "snippet": "<b>Bayesian</b> <b>neural</b> networks differ from plain <b>neural</b> networks in that their weights are assigned a probability distribution instead of a single value or point estimate. These probability distributions describe the uncertainty in weights and can be used to estimate uncertainty in predictions. Training a <b>Bayesian</b> <b>neural</b> <b>network</b> via variational inference learns the parameters of these distributions instead of the weights directly.", "dateLastCrawled": "2021-12-21T06:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "<b>Bayesian</b> <b>neural</b> networks are best explained using an <b>analogy</b> example. Suppose that instead of a <b>neural</b> <b>network</b>, you have a prediction equation y = (8.5 * x1) + (9.5 * x2) + 2.5 where y is the predicted income of an employee, x1 is normalized age, and x2 is years of job tenure. The predicted income of a 30-year old who has been on the job for 4 years would be y = (8.5 * 3.0) + (9.5 * 4.0) + 2.5 = 64.5 = $64,500. If you feed the same (age, tenure) input of (3.0, 4.0) to the prediction equation ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bayesian</b> <b>Neural Network</b> Series Post 2: Background Knowledge | by Kumar ...", "url": "https://medium.com/neuralspace/bayesian-neural-network-series-post-2-background-knowledge-fdec6ac62d43", "isFamilyFriendly": true, "displayUrl": "https://medium.com/<b>neural</b>space/<b>bayesian</b>-<b>neural-network</b>-series-post-2-background...", "snippet": "I will try to brief the <b>neural</b> networks <b>analogy</b> with the brain and will spend more time explaining the Probabilistic <b>Machine</b> <b>Learning</b> segments that we will work on in future. Brain Analogies. A ...", "dateLastCrawled": "2022-01-30T12:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep <b>neural</b> <b>network</b> models, and it has been used for conducting ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bayesian Belief Network in Artificial Intelligence</b> - Javatpoint", "url": "https://www.javatpoint.com/bayesian-belief-network-in-artificial-intelligence", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>bayesian-belief-network-in-artificial-intelligence</b>", "snippet": "<b>Bayesian Belief Network in artificial intelligence</b>. <b>Bayesian</b> belief <b>network</b> is key computer technology for dealing with probabilistic events and to solve a problem which has uncertainty. We can define a <b>Bayesian</b> <b>network</b> as: &quot;A <b>Bayesian</b> <b>network</b> is a probabilistic graphical model which represents a set of variables and their conditional ...", "dateLastCrawled": "2022-02-02T21:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "ML MCQ all 5 - <b>Machine</b> <b>Learning</b> MCQ&#39;s - KCS 052 - StuDocu", "url": "https://www.studocu.com/in/document/dr-apj-abdul-kalam-technical-university/machine-learning-techniques/ml-mcq-all-5-machine-learning-mcqs/16412586", "isFamilyFriendly": true, "displayUrl": "https://www.studocu.com/.../ml-mcq-all-5-<b>machine</b>-<b>learning</b>-mcqs/16412586", "snippet": "Which of the following is not numerical functions in the various function representation of <b>Machine</b> <b>Learning</b>? (A) <b>Neural</b> <b>Network</b> (B) Support Vector Machines (C) Case-based (D) Linear Regression. Answer Correct option is C . FIND-S Algorithm starts from the most specific hypothesis and generalize it by considering only ____ examples. (A) Negative (B) Positive (C) Negative or Positive (D) None of the above; Answer Correct option is B. FIND-S algorithm ignores ___ examples. (A) Negative (B ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Neural Networks and Learning Machines</b> - uniba.sk", "url": "https://dai.fmph.uniba.sk/courses/NN/haykin.neural-networks.3ed.2009.pdf", "isFamilyFriendly": true, "displayUrl": "https://dai.fmph.uniba.sk/courses/NN/haykin.<b>neural</b>-<b>networks</b>.3ed.2009.pdf", "snippet": "<b>Neural Networks and Learning Machines</b> Third Edition Simon Haykin McMaster University Hamilton, Ontario, Canada New York Boston San Francisco London Toronto Sydney Tokyo Singapore Madrid Mexico City Munich Paris Cape Town Hong Kong Montreal. Library of Congress Cataloging-in-Publication Data Haykin, Simon <b>Neural networks and learning machines</b> / Simon Haykin.\u20143rd ed. p. cm. Rev. ed of: <b>Neural</b> networks. 2nd ed., 1999. Includes bibliographical references and index. ISBN-13: 978-0-13-147139-9 ...", "dateLastCrawled": "2022-02-02T00:48:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bayesian neural network)  is like +(group of people)", "+(bayesian neural network) is similar to +(group of people)", "+(bayesian neural network) can be thought of as +(group of people)", "+(bayesian neural network) can be compared to +(group of people)", "machine learning +(bayesian neural network AND analogy)", "machine learning +(\"bayesian neural network is like\")", "machine learning +(\"bayesian neural network is similar\")", "machine learning +(\"just as bayesian neural network\")", "machine learning +(\"bayesian neural network can be thought of as\")", "machine learning +(\"bayesian neural network can be compared to\")"]}