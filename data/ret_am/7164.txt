{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>the opposite of gain? - Answers</b>", "url": "https://www.answers.com/Q/What_is_the_opposite_of_gain", "isFamilyFriendly": true, "displayUrl": "https://www.<b>answers</b>.com/Q/What_is_the_<b>opposite</b>_<b>of_gain</b>", "snippet": "The <b>opposite</b> <b>of gain</b> , from french to English is well its <b>like</b> you <b>gain</b>, then you lose so <b>gain</b>: is positive", "dateLastCrawled": "2022-01-12T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>What is the opposite of loss</b>? - Thesaurus and Word Tools", "url": "https://www.wordhippo.com/what-is/the-opposite-of/loss.html", "isFamilyFriendly": true, "displayUrl": "https://www.wordhippo.com/<b>what-is/the-opposite-of/loss</b>.html", "snippet": "<b>Opposite</b> of a gradual and continuous <b>loss</b> of strength, numbers, quality, or value. <b>Opposite</b> of a deterioration in state or health. <b>Opposite</b> of an occurrence of death by accident, in war, or from disease. <b>Opposite</b> of a lack or deficiency of something. <b>Opposite</b> of physical, mental or emotional injury to a person.", "dateLastCrawled": "2022-02-03T10:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Opposite</b> Of <b>Loss, Antonyms of Loss, Meaning and Example Sentences</b> ...", "url": "https://englishgrammarhere.com/opposite-words/opposite-of-loss-antonyms-of-loss-meaning-and-example-sentences/", "isFamilyFriendly": true, "displayUrl": "https://englishgrammarhere.com/<b>opposite</b>-words/<b>opposite</b>-of-<b>loss</b>-antonyms-of-<b>loss</b>...", "snippet": "<b>Opposite</b> Of <b>Loss, Antonyms of Loss, Meaning and Example Sentences</b> Antonym <b>opposite</b> words contradict each other and meet <b>opposite</b> meanings. A word has synonyms as well as antonyms. When we learn a language, when we learn a word in that language, it will be very useful for us to learn both the <b>opposite</b> and the synonyms of this word. Because learning a word with its synonyms increases our competence in that language as well as our competence in speaking and writing. Learning a word with its ...", "dateLastCrawled": "2022-01-16T12:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "182 Synonyms &amp; Antonyms of <b>LOSS</b> - <b>Merriam-Webster</b>", "url": "https://www.merriam-webster.com/thesaurus/loss", "isFamilyFriendly": true, "displayUrl": "https://<b>www.merriam-webster.com</b>/thesaurus/<b>loss</b>", "snippet": "Synonyms for <b>LOSS</b>: mislaying, misplacement, casualty, fatality, prey, victim, beating, defeat; Antonyms for <b>LOSS</b>: acquisition, <b>gain</b>, success, triumph, victory, win, boost, enlargement. <b>Loss</b>: the act or an instance of not having or being able to find. Synonyms: mislaying, misplacement, casualty\u2026 Antonyms: acquisition, <b>gain</b>, success\u2026 Find the right word. SINCE 1828. GAMES &amp; QUIZZES THESAURUS WORD OF THE DAY FEATURES; SHOP Buying Guide M-W Books . LOG IN; REGISTER ; settings log out. MY ...", "dateLastCrawled": "2022-02-03T18:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Eureka Math Grade 6 Module 3 Lesson 5 Answer</b> Key - CCSS Math Answers", "url": "https://ccssmathanswers.com/eureka-math-grade-6-module-3-lesson-5/", "isFamilyFriendly": true, "displayUrl": "https://ccssmathanswers.com/<b>eureka-math-grade-6-module-3-lesson</b>-5", "snippet": "\u2013 10 is the <b>opposite</b> of 10 (<b>loss</b> of pounds). \u2013 (- (- 10)) = \u2013 10. d. A withdrawal of $2,000 Answer: 2,000 is the <b>opposite</b> of \u2013 2,000 (deposit). \u2013 2,000 is the <b>opposite</b> of 2,000 (withdrawal). \u2013 (- (- 2,000)) = \u2013 2,000. Question 4. Write the integer that represents the statement. Locate and label each point on the number line below. Answer: a. The <b>opposite</b> of a <b>gain</b> of 6 Answer: \u2013 6. b. The <b>opposite</b> of a deposit of $10 Answer: \u2013 10. c. The <b>opposite</b> of the <b>opposite</b> of 0 Answer ...", "dateLastCrawled": "2022-02-02T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>What is the opposite of loss</b>? - Quora", "url": "https://www.quora.com/What-is-the-opposite-of-loss", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-the-opposite-of-loss</b>", "snippet": "Answer: <b>What is the opposite of loss</b>? Here are antonyms of \u2018<b>loss</b>\u2019 with different meanings: 1. Noun : <b>Opposite</b> of the fact or process of losing something or someone return, recovery, regaining, reclamation, recouping. 2. Noun : <b>Opposite</b> of the amount or degree by which something is reduced ...", "dateLastCrawled": "2022-01-16T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Asset gain/loss entry</b> | SAP Community", "url": "https://answers.sap.com/questions/10267150/asset-gainloss-entry.html", "isFamilyFriendly": true, "displayUrl": "https://answers.sap.com/questions/10267150", "snippet": "Currently, the <b>gain</b>/<b>loss</b> calculated with sale or retirement is automatically booked to accumulated depreciation, not <b>gain</b>/<b>loss</b> accounts. We have sold some assets and the handling is unique in that we will have to book a <b>gain</b>. We cannot post against accumulated depreciation. We thought that we might need another transaction type that will book to a <b>gain</b>/<b>loss</b> account instead of accumulated depreciation, but that would require moving all of the assets to a new account determination. And It ...", "dateLastCrawled": "2022-01-30T01:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "317 Synonyms &amp; Antonyms <b>of GAIN</b> - <b>Merriam-Webster</b>", "url": "https://www.merriam-webster.com/thesaurus/gain", "isFamilyFriendly": true, "displayUrl": "https://<b>www.merriam-webster.com</b>/thesaurus/<b>gain</b>", "snippet": "Synonyms for <b>GAIN</b>: build up, gather, grow (in), pick up, acquire, attain, bag, bring in; Antonyms for <b>GAIN</b>: decrease (in), lose, forfeit, contract, decrease, diminish, dwindle, lessen. <b>Gain</b>: to gradually increase in. Synonyms: build up, gather, grow (in)\u2026 Antonyms: decrease (in), lose, forfeit\u2026 Find the right word. SINCE 1828. GAMES &amp; QUIZZES THESAURUS WORD OF THE DAY FEATURES; SHOP Buying Guide M-W Books . LOG IN; REGISTER; settings log out. MY WORDS MY WORDS; dictionary. thesaurus ...", "dateLastCrawled": "2022-01-28T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Selling | Desire For <b>Gain</b> | Fear Of <b>Loss</b> | John Azh", "url": "https://johnazh.wordpress.com/2010/12/05/selling-desire-for-gain-fear-of-loss/", "isFamilyFriendly": true, "displayUrl": "https://johnazh.wordpress.com/2010/12/05/selling-desire-for-<b>gain</b>-fear-of-<b>loss</b>", "snippet": "Selling, desire for <b>gain</b>, and fear of <b>loss</b> are three concepts that are interrelated, and the nature of the relationship between them in every specific case determines whether you are going to make the sale or not. Desire for <b>gain</b> simply represents the things that we expect to <b>gain</b> as a result of making the buying decision. We all want to be admired, liked, respected, successful, and healthy. We all want prestige, recognition, social status, power, influence, and popularity. We all want ...", "dateLastCrawled": "2022-01-08T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "When a person sells two similar items, one at a <b>gain</b> of say x%, and the ...", "url": "https://www.quora.com/When-a-person-sells-two-similar-items-one-at-a-gain-of-say-x-and-the-other-at-a-loss-of-x-then-the-seller-always-incurs-a-loss-given-by-Loss-square-of-X-10-Why-will-it-experiences-a-loss", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/When-a-person-sells-two-similar-items-one-at-a-<b>gain</b>-of-say-x-and...", "snippet": "Answer (1 of 3): Thanks for A2A The given <b>loss</b> % will only hold true when Selling price is same\u2026 Let\u2019s understand this with an example\u2026Selling Price of each item be 120. and those item sold at 20% profit and 20% <b>loss</b>. 1. When it is sold at 20% profit Cost Price will be (120/1.2) 100. 2. When i...", "dateLastCrawled": "2022-01-27T12:52:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Opposite</b> <b>of Gain</b>, Antonyms <b>of gain</b> with meaning and Example Sentences ...", "url": "https://engdic.org/opposite-of-gain-antonyms-of-gain-with-meaning-and-example-sentences-in-english-pdf/", "isFamilyFriendly": true, "displayUrl": "https://engdic.org/<b>opposite</b>-<b>of-gain</b>-antonyms-<b>of-gain</b>-with-meaning-and-example...", "snippet": "<b>Opposite</b> <b>of Gain</b>, Antonyms <b>of gain</b> with meaning and Example Sentences in English PDF. What are <b>opposite</b> words or antonyms? <b>Opposite</b> words or Antonyms means those words that oppose the meaning of each other completely. For example Dark/Light, White/Black etc.", "dateLastCrawled": "2022-01-27T02:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "182 Synonyms &amp; Antonyms of <b>LOSS</b> - <b>Merriam-Webster</b>", "url": "https://www.merriam-webster.com/thesaurus/loss", "isFamilyFriendly": true, "displayUrl": "https://<b>www.merriam-webster.com</b>/thesaurus/<b>loss</b>", "snippet": "Synonyms for <b>LOSS</b>: mislaying, misplacement, casualty, fatality, prey, victim, beating, defeat; Antonyms for <b>LOSS</b>: acquisition, <b>gain</b>, success, triumph, victory, win, boost, enlargement. <b>Loss</b>: the act or an instance of not having or being able to find. Synonyms: mislaying, misplacement, casualty\u2026 Antonyms: acquisition, <b>gain</b>, success\u2026 Find the right word. SINCE 1828. GAMES &amp; QUIZZES THESAURUS WORD OF THE DAY FEATURES; SHOP Buying Guide M-W Books . LOG IN; REGISTER ; settings log out. MY ...", "dateLastCrawled": "2022-02-03T18:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>LOSS AND GAIN</b> in <b>Thesaurus</b>: 54 Synonyms &amp; Antonyms for <b>LOSS AND GAIN</b>", "url": "https://www.powerthesaurus.org/loss_and_gain", "isFamilyFriendly": true, "displayUrl": "https://www.power<b>thesaurus</b>.org/<b>loss_and_gain</b>", "snippet": "Related terms for <b>loss and gain</b>- synonyms, antonyms and sentences with <b>loss and gain</b>. Lists. synonyms. antonyms. definitions. sentences. <b>thesaurus</b>. Parts of speech. nouns. Synonyms <b>Similar</b> meaning. View all. advantages and disadvantages. strengths and weaknesses. pros and cons. highs and lows. pro and con. advantages and drawbacks. assets and liabilities. aye and nay. beneficial and negative impacts . benefits and burdens. benefits and disadvantages. benefits and hindrances. benefits and ill ...", "dateLastCrawled": "2021-10-19T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Comparison of gain-loss asymmetry behavior for stocks and</b> indexes", "url": "https://www.researchgate.net/publication/46462784_Comparison_of_gain-loss_asymmetry_behavior_for_stocks_and_indexes", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/46462784_<b>Comparison_of_gain-loss_asymmetry</b>...", "snippet": "This <b>gain</b>-<b>loss</b> asymmetry <b>is similar</b> to that previously found for developed markets (e.g. for the Dow Jones Index), but <b>opposite</b> to that found for indices in Eastern Europe. Given that previous ...", "dateLastCrawled": "2021-12-24T10:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>What is the opposite of loss</b>? - Quora", "url": "https://www.quora.com/What-is-the-opposite-of-loss", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-the-opposite-of-loss</b>", "snippet": "Answer: <b>What is the opposite of loss</b>? Here are antonyms of \u2018<b>loss</b>\u2019 with different meanings: 1. Noun : <b>Opposite</b> of the fact or process of losing something or someone return, recovery, regaining, reclamation, recouping. 2. Noun : <b>Opposite</b> of the amount or degree by which something is reduced ...", "dateLastCrawled": "2022-01-16T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "317 Synonyms &amp; Antonyms <b>of GAIN</b> - <b>Merriam-Webster</b>", "url": "https://www.merriam-webster.com/thesaurus/gain", "isFamilyFriendly": true, "displayUrl": "https://<b>www.merriam-webster.com</b>/thesaurus/<b>gain</b>", "snippet": "Synonyms for <b>GAIN</b>: build up, gather, grow (in), pick up, acquire, attain, bag, bring in; Antonyms for <b>GAIN</b>: decrease (in), lose, forfeit, contract, decrease, diminish, dwindle, lessen. <b>Gain</b>: to gradually increase in. Synonyms: build up, gather, grow (in)\u2026 Antonyms: decrease (in), lose, forfeit\u2026 Find the right word. SINCE 1828. GAMES &amp; QUIZZES THESAURUS WORD OF THE DAY FEATURES; SHOP Buying Guide M-W Books . LOG IN; REGISTER; settings log out. MY WORDS MY WORDS; dictionary. thesaurus ...", "dateLastCrawled": "2022-01-28T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>the opposite of a loss of</b> rupees 500 what - Brainly.in", "url": "https://brainly.in/question/25323542", "isFamilyFriendly": true, "displayUrl": "https://brainly.in/question/25323542", "snippet": "<b>The opposite of a loss of</b> rupees 500 what - 25323542 shalu paid rupee 88.20 for 23 <b>similar</b> pens and 18 <b>similar</b> files. the total cost of pen and a file is rupee 4.65. find the cost of one pen.", "dateLastCrawled": "2022-01-03T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "When a person sells two <b>similar</b> items, one at a <b>gain</b> of say x%, and the ...", "url": "https://www.quora.com/When-a-person-sells-two-similar-items-one-at-a-gain-of-say-x-and-the-other-at-a-loss-of-x-then-the-seller-always-incurs-a-loss-given-by-Loss-square-of-X-10-Why-will-it-experiences-a-loss", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/When-a-person-sells-two-<b>similar</b>-items-one-at-a-<b>gain</b>-of-say-x-and...", "snippet": "Answer (1 of 3): Thanks for A2A The given <b>loss</b> % will only hold true when Selling price is same\u2026 Let\u2019s understand this with an example\u2026Selling Price of each item be 120. and those item sold at 20% profit and 20% <b>loss</b>. 1. When it is sold at 20% profit Cost Price will be (120/1.2) 100. 2. When i...", "dateLastCrawled": "2022-01-27T12:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Report <b>of gain</b> / <b>loss</b> of asset retirement | SAP Community", "url": "https://answers.sap.com/questions/7843159/report-of-gain--loss-of-asset-retirement.html", "isFamilyFriendly": true, "displayUrl": "https://answers.sap.com/questions/7843159", "snippet": "Report <b>of gain</b> / <b>loss</b> of asset retirement. 607 Views. Follow. Answers Include Comments. Get RSS Feed. Hi SAP experts, Any one can please tell about which report can retrieve list on assets on <b>gain</b> / <b>loss</b> of asset retirement? Preferable to have <b>similar</b> report with AW01N - Asset Explorer. Thank you.", "dateLastCrawled": "2022-01-29T10:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What <b>is the opposite of impermanent loss</b>? : PantherSwap", "url": "https://www.reddit.com/r/PantherSwap/comments/nk04ni/what_is_the_opposite_of_impermanent_loss/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/nk04ni/what_<b>is_the_opposite_of_impermanent_loss</b>", "snippet": "Silly but somewhat legitimate question, what <b>is the opposite of impermanent loss</b>? To my understanding, IL is when there&#39;s a change in your coin prices which affects the ratio of coins each pool token holds/represents and thus causes you to lose potential gains you could&#39;ve made if you had just held the coins individually. Still an overall <b>gain</b>, but just missed out on even more that you potentially could&#39;ve had. Now, is it still considered an impermanent <b>loss</b> if the value of a coin drops and ...", "dateLastCrawled": "2022-01-06T13:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>What is the opposite of loss</b>? - Quora", "url": "https://www.quora.com/What-is-the-opposite-of-loss", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-the-opposite-of-loss</b>", "snippet": "Answer: <b>What is the opposite of loss</b>? Here are antonyms of \u2018<b>loss</b>\u2019 with different meanings: 1. Noun : <b>Opposite</b> of the fact or process of losing something or someone return, recovery, regaining, reclamation, recouping. 2. Noun : <b>Opposite</b> of the amount or degree by which something is reduced ...", "dateLastCrawled": "2022-01-16T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Effect <b>of Gain</b>-versus-<b>Loss</b> Framing of Economic and Health Prospects of ...", "url": "https://academic.oup.com/ijpor/article/33/4/927/6423103", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/ijpor/article/33/4/927/6423103", "snippet": "Contributing new insights to this line of literature, we investigated the conditionality <b>of gain</b>-versus-<b>loss</b> framing effects: We tested <b>gain</b>-versus-<b>loss</b> framing within scenarios of different interventions to combat the COVID-19 pandemic, and varied the domain to which these interventions were targeted (health or economic). Our main findings replicate the conclusion of Tversky and Kahneman. Framing interventions in terms of the consequences for the number of victims (losses) resulted in a ...", "dateLastCrawled": "2021-12-24T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The <b>Loss</b> of <b>Loss</b> Aversion: Will It Loom Larger Than Its <b>Gain</b>? - Gal ...", "url": "https://myscp.onlinelibrary.wiley.com/doi/full/10.1002/jcpy.1047", "isFamilyFriendly": true, "displayUrl": "https://myscp.onlinelibrary.wiley.com/doi/full/10.1002/jcpy.1047", "snippet": "Participants demand a substantial premium over an expected value of zero to accept a bet with even odds <b>of gain</b> and <b>loss</b>. It is <b>thought</b> that the possible <b>loss</b> of money looms larger than the possible <b>gain</b> of money: Inaction and action are confounded with <b>loss</b> and <b>gain</b>; when losses and gains are decoupled from inaction and action, no evidence for <b>loss</b> aversion is present (Ert &amp; Erev, 2013; Gal, 2006; Yechiam &amp; Hochman, 2013) Hedonic impact ratings: McGraw et al. Participants rated losses more ...", "dateLastCrawled": "2022-01-30T07:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What <b>is the opposite of impermanent loss</b>? : PantherSwap", "url": "https://www.reddit.com/r/PantherSwap/comments/nk04ni/what_is_the_opposite_of_impermanent_loss/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/nk04ni/what_<b>is_the_opposite_of_impermanent_loss</b>", "snippet": "Silly but somewhat legitimate question, what <b>is the opposite of impermanent loss</b>? To my understanding, IL is when there&#39;s a change in your coin prices which affects the ratio of coins each pool token holds/represents and thus causes you to lose potential gains you could&#39;ve made if you had just held the coins individually. Still an overall <b>gain</b>, but just missed out on even more that you potentially could&#39;ve had. Now, is it still considered an impermanent <b>loss</b> if the value of a coin drops and ...", "dateLastCrawled": "2022-01-06T13:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Translation between <b>Loss</b> and <b>Gain</b> - ResearchGate", "url": "https://www.researchgate.net/publication/328687655_Translation_between_Loss_and_Gain", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/328687655_Translation_between_<b>Loss</b>_and_<b>Gain</b>", "snippet": "majority of translation theorists and attempt to show that, while <b>loss</b> is an. undeniable consequence of transl ation, <b>gain</b> is also part of the process (in. my opinion, this is an issue that every ...", "dateLastCrawled": "2022-01-30T21:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Deaf <b>Gain</b>: reframing <b>how being deaf is</b> positive to individuals &amp; society", "url": "https://hearmeoutcc.com/deaf-gain/", "isFamilyFriendly": true, "displayUrl": "https://hearmeoutcc.com/deaf-<b>gain</b>", "snippet": "Here\u2019s a <b>thought</b> that I want you to consider: what if the topic and the whole concept of deafness and being deaf, what if that\u2019s a positive thing? What if it\u2019s a contribution to society, to humanity? What if it\u2019s something that is not a <b>loss</b>, it\u2019s not void or lacking, it is actually a <b>gain</b>? Have you ever <b>thought</b> about it that way? This a topic of \u2018Deaf <b>Gain</b>\u2019. In essence it kind of the <b>opposite</b> of hearing <b>loss</b>, and that might be a bit weird for you; it\u2019s a hearing <b>loss</b> but ...", "dateLastCrawled": "2022-02-01T17:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Prospect Theory Definition and Examples | BoyceWire</b>", "url": "https://boycewire.com/prospect-theory-definition-and-examples/", "isFamilyFriendly": true, "displayUrl": "https://boycewire.com/<b>prospect-theory-definition-and-examples</b>", "snippet": "This is also referred to as \u2018risk-averse\u2019. However, the <b>opposite</b> is true with losses. When faced with the certainty of losses, the theory concludes that people take greater risks in order to avoid the certainty of a <b>loss</b>. Just imagine the typical gambler trying to recover all of their losses and becoming increasingly desperate whilst doing so. Certainty of gains . With regards to the certainty of gains, consider two options. In the first scenario, you <b>can</b> take $50. In the second scenario ...", "dateLastCrawled": "2022-02-02T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>13 Surprising Medical Conditions</b> That <b>Can</b> Cause Weight <b>Gain</b> or <b>Loss</b> ...", "url": "https://www.yahoo.com/lifestyle/13-surprising-medical-conditions-cause-181950720.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.yahoo.com</b>/lifestyle/<b>13-surprising-medical-conditions</b>-cause-181950720.html", "snippet": "But a laundry list of health conditions <b>can</b> also influence weight <b>gain</b> or <b>loss</b>, either by affecting your appetite and energy levels or through other mechanisms. Let\u2019s explore 13 surprising ...", "dateLastCrawled": "2022-01-29T10:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "MMR, Rating <b>Gain</b>/<b>Loss</b>...is it just me? : worldofpvp", "url": "https://www.reddit.com/r/worldofpvp/comments/aqw9jv/mmr_rating_gainlossis_it_just_me/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/worldofpvp/comments/aqw9jv/<b>mmr_rating_gainlossis_it_just</b>_me", "snippet": "&#39;&#39;The intent of MMR <b>can</b>&#39;t be you need to win twice to protect against one <b>loss</b>. If I break even on win/<b>loss</b> then my points should stay where I started the evening.&#39;&#39; No, the system is more complicated than that - not that difficult to understand though. The amount of points you <b>gain</b> or lose from a win or a lose depends on what your opponents MMR is relative to yours. I do not know if the system is busted in rbgs, dont do much of it, but mmr as a system - independently of whatever probable ...", "dateLastCrawled": "2021-12-26T06:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>return loss &amp; gain</b> | Forum for Electronics", "url": "https://www.edaboard.com/threads/return-loss-gain.94847/", "isFamilyFriendly": true, "displayUrl": "https://www.edaboard.com/threads/<b>return-loss-gain</b>.94847", "snippet": "the matching the <b>gain</b> increased. you <b>can</b> also look at it in another way, matching is relative to S11 if the matching is poor than a lot of power is reflected, hence the S21 (which is relative to <b>gain</b>) is small. Apr 29, 2007 #4 B. bkd Full Member level 2. Joined Dec 18, 2005 Messages 120 Helped 3 Reputation 6 Reaction score 2 Trophy points 1,298 Activity points 2,105 good mathching -&gt; good total efficency and you know <b>gain</b>= directivity* total efficency. So in one kind of antenna( the same ...", "dateLastCrawled": "2022-01-21T04:00:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Effect <b>of Gain</b>-versus-<b>Loss</b> Framing of Economic and Health Prospects of ...", "url": "https://academic.oup.com/ijpor/article/33/4/927/6423103", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/ijpor/article/33/4/927/6423103", "snippet": "Concretely, we test whether <b>gain</b>-versus-<b>loss</b> framing for more or less restrictive policies\u2014in the case of (a) total lockdown versus (b) an \u201cintelligent\u201d lockdown (i.e., the Dutch term used for a less restrictive version of a total lockdown) versus (c) the \u201cSwedish\u201d opening up intervention\u2014results in stronger or weaker effects on preferences for risk-aversive versus risk-seeking interventions in the health domain <b>compared</b> to the economic domain.", "dateLastCrawled": "2021-12-24T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Gain/Loss on Investment</b> | Journal Entry | Example - Accountinguide", "url": "https://accountinguide.com/gain-loss-on-investment/", "isFamilyFriendly": true, "displayUrl": "https://accountinguide.com/<b>gain-loss-on-investment</b>", "snippet": "On the other hand, if an investor sells their investments at a lower price <b>compared</b> to the initial purchase. It means they are making losses, also known as a <b>loss</b> on investment. <b>Gain</b> or <b>Loss</b> on investment does not take into account the price change in the capital market. Investments such as bonds, stocks, and other financial instruments are traded in the capital market. Their price always changes depending on supply and demand in the market. Even the price increase, but the investors still ...", "dateLastCrawled": "2022-01-27T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Gain</b> vs. <b>loss</b>-<b>framing for reducing sugar consumption: Insights from</b> a ...", "url": "https://www.sciencedirect.com/science/article/abs/pii/S096399692030483X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/abs/pii/S096399692030483X", "snippet": "Health logos and nutritional warnings <b>can</b> be positioned on <b>opposite</b> sides of a continuous that goes from highlighting healthful products (<b>gain</b>-frame) to highlight unhealthful products (<b>loss</b>-frame), respectively. The aim of the present work was to evaluate the impact of health logos and nutritional warnings on consumers\u2019 choice of products with lower sugar content, and the impact of the two FOP nutrition labelling schemes on consumers\u2019 associations with sugar. An online study with 1232 ...", "dateLastCrawled": "2021-11-25T07:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to Calculate <b>Gain</b> and <b>Loss</b> on a Stock - <b>Investopedia</b>", "url": "https://www.investopedia.com/ask/answers/05/stockgainsandlosses.asp", "isFamilyFriendly": true, "displayUrl": "https://<b>www.investopedia.com</b>/ask/answers/05/stock<b>gain</b>sand<b>loss</b>es.asp", "snippet": "A <b>loss</b>, on the other hand, is the <b>opposite</b> of a <b>gain</b>. When you incur a <b>loss</b>, it means the current value of an asset or investment is lower than the price at which it was originally purchased.", "dateLastCrawled": "2022-02-02T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Study Your</b> Losses to Realize Gains - BabyPips.com", "url": "https://www.babypips.com/learn/forex/study-your-losing-trades", "isFamilyFriendly": true, "displayUrl": "https://www.babypips.com/learn/forex/<b>study-your</b>-losing-trades", "snippet": "Profit/<b>Loss</b> Ratio = Average <b>Gain</b> / Average <b>Loss</b>. For example, let\u2019s say you had 10 profitable trades with an average $200 <b>gain</b> per trade and 5 unprofitable trades with an average $300 <b>loss</b> per trade: Profit/<b>Loss</b> Ratio = $200 / $300 Profit/<b>Loss</b> Ratio = 0.67. A profit/<b>loss</b> ratio refers to the size of the average profit <b>compared</b> to the size of the average <b>loss</b> per trade. In the above example, since your average <b>gain</b> is $200 and your average <b>loss</b> is $300, your profit/<b>loss</b> ratio is 0.67. This ...", "dateLastCrawled": "2022-02-01T02:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Gain-Loss Framing</b> - IResearchNet", "url": "https://psychology.iresearchnet.com/social-psychology/social-cognition/gain-loss-framing/", "isFamilyFriendly": true, "displayUrl": "https://psychology.iresearchnet.com/social-psychology/social-cognition/<b>gain-loss-framing</b>", "snippet": "<b>Gain</b> or <b>loss</b> framing refers to phrasing a statement that describes a choice or outcome in terms of its positive (<b>gain</b>) or negative (<b>loss</b>) features. A message\u2019s framing does not alter its meaning. For example, the <b>gain</b>-framed message \u201cOne fourth of people will survive the attack\u201d is semantically equivalent to the <b>loss</b>-framed message \u201cThree fourths of people will perish in the attack.\u201d Framing does not refer to whether a communicator portrays a choice or outcome as good or bad ...", "dateLastCrawled": "2022-01-31T22:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What Are <b>Unrealized Gains and Losses</b>? - <b>Investopedia</b>", "url": "https://www.investopedia.com/ask/answers/04/021204.asp", "isFamilyFriendly": true, "displayUrl": "https://<b>www.investopedia.com</b>/ask/answers/04/021204.asp", "snippet": "Unrealized <b>Loss</b> . A realized <b>loss</b> is the <b>opposite</b> of a realized <b>gain</b>. It happens when an asset is sold for less than the original purchase price. So if you purchase one share of stock at $50 but ...", "dateLastCrawled": "2022-02-03T06:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The <b>Loss</b> of <b>Loss</b> Aversion: Will It Loom Larger Than Its <b>Gain</b>? - Gal ...", "url": "https://myscp.onlinelibrary.wiley.com/doi/full/10.1002/jcpy.1047", "isFamilyFriendly": true, "displayUrl": "https://myscp.onlinelibrary.wiley.com/doi/full/10.1002/jcpy.1047", "snippet": "Greater risk seeking in <b>loss</b> frames <b>compared</b> to <b>gain</b> frames <b>can</b> be explained by the reflection effect (Tversky &amp; Kahneman, 1981); meta-analyses do not support the conclusion that <b>loss</b> frames are generally more impactful than <b>gain</b> frames, and in fact, the <b>opposite</b> might be true (O&#39;Keefe &amp; Jensen, 2007) Riskless Choice Status quo bias. The status quo bias, the name given for individuals\u2019 propensity to prefer the status quo to an alternative option, has been attributed to <b>loss</b> aversion ...", "dateLastCrawled": "2022-01-30T07:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Translation between <b>Loss</b> and <b>Gain</b> - ResearchGate", "url": "https://www.researchgate.net/publication/328687655_Translation_between_Loss_and_Gain", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/328687655_Translation_between_<b>Loss</b>_and_<b>Gain</b>", "snippet": "majority of translation theorists and attempt to show that, while <b>loss</b> is an. undeniable consequence of transl ation, <b>gain</b> is also part of the process (in. my opinion, this is an issue that every ...", "dateLastCrawled": "2022-01-30T21:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>What is the opposite of loss</b>? - Quora", "url": "https://www.quora.com/What-is-the-opposite-of-loss", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-the-opposite-of-loss</b>", "snippet": "Answer: <b>What is the opposite of loss</b>? Here are antonyms of \u2018<b>loss</b>\u2019 with different meanings: 1. Noun : <b>Opposite</b> of the fact or process of losing something or someone return, recovery, regaining, reclamation, recouping. 2. Noun : <b>Opposite</b> of the amount or degree by which something is reduced ...", "dateLastCrawled": "2022-01-16T20:05:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> fundamentals I: An <b>analogy</b> | Finn Rietz.dev", "url": "http://www.finnrietz.dev/machine%20learning/part-1-analogy/", "isFamilyFriendly": true, "displayUrl": "www.finnrietz.dev/<b>machine</b> <b>learning</b>/part-1-<b>analogy</b>", "snippet": "And this is what the <b>loss</b> function does, so the <b>loss</b> function for a <b>Machine</b> <b>learning</b> algorithm is like the teacher for the real-world dermatologist in-training. In mathematical terms, the <b>loss</b> function could look something like this: \\(L = (y_i - \\hat{y_i})^2\\), where \\(y_i\\) is the actual output value (the one that the teacher has written down) and \\(\\hat{y_i}\\) is the one our <b>learning</b> algorithm produced.", "dateLastCrawled": "2022-01-16T09:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "Minimize a <b>loss</b> function in ... and it has been used for conducting research and for deploying <b>machine</b> <b>learning</b> systems into production across more than a dozen areas of computer science and other ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Human learning as an analogy of machine learning</b> - Weina Jin, MD", "url": "https://weina.me/ml-vs-human-learning/", "isFamilyFriendly": true, "displayUrl": "https://weina.me/ml-vs-human-<b>learning</b>", "snippet": "<b>Human learning as an analogy of machine learning</b>. 5 minute read. Published: July 24, 2018. These days, during my reading of computer vision papers, I discover a recurrent theme: to orient CNN-based network to a specific CV task, most papers focus on designing new architectures of the network and/or <b>loss</b> functions. This approach seems obvious.", "dateLastCrawled": "2020-07-13T08:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Why <b>Machine Learning Is A Metaphor For</b> Life \u2013 Adit Deshpande ...", "url": "https://adeshpande3.github.io/Why-Machine-Learning-is-a-Metaphor-For-Life", "isFamilyFriendly": true, "displayUrl": "https://adeshpande3.github.io/Why-<b>Machine-Learning-is-a-Metaphor-For</b>-Life", "snippet": "Another cool <b>analogy</b> is that of the epsilon greedy policy. This is a term used in reinforcement <b>learning</b> to fight the problem of exploration vs exploitation. The basic idea is that the RL agent will take a random action (instead of the optimal action according to its current policy) with probability \u03b5, in hope of searching a larger area of the state space, and eventually getting a better reward.", "dateLastCrawled": "2022-01-31T13:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "GitHub - arxaqapi/<b>analogy</b>-classifier: ML approach to <b>analogy</b> classification", "url": "https://github.com/arxaqapi/analogy-classifier", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/arxaqapi/<b>analogy</b>-classifier", "snippet": "<b>analogy</b>-classifier. This repository contains a minified version of the word <b>analogy</b> classifier described in the following paper: Lim S., Prade H., Richard G. (2019) Solving Word Analogies: A <b>Machine</b> <b>Learning</b> Perspective. In: Kern-Isberner G., Ognjanovi\u0107 Z. (eds) Symbolic and Quantitative Approaches to Reasoning with Uncertainty. ECSQARU 2019 ...", "dateLastCrawled": "2021-09-03T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is training <b>a neural network</b> like forming a habit? | Blog", "url": "https://jmsbrdy.com/blog/habit-formation-as-analogy-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://jmsbrdy.com/blog/habit-formation-as-<b>analogy</b>-for-<b>machine</b>-<b>learning</b>", "snippet": "Reward: during backpropagation, update our input weights according to the <b>loss</b> function; In fact, the <b>analogy</b> also works at the level of the network as a whole: Cue: transform our input example and input it into the first layer of the network; Routine: the network processes the input through its layers to produce a result; Reward: calculate how accurate the result is \u2013 compared to the labeling of the input example \u2013 and backpropagate; So, from a process perspective there do seem to broad ...", "dateLastCrawled": "2021-12-29T12:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Variants of Gradient Descent Optimizer in Deep <b>Learning</b> with Simple <b>Analogy</b>", "url": "https://manasanoolumortha.medium.com/variants-of-gradient-descent-optimizer-in-deep-learning-with-simple-analogy-6f2f59bd2e26", "isFamilyFriendly": true, "displayUrl": "https://manasanoolumortha.medium.com/variants-of-gradient-descent-optimizer-in-deep...", "snippet": "However, the ultimate goal of the dart game is to reach the target (middle point). The same <b>analogy</b> applies to the optimizer concept in deep <b>learning</b>. The main purpose of the optimizer is to reach the local minima (middle point) by updating the parameters (weights, <b>learning</b> rate, etc) and minimize the <b>loss</b>.", "dateLastCrawled": "2022-01-24T21:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>About loss and loss functions</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2019/10/04/about-loss-and-loss-functions/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2019/10/04/<b>about-loss-and-loss-functions</b>", "snippet": "The high-level supervised <b>learning</b> process. Before we can actually introduce the concept of loss, we\u2019ll have to take a look at the high-level supervised <b>machine</b> <b>learning</b> process.All supervised training approaches fall under this process, which means that it is equal for deep neural networks such as MLPs or ConvNets, but also for SVMs.. Let\u2019s take a look at this training process, which is cyclical in nature.", "dateLastCrawled": "2022-01-25T13:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>machine</b> <b>learning</b> - Why there is sudden drop in loss after every epoch ...", "url": "https://stackoverflow.com/questions/57248723/why-there-is-sudden-drop-in-loss-after-every-epoch", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/57248723", "snippet": "<b>machine</b>-<b>learning</b> keras deep-<b>learning</b> loss-function. Share. Follow edited Jul 29 &#39;19 at 12:40. Community Bot. 1 1 1 silver badge. asked Jul 29 &#39;19 at 7:09. Rahul Anand Rahul Anand. 389 1 1 gold badge 3 3 silver badges 15 15 bronze badges. Add a comment | 2 Answers Active Oldest Votes. 11 Note: This answer is assuming you are using Keras -- you might want to add this information to your post or at least add a relevant tag. ...", "dateLastCrawled": "2022-01-21T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>machine</b> <b>learning</b> - In training a triplet network, I first have a solid ...", "url": "https://stats.stackexchange.com/questions/475655/in-training-a-triplet-network-i-first-have-a-solid-drop-in-loss-but-eventually", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/475655/in-training-a-triplet-network-i-first...", "snippet": "Changing the losses changes the tasks, so comparing the value of semi-hard loss to batch hard <b>loss is like</b> comparing apples to oranges. Because of how semi-hard loss is defined, its value will always be smaller than ordinary triplet loss. But we still want to achieve the inequality $(*)$! To make a consistent comparison as training progresses, you should measure the loss on the hardest task throughout training to confirm that the model is, indeed, improving as you change tasks during ...", "dateLastCrawled": "2022-02-03T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Comparing images in frequency domain. \u201cSpectral loss\u201d \u2013 does it make ...", "url": "https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss-does-it-make-sense/", "isFamilyFriendly": true, "displayUrl": "https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss...", "snippet": "Recently, numerous academic papers in the <b>machine</b> <b>learning</b> / computer vision / image processing domains (re)introduce and discuss a \u201cfrequency loss function\u201d or &quot;spectral loss&quot; - and while for many it makes sense and nicely improves achieved results, some of them define or use it wrongly. The basic idea is - instead of comparing pixels\u2026", "dateLastCrawled": "2022-01-28T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "class4x.pdf - <b>Machine</b> <b>Learning</b> Topic 4 \\u2022\\u2008Perceptron Online ...", "url": "https://www.coursehero.com/file/107174025/class4xpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/107174025/class4xpdf", "snippet": "\u2022Multi-Layer Network can handle more complex decisions \u20221-layer: is linear, can\u2019t handle XOR \u2022Each layer adds more flexibility (but more parameters!) \u2022Each node splits its input space with linear hyperplane \u20222-layer: if last layer is AND operation, get convex hull \u20222-layer: can do almost anything multi-layer can by fanning out the inputs at 2 nd layer \u2022Note: Without loss of generality, we can omit the 1 and \u03b8 0 Multi-Layer Neural Networks", "dateLastCrawled": "2022-01-08T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "neural networks - Explanation of <b>Spikes</b> in training loss vs. iterations ...", "url": "https://stats.stackexchange.com/questions/303857/explanation-of-spikes-in-training-loss-vs-iterations-with-adam-optimizer", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/303857/explanation-of-<b>spikes</b>-in-training...", "snippet": "Cross Validated is a question and answer site for people interested in statistics, <b>machine</b> <b>learning</b>, data analysis, data mining, and data visualization. It only takes a minute to sign up. Sign up to join this community. Anybody can ask a question Anybody can answer The best answers are voted up and rise to the top Home Public; Questions; Tags Users Unanswered Teams. Stack Overflow for Teams \u2013 Collaborate and share knowledge with a private group. Create a free Team What is Teams? Teams ...", "dateLastCrawled": "2022-01-27T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[D] Looking for papers on treating regression as classification vs ...", "url": "https://www.reddit.com/r/MachineLearning/comments/7gun87/d_looking_for_papers_on_treating_regression_as/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/7gun87/d_looking_for_papers_on...", "snippet": "Doing the L2 <b>loss is like</b> doing maximum likelihood on a gaussian with a fixed variance - so the bad regression here is largely coming from the gaussian being mis-specified. I think the richer question would involve comparing approaches that consider the ordering vs. approaches that don t consider the ordering but where both have flexible enough distributions.", "dateLastCrawled": "2021-01-17T22:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Alan-D-Chen</b> (<b>Alan D Chen</b>) \u00b7 <b>GitHub</b>", "url": "https://github.com/Alan-D-Chen", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>Alan-D-Chen</b>", "snippet": "\ud83d\udd25 CDIoU and CDIoU <b>loss is like</b> a convenient plug-in that can be used in multiple models. CDIoU and CDIoU loss have different excellent performances in several models such as Faster R-CNN, YOLOv4, Re\u2026 Python 22 6 PCA_ICA_DEMO Public. Demo for PCA(Principal Component Analysis) &amp; ICA(Independent Component Analysis) in data analysis in Python and image separation written in MATLAB Python 8 2 meachine_<b>learning</b> Public. \u7b80\u5355\u7ebf\u6027\u56de\u5f52\uff0c\u591a\u5143\u7ebf\u6027\u56de\u5f52\uff0c\u975e\u7ebf\u6027\u56de\u5f52\uff0cKmeans\u7b97\u6cd5 ...", "dateLastCrawled": "2021-12-29T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Hearing Loss Simulator</b> - Find Out What <b>Hearing Loss is Like</b>", "url": "https://www.starkey.com/hearing-loss-simulator", "isFamilyFriendly": true, "displayUrl": "https://www.starkey.com/<b>hearing-loss-simulator</b>", "snippet": "Find out what they&#39;re experiencing with our <b>Hearing Loss Simulator</b>. Choose a situation. Select the <b>hearing loss</b> level you want to hear. Click Play. Set your computer volume to 50% for the best experience. Start.", "dateLastCrawled": "2022-02-02T08:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "7 <b>Things I\u2019ve Learned Since the Loss of</b> My Child", "url": "https://abedformyheart.com/7-things-since-loss-of-child/", "isFamilyFriendly": true, "displayUrl": "https://abedformyheart.com/7-things-since-loss-of-child", "snippet": "It is no worse than any loss of a child it is just different. I just want a time <b>machine</b> to go back and stop him to hold him and never let him go. It didn\u2019t have to happen I guess that\u2019s why the grief or denial or hope they will walk through the door is felt because you feel you could have stopped it. Maybe we could maybe they would have done it another time. Their are so many questions and no answers X . Reply. foreversadmom says. January 11, 2016 at 4:15 am. Sorry for your loss. I too ...", "dateLastCrawled": "2022-02-03T01:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What\u2019s considered a good Log <b>Loss</b> in <b>Machine</b> <b>Learning</b> ? | by Federico ...", "url": "https://medium.com/@fzammito/whats-considered-a-good-log-loss-in-machine-learning-a529d400632d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@fzammito/whats-considered-a-good-log-<b>loss</b>-in-<b>machine</b>-<b>learning</b>-a529...", "snippet": "Log <b>Loss is similar</b> to the Accuracy, but it will favor models that distinguish more strongly the classes. Log <b>Loss</b> it useful to compare models not only on their output but on their probabilistic ...", "dateLastCrawled": "2022-01-30T14:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Introduction to loss functions used in Deep Metric <b>Learning</b>. | Towards ...", "url": "https://towardsdatascience.com/metric-learning-loss-functions-5b67b3da99a5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metric-<b>learning</b>-loss-functions-5b67b3da99a5", "snippet": "Contributors : Jake Buglione, Sethu Hareesh Kolluru Recent advancements in <b>deep learning</b> have made it possible to learn a similarity measure for a set o f images using a deep metric <b>learning</b> network that maps visually similar images onto nearby locations in an embedding manifold, and visually dissimilar images apart from each other. Deep features learned using this approach result in well discriminative features with compact intra-product variance and well separated inter-product differences ...", "dateLastCrawled": "2022-01-25T23:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> Cats and Dogs\u2019 Breeds Classifier | by Mariana Santos ...", "url": "https://towardsdatascience.com/machine-learning-cats-and-dogs-breeds-classifier-b26a9df45000", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-cats-and-dogs-breeds-classifier-b26a9...", "snippet": "The accuracy of both the training and validation show similar curves and values, and even the train <b>loss is similar</b>, even though it is somewhat lower with the lower <b>learning</b> rate. The biggest difference is in the validation loss. With the larger <b>learning</b> rate, this curve did not converge to a value, probably because it was \u201chopping\u201d through the local minimum, due to the larger step. In this experience, we concluded that 0.001 is the best <b>learning</b> of all compared.", "dateLastCrawled": "2022-01-30T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Key techniques for Evaluating <b>Machine</b> <b>Learning</b> models - Data Analytics", "url": "https://vitalflux.com/key-techniques-evaluating-machine-learning-models-performance/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/key-techniques-evaluating-<b>machine</b>-<b>learning</b>-models-performance", "snippet": "Log loss is used to evaluate the performance of classification <b>machine</b> <b>learning</b> models that are built using classification algorithms such as logistic regression, support vector <b>machine</b> (SVM), random forest, and gradient boosting. The idea behind the use of Log <b>loss is similar</b> to taking a base-e exponential or natural logarithm in order to compare model scores from high-value functions which may indicate poor <b>machine</b> <b>learning</b> model performance. The logarithmic loss value is defined as ...", "dateLastCrawled": "2022-01-31T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "[2110.01601] DiffNet: Neural Field Solutions of Parametric Partial ...", "url": "https://arxiv.org/abs/2110.01601", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2110.01601", "snippet": "Computer Science &gt; <b>Machine</b> <b>Learning</b>. arXiv:2110.01601 (cs) [Submitted on 4 Oct 2021] ... (FEM <b>loss) is similar</b> to an energy functional that produces improved solutions, satisfies \\textit{a priori} mesh convergence, and can model Dirichlet and Neumann boundary conditions. We prove theoretically, and illustrate with experiments, convergence results analogous to mesh convergence analysis deployed in finite element solutions to PDEs. These results suggest that a mesh-based neural network ...", "dateLastCrawled": "2021-10-05T12:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Faster R-CNN step by step, Part II</b> | Notes for <b>machine</b> <b>learning</b>", "url": "https://dongjk.github.io/code/object+detection/keras/2018/06/10/Faster_R-CNN_step_by_step,_Part_II.html", "isFamilyFriendly": true, "displayUrl": "https://dongjk.github.io/code/object+detection/keras/2018/06/10/<b>Faster_R-CNN_step_by</b>...", "snippet": "regression <b>loss is similar</b> to RPN, using smooth l1 loss. there have 800 values but only 4 values are participant the gradient calculation. Summary. In this two posts, we have learnt how to implement <b>Faster R-CNN step by</b> step, how to prepare training data.", "dateLastCrawled": "2022-01-29T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - <b>hinge loss</b> vs logistic loss advantages and ...", "url": "https://stats.stackexchange.com/questions/146277/hinge-loss-vs-logistic-loss-advantages-and-disadvantages-limitations", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/146277/<b>hinge-loss</b>-vs-logistic-loss...", "snippet": "<b>machine</b>-<b>learning</b> svm loss-functions computer-vision. Share. Cite. Improve this question. Follow edited Jul 23 &#39;18 at 15:41. DHW. 644 3 3 silver badges 13 13 bronze badges. asked Apr 14 &#39;15 at 11:18. user570593 user570593. 1,059 2 2 gold badges 12 12 silver badges 19 19 bronze badges $\\endgroup$ Add a comment | 3 Answers Active Oldest Votes. 31 $\\begingroup$ Logarithmic loss minimization leads to well-behaved probabilistic outputs. <b>Hinge loss</b> leads to some (not guaranteed) sparsity on the ...", "dateLastCrawled": "2022-01-26T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Tabular Playground Series \u2013 June 2021 (Part 3) \u2013 <b>MACHINE</b> <b>LEARNING</b> CONCEPTS", "url": "https://srirangatarun.wordpress.com/2021/11/14/tabular-playground-series-june-2021-part-3/", "isFamilyFriendly": true, "displayUrl": "https://srirangatarun.wordpress.com/2021/11/14/tabular-playground-series-june-2021-part-3", "snippet": "The gap between the training and validation <b>loss is similar</b> to that of lightgbm, and lower than that of xgboost. So overfitting is not a major concern here. Additionally, catboost shows a strong LB performance with a score of 1.76 (very close to that of xgboost). catboost\u2019s CPU implementation is very fast compared to that of xgboost. catboost trains 20 estimators in just 6 seconds, compared to xgboost\u2019s 30. catboost, like xgboost, shows an impressive speed-up on GPU, going from 5.780 to ...", "dateLastCrawled": "2022-01-01T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What is an intuitive explanation for the log</b> loss function? - Quora", "url": "https://www.quora.com/What-is-an-intuitive-explanation-for-the-log-loss-function", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-an-intuitive-explanation-for-the-log</b>-loss-function", "snippet": "Answer (1 of 8): To me an intuitive explanation is that minimizing the log loss equals minimizing the Kullback-Leibler divergence (Kullback\u2013Leibler divergence - Wikipedia) between the function you want to optimize (for example a neural network) and the true function that generates the data (from ...", "dateLastCrawled": "2022-01-30T02:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Best <b>Artificial Intelligence</b> Course (AIML) by UT Austin", "url": "https://www.mygreatlearning.com/pg-program-artificial-intelligence-course", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/pg-program-<b>artificial-intelligence</b>-course", "snippet": "In <b>learning</b> a projection where the inputs can be distinguished, the triplet <b>loss is similar</b> to metric <b>learning</b>. The triplet loss is used for understanding the score vectors for the images. You can use the score vectors of face descriptors for verifying the faces in Euclidean Space. Natural Language Processing 4 Quizzes 2 Projects 4 Quizzes 2 Projects Learn how to work with natural language processing with Python using traditional <b>machine</b> <b>learning</b> methods. Then, deep dive into the realm of ...", "dateLastCrawled": "2022-02-01T17:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>learning</b> for metal additive manufacturing: Towards a physics ...", "url": "https://www.sciencedirect.com/science/article/pii/S0278612521002259", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0278612521002259", "snippet": "<b>Machine</b> <b>learning</b> (ML) has shown to be an effective alternative to physical models for quality prediction and process optimization of metal additive manufacturing (AM). However, the inherent \u201cblack box\u201d nature of ML techniques such as those represented by artificial neural networks has often presented a challenge to interpret ML outcomes in the framework of the complex thermodynamics that govern AM. While the practical benefits of ML provide an adequate justification, its utility as a ...", "dateLastCrawled": "2022-01-27T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "commonplace book redux \u2013 a diary of quotations", "url": "https://quotables.github.io/", "isFamilyFriendly": true, "displayUrl": "https://quotables.github.io", "snippet": "English-<b>learning</b> infants under the age of six months distinguish phonemes used in Czech, Hindi, and Inslekampx (a Native American language), but English-speaking adults cannot, even with five hundred trials of training or a year of university coursework. Adult ears can tell the sounds apart, though, when the consonants are stripped from the syllables and presented alone as chirpy sounds; they just cannot tell them apart as phonemes. [\u2026]", "dateLastCrawled": "2022-02-01T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Full text of &quot;91288819 Tosh Pursuit Of History 5th Ed&quot;", "url": "https://archive.org/stream/91288819ToshPursuitOfHistory5thEd/91288819-Tosh-Pursuit-of-History-5th-Ed_djvu.txt", "isFamilyFriendly": true, "displayUrl": "https://archive.org/stream/91288819ToshPursuitOfHistory5thEd/91288819-Tosh-Pursuit-of...", "snippet": "An illustration of a computer application window Wayback <b>Machine</b>. An illustration of an open book. Books. An illustration of two cells of a film strip. Video. An illustration of an audio speaker. Audio. An illustration of a 3.5&quot; floppy disk. Software. An illustration of two photographs. Images. An illustration of a heart shape Donate. An illustration of text ellipses. More. An icon used to represent a menu that can be toggled by interacting with this icon. ...", "dateLastCrawled": "2022-01-31T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Read <b>Mushoku Tensei</b> (WN),Free online novel online reading, online book ...", "url": "https://readnovelfreeonline.com/mushoku-tensei-wn/volume-5-h", "isFamilyFriendly": true, "displayUrl": "https://readnovelfreeonline.com/<b>mushoku-tensei</b>-wn/volume-5-h", "snippet": "If I remember correctly, I was <b>learning</b> swordsmanship at my house. It was an everyday life of being scolded by my father. Even when I put in a bit of work, he would complain about everything and hit me. &quot;Do you think the you of that time could have survived on the Magic Continent?&quot; &quot;Hah, Gisu, that entire premise is strange. Rudi you know, had ...", "dateLastCrawled": "2022-01-29T13:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What\u2019s My Line? <b>Next Sentence Prediction</b> in RunwayML with BERT | by ...", "url": "https://medium.com/runwayml/whats-my-line-next-sentence-prediction-in-runway-ad76cbf28c86", "isFamilyFriendly": true, "displayUrl": "https://medium.com/runwayml/whats-my-line-<b>next-sentence-prediction</b>-in-runway-ad76cbf28c86", "snippet": "The <b>loss can be thought of as</b> how much the model is surprised by the sequence. The lower the loss, the more likely it judges the sequence to be. Results: I\u2019m not sure what a score of 4.0966539 ...", "dateLastCrawled": "2022-01-31T03:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Notes on <b>Machine</b> <b>Learning</b> 3: <b>Decision theory</b>", "url": "https://cveai.github.io/notes/2018/03/27/mm-ml-3.html", "isFamilyFriendly": true, "displayUrl": "https://cveai.github.io/notes/2018/03/27/mm-ml-3.html", "snippet": "(ML 3.6) The Big Picture (part 2) Core ideas &amp; methods of ML: (not necessarily disjoint) Exact inference (usually not possible) Multivariate Gaussian (very nice) / Conjugate priors / Graphical models (use DP)", "dateLastCrawled": "2022-01-02T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Defect <b>Detection</b> in Products using Image Segmentation | by Vinithavn ...", "url": "https://medium.com/analytics-vidhya/defect-detection-in-products-using-image-segmentation-a87a8863a9e5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/defect-<b>detection</b>-in-products-using-image...", "snippet": "Dice <b>loss can be thought of as</b> 1-Dice coefficient where Dice coefficient is defined as, Dice coefficient=2* area of overlap area of intersection. You can read more about these metrics here. 5 ...", "dateLastCrawled": "2022-02-03T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Decision-Theoretic Approximations for Machine Learning</b>", "url": "https://www.ijcai.org/Proceedings/13/Papers/487.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/Proceedings/13/Papers/487.pdf", "snippet": "<b>Decision-Theoretic Approximations for Machine Learning</b> M. Ehsan Abbasnejad Abstract Decision theory focuses on the problem of mak-ing decisions under uncertainty. This uncertainty arises from the unknown aspects of the state of the world the decision maker is in or the unknown util- ity function of performing actions. The uncertainty can be modeled as a probability distribution captur-ing our belief about the world the decision maker is in. Upon making new observations, the decision maker ...", "dateLastCrawled": "2022-02-02T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Automatic Di\ufb00erentiation and <b>Neural Networks</b> 1 Introduction", "url": "https://people.cs.umass.edu/~domke/courses/sml2010/07autodiff_nnets.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.umass.edu/~domke/courses/sml2010/07autodiff_nnets.pdf", "snippet": "Statistical <b>Machine</b> <b>Learning</b> Notes 7 Automatic Di\ufb00erentiation and <b>Neural Networks</b> Instructor: Justin Domke 1 Introduction The name \u201cneuralnetwork\u201d is sometimes used torefer tomany things (e.g. Hop\ufb01eld networks, self-organizing maps). In these notes, we are only interested in the most common type of neural network, the multi-layer perceptron. A basic problem in <b>machine</b> <b>learning</b> is function approximation. We have some inputs x\u02c6 and some outputs y\u02c6, and we want to \ufb01t some function f ...", "dateLastCrawled": "2022-01-28T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Automatic Di\ufb00erentiation and Neural Networks</b>", "url": "https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf", "snippet": "Statistical <b>Machine</b> <b>Learning</b> Notes 8 <b>Automatic Di\ufb00erentiation and Neural Networks</b> Instructor: Justin Domke Contents 1 Introduction 1 2 Automatic Di\ufb00erentiation 2 3 Multi-Layer Perceptrons 5 4 MNIST 7 5 Backpropagation 10 6 Discussion 13 1 Introduction The name \u201cneuralnetwork\u201d is sometimes used torefer tomany things (e.g. Hop\ufb01eld networks, self-organizing maps). In these notes, we are only interested in the most common type of neural network, the multi-layer perceptron. A basic ...", "dateLastCrawled": "2022-01-28T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A cascaded fully convolutional network framework for dilated pancreatic ...", "url": "https://link.springer.com/article/10.1007/s11548-021-02530-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11548-021-02530-x", "snippet": "Deep-<b>learning</b>-base methods have successfully solved many challenging tasks in image processing, such as classification [8, 25], ... The Dice <b>loss can be thought of as</b> the minimization of the Dice score subtracted by one, which is minimized toward 0 to achieve optimal segmentation performance. Focal loss is proposed to dynamically rescale cross entropy loss and is conducive to imbalance problems . The voxel-wise Focal loss function is expressed as $$\\begin{aligned} {\\mathcal {L}}_F = -\\frac{1 ...", "dateLastCrawled": "2022-01-30T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Exploring deep neural networks via layer-peeled model: Minority ...", "url": "https://www.pnas.org/content/118/43/e2103091118", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/118/43/e2103091118", "snippet": "The remarkable development of deep <b>learning</b> over the past decade relies heavily on sophisticated heuristics and tricks. To better exploit its potential in the coming decade, perhaps a rigorous framework for reasoning about deep <b>learning</b> is needed, which, however, is not easy to build due to the intricate details of neural networks. For near-term purposes, a practical alternative is to develop a mathematically tractable surrogate model, yet maintaining many characteristics of neural networks.", "dateLastCrawled": "2021-12-30T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Adversarial Examples are Just Bugs</b>, Too - Latest articles about <b>machine</b> ...", "url": "https://distill.pub/2019/advex-bugs-discussion/response-5/", "isFamilyFriendly": true, "displayUrl": "https://distill.pub/2019/advex-bugs-discussion/response-5", "snippet": "Adversarial Examples With No Features. Using the above, we can construct adversarial examples which do not suffice for <b>learning</b>. Here, we replicate the Ilyas et al. experiment that \u201cNon-robust features suffice for standard classification\u201d (Section 3.2 of ), but show that it fails for our construction of adversarial examples.. To review, the Ilyas et al. non-robust experiment was:", "dateLastCrawled": "2022-01-31T12:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Network Traffic Anomaly Detection Using Recurrent Neural Networks", "url": "https://www.researchgate.net/publication/324104291_Network_Traffic_Anomaly_Detection_Using_Recurrent_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324104291_Network_Traffic_Anomaly_Detection...", "snippet": "Next, a supervised <b>machine</b> <b>learning</b> algorithm one-class SVM is trained to generalize the behavior model in order to predict user behavior anomalies. Results show that One-Class SVM is the most ...", "dateLastCrawled": "2022-01-26T23:23:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(loss)  is like +(opposite of gain)", "+(loss) is similar to +(opposite of gain)", "+(loss) can be thought of as +(opposite of gain)", "+(loss) can be compared to +(opposite of gain)", "machine learning +(loss AND analogy)", "machine learning +(\"loss is like\")", "machine learning +(\"loss is similar\")", "machine learning +(\"just as loss\")", "machine learning +(\"loss can be thought of as\")", "machine learning +(\"loss can be compared to\")"]}