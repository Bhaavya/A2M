{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Discrete</b> and continuous representations and processing in deep learning ...", "url": "https://www.sciencedirect.com/science/article/pii/S2666651021000206", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2666651021000206", "snippet": "The reverse mode is converting a <b>discrete</b> element <b>like</b> a <b>word</b> token in <b>language</b> or an action in reinforcement learning to a distributed representation. This is typically solved by extracting the right row or column, which is the wanted embedding, from an embedding matrix using the token index as index. 5.2.5. Indexing systems and memory", "dateLastCrawled": "2022-02-02T19:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Introduction to Text Representations for <b>Language</b> Processing \u2014 Part 1", "url": "https://towardsdatascience.com/introduction-to-text-representations-for-language-processing-part-1-dc6e8068b8a4", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-text-<b>representation</b>s-for-<b>language</b>...", "snippet": "Explosion in <b>feature</b> space if number of categories are very high; The vector <b>representation</b> of words is orthogonal and cannot determine or measure relationship between different words ; Cannot measure importance of a <b>word</b> in a sentence but understand mere presence/absence of a <b>word</b> in a sentence; High dimensional sparse matrix <b>representation</b> can be memory &amp; computationally expensive; Bag-of-words <b>representation</b>. Bag-of-words <b>representation</b> as the name suggests intutively, puts words in a ...", "dateLastCrawled": "2022-01-29T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Combining <b>Discrete</b> and Neural Features for Sequence Labeling | DeepAI", "url": "https://deepai.org/publication/combining-discrete-and-neural-features-for-sequence-labeling", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/combining-<b>discrete</b>-and-neural-<b>features</b>-for-sequence...", "snippet": "In this paper, we systematically investigate the effect of <b>discrete</b> and neural <b>feature</b> combination for a range of fundamental NLP tasks based on sequence labeling, including <b>word</b> segmentation, POS tagging and named entity recognition for Chinese and English, respectively. Our results on standard benchmarks show that state-of-the-art neural models can give accuracies comparable to the best <b>discrete</b> models in the literature for most tasks and combing <b>discrete</b> and neural features unanimously ...", "dateLastCrawled": "2021-12-15T05:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "8 text representation and advantages and disadvantages in the NLP field ...", "url": "https://easyai.tech/en/blog/nlp-%E9%A2%86%E5%9F%9F%E9%87%8C%E7%9A%848-%E7%A7%8D%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA%E6%96%B9%E5%BC%8F%E5%8F%8A%E4%BC%98%E7%BC%BA%E7%82%B9/?variant=zh-hans", "isFamilyFriendly": true, "displayUrl": "https://easyai.tech/en/blog/nlp-\u9886\u57df\u91cc\u76848-\u79cd\u6587\u672c\u8868\u793a\u65b9\u5f0f\u53ca\u4f18\u7f3a\u70b9...", "snippet": "<b>Discrete</b> representationDiscrete Representation); ... (Speech-<b>like</b> words with similar semantics); 1957 years,FirthFurther elaboration and clarification of the distributed hypothesis:A <b>word</b> is characterized by the company it keeps (The semantics of a <b>word</b> is determined by its context); 3.1 n-gram. N-gram is a <b>language</b> model (<b>Language</b> Model, LM).The <b>language</b> model is a discriminant model based on probability. The input of the model is a sentence (sequence of words), and the output is the ...", "dateLastCrawled": "2022-01-29T16:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Combining <b>Discrete</b> and Neural Features for Sequence Labeling | SpringerLink", "url": "https://link.springer.com/chapter/10.1007%2F978-3-319-75477-2_9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-319-75477-2_9", "snippet": "In this paper, we systematically investigate the effect of <b>discrete</b> and neural <b>feature</b> combination for a range of fundamental NLP tasks based on sequence labeling, including <b>word</b> segmentation, POS tagging and named entity recognition for Chinese and English, respectively. Our results on standard benchmarks show that state-of-the-art neural models can give accuracies comparable to the best <b>discrete</b> models in the literature for most tasks and combing <b>discrete</b> and neural features unanimously ...", "dateLastCrawled": "2021-12-14T13:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Phonology</b>: The Sound Patterns of <b>Language</b>", "url": "https://scholar.harvard.edu/files/adam/files/phonology.ppt.pdf", "isFamilyFriendly": true, "displayUrl": "https://scholar.harvard.edu/files/adam/files/<b>phonology</b>.ppt.pdf", "snippet": "<b>Language</b> \u2022 There are only a dozen or so features needed to describe every speech sound in every human <b>language</b> \u2013 All the languages in the world sound so different because the way the languages use speech sounds to form patterns differs from <b>language</b> to <b>language</b> \u2022 The study of how speech sounds form patterns is <b>phonology</b> \u2022 <b>Phonology</b> tells us what sounds are <b>in a language</b>, how they do and can combine into words, and explains why certain phonetic features are important to identifying a ", "dateLastCrawled": "2022-02-02T11:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning</b> \u2014 Text Processing | by Javaid Nabi | Towards Data Science", "url": "https://towardsdatascience.com/machine-learning-text-processing-1d5a2d638958", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine-learning</b>-text-processing-1d5a2d638958", "snippet": "In text processing, words of the text represent <b>discrete</b>, categorical features. How do we encode such data in a way which is ready to be used by the algorithms? The mapping from textual data to real valued vectors is called <b>feature</b> extraction. One of the simplest techniques to numerically represent text is Bag of Words. Bag of Words (BOW): We make the list of unique words in the text corpus called vocabulary. Then we can represent each sentence or document as a vector with each <b>word</b> ...", "dateLastCrawled": "2022-02-03T04:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Important <b>Language Features</b> You Should Know | Total Assignment Help", "url": "https://www.totalassignmenthelp.com/blog/language-features/", "isFamilyFriendly": true, "displayUrl": "https://www.totalassignmenthelp.com/blog/<b>language-features</b>", "snippet": "Rhetoric <b>Language</b>: This is a <b>language</b> <b>feature</b> which uses the rhetoric literary device to persuade the reader in thinking what the author intends. It is a tool which involves the words, sentences and questions in such a way that it automatically makes the audience think about the only logical interpretation. It may be used to hype, motivate or provoke a thought inside the audience\u2019s mind.", "dateLastCrawled": "2022-02-01T06:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Abstract vs Concrete <b>Language</b>: Example Words and Paragraphs", "url": "https://www.enchantingmarketing.com/abstract-vs-concrete-language/", "isFamilyFriendly": true, "displayUrl": "https://www.enchantingmarketing.com/abstract-vs-concrete-<b>language</b>", "snippet": "Even a <b>word</b> <b>like</b> apple is still a tiny bit abstract, as you might conjure up a different image from me. You might think of the bruised apples your mother used for cooking your favorite apple sauce. Or perhaps you think of the zesty Granny Smith you had yesterday afternoon. I\u2019m thinking of the Braeburn apple I had for breakfast with cinnamon, blueberries, almonds, and yogurt. So, abstract and concrete aren\u2019t <b>discrete</b> categories. They\u2019re a gliding scale. In his excellent book \u201cA Writer ...", "dateLastCrawled": "2022-02-02T23:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The <b>Nature of Language and Linguistics</b> \u2013 NeoEnglish: www.profnaeem.com", "url": "https://neoenglish.wordpress.com/2010/12/26/the-nature-of-language-and-linguistics/", "isFamilyFriendly": true, "displayUrl": "https://neoenglish.<b>word</b>press.com/2010/12/26/the-<b>nature-of-language-and-linguistics</b>", "snippet": "Both the definitions 5 and 6 above prominently point out that <b>language</b> is a system.Sounds join to form words according to a system. The letters k, n, i, t join to form a meaningful \u2018<b>word</b> knit, whereas combinations <b>like</b> n-k-i-t, t.k.n.i. or i.n.k.t. do not form any meaningful or sensible combinations. Although initially the formation of words, as said earlier, is only arbitrary, convention makes them parts of a system.", "dateLastCrawled": "2022-02-03T02:34:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to Text Representations for <b>Language</b> Processing \u2014 Part 1", "url": "https://towardsdatascience.com/introduction-to-text-representations-for-language-processing-part-1-dc6e8068b8a4", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-text-<b>representation</b>s-for-<b>language</b>...", "snippet": "The intuition behind BOW <b>representation</b> is that document having <b>similar</b> words are <b>similar</b> irrespective of the <b>word</b> positioning. Basic BOW \u2014 CountVectorizer. The CountVectorizer computes the frequency of occurrence of a <b>word</b> in a document. It converts the corpus of multiple sentences (say product reviews) into a matrix of reviews &amp; words &amp; fills it with frequency of each <b>word</b> in a sentence . Lets see how we can use Sklearn CountVectorizer: from sklearn.<b>feature</b>_extraction.text import ...", "dateLastCrawled": "2022-01-29T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Introduction to Text Representations for <b>Language</b> Processing \u2014 Part 2 ...", "url": "https://towardsdatascience.com/introduction-to-text-representations-for-language-processing-part-2-54fe6907868", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-text-<b>representation</b>s-for-<b>language</b>...", "snippet": "So the information about a <b>word</b> is distributed along the vector it is represented as. This is different from <b>discrete</b> <b>representation</b> where each <b>word</b> is considered unique &amp; independent of each others. Some of the commonly used distributed text representations are: Co-Occurrence matrix; Word2Vec; GloVe ; Co-Occurrence Matrix: The co-Occurrence matrix, as the name suggests, considers the co-occurrence of entities nearby each other. The entity used could be a single <b>word</b>, could be a bi-gram or ...", "dateLastCrawled": "2022-01-31T04:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Types of <b>Language</b> Tests - univ-tlemcen.dz", "url": "https://faclettre.univ-tlemcen.dz/assets/uploads/DOCUMENTS/cours%20en%20ligne/4-TYPE-L-BENM.pdf", "isFamilyFriendly": true, "displayUrl": "https://faclettre.univ-tlemcen.dz/assets/uploads/DOCUMENTS/cours en ligne/4-TYPE-L-BENM...", "snippet": "The <b>discrete</b>-point test, also called <b>discrete</b>-item test, is a <b>language</b> test which measures knowledge of individual <b>language</b> items, such as a grammar test which has different sections on tenses, adverbs and prepositions. <b>Discrete</b>-point tests are based on the theory that <b>language</b> consists of different parts such as speech sounds, grammar and vocabulary, and different skills such as listening, speaking, reading and writing, and these are made up of elements that can be . 5 tested separately ...", "dateLastCrawled": "2022-02-02T12:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Discrete</b> <b>Word</b> <b>Embedding for Logical Natural Language Understanding</b> ...", "url": "https://openreview.net/forum?id=4LHz4IFGLQ-", "isFamilyFriendly": true, "displayUrl": "https://openreview.net/forum?id=4LHz4IFGLQ-", "snippet": "We propose an unsupervised neural model for learning a <b>discrete</b> embedding of words. Unlike existing <b>discrete</b> embeddings, our binary embedding supports vector arithmetic operations <b>similar</b> to continuous embeddings. Our embedding represents each <b>word</b> as a set of propositional statements describing a transition rule in classical/STRIPS planning formalism. This makes the embedding directly compatible with symbolic, state of the art classical planning solvers.", "dateLastCrawled": "2022-01-29T04:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Incorporating Discrete Translation Lexicons into Neural</b> Machine ...", "url": "https://deepai.org/publication/incorporating-discrete-translation-lexicons-into-neural-machine-translation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>incorporating-discrete-translation-lexicons-into-neural</b>...", "snippet": "One <b>feature</b> of NMT systems is that they treat each <b>word</b> in the vocabulary as a vector of continuous-valued numbers. This is in contrast to more traditional SMT methods such as phrase-based machine translation (PBMT; koehn03phrasebased), which represent translations as <b>discrete</b> pairs of <b>word</b> strings in the source and target languages. The use of continuous representations is a major advantage, allowing NMT to share statistical power between <b>similar</b> words (e.g. \u201cdog\u201d and \u201ccat\u201d) or ...", "dateLastCrawled": "2021-12-25T12:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards a Multi-view <b>Language</b> Representation: A Shared Space of ...", "url": "https://typology-and-nlp.github.io/2019/assets/2019/papers/16.pdf", "isFamilyFriendly": true, "displayUrl": "https://typology-and-nlp.github.io/2019/assets/2019/papers/16.pdf", "snippet": "A Shared Space of <b>Discrete</b> and Continuous <b>Language</b> Features Arturo Oncevay, Barry Haddow and Alexandra Birch School of Informatics, University of Edinburgh, UK a.oncevay@ed.ac.uk Abstract Linguistic typology databases contain valu-able knowledge of the distinguishing proper-ties of different languages. Typically they contain sparse <b>discrete</b> features that are dif\ufb01-cult to integrate into computational methods, and dense task-learned <b>language</b> vectors have emerged in response. To join both ...", "dateLastCrawled": "2021-08-13T03:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Important <b>Language Features</b> You Should Know | Total Assignment Help", "url": "https://www.totalassignmenthelp.com/blog/language-features/", "isFamilyFriendly": true, "displayUrl": "https://www.totalassignmenthelp.com/blog/<b>language-features</b>", "snippet": "Since in the English <b>language</b>, multiple words may have <b>similar</b> meanings, therefore it is important to choose the right words which establish the tone and follow the diction and connotation of the context of the sentence, paragraph or the whole piece of writing. In addition to this, the writer should also keep in mind that the words used are easy to understand and doesn\u2019t require the reader to go grab a dictionary to understand one single <b>word</b>. Too much-sophisticated words may cause the ...", "dateLastCrawled": "2022-02-01T06:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Real time Translation of <b>Discrete</b> Sinh to Unicode Text", "url": "http://dr.lib.sjp.ac.lk/bitstream/handle/123456789/6034/Real%20time%20Translation%20of%20Discrete%20Sinhala%20Speech%20to%20Unicode%20Text.pdf?sequence=1", "isFamilyFriendly": true, "displayUrl": "dr.lib.sjp.ac.lk/bitstream/handle/123456789/6034/Real time Translation of <b>Discrete</b>...", "snippet": "coefficient as <b>feature</b> vector is used to recognize speech. Although a single person is used during the training session, an average accuracy of 95% is obtained for both speaker dependent and speaker independent speech recognition. Performance evaluation shows the capabilities of the proposed system to convert <b>discrete</b> Sinhala speech to Sinhala Unicode in both quiet and noisy environments. Keywords-Automatic Speech recognition, Hidden Markov Models, Sinhala speech I. Introduction In humans ...", "dateLastCrawled": "2022-01-31T18:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Text Similarities : Estimate the degree of <b>similarity</b> between two texts ...", "url": "https://medium.com/@adriensieg/text-similarities-da019229c894", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@adriensieg/text-<b>similar</b>ities-da019229c894", "snippet": "The <b>word</b> play in the second sentence should be more <b>similar</b> to play in the third sentence and less <b>similar</b> to play in the first. We can come up with any number of triplets like the above to test ...", "dateLastCrawled": "2022-02-02T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The <b>Nature of Language and Linguistics</b> \u2013 NeoEnglish: www.profnaeem.com", "url": "https://neoenglish.wordpress.com/2010/12/26/the-nature-of-language-and-linguistics/", "isFamilyFriendly": true, "displayUrl": "https://neoenglish.<b>word</b>press.com/2010/12/26/the-<b>nature-of-language-and-linguistics</b>", "snippet": "The situation in the case of the <b>language</b> is a <b>similar</b> one. The choice of a <b>word</b> selected to mean a particular thing or idea is purely arbitrary but once a <b>word</b> is selected for a particular referent, it comes to stay as such. It may be noted that had <b>language</b> not been arbitrary, there would have been only one <b>language</b> in the world. 3) <b>Language</b> is a System of Systems: <b>Language</b> is not an amorphous, a disorganised or a chaotic combination of sounds. Any brick may be used anywhere in a building ...", "dateLastCrawled": "2022-02-03T02:34:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to Text Representations for <b>Language</b> Processing \u2014 Part 1", "url": "https://towardsdatascience.com/introduction-to-text-representations-for-language-processing-part-1-dc6e8068b8a4", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-text-<b>representation</b>s-for-<b>language</b>...", "snippet": "Explosion in <b>feature</b> space if number of categories are very high; The vector <b>representation</b> of words is orthogonal and cannot determine or measure relationship between different words ; Cannot measure importance of a <b>word</b> in a sentence but understand mere presence/absence of a <b>word</b> in a sentence; High dimensional sparse matrix <b>representation</b> <b>can</b> be memory &amp; computationally expensive; Bag-of-words <b>representation</b>. Bag-of-words <b>representation</b> as the name suggests intutively, puts words in a ...", "dateLastCrawled": "2022-01-29T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Incorporating Discrete Translation Lexicons into Neural</b> Machine ...", "url": "https://deepai.org/publication/incorporating-discrete-translation-lexicons-into-neural-machine-translation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>incorporating-discrete-translation-lexicons-into-neural</b>...", "snippet": "One <b>feature</b> of NMT systems is that they treat each <b>word</b> in the vocabulary as a vector of continuous-valued numbers. This is in contrast to more traditional SMT methods such as phrase-based machine translation (PBMT; koehn03phrasebased), which represent translations as <b>discrete</b> pairs of <b>word</b> strings in the source and target languages. The use of continuous representations is a major advantage, allowing NMT to share statistical power between similar words (e.g. \u201cdog\u201d and \u201ccat\u201d) or ...", "dateLastCrawled": "2021-12-25T12:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to <b>use discrete in a sentence</b> - Thesaurus and <b>Word</b> Tools", "url": "https://www.wordhippo.com/what-is/sentences-with-the-word/discrete.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>word</b>hippo.com/what-is/sentences-with-the-<b>word</b>/<b>discrete</b>.html", "snippet": "A <b>discrete</b> morph <b>can</b> <b>be thought</b> of as an animation starting from the initial object and ending with the final object after a given number of the intermediate objects. It is more typical, however, to encounter a sample of artifacts exhibiting morphological characteristics along a continuum that are not easily sorted by <b>discrete</b> variables.", "dateLastCrawled": "2022-02-03T17:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Important <b>Language Features</b> You Should Know | Total Assignment Help", "url": "https://www.totalassignmenthelp.com/blog/language-features/", "isFamilyFriendly": true, "displayUrl": "https://www.totalassignmenthelp.com/blog/<b>language-features</b>", "snippet": "Rhetoric <b>Language</b>: This is a <b>language</b> <b>feature</b> which uses the rhetoric literary device to persuade the reader in thinking what the author intends. It is a tool which involves the words, sentences and questions in such a way that it automatically makes the audience think about the only logical interpretation. It may be used to hype, motivate or provoke a <b>thought</b> inside the audience\u2019s mind.", "dateLastCrawled": "2022-02-01T06:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is <b>discrete</b> behavior?", "url": "https://psichologyanswers.com/library/lecture/read/13230-what-is-discrete-behavior", "isFamilyFriendly": true, "displayUrl": "https://psichologyanswers.com/library/lecture/read/13230-what-is-<b>discrete</b>-behavior", "snippet": "<b>Discrete</b> math is something that definitely takes some getting used to. The actual calculations are not more difficult. The difficult part is the <b>thought</b> process and thinking logically. Why is it called <b>discrete</b> math? &quot;<b>Discrete</b> Math&quot; is not the name of a branch of mathematics, like number theory, algebra, calculus, etc. Rather, it&#39;s a ...", "dateLastCrawled": "2021-12-17T08:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Discrete</b> Infinity and the Syntax-semantics Interface", "url": "https://www.researchgate.net/publication/325675346_Discrete_Infinity_and_the_Syntax-semantics_Interface", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/325675346_<b>Discrete</b>_Infinity_and_the_Syntax...", "snippet": "Abstract. <b>Discrete</b> infnity was identifed as a central <b>feature</b> of human <b>language</b> by Humboldt who famously spoke of making infnite use of fnite means. Later Chomsky refocused attention on this ...", "dateLastCrawled": "2021-12-16T12:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Language</b> identification in web documents using <b>discrete</b> HMMs", "url": "https://www.researchgate.net/publication/222651095_Language_identification_in_web_documents_using_discrete_HMMs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/222651095_<b>Language</b>_identification_in_web...", "snippet": "This paper deals with <b>language</b> identification in the domain of web documents. The proposed system is built on hidden Markov models (HMMs) that enable the modeling of character sequences.", "dateLastCrawled": "2021-12-10T19:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Law and Language</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/law-language/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/law-<b>language</b>", "snippet": "Hart argued that we <b>can</b> understand that <b>feature</b> of law more clearly, if we understand where Bentham and his nineteenth-century disciple John Austin (not to be confused with J.L.Austin) went wrong in explaining the meaning and use of normative <b>language</b>. Hart\u2019s new approach to the issue has been a starting point for discussions of the normativity of law since the 1960s (see section 6.2 below). Ronald Dworkin argued that Hart\u2019s focus on <b>language</b> had a toxic effect on legal philosophy. He ...", "dateLastCrawled": "2022-02-02T22:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Displacement</b> in <b>Language</b>: Definition and Examples", "url": "https://www.thoughtco.com/displacement-language-term-1690399", "isFamilyFriendly": true, "displayUrl": "https://www.<b>thought</b>co.com/<b>displacement</b>-<b>language</b>-term-1690399", "snippet": "(Michael C. Corballis, The Recursive Mind: The Origins of Human <b>Language</b>, <b>Thought</b>, and Civilization. Princeton University Press, 2011) One Exception: The Dance of the Honeybee &quot;This <b>displacement</b>, which we take utterly for granted, is one of the most momentous differences between human languages and the signaling systems of all other species. . . . &quot;There is just one striking exception. A honeybee scout which has discovered a source of nectar returns to its hive and performs a dance, watched ...", "dateLastCrawled": "2022-02-02T07:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>LANGUAGE</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/107284416/language-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/107284416/<b>language</b>-flash-cards", "snippet": "A. <b>feature</b> B. phoneme C. phonetic D. morpheme E. <b>word</b>. D. morpheme . The ____ of a <b>language</b> refers to its sentence structure-the ways in which words <b>can</b> be legally combined to form phrases and sentences. A. phonology B. morphology C. syntax D. semantics E. pragmatics. C. syntax. The branch of linguistics devoted to the study of meaning: A. phonetics B. semantics C. morphology D. pragmatics E. syntax. B. semantics. The give-and-take of conversation, including the assumptions made by listeners ...", "dateLastCrawled": "2022-01-25T15:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "[1708.07279] Combining <b>Discrete</b> and Neural Features for Sequence Labeling", "url": "https://arxiv.org/abs/1708.07279", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1708.07279", "snippet": "Neural network models have recently received heated research attention in the natural <b>language</b> processing community. <b>Compared</b> with traditional models with <b>discrete</b> features, neural models have two main advantages. First, they take low-dimensional, real-valued embedding vectors as inputs, which <b>can</b> be trained over large raw data, thereby addressing the issue of <b>feature</b> sparsity in <b>discrete</b> models. Second, deep neural networks <b>can</b> be used to automatically combine input features, and including ...", "dateLastCrawled": "2021-11-27T11:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Combining <b>Discrete</b> and Neural Features for Sequence Labeling - NASA/ADS", "url": "https://ui.adsabs.harvard.edu/abs/2017arXiv170807279Y/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2017arXiv170807279Y/abstract", "snippet": "Such information <b>can</b> be complementary the features automatically induced from neural networks, and therefore combining <b>discrete</b> and neural features <b>can</b> potentially lead to better accuracy <b>compared</b> with models that leverage <b>discrete</b> or neural features only. In this paper, we systematically investigate the effect of <b>discrete</b> and neural <b>feature</b> combination for a range of fundamental NLP tasks based on sequence labeling, including <b>word</b> segmentation, POS tagging and named entity recognition for ...", "dateLastCrawled": "2020-06-16T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Combining <b>Discrete</b> and Neural Features for Sequence Labeling | SpringerLink", "url": "https://link.springer.com/chapter/10.1007%2F978-3-319-75477-2_9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-319-75477-2_9", "snippet": "First, they take low-dimensional, real-valued embedding vectors as inputs, which <b>can</b> be trained over large raw data, thereby addressing the issue of <b>feature</b> sparsity in <b>discrete</b> models. Second, deep neural networks <b>can</b> be used to automatically combine input features, and including non-local features that capture semantic patterns that cannot be expressed using <b>discrete</b> indicator features. As a result, neural network models have achieved competitive accuracies <b>compared</b> with the best <b>discrete</b> ...", "dateLastCrawled": "2021-12-14T13:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "[1708.07279v1] <b>Combining Discrete and Neural Features for Sequence Labeling</b>", "url": "https://arxiv.org/abs/1708.07279v1", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1708.07279v1", "snippet": "<b>Compared</b> with traditional models with <b>discrete</b> features, neural models have two main advantages. First, they take low-dimensional, real-valued embedding vectors as inputs, which <b>can</b> be trained over large raw data, thereby addressing the issue of <b>feature</b> sparsity in <b>discrete</b> models. Second, deep neural networks <b>can</b> be used to automatically combine input features, and including non-local features that capture semantic patterns that cannot be expressed using <b>discrete</b> indicator features. As a ...", "dateLastCrawled": "2021-11-08T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Combining <b>Discrete</b> and Neural Features for Sequence Labeling", "url": "https://www.researchgate.net/publication/319271841_Combining_Discrete_and_Neural_Features_for_Sequence_Labeling", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/319271841_Combining_<b>Discrete</b>_and_Neural...", "snippet": "<b>Compared</b> with traditional models with <b>discrete</b> features, neural models have two main advantages. First, they take low-dimensional, real-valued embedding vectors as inputs, which <b>can</b> be trained ...", "dateLastCrawled": "2022-01-06T14:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Integrating Discrete and Neural Features</b> via Mixed-<b>feature</b> Trans ...", "url": "https://www.researchgate.net/publication/339300990_Integrating_Discrete_and_Neural_Features_via_Mixed-feature_Trans-dimensional_Random_Field_Language_Models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339300990_Integrating_<b>Discrete</b>_and_Neural...", "snippet": "Request PDF | <b>Integrating Discrete and Neural Features</b> via Mixed-<b>feature</b> <b>Trans-dimensional Random Field Language Models</b> | There has been a long recognition that <b>discrete</b> features (n-gram features ...", "dateLastCrawled": "2022-01-17T21:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "INTEGRATING <b>DISCRETE</b> AND NEURAL FEATURES VIA MIXED-<b>FEATURE</b> TRANS ...", "url": "http://oa.ee.tsinghua.edu.cn/ouzhijian/pdf/ic20-mixed-TRF.pdf", "isFamilyFriendly": true, "displayUrl": "oa.ee.tsinghua.edu.cn/ouzhijian/pdf/ic20-mixed-TRF.pdf", "snippet": "<b>Compared</b> to interpolating two separately trained models with <b>discrete</b> and neural features respectively, the performance of mixed-<b>feature</b> TRF LMs matches the best interpolated model, and with simpli\ufb01ed one-step training process and reduced training time. Index Terms\u2014 <b>Language</b> models, Trans-dimensional random \ufb01elds, Dynamic noise-contrastive estimation, Speech recognition 1. INTRODUCTION <b>Language</b> modeling (LM) involves determining the joint probability of words in a sentence, and is a ...", "dateLastCrawled": "2021-11-22T10:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Difference Between <b>Discrete</b> and <b>Continuous</b> Data (with Comparison Chart ...", "url": "https://keydifferences.com/difference-between-discrete-and-continuous-data.html", "isFamilyFriendly": true, "displayUrl": "https://keydifferences.com/difference-between-<b>discrete</b>-and-<b>continuous</b>-data.html", "snippet": "The difference between <b>discrete</b> and <b>continuous</b> data <b>can</b> be drawn clearly on the following grounds: <b>Discrete</b> data is the type of data that has clear spaces between values. <b>Continuous</b> data is data that falls in a <b>continuous</b> sequence. <b>Discrete</b> data is countable while <b>continuous</b> data is measurable. <b>Discrete</b> data contains distinct or separate values. On the other hand, <b>continuous</b> data includes any value within range. <b>Discrete</b> data is graphically represented by bar graph whereas a histogram is ...", "dateLastCrawled": "2022-02-03T00:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Incorporating Discrete Translation Lexicons into Neural</b> Machine ...", "url": "https://deepai.org/publication/incorporating-discrete-translation-lexicons-into-neural-machine-translation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>incorporating-discrete-translation-lexicons-into-neural</b>...", "snippet": "One <b>feature</b> of NMT systems is that they treat each <b>word</b> in the vocabulary as a vector of continuous-valued numbers. This is in contrast to more traditional SMT methods such as phrase-based machine translation (PBMT; koehn03phrasebased), which represent translations as <b>discrete</b> pairs of <b>word</b> strings in the source and target languages. The use of continuous representations is a major advantage, allowing NMT to share statistical power between similar words (e.g. \u201cdog\u201d and \u201ccat\u201d) or ...", "dateLastCrawled": "2021-12-25T12:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Feature</b> Selection Techniques in Machine Learning - <b>GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/feature-selection-techniques-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>feature</b>-selection-techniques-in-machine-learning", "snippet": "Using hybrid methods for <b>feature</b> selection <b>can</b> offer a selection of best advantages from other methods, leading to reduce in the disadvantages of the algorithms. These models <b>can</b> provide greater accuracy and performance when <b>compared</b> to other methods. Dimensionality reduction techniques such as Principal Component Analysis (PCA), Heuristic Search Algorithms, etc. don\u2019t work in the way as to <b>feature</b> selection techniques but <b>can</b> help us to reduce the number of features.", "dateLastCrawled": "2022-01-30T23:28:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Learning</b>? <b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "Representing \u201cThings\u201d in <b>Machine</b> <b>Learning</b> \u2022An exampleor instance,x,represents a specific object (\u201cthing\u201d) \u2022xoften represented by a D-dimensional <b>feature</b> vectorx= (x 1, . . . , x D) \u2022Each dimension is called a featureorattribute \u2022Continuous or <b>discrete</b> valued \u2022xis a point in the D-dimensional <b>feature</b> space \u2022Abstraction of ...", "dateLastCrawled": "2022-02-03T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Types of Machine Learning</b> | Different Methods and Kinds of Model", "url": "https://www.educba.com/types-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>types-of-machine-learning</b>", "snippet": "<b>Machine</b> <b>Learning</b> Methods. We have four main <b>types of Machine learning</b> Methods based on the kind of <b>learning</b> we expect from the algorithms: 1. Supervised <b>Machine</b> <b>Learning</b>. Supervised <b>learning</b> algorithms are used when the output is classified or labeled. These algorithms learn from the past data that is inputted, called training data, runs its ...", "dateLastCrawled": "2022-02-02T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "What are the <b>basic concepts in machine learning</b>? I found that the best way to discover and get a handle on the <b>basic concepts in machine learning</b> is to review the introduction chapters to <b>machine learning</b> textbooks and to watch the videos from the first model in online courses. Pedro Domingos is a lecturer and professor on <b>machine learning</b> at the University of Washing and", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[R] Applying <b>Machine</b> <b>Learning</b> and <b>Discrete</b> Choice Modeling to ...", "url": "https://www.reddit.com/r/MachineLearning/comments/bwjt4p/r_applying_machine_learning_and_discrete_choice/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/bwjt4p/r_applying_<b>machine</b>_<b>learning</b>_and_<b>discrete</b>_choice", "snippet": "Furthermore, we find on the word <b>analogy</b> downstream task: 1) The <b>feature</b>-<b>learning</b> limit outperforms the NTK and the finite-width neural networks, 2) and the latter approach the <b>feature</b>-<b>learning</b> limit in performance as width increases. In the figure below, you can observe that NTK gets ~0 accuracy. This is because its word embeddings are ...", "dateLastCrawled": "2020-12-11T06:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "A. <b>Machine</b> <b>Learning</b> (ML) is that field of computer science. B. ML is a type of artificial intelligence that extract patterns out of raw data by using an algorithm or method. C. The main focus of ML is to allow computer systems learn from experience without being explicitly programmed or human intervention. D.", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> <b>Learning</b> MCQ.pdf - CHAPTER 1 1. <b>Machine</b> <b>learning</b> is _ field. 1 ...", "url": "https://www.coursehero.com/file/88144926/Machine-Learning-MCQpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/88144926/<b>Machine</b>-<b>Learning</b>-MCQpdf", "snippet": "View <b>Machine</b> <b>Learning</b> MCQ.pdf from CS 123 at Assam Engineering College. CHAPTER 1 1. <b>Machine</b> <b>learning</b> is _ field. 1. Inter-disciplinary 2. Single 3. Multi-disciplinary 4. All of the above Ans:", "dateLastCrawled": "2022-02-02T21:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Feature Selection Facilitates Learning Mixtures of</b> <b>Discrete</b> Product ...", "url": "https://arxiv.org/abs/1711.09195", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1711.09195", "snippet": "<b>Feature</b> selection can facilitate the <b>learning</b> of mixtures of <b>discrete</b> random variables as they arise, e.g. in crowdsourcing tasks. Intuitively, not all workers are equally reliable but, if the less reliable ones could be eliminated, then <b>learning</b> should be more robust. By <b>analogy</b> with Gaussian mixture models, we seek a low-order statistical approach, and here introduce an algorithm based on the (pairwise) mutual information. This induces an order over workers that is well structured for the ...", "dateLastCrawled": "2019-06-17T01:09:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(discrete feature)  is like +(word in a language)", "+(discrete feature) is similar to +(word in a language)", "+(discrete feature) can be thought of as +(word in a language)", "+(discrete feature) can be compared to +(word in a language)", "machine learning +(discrete feature AND analogy)", "machine learning +(\"discrete feature is like\")", "machine learning +(\"discrete feature is similar\")", "machine learning +(\"just as discrete feature\")", "machine learning +(\"discrete feature can be thought of as\")", "machine learning +(\"discrete feature can be compared to\")"]}