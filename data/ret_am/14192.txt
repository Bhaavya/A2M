{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Black</b>-<b>Box</b> Attacks against <b>RNN</b> based Malware Detection Algorithms ...", "url": "https://www.researchgate.net/publication/317088315_Black-Box_Attacks_against_RNN_based_Malware_Detection_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/317088315_<b>Black</b>-<b>Box</b>_Attacks_against_<b>RNN</b>_based...", "snippet": "The work in [70] proposes a <b>black</b>-<b>box</b> attack framework that targeting <b>RNN</b> model used in detecting malware. The framework consists of two models: one is a generative <b>RNN</b>, the other is a substitute ...", "dateLastCrawled": "2022-01-30T13:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Opening the <b>Black Box</b>: Low-dimensional dynamics in high-dimensional ...", "url": "https://barak.net.technion.ac.il/files/2012/11/sussillo_barak-neco.pdf", "isFamilyFriendly": true, "displayUrl": "https://barak.net.technion.ac.il/files/2012/11/sussillo_barak-neco.pdf", "snippet": "are often viewed as <b>black</b> boxes. This is in contrast to network models that were explicitly constructed to implement a speci\ufb01c known mechanism (e.g. see (Wang, 2008; Hop\ufb01eld, 1982)). One way to make progress may be to view an <b>RNN</b> as a nonlinear dynamical system (NLDS) and, in this light, there is a rich tradition of inquiry that can be ...", "dateLastCrawled": "2022-01-19T15:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Recurrent neural networks: building a custom</b> LSTM cell | AI Summer", "url": "https://theaisummer.com/understanding-lstm/", "isFamilyFriendly": true, "displayUrl": "https://theaisummer.com/understanding-lstm", "snippet": "And, for a lot of people in the computer vision community, recurrent neural networks (RNNs) are <b>like</b> this. More or less, another <b>black</b> <b>box</b> in the pile. However, in this tutorial, we will attempt to open the <b>RNN</b> magic <b>black</b> <b>box</b> and unravel its mysteries! Even though I have come across hundreds of tutorials on LSTM\u2019s out there, I felt there was something missing. Therefore, I honestly hope that this tutorial serves as a modern guide to RNNs. We try to deal with multiple details of practical ...", "dateLastCrawled": "2022-01-30T16:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "[1707.05970v1] Generic <b>Black</b>-<b>Box</b> End-to-End Attack against RNNs and ...", "url": "https://arxiv.org/abs/1707.05970v1", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1707.05970v1", "snippet": "In this paper we present a <b>black</b>-<b>box</b> attack against RNNs, focusing on finding adversarial API call sequences that would be misclassified by a <b>RNN</b> without affecting the malware functionality. We also show that the this attack is effective against many classifiers, due-to the transferability principle between <b>RNN</b> variants, feed-forward DNNs and state-of-the-art traditional machine learning classifiers. Finally, we introduce the transferability by transitivity principle, causing an attack ...", "dateLastCrawled": "2021-11-19T09:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Opening the <b>Black</b> <b>Box</b>: Low-Dimensional Dynamics in High-Dimensional ...", "url": "https://web.stanford.edu/class/cs379c/archive/2016/calendar_invited_talks/articles/SussilloandBarakNC-13.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/cs379c/archive/2016/calendar_invited_talks/articles/...", "snippet": "Opening the <b>Black</b> <b>Box</b>: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks David Sussillo sussillo@stanford.edu Department of Electrical Engineering, Neurosciences Program, Stanford University, Stanford, CA 94305-9505, U.S.A. Omri Barak omri.barak@gmail.com Department of Neuroscience, Columbia University College of Physicians and Surgeons, New York, NY 10032-2695, U.S.A. Recurrent neural networks (RNNs) are useful tools for learning nonlin-earrelationshipsbetweentime ...", "dateLastCrawled": "2022-01-19T17:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Process structure-based recurrent neural network modeling for model ...", "url": "https://www.sciencedirect.com/science/article/pii/S095915241930825X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S095915241930825X", "snippet": "Specifically, instead of treating the <b>RNN</b> system of Eq. (3) <b>like</b> a <b>black</b> <b>box</b> and training it using all the inputs and outputs available (termed the fully-connected model throughout the manuscript), we modify the <b>RNN</b> structure according to the structural process knowledge of the nonlinear system of Eq. (1). The details of the proposed new structure are discussed in the following section. Remark 2 . It is noted that in Eq. (3), we use a one-hidden-layer <b>RNN</b> model with n states in order to ...", "dateLastCrawled": "2022-01-08T13:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>RNN</b> to C code?", "url": "https://jam-world.github.io/rnn/ttic/study/2016/06/23/rnn-to-c-code.html", "isFamilyFriendly": true, "displayUrl": "https://jam-world.github.io/<b>rnn</b>/ttic/study/2016/06/23/<b>rnn</b>-to-c-code.html", "snippet": "We may get something that only compares the numerical variables and all the program is still <b>like</b> an <b>black</b> <b>box</b>. However, I believe it may be possible for us to go one step further. Is understanding <b>RNN</b> the same procedure as software reverse engineering? <b>RNN</b> to math expression? So <b>rnn</b> <b>is like</b> magic it can train over programs, which means <b>rnn</b> can learn any algorithm we can write in any Turing complete language. And, It&#39;s that possible for us to reverse this procedure to produce the math ...", "dateLastCrawled": "2021-12-13T02:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Distillation of weighted automata from recurrent neural networks</b> using ...", "url": "https://link.springer.com/article/10.1007/s10994-021-05948-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-021-05948-1", "snippet": "A second possibility, if the <b>black</b> <b>box</b> is a generative device <b>like</b> LM-<b>RNN</b>, is to use it to build a basis, for instance by recursively sampling a symbol from the next symbol distribution given by the network. Though other ways of generating a basis can be designed, for instance by using training data if available, the experiments presented in this paper concentrate on these two approaches, ...", "dateLastCrawled": "2022-01-30T05:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What\u2019s in the Black Box</b>? \u2013 Convolutional Neural Networks", "url": "https://convnets578736054.wordpress.com/2019/01/23/whats-in-the-black-box/", "isFamilyFriendly": true, "displayUrl": "https://convnets578736054.wordpress.com/2019/01/23/<b>whats-in-the-black-box</b>", "snippet": "The pooling layers are used to reduce the dimension of the input that they receive form the previous layer, so, in practice, if we are considering image, then we can consider the pooling <b>like</b> a method to reduce the resolution of our images input from the previous layer. The fully connected neural network is used to compute the probabilities assigned to each possible class for the input images, so we assign a label to our input by simply choosing the most probable class for the same input.", "dateLastCrawled": "2022-01-16T10:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[D] How do you choose which <b>Black</b>-<b>Box</b> Explainability method to use ...", "url": "https://www.reddit.com/r/MachineLearning/comments/sejdpy/d_how_do_you_choose_which_blackbox_explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../sejdpy/d_how_do_you_choose_which_<b>blackbox</b>_explainability", "snippet": "From just watching the video and guessing, it would make sense if noising the belief state (<b>rnn</b>(h,concat(proprio,extero)) + \\eps ~ Noise) and learning to condition proprioceptive attention on the belief uncertainty is enough. Very cool work and so exciting to see robotics groups exploiting ML more and more (gate attention + learned belief states here). 239. 39 comments. share. save. hide. report. 205. Posted by 3 days ago. News [N] Easily Build Machine Learning Products. Hey, I\u2019m Merve ...", "dateLastCrawled": "2022-01-28T22:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>RNN</b>- and LSTM-Based Soft Sensors Transferability for an Industrial Process", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7865368/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7865368", "snippet": "<b>Black</b>-<b>box</b> machine learning (ML) methods are often used as an efficient tool to implement SSs. Many efforts are, however, required to properly select input variables, model class, model order and the needed hyperparameters. The aim of this work was to investigate the possibility to transfer the knowledge acquired in the design of a SS for a given process to a <b>similar</b> one. This has been approached as a transfer learning problem from a source to a target domain. The implementation of a transfer ...", "dateLastCrawled": "2022-01-12T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Black</b>-<b>Box</b> Attacks against <b>RNN</b> based Malware Detection Algorithms - NASA/ADS", "url": "https://ui.adsabs.harvard.edu/abs/2017arXiv170508131H/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2017arXiv170508131H/abstract", "snippet": "<b>Similar</b> Papers Volume Content Graphics ... NASA/ADS. <b>Black</b>-<b>Box</b> Attacks against <b>RNN</b> based Malware Detection Algorithms Hu, Weiwei; Tan, Ying; Abstract. Recent researches have shown that machine learning based malware detection algorithms are very vulnerable under the attacks of adversarial examples. These works mainly focused on the detection algorithms which use features with fixed dimension, while some researchers have begun to use recurrent neural networks (<b>RNN</b>) to detect malware based on ...", "dateLastCrawled": "2020-12-24T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Black</b>-<b>Box</b> Attacks against <b>RNN</b> based Malware Detection Algorithms ...", "url": "https://www.researchgate.net/publication/317088315_Black-Box_Attacks_against_RNN_based_Malware_Detection_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/317088315_<b>Black</b>-<b>Box</b>_Attacks_against_<b>RNN</b>_based...", "snippet": "The work in [70] proposes a <b>black</b>-<b>box</b> attack framework that targeting <b>RNN</b> model used in detecting malware. The framework consists of two models: one is a generative <b>RNN</b>, the other is a substitute ...", "dateLastCrawled": "2022-01-30T13:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Mediated Multi-<b>RNN</b> Hybrid System for Prediction of Stock Prices", "url": "https://omidardakanicom.files.wordpress.com/2021/07/2020ardakanicsci.pdf", "isFamilyFriendly": true, "displayUrl": "https://omidardakanicom.files.wordpress.com/2021/07/2020ardakanicsci.pdf", "snippet": "of the <b>RNN</b> into another <b>black</b> <b>box</b> (another system) for improving the outcome or gets the output from a <b>black</b> <b>box</b> and feeds it into an <b>RNN</b> to improve the prediction. The <b>black</b> <b>box</b> is usually a system that uses a methodology other than <b>RNN</b>. We introduce a hybrid system that is made up of multiple RNNs and it is distinct from the other hybrid system for using historical stock prices along with two technical indicators of T and V. Practically, our hybrid system predicts two stock prices for each ...", "dateLastCrawled": "2021-11-22T00:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Recurrent neural networks: building a custom</b> LSTM cell | AI Summer", "url": "https://theaisummer.com/understanding-lstm/", "isFamilyFriendly": true, "displayUrl": "https://theaisummer.com/understanding-lstm", "snippet": "More or less, another <b>black</b> <b>box</b> in the pile. However, in this tutorial, we will attempt to open the <b>RNN</b> magic <b>black</b> <b>box</b> and unravel its mysteries! Even though I have come across hundreds of tutorials on LSTM\u2019s out there, I felt there was something missing. Therefore, I honestly hope that this tutorial serves as a modern guide to RNNs. We try to deal with multiple details of practical nature. To this end, we will build upon their fundamental concepts. The vast application field of <b>RNN</b>\u2019s ...", "dateLastCrawled": "2022-01-30T16:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Multiclass Text Classification Using Deep Learning | by vijay choubey ...", "url": "https://medium.com/analytics-vidhya/multiclass-text-classification-using-deep-learning-f25b4b1010e5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/multiclass-text-classification-using-deep-learning...", "snippet": "For a simple explanation of a bidirectional <b>RNN</b>, think of an <b>RNN</b> cell as a <b>black</b> <b>box</b> taking as input a hidden state (a vector) and a word vector and giving out an output vector and the next hidden ...", "dateLastCrawled": "2022-02-01T01:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Understanding LSTMs | <b>Black</b> <b>Box</b> ML", "url": "https://kushalj001.github.io/black-box-ml/lstm/pytorch/gates/vanishing%20gradient/2019/12/28/Understanding-LSTMs.html", "isFamilyFriendly": true, "displayUrl": "https://kushalj001.github.io/<b>black</b>-<b>box</b>-ml/lstm/pytorch/gates/vanishing gradient/2019/12...", "snippet": "Before we get into the abstract details of the LSTM, it is important to understand what the <b>black</b> <b>box</b> actually contains. The LSTM cell is nothing but a pack of 3-4 mini neural networks. These networks are comprised of linear layers that are parameterized by weight matrices and biases. The values of these weights are learnt by backpropagation. The following figure shows an LSTM cell with labelled gates and all the computations that take place inside the cell. Each cell has 3 inputs: the ...", "dateLastCrawled": "2021-10-14T13:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Binary <b>Black</b>-<b>box</b> Evasion Attacks Against Deep Learning-based Static ...", "url": "https://mohammadrezaebrahimi.github.io/publications/Ebrahimi_MalRNN.pdf", "isFamilyFriendly": true, "displayUrl": "https://mohammadrezaebrahimi.github.io/publications/Ebrahimi_Mal<b>RNN</b>.pdf", "snippet": "<b>black</b>-<b>box</b> scenario in which not only no a priori knowledge is assumed about the target, but also the adversary does not have access to a real-valued feedback from the attack target. Instead, in binary <b>black</b>-<b>box</b> scenario, the adversary can only observe a binary response associated with the success or fail-ure of the crafted instance in evading the attack target. This type of attack is also known as binary <b>black</b> <b>box</b> (Anderson et al. 2018). Binary <b>black</b>-<b>box</b> AEG is the most restrictive and the ...", "dateLastCrawled": "2021-11-07T14:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[D] Are <b>black</b>-<b>box</b> explainers (e.g. SHAP) just another <b>black</b>-<b>box</b> ...", "url": "https://www.reddit.com/r/MachineLearning/comments/sd973t/d_are_blackbox_explainers_eg_shap_just_another/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/MachineLearning/comments/sd973t/d_are_<b>blackbox</b>_explainers_eg...", "snippet": "The point is that the explaination would be so unintelligible to be basically useless. I see a <b>similar</b> risk for tools such as SHAP, since their assumptions and complexity, and the lack of knowledge on how they work by many of their users, essentially make them just another <b>black</b> <b>box</b> to trust.", "dateLastCrawled": "2022-01-26T18:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "In recurrent neural networks like LSTMs, is it possible to do transfer ...", "url": "https://www.quora.com/In-recurrent-neural-networks-like-LSTMs-is-it-possible-to-do-transfer-learning-Has-there-been-any-research-in-this-area", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-recurrent-neural-networks-like-LSTMs-is-it-possible-to-do...", "snippet": "Answer (1 of 4): The short answer is yes but we rarely transfer LSTM cells weights. A quick breakdown of LSTM (skip if you understand the basics): A standard LSTM, say for language modeling, has three parts, Embedding, LSTM cells, output layers. Embedding is a mapping between vocabularies to a v...", "dateLastCrawled": "2022-01-21T13:03:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Six Types of Neural Networks You Need</b> to Know About", "url": "https://sabrepc.com/blog/Deep-Learning-and-AI/6-types-of-neural-networks-to-know-about", "isFamilyFriendly": true, "displayUrl": "https://sabrepc.com/blog/Deep-Learning-and-AI/6-types-of-neural-networks-to-know-about", "snippet": "For a simple explanation of an <b>RNN</b>, think of an <b>RNN</b> cell as a <b>black</b> <b>box</b> taking as input a hidden state (a vector) and a word vector and giving out an output vector and the next hidden state. This <b>box</b> has some weights which need to be tuned using backpropagation of the losses. Also, the same cell is applied to all the words so that the weights are shared across the words in the sentence. This phenomenon is called weight-sharing. Hidden state, Word vector -&gt;(<b>RNN</b> Cell) -&gt; Output Vector , Next ...", "dateLastCrawled": "2022-01-20T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Real-Time <b>Black</b>-<b>Box</b> Modelling With Recurrent Neural Networks", "url": "https://www.researchgate.net/profile/Alec-Wright-3/publication/335714458_Real-Time_Black-Box_Modelling_with_Recurrent_Neural_Networks/links/5d77441592851cacdb2e0219/Real-Time-Black-Box-Modelling-with-Recurrent-Neural-Networks.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/profile/Alec-Wright-3/publication/335714458_Real-Time...", "snippet": "This paper is concerned with <b>black</b>-<b>box</b> modelling of tube ampli\ufb01ers and distortion pedals using a recurrent neural net- work (<b>RNN</b>). This is a very timely topic, as the \ufb01rst attempts to model ...", "dateLastCrawled": "2021-12-24T04:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Using Deep Learning for End to End Multiclass Text <b>Classification</b> | by ...", "url": "https://towardsdatascience.com/using-deep-learning-for-end-to-end-multiclass-text-classification-39b46aecac81", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-deep-learning-for-end-to-end-multiclass-text...", "snippet": "For a simple explanation of a bidirectional <b>RNN</b>, think of an <b>RNN</b> cell as a <b>black</b> <b>box</b> taking as input a hidden state (a vector) and a word vector and giving out an output vector and the next hidden state. This <b>box</b> has some weights which need to be tuned using backpropagation of the losses. Also, the same cell is applied to all the words so that the weights are shared across the words in the sentence. This phenomenon is called weight-sharing.", "dateLastCrawled": "2022-02-01T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Assignment 5 - Introduction to Deep Learning", "url": "https://ovgu-ailab.github.io/idl2020w/ass5.html", "isFamilyFriendly": true, "displayUrl": "https://ovgu-ailab.github.io/idl2020w/ass5.html", "snippet": "A Tensorflow <b>RNN</b> \u201clayer\u201d <b>can</b> be confusing due to its <b>black</b> <b>box</b> character: All computations over a full sequence of inputs are done internally. To make sure you understand how an <b>RNN</b> \u201cworks\u201d, you are asked to implement one from the ground up, defining variables yourself and using basic operations such as tf.matmul to define the computations at each time step and over a full input sequence. There are some related tutorials available on the TF website, but all of these use Keras. For ...", "dateLastCrawled": "2021-10-21T19:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning Queuing Networks by Recurrent Neural Networks</b> | DeepAI", "url": "https://deepai.org/publication/learning-queuing-networks-by-recurrent-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>learning-queuing-networks-by-recurrent-neural-networks</b>", "snippet": "It is worth remarking that, in principle, one could learn a QN model by relying on a standard, <b>black</b>-<b>box</b> <b>RNN</b> architecture by treating all the QN parameters (i.e., initial population, service demand, number of servers and routing probabilities) as input features of the learning algorithm. Unfortunately, this straightforward approach would require a considerable amount of input traces since the learning algorithm could not exploit the structural information about the problem. For instance, it ...", "dateLastCrawled": "2021-12-21T16:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "tensorflow - <b>LSTM with Keras to optimize a black box function</b> - Stack ...", "url": "https://stackoverflow.com/questions/65053311/lstm-with-keras-to-optimize-a-black-box-function", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/65053311/<b>lstm-with-keras-to-optimize</b>-a-<b>black</b>-<b>box</b>...", "snippet": "Evaluate y1 = f (p1) Call the LSTM cell with input= [p1,y1], and obtain output=p2. Evaluate y2 = f (p2) Repeat for few times, for example stopping at fifth iteration: y5 = f (p5). I&#39;m trying to implement a similar model in Tensorflow/Keras but I&#39;m having some troubles. In particular, this case is different from &quot;standard&quot; ones because we don&#39;t ...", "dateLastCrawled": "2022-01-23T02:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>box</b> jenkins | Am-241", "url": "https://am241.wordpress.com/tag/box-jenkins/", "isFamilyFriendly": true, "displayUrl": "https://am241.wordpress.com/tag/<b>box</b>-jenkins", "snippet": "Indeed, a <b>RNN</b>, once unrolled, <b>can</b> <b>be thought</b> of as a standard multilayer feedforward network whose inputs are taken at different times. Because of their intrinsically temporal structure (individual inputs being applied sequentially), RNNs are suited for speech recognition, language modelling (see 1409.2329 and references therein) and time-series prediction .", "dateLastCrawled": "2022-01-30T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "DeepMind &amp; IDSIA Introduce Symmetries to <b>Black</b>-<b>Box</b> MetaRL to Improve ...", "url": "https://medium.com/syncedreview/deepmind-idsia-introduce-symmetries-to-black-box-metarl-to-improve-its-generalization-ability-f0de828aee03", "isFamilyFriendly": true, "displayUrl": "https://medium.com/syncedreview/deepmind-idsia-introduce-symmetries-to-<b>black</b>-<b>box</b>...", "snippet": "A research team from DeepMind and The Swiss AI Lab IDSIA explores the role of symmetries in meta generalization and shows that introducing more symmetries to <b>black</b>-<b>box</b> meta-learners <b>can</b> improve ...", "dateLastCrawled": "2021-09-28T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep Learning: No more BlackBox. Deep Learning is defamed for its\u2026 | by ...", "url": "https://sarafparam.medium.com/ai-deep-learning-no-more-blackbox-1faa5c7ffd10", "isFamilyFriendly": true, "displayUrl": "https://sarafparam.medium.com/ai-deep-learning-no-more-<b>blackbox</b>-1faa5c7ffd10", "snippet": "Deep Learning is defamed for its <b>Black</b>-<b>Box</b> nature, meaning one <b>can</b>\u2019t get an easy explanation about the model and its features, ... Deep Learning creates its own features out of the dataset. These features <b>can</b> <b>be thought</b> of as different layers of neurons that activate/deactivate based on specific criteria, hence it is difficult to decode what has the model learned. Captum : Captum (which means comprehension in latin) is a model interpretability and understanding library for PyTorch. Model ...", "dateLastCrawled": "2022-01-16T11:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is a <b>black box in machine learning? - Quora</b>", "url": "https://www.quora.com/What-is-a-black-box-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-a-<b>black-box-in-machine-learning</b>", "snippet": "Answer (1 of 2): Any group of code where the user has no idea how the code is designed. For example, let\u2019s say you are building a model in Keras from an online tutorial. The deep learning network you are building is a <b>black</b> <b>box</b> to you because you have no idea how deep learning networks are buil...", "dateLastCrawled": "2022-01-29T15:25:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Black</b>-<b>Box</b> Attacks against <b>RNN</b> based Malware Detection Algorithms ...", "url": "https://www.researchgate.net/publication/317088315_Black-Box_Attacks_against_RNN_based_Malware_Detection_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/317088315_<b>Black</b>-<b>Box</b>_Attacks_against_<b>RNN</b>_based...", "snippet": "The work in [70] proposes a <b>black</b>-<b>box</b> attack framework that targeting <b>RNN</b> model used in detecting malware. The framework consists of two models: one is a generative <b>RNN</b>, the other is a substitute ...", "dateLastCrawled": "2022-01-30T13:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Black</b>-<b>Box</b> Attacks <b>against RNN based Malware Detection Algorithms</b> ...", "url": "https://www.arxiv-vanity.com/papers/1705.08131/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1705.08131", "snippet": "A substitute <b>RNN</b> is trained to fit the <b>black</b>-<b>box</b> victim <b>RNN</b>. We use Gumbel-Softmax to approximate the generated discrete APIs, which is able to propagate the gradients from the substitute <b>RNN</b> to the generative <b>RNN</b>. The proposed model has successfully made most of the generated adversarial examples able to bypass several <b>black</b>-<b>box</b> victim RNNs with different structures.", "dateLastCrawled": "2022-01-05T13:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "RNNRepair: Automatic <b>RNN</b> Repair via Model-based Analysis", "url": "https://proceedings.mlr.press/v139/xie21b.html", "isFamilyFriendly": true, "displayUrl": "https://proceedings.mlr.press/v139/xie21b.html", "snippet": "Due to their <b>black</b>-<b>box</b> nature, it is rather challenging to interpret and properly repair these incorrect behaviors. This paper focuses on interpreting and repairing the incorrect behaviors of Recurrent Neural Networks (RNNs). We propose a lightweight model-based approach (RNNRepair) to help understand and repair incorrect behaviors of an <b>RNN</b>. Specifically, we build an influence model to characterize the stateful and statistical behaviors of an <b>RNN</b> over all the training data and to perform ...", "dateLastCrawled": "2021-12-15T18:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>RNN</b>- and LSTM-Based Soft Sensors Transferability for an Industrial Process", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7865368/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7865368", "snippet": "<b>Black</b>-<b>box</b> machine learning (ML) methods are often used as an efficient tool to implement SSs. Many efforts are, however, required to properly select input variables, model class, model order and the needed hyperparameters. The aim of this work was to investigate the possibility to transfer the knowledge acquired in the design of a SS for a given process to a similar one. This has been approached as a transfer learning problem from a source to a target domain. The implementation of a transfer ...", "dateLastCrawled": "2022-01-12T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "RNNRepair: Automatic <b>RNN</b> Repair via Model-based Analysis", "url": "http://proceedings.mlr.press/v139/xie21b/xie21b.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v139/xie21b/xie21b.pdf", "snippet": "Due to their <b>black</b>-<b>box</b> nature, it is rather challenging to interpret and properly re-pair these incorrect behaviors. This paper focuses on interpreting and repairing the incorrect behav-iors of Recurrent Neural Networks (RNNs). We propose a lightweight model-based approach (RN-NRepair) to help understand and repair incorrect behaviors of an <b>RNN</b>. Speci\ufb01cally, we build an in\ufb02uence model to characterize the stateful and statistical behaviors of an <b>RNN</b> over all the train-ing data and to ...", "dateLastCrawled": "2022-01-27T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Black</b>-<b>Box</b> Modelling of a DC-DC Buck Converter Based on a Recurrent ...", "url": "https://upcommons.upc.edu/bitstream/handle/2117/188104/Black-Box%20Modelling%20of%20a%20DC-DC%20Buck%20Converter%20Based%20on%20a%20Recurrent%20Neural%20Network_Rojas.pdf;sequence=5", "isFamilyFriendly": true, "displayUrl": "https://upcommons.upc.edu/bitstream/handle/2117/188104/<b>Black</b>-<b>Box</b> Modelling of a DC-DC...", "snippet": "<b>black</b> <b>box</b> system. A Recurrent NARX NN (or NARX-<b>RNN</b>) arises as a solution for the identification of a <b>black</b>-<b>box</b> system performance. It <b>can</b> predict the output of a nonlinear system based on the expansion of past inputs and outputs. The model depends on the configuration of the system, and <b>can</b> be defined either by one of the two following equations:", "dateLastCrawled": "2022-02-02T15:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Difference between ANN, CNN and RNN - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/difference-between-ann-cnn-and-rnn/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/<b>difference-between-ann-cnn-and</b>-<b>rnn</b>", "snippet": "Differences between <b>Black</b> <b>Box</b> Testing vs White <b>Box</b> Testing; Stack vs Heap Memory Allocation; Differences between TCP and UDP; Differences between Procedural and Object Oriented Programming ; Differences between JDK, JRE and JVM; Difference between C and C++; Difference between Process and Thread; Difference between Structure and Union in C; Difference between Hardware and Software; Difference between Primary Key and Foreign Key; Web 1.0, Web 2.0 and Web 3.0 with their difference; Difference ...", "dateLastCrawled": "2022-02-02T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Autoregressive neural networks with exogenous variables</b> for indoor ...", "url": "http://www.professeurs.polymtl.ca/jerome.le-ny/docs/journals/2020_Buildings_estimation.pdf", "isFamilyFriendly": true, "displayUrl": "www.professeurs.polymtl.ca/jerome.le-ny/docs/journals/2020_Buildings_estimation.pdf", "snippet": "<b>compared</b> to <b>RNN</b>. An intermediate solution between white-<b>box</b> and <b>black</b>-<b>box</b> approaches is gray-<b>box</b> modeling. Gray-<b>box</b> models are reduced or low-order models that are well documented in the literature, especially for simplified building energy simulation. They <b>can</b> take different designations, such as", "dateLastCrawled": "2022-01-24T07:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>CNN vs RNN</b> | Learn the Top 6 Comparisons between <b>CNN vs RNN</b>", "url": "https://www.educba.com/cnn-vs-rnn/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>cnn-vs-rnn</b>", "snippet": "<b>RNN</b> has fewer features and low capabilities <b>compared</b> to CNN. The interconnection consumes a finite set of input and generates a finite set of output according to the input. <b>RNN</b> <b>can</b> allow arbitrary input length and output length. CNN is a clockwise type of feed-forward artificial neural network with a variety of multiple layers of perception, which is specially designed to utilize the minimum amount of pre-processing. <b>RNN</b> works on a loop network that uses their internal memory to handle the ...", "dateLastCrawled": "2022-02-03T15:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[D] <b>Can</b> attention be computed implicitly by an <b>RNN</b>? : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/bfnhv5/d_can_attention_be_computed_implicitly_by_an_rnn/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../bfnhv5/d_<b>can</b>_attention_be_computed_implicitly_by_an_<b>rnn</b>", "snippet": "[D] Proprietary <b>black</b>-<b>box</b> ML systems for decision-making in society A product, NarxCare, [1] uses ML to predict whether a patient is likely to be abusing prescription medication in the United States. Doctors in several states are legally required to consult NarxCare, and potentially base their decision on the outputted risk score, when prescribing controlled substances to patients.", "dateLastCrawled": "2021-08-15T20:09:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Mathematical understanding of <b>RNN</b> and its variants - <b>GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/mathematical-understanding-of-rnn-and-its-variants/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/mathematical-understanding-of-<b>rnn</b>-and-its-variants", "snippet": "<b>RNN</b> is suitable for such work thanks to their capability of <b>learning</b> the context. Other applications include speech to text conversion, building virtual assistance, time-series stocks forecasting, sentimental analysis, language modelling and <b>machine</b> translation. On the other hand, a feed-forward neural network produces an output which only depends on the current input. Examples for such are image classification task, image segmentation or object detection task. One such type of such network ...", "dateLastCrawled": "2022-01-29T04:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Deep Learning: Models for Sequence Data</b> (<b>RNN</b> and LSTM)", "url": "https://cse.iitk.ac.in/users/piyush/courses/ml_autumn16/771A_lec24_slides.pdf", "isFamilyFriendly": true, "displayUrl": "https://cse.iitk.ac.in/users/piyush/courses/ml_autumn16/771A_lec24_slides.pdf", "snippet": "Filters are like basis/dictionary (PCA <b>analogy</b>) Each lter is convolved over entire input to produce a feature map Nonlinearity and pooling and applied after each convolution layer Last layer (one that connects to outputs) is fully connected <b>Machine</b> <b>Learning</b> (CS771A) <b>Deep Learning: Models for Sequence Data</b> (<b>RNN</b> and LSTM) 3. Recap: Convolutional Neural Network Special type of feedforward neural nets (local connectivity + weight sharing) Each layer uses a set of \\ lters&quot; (basically, weights to ...", "dateLastCrawled": "2022-01-17T20:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> (ML) and Neural Networks (NN)\u2026 An Intuitive ...", "url": "https://medium.com/visionary-hub/machine-learning-ml-and-neural-networks-nn-an-intuitive-walkthrough-76bdaba8b0e3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/visionary-hub/<b>machine</b>-<b>learning</b>-ml-and-neural-networks-nn-an...", "snippet": "A better <b>analogy</b> for unsupervised <b>learning</b>, and one that\u2019s more commonly used, is separating a group of blocks by colour. Suppose we have 10 blocks, each with different coloured faces. In the ...", "dateLastCrawled": "2022-01-30T17:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Chapter 8 Recurrent Neural Networks</b> | Deep <b>Learning</b> and its Applications", "url": "https://frcs.github.io/4C16-LectureNotes/recurrent-neural-networks.html", "isFamilyFriendly": true, "displayUrl": "https://frcs.github.io/4C16-LectureNotes/recurrent-neural-networks.html", "snippet": "In its simplest form, the inner structure of the hidden layer block is simply a dense layer of neurons with \\(\\mathrm{tanh}\\) activation. This is called a simple <b>RNN</b> architecture or Elman network.. We usually take a \\(\\mathrm{tanh}\\) activation as it can produce positive or negative values, allowing for increases and decreases of the state values. Also \\(\\mathrm{tanh}\\) bounds the state values between -1 and 1, and thus avoids a potential explosion of the state values.. The equations for ...", "dateLastCrawled": "2022-02-02T05:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What Are Recurrent Neural Networks? A Complete Guide To RNNs | Built In", "url": "https://builtin.com/data-science/recurrent-neural-networks-powerhouse-language-modeling", "isFamilyFriendly": true, "displayUrl": "https://builtin.com/data-science/recurrent-neural-networks-powerhouse-language-modeling", "snippet": "Obama-<b>RNN</b> (<b>Machine</b> Generated Political Speeches): Here the author used <b>RNN</b> to generate hypothetical political speeches given by Barrack Obama. Taking in over 4.3 MB / 730,895 words of text written by Obama\u2019s speech writers as input, the model generates multiple versions with a wide range of topics including jobs, war on terrorism, democracy, China\u2026 Super hilarious!", "dateLastCrawled": "2022-02-01T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Python <b>RNN</b>: Recurrent Neural Networks for Time Series Forecasting | by ...", "url": "https://towardsdatascience.com/temporal-loops-intro-to-recurrent-neural-networks-for-time-series-forecasting-in-python-b0398963dc1f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/temporal-loops-intro-to-recurrent-neural-networks-for...", "snippet": "We have put a relatively fine-toothed comb to the <b>learning</b> rate, 0.001, and the epochs, 300, in our setup of the <b>RNN</b> model. We could also play with the dropout parameter (to make the <b>RNN</b> try out various subsets of nodes during training); and with the size of the hidden state (a higher hidden dimension value increases the <b>RNN</b>\u2019s capability to deal with more intricate patterns over longer time frames). A tuning algorithm could tweak them while rerunning the fitting process to try to achieve ...", "dateLastCrawled": "2022-02-02T15:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Neural Networks and <b>Deep Learning Coursera Quiz Answers - Solved Assignment</b>", "url": "https://priyadogra.com/neural-networks-and-deep-learning-coursera-quiz-answers-solved-assignment/", "isFamilyFriendly": true, "displayUrl": "https://priyadogra.com/neural-networks-and-<b>deep-learning-coursera-quiz-answers-solved</b>...", "snippet": "Question 8: Why is an <b>RNN</b> (Recurrent Neural Network) used for <b>machine</b> translation, say translating English to French? (Check all that apply.) It can be trained as a supervised <b>learning</b> problem. It is strictly more powerful than a Convolutional Neural Network (CNN). It is applicable when the input/output is a sequence (e.g., a sequence of words).", "dateLastCrawled": "2022-01-26T13:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Gentle Introduction to <b>Long Short-Term Memory</b> Networks by the Experts", "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>long-short-term-memory</b>-networks...", "snippet": "<b>Long Short-Term Memory</b> (LSTM) networks are a type of recurrent neural network capable of <b>learning</b> order dependence in sequence prediction problems. This is a behavior required in complex problem domains like <b>machine</b> translation, speech recognition, and more. LSTMs are a complex area of deep <b>learning</b>. It can be hard to get your hands around what LSTMs are, and how terms like bidirectional", "dateLastCrawled": "2022-01-31T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Coursera: Neural Networks and Deep Learning</b> (Week 1) Quiz [MCQ Answers ...", "url": "https://www.apdaga.com/2019/03/coursera-neural-networks-and-deep-learning-week-1-quiz.html", "isFamilyFriendly": true, "displayUrl": "https://www.apdaga.com/2019/03/<b>coursera-neural-networks-and-deep-learning</b>-week-1-quiz.html", "snippet": "Recommended <b>Machine</b> <b>Learning</b> Courses: ... edX: <b>Machine</b> <b>Learning</b>; Fast.ai: Introduction to <b>Machine</b> <b>Learning</b> for Coders; What does the <b>analogy</b> \u201cAI is the new electricity\u201d refer to? AI runs on computers and is thus powered by electricity, but it is letting computers do things not possible before. Similar to electricity starting about 100 years ago, AI is transforming multiple industries. Correct. Yes. AI is transforming many fields from the car industry to agriculture to supply-chain ...", "dateLastCrawled": "2022-01-30T01:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "deep-<b>learning</b>-coursera/Week 1 Quiz - Introduction to deep <b>learning</b>.md ...", "url": "https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%201%20Quiz%20-%20Introduction%20to%20deep%20learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/Kulbear/deep-<b>learning</b>-coursera/blob/master/Neural Networks and Deep...", "snippet": "Why is an <b>RNN</b> (Recurrent Neural Network) used for <b>machine</b> translation, say translating English to French? (Check all that apply.) It can be trained as a supervised <b>learning</b> problem. It is strictly more powerful than a Convolutional Neural Network (CNN). It is applicable when the input/output is a sequence (e.g., a sequence of words).", "dateLastCrawled": "2022-02-03T05:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to Recurrent Neural Networks | <b>Machine</b> <b>Learning</b> lab", "url": "https://en.mlab.ai/blog/introduction-recurrent-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://en.mlab.ai/blog/introduction-recurrent-neural-networks", "snippet": "The <b>Machine</b> <b>Learning</b> Blog. 09/27/2018. Introduction to Recurrent Neural Networks In this article, I will explain what are Recurrent Neural Networks (RNN), how they work and what you can do with them. I will also show a very cool example of music generation using artificial intelligence. However, before discussing RNN, we need to explain the concept of sequence data. Sequence Data As the name indicates, sequence data is a collection of data in different states through time so it can form ...", "dateLastCrawled": "2022-02-01T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Notes on Recurrent Neural Networks</b> \u2013 humblesoftwaredev", "url": "https://humblesoftwaredev.wordpress.com/2016/12/04/notes-on-recurrent-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://humblesoftwaredev.wordpress.com/2016/12/04/<b>notes-on-recurrent-neural-networks</b>", "snippet": "Recurrent neural nets have states, unlike feed-forward networks. An analogy for RNN is the C strtok function, where calling it with the same parameter typically yields a different value (but of course, unlike strtok, RNN does not modify the input). An analogy for feed-forward networks is a function in the mathematical sense, where y=f(x) regardless of how many times\u2026", "dateLastCrawled": "2022-01-14T08:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning for NLP</b> - Aurelie Herbelot", "url": "http://aurelieherbelot.net/resources/slides/teaching/RNNs.pdf", "isFamilyFriendly": true, "displayUrl": "aurelieherbelot.net/resources/slides/teaching/RNNs.pdf", "snippet": "An RNN, step by step Now we backpropagate through time. We need to compute gradients for three matrices: Why, Whh and Wxh. The gradient of matrix Why is straightforward \u2013 it is simply the sum", "dateLastCrawled": "2021-09-18T14:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "State-of-the-art in artificial <b>neural network applications</b>: A survey ...", "url": "https://www.sciencedirect.com/science/article/pii/S2405844018332067", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2405844018332067", "snippet": "Unlike a recurrent neural network, an <b>RNN is like</b> a hierarchical network where the input need processing hierarchically in the form of a tree because there is no time to the input sequence. 2.4. Deep <b>learning</b>. Artificial intelligence (AI) has existed over many decades, and the field is wide. AI can be view as a set that contains <b>machine</b> <b>learning</b> (ML), and deep <b>learning</b> (DL). The ML is a subset of AI, meanwhile, DL, in turn, a subset of ML. That is DL is an aspect of AI; the term deep ...", "dateLastCrawled": "2022-01-27T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Very simple example of RNN</b>? : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/84bk5r/very_simple_example_of_rnn/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/84bk5r/<b>very_simple_example_of_rnn</b>", "snippet": "basically, an <b>RNN is like</b> a regular layer (the dense layer where all neurons are connected to the next layer&#39;s neurons), except that it takes as an additional paramenter its own output from the previous training iteration.", "dateLastCrawled": "2021-01-08T07:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Deep <b>Learning Approaches for Phantom Movement Recognition</b>", "url": "https://www.researchgate.net/publication/336367291_Deep_Learning_Approaches_for_Phantom_Movement_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/336367291_Deep_<b>Learning</b>_Approaches_for...", "snippet": "<b>RNN is, like</b> MLP, only. have good results for T A WD while other region successes are. far behind other algorithms. For <b>machine</b> <b>learning</b> algorithms, cross validation (k=10) is used to split the ...", "dateLastCrawled": "2022-01-04T05:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Artificial intelligence in drug design: algorithms, applications ...", "url": "https://www.future-science.com/doi/full/10.4155/fdd-2020-0028", "isFamilyFriendly": true, "displayUrl": "https://www.future-science.com/doi/full/10.4155/fdd-2020-0028", "snippet": "The discovery paradigm of drugs is rapidly growing due to advances in <b>machine</b> <b>learning</b> (ML) and artificial intelligence (AI). This review covers myriad faces of AI and ML in drug design. There is a plethora of AI algorithms, the most common of which are summarized in this review. In addition, AI is fraught with challenges that are highlighted along with plausible solutions to them. Examples are provided to illustrate the use of AI and ML in drug discovery and in predicting drug properties ...", "dateLastCrawled": "2022-01-29T02:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "State-of-the-art <b>in artificial neural network applications: A</b> survey", "url": "https://www.researchgate.net/publication/329149409_State-of-the-art_in_artificial_neural_network_applications_A_survey", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/329149409_State-of-the-art_in_artificial...", "snippet": "ANNs are one type of model for <b>machine</b> <b>learning</b> (ML) and has become . relatively competitive to conventional regression and stat istical models regarding. usefulness [1]. Currently, arti \ufb01 cial ...", "dateLastCrawled": "2022-01-29T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Applications of artificial intelligence in water treatment for ...", "url": "https://www.sciencedirect.com/science/article/pii/S1385894721015965", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1385894721015965", "snippet": "k-NN is a simple <b>machine</b> <b>learning</b> technique used for regression and classification. k-NN save all the existing data and perform classification on new data points on the basis of similarity .For example, consider a classification problem having two categories W and Z, as shown in Fig. 2. If a new data point occurred, having a placement issue with W and Z category, the new data point should be placed in a suitable category based on calculating Euclidean distance.", "dateLastCrawled": "2022-02-03T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>The future of AI music is Magenta</b> | DataDrivenInvestor", "url": "https://www.datadriveninvestor.com/2020/04/25/the-future-of-ai-music-is-magenta/", "isFamilyFriendly": true, "displayUrl": "https://www.datadriveninvestor.com/2020/04/25/<b>the-future-of-ai-music-is-magenta</b>", "snippet": "<b>The future of AI music is Magenta</b>. Music seems to be one of the fields that, at a surface level at least, AI just can\u2019t seem to penetrate. AI is rapidly taking over so many fields, and there\u2019s huge progress in music too! There are so many awesome developments (check out the app Transformer) and progress is moving at a breakneck pace.", "dateLastCrawled": "2022-01-28T07:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "End to end <b>machine</b> <b>learning</b> for fault detection and classification in ...", "url": "https://www.sciencedirect.com/science/article/pii/S0378779621004119", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0378779621004119", "snippet": "The training process for <b>RNN is similar</b> to traditional ANNs. However, since the parameters are shared among time instances in RNNs, the back-propagation algorithm for RNNs is termed as Backpropagation through time (BPTT) . As the number of time steps increase in RNN, it faces a problem termed as \u201cvanishing gradients\u201d due to which it cannot retain long term dependencies. Description can be seen in 39,40]. This phenomenon makes RNNs difficult to train and render them impractical in most of ...", "dateLastCrawled": "2021-12-14T22:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "2_tensorflow_lstm", "url": "http://ethen8181.github.io/machine-learning/deep_learning/rnn/2_tensorflow_lstm.html", "isFamilyFriendly": true, "displayUrl": "ethen8181.github.io/<b>machine</b>-<b>learning</b>/deep_<b>learning</b>/rnn/2_tensorflow_lstm.html", "snippet": "Training a <b>RNN is similar</b> to training a traditional Neural Network, we also use the backpropagation algorithm, but with a little twist. Because the parameters are shared by all time steps in the network, the gradient at each output depends not only on the calculations of the current time step, but also the previous time steps. For example, in order to calculate the gradient at t=4 we would need to backpropagate 3 steps and sum up the gradients. This is called Backpropagation Through Time ...", "dateLastCrawled": "2022-02-03T13:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Deep <b>Recurrent Neural Networks</b> with Keras | <b>Paperspace Blog</b>", "url": "https://blog.paperspace.com/advanced-recurrent-neural-networks-deep-rnns/", "isFamilyFriendly": true, "displayUrl": "https://blog.paperspace.com/advanced-<b>recurrent-neural-networks</b>-deep-rnns", "snippet": "The training of a deep <b>RNN is similar</b> to the Backpropagation Through Time (BPTT) algorithm, as in an RNN but with additional hidden units. Now that you\u2019ve got an idea of what a deep RNN is, in the next section we&#39;ll build a music generator using a deep RNN and Keras. Generating Music Using a Deep RNN. Music is the ultimate language. We have been creating and rendering beautiful melodies since time unknown. In this context, do you think a computer can generate musical notes comparable to ...", "dateLastCrawled": "2022-02-03T18:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> - <b>Kbeznak Parmatonic</b>", "url": "https://sites.google.com/view/kbeznak-parmatonic-guru-of-ml/home", "isFamilyFriendly": true, "displayUrl": "https://<b>sites.google.com</b>/view/<b>kbeznak-parmatonic</b>-guru-of-ml/home", "snippet": "Backpropagation in <b>RNN is similar</b> to Neural Network, but we have to take care of the weight with respect to all the time steps. So, the gradient has to be calculated for all those steps going backwards, this is called Backpropagation Through Time(BPTT). Software and Tools: <b>Kbeznak Parmatonic</b> prefers Tensorflow and Caffe2 for deeplearning, and keras would help you lot in the initial stages. Author <b>Kbeznak Parmatonic</b>: Dr. <b>Kbeznak Parmatonic</b>, was a chief scientist at NASA and was well deserved ...", "dateLastCrawled": "2021-12-23T18:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Motor-Imagery BCI System Based on Deep <b>Learning</b> Networks and Its ...", "url": "https://www.intechopen.com/chapters/60241", "isFamilyFriendly": true, "displayUrl": "https://www.intechopen.com/chapters/60241", "snippet": "Training an <b>RNN is similar</b> to training a traditional neural network (TNN). Because RNNs trained by TNN\u2019s style have difficulties in <b>learning</b> long-term dependencies due to the vanishing and exploding gradient problem. LSTMs do not have a fundamentally different architecture from RNNs, but they use a different function to calculate the states in hidden layer. The memory in LSTMs is called cells and can be thought as black boxes that take as input the previous state and current input ...", "dateLastCrawled": "2022-02-02T11:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Review of Vibration-Based Structural Health Monitoring Using Deep <b>Learning</b>", "url": "https://www.mdpi.com/2076-3417/10/5/1680/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2076-3417/10/5/1680/htm", "snippet": "An <b>RNN is similar</b> to recurrent neural networks in that it is good at dealing with sequential data. Recurrent neural networks are also called RNNs in the literature; to distinguish between the architectures, only the recursive neural network is abbreviated as RNN in this paper. An RNN models hierarchical structures in a tree fashion, which is overly time-consuming and costly. This has led to a lack of attention being given to RNNs. Because an RNN processes all information of the input ...", "dateLastCrawled": "2022-01-12T00:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Deep Neural Network</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/deep-neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>deep-neural-network</b>", "snippet": "This dataset is designed for <b>machine</b> <b>learning</b> classification tasks and includes 60,000 training and 10,000 test gray scale images composed of 28-by-28 pixels. Every training and test case is related to one of ten labels (0\u20139). Zalando\u2019s new dataset is mainly the same as the original handwritten digits data. But instead of having images of the digits 0\u20139, Zalando\u2019s data involves images with 10 different fashion products. Hence the dataset is named fashion-MNIST dataset and can be ...", "dateLastCrawled": "2022-01-30T06:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Deep Learning</b> - SlideShare", "url": "https://www.slideshare.net/JunWang5/deep-learning-61493694", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/JunWang5/<b>deep-learning</b>-61493694", "snippet": "\u2022 ClockWork-<b>RNN is similar</b> to a simple RNN with an input, output and hidden layer \u2022 Difference lies in \u2013 The hidden layer is partitioned into g modules each with its own clock rate \u2013 Neurons in faster module are connected to neurons in a slower module RNN applications: time series Koutnik, Jan, et al. &quot;A clockwork rnn.&quot; arXiv preprint arXiv:1402.3511 (2014). A Clockwork RNN Figure 1. CW-RNN architecture is similar to a simple RNN with an input, output and hidden layer. The hidden ...", "dateLastCrawled": "2022-01-31T18:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Deep Learning</b> for Geophysics: Current and Future Trends - Yu - 2021 ...", "url": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021RG000742", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021RG000742", "snippet": "Different from traditional model-driven methods, <b>machine</b> <b>learning</b> (ML) is a type of data-driven approach that trains a regression or classification model through a complex nonlinear mapping with adjustable parameters based on a training data set. The comparison of model-driven and data-driven approaches is summarized in Figure 1. For decades, ML methods have been widely adopted in various geophysical applications, such as exploration geophysics (Huang et al., 2006; Helmy et al., 2010; Jia ...", "dateLastCrawled": "2022-01-31T08:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Different Architecture of Deep <b>Learning</b> Algorithms Extensive number of ...", "url": "https://www.researchgate.net/figure/Different-Architecture-of-Deep-Learning-Algorithms-Extensive-number-of-deep-learning_fig1_324149367", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/Different-Architecture-of-Deep-<b>Learning</b>-Algorithms...", "snippet": "Unlike classical <b>machine</b> <b>learning</b> (support vector <b>machine</b>, k-nearest neighbour, k-mean, etc.) that require a human engineered feature to perform optimally (LeCun, et al., 2015). Over the years ...", "dateLastCrawled": "2022-01-29T15:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Towards deep entity resolution via soft schema matching - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0925231221016635", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231221016635", "snippet": "Technically, TLM is a new fundamental architecture for deep ER, <b>just as RNN</b>. Our work and TLM based approaches falls into different lines of deep ER research, which are orthogonal and complementary to each other. Our major contribution is proposing soft schema mapping and incorporating it into (RNN based) deep ER models, which does not require huge amounts of NLP corpora for pre-training, while TLM based approaches exploit the deeper language understanding capability from tremendously pre ...", "dateLastCrawled": "2022-01-21T02:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Positional encoding, residual connections, padding masks</b>: covering the ...", "url": "https://data-science-blog.com/blog/2021/04/22/positional-encoding-residual-connections-padding-masks-all-the-details-of-transformer-model/", "isFamilyFriendly": true, "displayUrl": "https://data-science-blog.com/blog/2021/04/22/positional-encoding-residual-connections...", "snippet": "Transformer decoder also predicts the output sequences autoregressively one token at a time step, <b>just as RNN</b> decoders. I think it easy to understand this process because RNN decoder generates tokens just as you connect RNN cells one after another, like connecting rings to a chain. In this way it is easy to make sure that generating of one token in only affected by the former tokens. On the other hand, during training Transformer decoders, you input the whole sentence at once. That means ...", "dateLastCrawled": "2022-01-30T16:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> Archives - Data Science Blog", "url": "https://data-science-blog.com/blog/category/main-category/machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://data-science-blog.com/blog/category/main-category/<b>machine</b>-<b>learning</b>", "snippet": "Most <b>machine</b> <b>learning</b> algorithms covered by major introductory textbooks tend to be too deterministic and dependent on the size of data. Many of those algorithms have another \u201cparallel world,\u201d where you can handle inaccuracy in better ways. I hope I can also write about them, and I might prepare another trilogy for such PCA. But I will not disappoint you, like \u201cThe Phantom Menace.\u201d Appendix: making a model of a bunch of grape with ellipsoid berries. If you can control quadratic ...", "dateLastCrawled": "2022-01-05T04:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "1561982779 | PDF | Equity Crowdfunding | Investor", "url": "https://www.scribd.com/document/550868164/1878586842-1561982779", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/550868164/1878586842-1561982779", "snippet": "Scribd is the world&#39;s largest social reading and publishing site.", "dateLastCrawled": "2022-01-25T03:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Recurrent Neural Networks and LSTM explained", "url": "https://dhrubajitdas44.blogspot.com/2018/10/recurrent-neural-networks-and-lstm.html", "isFamilyFriendly": true, "displayUrl": "https://dhrubajitdas44.blogspot.com/2018/10/recurrent-neural-networks-and-lstm.html", "snippet": "A <b>RNN can be thought of as</b> multiple copies of the same network , each passing message to . the next. Because of their internal memory, RNN\u2019s are able to remember important things about the input they received, which enables them to be very precise in predicting what\u2019s coming next. This is the reason why they are the preferred algorithm for sequential data like time series, speech, text, financial data, audio, video, weather and much more because they can form a much deeper understanding ...", "dateLastCrawled": "2022-01-10T10:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Decoding Your Genes</b>. Can Neural Networks Unravel The Secrets\u2026 | by ...", "url": "https://towardsdatascience.com/decoding-your-genes-4a23e89aba98", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>decoding-your-genes</b>-4a23e89aba98", "snippet": "Conceptually, an <b>RNN can be thought of as</b> a connected sequence of feed-forward networks with information passed between them. The information being passed is the hidden-state which represents all the previous inputs to the network. At each step of the RNN, the hidden state generated from the previous step is passed in, as well as the next sequence input. This then returns an output as well as the new hidden state to be passed on again. This allows the RNN to retain a \u2018memory\u2019 of the ...", "dateLastCrawled": "2022-01-26T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "PHC6937-<b>Machine</b> <b>Learning</b>-Guest Lecture", "url": "https://slides.com/benh-hu/phc6937machinelearning", "isFamilyFriendly": true, "displayUrl": "https://slides.com/benh-hu/phc6937<b>machinelearning</b>", "snippet": "<b>Machine</b> <b>learning</b> is predicated on this idea of <b>learning</b> from example ... A <b>RNN can be thought of as</b> the addition of loops to the archetecture of a standard feedforward NN - the output of the network may feedback as an input to the network with the next input vector, and so on The recurrent connections add state or memory to the network and allow it to learn broader abstractions from the input sequences; Reading. PHC6937-<b>Machine</b> <b>Learning</b>-Guest Lecture. By Hui Hu. PHC6937-<b>Machine</b> <b>Learning</b> ...", "dateLastCrawled": "2022-01-25T13:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Using RNNs for <b>Machine Translation</b> | by Aryan Misra | Towards Data Science", "url": "https://towardsdatascience.com/using-rnns-for-machine-translation-11ddded78ddf", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-rnns-for-<b>machine-translation</b>-11ddded78ddf", "snippet": "3. Sequence to Sequence. The RNN takes in an input sequence and outputs a sequence. <b>Machine Translation</b>: an RNN reads a sentence in one language and then outputs it in another. This should help you get a high-level understanding of RNNs, if you want to learn more about the math behind the operations an RNN performs, I recommend you check out ...", "dateLastCrawled": "2022-02-01T23:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Time series prediction of COVID-19 transmission in America using LSTM ...", "url": "https://www.sciencedirect.com/science/article/pii/S2211379721005775", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2211379721005775", "snippet": "The <b>machine</b> <b>learning</b> algorithm XGBoost was employed to build the models to predict the criticality , mortality , and ... RNNs can use their internal state (memory) to process variable length sequences of inputs. A <b>RNN can be thought of as</b> multiple copies of the same network, each passing a message to a successor (see Fig. 4). They might be able to connect previous information to the present task. However, as that gap grows, RNNs become unable to learn to connect the information. The short ...", "dateLastCrawled": "2022-01-24T06:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "[DL] 11. RNN <b>2(Bidirectional, Deep RNN, Long term connection</b>) | by Jun ...", "url": "https://medium.com/jun-devpblog/dl-11-rnn-2-bidirectional-deep-rnn-long-term-connection-8a836a7f2260", "isFamilyFriendly": true, "displayUrl": "https://medium.com/jun-devpblog/dl-11-rnn-<b>2-bidirectional-deep-rnn-long-term</b>...", "snippet": "Basically, Bidirectional <b>RNN can be thought of as</b> two RNNs in a network, one is moving forwards in time and the other one is moving backward and both are contributing to producing output ...", "dateLastCrawled": "2021-08-12T14:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Convolutional Neural Network and RNN</b> for OCR problem.", "url": "https://www.slideshare.net/vishalmishra982/convolutional-neural-network-and-rnn-for-ocr-problem-86087045", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/vishalmishra982/<b>convolutional-neural-network-and-rnn</b>-for...", "snippet": "Sequence-to-Sequence <b>Learning</b> using Deep <b>Learning</b> for Optical Character Recognition. ... <b>RNN can be thought of as</b> multiple copies of the same network, each passing a message to a successor. An unrolled RNN is shown below. \u2022 In fast last few years, there have been incredible success applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioning\u2026. The list goes on. An Unrolled RNN 44. DRAWBACK OF AN RNN \u2022 RNN has a problem of long term ...", "dateLastCrawled": "2022-01-17T23:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A diagram of (a) the RNN and its (b) unrolled version. | Download ...", "url": "https://researchgate.net/figure/A-diagram-of-a-the-RNN-and-its-b-unrolled-version_fig1_342349801", "isFamilyFriendly": true, "displayUrl": "https://researchgate.net/figure/A-diagram-of-a-the-RNN-and-its-b-unrolled-version_fig1...", "snippet": "Download scientific diagram | A diagram of (a) the RNN and its (b) unrolled version. from publication: ML-descent: an optimization algorithm for FWI using <b>machine</b> <b>learning</b> | Full-waveform ...", "dateLastCrawled": "2021-06-06T20:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Remaining useful life prediction of PEMFC based on long short ...", "url": "https://www.researchgate.net/publication/328587416_Remaining_useful_life_prediction_of_PEMFC_based_on_long_short-term_memory_recurrent_neural_networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/328587416_Remaining_useful_life_prediction_of...", "snippet": "LSTM <b>RNN can be thought of as</b> a series of BPNN with equal. Fig. 10 e Prognostic results of LSTM RNN at T. p. \u00bc 550 h. Fig. 11 e System training loss and test loss. Table 3 e Prediction results of ...", "dateLastCrawled": "2022-01-29T16:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>How I Used Deep Learning To Train A Chatbot</b> To Talk Like Me (Sorta ...", "url": "https://adeshpande3.github.io/How-I-Used-Deep-Learning-to-Train-a-Chatbot-to-Talk-Like-Me", "isFamilyFriendly": true, "displayUrl": "https://adeshpande3.github.io/<b>How-I-Used-Deep-Learning-to-Train-a-Chatbot</b>-to-Talk-Like-Me", "snippet": "This paper showed great results in <b>machine</b> translation specifically, but Seq2Seq models have grown to encompass a variety of NLP tasks. ... By this logic, the final hidden state vector of the encoder <b>RNN can be thought of as</b> a pretty accurate representation of the whole input text. The decoder is another RNN, which takes in the final hidden state vector of the encoder and uses it to predict the words of the output reply. Let&#39;s look at the first cell. The cell&#39;s job is to take in the vector ...", "dateLastCrawled": "2022-01-30T02:41:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(rnn)  is like +(black box)", "+(rnn) is similar to +(black box)", "+(rnn) can be thought of as +(black box)", "+(rnn) can be compared to +(black box)", "machine learning +(rnn AND analogy)", "machine learning +(\"rnn is like\")", "machine learning +(\"rnn is similar\")", "machine learning +(\"just as rnn\")", "machine learning +(\"rnn can be thought of as\")", "machine learning +(\"rnn can be compared to\")"]}