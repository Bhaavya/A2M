{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Unsupervised</b> <b>Bidirectional</b> Cross-Modality Adaptation via Deeply ...", "url": "https://www.cse.cuhk.edu.hk/~qdou/papers/2020/[TMI]%20Unsupervised%20Bidirectional%20Cross-Modality%20Adaptation%20via%20Deeply%20Synergistic%20Image%20and%20Feature%20Alignment%20for%20Medical%20Image%20Segmentation.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cse.cuhk.edu.hk/~qdou/papers/2020/[TMI] <b>Unsupervised</b> <b>Bidirectional</b> Cross...", "snippet": "<b>learning</b> in two aspects, i.e., semantic prediction space and generated image space, and incorporating the deeply <b>supervised</b> mechanism on top of the adversarial <b>learning</b>. We conduct extensive experiments of <b>bidirectional</b> cross-modality adaptation between MRI and CT on two multi-class segmentation tasks, i.e., cardiac substructure seg-", "dateLastCrawled": "2022-01-18T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Unsupervised</b> Video Representation <b>Learning</b> by <b>Bidirectional</b> Feature ...", "url": "https://openaccess.thecvf.com/content/WACV2021/papers/Behrmann_Unsupervised_Video_Representation_Learning_by_Bidirectional_Feature_Prediction_WACV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/WACV2021/papers/Behrmann_<b>Unsupervised</b>_Video...", "snippet": "<b>supervised</b> multi-modal video representation <b>learning</b> has shown to be very effective [29], we are interested in RGB-only self-<b>supervised</b> video representation <b>learning</b>. Besides the scienti\ufb01c value of pure vision based models, a practical motivation involves applications where the audio signal is not accessible, e.g. autonomous driving.", "dateLastCrawled": "2021-10-21T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Global-Local <b>Bidirectional Reasoning for Unsupervised Representation</b> ...", "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Rao_Global-Local_Bidirectional_Reasoning_for_Unsupervised_Representation_Learning_of_3D_Point_CVPR_2020_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Rao_Global-Local_<b>Bidirectional</b>...", "snippet": "point cloud representation <b>learning</b> by <b>bidirectional</b> reason-ing between local representations at different abstraction hierarchies in a network and global representation of a 3D object. Our method is simple yet effective, which can be applied to a wide range of deep <b>learning</b> methods for point cloud understanding. While most existing <b>unsupervised</b> <b>learning</b> methods focus on exploiting structure information by <b>learning</b> various autoencoders, our method aims to cap-ture the underlying semantic ...", "dateLastCrawled": "2022-02-02T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Fast and Accurate Deep <b>Bidirectional</b> Language Representations for ...", "url": "https://aclanthology.org/2020.acl-main.76.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2020.acl-main.76.pdf", "snippet": "Fast and Accurate Deep <b>Bidirectional</b> Language Representations for <b>Unsupervised</b> <b>Learning</b> Joongbo Shin, Yoonhyung Lee, Seunghyun Yoon, Kyomin Jung Seoul National University Republic of Korea fjbshin, cpi1234, mysmilish, kjungg@snu.ac.kr Abstract Even though BERT has achieved success- ful performance improvements in various <b>su-pervised</b> <b>learning</b> tasks, BERT is still lim-ited by repetitive inferences on <b>unsupervised</b> tasks for the computation of contextual lan-guage representations. To resolve ...", "dateLastCrawled": "2022-02-02T10:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bidirectional GAN</b> - The latest in Machine <b>Learning</b> | Papers With Code", "url": "https://paperswithcode.com/method/bigan", "isFamilyFriendly": true, "displayUrl": "https://paperswithcode.com/method/bigan", "snippet": "A BiGAN, or <b>Bidirectional GAN</b>, is a type of generative adversarial network where the generator not only maps latent samples to generated data, but also has an inverse mapping from data to the latent representation. The motivation is to make a type of GAN that can learn rich representations for us in applications <b>like</b> <b>unsupervised</b> <b>learning</b>.", "dateLastCrawled": "2022-02-03T14:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Collaborative <b>Learning</b> of <b>Bidirectional</b> Decoders for <b>Unsupervised</b> Text ...", "url": "https://aclanthology.org/2021.emnlp-main.729.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.emnlp-main.729.pdf", "snippet": "Collaborative <b>Learning</b> of <b>Bidirectional</b> Decoders for <b>Unsupervised</b> Text Style Transfer Yun Ma 1, Yangbin Chen 2, Xudong Mao3, Qing Li 1Department of Computing, The Hong Kong Polytechnic University 2Department of Information Engineering, The Chinese University of Hong Kong 3Department of Arti\ufb01cial Intelligence, Xiamen University mayun371@gmail.com, dongyiwu92@gmail.com xudong.xdmao@gmail.com, csqli@comp.polyu.edu.hk Abstract <b>Unsupervised</b> text style transfer aims to alter the underlying style ...", "dateLastCrawled": "2022-01-30T06:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[2004.08097] Fast and Accurate Deep <b>Bidirectional</b> Language ...", "url": "https://arxiv.org/abs/2004.08097", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2004.08097", "snippet": "Even though BERT achieves successful performance improvements in various <b>supervised</b> <b>learning</b> tasks, applying BERT for <b>unsupervised</b> tasks still holds a limitation that it requires repetitive inference for computing contextual language representations. To resolve the limitation, we propose a novel deep <b>bidirectional</b> language model called Transformer-based Text Autoencoder (T-TA). The T-TA computes contextual language representations without repetition and has benefits of the deep <b>bidirectional</b> ...", "dateLastCrawled": "2021-08-12T12:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Semi-supervised learning with Bidirectional GANs</b> | DeepAI", "url": "https://deepai.org/publication/semi-supervised-learning-with-bidirectional-gans", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>semi-supervised-learning-with-bidirectional-gans</b>", "snippet": "<b>Semi-supervised learning with Bidirectional GANs</b>. 11/28/2018 . \u2219. by Maciej Zamorski, et al. \u2219. Politechnika \u2219. 0 \u2219. share In this work we introduce a novel approach to train <b>Bidirectional</b> Generative Adversarial Model (BiGAN) in a semi-<b>supervised</b> manner. The presented method utilizes triplet loss function as an additional component of the objective function used to train discriminative data representation in the latent space of the BiGAN model. This representation can be further used ...", "dateLastCrawled": "2022-02-01T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Self-<b>Supervised</b> <b>Learning</b>", "url": "http://cs229.stanford.edu/notes2021spring/notes2021spring/cs229_lecture_selfsupervision_final.pdf", "isFamilyFriendly": true, "displayUrl": "cs229.stanford.edu/notes2021spring/notes2021spring/cs229_lecture_selfsupervision_final.pdf", "snippet": "\u2022Self-<b>supervised</b> <b>learning</b> (informal definition): supervise using labels generated ... \u2022<b>Bidirectional</b>, pretrained language representations \u2022Initializes fulldownstream model 13. Word Embeddings \u2022Goal: represent words as vectors for input into neural networks. \u2022One-hot vectors? (single 1, rest 0s) pizza = [0 0 0 0 0 1 0 \u2026 0 0 0 0 0 ] pie = [0 0 0 0 0 0 0 \u2026 0 0 0 1 0 ] \u2639Millions of words high-dimensional, sparse vectors \u2639No notion of word similarity \u2022Instead: we want a dense ...", "dateLastCrawled": "2022-01-29T18:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Intelligent fault diagnosis under small sample size conditions via ...", "url": "https://www.sciencedirect.com/science/article/pii/S0950705121007504", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0950705121007504", "snippet": "In this work, we proposed an <b>unsupervised</b> representation <b>learning</b> method called <b>Bidirectional</b> InfoMax GAN (BIMGAN), which can perform fast and effective feature extraction and fault recognition with few samples. First, we obtain the low-dimensional feature representation by a prior normalized encoder and reconstruction of the sample via the generator. Second, the mapping relationship between the sample and its corresponding feature representation is learned by maximizing mutual information ...", "dateLastCrawled": "2022-01-16T15:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Unsupervised</b> Video Representation <b>Learning</b> by <b>Bidirectional</b> Feature ...", "url": "https://openaccess.thecvf.com/content/WACV2021/papers/Behrmann_Unsupervised_Video_Representation_Learning_by_Bidirectional_Feature_Prediction_WACV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/WACV2021/papers/Behrmann_<b>Unsupervised</b>_Video...", "snippet": "<b>supervised</b> multi-modal video representation <b>learning</b> has shown to be very effective [29], we are interested in RGB-only self-<b>supervised</b> video representation <b>learning</b>. Besides the scienti\ufb01c value of pure vision based models, a practical motivation involves applications where the audio signal is not accessible, e.g. autonomous driving.", "dateLastCrawled": "2021-10-21T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Attention in Neural Networks - 22. BERT (1) Introduction to BERT ...", "url": "https://buomsoo-kim.github.io/attention/2020/07/24/Attention-mechanism-22.md/", "isFamilyFriendly": true, "displayUrl": "https://buomsoo-kim.github.io/attention/2020/07/24/Attention-mechanism-22.md", "snippet": "<b>Supervised</b> <b>learning</b> and <b>unsupervised</b> <b>learning</b>. In the abstract, BERT combines <b>unsupervised</b> <b>learning</b> and <b>supervised</b> <b>learning</b> to provide a generic language model that can be used for virtually any NLP task. Many of you would know, but just for recap, <b>unsupervised</b> <b>learning</b> is inferring patterns in the data without a definite target label.", "dateLastCrawled": "2022-01-26T13:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Combining <b>Supervised</b> and <b>Unsupervised</b> <b>Learning</b> Algorithms for Human ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473063/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8473063", "snippet": "The method combines <b>supervised</b> and <b>unsupervised</b> <b>learning</b> algorithms in order to provide qualitative results and performance in real time. The proposed method involves a two-stage framework: the first stage applies an <b>unsupervised</b> clustering technique to group up activities based on their similarity, while the second stage classifies data assigned to each group using graph convolutional networks. Different clustering techniques and data augmentation strategies are explored for improving the ...", "dateLastCrawled": "2022-01-27T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bidirectional Learning for Domain Adaptation of Semantic Segmentation</b>", "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Bidirectional_Learning_for_Domain_Adaptation_of_Semantic_Segmentation_CVPR_2019_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_<b>Bidirectional</b>_<b>Learning</b>_for...", "snippet": "with <b>supervised</b> <b>learning</b>. In this paper, we propose a novel <b>bidirectional</b> <b>learning</b> framework for domain adap-tation of segmentation. Using the <b>bidirectional</b> <b>learning</b>, the image translation model and the segmentation adap-tation model can be learned alternatively and promote to each other. Furthermore, we propose a self-<b>supervised</b> <b>learning</b> algorithm to learn a better segmentation adap-tation model and in return improve the image translation model. Experiments show that our method is superior ...", "dateLastCrawled": "2022-01-30T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>UNSUPERVISED MACHINE-LEARNING</b>", "url": "https://people.minesparis.psl.eu/fabien.moutarde/ES_MachineLearning/Slides/UNSUPERVISED-learning_course_2pp.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.minesparis.psl.eu/.../Slides/<b>UNSUPERVISED</b>-<b>learning</b>_course_2pp.pdf", "snippet": "<b>Supervised</b> vs <b>UNsupervised</b> <b>learning</b> <b>Learning</b> is called &quot;<b>supervised</b> &quot;when there are &quot;target&quot; values for every example in training dataset: examples = (input-output) = (x 1,y 1),(x 2,y 2), \u2026,(x n,y n) The goal is to build a (generally non-linear) approximate model for interpolation, in order to be able to GENERALIZE to input values other than those in training set &quot;<b>Unsupervised</b> &quot;= when there are NO target values: dataset = {x 1, x 2, \u2026 , x n} The goal is typically either to do datamining ...", "dateLastCrawled": "2022-01-16T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Collaborative <b>Learning</b> of <b>Bidirectional</b> Decoders for <b>Unsupervised</b> Text ...", "url": "https://aclanthology.org/2021.emnlp-main.729.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.emnlp-main.729.pdf", "snippet": "Collaborative <b>Learning</b> of <b>Bidirectional</b> Decoders for <b>Unsupervised</b> Text Style Transfer Yun Ma 1, Yangbin Chen 2, Xudong Mao3, Qing Li 1Department of Computing, The Hong Kong Polytechnic University 2Department of Information Engineering, The Chinese University of Hong Kong 3Department of Arti\ufb01cial Intelligence, Xiamen University mayun371@gmail.com, dongyiwu92@gmail.com xudong.xdmao@gmail.com, csqli@comp.polyu.edu.hk Abstract <b>Unsupervised</b> text style transfer aims to alter the underlying style ...", "dateLastCrawled": "2022-01-30T06:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Is Bert <b>supervised</b> or <b>unsupervised</b>?", "url": "https://philosophy-question.com/library/lecture/read/218246-is-bert-supervised-or-unsupervised", "isFamilyFriendly": true, "displayUrl": "https://philosophy-question.com/.../lecture/read/218246-is-bert-<b>supervised</b>-or-<b>unsupervised</b>", "snippet": "What is BERT?BERT, which stands for <b>Bidirectional</b> Encoder Representations from Transformers, is a neural network-based technique for natural language processing pre-training.In plain English, it can be used to help Google better discern the context of words in search queries.. What are Pretrained models? What is a Pre-trained Model?Simply put, a pre-trained model is a model created by some one else to solve a <b>similar</b> problem. Instead of building a model from scratch to solve a <b>similar</b> ...", "dateLastCrawled": "2022-01-23T15:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Semi-supervised learning with Bidirectional GANs</b> | DeepAI", "url": "https://deepai.org/publication/semi-supervised-learning-with-bidirectional-gans", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>semi-supervised-learning-with-bidirectional-gans</b>", "snippet": "<b>Semi-supervised learning with Bidirectional GANs</b>. 11/28/2018 . \u2219. by Maciej Zamorski, et al. \u2219. Politechnika \u2219. 0 \u2219. share In this work we introduce a novel approach to train <b>Bidirectional</b> Generative Adversarial Model (BiGAN) in a semi-<b>supervised</b> manner. The presented method utilizes triplet loss function as an additional component of the objective function used to train discriminative data representation in the latent space of the BiGAN model. This representation can be further used ...", "dateLastCrawled": "2022-02-01T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Self-<b>Supervised</b> <b>Learning</b>", "url": "http://cs229.stanford.edu/notes2021spring/notes2021spring/cs229_lecture_selfsupervision_final.pdf", "isFamilyFriendly": true, "displayUrl": "cs229.stanford.edu/notes2021spring/notes2021spring/cs229_lecture_selfsupervision_final.pdf", "snippet": "\u2022Self-<b>supervised</b> <b>learning</b> (informal definition): supervise using labels generated ... \u2022<b>Bidirectional</b>, pretrained language representations \u2022Initializes fulldownstream model 12. Examples of Self-Supervision in NLP \u2022Word embeddings \u2022Pretrained word representations \u2022Initializes 1st layer of downstream models \u2022Language models \u2022Unidirectional, pretrained language representations \u2022Initializes fulldownstream model \u2022Masked language models \u2022<b>Bidirectional</b>, pretrained language repr", "dateLastCrawled": "2022-01-29T18:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Learning</b> decomposed subspaces for <b>supervised</b> <b>bidirectional</b> image ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ccs.2019.0009", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ccs.2019.0009", "snippet": "Illustration of the <b>supervised</b> <b>bidirectional</b> image generation task. Given a photo and a sketch, we aim to synthesise a novel pair of sketch and photo that (i) the synthesised photo image (third column) has <b>similar</b> colour and texture as the given photo (first column), while the shape comes from the input sketch (second column); (ii) the synthesised sketch image (fourth column) has the corresponding colour property as the given sketch (second column), while the shape follows the input photo ...", "dateLastCrawled": "2021-12-03T11:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Supervised</b> vs <b>Unsupervised</b> <b>Learning</b>", "url": "https://devopedia.org/supervised-vs-unsupervised-learning", "isFamilyFriendly": true, "displayUrl": "https://devopedia.org/<b>supervised</b>-vs-<b>unsupervised</b>-<b>learning</b>", "snippet": "<b>Supervised</b> <b>Learning</b> <b>can</b> be broadly classified into Classification and Regression problems. Classification problems use algorithms to allot the data into categories such as true-false or some specific categories like apple-oranges etc. Classification of an email as Spam or not is an example. Support Vector Machine and Decision Tree, etc are some classification algorithms.", "dateLastCrawled": "2022-02-02T23:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Unsupervised</b> <b>Learning</b>: Autoencoders - Yunsheng B", "url": "http://yunshengb.com/wp-content/uploads/2018/04/0412018_unsupervised_learning_autoencoders.pdf", "isFamilyFriendly": true, "displayUrl": "yunshengb.com/wp-content/uploads/2018/04/0412018_<b>unsupervised</b>_<b>learning</b>_autoencoders.pdf", "snippet": "<b>can</b> leverage <b>unsupervised</b> or semi-<b>supervised</b> <b>learning</b>.) There are other tasks where we do still use autoencoders, but they\u2019re not the fundamental solution to training deep nets that people once <b>thought</b> they were going to be.", "dateLastCrawled": "2022-01-27T23:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bidirectional</b> Active <b>Learning</b>: A Two-Way Exploration Into Unlabeled and ...", "url": "https://d1b10bmlvqabco.cloudfront.net/attach/jqpg7shaoyy1cn/jqztu8w6QVFz/jrc65cmv35l3/Bidirectional_Active_Learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://d1b10bmlvqabco.cloudfront.net/.../jrc65cmv35l3/<b>Bidirectional</b>_Active_<b>Learning</b>.pdf", "snippet": "Index Terms\u2014Active <b>learning</b>, <b>bidirectional</b> exploration, generalization performance, noisy data, selective sampling. I. INTRODUCTION W ITH the remarkable progress in computer science and arti\ufb01cial intelligence, machine <b>learning</b> is thriving as the computational process of extracting patterns in data and making predictions based on the experience gained from these patterns [1]\u2013[6]. Classic machine <b>learning</b> <b>can</b> be divided into two types: 1) <b>supervised</b> <b>learning</b> and 2) <b>unsupervised</b> <b>learning</b> ...", "dateLastCrawled": "2022-01-05T19:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Neural Networks (AI) MCQ Questions &amp; Answers - Letsfindcourse", "url": "https://letsfindcourse.com/ai-mcq-questions/neural-networks-mcq-questions-ai", "isFamilyFriendly": true, "displayUrl": "https://letsfindcourse.com/ai-mcq-questions/neural-networks-mcq-questions-ai", "snippet": "A. unidirectional B. <b>bidirectional</b> C. multidirectional D. All of the above. View Answer 13. Which of the following is not an Machine <b>Learning</b> strategies in ANNs? A. <b>Unsupervised</b> <b>Learning</b> B. Reinforcement <b>Learning</b> C. Supreme <b>Learning</b> D. <b>Supervised</b> <b>Learning</b> . View Answer. 14. Which of the following is an Applications of Neural Networks? A. Automotive B. Aerospace C. Electronics D. All of the above. View Answer. 15. What is perceptron? A. a single layer feed-forward <b>neural network</b> with pre ...", "dateLastCrawled": "2022-02-02T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Review: Semi-<b>Supervised</b> Sequence Tagging with <b>Bidirectional</b> Language ...", "url": "https://sh-tsang.medium.com/review-semi-supervised-sequence-tagging-with-bidirectional-language-models-taglm-15485e98d15", "isFamilyFriendly": true, "displayUrl": "https://sh-tsang.medium.com/review-semi-<b>supervised</b>-sequence-tagging-with-<b>bidirectional</b>...", "snippet": "Besides language problem, it <b>can</b> also be used in DNA sequence tagging for A, C, G, T. Language-Model Augmented Sequence Tagger (TagLM) is proposed where pretrained context embeddings from <b>bidirectional</b> language models are added to NLP systems and particularly applied to sequence labeling tasks. This is a paper in 2017 ACL with over 500 citations.", "dateLastCrawled": "2022-01-27T21:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Unsupervised Deep Learning</b> - GitHub Pages", "url": "https://ranzato.github.io/publications/tutorial_deep_unsup_learning_part2_NeurIPS2018.pdf", "isFamilyFriendly": true, "displayUrl": "https://ranzato.github.io/publications/tutorial_deep_unsup_<b>learning</b>_part2_NeurIPS2018.pdf", "snippet": "\u2022 In general, still a seizable gap between <b>unsupervised</b> feature <b>learning</b> and <b>supervised</b> <b>learning</b> in vision. ... skip-<b>thought</b> . word2vec T. Mikolov et al. \u201cEf\ufb01cient estimation of word representations in vector space\u201d arXiv 2013 \u201cAll of the sudden a cat jumped from a tree to chase a mouse.\u201d The meaning of a word is determined by its context. 33. word2vec T. Mikolov et al. \u201cEf\ufb01cient estimation of word representations in vector space\u201d arXiv 2013 \u201cAll of the sudden a __ jumped ...", "dateLastCrawled": "2022-02-02T15:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "Explanation: Pattern classification involves <b>supervised</b> <b>learning</b> while grouping is an <b>unsupervised</b> one. 9. Does for feature mapping there\u2019s need of <b>supervised</b> <b>learning</b>? a) yes b) no Answer: b Explanation: Feature mapping <b>can</b> be <b>unsupervised</b>, so it\u2019s not a sufficient condition. 10. Example of a <b>unsupervised</b> feature map? a) text recognition", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "300+ TOP <b>Neural Networks Multiple Choice Questions and Answers</b>", "url": "https://engineeringinterviewquestions.com/neural-networks-multiple-choice-questions-and-answers/", "isFamilyFriendly": true, "displayUrl": "https://engineeringinterviewquestions.com/<b>neural-networks-multiple-choice-questions</b>...", "snippet": "a) <b>Supervised</b> <b>learning</b> b) <b>Unsupervised</b> <b>learning</b> c) Active <b>learning</b> d) Reinforcement <b>learning</b>. Answer: a Explanation: In automatic vehicle set of vision inputs and corresponding actions are available to learner hence it\u2019s an example of <b>supervised</b> <b>learning</b>. 25. Following is an example of active <b>learning</b>: a) News recommendation system b) Dust ...", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Emotion Recognition from Speech: An <b>Unsupervised</b> <b>Learning</b> Approach ...", "url": "https://www.atlantis-press.com/journals/ijcis/125945494/view", "isFamilyFriendly": true, "displayUrl": "https://www.atlantis-press.com/journals/ijcis/125945494/view", "snippet": "Though the obtained classification results may be lower than those that should have been provided by <b>supervised</b> <b>learning</b>, the obtained rates <b>can</b> be considered as satisfactory in the framework of <b>unsupervised</b> <b>learning</b>. In fact, cluster labeling has been utilized in this work only to check the performance. However, in real-world application of the proposed method, the data need not be entirely labeled, hence obtaining an overall accuracy of about 60% might be encouraging. A deeper analysis of ...", "dateLastCrawled": "2022-01-18T03:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[<b>MCQ] Soft Computing</b> - Last Moment Tuitions", "url": "https://lastmomenttuitions.com/mcq-soft-computing/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcq-soft-computing</b>", "snippet": "26.Membership function <b>can</b> <b>be thought</b> of as a technique to solve empirical problems on the basis of a) knowledge b) example c) <b>learning</b> d) experience Ans: D. 27.Three main basic features involved in characterizing membership function are a)Intution, Inference, Rank Ordering b)Fuzzy Algorithm, Neural network, Genetic Algorithm c)Core, Support , Boundary d)Weighted Average, center of Sums, Median Ans : C. 28. A fuzzy set whose membership function has at least one element x in the universe ...", "dateLastCrawled": "2022-02-02T15:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Supervised</b> vs <b>Unsupervised</b> <b>Learning</b>", "url": "https://devopedia.org/supervised-vs-unsupervised-learning", "isFamilyFriendly": true, "displayUrl": "https://devopedia.org/<b>supervised</b>-vs-<b>unsupervised</b>-<b>learning</b>", "snippet": "<b>Supervised</b> <b>Learning</b> <b>can</b> be broadly classified into Classification and Regression problems. Classification problems use algorithms to allot the data into categories such as true-false or some specific categories like apple-oranges etc. Classification of an email as Spam or not is an example. Support Vector Machine and Decision Tree, etc are some classification algorithms.", "dateLastCrawled": "2022-02-02T23:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Unsupervised</b> Video Representation <b>Learning</b> by <b>Bidirectional</b> Feature ...", "url": "https://openaccess.thecvf.com/content/WACV2021/papers/Behrmann_Unsupervised_Video_Representation_Learning_by_Bidirectional_Feature_Prediction_WACV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/WACV2021/papers/Behrmann_<b>Unsupervised</b>_Video...", "snippet": "<b>supervised</b> multi-modal video representation <b>learning</b> has shown to be very effective [29], we are interested in RGB-only self-<b>supervised</b> video representation <b>learning</b>. Besides the scienti\ufb01c value of pure vision based models, a practical motivation involves applications where the audio signal is not accessible, e.g. autonomous driving.", "dateLastCrawled": "2021-10-21T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bidirectional Learning for Domain Adaptation of Semantic Segmentation</b>", "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Bidirectional_Learning_for_Domain_Adaptation_of_Semantic_Segmentation_CVPR_2019_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_<b>Bidirectional</b>_<b>Learning</b>_for...", "snippet": "<b>Bidirectional Learning for Domain Adaptation of Semantic Segmentation</b> ... or yield not so good performance <b>compared</b> with <b>supervised</b> <b>learning</b>. In this paper, we propose a novel <b>bidirectional</b> <b>learning</b> framework for domain adap-tation of segmentation. Using the <b>bidirectional</b> <b>learning</b>, the image translation model and the segmentation adap-tation model <b>can</b> be learned alternatively and promote to each other. Furthermore, we propose a self-<b>supervised</b> <b>learning</b> algorithm to learn a better ...", "dateLastCrawled": "2022-01-30T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>Bidirectional</b> Transformer Based Alignment Model for <b>Unsupervised</b> Word ...", "url": "https://aclanthology.org/2021.acl-long.24.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.acl-long.24.pdf", "snippet": "<b>Compared</b> to these <b>supervised</b> methods, our method does not require gold human alignments for model training. 4 Our Approach We present a <b>bidirectional</b> Transformer based align-ment (BTBA) model for <b>unsupervised</b> <b>learning</b> of the word alignment task. Motivated by BERT which learns a masked language model (Devlin et al.,2019), we randomly mask 10% of the words in the target sentence and then train our BTBA model to predict the masked target words by pay- ing attention to the source context and ...", "dateLastCrawled": "2022-01-28T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Unsupervised</b> <b>Bidirectional</b> Cross-Modality Adaptation via Deeply ...", "url": "https://www.cse.cuhk.edu.hk/~qdou/papers/2020/[TMI]%20Unsupervised%20Bidirectional%20Cross-Modality%20Adaptation%20via%20Deeply%20Synergistic%20Image%20and%20Feature%20Alignment%20for%20Medical%20Image%20Segmentation.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cse.cuhk.edu.hk/~qdou/papers/2020/[TMI] <b>Unsupervised</b> <b>Bidirectional</b> Cross...", "snippet": "<b>learning</b> in two aspects, i.e., semantic prediction space and generated image space, and incorporating the deeply <b>supervised</b> mechanism on top of the adversarial <b>learning</b>. We conduct extensive experiments of <b>bidirectional</b> cross-modality adaptation between MRI and CT on two multi-class segmentation tasks, i.e., cardiac substructure seg-", "dateLastCrawled": "2022-01-18T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Combining <b>Supervised</b> and <b>Unsupervised</b> <b>Learning</b> Algorithms for Human ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8473063/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8473063", "snippet": "The method combines <b>supervised</b> and <b>unsupervised</b> <b>learning</b> algorithms in order to provide qualitative results and performance in real time. The proposed method involves a two-stage framework: the first stage applies an <b>unsupervised</b> clustering technique to group up activities based on their similarity, while the second stage classifies data assigned to each group using graph convolutional networks. Different clustering techniques and data augmentation strategies are explored for improving the ...", "dateLastCrawled": "2022-01-27T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Comparison of <b>Supervised</b> and <b>Unsupervised</b> Deep <b>Learning</b> Methods for ...", "url": "https://downloads.hindawi.com/journals/bmri/2020/5193707.pdf", "isFamilyFriendly": true, "displayUrl": "https://downloads.hindawi.com/journals/bmri/2020/5193707.pdf", "snippet": "Among all these methods, deep <b>learning</b> method exhibited superior ability of <b>learning</b> a nonlinear mapping from one image domain to another image domain. It <b>can</b> be classi-\ufb01ed into two categories: <b>supervised</b> and <b>unsupervised</b> deep <b>learning</b> methods. <b>Supervised</b> deep <b>learning</b> methods required paired images for model training. In the MR/CT", "dateLastCrawled": "2022-01-31T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Unsupervised Learning of Particle Image Velocimetry</b> | DeepAI", "url": "https://deepai.org/publication/unsupervised-learning-of-particle-image-velocimetry", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>unsupervised-learning-of-particle-image-velocimetry</b>", "snippet": "<b>Supervised</b> and <b>unsupervised</b> <b>learning</b> are two different <b>learning</b> approaches. The key difference is that <b>supervised</b> <b>learning</b> requires ground truth data while <b>unsupervised</b> <b>learning</b> does not. 2.1 <b>Supervised</b> <b>learning</b> methods. End-to-end <b>supervised</b> <b>learning</b> using neural networks for PIV was first introduced by Rabault et al. in . A convolutional neural network and a fully-connected neural network were trained to perform PIV on several test cases. That work provided a proof-of-concept for the ...", "dateLastCrawled": "2021-12-29T17:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Learning</b> decomposed subspaces for <b>supervised</b> <b>bidirectional</b> image ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ccs.2019.0009", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ccs.2019.0009", "snippet": "Illustration of the <b>supervised</b> <b>bidirectional</b> image generation task. Given a photo and a sketch, we aim to synthesise a novel pair of sketch and photo that (i) the synthesised photo image (third column) has similar colour and texture as the given photo (first column), while the shape comes from the input sketch (second column); (ii) the synthesised sketch image (fourth column) has the corresponding colour property as the given sketch (second column), while the shape follows the input photo ...", "dateLastCrawled": "2021-12-03T11:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Neural Network Learning Rules</b> \u2013 Perceptron &amp; Hebbian <b>Learning</b>", "url": "https://www.softwaretestinghelp.com/neural-network-learning-rules/", "isFamilyFriendly": true, "displayUrl": "https://www.softwaretestinghelp.com/<b>neural-network-learning-rules</b>", "snippet": "The net input is <b>compared</b> with the threshold to get the output. In NN, the activation function is defined based on the threshold value and output is calculated. The threshold value is: #4) <b>Learning</b> Rate: It is denoted by alpha ?. The <b>learning</b> rate ranges from 0 to 1. It is used for weight adjustment during the <b>learning</b> process of NN. #5) Momentum Factor: It is added for faster convergence of results. The momentum factor is added to the weight and is generally used in backpropagation networks ...", "dateLastCrawled": "2022-02-02T22:20:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Gentle Introduction to <b>Long Short-Term Memory</b> Networks by the Experts", "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>long-short-term-memory</b>-networks...", "snippet": "<b>Long Short-Term Memory</b> (LSTM) networks are a type of recurrent neural network capable of <b>learning</b> order dependence in sequence prediction problems. This is a behavior required in complex problem domains like <b>machine</b> translation, speech recognition, and more. LSTMs are a complex area of deep <b>learning</b>. It can be hard to get your hands around what LSTMs are, and how terms like <b>bidirectional</b>", "dateLastCrawled": "2022-01-31T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning for Trading</b>", "url": "https://ml4trading.io/chapter/15", "isFamilyFriendly": true, "displayUrl": "https://ml4trading.io/chapter/15", "snippet": "Key characteristics of these models are - the use of <b>bidirectional</b> language models that process text both left-to-right and right-to-left for a richer context representation, and - the use of semi-supervised pretraining on a large generic corpus to learn universal language aspects in the form of embeddings and network weights that can be used end fine-tuned for specific tasks", "dateLastCrawled": "2022-01-25T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The language of <b>proteins: NLP, machine learning &amp; protein sequences</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S2001037021000945", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2001037021000945", "snippet": "By this <b>analogy</b>, common protein motifs and domains, which are the basic functional building blocks of proteins, ... ELMO uses representations derived from the hidden states of <b>bidirectional</b> LSTMs. CoVe is a seq2seq model with attention, originally developed for language translation. A CoVe model pretrained on translation was then used on other NLP tasks. There have been works using contextualized embedding models (e.g. ELMO) on proteins for supervised-<b>learning</b> tasks (such as GO annotation ...", "dateLastCrawled": "2022-02-03T02:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>learning</b> fundamentals (I): Cost functions and gradient descent ...", "url": "https://conorsdatablog.wordpress.com/2017/11/27/understanding-machine-learning-fundamentals-via-linear-regression/", "isFamilyFriendly": true, "displayUrl": "https://conorsdatablog.wordpress.com/2017/11/27/understanding-<b>machine</b>-<b>learning</b>...", "snippet": "In this post I\u2019ll use a simple linear regression model to explain some <b>machine</b> <b>learning</b> (ML) fundamentals. The linear regression isn\u2019t the most powerful model in the ML tool kit, but due to its familiarity and interpretability, it is still in widespread use in research and industry. Simply, linear regression is used to estimate linear relationships between continuous or/and categorical data and a continuous output variable. As I go through this post, I\u2019ll use X and y to refer to ...", "dateLastCrawled": "2022-01-26T14:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Introduction to <b>Machine Learning</b> Algorithms: <b>Linear Regression</b> | by ...", "url": "https://towardsdatascience.com/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-<b>machine-learning</b>-algorithms-linear...", "snippet": "The rudimental algorithm that every <b>Machine Learning</b> enthusiast starts with is a <b>linear regression</b> algorithm. Therefore, we shall do the same as it provides a base for us to build on and learn other ML algorithms. What is <b>linear regression</b>?? Before knowing what is <b>linear regression</b>, let us get ourselves accustomed to <b>regression</b>. <b>Regression</b> is a method of modelling a target value based on independent predictors. This method is mostly used for forecasting and finding out cause and effect ...", "dateLastCrawled": "2022-02-02T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Word</b> <b>Embeddings</b> for NLP. Understanding <b>word</b> <b>embeddings</b> and their\u2026 | by ...", "url": "https://towardsdatascience.com/word-embeddings-for-nlp-5b72991e01d4", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>word</b>-<b>embeddings</b>-for-nlp-5b72991e01d4", "snippet": "In this article, we will understand how to process text for usage in <b>machine</b> <b>learning</b> algorithms. What are <b>embeddings</b> and why are they used for text processing? word2vec and GloVe <b>word</b> <b>embeddings</b>. Natural Language Processing(NLP) refers to computer systems designed to understand human language. Human language, like English or Hindi consists of words and sentences, and NLP attempts to extract information from these sentences. A few of the tasks that NLP is used for. Text summarization ...", "dateLastCrawled": "2022-02-02T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Dive into Deep <b>Learning</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "http://d2l.ai/", "isFamilyFriendly": true, "displayUrl": "d2l.ai", "snippet": "Dive into Deep <b>Learning</b>. Interactive deep <b>learning</b> book with code, math, and discussions. Implemented with NumPy/MXNet, PyTorch, and TensorFlow. Adopted at 200 universities from 50 countries.", "dateLastCrawled": "2022-01-30T00:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Sequence Classification with LSTM Recurrent Neural Networks in Python ...", "url": "https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/sequence-classification-", "snippet": "How to Develop a <b>Bidirectional</b> LSTM For Sequence\u2026 How to Develop an Encoder-Decoder Model with\u2026 About Jason Brownlee Jason Brownlee, PhD is a <b>machine</b> <b>learning</b> specialist who teaches developers how to get results with modern <b>machine</b> <b>learning</b> methods via hands-on tutorials. View all posts by Jason Brownlee \u2192 How To Use Classification <b>Machine</b> <b>Learning</b> Algorithms in Weka. How to Use Ensemble <b>Machine</b> <b>Learning</b> Algorithms in Weka . 678 Responses to Sequence Classification with LSTM Recurrent ...", "dateLastCrawled": "2022-02-02T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "300+ TOP <b>Neural Networks Multiple Choice Questions and Answers</b>", "url": "https://engineeringinterviewquestions.com/neural-networks-multiple-choice-questions-and-answers/", "isFamilyFriendly": true, "displayUrl": "https://engineeringinterviewquestions.com/<b>neural-networks-multiple-choice-questions</b>...", "snippet": "Explanation: Different <b>learning</b> methods include memorization, <b>analogy</b> and deduction. 22. Following are the advantage/s of Decision Trees. Choose that apply. a) Possible Scenarios can be added b) For data including categorical variables with different number of levels, information gain in decision trees are biased in favor of those attributes with more levels c) Worst, best and expected values can be determined for different scenarios d) Use a white box model, If given result is provided by a ...", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[D] <b>Machine</b> <b>Learning</b> - WAYR (What Are You Reading) - Week 85 ...", "url": "https://www.reddit.com/r/MachineLearning/comments/fvk7j6/d_machine_learning_wayr_what_are_you_reading_week/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/fvk7j6/d_<b>machine</b>_<b>learning</b>_wayr_what...", "snippet": "This is a place to share <b>machine</b> <b>learning</b> research papers, journals, and articles that you&#39;re reading this week. If it relates to what you&#39;re researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you&#39;ve read. Please try to provide some insight from your understanding and please don&#39;t post things which are present in wiki. Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not ...", "dateLastCrawled": "2021-11-04T04:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Jason Dion Network+ Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/ca/468845736/jason-dion-network-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/ca/468845736/jason-dion-network-flash-cards", "snippet": "<b>Bidirectional is like</b> talking on a walkie-talkie where only one person can send a message as a time, whereas Full-Duplex is more like talking on the phone where both people can talk at the same time. 110 Block patch panel. required for CAT 5 and above. Used as well as 66 blocks in MDF(main distribution frames) and IDF(Intermediate distribution frames) 10BaseT. Maximum speed: 10Mbps Maximum distance: 100meters Cat 3 or Higher. 1000BaseSX? 1000BaseLX? 1000BaseZX? Fibre Optic: MMF 1Gbps 220m SX ...", "dateLastCrawled": "2020-12-05T02:22:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "2004 <b>Winter Brain</b> Abstracts", "url": "https://brainmeeting.com/a2004_abstracts.htm", "isFamilyFriendly": true, "displayUrl": "https://brainmeeting.com/a2004_abstracts.htm", "snippet": "A <b>machine</b> <b>learning</b> algorithm from the domain of artificial intelligence was implemented to compose and perform brief musical passages. In its basic configuration, the program generates compositions then improves them based on evaluative feedback from a human listener. The listener serves as a &quot;tutor&quot; for the program by judging the quality of each composition. For purposes of this study, the program was given the capability of monitoring the listener&#39;s EEG responses to each musical passage ...", "dateLastCrawled": "2022-01-23T11:27:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(bidirectional)  is like +(unsupervised learning  supervised learning)", "+(bidirectional) is similar to +(unsupervised learning  supervised learning)", "+(bidirectional) can be thought of as +(unsupervised learning  supervised learning)", "+(bidirectional) can be compared to +(unsupervised learning  supervised learning)", "machine learning +(bidirectional AND analogy)", "machine learning +(\"bidirectional is like\")", "machine learning +(\"bidirectional is similar\")", "machine learning +(\"just as bidirectional\")", "machine learning +(\"bidirectional can be thought of as\")", "machine learning +(\"bidirectional can be compared to\")"]}