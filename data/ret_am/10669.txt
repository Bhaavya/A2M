{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Develop an Encoder-Decoder Model for <b>Sequence-to-Sequence</b> ...", "url": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence...", "snippet": "The encoder-decoder model provides a pattern for using recurrent neural networks to address challenging <b>sequence-to-sequence prediction</b> problems such as machine translation. Encoder-decoder models can be developed in the Keras Python deep learning library and an example of a neural machine translation system developed with this model has been described on the Keras blog, with sample code distributed with the Keras project. This", "dateLastCrawled": "2022-01-29T13:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Hi, robot: Why robotics and <b>language</b> need each other", "url": "https://knowablemagazine.org/article/technology/2020/teaching-robots-to-talk", "isFamilyFriendly": true, "displayUrl": "https://knowablemagazine.org/article/technology/2020/<b>teaching</b>-robots-to-talk", "snippet": "Implementing a \u201c<b>sequence-to-sequence</b>\u201d architecture, this system takes in a sequence of words and outputs a sequence of action commands, rather <b>like</b> translating from one <b>language</b> to another. In between is a neural network, an arrangement of simple computing elements roughly mimicking the brain\u2019s wiring. The network has sub-networks specialized for handling <b>language</b> (the instructions) and images (what the virtual robot sees). When it succeeds during training, the active neural ...", "dateLastCrawled": "2022-02-03T12:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 <b>Technical Approaches For Building Conversational AI</b>", "url": "https://www.topbots.com/building-conversational-ai/", "isFamilyFriendly": true, "displayUrl": "https://www.topbots.com/building-conversational-ai", "snippet": "Supervised learning frames conversation as a <b>sequence-to-sequence</b> problem, where user input is mapped to <b>a computer</b>-generated response. However, <b>sequence to sequence</b> learning tends to prioritize high-priority, high-probability response content (i.e. \u201cI don\u2019t know\u201d). Such systems also have trouble incorporating proper nouns into their speech because they occur at a much lower frequency in dialogue as compared to other classes of words. All of these issues add up to systems that are ...", "dateLastCrawled": "2022-01-31T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 8: Building a Chatbot Using Attention-Based Neural Networks ...", "url": "http://devguis.com/chapter-8-building-a-chatbot-using-attention-based-neural-networks-hands-on-natural-language-processing-with-pytorch-1-x.html", "isFamilyFriendly": true, "displayUrl": "devguis.com/chapter-8-building-a-chatbot-using-attention-based-neural-networks-hands...", "snippet": "In the previous chapter, we looked at how to construct <b>sequence-to-sequence</b> models to translate sentences from one <b>language</b> into another. A conversational chatbot that is capable of basic interactions works in much the same way. When we talk to a chatbot, our sentence becomes the input to the model. The output is whatever the chatbot chooses to reply with. Therefore, rather than training our chatbot to learn how to interpret our input sentence, we are <b>teaching</b> it how to <b>respond</b>.", "dateLastCrawled": "2021-12-28T04:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Seq2seq-Vis: A <b>Visual Debugging Tool for Sequence-to-Sequence Models</b> ...", "url": "https://www.researchgate.net/publication/328361147_Seq2seq-Vis_A_Visual_Debugging_Tool_for_Sequence-to-Sequence_Models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/328361147_Seq2seq-Vis_A_Visual_Debugging_Tool...", "snippet": "Other works are more <b>task</b>-specific, e.g. interactively exploring machine translation [46] and inspecting classification decisions <b>in natural</b> <b>language</b> inference tasks [32], while Cashman et al. [7 ...", "dateLastCrawled": "2022-02-02T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Evolution of Language Modelling in Modern Life</b> | upGrad blog", "url": "https://www.upgrad.com/blog/nlp-natural-language-processing-real-life-applications/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/nlp-<b>natural</b>-<b>language</b>-processing-real-life-applications", "snippet": "Within the last two decades, NLP has explored more neural <b>language</b> models, multi-<b>task</b> learning, word embeddings, more advanced neural networks, <b>sequence-to-sequence</b> models, memory-based networks and pre-trained <b>language</b> models. This advancement has led to applications such as intelligent keyboards and email response suggestions to speech-enabled assistance by machines. Now there is a steady move from <b>Natural</b> <b>Language</b> Processing (NLP) to <b>Natural</b> <b>Language</b> Understanding (NLU), where a user ...", "dateLastCrawled": "2022-01-05T01:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Conversational Agents - Chatbots", "url": "https://adimen.si.ehu.es/~rigau/teaching/EHU/TAIA/Curs2020-2021/Homework1/G6Report.pdf", "isFamilyFriendly": true, "displayUrl": "https://adimen.si.ehu.es/~rigau/<b>teaching</b>/EHU/TAIA/Curs2020-2021/Homework1/G6Report.pdf", "snippet": "is <b>a computer</b> system that, by using speeches, graphics, haptics or even gestures, is able to converse with human beings. Since the \ufb01rst speaking dialogue system was issued by DARPA in 1977, Conversational Agents have been incredibly improved. Nowadays, Conversational Agents are divided in two types: <b>Task</b>-oriented CA and non-<b>task</b> oriented CA. Regarding to <b>Task</b>-oriented conversational agents, these are software components based on arti\ufb01cial intelligence that are able to simulate an ...", "dateLastCrawled": "2022-01-09T05:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "\u201cPyTorch <b>Natural</b> <b>Language</b> Processing Series\u201d 9. NLP classics, frontiers ...", "url": "https://opensourcebiology.eu/2021/11/12/pytorch-natural-language-processing-series-9-nlp-classics-frontiers-and-follow-ups/", "isFamilyFriendly": true, "displayUrl": "https://opensourcebiology.eu/2021/11/12/pytorch-<b>natural</b>-<b>language</b>-processing-series-9...", "snippet": "In this book, we discussed several different deep learning architectures of NLP: MLP, CNN, sequence model, <b>sequence-to-sequence</b> model and attention-based model. Note that we have discussed these models separately because of better <b>teaching</b> and understanding, but the trend in the literature is to combine different architectures to complete the work. For example, you can write a convolutional network to represent the characters of a word, and then write an LSTM based on the representation, and ...", "dateLastCrawled": "2022-02-01T18:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Can you build an AI <b>capable to understand a text</b> and answer questions ...", "url": "https://www.quora.com/Can-you-build-an-AI-capable-to-understand-a-text-and-answer-questions-about-it", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Can-you-build-an-AI-<b>capable-to-understand-a-text</b>-and-answer...", "snippet": "Answer (1 of 4): Yes I can, and have, but it took about 800 days to program and is far from perfect. For instance, <b>like</b> myself, it has the tendency to take \u201ccan you ...", "dateLastCrawled": "2022-01-14T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>do natural language parsing systems work? How</b> do they get the ...", "url": "https://www.quora.com/How-do-natural-language-parsing-systems-work-How-do-they-get-the-grammar-right", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>do-natural-language-parsing-systems-work-How</b>-do-they-get-the...", "snippet": "Answer (1 of 3): N.B. This will be extremely simplified. I don\u2019t know the exact process, this is just my understanding of it. N.B. 2 This describes neural machine translation. Older technologies such as rule-based or statistical machine translation relied on very different mechanisms. They do i...", "dateLastCrawled": "2022-01-18T22:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chapter 8: Building a Chatbot Using Attention-Based Neural Networks ...", "url": "https://w3sdev.com/chapter-8-building-a-chatbot-using-attention-based-neural-networks-hands-on-natural-language-processing-with-pytorch-1-x.html", "isFamilyFriendly": true, "displayUrl": "https://w3sdev.com/chapter-8-building-a-chatbot-using-attention-based-neural-networks...", "snippet": "In the previous chapter, we looked at how to construct <b>sequence-to-sequence</b> models to translate sentences from one <b>language</b> into another. A conversational chatbot that is capable of basic interactions works in much the same way. When we talk to a chatbot, our sentence becomes the input to the model. The output is whatever the chatbot chooses to reply with. Therefore, rather than training our chatbot to learn how to interpret our input sentence, we are <b>teaching</b> it how to <b>respond</b>.", "dateLastCrawled": "2021-10-13T19:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to Develop an Encoder-Decoder Model for <b>Sequence-to-Sequence</b> ...", "url": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence...", "snippet": "Here you can see how the recursive use of the model can be used to build up output sequences. During prediction, the inference_encoder model is used to encode the input sequence once which returns states that are used to initialize the inference_decoder model. From that point, the inference_decoder model is used to generate predictions step by step.. The function below named predict_sequence() can be used after the model is trained to generate a target sequence given a source sequence.", "dateLastCrawled": "2022-01-29T13:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Evolution of Language Modelling in Modern Life</b> | upGrad blog", "url": "https://www.upgrad.com/blog/nlp-natural-language-processing-real-life-applications/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/nlp-<b>natural</b>-<b>language</b>-processing-real-life-applications", "snippet": "Within the last two decades, NLP has explored more neural <b>language</b> models, multi-<b>task</b> learning, word embeddings, more advanced neural networks, <b>sequence-to-sequence</b> models, memory-based networks and pre-trained <b>language</b> models. This advancement has led to applications such as intelligent keyboards and email response suggestions to speech-enabled assistance by machines. Now there is a steady move from <b>Natural</b> <b>Language</b> Processing (NLP) to <b>Natural</b> <b>Language</b> Understanding (NLU), where a user ...", "dateLastCrawled": "2022-01-05T01:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Seq2seq-Vis: A <b>Visual Debugging Tool for Sequence-to-Sequence Models</b> ...", "url": "https://www.researchgate.net/publication/328361147_Seq2seq-Vis_A_Visual_Debugging_Tool_for_Sequence-to-Sequence_Models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/328361147_Seq2seq-Vis_A_Visual_Debugging_Tool...", "snippet": "Other works are more <b>task</b>-specific, e.g. interactively exploring machine translation [46] and inspecting classification decisions <b>in natural</b> <b>language</b> inference tasks [32], while Cashman et al. [7 ...", "dateLastCrawled": "2022-02-02T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to <b>build autocorrect with neural networks? How</b> should I start - Quora", "url": "https://www.quora.com/How-can-I-build-autocorrect-with-neural-networks-How-should-I-start", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-can-I-<b>build-autocorrect-with-neural-networks-How</b>-should-I-start", "snippet": "Answer (1 of 3): This is an interesting problem. If you opt for neural networks, then the approach would likely be a <b>sequence-to-sequence</b> model such as the ones used for <b>language</b> translation and such. However you need to take into account a dictionary of words and find which of these words would ...", "dateLastCrawled": "2022-01-13T16:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>seq2seq learning for end-to-end dialogue systems</b>", "url": "https://www.slideshare.net/JordyVanLandeghem/seq2seq-learning-for-endtoend-dialogue-systems-71814464", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/JordyVanLandeghem/seq2seq-learning-for-endtoend-dialogue...", "snippet": "Typically, the first component of a dialogue system is a <b>natural</b> <b>language</b> understanding module, which extracts meaning from the input, and conversely at the end a <b>natural</b> <b>language</b> generation module, which translates meaning to an output response. Given the nature of the input optionally preceding and succeeding modules can be speech recognition and text-to-speech synthesis. Plausibly the most important building block in the pipeline is the dialogue manager. This module is connected to the ...", "dateLastCrawled": "2022-01-26T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Artificial Intelligence (AI) Chatbot as Language Learning Medium</b> ...", "url": "https://www.researchgate.net/publication/337711693_Artificial_Intelligence_AI_Chatbot_as_Language_Learning_Medium_An_inquiry", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/337711693_Artificial_Intelligence_AI_Chatbot...", "snippet": "chatterbot [5, 6]. Chatbot is <b>a computer</b> pro gram or artificial intelligence which carries out. conversations through aud io or text [7], and interact with users in a particular domain or topic by ...", "dateLastCrawled": "2022-01-30T00:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Conversational Agents - Chatbots", "url": "https://adimen.si.ehu.es/~rigau/teaching/EHU/TAIA/Curs2020-2021/Homework1/G6Report.pdf", "isFamilyFriendly": true, "displayUrl": "https://adimen.si.ehu.es/~rigau/<b>teaching</b>/EHU/TAIA/Curs2020-2021/Homework1/G6Report.pdf", "snippet": "is <b>a computer</b> system that, by using speeches, graphics, haptics or even gestures, is able to converse with human beings. Since the \ufb01rst speaking dialogue system was issued by DARPA in 1977, Conversational Agents have been incredibly improved. Nowadays, Conversational Agents are divided in two types: <b>Task</b>-oriented CA and non-<b>task</b> oriented CA. Regarding to <b>Task</b>-oriented conversational agents, these are software components based on arti\ufb01cial intelligence that are able to simulate an ...", "dateLastCrawled": "2022-01-09T05:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The <b>Design and Implementation of XiaoIce, an Empathetic Social Chatbot</b> ...", "url": "https://direct.mit.edu/coli/article/46/1/53/93380/The-Design-and-Implementation-of-XiaoIce-an", "isFamilyFriendly": true, "displayUrl": "https://direct.mit.edu/coli/article/46/1/53/93380/The-Design-and-Implementation-of...", "snippet": "XiaoIce is developed on an empathetic computing framework (Cai 2006; Fung et al. 2016) that enables the machine (social chatbot in our case) to recognize human feelings and states, <b>understand</b> user intents, <b>and respond</b> to user needs dynamically. XiaoIce aims to pass a particular form of the Turing Test known as the time-sharing test, where machines and humans coexist in a companion system with a time-sharing schedule. If a person enjoys its companionship (via conversation), we can call the ...", "dateLastCrawled": "2022-01-30T17:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Can you build an AI <b>capable to understand a text</b> and answer questions ...", "url": "https://www.quora.com/Can-you-build-an-AI-capable-to-understand-a-text-and-answer-questions-about-it", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Can-you-build-an-AI-<b>capable-to-understand-a-text</b>-and-answer...", "snippet": "Answer (1 of 4): Yes I can, and have, but it took about 800 days to program and is far from perfect. For instance, like myself, it has the tendency to take \u201ccan you ...", "dateLastCrawled": "2022-01-14T06:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Develop an Encoder-Decoder Model for <b>Sequence-to-Sequence</b> ...", "url": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence...", "snippet": "Here you <b>can</b> see how the recursive use of the model <b>can</b> be used to build up output sequences. During prediction, the inference_encoder model is used to encode the input sequence once which returns states that are used to initialize the inference_decoder model. From that point, the inference_decoder model is used to generate predictions step by step.. The function below named predict_sequence() <b>can</b> be used after the model is trained to generate a target sequence given a source sequence.", "dateLastCrawled": "2022-01-29T13:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 <b>Technical Approaches For Building Conversational AI</b>", "url": "https://www.topbots.com/building-conversational-ai/", "isFamilyFriendly": true, "displayUrl": "https://www.topbots.com/building-conversational-ai", "snippet": "Supervised learning frames conversation as a <b>sequence-to-sequence</b> problem, where user input is mapped to <b>a computer</b>-generated response. However, <b>sequence to sequence</b> learning tends to prioritize high-priority, high-probability response content (i.e. \u201cI don\u2019t know\u201d). Such systems also have trouble incorporating proper nouns into their speech because they occur at a much lower frequency in dialogue as compared to other classes of words. All of these issues add up to systems that are ...", "dateLastCrawled": "2022-01-31T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Hi, robot: Why robotics and <b>language</b> need each other", "url": "https://knowablemagazine.org/article/technology/2020/teaching-robots-to-talk", "isFamilyFriendly": true, "displayUrl": "https://knowablemagazine.org/article/technology/2020/<b>teaching</b>-robots-to-talk", "snippet": "Implementing a \u201c<b>sequence-to-sequence</b>\u201d architecture, this system takes in a sequence of words and outputs a sequence of action commands, rather like translating from one <b>language</b> to another. In between is a neural network, an arrangement of simple computing elements roughly mimicking the brain\u2019s wiring. The network has sub-networks specialized for handling <b>language</b> (the instructions) and images (what the virtual robot sees). When it succeeds during training, the active neural ...", "dateLastCrawled": "2022-02-03T12:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>seq2seq learning for end-to-end dialogue systems</b>", "url": "https://www.slideshare.net/JordyVanLandeghem/seq2seq-learning-for-endtoend-dialogue-systems-71814464", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/JordyVanLandeghem/seq2seq-learning-for-endtoend-dialogue...", "snippet": "Typically, the first component of a dialogue system is a <b>natural</b> <b>language</b> understanding module, which extracts meaning from the input, and conversely at the end a <b>natural</b> <b>language</b> generation module, which translates meaning to an output response. Given the nature of the input optionally preceding and succeeding modules <b>can</b> be speech recognition and text-to-speech synthesis. Plausibly the most important building block in the pipeline is the dialogue manager. This module is connected to the ...", "dateLastCrawled": "2022-01-26T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Common ML Problems | Introduction to <b>Machine Learning</b> Problem Framing ...", "url": "https://developers.google.com/machine-learning/problem-framing/cases", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/problem-framing/cases", "snippet": "<b>Natural</b> <b>language</b> parse trees, image recognition bounding boxes: Ranking: Identify position on a scale or status: Search result ranking: Check Your Understanding . Which ML problem is an example of unsupervised learning? Click on an answer to expand the section and check your response. Clustering. Clustering is typically done when labeled data is not available. This is an unsupervised learning problem. Structured output. Complex outputs require complex labeled data. This is a supervised ...", "dateLastCrawled": "2022-01-30T12:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Publications - <b>Computer</b> and Information Science", "url": "https://www.cis.upenn.edu/~ccb/publications.html", "isFamilyFriendly": true, "displayUrl": "https://www.cis.upenn.edu/~ccb/publications.html", "snippet": "Procedural events <b>can</b> often <b>be thought</b> of as a high level goal composed of a sequence of steps. Inferring the sub-sequence of steps of a goal <b>can</b> help artificial intelligence systems reason about human activities. Past work in NLP has examined the <b>task</b> of goal-step inference for text. We introduce the visual analogue. We propose the Visual Goal-Step Inference (VGSI) <b>task</b> where a model is given a textual goal and must choose a plausible step towards that goal from among four candidate images ...", "dateLastCrawled": "2022-02-03T07:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Artificial Intelligence (AI) Chatbot as Language Learning Medium</b> ...", "url": "https://www.researchgate.net/publication/337711693_Artificial_Intelligence_AI_Chatbot_as_Language_Learning_Medium_An_inquiry", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/337711693_Artificial_Intelligence_AI_Chatbot...", "snippet": "With <b>Computer</b>-Assisted <b>Language</b> Learning (CALL), the English learning process <b>can</b> now be interactive and productive. The students <b>can</b> now improve their <b>language</b> skills by conversing with AI-based ...", "dateLastCrawled": "2022-01-30T00:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "US20180052664A1 - Method and system for developing, training, and ...", "url": "https://patents.google.com/patent/US20180052664A1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US20180052664", "snippet": "The present <b>teaching</b> relates to developing a virtual agent. In one example, a plurality of graphical objects is presented to a user via a bot design programming interface. Each of the plurality of graphical objects represents a module corresponding to an action to be performed by the virtual agent. One or more inputs from the user are received, via the bot design programming interface, for selecting a set of graphical objects from the plurality of graphical objects. The one or more inputs ...", "dateLastCrawled": "2021-12-12T11:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Long Short-Term Memory Networks With Python", "url": "https://machinelearningmastery.com/lstms-with-python/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/lstms-with-python", "snippet": "Given a standard feedforward MLP network, an RNN <b>can</b> <b>be thought</b> of as the addition of loops to the architecture. The recurrent connections add state or memory to the network and allow it to learn and harness the ordered nature of observations within input sequences. The internal memory means outputs of the network are conditional on the recent context in the input sequence, not what has just been presented as input to the network. In a sense, this capability unlocks sequence prediction for ...", "dateLastCrawled": "2022-01-31T01:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Can</b> you build an AI <b>capable to understand a text</b> and answer questions ...", "url": "https://www.quora.com/Can-you-build-an-AI-capable-to-understand-a-text-and-answer-questions-about-it", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Can</b>-you-build-an-AI-<b>capable-to-understand-a-text</b>-and-answer...", "snippet": "Answer (1 of 4): Yes I <b>can</b>, and have, but it took about 800 days to program and is far from perfect. For instance, like myself, it has the tendency to take \u201c<b>can</b> you ...", "dateLastCrawled": "2022-01-14T06:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Develop an Encoder-Decoder Model for <b>Sequence-to-Sequence</b> ...", "url": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence...", "snippet": "Here you <b>can</b> see how the recursive use of the model <b>can</b> be used to build up output sequences. During prediction, the inference_encoder model is used to encode the input sequence once which returns states that are used to initialize the inference_decoder model. From that point, the inference_decoder model is used to generate predictions step by step.. The function below named predict_sequence() <b>can</b> be used after the model is trained to generate a target sequence given a source sequence.", "dateLastCrawled": "2022-01-29T13:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Evolution of Language Modelling in Modern Life</b> | upGrad blog", "url": "https://www.upgrad.com/blog/nlp-natural-language-processing-real-life-applications/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/nlp-<b>natural</b>-<b>language</b>-processing-real-life-applications", "snippet": "Within the last two decades, NLP has explored more neural <b>language</b> models, multi-<b>task</b> learning, word embeddings, more advanced neural networks, <b>sequence-to-sequence</b> models, memory-based networks and pre-trained <b>language</b> models. This advancement has led to applications such as intelligent keyboards and email response suggestions to speech-enabled assistance by machines. Now there is a steady move from <b>Natural</b> <b>Language</b> Processing (NLP) to <b>Natural</b> <b>Language</b> Understanding (NLU), where a user ...", "dateLastCrawled": "2022-01-05T01:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Gentle Introduction to <b>LSTM Autoencoders</b>", "url": "https://machinelearningmastery.com/lstm-autoencoders/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>lstm-autoencoders</b>", "snippet": "These are called <b>sequence-to-sequence</b>, or seq2seq, prediction problems. You <b>can</b> learn more about sequence prediction problems here: ... both of which are described as an unsupervised learning <b>task</b>. The input to the model is a sequence of vectors (image patches or features). The encoder LSTM reads in this sequence. After the last input has been read, the decoder LSTM takes over and outputs a prediction for the target sequence. \u2014 Unsupervised Learning of Video Representations using LSTMs ...", "dateLastCrawled": "2022-02-03T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) A <b>Survey on Evaluation Methods for Chatbots</b>", "url": "https://www.researchgate.net/publication/333524709_A_Survey_on_Evaluation_Methods_for_Chatbots", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/333524709_A_<b>Survey_on_Evaluation_Methods_for</b>...", "snippet": "Retrieval (IR) and <b>Sequence to Sequence</b> (Seq2Seq) using attentive Seq2Seq rerank model in the ir AliMe Ch at in order to be able to answer open - domain <b>natural</b> - <b>language</b> questions from their", "dateLastCrawled": "2022-01-29T17:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "6 <b>Technical Approaches For Building Conversational AI</b>", "url": "https://www.topbots.com/building-conversational-ai/", "isFamilyFriendly": true, "displayUrl": "https://www.topbots.com/building-conversational-ai", "snippet": "Supervised learning frames conversation as a <b>sequence-to-sequence</b> problem, where user input is mapped to <b>a computer</b>-generated response. However, <b>sequence to sequence</b> learning tends to prioritize high-priority, high-probability response content (i.e. \u201cI don\u2019t know\u201d). Such systems also have trouble incorporating proper nouns into their speech because they occur at a much lower frequency in dialogue as <b>compared</b> to other classes of words. All of these issues add up to systems that are ...", "dateLastCrawled": "2022-01-31T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Artificial Intelligence (AI) Chatbot as Language Learning Medium</b> ...", "url": "https://www.researchgate.net/publication/337711693_Artificial_Intelligence_AI_Chatbot_as_Language_Learning_Medium_An_inquiry", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/337711693_Artificial_Intelligence_AI_Chatbot...", "snippet": "With <b>Computer</b>-Assisted <b>Language</b> Learning (CALL), the English learning process <b>can</b> now be interactive and productive. The students <b>can</b> now improve their <b>language</b> skills by conversing with AI-based ...", "dateLastCrawled": "2022-01-30T00:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Explainable AI: A Review of Machine Learning Interpretability Methods", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7824368/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7824368", "snippet": "White-box highly performing models are very hard to create, especially in <b>computer</b> vision and <b>natural</b> <b>language</b> processing, where the gap in performance against deep learning models is unbridgeable. Furthermore, because models are more than ever expected to be competitive on more than one tasks and knowledge transfer from one domain to another is becoming a recurring theme, white-box models, being able to perform well only in a single given <b>task</b>, are losing traction within the literature and ...", "dateLastCrawled": "2022-01-29T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Automatic question generation based on sentence structure analysis ...", "url": "https://www.cambridge.org/core/journals/natural-language-engineering/article/automatic-question-generation-based-on-sentence-structure-analysis-using-machine-learning-approach/20466C8F42F34BDBB3302B796C4101B2", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/<b>natural</b>-<b>language</b>-engineering/article/automatic...", "snippet": "Automatic question generation is one of the most challenging tasks of <b>Natural</b> <b>Language</b> Processing. It requires \u201cbidirectional\u201d <b>language</b> processing: first, the system has to <b>understand</b> the input text (<b>Natural</b> <b>Language</b> Understanding), and it then has to generate questions also in the form of text (<b>Natural</b> <b>Language</b> Generation). In this article, we introduce our framework for generating the factual questions from unstructured text in the English <b>language</b>. It uses a combination of traditional ...", "dateLastCrawled": "2021-12-24T13:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Artificial Intelligence A Modern Approach</b> (4th Edition) | Fahim ...", "url": "https://www.academia.edu/45126798/Artificial_Intelligence_A_Modern_Approach_4th_Edition_", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/45126798/<b>Artificial_Intelligence_A_Modern_Approach</b>_4th_Edition_", "snippet": "Artificial Intelligence (AI) is a big field, and this is a big book. We have tried to explore the full breadth of the field, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; fairness,", "dateLastCrawled": "2022-02-02T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Publications - <b>Computer</b> and Information Science", "url": "https://www.cis.upenn.edu/~ccb/publications.html", "isFamilyFriendly": true, "displayUrl": "https://www.cis.upenn.edu/~ccb/publications.html", "snippet": "Inherently, this is a <b>natural</b> <b>language</b> understanding <b>task</b>, and we propose to address it as such. Specifically, we propose the <b>task</b> of substantiated perspective discovery where, given a claim, a system is expected to discover a diverse set of well-corroborated perspectives that take a stance with respect to the claim. Each perspective should be substantiated by evidence paragraphs which summarize pertinent results and facts. We construct PERSPECTRUM, a dataset of claims, perspectives and ...", "dateLastCrawled": "2022-02-03T07:48:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The language of <b>proteins: NLP, machine learning &amp; protein sequences</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S2001037021000945", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2001037021000945", "snippet": "Popular deep-<b>learning</b> architectures are long short-term memory (LSTM) , <b>sequence-to-sequence</b> (seq2seq) and attention . In seq2seq models, a text is transformed using an encoder component, then a separate decoder uses the encoded representation to solve some <b>task</b> (e.g. translating between English and French). Attention models use attention layers (also called attention heads) that allow the network to concentrate on specific tokens in the text", "dateLastCrawled": "2022-02-03T02:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Is the race over for <b>Seq2Seq</b> models? | by Thushan Ganegedara | Towards ...", "url": "https://towardsdatascience.com/is-the-race-over-for-seq2seq-models-adef2b24841c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/is-the-race-over-for-<b>seq2seq</b>-models-adef2b24841c", "snippet": "This goes for any <b>machine</b> <b>learning</b> <b>task</b>, be it <b>machine</b> translation, dependency parsing or language modelling. Self-attention layer enables to transformer to exactly do that. While processing the word \u201cits\u201d, the model can look at all the other words and decide for itself which words are important to \u201c mix \u201d into the output, so that the transformer can solve the <b>task</b> effectively.", "dateLastCrawled": "2022-02-02T02:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Introduction to Transformers in Machine Learning</b>", "url": "https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/.../12/28/<b>introduction-to-transformers-in-machine-learning</b>", "snippet": "When you talk about <b>Machine</b> <b>Learning</b> in Natural Language Processing these days, all you hear is one thing \u2013 Transformers. Models based on this Deep <b>Learning</b> architecture have taken the NLP world by storm since 2017. In fact, they are the go-to approach today, and many of the approaches build on top of the original Transformer, one way or another. Transformers are however not simple. The original Transformer architecture is quite complex and the same is true for many of the spin-off ...", "dateLastCrawled": "2022-02-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "9.7. <b>Sequence to Sequence</b> <b>Learning</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 ...", "url": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html", "snippet": "As we have seen in Section 9.5, in <b>machine</b> translation both the input and output are a variable-length <b>sequence</b>.To address this type of problem, we have designed a general encoder-decoder architecture in Section 9.6.In this section, we will use two RNNs to design the encoder and the decoder of this architecture and apply it to <b>sequence to sequence</b> <b>learning</b> for <b>machine</b> translation [Sutskever et al., 2014] [Cho et al., 2014b].. Following the design principle of the encoder-decoder architecture ...", "dateLastCrawled": "2022-01-26T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Geometric deep <b>learning</b> on molecular representations | Nature <b>Machine</b> ...", "url": "https://www.nature.com/articles/s42256-021-00418-8", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42256-021-00418-8", "snippet": "In <b>analogy</b> to some popular pre-deep <b>learning</b> ... which can be cast as a <b>sequence-to-sequence</b> translation <b>task</b> in which the string representations of the reactants are mapped to those of the ...", "dateLastCrawled": "2022-01-29T04:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning Gist</b> \u00b7 GitHub", "url": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "snippet": "Week 3: <b>Sequence to sequence</b> architectures. <b>Sequence to sequence</b> models Language translation for example; Image captioning, caption an image; Picking the most likely model <b>Machine</b> Transation Model Split into a model encoding the sentence; and then a language model. Calculate the probability of an English sentence conditioned on a French sentence.", "dateLastCrawled": "2022-01-29T03:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Benefits of AI and Deep <b>Learning</b> - <b>Machine</b> <b>Learning</b> Company ...", "url": "https://www.folio3.ai/blog/advantages-of-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.folio3.ai/blog/<b>advantages-of-neural-networks</b>", "snippet": "<b>Sequence-To-Sequence</b> models are mainly applied in question answering, <b>machine</b> translations systems, and chatbots. What Are The <b>Advantages of Neural Networks</b> . There are various <b>advantages of neural networks</b>, some of which are discussed below: 1) Store information on the entire network. Just like it happens in traditional programming where information is stored on the network and not on a database. If a few pieces of information disappear from one place, it does not stop the whole network ...", "dateLastCrawled": "2022-02-02T09:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Gentle Introduction to <b>Long Short-Term Memory</b> Networks by the Experts", "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>long-short-term-memory</b>-networks...", "snippet": "<b>Long Short-Term Memory</b> (LSTM) networks are a type of recurrent neural network capable of <b>learning</b> order dependence in sequence prediction problems. This is a behavior required in complex problem domains like <b>machine</b> translation, speech recognition, and more. LSTMs are a complex area of deep <b>learning</b>. It can be hard to get your hands around what LSTMs are, and how terms like bidirectional", "dateLastCrawled": "2022-01-31T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Sequence Classification with LSTM Recurrent Neural Networks in Python ...", "url": "https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/sequence-classification-", "snippet": "Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras. Sequence classification is a predictive modeling problem where you have some sequence of inputs over space or time and the <b>task</b> is to predict a category for the sequence. What makes this problem difficult is that the sequences can vary in length, be comprised of a ...", "dateLastCrawled": "2022-02-02T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "deep-<b>learning</b>-coursera/Week 1 Quiz - Introduction to deep <b>learning</b>.md ...", "url": "https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%201%20Quiz%20-%20Introduction%20to%20deep%20learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/Kulbear/deep-<b>learning</b>-coursera/blob/master/Neural Networks and Deep...", "snippet": "Week 1 Quiz - Introduction to deep <b>learning</b>. What does the <b>analogy</b> \u201cAI is the new electricity\u201d refer to? AI is powering personal devices in our homes and offices, similar to electricity. Through the \u201csmart grid\u201d, AI is delivering a new wave of electricity. AI runs on computers and is thus powered by electricity, but it is letting computers do things not possible before. Similar to electricity starting about 100 years ago, AI is transforming multiple industries. Note: Andrew ...", "dateLastCrawled": "2022-02-03T05:16:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(sequence-to-sequence task)  is like +(teaching a computer how to understand and respond in natural language)", "+(sequence-to-sequence task) is similar to +(teaching a computer how to understand and respond in natural language)", "+(sequence-to-sequence task) can be thought of as +(teaching a computer how to understand and respond in natural language)", "+(sequence-to-sequence task) can be compared to +(teaching a computer how to understand and respond in natural language)", "machine learning +(sequence-to-sequence task AND analogy)", "machine learning +(\"sequence-to-sequence task is like\")", "machine learning +(\"sequence-to-sequence task is similar\")", "machine learning +(\"just as sequence-to-sequence task\")", "machine learning +(\"sequence-to-sequence task can be thought of as\")", "machine learning +(\"sequence-to-sequence task can be compared to\")"]}