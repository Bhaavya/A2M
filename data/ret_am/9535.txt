{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to Machine <b>Translation</b> | by Cyprien NIELLY | Towards Data ...", "url": "https://towardsdatascience.com/introduction-to-machine-translation-9cb0e93e7cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-machine-<b>translation</b>-9cb0e93e7cb", "snippet": "<b>BLEU</b> (<b>bilingual</b> <b>evaluation</b> <b>understudy</b>) is an algorithm for evaluating the quality of a machine-translated text. It compares the machine <b>translation</b> to one or several human-written <b>translation</b>(s), and it computes a similarity score between 0 and 1. A perfect match results in a score of 1, whereas a perfect mismatch results in a score of 0. <b>BLEU</b> score is today the benchmark metric most commonly used. Although this metric is not perfect, it has the advantage of being interpretable and easy to ...", "dateLastCrawled": "2022-01-31T02:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to Perform Machine Translation <b>Evaluation</b> - Defined.ai", "url": "https://www.defined.ai/blog/machine-translation-101-part-3/", "isFamilyFriendly": true, "displayUrl": "https://www.defined.ai/blog/machine-translation-101-part-3", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) is the most common automatic approach to machine translation <b>evaluation</b> at present. It focuses on precision-based features. <b>BLEU</b> works by comparing the machine translation to a number of reference translations. It gives a higher score (on a scale of 0 to 1) when the machine translation text shares a lot of strings with the reference translation text. When the score is closer to 1, the more similar the machine translation is to a human translation. But ...", "dateLastCrawled": "2022-01-08T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Neural <b>Machine Translation</b>: Inner Workings, Seq2Seq, and Transformers ...", "url": "https://towardsdatascience.com/neural-machine-translation-inner-workings-seq2seq-and-transformers-229faff5895b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-<b>machine-translation</b>-inner-workings-seq2seq-and...", "snippet": "Alternatively, people mostly use the <b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) score. It produces a score between [0,1], in some cases, we multiply it with 100 for convenience. It uses n-grams (1, 2, 3, and 4 mostly) to evaluate the translation with some additional internal tricks. But this <b>evaluation</b> mechanism might slightly fail in this example ...", "dateLastCrawled": "2022-01-29T08:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How Machine Learning and Artificial Intelligence has changed Language ...", "url": "https://www.langminds.com/blog/2019/12/31/how-machine-learning-and-artificial-intelligence-has-changed-language-industry/", "isFamilyFriendly": true, "displayUrl": "https://www.langminds.com/blog/2019/12/31/how-machine-learning-and-artificial...", "snippet": "The industry measures the translation quality by an algorithm called as <b>BLEU</b> (the <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>). It matters because human\u2019s translation accuracy scores up to 4.636. The <b>BLEU</b> matrices check how close the machine translation is to human version of the translation.", "dateLastCrawled": "2021-12-08T14:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Linguistics and Arabic Natural Language Processing (NLP) Introduction ...", "url": "https://learnbeneficial.com/linguistics-and-arabic-natural-language-processing-introduction/", "isFamilyFriendly": true, "displayUrl": "https://learnbeneficial.com/linguistics-and-arabic-natural-language-processing...", "snippet": "<b>BLEU</b> (<b>bilingual</b> <b>evaluation</b> <b>understudy</b>) is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another. 3.16 BERT Bidirectional Encoder Representations from Transformers (BERT) is a transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google.", "dateLastCrawled": "2022-01-29T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Understanding Terminologies of CAT Tools and Machine Translation ...", "url": "https://www.academia.edu/69654553/Understanding_Terminologies_of_CAT_Tools_and_Machine_Translation_Applications_Authors_Details", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69654553/<b>Understand</b>ing_Terminologies_of_CAT_Tools_and_Machine...", "snippet": "<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>BLEU</b>) Scores evaluates the fluency of the translation correlation with human <b>evaluation</b>, 3. Terminology (Ter) Scores estimates the amount of post-editing effort required, and 4. Post-editing efficiency measures the amount of engine efficiency of post-editing work. According to Lopez (14), the first campaign for the Automatic Language Processing Advisory Committee (ALPAC) already revealed the wide gap between human and machine translators. MTs are still ...", "dateLastCrawled": "2022-02-01T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What Litigators &amp; In-House Counsel Should Know About Foreign Language ...", "url": "https://www.llmlawreview.com/2019/04/04/what-litigators-in-house-counsel-should-know-about-foreign-language-document-review-part-i/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>llmlawreview</b>.com/2019/04/04/what-litigators-in-house-counsel-should-know...", "snippet": "Lastly, while we are keenly aware of methodologies such as the <b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) score, an algorithm that evaluates the quality of translation output from one language to another, my experience on fast moving litigation with so many moving pieces of data, or noise, often does not lend itself to a contained laboratory for easy translation. Think about it. We have data sources coming from spreadsheets with dense information buried in cells, chat logs on messaging platforms ...", "dateLastCrawled": "2021-12-17T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Impact Factor 3.582 Case Studies Journal ISSN (2305-509X) \u2013 Volume 10 ...", "url": "https://www.casestudiesjournal.com/Volume%2010%20Issue%2012%20Paper%204.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.casestudiesjournal.com/Volume 10 Issue 12 Paper 4.pdf", "snippet": "<b>BLEU</b> - <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> CAT - Computer Assisted Translation DL - Deep Learning DTP - Desktop Publishing GT - Google Translate HMTE - Human Machine Translation <b>Evaluation</b> HMT - Hybrid Machine Translation ML - Machine Learning MT - Machine Translation NER - Named Entity Recognition NLG - Natural Language Generation NLP - Natural Language Processing NLTK - Natural Language Tool Kit NLU - Natural Language Understanding NN - Neural Networks POS - Part of Speech RBMT - Rule-Based ...", "dateLastCrawled": "2022-01-09T18:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Review of the Neural <b>History of Natural Language Processing</b> - AYLIEN ...", "url": "https://aylien.com/blog/a-review-of-the-recent-history-of-natural-language-processing", "isFamilyFriendly": true, "displayUrl": "https://aylien.com/blog/a-review-of-the-recent-<b>history-of-natural-language-processing</b>", "snippet": "In 2002, the <b>bilingual</b> <b>evaluation</b> <b>understudy</b> (<b>BLEU</b>; Papineni et al., 2002) metric was proposed, which enabled MT systems to scale up and is still the standard metric for MT <b>evaluation</b> these days. In the same year, the structured preceptron (Collins, 2002) was introduced, which laid the foundation for work in structured perception. At the same conference, sentiment analysis, one of the most popular and widely studied NLP tasks, was introduced (Pang et al., 2002). All three papers won the", "dateLastCrawled": "2022-01-30T00:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>REVIEW OF CHATBOT DESIGN AND TRENDS</b>", "url": "https://www.researchgate.net/publication/337927323_REVIEW_OF_CHATBOT_DESIGN_AND_TRENDS", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/337927323_<b>REVIEW_OF_CHATBOT_DESIGN_AND_TRENDS</b>", "snippet": "chatbot such as a) <b>Bleu</b> Score: <b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>BLEU</b>) score, a method used to compare a generated sequence of words with reference sequence. <b>BLEU</b> score was proposed by Kishore ...", "dateLastCrawled": "2022-01-22T18:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Perform Machine Translation <b>Evaluation</b> - Defined.ai", "url": "https://www.defined.ai/blog/machine-translation-101-part-3/", "isFamilyFriendly": true, "displayUrl": "https://www.defined.ai/blog/machine-translation-101-part-3", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) is the most common automatic approach to machine translation <b>evaluation</b> at present. It focuses on precision-based features. <b>BLEU</b> works by comparing the machine translation to a number of reference translations. It gives a higher score (on a scale of 0 to 1) when the machine translation text shares a lot of strings with the reference translation text. When the score is closer to 1, the more <b>similar</b> the machine translation is to a human translation. But ...", "dateLastCrawled": "2022-01-08T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Natural language processing (NLP) and its use in machine translation", "url": "https://www.qblocks.cloud/blog/natural-language-processing-machine-translation", "isFamilyFriendly": true, "displayUrl": "https://www.qblocks.cloud/blog/natural-language-processing-machine-translation", "snippet": "Machine Translation as discussed earlier, translates the meaningful text of one language to another language, with no human involvement. Machine Translation is evaluated on the <b>BLEU</b>(<b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>) score. <b>BLEU</b> is a metric for automatically evaluating machine-translated text. The score is between 0-1, the higher the score the ...", "dateLastCrawled": "2022-01-29T16:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A <b>Comparatives Study of Machine Translation Evaluation Systems</b> | July ...", "url": "https://www.translationjournal.net/July-2016/a-comparatives-study-of-machine-translation-evaluation-systems.html", "isFamilyFriendly": true, "displayUrl": "https://www.translationjournal.net/July-2016/a-comparatives-study-of-machine...", "snippet": "<b>Different</b> Automatic MT is used to assessing MTs output, but the main concern of the recent study is <b>BLEU</b> system of automatic <b>evaluation</b> of MT which is presented briefly: <b>Bilingual</b> <b>Evaluation</b> <b>understudy</b> (<b>BLEU</b>) method of Mt output scoring was developed in the IBM labs (Papineni et al., 2001) to obtain a rapid and economical way to automatically evaluate machine translation. The initial purpose of designing of this method was to correlate with human assessment. In this scoring method the ...", "dateLastCrawled": "2022-02-02T07:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Linguistics and Arabic Natural Language Processing (NLP) Introduction ...", "url": "https://learnbeneficial.com/linguistics-and-arabic-natural-language-processing-introduction/", "isFamilyFriendly": true, "displayUrl": "https://learnbeneficial.com/linguistics-and-arabic-natural-language-processing...", "snippet": "<b>BLEU</b> (<b>bilingual</b> <b>evaluation</b> <b>understudy</b>) is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another. 3.16 BERT Bidirectional Encoder Representations from Transformers (BERT) is a transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google.", "dateLastCrawled": "2022-01-29T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Presenting artificial intelligence, deep learning, and machine learning ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8519529/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8519529", "snippet": "<b>Bilingual</b> <b>evaluation</b> <b>understudy</b>: Compares generated text with (<b>BLEU</b>) reference texts: Recall-oriented <b>Understudy</b> for: Compares generated text with : Gisting <b>Evaluation</b> (ROUGE) reference texts: Multiple measurements: Frequency weighted average: Summarizes many <b>different</b> outcomes: TP = true positive, FP = false positive, TN = true negative, FN = false negative. The confusion table. Many of the performance measures presented here are familiar to clinicians from diagnostic testing, e.g ...", "dateLastCrawled": "2021-12-01T21:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How Machine Learning and Artificial Intelligence has changed Language ...", "url": "https://www.langminds.com/blog/2019/12/31/how-machine-learning-and-artificial-intelligence-has-changed-language-industry/", "isFamilyFriendly": true, "displayUrl": "https://www.langminds.com/blog/2019/12/31/how-machine-learning-and-artificial...", "snippet": "The industry measures the translation quality by an algorithm called as <b>BLEU</b> (the <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>). It matters because human\u2019s translation accuracy scores up to 4.636. The <b>BLEU</b> matrices check how close the machine translation is to human version of the translation.", "dateLastCrawled": "2021-12-08T14:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Translation <b>and Localization Terms You Need to</b> Know - LangWit", "url": "http://langwit.com/translation-and-localization-terms-you-need-to-know/", "isFamilyFriendly": true, "displayUrl": "langwit.com/translation-<b>and-localization-terms-you-need-to</b>-know", "snippet": "<b>Bilingual</b> <b>evaluation</b> <b>understudy</b> \u2014 See <b>BLEU</b>. <b>BLEU</b> \u2014 Abbreviation for <b>bilingual</b> <b>evaluation</b> <b>understudy</b>. An algorithm to help determine the quality of a machine translation, providing an objective way to compare MT output. Business analytics \u2014 Measurements that show how translators and translation managers are performing. CAT \u2014 See computer-aided translation. Character encoding \u2014 A system of codes for each character of a language, including punctuation and symbols. Common encodings are ...", "dateLastCrawled": "2021-12-06T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Finding Similar Sentences across Multiple Languages in Wikipedia</b>", "url": "https://www.researchgate.net/publication/200772754_Finding_Similar_Sentences_across_Multiple_Languages_in_Wikipedia", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/200772754_Finding_<b>Similar</b>_Sentences_across...", "snippet": "Among the commonly used SMT metrics are: <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>BLEU</b>) [11] the U.S. National Institute of Standards &amp; Technology (NIST) metric [20], the Metric for <b>Evaluation</b> of ...", "dateLastCrawled": "2021-09-18T23:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What Litigators &amp; In-House Counsel Should Know About Foreign Language ...", "url": "https://www.llmlawreview.com/2019/04/04/what-litigators-in-house-counsel-should-know-about-foreign-language-document-review-part-i/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>llmlawreview</b>.com/2019/04/04/what-litigators-in-house-counsel-should-know...", "snippet": "Lastly, while we are keenly aware of methodologies such as the <b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) score, an algorithm that evaluates the quality of translation output from one language to another, my experience on fast moving litigation with so many moving pieces of data, or noise, often does not lend itself to a contained laboratory for easy translation. Think about it. We have data sources coming from spreadsheets with dense information buried in cells, chat logs on messaging platforms ...", "dateLastCrawled": "2021-12-17T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A comprehensive survey on Indian regional language processing ...", "url": "https://link.springer.com/article/10.1007/s42452-020-2983-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42452-020-2983-x", "snippet": "This process will be <b>different</b> for <b>different</b> <b>languages</b> owing to differences in grammatical structure. POS tagging <b>helps</b> in the natural language processing applications like cross-lingual machine translation, Documents-Tagging using named entity recognition, sentiment analysis, etc. However, understanding the grammatical structure of a sentence for automatic POS tagging is a challenging task. In India, many researchers are working towards proposing POS tagging for various regional <b>languages</b>", "dateLastCrawled": "2022-01-19T04:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Neural <b>Machine Translation</b>: Inner Workings, Seq2Seq, and Transformers ...", "url": "https://towardsdatascience.com/neural-machine-translation-inner-workings-seq2seq-and-transformers-229faff5895b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-<b>machine-translation</b>-inner-workings-seq2seq-and...", "snippet": "Alternatively, people mostly use the <b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) score. It produces a score between [0,1], in some cases, we multiply it with 100 for convenience. It uses n-grams (1, 2, 3, and 4 mostly) to evaluate the translation with some additional internal tricks. But this <b>evaluation</b> mechanism might slightly fail in this example ...", "dateLastCrawled": "2022-01-29T08:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Understanding Terminologies of CAT Tools and Machine Translation ...", "url": "https://www.academia.edu/69654553/Understanding_Terminologies_of_CAT_Tools_and_Machine_Translation_Applications_Authors_Details", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69654553/<b>Understand</b>ing_Terminologies_of_CAT_Tools_and_Machine...", "snippet": "<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>BLEU</b>) Scores evaluates the fluency of the translation correlation with human <b>evaluation</b>, 3. Terminology (Ter) Scores estimates the amount of post-editing effort required, and 4. Post-editing efficiency measures the amount of engine efficiency of post-editing work. According to Lopez (14), the first campaign for the Automatic Language Processing Advisory Committee (ALPAC) already revealed the wide gap between human and machine translators. MTs are still ...", "dateLastCrawled": "2022-02-01T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Evaluation</b> of <b>Text Generation</b>: A Survey | DeepAI", "url": "https://deepai.org/publication/evaluation-of-text-generation-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>evaluation</b>-of-<b>text-generation</b>-a-survey", "snippet": "The <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>bleu</b>) is one of the first metrics used to measure the similarity between two sentences (Papineni et al., 2002). Originally proposed for machine translation, it compares a candidate translation of text to one or more reference translations. <b>bleu</b>. is a weighted geometric mean of . n-gram precision scores ...", "dateLastCrawled": "2022-02-03T15:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Development of machine translation technology for assisting</b> health ...", "url": "https://www.sciencedirect.com/science/article/pii/S1532046418301448", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1532046418301448", "snippet": "<b>BLEU</b>- <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> score. Only two text systems were based exclusively on RBT , , with ... and method of <b>evaluation</b>. However, making comparisons across these studies is complicated by the incommensurability of <b>different</b> <b>languages</b> (e.g., English to Japanese, Chinese, Spanish, French , Hungarian, Polish, Turkish, German), source documents (e.g., health promotion materials, journal abstracts, electronic health record notes, clinic conversations), and <b>evaluation</b> measurements ...", "dateLastCrawled": "2022-01-05T15:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Colouring summaries BLEU</b> - ResearchGate", "url": "https://www.researchgate.net/publication/2478790_Colouring_summaries_BLEU", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/2478790_<b>Colouring_summaries_BLEU</b>", "snippet": "We found that Recall-Oriented <b>Understudy</b> for Gisting <b>Evaluation</b> (ROUGE) [27] and <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>BLEU</b>) [28] are two standard quantitative <b>evaluation</b> matrices. As far as our ...", "dateLastCrawled": "2021-12-05T23:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Review of the Neural <b>History of Natural Language Processing</b> - AYLIEN ...", "url": "https://aylien.com/blog/a-review-of-the-recent-history-of-natural-language-processing", "isFamilyFriendly": true, "displayUrl": "https://aylien.com/blog/a-review-of-the-recent-<b>history-of-natural-language-processing</b>", "snippet": "In 2002, the <b>bilingual</b> <b>evaluation</b> <b>understudy</b> (<b>BLEU</b>; Papineni et al., 2002) metric was proposed, which enabled MT systems to scale up and is still the standard metric for MT <b>evaluation</b> these days. In the same year, the structured preceptron (Collins, 2002) was introduced, which laid the foundation for work in structured perception. At the same conference, sentiment analysis, one of the most popular and widely studied NLP tasks, was introduced (Pang et al., 2002). All three papers won the", "dateLastCrawled": "2022-01-30T00:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A framework <b>for multi-document abstractive summarization based</b> on ...", "url": "https://www.researchgate.net/publication/273507606_A_framework_for_multi-document_abstractive_summarization_based_on_semantic_role_labelling", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/273507606_A_framework_for_multi-document...", "snippet": "<b>BLEU</b>-<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>: It is a special algorithm for quality <b>evaluation</b> of machine-translated text between natural <b>languages</b>. ... Extractive Multi-Document Summarization: A Review ...", "dateLastCrawled": "2021-11-05T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(DOC) COMPARISON OF TRADITIONAL STATISTICAL MACHINE TRANSLATION AND ...", "url": "https://www.academia.edu/43563603/COMPARISON_OF_TRADITIONAL_STATISTICAL_MACHINE_TRANSLATION_AND_NEURAL_MACHINE_TRANSLATION", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43563603/COMPARISON_OF_TRADITIONAL_STATISTICAL_MACHINE...", "snippet": "This thesis shows how accurate the translation system works using the <b>bleu</b> score <b>bilingual</b> <b>evaluation</b> tool. And there are lots to learn and determine from both approaches of machine translation. We used <b>different</b> criteria to compare both approaches to ascertain how well both approaches work. Two translation systems were built; Japanese\u2013Vietnamese language pair with Traditional Statistical Machine Translation and Neural Machine Translation using Deep Learning. Both systems use the same ...", "dateLastCrawled": "2022-01-28T23:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "DataHunter: A System for Finding Datasets", "url": "https://data-hunter.io/possible_queries", "isFamilyFriendly": true, "displayUrl": "https://data-hunter.io/possible_queries", "snippet": "The comparative analysis evaluates the systems by three performance <b>evaluation</b> measures: <b>BLEU</b> (<b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>), METEOR (Metric for <b>Evaluation</b> of Translation with Explicit ORdering) and NIST (National Institute of Standard and Technology) with the help of a standard corpus. The results show that Google translator is far better than Bing and Babylon translators. It outperforms, on the average, Babylon by 28.55% and Bing by 15.74%. We present three natural language marking ...", "dateLastCrawled": "2022-01-26T22:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Proceedings of the International Conference on Recent Advances in ...", "url": "https://aclanthology.org/volumes/2021.ranlp-1/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/volumes/2021.ranlp-1", "snippet": "In order to simplify the <b>evaluation</b> process for poorly-resourced <b>languages</b> (in terms of STS <b>evaluation</b> datasets), we present new datasets for cross-lingual and monolingual STS for <b>languages</b> without this <b>evaluation</b> data. We also present the results of several state-of-the-art methods on these data which <b>can</b> be used as a baseline for further research. We believe that this article will not only extend the current STS research to other <b>languages</b>, but will also encourage competition on this new ...", "dateLastCrawled": "2022-01-28T13:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to Machine <b>Translation</b> | by Cyprien NIELLY | Towards Data ...", "url": "https://towardsdatascience.com/introduction-to-machine-translation-9cb0e93e7cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-machine-<b>translation</b>-9cb0e93e7cb", "snippet": "<b>BLEU</b> (<b>bilingual</b> <b>evaluation</b> <b>understudy</b>) is an algorithm for evaluating the quality of a machine-translated text. It compares the machine <b>translation</b> to one or several human-written <b>translation</b>(s), and it computes a similarity score between 0 and 1. A perfect match results in a score of 1, whereas a perfect mismatch results in a score of 0. <b>BLEU</b> score is today the benchmark metric most commonly used. Although this metric is not perfect, it has the advantage of being interpretable and easy to ...", "dateLastCrawled": "2022-01-31T02:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Neural <b>Machine Translation</b>: Inner Workings, Seq2Seq, and Transformers ...", "url": "https://towardsdatascience.com/neural-machine-translation-inner-workings-seq2seq-and-transformers-229faff5895b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-<b>machine-translation</b>-inner-workings-seq2seq-and...", "snippet": "Alternatively, people mostly use the <b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) score. It produces a score between [0,1], in some cases, we multiply it with 100 for convenience. It uses n-grams (1, 2, 3, and 4 mostly) to evaluate the translation with some additional internal tricks. But this <b>evaluation</b> mechanism might slightly fail in this example ...", "dateLastCrawled": "2022-01-29T08:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to Choose Machine Translation Software", "url": "https://blog.andovar.com/how-to-choose-machine-translation-software", "isFamilyFriendly": true, "displayUrl": "https://blog.andovar.com/how-to-choose-machine-translation-software", "snippet": "<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>BLEU</b>): Measures similarity of MT output to a set of high-quality reference translations. ... <b>Different</b> engines are best for <b>different</b> <b>languages</b>, content types, industry types, etc., so using the best-of-breed solution discussed above gives you what you need for particular projects automatically. That means you have complete coverage by all the best MT software options managed for you with the incomparable convenience of an automatic MT engine <b>evaluation</b> and ...", "dateLastCrawled": "2022-01-11T12:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Re-<b>evaluation</b> the Role of <b>Bleu in Machine Translation Research</b> ...", "url": "https://www.researchgate.net/publication/220947104_Re-evaluation_the_Role_of_Bleu_in_Machine_Translation_Research", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220947104_Re-<b>evaluation</b>_the_Role_of_<b>Bleu</b>_in...", "snippet": "Re-<b>evaluation</b> the Role of <b>Bleu in Machine Translation Research</b>. Conference: EACL 2006, 11st Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the ...", "dateLastCrawled": "2021-12-24T22:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Impact Factor 3.582 Case Studies Journal ISSN (2305-509X) \u2013 Volume 10 ...", "url": "https://www.casestudiesjournal.com/Volume%2010%20Issue%2012%20Paper%204.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.casestudiesjournal.com/Volume 10 Issue 12 Paper 4.pdf", "snippet": "<b>BLEU</b> - <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> CAT - Computer Assisted Translation DL - Deep Learning DTP - Desktop Publishing GT - Google Translate HMTE - Human Machine Translation <b>Evaluation</b> HMT - Hybrid Machine Translation ML - Machine Learning MT - Machine Translation NER - Named Entity Recognition NLG - Natural Language Generation NLP - Natural Language Processing NLTK - Natural Language Tool Kit NLU - Natural Language Understanding NN - Neural Networks POS - Part of Speech RBMT - Rule-Based ...", "dateLastCrawled": "2022-01-09T18:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Presenting artificial intelligence, deep learning, and machine learning ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8519529/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8519529", "snippet": "<b>Bilingual</b> <b>evaluation</b> <b>understudy</b>: Compares generated text with (<b>BLEU</b>) reference texts: Recall-oriented <b>Understudy</b> for: Compares generated text with : Gisting <b>Evaluation</b> (ROUGE) reference texts: Multiple measurements: Frequency weighted average: Summarizes many <b>different</b> outcomes: TP = true positive, FP = false positive, TN = true negative, FN = false negative. The confusion table. Many of the performance measures presented here are familiar to clinicians from diagnostic testing, e.g ...", "dateLastCrawled": "2021-12-01T21:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Understanding Terminologies of CAT Tools and Machine Translation ...", "url": "https://www.academia.edu/69654553/Understanding_Terminologies_of_CAT_Tools_and_Machine_Translation_Applications_Authors_Details", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69654553/<b>Understand</b>ing_Terminologies_of_CAT_Tools_and_Machine...", "snippet": "<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>BLEU</b>) Scores evaluates the fluency of the translation correlation with human <b>evaluation</b>, 3. Terminology (Ter) Scores estimates the amount of post-editing effort required, and 4. Post-editing efficiency measures the amount of engine efficiency of post-editing work. According to Lopez (14), the first campaign for the Automatic Language Processing Advisory Committee (ALPAC) already revealed the wide gap between human and machine translators. MTs are still ...", "dateLastCrawled": "2022-02-01T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "SUGAMAN: describing floor plans for visually impaired by annotation ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2018.5627", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2018.5627", "snippet": "For that purpose several metrics for example <b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b> (<b>BLEU</b>) , Recall-Oriented <b>Understudy</b> for Gisting <b>Evaluation</b> ... It <b>can</b> be observed that <b>different</b> descriptions of the same image vary inthe amount of information provided, the sequence of describing each room, thenames for each decor item could be <b>different</b> for <b>different</b> user. Also, a roommay have variations in its name for <b>different</b> user. The length of thedescriptions provided for each image is also varied. After ...", "dateLastCrawled": "2022-01-24T16:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Analysis <b>of human versus machine translation accuracy</b> \u2013 TRANSLATOLOGIA", "url": "http://www.translatologia.ukf.sk/2017/01/analysis-of-human-versus-machine-translation-accuracy/", "isFamilyFriendly": true, "displayUrl": "www.translatologia.ukf.sk/2017/01/analysis-<b>of-human-versus-machine-translation-accuracy</b>", "snippet": "Using reliable, objective, and consistent methods such as <b>BLEU</b> (<b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>) and NIST (National Institute of Standards and Technology), they translated text from 13 <b>languages</b> into English. The domain consisted of a large corpus of legal texts of importance to law librarians and law library users. Users with MT tool experience were able to identify limitations of MT, which was generally not able to identify language exceptions and ambiguities (for example lexical ambiguity ...", "dateLastCrawled": "2021-12-06T15:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Proceedings of the Fifth Conference on Machine Translation</b> - ACL Anthology", "url": "https://aclanthology.org/volumes/2020.wmt-1/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/volumes/2020.wmt-1", "snippet": "Our model has achieved Hindi to Marathi <b>bilingual</b> <b>evaluation</b> <b>understudy</b> (<b>BLEU</b>) score of 11.59, rank-based intuitive <b>bilingual</b> <b>evaluation</b> score (RIBES) score of 57.76 and translation edit rate (TER) score of 79.07 and Marathi to Hindi <b>BLEU</b> score of 15.44, RIBES score of 61.13 and TER score of 75.96. pdf bib abs Transfer Learning for Related <b>Languages</b>: Submissions to the WMT 20 Similar Language Translation Task Lovish Madaan | Soumya Sharma | Parag Singla. In this paper, we describe IIT Delhi ...", "dateLastCrawled": "2021-12-30T23:52:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> Glossary: Language <b>Evaluation</b> | Google Developers", "url": "https://developers.google.com/machine-learning/glossary/language", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/glossary/language", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) #language. A score between 0.0 and 1.0, inclusive, indicating the quality of a translation between two human languages (for example, between English and Russian). A <b>BLEU</b> score of 1.0 indicates a perfect translation; a <b>BLEU</b> score of 0.0 indicates a terrible translation. C. causal language model. #language. Synonym for unidirectional language model. See bidirectional language model to contrast different directional approaches in language modeling. crash ...", "dateLastCrawled": "2022-01-29T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Evaluation</b> of an <b>NLP</b> model \u2014 latest benchmarks | by Ria Kulshrestha ...", "url": "https://towardsdatascience.com/evaluation-of-an-nlp-model-latest-benchmarks-90fd8ce6fae5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>evaluation</b>-of-an-<b>nlp</b>-model-latest-benchmarks-90fd8ce6fae5", "snippet": "<b>BLEU</b> Score \u2014 <b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>. As the name suggests, it was originally used to evaluate translations from one language to another. How to calculate <b>BLEU</b> score? Calculating unigram precision: Step 1: Look at each word in the output sentence and assign it a score of 1 if it shows up in any of the reference sentences and 0 if it doesn\u2019t. Step 2: Normalize that count, so that it\u2019s always between 0 and 1, by dividing the number of words that showed up in one of the reference ...", "dateLastCrawled": "2022-01-28T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Natrual language processing basic concepts - language model - word ...", "url": "https://shuffleai.blog/blog/nlp_concepts_part_1.html", "isFamilyFriendly": true, "displayUrl": "https://shuffleai.blog/blog/nlp_concepts_part_1.html", "snippet": "<b>BLEU</b> stands for <b>bilingual</b> <b>evaluation</b> <b>understudy</b>. It&#39;s an automatic metric to evaluate how close a sequence of text generated by a language model is to a reference. At first, it&#39;s used to evaluate the quality of <b>machine</b> translation text. Now other natural language processing tasks such as task-oriented dialogue generation adopt it as well. For a reference &quot;The man returned to the store&quot;, a generated text &quot;the the man the&quot; would get a BLUE score as below. For each word in the generated text ...", "dateLastCrawled": "2021-12-24T07:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) pathak2019.pdf | Aditya Kumar Pathak and Priyankit Acharya ...", "url": "https://www.academia.edu/38228943/pathak2019_pdf", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/38228943/pathak2019_pdf", "snippet": "The standard metric people are using for <b>evaluation</b> of MT systems is <b>BLEU</b> score.<b>Bilingual</b> <b>evaluation</b> <b>understudy</b> (<b>BLEU</b>) is the algorithm to determine the quality of text translated by a <b>machine</b> translation. Quality is the comparison between <b>machine</b>-translated output to that of human-generated output; the closer <b>machine</b> translation is to human-generated translation, the better is the <b>BLEU</b> score. <b>BLEU</b> score is a n-gram overlap of <b>machine</b> translation to that of reference translation.<b>BLEU</b> \u00bc min ...", "dateLastCrawled": "2021-02-16T17:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "9.7. <b>Sequence</b> to <b>Sequence</b> <b>Learning</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 ...", "url": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>), though originally proposed for evaluating <b>machine</b> translation results [Papineni et al., 2002], has been extensively used in measuring the quality of output sequences for different applications.", "dateLastCrawled": "2022-01-26T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The <b>Computational</b> Limits of Deep <b>Learning</b> | DeepAI", "url": "https://deepai.org/publication/the-computational-limits-of-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/the-<b>computational</b>-limits-of-deep-<b>learning</b>", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) [papineni2002bleu] score is a metric for translation and computes the similarity between human translation and <b>machine</b> translation based on n-gram. An n-gram is a continuous sequence of n items from a given text. The score is based on precision, brevity penalty, and clipping. The modified n-gram precision ...", "dateLastCrawled": "2022-01-28T07:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Automatic Image Captioning Based on ResNet50 and</b> LSTM with ... - <b>Hindawi</b>", "url": "https://www.hindawi.com/journals/wcmc/2020/8909458/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/wcmc/2020/8909458", "snippet": "<b>BLEU</b> (<b>Bilingual</b> <b>Evaluation</b> <b>Understudy</b>) is an algorithm that measures the precision of an -gram between the generated and reference captions. <b>BLEU</b>-() scores can be calculated based on the length of the reference sentence, the generated sentence, the uniform weights, and the modified -gram precisions.", "dateLastCrawled": "2022-01-30T14:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Arti cial Intelligence Master Thesis", "url": "https://upcommons.upc.edu/bitstream/handle/2117/105513/122533.pdf?sequence=1", "isFamilyFriendly": true, "displayUrl": "https://upcommons.upc.edu/bitstream/handle/2117/105513/122533.pdf?sequence=1", "snippet": "2:87 <b>BLEU</b> (<b>BiLingual</b> <b>Evaluation</b> <b>Understudy</b>) score over the baseline; attention model, for German-English translation, and 0:34 <b>BLEU</b> score improvement for Catalan-Spanish trans-lation. Keywords <b>Machine</b> <b>Learning</b>, Deep <b>Learning</b>, Natural Language Processing, Neural <b>Machine</b> Transla-tion", "dateLastCrawled": "2021-12-27T01:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> translation from text to sign language: a systematic review ...", "url": "https://link.springer.com/article/10.1007/s10209-021-00823-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10209-021-00823-1", "snippet": "The SMT component of the system uses MOSES for generating a language model and decodes the input sentence. The approach uses the <b>BLEU</b> metric for <b>evaluation</b> and reports the scores as <b>BLEU</b>-4 12.64% <b>BLEU</b>-3 19.28% <b>BLEU</b>-2 31.48% <b>BLEU</b>-1 53.17%. The results reported are satisfactory; however, the system needs a virtual avatar tool for completeness.", "dateLastCrawled": "2022-01-30T15:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Evaluation of machine translation systems and related procedures</b>", "url": "https://www.researchgate.net/publication/326320090_Evaluation_of_machine_translation_systems_and_related_procedures", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/326320090_<b>Evaluation</b>_of_<b>machine</b>_translation...", "snippet": "<b>Evaluation of machine translation systems and related procedures</b>. June 2018 ; Journal of Engineering and Applied Sciences 13(12):3961-3972; Project: <b>Machine</b> <b>learning</b>; Authors: Musatafa Albadr ...", "dateLastCrawled": "2022-01-15T04:04:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bleu (bilingual evaluation understudy))  is like +(helps machines understand different languages)", "+(bleu (bilingual evaluation understudy)) is similar to +(helps machines understand different languages)", "+(bleu (bilingual evaluation understudy)) can be thought of as +(helps machines understand different languages)", "+(bleu (bilingual evaluation understudy)) can be compared to +(helps machines understand different languages)", "machine learning +(bleu (bilingual evaluation understudy) AND analogy)", "machine learning +(\"bleu (bilingual evaluation understudy) is like\")", "machine learning +(\"bleu (bilingual evaluation understudy) is similar\")", "machine learning +(\"just as bleu (bilingual evaluation understudy)\")", "machine learning +(\"bleu (bilingual evaluation understudy) can be thought of as\")", "machine learning +(\"bleu (bilingual evaluation understudy) can be compared to\")"]}