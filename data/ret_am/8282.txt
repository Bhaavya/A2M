{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>US20200066296A1 - Speech Enhancement And Noise Suppression Systems</b> And ...", "url": "https://patents.google.com/patent/US20200066296A1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US20200066296A1/en", "snippet": "Example <b>speech enhancement and noise suppression systems</b> and methods are described. In one implementation, a method receives an audio file comprising a combination of voice <b>data</b> and <b>noise</b> <b>data</b>, and divides the audio file into multiple frames. The method performs a discrete Fourier transform on each frame of a first subset of the multiple frames to provide a plurality of frequency-domain outputs, which are <b>input</b> to a neural network. A ratio mask is obtained as an output from the neural ...", "dateLastCrawled": "2021-12-30T07:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Security and <b>Privacy</b> Issues in <b>Deep Learning</b> | DeepAI", "url": "https://deepai.org/publication/security-and-privacy-issues-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/security-and-<b>privacy</b>-issues-in-<b>deep-learning</b>", "snippet": "Beyond <b>adding</b> different <b>noise</b> values per <b>input</b> for misclassification, ... The label can be obtained by putting the <b>data</b> as a <b>input</b> in oracle which is the target model. After training the substitute using <b>the input</b> and label pair, the authors crafted an adversarial example using Goodfellow et al. and Papernot et al. . The results of the experiment on the transferability of the MNIST case showed about 90% success rate that corresponded to the epsilon range of 0.5\u20130.9. However, if an attacker ...", "dateLastCrawled": "2022-01-18T18:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Deep Learning with Differential Privacy</b> | Request PDF", "url": "https://www.researchgate.net/publication/309444608_Deep_Learning_with_Differential_Privacy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/309444608_<b>Deep_Learning_with_Differential_Privacy</b>", "snippet": "This whole process inherits the DP property from the DP-GAN, and the subsequent step of G p is a <b>post-processing</b> step that does not alter the DP property of <b>the input</b>, according to Theorem 1.", "dateLastCrawled": "2022-01-22T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 12 Supervised Deep Learning I | Environmental Systems <b>Data</b> Science", "url": "https://stineb.github.io/esds_book/ch-12.html", "isFamilyFriendly": true, "displayUrl": "https://stineb.github.io/esds_book/ch-12.html", "snippet": "A dense layer with 512 <b>neurons</b>, each with a ReLU <b>activation</b> <b>function</b>. A single output neuron with a sigmoid <b>activation</b> <b>function</b>. The <b>function</b> takes two <b>input</b> parameters: (1) the L2 regularization rate and (2) the dropout rate. We\u2019ll look into these in detail later. build_model = <b>function</b> (L2_rate = 0, drop_rate = 0){#Name the model model.name = paste (&#39;convnet_L2_&#39;,L2_rate, &#39;_dropout_&#39;,drop_rate, sep= &quot;&quot;) #sequential model model = keras_model_sequential (name = model.name) model = model ...", "dateLastCrawled": "2021-11-27T16:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Victoria&#39;s ML Implementation Notes - Persagen Consulting", "url": "https://persagen.com/files/ml-implementation_notes.html", "isFamilyFriendly": true, "displayUrl": "https://persagen.com/files/ml-implementation_notes.html", "snippet": "By <b>adding</b> <b>noise</b> only to the problematic parts of <b>the activation</b> <b>function</b> we allow the optimization procedure to explore the boundary between the degenerate (saturating) and the well-behaved parts of <b>the activation</b> <b>function</b>. We also establish connections to simulated annealing, when the amount of <b>noise</b> is annealed down, making it easier to optimize hard objective functions. We find experimentally that replacing such saturating <b>activation</b> functions by by noisy variants helps training in many ...", "dateLastCrawled": "2022-01-17T01:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "BIR Publications", "url": "https://www.birpublications.org/doi/full/10.1259/bjr.20201107", "isFamilyFriendly": true, "displayUrl": "https://www.birpublications.org/doi/full/10.1259/bjr.20201107", "snippet": "The weight and bias are combined using <b>the activation</b> <b>function</b> to produce an <b>activation</b> that impacts the strength of connections within the network. Once an <b>input</b> has been passed through the network, it is compared to a desired output, such as an expert segmentation of an anatomical region of interest, to produce a loss. This loss is used to propagate changes to weights and biases, hence, <b>changing</b> the strength of connections for the subsequent example. The continued repetition of this two ...", "dateLastCrawled": "2022-01-16T05:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) [<b>Christopher M. Bishop] Neural Networks for Patter</b>(b-ok.org ...", "url": "https://www.academia.edu/35719617/_Christopher_M_Bishop_Neural_Networks_for_Patter_b_ok_org_", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/35719617/_<b>Christopher_M_Bishop_Neural_Networks_for_Patter</b>_b...", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-02T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Perceptual hashing for image authentication</b>: A survey - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0923596519301286", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0923596519301286", "snippet": "The traditional cryptographic hash functions are very sensitive <b>to the input</b> <b>data</b> where 1-bit change can affect the output, leading to an avalanche effect resulting in an entirely different hash. On the other hand, the perceptual hash functions are not very sensitive to small changes in <b>the input</b> <b>data</b> but are susceptible to the differences in the perceptual features of the compared object. Unlike textual <b>data</b> that is transmitted through a lossless medium, multimedia <b>data</b> <b>like</b> images (or ...", "dateLastCrawled": "2022-01-26T07:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Smart blind stick book</b> - SlideShare", "url": "https://www.slideshare.net/ahmedmaawad/smart-blind-stick-book", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ahmedmaawad/<b>smart-blind-stick-book</b>", "snippet": "More complex systems will have more layers of <b>neurons</b> with some having increased layers of <b>input</b> <b>neurons</b> and output <b>neurons</b>. The synapses store parameters called &quot;weights&quot; that manipulate the <b>data</b> in the calculations. An ANN is typically defined by three types of parameters: The interconnection pattern between different layers of <b>neurons</b> The learning process for updating the weights of the interconnections <b>The activation</b> <b>function</b> that converts a <b>neuron&#39;s</b> weighted <b>input</b> to its output ...", "dateLastCrawled": "2022-01-30T12:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Neural Network FAQ, part 1 of 7: Introduction", "url": "http://carfield.com.hk/document/ai/NeuralNetwork_FAQ.html", "isFamilyFriendly": true, "displayUrl": "carfield.com.hk/document/ai/NeuralNetwork_FAQ.html", "snippet": "The inputs to each hidden or output unit must be combined with the weights to yield a single value called the &quot;net <b>input</b>&quot; to which <b>the activation</b> <b>function</b> is applied. There does not seem to be a standard term for the <b>function</b> that combines the inputs and weights; I will use the term &quot;combination <b>function</b>&quot;. Thus, each hidden or output unit in a feedforward network first computes a combination <b>function</b> to produce the net <b>input</b>, and then applies an <b>activation</b> <b>function</b> to the net <b>input</b> yielding ...", "dateLastCrawled": "2021-12-21T18:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>US20200066296A1 - Speech Enhancement And Noise Suppression Systems</b> And ...", "url": "https://patents.google.com/patent/US20200066296A1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US20200066296A1/en", "snippet": "Example <b>speech enhancement and noise suppression systems</b> and methods are described. In one implementation, a method receives an audio file comprising a combination of voice <b>data</b> and <b>noise</b> <b>data</b>, and divides the audio file into multiple frames. The method performs a discrete Fourier transform on each frame of a first subset of the multiple frames to provide a plurality of frequency-domain outputs, which are <b>input</b> to a neural network. A ratio mask is obtained as an output from the neural ...", "dateLastCrawled": "2021-12-30T07:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Victoria&#39;s ML Implementation Notes - Persagen Consulting", "url": "https://persagen.com/files/ml-implementation_notes.html", "isFamilyFriendly": true, "displayUrl": "https://persagen.com/files/ml-implementation_notes.html", "snippet": "By <b>adding</b> <b>noise</b> only to the problematic parts of <b>the activation</b> <b>function</b> we allow the optimization procedure to explore the boundary between the degenerate (saturating) and the well-behaved parts of <b>the activation</b> <b>function</b>. We also establish connections to simulated annealing, when the amount of <b>noise</b> is annealed down, making it easier to optimize hard objective functions. We find experimentally that replacing such saturating <b>activation</b> functions by by noisy variants helps training in many ...", "dateLastCrawled": "2022-01-17T01:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Security and <b>Privacy</b> Issues in <b>Deep Learning</b> | DeepAI", "url": "https://deepai.org/publication/security-and-privacy-issues-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/security-and-<b>privacy</b>-issues-in-<b>deep-learning</b>", "snippet": "Beyond <b>adding</b> different <b>noise</b> values per <b>input</b> for misclassification, ... RNN, and MLP through <b>the input</b> format (image or sequence). The model can be trained by collecting <b>data</b> <b>similar</b> to the <b>data</b> obtained by learning the target from the public. However, The cost of collecting is enormous. Papernot et al. solved this issue using an initial synthetic dataset and Jacobian-based <b>data</b> augmentation method. If the dataset of the target is MNIST, then the initial synthetic dataset can be ...", "dateLastCrawled": "2022-01-18T18:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Combining case based reasoning with neural networks</b> | Sunil ...", "url": "https://www.academia.edu/1255369/Combining_case_based_reasoning_with_neural_networks", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/1255369/<b>Combining_case_based_reasoning_with_neural_networks</b>", "snippet": "The training <b>data</b> to be able to learn to produce a meaningful out- set of basis <b>function</b> \u2018<b>neurons</b>\u2019 can be extended to include put in the given area [12][14]. the fuzzy set\u2019s membership functions for a particular <b>input</b> This can help the designer when testing the system, as it is dimension, by forming the tensor product ( ) of the avail- easier to find gaps in the training set or areas of complex able adaptable basis functions, with the fuzzy sets for the structures in the <b>data</b>, which ...", "dateLastCrawled": "2022-01-25T05:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>DeepFool: A Simple and Accurate Method to</b> Fool Deep Neural Networks ...", "url": "https://www.researchgate.net/publication/311610675_DeepFool_A_Simple_and_Accurate_Method_to_Fool_Deep_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/311610675_<b>DeepFool_A_Simple_and_Accurate</b>...", "snippet": "At present, the most effective black-box attack methods mainly adopt <b>data</b> enhancement methods, such as <b>input</b> transformation. Previous <b>data</b> enhancement frameworks only work on <b>input</b> transformations ...", "dateLastCrawled": "2022-01-09T18:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "notes-1/Deep Learning.md at master \u00b7 kirk86/notes-1 \u00b7 <b>GitHub</b>", "url": "https://github.com/kirk86/notes-1/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/kirk86/notes-1/blob/master/Deep Learning.md", "snippet": "<b>Neurons</b>, as non-linear (e.g. sigmoidal) functions of a dot-product of their <b>input</b>, can only capture linearly separable properties of their <b>input</b> layer. Linear separability is possible when <b>the input</b> layer units are close to conditional independence, given the output classification. This is generally not true for the <b>data</b> distribution and intermediate hidden layer are required. We suggest here that the break down of the linear-separability is associated with a representational phase ...", "dateLastCrawled": "2021-12-24T03:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Neural Network FAQ, part 1 of 7: Introduction", "url": "http://carfield.com.hk/document/ai/NeuralNetwork_FAQ.html", "isFamilyFriendly": true, "displayUrl": "carfield.com.hk/document/ai/NeuralNetwork_FAQ.html", "snippet": "The inputs to each hidden or output unit must be combined with the weights to yield a single value called the &quot;net <b>input</b>&quot; to which <b>the activation</b> <b>function</b> is applied. There does not seem to be a standard term for the <b>function</b> that combines the inputs and weights; I will use the term &quot;combination <b>function</b>&quot;. Thus, each hidden or output unit in a feedforward network first computes a combination <b>function</b> to produce the net <b>input</b>, and then applies an <b>activation</b> <b>function</b> to the net <b>input</b> yielding ...", "dateLastCrawled": "2021-12-21T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Similar</b> papers - ailb-web.ing.unimore.it", "url": "https://ailb-web.ing.unimore.it/icpr/paper/355/nn", "isFamilyFriendly": true, "displayUrl": "https://ailb-web.ing.unimore.it/icpr/paper/355/nn", "snippet": "In a Convolutional Neural Network, each neuron in the output feature map takes <b>input</b> from the <b>neurons</b> in its receptive field. This receptive field concept plays a vital role in today&#39;s deep neural networks. However, inspired by neuro-biological research, it has been proposed to add inhibitory <b>neurons</b> outside the receptive field, which may enhance the performance of neural network models. In this paper, we begin with deep network architectures such as VGG and ResNet, and propose an approach ...", "dateLastCrawled": "2022-01-05T05:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Smart blind stick book</b> - SlideShare", "url": "https://www.slideshare.net/ahmedmaawad/smart-blind-stick-book", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ahmedmaawad/<b>smart-blind-stick-book</b>", "snippet": "More complex systems will have more layers of <b>neurons</b> with some having increased layers of <b>input</b> <b>neurons</b> and output <b>neurons</b>. The synapses store parameters called &quot;weights&quot; that manipulate the <b>data</b> in the calculations. An ANN is typically defined by three types of parameters: The interconnection pattern between different layers of <b>neurons</b> The learning process for updating the weights of the interconnections <b>The activation</b> <b>function</b> that converts a <b>neuron&#39;s</b> weighted <b>input</b> to its output ...", "dateLastCrawled": "2022-01-30T12:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Passive stereo vision with deep learning</b> - SlideShare", "url": "https://www.slideshare.net/yuhuang/passive-stereo-vision-with-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/yuhuang/<b>passive-stereo-vision-with-deep-learning</b>", "snippet": "Filter: A trainable filter (kernel) in filter bank connects <b>input</b> feature map to output feature map; Nonlinearity: a pointwise sigmoid tanh() or a rectified sigmoid abs(gi\u2022tanh()) <b>function</b>; In rectified <b>function</b>, gi is a trainable gain parameter, might be followed a contrast normalization N; Feature pooling: treats each feature map separately -&gt; a reduced-resolution output feature map; Supervised training is performed using a form of SGD to minimize the prediction error; Gradients are ...", "dateLastCrawled": "2022-02-02T01:50:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep Learning with Differential Privacy</b> | Request PDF", "url": "https://www.researchgate.net/publication/309444608_Deep_Learning_with_Differential_Privacy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/309444608_<b>Deep_Learning_with_Differential_Privacy</b>", "snippet": "This whole process inherits the DP property from the DP-GAN, and the subsequent step of G p is a <b>post-processing</b> step that does not alter the DP property of <b>the input</b>, according to Theorem 1.", "dateLastCrawled": "2022-01-22T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Victoria&#39;s ML Implementation Notes - Persagen", "url": "http://persagen.com/files/ml-implementation_notes.html", "isFamilyFriendly": true, "displayUrl": "persagen.com/files/ml-implementation_notes.html", "snippet": "By <b>adding</b> <b>noise</b> only to the problematic parts of <b>the activation</b> <b>function</b> we allow the optimization procedure to explore the boundary between the degenerate (saturating) and the well-behaved parts of <b>the activation</b> <b>function</b>. We also establish connections to simulated annealing, when the amount of <b>noise</b> is annealed down, making it easier to optimize hard objective functions. We find experimentally that replacing such saturating <b>activation</b> functions by by noisy variants helps training in many ...", "dateLastCrawled": "2022-02-02T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "BIR Publications", "url": "https://www.birpublications.org/doi/full/10.1259/bjr.20201107", "isFamilyFriendly": true, "displayUrl": "https://www.birpublications.org/doi/full/10.1259/bjr.20201107", "snippet": "An artificial neural network (ANN), inspired by biological <b>neurons</b>, <b>can</b> <b>be thought</b> of as a series of connected nodes containing weights and biases which are combined using an <b>activation</b> <b>function</b> to produce an <b>activation</b>; <b>the activation</b> determines the strength of connections within the network. At the heart of DL is optimisation; an ANN learns by optimising weights and biases for a generalisable solution. This optimisation occurs in a two-step process of forward propagation and ...", "dateLastCrawled": "2022-01-16T05:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "notes-1/Deep Learning.md at master \u00b7 kirk86/notes-1 \u00b7 <b>GitHub</b>", "url": "https://github.com/kirk86/notes-1/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/kirk86/notes-1/blob/master/Deep Learning.md", "snippet": "<b>Neurons</b>, as non-linear (e.g. sigmoidal) functions of a dot-product of their <b>input</b>, <b>can</b> only capture linearly separable properties of their <b>input</b> layer. Linear separability is possible when <b>the input</b> layer units are close to conditional independence, given the output classification. This is generally not true for the <b>data</b> distribution and intermediate hidden layer are required. We suggest here that the break down of the linear-separability is associated with a representational phase ...", "dateLastCrawled": "2021-12-24T03:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Advances in <b>Intelligent Systems and Computing 937</b> Emerging ...", "url": "https://www.academia.edu/39931551/Advances_in_Intelligent_Systems_and_Computing_937_Emerging_Technology_in_Modelling_and_Graphics_Proceedings_of_IEM_Graph_2018", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/39931551/Advances_in_<b>Intelligent_Systems_and_Computing_937</b>...", "snippet": "In modern world, we have to deal with huge volumes of <b>data</b> which include image, video, text and web documents, DNA, microarray gene <b>data</b>, etc. Organizing such <b>data</b> into rational groups is a critical first step to draw inferences. <b>Data</b> clustering", "dateLastCrawled": "2022-01-24T19:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Neural Network FAQ, part 1 of 7: Introduction", "url": "http://carfield.com.hk/document/ai/NeuralNetwork_FAQ.html", "isFamilyFriendly": true, "displayUrl": "carfield.com.hk/document/ai/NeuralNetwork_FAQ.html", "snippet": "Many NNs <b>can</b> <b>be thought</b> of mappings from an <b>input</b> space to an output space. Thus, loosely speaking, an NN needs to somehow &quot;monitor&quot;, cover or represent every part of its <b>input</b> space in order to know how that part of the space should be mapped. Covering <b>the input</b> space takes resources, and, in the most general case, the amount of resources needed is proportional to the hypervolume of <b>the input</b> space. The exact formulation of &quot;resources&quot; and &quot;part of <b>the input</b> space&quot; depends on the type of ...", "dateLastCrawled": "2021-12-21T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Using Recurrent Neural <b>Networks to Optimize Dynamical Decoupling</b> for ...", "url": "https://www.researchgate.net/publication/301879650_Using_Recurrent_Neural_Networks_to_Optimize_Dynamical_Decoupling_for_Quantum_Memory", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/301879650_Using_Recurrent_Neural_Networks_to...", "snippet": "The technique requires only a two-pulse echo decay curve as <b>input</b> <b>data</b> and <b>can</b> further be extended either for constructing customized optimal dynamical decoupling protocols or for obtaining ...", "dateLastCrawled": "2021-11-10T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Incorporating Human Contrast Sensitivity in Model Observers for ...", "url": "https://www.researchgate.net/publication/24041290_Incorporating_Human_Contrast_Sensitivity_in_Model_Observers_for_Detection_Tasks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/24041290_Incorporating_Human_Contrast...", "snippet": "The results also demonstrate that, in some models, the optimal internal-<b>noise</b> parameter is very sensitive to the choice of training <b>data</b>; therefore, these models are prone to overfitting, and will ...", "dateLastCrawled": "2022-01-28T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>DeepFool: A Simple and Accurate Method to</b> Fool Deep Neural Networks ...", "url": "https://www.researchgate.net/publication/311610675_DeepFool_A_Simple_and_Accurate_Method_to_Fool_Deep_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/311610675_<b>DeepFool_A_Simple_and_Accurate</b>...", "snippet": "The possibility for one to recover the parameters-weights and biases-of a neural network thanks to the knowledge of its <b>function</b> on a subset of <b>the input</b> space <b>can</b> be, depending on the situation ...", "dateLastCrawled": "2022-01-09T18:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Proc. 4 inter. conf. <b>Computer Vision and Image Processing</b>, CVIP 2019 ...", "url": "https://dokumen.pub/proc-4-inter-conf-computer-vision-and-image-processing-cvip-2019-part-2-9789811540172-9789811540189.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/proc-4-inter-conf-<b>computer-vision-and-image-processing</b>-cvip-2019...", "snippet": "\u2022 <b>Activation</b> <b>function</b>: It de\ufb01nes the output of a node when an <b>input</b> or set of inputs are fed to it. It is the non-linear element-wise operator which decides the excitation of a neuron [20\u201322]. Normalization Layer: Normalization layer are used between the convolution layer and <b>the activation</b> <b>function</b> layer to speed up the training process. It aims at acquiring an improved description of <b>the input</b> [22]. Dropout Regularization Layer: This layer helps in minimizing the over-\ufb01tting of the ...", "dateLastCrawled": "2021-12-25T21:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>US20200066296A1 - Speech Enhancement And Noise Suppression Systems</b> And ...", "url": "https://patents.google.com/patent/US20200066296A1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US20200066296A1/en", "snippet": "Example <b>speech enhancement and noise suppression systems</b> and methods are described. In one implementation, a method receives an audio file comprising a combination of voice <b>data</b> and <b>noise</b> <b>data</b>, and divides the audio file into multiple frames. The method performs a discrete Fourier transform on each frame of a first subset of the multiple frames to provide a plurality of frequency-domain outputs, which are <b>input</b> to a neural network. A ratio mask is obtained as an output from the neural ...", "dateLastCrawled": "2021-12-30T07:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Review of Detection and Removal of Raindrops in Automotive Vision Systems", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321291/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8321291", "snippet": "1. Introduction. Adverse weather conditions degrade the performance of many image and video-based algorithms used in the automotive domain. Garg and Nayar [] broadly classify adverse weather conditions into steady (fog, mist, and haze) or dynamic (rain, snow, and hail).Fog, as an example of adverse weather conditions, reduces the visible range of onboard cameras and causes loss of contrast and fidelity in captured images [2,3].Rain is a common adverse weather condition and is the focus of ...", "dateLastCrawled": "2021-12-27T16:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Improving Performance of Semantic Segmentation CycleGANs by <b>Noise</b> ...", "url": "https://www.researchgate.net/publication/357925785_Improving_Performance_of_Semantic_Segmentation_CycleGANs_by_Noise_Injection_into_the_Latent_Segmentation_Space", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357925785_Improving_Performance_of_Semantic...", "snippet": "These networks not only learn the mapping from <b>input</b> image to output image, but also learn a loss <b>function</b> to train this mapping. This makes it possible to apply the same generic approach to ...", "dateLastCrawled": "2022-01-20T09:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Security and <b>Privacy</b> Issues in <b>Deep Learning</b> | DeepAI", "url": "https://deepai.org/publication/security-and-privacy-issues-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/security-and-<b>privacy</b>-issues-in-<b>deep-learning</b>", "snippet": "Beyond <b>adding</b> different <b>noise</b> values per <b>input</b> for misclassification, ... the idea of secure multi-party training, which trains a joint <b>deep learning</b> model of private <b>data</b> <b>input</b>, has been emerging. In such training processes, the <b>data</b> <b>privacy</b> of each participant must be preserved in the face of adversarial behavior by other participants or by an external party. Hitaj et al. shows that a distributed, federated, or decentralized <b>deep learning</b> approach is fundamentally broken and does not ...", "dateLastCrawled": "2022-01-18T18:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Deep Learning with Differential Privacy</b> | Request PDF", "url": "https://www.researchgate.net/publication/309444608_Deep_Learning_with_Differential_Privacy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/309444608_<b>Deep_Learning_with_Differential_Privacy</b>", "snippet": "The possibility for one to recover the parameters-weights and biases-of a neural network thanks to the knowledge of its <b>function</b> on a subset of <b>the input</b> space <b>can</b> be, depending on the situation ...", "dateLastCrawled": "2022-01-22T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Incorporating Human Contrast Sensitivity in Model Observers for ...", "url": "https://www.researchgate.net/publication/24041290_Incorporating_Human_Contrast_Sensitivity_in_Model_Observers_for_Detection_Tasks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/24041290_Incorporating_Human_Contrast...", "snippet": "We <b>compared</b> the human and the MO performance on a simple detection task of the calcification-like discs in ROIs with and without <b>post-processing</b>. Proportion of correct responses of the human (PCH ...", "dateLastCrawled": "2022-01-28T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Chapter 12 Supervised Deep Learning I | Environmental Systems <b>Data</b> Science", "url": "https://stineb.github.io/esds_book/ch-12.html", "isFamilyFriendly": true, "displayUrl": "https://stineb.github.io/esds_book/ch-12.html", "snippet": "A dense layer with 512 <b>neurons</b>, each with a ReLU <b>activation</b> <b>function</b>. A single output neuron with a sigmoid <b>activation</b> <b>function</b>. The <b>function</b> takes two <b>input</b> parameters: (1) the L2 regularization rate and (2) the dropout rate. We\u2019ll look into these in detail later. build_model = <b>function</b> (L2_rate = 0, drop_rate = 0){#Name the model model.name = paste (&#39;convnet_L2_&#39;,L2_rate, &#39;_dropout_&#39;,drop_rate, sep= &quot;&quot;) #sequential model model = keras_model_sequential (name = model.name) model = model ...", "dateLastCrawled": "2021-11-27T16:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "BIR Publications", "url": "https://www.birpublications.org/doi/full/10.1259/bjr.20201107", "isFamilyFriendly": true, "displayUrl": "https://www.birpublications.org/doi/full/10.1259/bjr.20201107", "snippet": "The weight and bias are combined using <b>the activation</b> <b>function</b> to produce an <b>activation</b> that impacts the strength of connections within the network. Once an <b>input</b> has been passed through the network, it is <b>compared</b> to a desired output, such as an expert segmentation of an anatomical region of interest, to produce a loss. This loss is used to propagate changes to weights and biases, hence, <b>changing</b> the strength of connections for the subsequent example. The continued repetition of this two ...", "dateLastCrawled": "2022-01-16T05:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Passive stereo vision with deep learning</b> - SlideShare", "url": "https://www.slideshare.net/yuhuang/passive-stereo-vision-with-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/yuhuang/<b>passive-stereo-vision-with-deep-learning</b>", "snippet": "Denoising Auto-Encoder Multilayer NNs with target output=<b>input</b>; Reconstruction=decoder(encoder(<b>input</b>)); Perturbs <b>the input</b> x to a corrupted version; Randomly sets some of the coordinates of <b>input</b> to zeros. Recover x from encoded perturbed <b>data</b>. Learns a vector field towards higher probability regions; Pre-trained with DBN or regularizer with perturbed training <b>data</b>; Minimizes variational lower bound on a generative model; corresponds to regularized score matching on an RBM; PCA=linear ...", "dateLastCrawled": "2022-02-02T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Smart blind stick book</b> - SlideShare", "url": "https://www.slideshare.net/ahmedmaawad/smart-blind-stick-book", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ahmedmaawad/<b>smart-blind-stick-book</b>", "snippet": "More complex systems will have more layers of <b>neurons</b> with some having increased layers of <b>input</b> <b>neurons</b> and output <b>neurons</b>. The synapses store parameters called &quot;weights&quot; that manipulate the <b>data</b> in the calculations. An ANN is typically defined by three types of parameters: The interconnection pattern between different layers of <b>neurons</b> The learning process for updating the weights of the interconnections <b>The activation</b> <b>function</b> that converts a <b>neuron&#39;s</b> weighted <b>input</b> to its output ...", "dateLastCrawled": "2022-01-30T12:32:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Analogy</b> of <b>machine</b> <b>learning</b> and human thinking. [Colour online ...", "url": "https://researchgate.net/figure/Analogy-of-machine-learning-and-human-thinking-Colour-online_fig1_326306245", "isFamilyFriendly": true, "displayUrl": "https://researchgate.net/figure/<b>Analogy</b>-of-<b>machine</b>-<b>learning</b>-and-human-thinking-Colour...", "snippet": "<b>Machine</b> <b>learning</b> algorithms have already been used to develop various predictive applications in forest ecology, e.g. for carbon and energy fluxes (Zhao et al., 2017), gross primary production ...", "dateLastCrawled": "2021-06-14T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Trustworthy <b>Machine</b> <b>Learning</b> - Kush R. Varshney - Chapter 2: <b>Machine</b> ...", "url": "http://www.trustworthymachinelearning.com/trustworthymachinelearning-02.htm", "isFamilyFriendly": true, "displayUrl": "www.trustworthy<b>machinelearning</b>.com/trustworthy<b>machinelearning</b>-02.htm", "snippet": "training the model with a <b>machine</b> <b>learning</b> algorithm, and. 3. <b>post-processing</b> the model\u2019s output predictions. This idea is diagrammed in figure 2.2. Details of this step will be covered in depth throughout the book, but an overview is provided here. Figure 2.2 Main parts of trustworthy <b>machine</b> <b>learning</b> modeling. Distribution shift (red ...", "dateLastCrawled": "2022-01-07T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Data</b> Preprocessing: Concepts. Introduction to the concepts of <b>Data</b> ...", "url": "https://towardsdatascience.com/data-preprocessing-concepts-fa946d11c825", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/<b>data</b>-preprocessing-concepts-fa946d11c825", "snippet": "In any <b>Machine</b> <b>Learning</b> process, <b>Data</b> Preprocessing is that step in which the <b>data</b> gets transformed, or Encoded, to bring it to such a state that now the <b>machine</b> can easily parse it. In other words, the features of the <b>data</b> can now be easily interpreted by the algorithm. Features in <b>Machine</b> <b>Learning</b>. A dataset can be viewed as a collection of <b>data</b> objects, which are often also called as a records, points, vectors, patterns, events, cases, samples, observations, or entities. <b>Data</b> objects are ...", "dateLastCrawled": "2022-02-02T21:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "[1905.10971] An <b>Empirical Study on Post-processing</b> Methods for Word ...", "url": "https://arxiv.org/abs/1905.10971", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1905.10971", "snippet": "Word embeddings learnt from large corpora have been adopted in various applications in natural language processing and served as the general input representations to <b>learning</b> systems. Recently, a series of <b>post-processing</b> methods have been proposed to boost the performance of word embeddings on similarity comparison and <b>analogy</b> retrieval tasks, and some have been adapted to compose sentence representations. The general hypothesis behind these methods is that by enforcing the embedding space ...", "dateLastCrawled": "2021-11-13T13:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "AlphaD3M: <b>Machine</b> <b>Learning</b> Pipeline Synthesis | DeepAI", "url": "https://deepai.org/publication/alphad3m-machine-learning-pipeline-synthesis", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/alphad3m-<b>machine</b>-<b>learning</b>-pipeline-synthesis", "snippet": "Our goal is to search within a large space for the <b>machine</b> <b>learning</b>, and pre and <b>post processing</b> primitives and parameters which together constitute a pipeline for solving a task on a given dataset. The problem is that of high dimensional search. Although the datasets differ, the solution pipelines contain recurring patterns. Just as a data scientist develops intuition and patterns about the pipeline components, we use a neural network along with a Monte-Carlo tree search in an iterative ...", "dateLastCrawled": "2022-01-27T02:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "AlphaD3M: <b>Machine</b> <b>Learning</b> Pipeline Synthesis", "url": "https://www.cs.columbia.edu/~idrori/alphad3m-paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.columbia.edu/~idrori/alphad3m-paper.pdf", "snippet": "Our goal is to search within a large space for the <b>machine</b> <b>learning</b>, and pre and <b>post processing</b> primitives and parameters which together constitute a pipeline for solving a task on a given dataset. The problem is that of high dimensional search. Although the datasets di er, the solution pipelines contain recurring patterns. Just as a data scientist develops intuition and patterns about the pipeline components, we use a neural network along with a Monte-Carlo tree search in an iterative ...", "dateLastCrawled": "2021-12-25T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning</b> | Gendered Innovations", "url": "http://genderedinnovations.stanford.edu/case-studies/machinelearning.html", "isFamilyFriendly": true, "displayUrl": "genderedinnovations.stanford.edu/case-studies/<b>machinelearning</b>.html", "snippet": "Word embedding is a popular <b>machine learning</b> method that maps each English word to a geometric vector such that the distance between the vectors captures semantic similarities between the corresponding words. The embedding successfully captures <b>analogy</b> relations such as man is to king as woman is to queen. However, the same embeddings also yield man is to doctor as woman is to nurse, and man is to computer programmer as woman is to homemaker. Taking no action means that we may relive the ...", "dateLastCrawled": "2022-01-25T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Automatic Morphological Query Expansion Using Analogy</b>-Based <b>Machine</b> ...", "url": "https://www.researchgate.net/publication/221397809_Automatic_Morphological_Query_Expansion_Using_Analogy-Based_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221397809_Automatic_Morphological_Query...", "snippet": "3.1 <b>Learning</b> by <b>analogy</b> Our approac h for morphological v arian t acquisition of query terms is based on a technique initially dev elop ed to b e used in the \ufb01eld of terminology [13].", "dateLastCrawled": "2021-10-12T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>15 Greatest AI/ML Research Papers Of All Time</b> | by Naina Chaturvedi ...", "url": "https://medium.datadriveninvestor.com/15-greatest-ai-ml-research-papers-of-all-time-401221761d1c", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/<b>15-greatest-ai-ml-research-papers-of-all-time</b>...", "snippet": "Abstract \u2014 Deep <b>learning</b> frameworks have often focused on either usability or speed, but not both. PyTorch is a <b>machine</b> <b>learning</b> library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.", "dateLastCrawled": "2022-01-18T00:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "GitHub - ahernanzl/pyClimateSD", "url": "https://github.com/ahernanzl/pyClimateSD", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ahernanzl/pyClimateSD", "snippet": "Author: Alfonso Hernanz Lazaro - ahernanzl@aemet.es. License: GNU General Public License v3.0. pyClimateSD is a software for statistical downscaling of climate change projections with the following utilities: downscaling of both reanalysis and Earth System Models (ESMs). bias correction of downscaled climate projections.", "dateLastCrawled": "2022-01-27T04:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "BIR Publications", "url": "https://www.birpublications.org/doi/full/10.1259/dmfr/30642039", "isFamilyFriendly": true, "displayUrl": "https://www.birpublications.org/doi/full/10.1259/dmfr/30642039", "snippet": "<b>Artefacts</b> are common in today&#39;s cone beam CT (CBCT). They are induced by discrepancies between the mathematical modelling and the actual physical imaging process. Since <b>artefacts</b> may interfere with the diagnostic process performed on CBCT data sets, every user should be aware of their presence. This article aims to discuss the most prominent <b>artefacts</b> identified in the scientific literature and review the existing knowledge on these <b>artefacts</b>. We also briefly review the basic three ...", "dateLastCrawled": "2022-01-26T02:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Pytorch</b> model in Deep <b>Java</b> Library | by Shantanu ... - Towards Data Science", "url": "https://towardsdatascience.com/pytorch-model-in-deep-java-library-a9ca18d8ce51", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>pytorch</b>-model-in-deep-<b>java</b>-library-a9ca18d8ce51", "snippet": "<b>PyTorch</b> is a fast growing and very popular open source <b>Machine</b> <b>Learning</b> framework. Its imperative design combined with \u201cnumpy\u201d like workflow makes it a compelling first choice for beginners and professionals alike. However, serving these model in production is not straightforward and things are particularly difficult if the goal is to serve them natively in <b>Java</b>. Amazon\u2019s Deep <b>Java</b> Library (DJL) aims to sol v e this particular pain point by providing high level APIs that can run ...", "dateLastCrawled": "2022-02-03T00:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Automated extraction of chemical synthesis actions from experimental ...", "url": "https://www.nature.com/articles/s41467-020-17266-6", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-020-17266-6", "snippet": "The evaluation of the <b>machine</b>-<b>learning</b> model on the annotation test set results in a perfect match of the action sequence for 60.8% of the sentences. A detailed inspection of the incorrect ...", "dateLastCrawled": "2022-01-25T17:53:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(post-processing)  is like +(adding noise to the input data, rescaling the input data, or changing the activation function of certain neurons)", "+(post-processing) is similar to +(adding noise to the input data, rescaling the input data, or changing the activation function of certain neurons)", "+(post-processing) can be thought of as +(adding noise to the input data, rescaling the input data, or changing the activation function of certain neurons)", "+(post-processing) can be compared to +(adding noise to the input data, rescaling the input data, or changing the activation function of certain neurons)", "machine learning +(post-processing AND analogy)", "machine learning +(\"post-processing is like\")", "machine learning +(\"post-processing is similar\")", "machine learning +(\"just as post-processing\")", "machine learning +(\"post-processing can be thought of as\")", "machine learning +(\"post-processing can be compared to\")"]}