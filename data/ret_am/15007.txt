{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Learn from <b>Mistakes, a 21st Century Leadership Skill</b> \u2013 David Wray", "url": "https://davidwray.com/index.php/2020/08/31/learn-from-mistakes-a-21st-century-leadership-skill/", "isFamilyFriendly": true, "displayUrl": "https://davidwray.com/.../2020/08/31/learn-from-<b>mistakes-a-21st-century-leadership-skill</b>", "snippet": "What do these leaders look <b>like</b>? Acknowledging fallibility. Walking the talk to promote a tolerance for <b>mistakes</b>, for instance by openly acknowledging their own fallibility. Help team members understand that <b>making</b> a mistake is safe but not disclosing it or <b>learning</b> from it is an issue. Accessibility. Getting personally involved in tasks. Rolling up their sleeves and being available to support team members with a lending hand. Always taking the time to explain something (the how and why ...", "dateLastCrawled": "2022-01-23T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Making Mistakes and Learning</b> | <b>Educational Technology and Change Journal</b>", "url": "https://etcjournal.com/2013/12/30/making-mistakes-and-learning/", "isFamilyFriendly": true, "displayUrl": "https://etcjournal.com/2013/12/30/<b>making-mistakes-and-learning</b>", "snippet": "For genuinely decent labs, the <b>loss</b> harms the <b>learning</b>. The next time a science instructor tells you that he or she would <b>like</b> to see their students <b>making</b> <b>mistakes</b> in the lab, check on what sort of <b>mistakes</b> are being promoted as good. Procedural <b>mistakes</b> ruin the experience. As much of the procedure as possible should be taken out of students ...", "dateLastCrawled": "2021-12-29T09:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 <b>Reasons Why Mistakes Are Important for Success</b> | <b>Mark&#39;s Daily Apple</b>", "url": "https://www.marksdailyapple.com/6-reasons-why-mistakes-are-important-for-success/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.marksdailyapple.com</b>/6-<b>reasons-why-mistakes-are-important-for-success</b>", "snippet": "<b>Mistakes</b> move us out of the small view of success as honing <b>a skill</b> to (supposed) perfection and into a enlarging perspective that embraces success as living into encompassing actualization and fulfillment. To move on from them, we view <b>mistakes</b> against the larger backdrop of the vision we have for our lives. Doing so helps us see them in right proportion (i.e. not a big deal in the grand scheme). We surrender the <b>loss</b>, in other words, to re-affirm the vision and gather ourselves to keep ...", "dateLastCrawled": "2022-02-02T02:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Quotes About Making Mistakes</b> - Roli Edema", "url": "https://www.roliedema.com/quotes-about-making-mistakes.html", "isFamilyFriendly": true, "displayUrl": "https://www.roliedema.com/<b>quotes-about-making-mistakes</b>.html", "snippet": "It&#39;s an interesting concept that one can profit from a mistake, since we normally think of <b>mistakes</b> as a <b>loss</b>. I&#39;ve personally experienced <b>making</b> so many <b>mistakes</b> <b>while</b> <b>learning</b>, and therefore being forced to try something new every time. Although <b>making</b> <b>mistakes</b> is disappointing, this quote proves that <b>mistakes</b> can help you learn new, better ways to get stuff done. 2. &quot;Do not fear <b>mistakes</b>. There are none.&quot; - Miles Davis. There are no <b>mistakes</b>? This quote is a particularly positive one. It ...", "dateLastCrawled": "2022-01-17T08:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Why It\u2019<b>s Important To Learn From Your Mistakes</b> \u2013 Vunela", "url": "https://www.vunela.com/why-its-important-to-learn-from-your-mistakes/", "isFamilyFriendly": true, "displayUrl": "https://www.vunela.com/why-it<b>s-important-to-learn-from-your-mistakes</b>", "snippet": "And that requires <b>making</b> <b>mistakes</b>. ... But not <b>learning</b> from them is a huge <b>loss</b>. To thrive in uncertainty , experimentation and innovation are a must. And there\u2019s no invention without failure. <b>Mistakes</b> are a necessary stop, not the final destination. Embrace <b>mistakes</b> as part of the innovation journey. Define clear rules of what role errors play in your company. Innovation is messy, at least have clarity on how the game should be played. Encourage your team to take risks and make <b>mistakes</b> ...", "dateLastCrawled": "2022-02-02T08:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to <b>Learn From Your Mistakes</b> - From <b>MindTools.com</b>", "url": "https://www.mindtools.com/pages/article/learn-from-mistakes.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mindtools.com</b>/pages/article/learn-from-<b>mistakes</b>.htm", "snippet": "Tip 1: <b>Learning</b> from <b>mistakes</b>, and putting that <b>learning</b> into practice, involves change. If that change will impact other people, the ADKAR Change Management Model could help you to get them &quot;on board&quot; \u2013 and to keep them there.. Tip 2: Don&#39;t be afraid to ask colleagues or your manager for help if you&#39;re unsure which tactic or tool will be the most effective in preventing further <b>mistakes</b>.", "dateLastCrawled": "2022-02-03T05:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Learning from Mistakes</b> - ResearchGate", "url": "https://www.researchgate.net/publication/323695816_Learning_from_Mistakes", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323695816_<b>Learning_from_Mistakes</b>", "snippet": "<b>While</b> people do <b>like</b> to hear positive feedback, ... in their decision <b>making</b> process. Managers can test ... <b>Learning from mistakes</b> i s <b>a skill</b> that marks successful individuals and organizations ...", "dateLastCrawled": "2022-01-28T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The <b>Most Common Fat Loss Mistakes</b> \u2014 JAY DARKO FITNESS", "url": "https://www.jaydarkofitness.com/blog/2018/9/28/my-biggest-training-struggles-early-on-fy7t4-5rwk9", "isFamilyFriendly": true, "displayUrl": "https://www.jaydarkofitness.com/blog/2018/9/28/my-biggest-training-struggles-early-on...", "snippet": "The <b>Most Common Fat Loss Mistakes</b>. There are a lot of fitness myths and fads that might be overhyped and would derail your overall progress. To aid your journey, Here are the most common <b>mistakes</b> I see people <b>making</b> when it comes to fat <b>loss</b>. Cutting/ losing weight too quickly \u2013 This is a surefire way lose muscle &amp; strength rapidly. Focus on eating as many calories as possible whilst still losing fat at a steady rate so you can maintain your hard earned muscle mass and strength. Consuming ...", "dateLastCrawled": "2021-12-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Top Tier Strategy: Making Mistakes- and Learning</b> From Them - The Rathe ...", "url": "https://rathetimes.com/articles/top-tier-strategy-making-mistakes-and-learning-from-them", "isFamilyFriendly": true, "displayUrl": "https://rathetimes.com/articles/<b>top-tier-strategy-making-mistakes-and-learning</b>-from-them", "snippet": "<b>Top Tier Strategy: Making Mistakes- and Learning</b> From Them. Welcome to my new series where I look back at 20+ years of playing games competitively and share with you what I\u2019ve learned, from the grand successes to the embarrassing failures. From game theory to self-improvement, this series will focus on how you can improve as a player and ...", "dateLastCrawled": "2022-01-14T19:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "29 Inspiring Similes &amp; Metaphors about <b>Learning</b> that Pop!", "url": "https://helpfulprofessor.com/metaphors-for-learning/", "isFamilyFriendly": true, "displayUrl": "https://helpfulprofessor.com/metaphors-for-<b>learning</b>", "snippet": "<b>Learning</b> <b>is like</b> <b>making</b> new friends. Friends provide advice, input, and humor in our lives. When we learn new things, we get some similar benefits. We get advice from books and movies we learn from; and when we learn new things, we can get that same excitement that we can get from new friends. Related: 13 Qualities of a Good College Student; Related: 107 Adjectives to Describe Education; 8. <b>Learning</b> is a Gift. This metaphor reminds us that <b>learning</b> is something we shouldn\u2019t take for ...", "dateLastCrawled": "2022-02-02T03:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Mistakes</b> are Critical to Learn | CAL Sports Academy", "url": "https://calsportsacademy.com/mistakes-are-critical-to-learn/", "isFamilyFriendly": true, "displayUrl": "https://calsportsacademy.com/<b>mistakes</b>-are-critical-to-learn", "snippet": "<b>Mistakes</b> occur during a <b>learning</b> process of a new <b>skill</b>, technique, or sport. <b>Making</b> a mistake can assist the athlete to learn to prevent this from occurring again in the future. Practice is a time for <b>learning</b> new skills, then <b>making</b> <b>mistakes</b> to perfect the <b>skill</b>. During competitions, <b>mistakes</b> occur that provide teams and individual athletes with the opportunity to learn from a <b>loss</b> to gain success for the future.", "dateLastCrawled": "2022-01-26T19:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Lose</b>, lost, loose and <b>loss</b> \u2013 Do you understand the difference? - eAge Tutor", "url": "https://english.eagetutor.com/spoken-english-grammar/lose-lost-loose-and-loss-do-you-understand-the-difference", "isFamilyFriendly": true, "displayUrl": "https://english.eagetutor.com/spoken-english-grammar/<b>lose</b>-lost-loose-and-<b>loss</b>-do-you...", "snippet": "They seem to be <b>similar</b> but they are used at different situations. For Example- The jeans which you bought for me yesterday from the market, is too loose. Do you think in this situation, the <b>lose</b> can be replaced with loose? No. So let us have a look at some more examples of the same kind and clear out our confusion between the uses of these words. Common <b>mistakes</b> to avoid between <b>lose</b>, loose, lost and <b>loss</b> 1. <b>Lose</b> <b>Lose</b> is a verb and it is used when you are not able to find something. Example ...", "dateLastCrawled": "2022-01-30T08:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Why It\u2019<b>s Important To Learn From Your Mistakes</b> \u2013 Vunela", "url": "https://www.vunela.com/why-its-important-to-learn-from-your-mistakes/", "isFamilyFriendly": true, "displayUrl": "https://www.vunela.com/why-it<b>s-important-to-learn-from-your-mistakes</b>", "snippet": "And that requires <b>making</b> <b>mistakes</b>. ... But not <b>learning</b> from them is a huge <b>loss</b>. To thrive in uncertainty , experimentation and innovation are a must. And there\u2019s no invention without failure. <b>Mistakes</b> are a necessary stop, not the final destination. Embrace <b>mistakes</b> as part of the innovation journey. Define clear rules of what role errors play in your company. Innovation is messy, at least have clarity on how the game should be played. Encourage your team to take risks and make <b>mistakes</b> ...", "dateLastCrawled": "2022-02-02T08:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>The Challenge of Learning Anticipatory</b> Service: <b>Making</b> <b>Mistakes</b> ...", "url": "https://www.submissiveguide.com/skills/articles/the-challenge-of-learning-anticipatory-servic", "isFamilyFriendly": true, "displayUrl": "https://www.submissiveguide.com/<b>skills</b>/articles/<b>the-challenge-of-learning-anticipatory</b>...", "snippet": "<b>While</b> some Masters reject anticipatory service entirely, for this reason, others simply don\u2019t enjoy it because they dislike the implied momentary <b>loss</b> of governance. They prefer the control of giving all orders and having them fulfilled, on command. In service, these Masters tend to favor immediate obedience over supposition. They dislike the lack of control inherent in moments the servant is preparing to meet a likely need\u2014they would prefer to voice their needs explicitly and have them ...", "dateLastCrawled": "2022-01-03T13:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Learning from Mistakes</b> - ResearchGate", "url": "https://www.researchgate.net/publication/323695816_Learning_from_Mistakes", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323695816_<b>Learning_from_Mistakes</b>", "snippet": "<b>Learning from mistakes</b> i s <b>a skill</b> that marks successful individuals and organizations, and not all have it. It\u201fs also <b>a skill</b> that can be l earned, but not before getting over an emotional ...", "dateLastCrawled": "2022-01-28T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "8 Training <b>Mistakes</b> That Can Seriously Hinder Your Progress | <b>BarBend</b>", "url": "https://barbend.com/strength-training-mistakes/", "isFamilyFriendly": true, "displayUrl": "https://<b>barbend</b>.com/strength-training-<b>mistakes</b>", "snippet": "<b>While</b> <b>making</b> <b>mistakes</b> may be part of the <b>learning</b> process, reducing them <b>while</b> you\u2019re under the bar will help keep you safe, more efficiently hit your goals, and minimize your medical bills. Let ...", "dateLastCrawled": "2022-01-30T14:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How <b>Making</b> <b>Mistakes</b> Can Accelerate <b>Learning</b> - Bulletproof Musician", "url": "https://bulletproofmusician.com/how-making-mistakes-can-accelerate-learning/", "isFamilyFriendly": true, "displayUrl": "https://bulletproofmusician.com/how-<b>making</b>-<b>mistakes</b>-can-accelerate-<b>learning</b>", "snippet": "Aren\u2019t <b>making</b> <b>mistakes</b>, missing shifts, and cracking notes bad for our confidence, and won\u2019t they lead to the reinforcement of bad habits? The benefits of inconsistent performance. Researchers at the University of Sheffield studied player data from an online game called Axon (play the game here or watch a short video if you want to avoid getting hooked). Their study generated a number of interesting findings about the <b>learning</b> process, but one of the more intriguing findings was that ...", "dateLastCrawled": "2022-01-26T19:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Has anyone else ever experienced losing his/her <b>skill</b> in <b>a skill</b> based ...", "url": "https://www.reddit.com/r/truegaming/comments/80mzja/has_anyone_else_ever_experienced_losing_hisher/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/truegaming/comments/80mzja/has_anyone_else_ever_experienced...", "snippet": "Now I not only realised that a <b>similar</b> thing happend to me a year or so ago but also that the circumstances were <b>similar</b>. Back then I was very self-concious because I felt I was not living up to what I should do or what others expected me to do in school and life in generell. Right now I think that I am in a very <b>similar</b> situation because I&#39;m struggeling with many task that I want and have to fulfill at the same time like passing driving test to get my license(yep, I am rather young ...", "dateLastCrawled": "2021-11-13T13:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "linkedin-<b>skill</b>-assessments-quizzes/machine-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/Ebazhanov/linkedin-<b>skill</b>-assessments-quizzes/blob/master/machine...", "snippet": "Machine <b>learning</b> algorithms are powerful enough to eliminate bias from the data. All human-created data is biased, and data scientists need to account for that. Explanation: <b>While</b> machine <b>learning</b> algorithms don&#39;t have bias, the data can have them. Q21. What is stacking? The predictions of one model become the inputs another.", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>5 Common Negotiation Mistakes and How You</b> Can Avoid Them - PON ...", "url": "https://www.pon.harvard.edu/daily/negotiation-skills-daily/5-common-negotiation-mistakes-and-how-you-can-avoid-them/", "isFamilyFriendly": true, "displayUrl": "https://www.pon.harvard.edu/daily/negotiation-<b>skills</b>-daily/5-common-negotiation...", "snippet": "We are all prone <b>to making</b> the same negotiation <b>mistakes</b>. Fortunately, through awareness, preparation, and practice, we can begin to overcome our negotiation <b>mistakes</b> and reach better deals. By Katie Shonk \u2014 on January 20th, 2022 / Negotiation Skills. Comment. Sometimes our negotiation <b>mistakes</b> are glaring: We accidentally reveal our bottom line, criticize the other party when patience was warranted, or get our numbers mixed up. More often, though, our negotiation <b>mistakes</b> are invisible ...", "dateLastCrawled": "2022-02-02T16:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "6 <b>Reasons Why Mistakes Are Important for Success</b> | <b>Mark&#39;s Daily Apple</b>", "url": "https://www.marksdailyapple.com/6-reasons-why-mistakes-are-important-for-success/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.marksdailyapple.com</b>/6-<b>reasons-why-mistakes-are-important-for-success</b>", "snippet": "<b>Mistakes</b> move us out of the small view of success as honing <b>a skill</b> to (supposed) perfection and into a enlarging perspective that embraces success as living into encompassing actualization and fulfillment. To move on from them, we view <b>mistakes</b> against the larger backdrop of the vision we have for our lives. Doing so helps us see them in right proportion (i.e. not a big deal in the grand scheme). We surrender the <b>loss</b>, in other words, to re-affirm the vision and gather ourselves to keep ...", "dateLastCrawled": "2022-02-02T02:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "7 Steps to Learn from <b>Mistakes</b> and Grow as a Person", "url": "https://www.developgoodhabits.com/learn-mistakes/", "isFamilyFriendly": true, "displayUrl": "https://www.developgoodhabits.com/learn-<b>mistakes</b>", "snippet": "<b>Mistakes</b> come in many forms\u2013some <b>can</b> be deadly, some <b>can</b> lead to the <b>loss</b> of money or friends, and others have few consequences and are often overlooked. But no matter what type of mistake you make, you should analyze the reasoning behind it to keep it from happening again. Feeling ashamed of <b>making</b> a mistake or trying to deny that it occurred will interfere with your ability to learn from it.", "dateLastCrawled": "2022-02-02T19:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Top Tier Strategy: Making Mistakes- and Learning</b> From Them - The Rathe ...", "url": "https://rathetimes.com/articles/top-tier-strategy-making-mistakes-and-learning-from-them", "isFamilyFriendly": true, "displayUrl": "https://rathetimes.com/articles/<b>top-tier-strategy-making-mistakes-and-learning</b>-from-them", "snippet": "As a follow-up to my prior article, your opponent <b>can</b> actually be a terrific source of <b>learning</b> after a game. If you have developed a rapport with them, strike up a conversation at the end of the game. Talk about your play, what you were thinking, and ask them their thoughts on the same. Often they will talk about how scared they were of X happening, or how they wanted you to make the decision you did so they could do Y. Either way, you learn a lot by seeing the other side of the game.", "dateLastCrawled": "2022-01-14T19:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Quotes About Making Mistakes</b> - Roli Edema", "url": "https://www.roliedema.com/quotes-about-making-mistakes.html", "isFamilyFriendly": true, "displayUrl": "https://www.roliedema.com/<b>quotes-about-making-mistakes</b>.html", "snippet": "Top <b>Quotes About Making Mistakes</b> That We <b>Can</b> All Learn From - 1. &quot;The successful man will profit from his <b>mistakes</b> and try again in a different way.&quot; - Dale Carnegie. This is a quote about <b>making</b> <b>mistakes</b> that I recently discovered. It&#39;s an interesting concept that one <b>can</b> profit from a mistake, since we normally think of <b>mistakes</b> as a <b>loss</b>. I&#39;ve personally experienced <b>making</b> so many <b>mistakes</b> <b>while</b> <b>learning</b>, and therefore being forced to try something new every time. Although <b>making</b> <b>mistakes</b> ...", "dateLastCrawled": "2022-01-17T08:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How <b>Making</b> <b>Mistakes</b> <b>Can</b> Accelerate <b>Learning</b> - Bulletproof Musician", "url": "https://bulletproofmusician.com/how-making-mistakes-can-accelerate-learning/", "isFamilyFriendly": true, "displayUrl": "https://bulletproofmusician.com/how-<b>making</b>-<b>mistakes</b>-<b>can</b>-accelerate-<b>learning</b>", "snippet": "A few months ago, I decided to take a page out of Indiana Jones&#39;s playbook, and embarked on a quest.Not for the holy grail, or some noble intellectual pursuit...But for the best nachos in my neighborhood.Yep. Every Saturday evening, for the last couple months, I&#39;ve ordered nachos from a different place.Chili nachos. Chicken ranchero nachos. Nachos texanos. Nachos el grande deluxe.But every weekend, I&#39;m faced with a dilemma.", "dateLastCrawled": "2022-01-26T19:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Learning from Mistakes</b> - ResearchGate", "url": "https://www.researchgate.net/publication/323695816_Learning_from_Mistakes", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323695816_<b>Learning_from_Mistakes</b>", "snippet": "<b>Learning from mistakes</b> i s <b>a skill</b> that marks successful individuals and organizations, and not all have it. It\u201fs also <b>a skill</b> that <b>can</b> be l earned, but not before getting over an emotional ...", "dateLastCrawled": "2022-01-28T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is a mistake? What is an error? Words have meanings.", "url": "https://www.thehumandiver.com/blog/mistakes-errors-words-have-meaning", "isFamilyFriendly": true, "displayUrl": "https://www.thehumandiver.com/blog/<b>mistakes</b>-errors-words-have-meaning", "snippet": "This might be where you take a wrong turn <b>while</b> driving because you were thinking back to your previous experience of driving down this road; giving a dive brief to navigate a wreck and describe the wreck entry point as the 2nd hatchway instead of the 3rd; teaching a student how to undertake a specific in-water <b>skill</b> but your idea of how to teach it is flawed because you\u2019ve slowly drifted from your previous training. In each of the above situations, we consider them to be errors of ...", "dateLastCrawled": "2022-01-24T10:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Best Way to Master <b>Skill</b> Development - Chris Sajnog&#39;s Blog - Learn ...", "url": "https://www.chrissajnog.com/blog/five-stages-of-skill-development/", "isFamilyFriendly": true, "displayUrl": "https://www.chrissajnog.com/blog/five-stages-of-<b>skill</b>-development", "snippet": "I spend a lot of time talking about <b>learning</b> and <b>skill</b> development as it relates to shooting, ... you still do not understand or know how to execute the <b>skill</b>, but the <b>making</b> of <b>mistakes</b> <b>can</b> be integral to your <b>learning</b> process and you need to be comfortable <b>making</b> <b>mistakes</b>. The realization that you don\u2019t know how to do something that you need or want to do <b>can</b> be difficult to handle. Some people experience a <b>loss</b> of confidence and feel like giving up before they even attempt to become ...", "dateLastCrawled": "2022-01-21T18:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Learning</b> Styles MCQ [Free PDF] - Objective Question Answer for <b>Learning</b> ...", "url": "https://testbook.com/objective-questions/mcq-on-learning-styles--5eea6a1539140f30f369f4f6", "isFamilyFriendly": true, "displayUrl": "https://testbook.com/objective-questions/mcq-on-<b>learning</b>-styles--5eea6a1539140f30f369f4f6", "snippet": "&#39;<b>Learning</b>&#39; means a relatively permanent change in behaviour that occurs as a result of experience with the environment. <b>Learning</b> is a process of acquiring knowledge and remembering information so that it may be applied to life situations.. <b>Learning</b> is fostered when the learner has opportunities to practice the new information, receive feedback and apply the knowledge or <b>skill</b> in familiar and unfamiliar situations, with less and less assistance from others. Some general guidelines to help the ...", "dateLastCrawled": "2022-02-02T15:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Has anyone else ever experienced losing his/her <b>skill</b> in <b>a skill</b> based ...", "url": "https://www.reddit.com/r/truegaming/comments/80mzja/has_anyone_else_ever_experienced_losing_hisher/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/truegaming/comments/80mzja/has_anyone_else_ever_experienced...", "snippet": "You might have played in a mental situation where you anticipated <b>making</b> <b>mistakes</b>, and every actual mistake you made in the game was amplified in your perception, and nurtured your doubt, therefore increasing stress level and and the probability of additional <b>mistakes</b>. Just try to take it easy, don&#39;t pressure yourself. 8. Share. Report Save. level 2 \u00b7 4y \u00b7 edited 4y. Haruki Murakami. which story. also i&#39;ve fallen victim to this. when you perform well in a game you adapt all of those ...", "dateLastCrawled": "2021-11-13T13:08:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Simulation-based <b>learning</b>: Just like the real thing", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2966567/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2966567", "snippet": "The simulated environment allows <b>learning</b> and re-<b>learning</b> as often as required to correct <b>mistakes</b>, allowing the trainee to perfect steps and fine-tune skills to optimize clinical outcomes.[5,6] There <b>can</b> also be simulated examples or scenarios of rare or unusual cases that are often hard to come by in the clinical settings. The simulated situation and scenarios <b>can</b> give students and inexperienced junior doctors realistic exposure to such cases. It <b>can</b> certainly help in <b>making</b> books and ...", "dateLastCrawled": "2022-02-03T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Experiential <b>Learning Vs. Traditional Learning Methodologies</b> - KNOLSKAPE", "url": "https://knolskape.com/experiential-learning-vs-traditional-learning-methodologies/", "isFamilyFriendly": true, "displayUrl": "https://knolskape.com/experiential-<b>learning-vs-traditional-learning-methodologies</b>", "snippet": "Experiential <b>Learning Vs. Traditional Learning Methodologies</b>. More than a hundred years ago, Hermann Ebbinghaus formulated the <b>learning</b> curve, which describes the relationship between memory and time. In a nutshell, it says that, during a lecture, if your absorption rate is at 100 percent on day one, there is a 50-80 percent <b>loss</b> of <b>learning</b> ...", "dateLastCrawled": "2022-02-03T16:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-curve", "snippet": "A <b>learning</b> curve is a plot of model <b>learning</b> performance over experience or time. <b>Learning</b> curves are a widely used diagnostic tool in <b>machine learning</b> for algorithms that learn from a training dataset incrementally. The model <b>can</b> be evaluated on the training dataset and on a hold out validation dataset after each update during training and plots of the measured performance", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "English Pedagogy MCQ [Free PDF] - Objective Question Answer for English ...", "url": "https://testbook.com/objective-questions/mcq-on-english-pedagogy--5eea6a0839140f30f369d8a5", "isFamilyFriendly": true, "displayUrl": "https://testbook.com/objective-questions/mcq-on-english-pedagogy--5eea6a0839140f30f369d8a5", "snippet": "Remedial teaching: During <b>learning</b>, a child makes <b>mistakes</b> willingly-unwillingly or due to some alternative conceptions. It is the job of a teacher to help students to correct those <b>mistakes</b> after diagnosing them. The method so followed is known as remedial teaching. The following are its characteristics: It <b>can</b> be used for improving language ...", "dateLastCrawled": "2022-02-02T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning</b> New Skills: 10 In-Demand Skills To Learn Online", "url": "https://www.lifehack.org/909191/learning-new-skills", "isFamilyFriendly": true, "displayUrl": "https://<b>www.lifehack.org</b>/909191/<b>learning</b>-new-<b>skills</b>", "snippet": "Cultures bond and borrow the good from one another <b>while</b> also <b>learning</b> from each other\u2019s experiences and perspectives. That\u2019s why <b>learning</b> a foreign language will put you ahead of the pack. In addition, scientific research has shown that <b>learning</b> a second language improves your brain and critical thinking. [1] 3. Coding. For most people who haven\u2019t dabbed into computer programming, the word coding is just as scary as a spacewalk. It sounds alien and downright impossible to grasp. The ...", "dateLastCrawled": "2021-12-12T16:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "linkedin-<b>skill</b>-assessments-quizzes/machine-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/Ebazhanov/linkedin-<b>skill</b>-assessments-quizzes/blob/master/machine...", "snippet": "Machine <b>learning</b> algorithms are powerful enough to eliminate bias from the data. All human-created data is biased, and data scientists need to account for that. Explanation: <b>While</b> machine <b>learning</b> algorithms don&#39;t have bias, the data <b>can</b> have them. Q21. What is stacking? The predictions of one model become the inputs another.", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Has anyone else ever experienced losing his/her <b>skill</b> in <b>a skill</b> based ...", "url": "https://www.reddit.com/r/truegaming/comments/80mzja/has_anyone_else_ever_experienced_losing_hisher/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/truegaming/comments/80mzja/has_anyone_else_ever_experienced...", "snippet": "You might have played in a mental situation where you anticipated <b>making</b> <b>mistakes</b>, and every actual mistake you made in the game was amplified in your perception, and nurtured your doubt, therefore increasing stress level and and the probability of additional <b>mistakes</b>. Just try to take it easy, don&#39;t pressure yourself. 8. Share. Report Save. level 2 \u00b7 4y \u00b7 edited 4y. Haruki Murakami. which story. also i&#39;ve fallen victim to this. when you perform well in a game you adapt all of those ...", "dateLastCrawled": "2021-11-13T13:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>LinkedIn: Machine Learning | Skill Assessment Quiz Solutions</b>", "url": "https://www.apdaga.com/2021/03/linkedin-machine-learning-skill-assessment-quiz-solutions.html", "isFamilyFriendly": true, "displayUrl": "https://www.apdaga.com/2021/03/<b>linkedin-machine-learning-skill-assessment-quiz</b>...", "snippet": "Machine <b>learning</b> servers <b>can</b> host larger databases. The algorithms <b>can</b> run on unstructured data. You work for an insurance company. Which machine <b>learning</b> project would add the most value for the company! Create an artificial neural network that would host the company directory. Use machine <b>learning</b> to better predict risk.", "dateLastCrawled": "2022-01-30T11:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How <b>to Improve Decision Making Skills in</b> the Workplace? - Learn a ...", "url": "https://learnacourseonline.com/how-to-improve-decision-making-skills-in-the-workplace/", "isFamilyFriendly": true, "displayUrl": "https://learnacourseonline.com/how-<b>to-improve-decision-making-skills-in</b>-the-workplace", "snippet": "Decision <b>making</b> as a team. When working as a group, this <b>skill</b> <b>can</b> be utilized extremely well, gathering the opinion s from a wide variety of sources. This not only increases the chances of <b>making</b> a suitable choice, but makes workers feel more involved; in turn strengthening the trust and bond in work relationships.", "dateLastCrawled": "2022-01-28T21:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "30 Best Quotes to Inspire You to Never Stop <b>Learning</b>", "url": "https://www.lifehack.org/articles/communication/30-best-quotes-inspire-you-never-stop-learning.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.lifehack.org</b>/.../30-best-quotes-inspire-you-never-stop-<b>learning</b>.html", "snippet": "In this rapidly changing world, traditional education skills just don\u2019t cut it anymore. You <b>can</b>\u2019t afford to take years <b>learning</b> <b>a skill</b> you\u2019ll never really practice. Besides offering some paid courses that will help you become a better self, it offers a list of free courses which aim to train some of the Core Life Multipliers including: How to stop procrastinating to reach your goal \u2013 Hack Your Procrastination; These are cross-functional skills that work across many aspects of life ...", "dateLastCrawled": "2022-01-26T05:40:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> fundamentals I: An <b>analogy</b> | Finn Rietz.dev", "url": "http://www.finnrietz.dev/machine%20learning/part-1-analogy/", "isFamilyFriendly": true, "displayUrl": "www.finnrietz.dev/<b>machine</b> <b>learning</b>/part-1-<b>analogy</b>", "snippet": "And this is what the <b>loss</b> function does, so the <b>loss</b> function for a <b>Machine</b> <b>learning</b> algorithm is like the teacher for the real-world dermatologist in-training. In mathematical terms, the <b>loss</b> function could look something like this: \\(L = (y_i - \\hat{y_i})^2\\), where \\(y_i\\) is the actual output value (the one that the teacher has written down) and \\(\\hat{y_i}\\) is the one our <b>learning</b> algorithm produced.", "dateLastCrawled": "2022-01-16T09:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "Minimize a <b>loss</b> function in ... and it has been used for conducting research and for deploying <b>machine</b> <b>learning</b> systems into production across more than a dozen areas of computer science and other ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding the 3 most common <b>loss</b> functions for <b>Machine</b> <b>Learning</b> ...", "url": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-the-3-most-common-<b>loss</b>-functions-for...", "snippet": "A <b>loss function</b> in <b>Machine</b> <b>Learning</b> is a measure of how accurately your ML model is able to predict the expected outcome i.e the ground truth. The <b>loss function</b> will take two items as input: the output value of our model and the ground truth expected value. The output of the <b>loss function</b> is called the <b>loss</b> which is a measure of how well our model did at predicting the outcome. A high value for the <b>loss</b> means our model performed very poorly. A low value for the <b>loss</b> means our model performed ...", "dateLastCrawled": "2022-02-02T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Is training <b>a neural network</b> like forming a habit? | Blog", "url": "https://jmsbrdy.com/blog/habit-formation-as-analogy-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://jmsbrdy.com/blog/habit-formation-as-<b>analogy</b>-for-<b>machine</b>-<b>learning</b>", "snippet": "Reward: during backpropagation, update our input weights according to the <b>loss</b> function; In fact, the <b>analogy</b> also works at the level of the network as a whole: Cue: transform our input example and input it into the first layer of the network; Routine: the network processes the input through its layers to produce a result; Reward: calculate how accurate the result is \u2013 compared to the labeling of the input example \u2013 and backpropagate; So, from a process perspective there do seem to broad ...", "dateLastCrawled": "2021-12-29T12:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Human learning as an analogy of machine learning</b> - Weina Jin, MD", "url": "https://weina.me/ml-vs-human-learning/", "isFamilyFriendly": true, "displayUrl": "https://weina.me/ml-vs-human-<b>learning</b>", "snippet": "<b>Human learning as an analogy of machine learning</b>. 5 minute read. Published: July 24, 2018. These days, during my reading of computer vision papers, I discover a recurrent theme: to orient CNN-based network to a specific CV task, most papers focus on designing new architectures of the network and/or <b>loss</b> functions. This approach seems obvious.", "dateLastCrawled": "2020-07-13T08:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[2111.09109] Physics-guided <b>Loss</b> Functions Improve Deep <b>Learning</b> ...", "url": "https://arxiv.org/abs/2111.09109", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2111.09109", "snippet": "Computer Science &gt; <b>Machine</b> <b>Learning</b>. arXiv:2111.09109 (cs) [Submitted on 13 Nov 2021] ... we analyse the <b>analogy</b> between DNN solvers and traditional iterative algorithms and discuss how important physical phenomena cannot be effectively incorporated in the training process. We show the importance of including near-field priors in the <b>learning</b> process of DNNs. To this end, we propose new designs of <b>loss</b> functions which incorporate multiple-scattering based near-field quantities (such as ...", "dateLastCrawled": "2022-01-07T13:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The intuition of <b>Triplet Loss</b>. Getting an essence of how <b>loss</b> is\u2026 | by ...", "url": "https://medium.com/analytics-vidhya/triplet-loss-b9da35be21b8", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>triplet-loss</b>-b9da35be21b8", "snippet": "Many of us feel <b>Machine</b> <b>learning</b> is a black box that takes some input and gives out some fantastic output. In recent years, this same Black box has been creating wonders by acting as a mimic of\u2026", "dateLastCrawled": "2022-01-23T03:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>About loss and loss functions</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2019/10/04/about-loss-and-loss-functions/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2019/10/04/<b>about-loss-and-loss-functions</b>", "snippet": "The high-level supervised <b>learning</b> process. Before we can actually introduce the concept of loss, we\u2019ll have to take a look at the high-level supervised <b>machine</b> <b>learning</b> process.All supervised training approaches fall under this process, which means that it is equal for deep neural networks such as MLPs or ConvNets, but also for SVMs.. Let\u2019s take a look at this training process, which is cyclical in nature.", "dateLastCrawled": "2022-01-25T13:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>machine</b> <b>learning</b> - Why there is sudden drop in loss after every epoch ...", "url": "https://stackoverflow.com/questions/57248723/why-there-is-sudden-drop-in-loss-after-every-epoch", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/57248723", "snippet": "<b>machine</b>-<b>learning</b> keras deep-<b>learning</b> loss-function. Share. Follow edited Jul 29 &#39;19 at 12:40. Community Bot. 1 1 1 silver badge. asked Jul 29 &#39;19 at 7:09. Rahul Anand Rahul Anand. 389 1 1 gold badge 3 3 silver badges 15 15 bronze badges. Add a comment | 2 Answers Active Oldest Votes. 11 Note: This answer is assuming you are using Keras -- you might want to add this information to your post or at least add a relevant tag. ...", "dateLastCrawled": "2022-01-21T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>machine</b> <b>learning</b> - In training a triplet network, I first have a solid ...", "url": "https://stats.stackexchange.com/questions/475655/in-training-a-triplet-network-i-first-have-a-solid-drop-in-loss-but-eventually", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/475655/in-training-a-triplet-network-i-first...", "snippet": "Changing the losses changes the tasks, so comparing the value of semi-hard loss to batch hard <b>loss is like</b> comparing apples to oranges. Because of how semi-hard loss is defined, its value will always be smaller than ordinary triplet loss. But we still want to achieve the inequality $(*)$! To make a consistent comparison as training progresses, you should measure the loss on the hardest task throughout training to confirm that the model is, indeed, improving as you change tasks during ...", "dateLastCrawled": "2022-02-03T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Comparing images in frequency domain. \u201cSpectral loss\u201d \u2013 does it make ...", "url": "https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss-does-it-make-sense/", "isFamilyFriendly": true, "displayUrl": "https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss...", "snippet": "I\u2019ve touched upon loss functions in my previous <b>machine</b> <b>learning</b> oriented posts (I\u2019ll highlight the separable filter optimization and generating blue noise through optimization, where in both I discuss some properties of a good loss), but for a fast recap \u2013 in <b>machine</b> <b>learning</b>, loss function is a \u201ccost\u201d that the optimization process tries to minimize. Loss functions are designed to capture aspects of the process / function that we want to \u201cimprove\u201d or solve. They can be also ...", "dateLastCrawled": "2022-01-28T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "class4x.pdf - <b>Machine</b> <b>Learning</b> Topic 4 \\u2022\\u2008Perceptron Online ...", "url": "https://www.coursehero.com/file/107174025/class4xpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/107174025/class4xpdf", "snippet": "\u2022Multi-Layer Network can handle more complex decisions \u20221-layer: is linear, can\u2019t handle XOR \u2022Each layer adds more flexibility (but more parameters!) \u2022Each node splits its input space with linear hyperplane \u20222-layer: if last layer is AND operation, get convex hull \u20222-layer: can do almost anything multi-layer can by fanning out the inputs at 2 nd layer \u2022Note: Without loss of generality, we can omit the 1 and \u03b8 0 Multi-Layer Neural Networks", "dateLastCrawled": "2022-01-08T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "neural networks - Explanation of <b>Spikes</b> in training loss vs. iterations ...", "url": "https://stats.stackexchange.com/questions/303857/explanation-of-spikes-in-training-loss-vs-iterations-with-adam-optimizer", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/303857/explanation-of-<b>spikes</b>-in-training...", "snippet": "Cross Validated is a question and answer site for people interested in statistics, <b>machine</b> <b>learning</b>, data analysis, data mining, and data visualization. It only takes a minute to sign up. Sign up to join this community. Anybody can ask a question Anybody can answer The best answers are voted up and rise to the top Home Public; Questions; Tags Users Unanswered Teams. Stack Overflow for Teams \u2013 Collaborate and share knowledge with a private group. Create a free Team What is Teams? Teams ...", "dateLastCrawled": "2022-01-27T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[D] Looking for papers on treating regression as classification vs ...", "url": "https://www.reddit.com/r/MachineLearning/comments/7gun87/d_looking_for_papers_on_treating_regression_as/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/7gun87/d_looking_for_papers_on...", "snippet": "Doing the L2 <b>loss is like</b> doing maximum likelihood on a gaussian with a fixed variance - so the bad regression here is largely coming from the gaussian being mis-specified. I think the richer question would involve comparing approaches that consider the ordering vs. approaches that don t consider the ordering but where both have flexible enough distributions.", "dateLastCrawled": "2021-01-17T22:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Alan-D-Chen</b> (<b>Alan D Chen</b>) \u00b7 <b>GitHub</b>", "url": "https://github.com/Alan-D-Chen", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>Alan-D-Chen</b>", "snippet": "\ud83d\udd25 CDIoU and CDIoU <b>loss is like</b> a convenient plug-in that can be used in multiple models. CDIoU and CDIoU loss have different excellent performances in several models such as Faster R-CNN, YOLOv4, Re\u2026 Python 22 6 PCA_ICA_DEMO Public. Demo for PCA(Principal Component Analysis) &amp; ICA(Independent Component Analysis) in data analysis in Python and image separation written in MATLAB Python 8 2 meachine_<b>learning</b> Public. \u7b80\u5355\u7ebf\u6027\u56de\u5f52\uff0c\u591a\u5143\u7ebf\u6027\u56de\u5f52\uff0c\u975e\u7ebf\u6027\u56de\u5f52\uff0cKmeans\u7b97\u6cd5 ...", "dateLastCrawled": "2021-12-29T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Hearing Loss Simulator</b> - Find Out What <b>Hearing Loss is Like</b>", "url": "https://www.starkey.com/hearing-loss-simulator", "isFamilyFriendly": true, "displayUrl": "https://www.starkey.com/<b>hearing-loss-simulator</b>", "snippet": "Find out what they&#39;re experiencing with our <b>Hearing Loss Simulator</b>. Choose a situation. Select the <b>hearing loss</b> level you want to hear. Click Play. Set your computer volume to 50% for the best experience. Start.", "dateLastCrawled": "2022-02-02T08:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "7 <b>Things I\u2019ve Learned Since the Loss of</b> My Child", "url": "https://abedformyheart.com/7-things-since-loss-of-child/", "isFamilyFriendly": true, "displayUrl": "https://abedformyheart.com/7-things-since-loss-of-child", "snippet": "It is no worse than any loss of a child it is just different. I just want a time <b>machine</b> to go back and stop him to hold him and never let him go. It didn\u2019t have to happen I guess that\u2019s why the grief or denial or hope they will walk through the door is felt because you feel you could have stopped it. Maybe we could maybe they would have done it another time. Their are so many questions and no answers X . Reply. foreversadmom says. January 11, 2016 at 4:15 am. Sorry for your loss. I too ...", "dateLastCrawled": "2022-02-03T01:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What\u2019s considered a good Log <b>Loss</b> in <b>Machine</b> <b>Learning</b> ? | by Federico ...", "url": "https://medium.com/@fzammito/whats-considered-a-good-log-loss-in-machine-learning-a529d400632d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@fzammito/whats-considered-a-good-log-<b>loss</b>-in-<b>machine</b>-<b>learning</b>-a529...", "snippet": "Log <b>Loss is similar</b> to the Accuracy, but it will favor models that distinguish more strongly the classes. Log <b>Loss</b> it useful to compare models not only on their output but on their probabilistic ...", "dateLastCrawled": "2022-01-30T14:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Introduction to loss functions used in Deep Metric <b>Learning</b>. | Towards ...", "url": "https://towardsdatascience.com/metric-learning-loss-functions-5b67b3da99a5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metric-<b>learning</b>-loss-functions-5b67b3da99a5", "snippet": "Contributors : Jake Buglione, Sethu Hareesh Kolluru Recent advancements in <b>deep learning</b> have made it possible to learn a similarity measure for a set o f images using a deep metric <b>learning</b> network that maps visually similar images onto nearby locations in an embedding manifold, and visually dissimilar images apart from each other. Deep features learned using this approach result in well discriminative features with compact intra-product variance and well separated inter-product differences ...", "dateLastCrawled": "2022-01-25T23:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Key techniques for Evaluating <b>Machine</b> <b>Learning</b> models - Data Analytics", "url": "https://vitalflux.com/key-techniques-evaluating-machine-learning-models-performance/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/key-techniques-evaluating-<b>machine</b>-<b>learning</b>-models-performance", "snippet": "Log loss is used to evaluate the performance of classification <b>machine</b> <b>learning</b> models that are built using classification algorithms such as logistic regression, support vector <b>machine</b> (SVM), random forest, and gradient boosting. The idea behind the use of Log <b>loss is similar</b> to taking a base-e exponential or natural logarithm in order to compare model scores from high-value functions which may indicate poor <b>machine</b> <b>learning</b> model performance. The logarithmic loss value is defined as ...", "dateLastCrawled": "2022-01-31T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> Cats and Dogs\u2019 Breeds Classifier | by Mariana Santos ...", "url": "https://towardsdatascience.com/machine-learning-cats-and-dogs-breeds-classifier-b26a9df45000", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-cats-and-dogs-breeds-classifier-b26a9...", "snippet": "The accuracy of both the training and validation show similar curves and values, and even the train <b>loss is similar</b>, even though it is somewhat lower with the lower <b>learning</b> rate. The biggest difference is in the validation loss. With the larger <b>learning</b> rate, this curve did not converge to a value, probably because it was \u201chopping\u201d through the local minimum, due to the larger step. In this experience, we concluded that 0.001 is the best <b>learning</b> of all compared.", "dateLastCrawled": "2022-01-30T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Tabular Playground Series \u2013 June 2021 (Part 3) \u2013 <b>MACHINE</b> <b>LEARNING</b> CONCEPTS", "url": "https://srirangatarun.wordpress.com/2021/11/14/tabular-playground-series-june-2021-part-3/", "isFamilyFriendly": true, "displayUrl": "https://srirangatarun.wordpress.com/2021/11/14/tabular-playground-series-june-2021-part-3", "snippet": "The gap between the training and validation <b>loss is similar</b> to that of lightgbm, and lower than that of xgboost. So overfitting is not a major concern here. Additionally, catboost shows a strong LB performance with a score of 1.76 (very close to that of xgboost). catboost\u2019s CPU implementation is very fast compared to that of xgboost. catboost trains 20 estimators in just 6 seconds, compared to xgboost\u2019s 30. catboost, like xgboost, shows an impressive speed-up on GPU, going from 5.780 to ...", "dateLastCrawled": "2022-01-01T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Faster R-CNN step by step, Part II</b> | Notes for <b>machine</b> <b>learning</b>", "url": "https://dongjk.github.io/code/object+detection/keras/2018/06/10/Faster_R-CNN_step_by_step,_Part_II.html", "isFamilyFriendly": true, "displayUrl": "https://dongjk.github.io/code/object+detection/keras/2018/06/10/<b>Faster_R-CNN_step_by</b>...", "snippet": "regression <b>loss is similar</b> to RPN, using smooth l1 loss. there have 800 values but only 4 values are participant the gradient calculation. Summary. In this two posts, we have learnt how to implement <b>Faster R-CNN step by</b> step, how to prepare training data.", "dateLastCrawled": "2022-01-29T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - <b>hinge loss</b> vs logistic loss advantages and ...", "url": "https://stats.stackexchange.com/questions/146277/hinge-loss-vs-logistic-loss-advantages-and-disadvantages-limitations", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/146277/<b>hinge-loss</b>-vs-logistic-loss...", "snippet": "<b>machine</b>-<b>learning</b> svm loss-functions computer-vision. Share. Cite. Improve this question. Follow edited Jul 23 &#39;18 at 15:41. DHW. 644 3 3 silver badges 13 13 bronze badges. asked Apr 14 &#39;15 at 11:18. user570593 user570593. 1,059 2 2 gold badges 12 12 silver badges 19 19 bronze badges $\\endgroup$ Add a comment | 3 Answers Active Oldest Votes. 31 $\\begingroup$ Logarithmic loss minimization leads to well-behaved probabilistic outputs. <b>Hinge loss</b> leads to some (not guaranteed) sparsity on the ...", "dateLastCrawled": "2022-01-26T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Best <b>Artificial Intelligence</b> Course (AIML) by UT Austin", "url": "https://www.mygreatlearning.com/pg-program-artificial-intelligence-course", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/pg-program-<b>artificial-intelligence</b>-course", "snippet": "In <b>learning</b> a projection where the inputs can be distinguished, the triplet <b>loss is similar</b> to metric <b>learning</b>. The triplet loss is used for understanding the score vectors for the images. You can use the score vectors of face descriptors for verifying the faces in Euclidean Space. Natural Language Processing 4 Quizzes 2 Projects 4 Quizzes 2 Projects Learn how to work with natural language processing with Python using traditional <b>machine</b> <b>learning</b> methods. Then, deep dive into the realm of ...", "dateLastCrawled": "2022-02-01T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Generative Adversarial <b>Imitation Learning</b> | by Sanket Gujar | Medium", "url": "https://medium.com/@sanketgujar95/generative-adversarial-imitation-learning-266f45634e60", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@sanketgujar95/generative-adversarial-<b>imitation-learning</b>-266f45634e60", "snippet": "Generative Adversarial <b>Imitation Learning</b>. Sanket Gujar. Apr 20, 2018 \u00b7 8 min read. <b>Learning</b> from demonstrations will play a very important role in the age of robotics. If the robots or humans ...", "dateLastCrawled": "2022-01-11T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>What is an intuitive explanation for the log</b> loss function? - Quora", "url": "https://www.quora.com/What-is-an-intuitive-explanation-for-the-log-loss-function", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-an-intuitive-explanation-for-the-log</b>-loss-function", "snippet": "Answer (1 of 8): To me an intuitive explanation is that minimizing the log loss equals minimizing the Kullback-Leibler divergence (Kullback\u2013Leibler divergence - Wikipedia) between the function you want to optimize (for example a neural network) and the true function that generates the data (from ...", "dateLastCrawled": "2022-01-30T02:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>learning</b> for metal additive manufacturing: Towards a physics ...", "url": "https://www.sciencedirect.com/science/article/pii/S0278612521002259", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0278612521002259", "snippet": "<b>Machine</b> <b>learning</b> (ML) has shown to be an effective alternative to physical models for quality prediction and process optimization of metal additive manufacturing (AM). However, the inherent \u201cblack box\u201d nature of ML techniques such as those represented by artificial neural networks has often presented a challenge to interpret ML outcomes in the framework of the complex thermodynamics that govern AM. While the practical benefits of ML provide an adequate justification, its utility as a ...", "dateLastCrawled": "2022-01-27T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Full text of &quot;91288819 Tosh Pursuit Of History 5th Ed&quot;", "url": "https://archive.org/stream/91288819ToshPursuitOfHistory5thEd/91288819-Tosh-Pursuit-of-History-5th-Ed_djvu.txt", "isFamilyFriendly": true, "displayUrl": "https://archive.org/stream/91288819ToshPursuitOfHistory5thEd/91288819-Tosh-Pursuit-of...", "snippet": "An illustration of a computer application window Wayback <b>Machine</b>. An illustration of an open book. Books. An illustration of two cells of a film strip. Video. An illustration of an audio speaker. Audio. An illustration of a 3.5&quot; floppy disk. Software. An illustration of two photographs. Images. An illustration of a heart shape Donate. An illustration of text ellipses. More. An icon used to represent a menu that can be toggled by interacting with this icon. ...", "dateLastCrawled": "2022-01-31T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "commonplace book redux \u2013 a diary of quotations", "url": "https://quotables.github.io/", "isFamilyFriendly": true, "displayUrl": "https://quotables.github.io", "snippet": "English-<b>learning</b> infants under the age of six months distinguish phonemes used in Czech, Hindi, and Inslekampx (a Native American language), but English-speaking adults cannot, even with five hundred trials of training or a year of university coursework. Adult ears can tell the sounds apart, though, when the consonants are stripped from the syllables and presented alone as chirpy sounds; they just cannot tell them apart as phonemes. [\u2026]", "dateLastCrawled": "2022-02-01T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Read <b>Mushoku Tensei</b> (WN),Free online novel online reading, online book ...", "url": "https://readnovelfreeonline.com/mushoku-tensei-wn/volume-5-h", "isFamilyFriendly": true, "displayUrl": "https://readnovelfreeonline.com/<b>mushoku-tensei</b>-wn/volume-5-h", "snippet": "If I remember correctly, I was <b>learning</b> swordsmanship at my house. It was an everyday life of being scolded by my father. Even when I put in a bit of work, he would complain about everything and hit me. &quot;Do you think the you of that time could have survived on the Magic Continent?&quot; &quot;Hah, Gisu, that entire premise is strange. Rudi you know, had ...", "dateLastCrawled": "2022-01-29T13:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Notes on <b>Machine</b> <b>Learning</b> 3: <b>Decision theory</b>", "url": "https://cveai.github.io/notes/2018/03/27/mm-ml-3.html", "isFamilyFriendly": true, "displayUrl": "https://cveai.github.io/notes/2018/03/27/mm-ml-3.html", "snippet": "(ML 3.6) The Big Picture (part 2) Core ideas &amp; methods of ML: (not necessarily disjoint) Exact inference (usually not possible) Multivariate Gaussian (very nice) / Conjugate priors / Graphical models (use DP)", "dateLastCrawled": "2022-01-02T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What\u2019s My Line? <b>Next Sentence Prediction</b> in RunwayML with BERT | by ...", "url": "https://medium.com/runwayml/whats-my-line-next-sentence-prediction-in-runway-ad76cbf28c86", "isFamilyFriendly": true, "displayUrl": "https://medium.com/runwayml/whats-my-line-<b>next-sentence-prediction</b>-in-runway-ad76cbf28c86", "snippet": "The <b>loss can be thought of as</b> how much the model is surprised by the sequence. The lower the loss, the more likely it judges the sequence to be. Results: I\u2019m not sure what a score of 4.0966539 ...", "dateLastCrawled": "2022-01-31T03:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Defect <b>Detection</b> in Products using Image Segmentation | by Vinithavn ...", "url": "https://medium.com/analytics-vidhya/defect-detection-in-products-using-image-segmentation-a87a8863a9e5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/defect-<b>detection</b>-in-products-using-image...", "snippet": "Dice <b>loss can be thought of as</b> 1-Dice coefficient where Dice coefficient is defined as, Dice coefficient=2* area of overlap area of intersection. You can read more about these metrics here. 5 ...", "dateLastCrawled": "2022-02-03T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Automatic Di\ufb00erentiation and Neural Networks</b>", "url": "https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf", "snippet": "Statistical <b>Machine</b> <b>Learning</b> Notes 8 <b>Automatic Di\ufb00erentiation and Neural Networks</b> Instructor: Justin Domke Contents 1 Introduction 1 2 Automatic Di\ufb00erentiation 2 3 Multi-Layer Perceptrons 5 4 MNIST 7 5 Backpropagation 10 6 Discussion 13 1 Introduction The name \u201cneuralnetwork\u201d is sometimes used torefer tomany things (e.g. Hop\ufb01eld networks, self-organizing maps). In these notes, we are only interested in the most common type of neural network, the multi-layer perceptron. A basic ...", "dateLastCrawled": "2022-01-28T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Automatic Di\ufb00erentiation and <b>Neural Networks</b> 1 Introduction", "url": "https://people.cs.umass.edu/~domke/courses/sml2010/07autodiff_nnets.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.umass.edu/~domke/courses/sml2010/07autodiff_nnets.pdf", "snippet": "Statistical <b>Machine</b> <b>Learning</b> Notes 7 Automatic Di\ufb00erentiation and <b>Neural Networks</b> Instructor: Justin Domke 1 Introduction The name \u201cneuralnetwork\u201d is sometimes used torefer tomany things (e.g. Hop\ufb01eld networks, self-organizing maps). In these notes, we are only interested in the most common type of neural network, the multi-layer perceptron. A basic problem in <b>machine</b> <b>learning</b> is function approximation. We have some inputs x\u02c6 and some outputs y\u02c6, and we want to \ufb01t some function f ...", "dateLastCrawled": "2022-01-28T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Decision-Theoretic Approximations for Machine Learning</b>", "url": "https://www.ijcai.org/Proceedings/13/Papers/487.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/Proceedings/13/Papers/487.pdf", "snippet": "<b>Decision-Theoretic Approximations for Machine Learning</b> M. Ehsan Abbasnejad Abstract Decision theory focuses on the problem of mak-ing decisions under uncertainty. This uncertainty arises from the unknown aspects of the state of the world the decision maker is in or the unknown util- ity function of performing actions. The uncertainty can be modeled as a probability distribution captur-ing our belief about the world the decision maker is in. Upon making new observations, the decision maker ...", "dateLastCrawled": "2022-02-02T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A cascaded fully convolutional network framework for dilated pancreatic ...", "url": "https://link.springer.com/article/10.1007/s11548-021-02530-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11548-021-02530-x", "snippet": "Deep-<b>learning</b>-base methods have successfully solved many challenging tasks in image processing, such as classification [8, 25], ... The Dice <b>loss can be thought of as</b> the minimization of the Dice score subtracted by one, which is minimized toward 0 to achieve optimal segmentation performance. Focal loss is proposed to dynamically rescale cross entropy loss and is conducive to imbalance problems . The voxel-wise Focal loss function is expressed as $$\\begin{aligned} {\\mathcal {L}}_F = -\\frac{1 ...", "dateLastCrawled": "2022-01-30T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Adversarial Examples are Just Bugs</b>, Too - Latest articles about <b>machine</b> ...", "url": "https://distill.pub/2019/advex-bugs-discussion/response-5/", "isFamilyFriendly": true, "displayUrl": "https://distill.pub/2019/advex-bugs-discussion/response-5", "snippet": "Adversarial Examples With No Features. Using the above, we can construct adversarial examples which do not suffice for <b>learning</b>. Here, we replicate the Ilyas et al. experiment that \u201cNon-robust features suffice for standard classification\u201d (Section 3.2 of ), but show that it fails for our construction of adversarial examples.. To review, the Ilyas et al. non-robust experiment was:", "dateLastCrawled": "2022-01-31T12:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Network Traffic Anomaly Detection Using Recurrent Neural Networks", "url": "https://www.researchgate.net/publication/324104291_Network_Traffic_Anomaly_Detection_Using_Recurrent_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324104291_Network_Traffic_Anomaly_Detection...", "snippet": "Next, a supervised <b>machine</b> <b>learning</b> algorithm one-class SVM is trained to generalize the behavior model in order to predict user behavior anomalies. Results show that One-Class SVM is the most ...", "dateLastCrawled": "2022-01-26T23:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Exploring deep neural networks via layer-peeled model: Minority ...", "url": "https://www.pnas.org/content/118/43/e2103091118", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/118/43/e2103091118", "snippet": "The remarkable development of deep <b>learning</b> over the past decade relies heavily on sophisticated heuristics and tricks. To better exploit its potential in the coming decade, perhaps a rigorous framework for reasoning about deep <b>learning</b> is needed, which, however, is not easy to build due to the intricate details of neural networks. For near-term purposes, a practical alternative is to develop a mathematically tractable surrogate model, yet maintaining many characteristics of neural networks.", "dateLastCrawled": "2021-12-30T16:12:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(loss)  is like +(making mistakes while learning a skill)", "+(loss) is similar to +(making mistakes while learning a skill)", "+(loss) can be thought of as +(making mistakes while learning a skill)", "+(loss) can be compared to +(making mistakes while learning a skill)", "machine learning +(loss AND analogy)", "machine learning +(\"loss is like\")", "machine learning +(\"loss is similar\")", "machine learning +(\"just as loss\")", "machine learning +(\"loss can be thought of as\")", "machine learning +(\"loss can be compared to\")"]}