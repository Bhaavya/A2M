{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Machine Learning Glossary: <b>Fairness</b> | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/fairness", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/glossary/<b>fairness</b>", "snippet": "<b>Predictive</b> <b>parity</b> is sometime also called <b>predictive</b> rate <b>parity</b>. See &quot;<b>Fairness</b> Definitions Explained&quot; (section 3.2.1) for a more detailed discussion of <b>predictive</b> <b>parity</b>. <b>predictive</b> rate <b>parity</b>. #<b>fairness</b>. Another name for <b>predictive</b> <b>parity</b>. preprocessing. #<b>fairness</b>. Processing data before it&#39;s used to train a <b>model</b>. Preprocessing could be as simple as removing words from an English text corpus that don&#39;t occur in the English dictionary, or could be as complex as re-expressing data points ...", "dateLastCrawled": "2022-02-02T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Prediction of stillbirth in women with overweight or obesity\u2014A register ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6242307/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6242307", "snippet": "<b>A predictive</b> <b>model</b> with an AUC 0.70\u20130.80 is commonly interpreted as fairly good, AUC 0.8\u20130.9 as good and AUC 0.9\u20131 as excellent . However, when interpreting the strength of a prediction it is also important to be aware of the prevalence or incidence of the outcome and the consequences of false negative or false positive results. Stillbirth is a rare outcome, however a severe complication. A higher proportion of cases would be possible to identify with a decreased specificity, hence an ...", "dateLastCrawled": "2021-12-16T01:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Predictive Queries vs Supervised ML Models</b> | by Antti Rauhala | Towards ...", "url": "https://towardsdatascience.com/predictive-queries-vs-supervised-ml-models-ee7f17e4840e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>predictive-queries-vs-supervised-ml-models</b>-ee7f17e4840e", "snippet": "<b>Like</b> we see in the benchmark, the ad hoc <b>model</b> approach produces very good prediction quality despite the millisecond scale budget to train the <b>predictive</b> <b>model</b>. <b>Creating</b> a good ad hoc <b>model</b> in the millisecond scale is feasible, because <b>creating</b> a specific <b>model</b> to serve a specific prediction is radically faster than <b>creating</b> a generic <b>model</b> to serve a generic prediction.", "dateLastCrawled": "2022-01-26T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Measuring and Mitigating Algorithmic Bias \u00b7 Notes", "url": "https://jsinkers.github.io/notes/notebooks/machine_learning/03_fairness.html", "isFamilyFriendly": true, "displayUrl": "https://jsinkers.github.io/notes/notebooks/machine_learning/03_fairness.html", "snippet": "positive <b>predictive</b> value (PPV) GAP: <b>predictive</b> <b>parity</b>; <b>Creating</b> Fairer Classifiers. we know where bias can arise: data, <b>model</b>, \u2026 how to statistically define fairness in classifiers; how to diagnose unfairness in evaluation; what steps can we take to achieve better fairness? pre-processing; training/optimisation: select models known to be fair", "dateLastCrawled": "2022-01-28T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Predictive</b> Regression using splines, partial-least squares ...", "url": "https://medium.com/@marc.jacobs012/predictive-regression-using-splines-partial-least-squares-penalization-cross-validation-and-339b74a7e108", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@marc.jacobs012/<b>predictive</b>-regression-using-splines-partial-least...", "snippet": "In summary, if you want to build <b>a predictive</b> <b>model</b> from a large number of predictors, the PROC GLMSELECT procedure is the most advanced procedure you can use in SAS/STAT. There are numerous ...", "dateLastCrawled": "2021-12-27T10:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Myth of the <b>Impartial Machine</b> - parametric.press", "url": "https://parametric.press/issue-01/the-myth-of-the-impartial-machine/", "isFamilyFriendly": true, "displayUrl": "https://parametric.press/issue-01/the-myth-of-the-<b>impartial-machine</b>", "snippet": "In the simplified recidivism <b>model</b> below, the <b>predictive</b> <b>parity</b> rule has been imposed such that for both groups, 67% of people that are labeled as \u201chigh risk\u201d indeed get rearrested. Play with the <b>model</b> by setting the total number of people in Group A that are labeled as \u201chigh risk\u201d. Can you set this number such that the <b>model</b> achieves equal false negative rates in addition to <b>predictive</b> <b>parity</b>? Is there a value that allows the <b>model</b> to achieve equal false positive and false negative ...", "dateLastCrawled": "2022-02-03T05:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Aito.ai - <b>Could predictive database queries replace machine learning</b> ...", "url": "https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://aito.ai/blog/<b>could-predictive-database-queries-replace-machine-learning</b>-<b>models</b>", "snippet": "<b>Like</b> we see in the benchmark, the lazy learning approach produces very good prediction quality despite the millisecond scale budget to train the <b>predictive</b> <b>model</b>. <b>Creating</b> a good lazy <b>model</b> in the millisecond scale is feasible, because <b>creating</b> a specific <b>model</b> to serve a specific prediction is radically faster than <b>creating</b> a generic <b>model</b> to serve a generic prediction.", "dateLastCrawled": "2021-12-30T19:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Predicting <b>mental health</b> problems in adolescence using machine learning ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230389", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230389", "snippet": "Our top <b>model</b> had <b>a predictive</b> value of 15%, while the negative <b>predictive</b> value was at 96%. This corresponds to a sensitivity of .91 and a specificity of .30, and classified 15% of the test set with the outcome. Sensitivity analysis. The more stringent cut-off based on a UK sample categorized roughly 3% of our sample as having <b>mental health</b> issues. We trained a random forest <b>model</b> based on this new cut-off, and found a test AUC of 0.765 (95% CI 0.698\u20130.826). Although the AUC was ...", "dateLastCrawled": "2021-12-28T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>COMPAS</b> Case Study: Fairness of a Machine Learning <b>Model</b> | by Farhan ...", "url": "https://towardsdatascience.com/compas-case-study-fairness-of-a-machine-learning-model-f0f804108751", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>compas</b>-case-study-fairness-of-a-machine-learning-<b>model</b>...", "snippet": "Photo by Clay Banks on Unsplash. Recent events around the world raise many questions \u2014 is the society we are living in biased to a pa r ticular sect. With many unanswered questions about the racial discrimination, lets explore a case study about <b>COMPAS</b> which is tool used in many jurisdictions around the U.S. to predict if a convicted criminal is likely to re-offend.", "dateLastCrawled": "2022-02-03T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>SAP Data Intelligence \u2013 What\u2019s New</b> in 3.1 | SAP Blogs", "url": "https://blogs.sap.com/2020/12/02/sap-data-intelligence-whats-new-in-3.1/", "isFamilyFriendly": true, "displayUrl": "https://blogs.sap.com/2020/12/02/<b>sap-data-intelligence-whats-new</b>-in-3.1", "snippet": "SAP Data Intelligence can be configured for point-in-time backups of the complete system state (pipelines, connections, users, Vora tables, system configuration). These are the new functions, features and enhancements in SAP Data Intelligence 3.1, on-premise edition release. We hope you <b>like</b> them and, by reading the above descriptions, have ...", "dateLastCrawled": "2022-01-27T15:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>COMPAS</b> Case Study: Fairness of a Machine Learning <b>Model</b> | by Farhan ...", "url": "https://towardsdatascience.com/compas-case-study-fairness-of-a-machine-learning-model-f0f804108751", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>compas</b>-case-study-fairness-of-a-machine-learning-<b>model</b>...", "snippet": "Again, <b>similar</b> (within a few points). This is a type of fairness known as <b>predictive</b> <b>parity</b>. We can extend this idea, to check whether a defendant with a given score has the same probability of recidivism for the two groups:", "dateLastCrawled": "2022-02-03T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Machine Learning Glossary: <b>Fairness</b> | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/fairness", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/glossary/<b>fairness</b>", "snippet": "For example, a <b>model</b> that predicts college acceptance would satisfy <b>predictive</b> <b>parity</b> for nationality if its precision rate is the same for Lilliputians and Brobdingnagians. <b>Predictive</b> <b>parity</b> is sometime also called <b>predictive</b> rate <b>parity</b>. See &quot;<b>Fairness</b> Definitions Explained&quot; (section 3.2.1) for a more detailed discussion of <b>predictive</b> <b>parity</b>.", "dateLastCrawled": "2022-02-02T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Aito.ai - <b>Could predictive database queries replace machine learning</b> ...", "url": "https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://aito.ai/blog/<b>could-predictive-database-queries-replace-machine-learning</b>-<b>models</b>", "snippet": "The workflow with the <b>predictive</b> queries <b>is similar</b> to the workflow with the database queries. Still, because <b>predictive</b> functionality is statistical and its behavior may drift as the data changes: it is advisable to verify the prediction quality (step 2) before implementation and monitor the prediction quality in production (step 5). While putting an auxiliary database (like ElasticSearch) into production can take weeks, the expense related to putting each query into production is closer to ...", "dateLastCrawled": "2021-12-30T19:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Create <b>predictive</b> models in R with <b>Caret</b> | by Luiz Fonseca | Towards ...", "url": "https://towardsdatascience.com/create-predictive-models-in-r-with-caret-12baf9941236", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/create-<b>predictive</b>-<b>models</b>-in-r-with-<b>caret</b>-12baf9941236", "snippet": "Create <b>predictive</b> models in R with <b>Caret</b>. Luiz Fonseca. Jul 19, 2019 \u00b7 8 min read. <b>Caret</b> is the short for C lassification A nd RE gression T raining. It is a complete package that covers all the stages of a pipeline for <b>creating</b> a machine learning <b>predictive</b> <b>model</b>. In this tutorial, I will explain the following topics:", "dateLastCrawled": "2022-01-28T14:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Predicting <b>mental health</b> problems in adolescence using machine learning ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230389", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230389", "snippet": "The variable importance derived from the random forest <b>model</b> indicated that the <b>model</b> did not overly rely on any variable, thus the <b>model</b> would be relatively stable with the removal of any one variable, including those stable over time. The highest ranked variables were parent-reported <b>mental health</b> symptoms such as impulsivity, inattention, and emotional symptoms were important <b>predictive</b> factors for poor <b>mental health</b> at 15. Register information on neighborhood quality, <b>parity</b> and ...", "dateLastCrawled": "2021-12-28T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "SAP Tech Bytes: Feature Engineering using Data Wrangling | SAP Blogs", "url": "https://blogs.sap.com/2021/08/17/sac-feature-engineering-data-wrangling-kaggle-titanic/", "isFamilyFriendly": true, "displayUrl": "https://blogs.sap.com/2021/08/17/sac-feature-engineering-data-wrangling-kaggle-titanic", "snippet": "Once again let\u2019s create a new <b>model</b>. It will be <b>similar</b> to the previous <b>Model</b> 2, with the only difference that now excludes the AgeCategory and not Age from influencers. Train the <b>model</b>. This time the third <b>model</b>\u2019s prediction confidence slightly improved over the <b>Model</b> 2, but the <b>predictive</b> power dropped to the level of the <b>Model</b> 1. In simple words, based on the validation subset of the training dataset it makes slightly more incorrect predictions than <b>Model</b> 2, but does make them more ...", "dateLastCrawled": "2022-02-01T18:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Bias detectives: the researchers striving to make algorithms fair", "url": "https://www.nature.com/articles/d41586-018-05469-3/", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/d41586-018-05469-3", "snippet": "This algorithm has <b>predictive</b> <b>parity</b>. But there\u2019s a problem. In the blue group, 1 person out of 7 (14%) was misidentified as high risk; in the purple group, it was 2 people out of 4 (50%). So ...", "dateLastCrawled": "2022-01-30T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Predictive</b> Modeling Early", "url": "https://predictivemodellingearly.github.io/", "isFamilyFriendly": true, "displayUrl": "https://<b>predictivemodel</b>lingearly.github.io", "snippet": "Students apply <b>predictive</b> modeling to build a <b>model</b> that predicts re-arrest of criminal defendants using real data. Students assess the algorithmic fairness of a real-world criminal risk assessment tool (RAT), and reproduce results from an impactful story in ProPublica and a 2018 Science Advances paper. Students explore different measures of algorithmic fairness, and adjust a <b>model</b> they build to satisfy the false positive <b>parity</b> measure.", "dateLastCrawled": "2022-02-03T14:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A statistical framework for fair <b>predictive</b> algorithms | DeepAI", "url": "https://deepai.org/publication/a-statistical-framework-for-fair-predictive-algorithms", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-statistical-framework-for-fair-<b>predictive</b>-algorithms", "snippet": "The approach we propose is most <b>similar</b> to ... Using only this data, we attempt to build a fair <b>predictive</b> <b>model</b> in which the outcome of interest is re-arrest within two years. We construct regression models for each x j in the recidivism data, conditional on the protected variable (z = race) and each of the previously transformed variables (\u02dc x 1: (j \u2212 1)). Of the six x j, one (sex) is binary, one (log (age) \u2013 henceforth simply \u201cage\u201d) is continuous, and the other four, which relate ...", "dateLastCrawled": "2022-02-01T19:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Myth of the <b>Impartial Machine</b> - parametric.press", "url": "https://parametric.press/issue-01/the-myth-of-the-impartial-machine/", "isFamilyFriendly": true, "displayUrl": "https://parametric.press/issue-01/the-myth-of-the-<b>impartial-machine</b>", "snippet": "Even when sub-groups are statistically <b>similar</b>, feedback loops can still lead to noisy and less accurate predictions. Algorithms where the <b>predictive</b> outcome determines what feedback the algorithm receives\u2014e.g. recidivism prediction, language translation, and social media news feeds\u2014should always be diligently monitored for the presence of feedback loops bias. Bias in data and in algorithms are interrelated. It should be clear by this point that bias in data and algorithms are ...", "dateLastCrawled": "2022-02-03T05:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Predictive Queries vs Supervised ML Models</b> | by Antti Rauhala | Towards ...", "url": "https://towardsdatascience.com/predictive-queries-vs-supervised-ml-models-ee7f17e4840e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>predictive-queries-vs-supervised-ml-models</b>-ee7f17e4840e", "snippet": "<b>Creating</b> a good ad hoc <b>model</b> in the millisecond scale is feasible, because <b>creating</b> a specific <b>model</b> to serve a specific prediction is radically faster than <b>creating</b> a generic <b>model</b> to serve a generic prediction. Like mentioned before, the training phase doesn\u2019t need to consider every million features and million samples available, but only a few hundred features and a few thousand samples relevant for the query. The reduced complexity together with a specialized database enables serving ...", "dateLastCrawled": "2022-01-26T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Risk <b>Parity</b>: What It Is, How It Works, and Why It Matters - <b>Hedgewise</b> Blog", "url": "https://www.hedgewise.com/blog/investmentstrategy/risk-parity-introduction-what-it-is-how-it-works.php", "isFamilyFriendly": true, "displayUrl": "https://www.<b>hedgewise</b>.com/blog/investmentstrategy/risk-<b>parity</b>-introduction-what-it-is...", "snippet": "Risk <b>can</b> <b>be thought</b> of as the probability that you will make or lose a certain amount of money. To have the &#39;same risk&#39;, then, would be a case where you had the same probability of making or losing the same amount of money across each of your investments. To quantify this, we define a new concept called &#39;dollars at risk&#39; for each asset. &#39;Dollars at risk&#39; is equal to the total dollar investment in an asset multiplied by the probability of making or losing money on that investment. We use ...", "dateLastCrawled": "2022-01-30T18:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Review of Challenges and Opportunities in Machine Learning for Health", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233077/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7233077", "snippet": "Dealing with representations explicitly may be advantageous because they <b>can</b> conveniently express general priors that are not specific to a single <b>predictive</b> task 108, and this is particularly important for zero-shot learning 109 in unseen categories. There are several potential opportunities to address for representations for a clinical setting. First, a single patient input (e.g., physiological data) <b>can</b> correspond to many possible correct outputs (e.g., diagnostic codes), and this must be ...", "dateLastCrawled": "2022-01-25T00:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Testing discrimination in practice", "url": "https://fairmlbook.org/testing.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/testing.html", "snippet": "Such a researcher <b>can</b> test <b>predictive</b> <b>parity</b> rather than sufficiency. <b>Predictive</b> <b>parity</b> requires that the rate of default (Y) for favorably classified applicants (\\hat{Y} = 1) of any group (A) be the same. This observational test is called the outcome test (row 7 in the summary table).", "dateLastCrawled": "2022-01-30T14:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Aito.ai - <b>Could predictive database queries replace machine learning</b> ...", "url": "https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://aito.ai/blog/<b>could-predictive-database-queries-replace-machine-learning</b>-<b>models</b>", "snippet": "Just as a <b>thought</b> play: if you have a database that <b>can</b> answer queries of both the known and the unknown: why would you maintain a separate normal database on the side or deploy a multitude of redundant ML models/systems? 3. The Quality. In the early days of AI, you could see people envisioning <b>a predictive</b> database like system. One vision was McCarthy\u2019s idea of the epistemological part, which would combine machine learning, knowledge representation and reasoning in a seamless way. This ...", "dateLastCrawled": "2021-12-30T19:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Fairness Metrics: A Comparative Analysis</b>", "url": "https://www.researchgate.net/publication/338762666_Fairness_Metrics_A_Comparative_Analysis", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338762666_<b>Fairness_Metrics_A_Comparative_Analysis</b>", "snippet": "Does this <b>model</b> satisfy <b>predictive</b> <b>parity</b>? Choosing 0.49 as the threshold gives a total of 60 positive predictions for . both the orange group and the blue group. However, of the people with ...", "dateLastCrawled": "2021-11-10T12:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Reprogramming Fairness: Affirmative Action in Algorithmic Criminal</b> ...", "url": "http://hrlr.law.columbia.edu/hrlr-online/reprogramming-fairness-affirmative-action-in-algorithmic-criminal-sentencing/", "isFamilyFriendly": true, "displayUrl": "hrlr.law.columbia.edu/hrlr-online/<b>reprogramming-fairness-affirmative-action-in</b>...", "snippet": "<b>Predictive</b> accuracy is certainly an important value for both legislatures and courts. Employing algorithmic risk assessments that satisfy <b>predictive</b> <b>parity</b> <b>can</b> adequately fulfill our commitment to that value. And yet, the founding ideals of this nation remind us of the moral imperative to equalize the odds in our criminal justice system.", "dateLastCrawled": "2022-02-01T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fair prediction with disparate impact</b>: A study of bias in ... - DeepAI", "url": "https://deepai.org/publication/fair-prediction-with-disparate-impact-a-study-of-bias-in-recidivism-prediction-instruments", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fair-prediction-with-disparate-impact</b>-a-study-of-bias...", "snippet": "<b>Predictive</b> <b>parity</b> at a given threshold s H R amounts to requiring that the positive <b>predictive</b> value (PPV) of the classifier ^ Y = 1 S &gt; s H R be the same across groups. While <b>predictive</b> <b>parity</b> and calibration look like very similar criteria, well-calibrated scores <b>can</b> fail to satisfy <b>predictive</b> <b>parity</b> at a given threshold.", "dateLastCrawled": "2022-01-13T20:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Defining fairness</b>. For our upcoming ethics book club on\u2026 | by DataKind ...", "url": "https://medium.com/datakinduk/defining-fairness-1e12586d4b36", "isFamilyFriendly": true, "displayUrl": "https://medium.com/datakinduk/<b>defining-fairness</b>-1e12586d4b36", "snippet": "If an instrument satisfies <b>predictive</b> <b>parity</b> but the prevalence differs between groups, the instrument cannot achieve equal false positive and false negative rates across those groups . This is ...", "dateLastCrawled": "2022-01-25T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Evaluating the Fairness of <b>Predictive</b> Student Models Through ...", "url": "https://www.researchgate.net/publication/331230873_Evaluating_the_Fairness_of_Predictive_Student_Models_Through_Slicing_Analysis", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/331230873_Evaluating_the_Fairness_of...", "snippet": "of such a method, the problem of <b>creating</b> a \u0142fair\u017e classi er <b>can</b> be Evaluating the Fairness of <b>Predictive</b> Student Models Through Slicing Analysis LAK19, March 4\u20138, 2019, Tempe, AZ, USA reduced ...", "dateLastCrawled": "2021-11-13T03:25:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Predictive Queries vs Supervised ML Models</b> | by Antti Rauhala | Towards ...", "url": "https://towardsdatascience.com/predictive-queries-vs-supervised-ml-models-ee7f17e4840e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>predictive-queries-vs-supervised-ml-models</b>-ee7f17e4840e", "snippet": "<b>Creating</b> a good ad hoc <b>model</b> in the millisecond scale is feasible, because <b>creating</b> a specific <b>model</b> to serve a specific prediction is radically faster than <b>creating</b> a generic <b>model</b> to serve a generic prediction. Like mentioned before, the training phase doesn\u2019t need to consider every million features and million samples available, but only a few hundred features and a few thousand samples relevant for the query. The reduced complexity together with a specialized database enables serving ...", "dateLastCrawled": "2022-01-26T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Myth of the <b>Impartial Machine</b> - parametric.press", "url": "https://parametric.press/issue-01/the-myth-of-the-impartial-machine/", "isFamilyFriendly": true, "displayUrl": "https://parametric.press/issue-01/the-myth-of-the-<b>impartial-machine</b>", "snippet": "In the simplified recidivism <b>model</b> below, the <b>predictive</b> <b>parity</b> rule has been imposed such that for both groups, 67% of people that are labeled as \u201chigh risk\u201d indeed get rearrested. Play with the <b>model</b> by setting the total number of people in Group A that are labeled as \u201chigh risk\u201d. <b>Can</b> you set this number such that the <b>model</b> achieves equal false negative rates in addition to <b>predictive</b> <b>parity</b>? Is there a value that allows the <b>model</b> to achieve equal false positive and false negative ...", "dateLastCrawled": "2022-02-03T05:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Evaluating the Fairness of <b>Predictive</b> Student Models Through Slicing ...", "url": "https://www.upenn.edu/learninganalytics/ryanbaker/LAK_PAPER97_CAMERA.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.upenn.edu</b>/learninganalytics/ryanbaker/LAK_PAPER97_CAMERA.pdf", "snippet": "subgroups might <b>be compared</b>. 2 RELATED WORK 2.1 <b>Predictive</b> Modeling in Learning Analytics There is an extensive research base on the use of <b>predictive</b> models inlearninganalytics,andinMOOCsinparticular.Acomprehensive survey of such work is beyond the scope of this paper, and we refer the reader to [15, 26] for such reviews. However, we provide a brief overview of the diversity of approaches taken to the task of student success prediction in MOOCs in order to motivate the need for a more ...", "dateLastCrawled": "2022-01-11T08:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Aito.ai - <b>Could predictive database queries replace machine learning</b> ...", "url": "https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://aito.ai/blog/<b>could-predictive-database-queries-replace-machine-learning</b>-<b>models</b>", "snippet": "<b>Creating</b> a good lazy <b>model</b> in the millisecond scale is feasible, because <b>creating</b> a specific <b>model</b> to serve a specific prediction is radically faster than <b>creating</b> a generic <b>model</b> to serve a generic prediction. Like mentioned before, the training phase doesn\u2019t need to consider every million features and million samples available, but only a few hundred features and a few thousand samples relevant for the query. The reduced complexity together with a specialized database enables serving ...", "dateLastCrawled": "2021-12-30T19:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Prediction of stillbirth in women with overweight or obesity\u2014A register ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6242307/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6242307", "snippet": "<b>A predictive</b> <b>model</b> with an AUC 0.70\u20130.80 is commonly interpreted as fairly good, AUC 0.8\u20130.9 as good and AUC 0.9\u20131 as excellent . However, when interpreting the strength of a prediction it is also important to be aware of the prevalence or incidence of the outcome and the consequences of false negative or false positive results. Stillbirth is a rare outcome, however a severe complication. A higher proportion of cases would be possible to identify with a decreased specificity, hence an ...", "dateLastCrawled": "2021-12-16T01:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "azure-content/machine-learning-linear-regression-in-azure.md at master ...", "url": "https://github.com/uglide/azure-content/blob/master/articles/machine-learning/machine-learning-linear-regression-in-azure.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/uglide/azure-content/blob/master/articles/machine-learning/machine...", "snippet": "Achieving <b>predictive</b> performance <b>parity</b>. Our first priority was to achieve <b>parity</b> between Azure ML and Excel regression models. Given the exact same data, and the same split for training and testing data we wanted to achieve <b>predictive</b> performance <b>parity</b> between Excel and Azure ML. Initially we failed. The Excel <b>model</b> outperformed the Azure ML <b>model</b>. The failure was due to a lack of understanding of the base tool setting in Azure ML. After a sync with the Azure ML product team, we gained a ...", "dateLastCrawled": "2021-09-15T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Predicting <b>mental health</b> problems in adolescence using machine learning ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230389", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230389", "snippet": "While the negative <b>predictive</b> value is at 96% indicates clinical level sensitivity, the positive <b>predictive</b> value of this <b>model</b> is only 15%. This indicates that only a small percentage of the children flagged will actually reach our pre-specified cut-off for <b>mental health</b> problems, which should <b>be compared</b> to the prevalence in the sample of 10%.", "dateLastCrawled": "2021-12-28T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Reprogramming Fairness: Affirmative Action in Algorithmic Criminal</b> ...", "url": "http://hrlr.law.columbia.edu/hrlr-online/reprogramming-fairness-affirmative-action-in-algorithmic-criminal-sentencing/", "isFamilyFriendly": true, "displayUrl": "hrlr.law.columbia.edu/hrlr-online/<b>reprogramming-fairness-affirmative-action-in</b>...", "snippet": "<b>Predictive</b> accuracy is certainly an important value for both legislatures and courts. Employing algorithmic risk assessments that satisfy <b>predictive</b> <b>parity</b> <b>can</b> adequately fulfill our commitment to that value. And yet, the founding ideals of this nation remind us of the moral imperative to equalize the odds in our criminal justice system.", "dateLastCrawled": "2022-02-01T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Predicting Segregation Energy in Single Atom Alloys Using Physics and ...", "url": "https://pubs.acs.org/doi/10.1021/acsomega.1c06337", "isFamilyFriendly": true, "displayUrl": "https://pubs.acs.org/doi/10.1021/acsomega.1c06337", "snippet": "To gain more insights on the accuracy of our <b>model</b>, we <b>compared</b> it to another <b>model</b> reported in the literature trained on the same data set. Farsi and Deskins refitted their data set to Yu et al.\u2019s <b>model</b> and found that it produced an R 2 of 0.61 and a RMSE of 0.60 eV. Based on these metrics, we <b>can</b> conclude that our <b>model</b> shows enhanced performance. Additionally, Yu et al.\u2019s <b>model</b> does not differentiate between the different facets due to its use of metal-dependent surface energy, which ...", "dateLastCrawled": "2022-01-28T12:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why do we need a <b>parity</b> violation in beta decay? - Quora", "url": "https://www.quora.com/Why-do-we-need-a-parity-violation-in-beta-decay", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-do-we-need-a-<b>parity</b>-violation-in-beta-decay", "snippet": "Answer (1 of 2): If the <b>parity</b> operator commutes with the Hamiltonian of the system, the <b>parity</b> is conserved. It is now well established that in strong interactions, <b>parity</b> is conserved. However,it is not conserved in ( beta) decay, (pi)+ and ( pi)- mesons as they are caused by weak interactions...", "dateLastCrawled": "2022-01-14T18:42:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and bias \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-bias", "snippet": "<b>Machine learning</b> has shown great promise in powering self-driving cars, accurately recognizing cancer in radiographs, and predicting our interests based upon past behavior (to name just a few). But with the benefits from <b>machine learning</b>, there are also challenges. One key challenge is the presence of bias in the classifications and predictions of <b>machine learning</b>. These biases are not benign. They have consequences based upon the decisions resulting from a <b>machine learning</b> model. Therefore ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "Heidari et al. have written a paper comparing the three criteria \u2013 demographic <b>parity</b>, equality of opportunity, and <b>predictive</b> <b>parity</b> \u2013 to egalitarianism, equality of opportunity (EOP) in the Rawlsian sense, and EOP seen through the glass of luck egalitarianism, respectively. While the <b>analogy</b> is fascinating, it too assumes that we may take what is in the data at face value. In their likening <b>predictive</b> <b>parity</b> to luck egalitarianism, they have to go to especially great lengths, in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Explaining <b>Machine</b> <b>Learning</b> Decisions | Philosophy of Science ...", "url": "https://www.cambridge.org/core/journals/philosophy-of-science/article/explaining-machine-learning-decisions/8E20E695A0ADBB2DEC78D0568B78CDF5", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/philosophy-of-science/article/explaining...", "snippet": "<b>Machine</b> <b>learning</b> is a form of data processing that identifies statistical patterns from large quantities of information. Instead of being programmed with predetermined responses to a set of conditions\u2014the dominant approach to AI up until fairly recently\u2014an ML system is set up to \u201clearn\u201d its own suitable responses to those conditions under a training regime. Many tasks for which no straightforward sequence of \u201cif-then\u201d rules can be formulated may be handled more efficiently, and ...", "dateLastCrawled": "2022-01-31T14:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Starting to think about AI Fairness - Adolfo Eliaz\u00e0t - Artificial ...", "url": "https://adolfoeliazat.com/2022/01/01/starting-to-think-about-ai-fairness-2/", "isFamilyFriendly": true, "displayUrl": "https://adolfoeliazat.com/2022/01/01/starting-to-think-about-ai-fairness-2", "snippet": "() have written a paper comparing the three criteria \u2013 demographic <b>parity</b>, equality of opportunity, and <b>predictive</b> <b>parity</b> \u2013 to egalitarianism, equality of opportunity (EOP) in the Rawlsian sense, and EOP seen through the glass of luck egalitarianism, respectively. While the <b>analogy</b> is fascinating, it too assumes that we may take what is in the data at face value. In their likening <b>predictive</b> <b>parity</b> to luck egalitarianism, they have to go to especially great lengths, in assuming that the", "dateLastCrawled": "2022-02-01T05:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "Simply put, the goal of classification is to determine a plausible value for an unknown variable Y given an observed variable X.For example, we might try to predict whether a loan applicant will pay back her loan by looking at various characteristics such as credit history, income, and net worth. Classification also applies in situations where the variable Y does not refer to an event that lies in the future. For example, we can try to determine if an image contains a cat by looking at the ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The <b>measure and mismeasure of fairness: a critical review</b> of fair ...", "url": "https://blog.acolyer.org/2020/02/03/measure-mismeasure-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blog.acolyer.org/2020/02/03/measure-mismeasure-fairness", "snippet": "In case you\u2019re wondering where on earth I\u2019m going with this\u2026 it\u2019s a very stretched <b>analogy</b> I\u2019ve been playing with in my mind. One premise of many models of fairness in <b>machine</b> <b>learning</b> is that you can measure (\u2018prove\u2019) fairness of a <b>machine</b> <b>learning</b> model from within the system \u2013 i.e. from properties of the model itself and perhaps the data it is trained on. Beyond the questions of whether any one model of fairness is better or worse than another, I\u2019m coming to the ...", "dateLastCrawled": "2022-01-30T11:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Predicting phosphorescence energies and inferring wavefunction ...", "url": "https://pubs.rsc.org/en/content/articlelanding/2021/sc/d1sc02136b#!", "isFamilyFriendly": true, "displayUrl": "https://pubs.rsc.org/en/content/articlelanding/2021/sc/d1sc02136b#!", "snippet": "Phosphorescence is commonly utilized for applications including light-emitting diodes and photovoltaics. <b>Machine</b> <b>learning</b> (ML) approaches trained on ab initio datasets of singlet\u2013triplet energy gaps may expedite the discovery of phosphorescent compounds with the desired emission energies. However, we show that standard ML approaches for modeling potential energy surfaces inaccurately predict singlet\u2013triplet energy gaps due to the failure to account for spatial localities of spin transitions.", "dateLastCrawled": "2022-01-31T06:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Mitigating Unwanted Biases with Adversarial Learning</b>", "url": "https://www.aies-conference.com/2018/contents/papers/main/AIES_2018_paper_162.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aies-conference.com/2018/contents/papers/main/AIES_2018_paper_162.pdf", "snippet": "<b>Machine</b> <b>learning</b> is a tool for building models that accurately represent input training data. When undesired biases concern- ing demographic groups are in the training data, well-trained models will re\ufb02ect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously <b>learning</b> a predictor and an ad-versary. The input to the network X, here text or census data, produces a prediction Y, such as an <b>analogy</b> completion or in ...", "dateLastCrawled": "2021-12-17T22:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "On the integration of molecular dynamics, data science, and experiments ...", "url": "https://www.sciencedirect.com/science/article/pii/S2211339822000065", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2211339822000065", "snippet": "<b>Machine</b> <b>learning</b> (ML) models have been used for efficiently identifying ternary platinum alloys ... and the slope of a <b>parity</b> line between predicted and experimentally measured values. When trained on mixtures of water and dioxane, a linear regression model was accurate, obtaining an RMSE of 0.23 and <b>parity</b> line slope of 0.89; however, this model was not as accurate when including mixtures with other cosolvents (gamma-valerolactone or tetrahydrofuran), obtaining an RMSE of 0.58 and ...", "dateLastCrawled": "2022-02-03T03:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>All Unit MCQ questions of ML</b> \u2013 TheCodingShef", "url": "https://thecodingshef.com/all-unit-mcq-questions-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://thecodingshef.com/<b>all-unit-mcq-questions-of</b>-<b>machine</b>-<b>learning</b>", "snippet": "Correct option is C. Choose the correct option regarding <b>machine</b> <b>learning</b> (ML) and artificial intelligence (AI) ML is a set of techniques that turns a dataset into a software. AI is a software that can emulate the human mind. ML is an alternate way of programming intelligent machines. All of the above. Correct option is D.", "dateLastCrawled": "2022-01-30T22:09:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(predictive parity)  is like +(creating a predictive model)", "+(predictive parity) is similar to +(creating a predictive model)", "+(predictive parity) can be thought of as +(creating a predictive model)", "+(predictive parity) can be compared to +(creating a predictive model)", "machine learning +(predictive parity AND analogy)", "machine learning +(\"predictive parity is like\")", "machine learning +(\"predictive parity is similar\")", "machine learning +(\"just as predictive parity\")", "machine learning +(\"predictive parity can be thought of as\")", "machine learning +(\"predictive parity can be compared to\")"]}