{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "python - <b>Bayesian Neural Network: Computation of Hessian</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/33567260/bayesian-neural-network-computation-of-hessian", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/<b>question</b>s/33567260", "snippet": "<b>Bayesian Neural Network: Computation of Hessian</b>. Ask <b>Question</b> Asked 6 years, 2 months ago. Active 5 years, 11 months ago. Viewed 677 times 2 I&#39;m <b>trying</b> to code in Python several types of ANN algorithms in order to get a better understanding/intuition of those. I&#39;m not using Scikit-learn or any other ready-to-go packages since my goal is rather educational than practical. As an example problem, I use MNIST database ...", "dateLastCrawled": "2022-01-14T11:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian methods for neural networks</b> - FAQ. - Inference <b>Group</b>: Home", "url": "http://www.inference.org.uk/mackay/Bayes_FAQ.html", "isFamilyFriendly": true, "displayUrl": "www.inference.org.uk/mackay/Bayes_FAQ.html", "snippet": "I have read your introductory papers on the <b>Bayesian</b> framework for training multilayer perceptrons (&quot;<b>Bayesian</b> Interpolation&quot;, &quot;A Practical <b>Bayesian</b> Framework for Backpropagation Networks&quot;, <b>Neural</b> Computation 4 (1992)) with great interest, but have a <b>question</b> concerning the practical implementation. The scale parameters alpha and beta can be calculated via the number of free parameters, gamma= k-alpha*Trace(A^-1), according to 2*alpha*Ew(w_mp)=gamma, 2*beta*Ed(w_mp)=N-gamma (equations (4.8 ...", "dateLastCrawled": "2021-12-14T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "deep learning - How should the <b>neural</b> <b>network</b> deal with unexpected ...", "url": "https://ai.stackexchange.com/questions/18745/how-should-the-neural-network-deal-with-unexpected-inputs", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/<b>questions</b>/18745/how-should-the-<b>neural</b>-<b>network</b>-deal-with...", "snippet": "A partial solution to your problem is to use a <b>Bayesian</b> <b>neural</b> <b>network</b> (BNN). The idea of a BNN is to associate, rather than a single number, a distribution (usually a Gaussian distribution) with each unit (or neuron) of the <b>neural</b> <b>network</b>. Therefore, for each unit of the <b>network</b>, there are two learnable parameters: the mean and variance of a Gaussian distribution. Consequently, a BNN usually has the double of the number of parameters of a conventional (or non-<b>Bayesian</b>) <b>neural</b> <b>network</b> ...", "dateLastCrawled": "2022-01-22T12:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "\u201cMachine <b>Learning Under a Modern Optimization Lens\u201d Under a Bayesian</b> ...", "url": "https://statmodeling.stat.columbia.edu/2019/11/26/machine-learning-under-a-modern-optimization-lens-under-a-bayesian-lens/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2019/11/26/machine-learning-under-a-modern...", "snippet": "I (Yuling) read this new book Machine <b>Learning Under a Modern Optimization Lens</b> (by Dimitris Bertsimas and Jack Dunn) after I grabbed it from Andrew\u2019s desk. Apparently machine learning is now such a wide-ranging area that we have to access it through some sub-manifold so as to evade dimension curse, and it is the same reason why I would <b>like</b> to discuss this comprehensive and clearly-structured book through a <b>Bayesian</b> perspective.", "dateLastCrawled": "2022-01-31T08:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Masters of suspicion: A <b>Bayesian decision model of motivated political</b> ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/jtsb.12274", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/jtsb.12274", "snippet": "The idea is that the person adopts <b>Bayesian</b> statistics to integrate the friends&#39; opinions plus her own prior <b>guess</b> about the house price (e.g., the person&#39;s own initial <b>guess</b> might be \u00a3300000). This integration results in a posterior estimate of the house price, corresponding to the final <b>guess</b> (formally, this is the conditional probability of the house price given knowledge of the opinions of the three friends: P(HP|F1, F2, F3)). Importantly, in this framework, the person can attribute ...", "dateLastCrawled": "2022-01-09T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "126 questions with answers in <b>BAYESIAN NETWORK</b> | Science topic", "url": "https://www.researchgate.net/topic/Bayesian-Network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Bayesian-Network</b>", "snippet": "Dec 28, 2021. <b>Answer</b>. <b>Bayesian network</b> can use to identify the relationship between variables and to calculate probabilities. But If we consider down stream SC, it&#39;s mainly covering through 7 ...", "dateLastCrawled": "2022-01-29T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What&#39;s the best <b>algorithm for log event classification</b>? (e.g. <b>Bayesian</b> ...", "url": "https://www.quora.com/Whats-the-best-algorithm-for-log-event-classification-e-g-Bayesian-network-Naive-bayes-Neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Whats-the-best-<b>algorithm-for-log-event-classification</b>-e-g...", "snippet": "<b>Answer</b>: Not to be contrarian, but most logs are in fact structured. Dmesg logs have a \u201c&lt;time&gt; &lt;device&gt; : &lt;message&gt;\u201d format, apache error logs follow format ...", "dateLastCrawled": "2022-01-15T18:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Open Mind Tree: <b>bayesian network</b>", "url": "https://openmindtree.blogspot.com/2011/11/bayesian-network.html", "isFamilyFriendly": true, "displayUrl": "https://openmindtree.blogspot.com/2011/11/<b>bayesian-network</b>.html", "snippet": "The graphical structure provides an easy way to specify these conditional independencies, and hence to provide a compact parameterization of the model.Note that &quot;temporal <b>Bayesian network</b>&quot; would be a better name than &quot;dynamic <b>Bayesian network</b>&quot;, since it is assumed that the model structure does not change, but the term DBN has become entrenched. We also normally assume that the parameters do not change, i.e., the model is time-invariant. However, we can always add extra hidden nodes to ...", "dateLastCrawled": "2021-12-05T10:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Neural</b> Annealing: Toward a <b>Neural</b> Theory of Everything", "url": "https://www.qualiaresearchinstitute.org/blog/neural-annealing", "isFamilyFriendly": true, "displayUrl": "https://www.qualiaresearchinstitute.org/blog/<b>neural</b>-annealing", "snippet": "A special hybrid of annealing to an ontology and to other <b>people</b> is social annealing, wherein a <b>group</b> <b>of people</b> undergoes the \u2018entropic disintegration -&gt; <b>neural</b> search -&gt; annealing\u2019 process together, within some shared context- a religious service, a sporting event, a retreat. This seems <b>like</b> the natural mechanism by which tribes are formed (loosely speaking, <b>group</b> synchronization of connectome-specific harmonic wave dynamics) and underlies many of our most sacred experiences. The power ...", "dateLastCrawled": "2022-01-29T22:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Where to ask <b>theoretical AI (neural network questions</b>) - Meta Stack ...", "url": "https://meta.stackoverflow.com/questions/302486/where-to-ask-theoretical-ai-neural-network-questions", "isFamilyFriendly": true, "displayUrl": "https://<b>meta.stackoverflow</b>.com/.../where-to-ask-<b>theoretical-ai-neural-network-questions</b>", "snippet": "Some techniques require a (deep?) understanding in <b>bayesian</b> statistics. As many of us computer scientists and programmers are not familiar with <b>bayesian</b> statistics, such questions should probably find their home at stats. Other techniques are based not so much on mathematical theory, but on very clever algorithms. I agree with commenters that ComputerScience or Theoretical Computer Science could be a good match. I <b>guess</b> Artificial <b>Neural</b> Networks belong to the second <b>group</b>. Many computer ...", "dateLastCrawled": "2022-01-16T08:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>bayesian</b> - What is the difference between probabilistic programming vs ...", "url": "https://stackoverflow.com/questions/57300913/what-is-the-difference-between-probabilistic-programming-vs-probabilistic-machi", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/<b>question</b>s/57300913", "snippet": "A straightforward and generic <b>Bayesian</b> <b>network</b> algorithm would have to consider the large number of 2^N combinations of assignments to the disease variables in order to compute that <b>answer</b>. The probabilistic program representation, however, explicitly indicates that the conditional probabilities for disease[i] and male[i] are identical for all i .", "dateLastCrawled": "2022-01-18T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "\u201cMachine <b>Learning Under a Modern Optimization Lens\u201d Under a Bayesian</b> ...", "url": "https://statmodeling.stat.columbia.edu/2019/11/26/machine-learning-under-a-modern-optimization-lens-under-a-bayesian-lens/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2019/11/26/machine-learning-under-a-modern...", "snippet": "The authors prove that a deep enough optimal classification tree can achieve the same prediction ability as a deep <b>neural</b> <b>network</b> \u2014 when the tree makes splits exactly according to the same <b>network</b> \u2014 whereas tree has a much better interpretability (evidently we could prove a multilevel model at the same setting will achieve a prediction ability no worse than that deep net).", "dateLastCrawled": "2022-01-31T08:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Masters of suspicion: A <b>Bayesian decision model of motivated political</b> ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/jtsb.12274", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/jtsb.12274", "snippet": "The idea is that the person adopts <b>Bayesian</b> statistics to integrate the friends&#39; opinions plus her own prior <b>guess</b> about the house price (e.g., the person&#39;s own initial <b>guess</b> might be \u00a3300000). This integration results in a posterior estimate of the house price, corresponding to the final <b>guess</b> (formally, this is the conditional probability of the house price given knowledge of the opinions of the three friends: P(HP|F1, F2, F3)). Importantly, in this framework, the person can attribute ...", "dateLastCrawled": "2022-01-09T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Brief <b>Introduction to Graphical Models and Bayesian Networks</b>", "url": "https://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html", "snippet": "Despite the name, <b>Bayesian</b> networks do not necessarily imply a commitment to <b>Bayesian</b> statistics. Indeed, it is common to use frequentists methods to estimate the parameters of the CPDs. Rather, they are so called because they use Bayes&#39; rule for probabilistic inference, as we explain below. (The term &quot;directed graphical model&quot; is perhaps more appropriate.) Nevetherless, Bayes nets are a useful representation for hierarchical <b>Bayesian</b> models, which form the foundation of applied <b>Bayesian</b> ...", "dateLastCrawled": "2022-02-01T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bayesian methods for neural networks</b> - FAQ. - Inference <b>Group</b>: Home", "url": "http://www.inference.org.uk/mackay/Bayes_FAQ.html", "isFamilyFriendly": true, "displayUrl": "www.inference.org.uk/mackay/Bayes_FAQ.html", "snippet": "I understand your <b>question</b>, but I think <b>the answer</b> is no, the addition of noise that I describe is a correct procedure for generating samples from the posterior distribution of the parameters (subject to the Gaussian assumption, etc., of course). The procedure should not be viewed as a bootstrap procedure. It is not intended as such. It is intended as a Monte Carlo procedure for obtaining samples from the <b>Bayesian</b> posterior distribution. Maybe I can back up my assertion with the aid of a toy ...", "dateLastCrawled": "2021-12-14T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "243 questions with answers in <b>BAYESIAN</b> | Science topic", "url": "https://www.researchgate.net/topic/Bayesian", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Bayesian</b>", "snippet": "The use of <b>the answer</b> resulting from to the latter <b>question</b> might also be more pragmatic (less experimental an causative). Lets say we obtained a CLES of 0.67 P(A &gt; B). If I go outside and observe ...", "dateLastCrawled": "2022-02-03T17:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Most <b>asked Data Science Interview Questions in India</b> | <b>Springboard Blog</b>", "url": "https://in.springboard.com/blog/most-asked-data-science-interview-questions-in-india/", "isFamilyFriendly": true, "displayUrl": "https://in.springboard.com/blog/most-<b>asked-data-science-interview-questions-in-india</b>", "snippet": "have a pre-trained <b>neural</b> <b>network</b> used on a <b>similar</b> problem. Which method would . you choose to make use of this pre-trained <b>network</b>, and why? <b>The answer</b> demonstrates your problem-solving skills. So explain the process briefly with examples, to display your understanding. If the data is mostly <b>similar</b>, the best method would be to freeze all the layers and re-train only the last layer; because the previous layers work as feature extractors. E. TOOL / LANGUAGE . It is not all about mentioning ...", "dateLastCrawled": "2022-01-27T18:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Explaining Explainable AI. Explainable AI \u2014 \u201cAn approximation of\u2026 | by ...", "url": "https://medium.com/swlh/explaining-explainable-ai-b3ca0f8b357b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/explaining-explainable-ai-b3ca0f8b357b", "snippet": "A very oversimplified definition of a <b>neural</b> <b>network</b> is a function which, based on the inputs can automatically adjust its parameters to approximate the output.", "dateLastCrawled": "2022-01-06T03:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "regression - How to determine the <b>confidence</b> of a <b>neural</b> <b>network</b> ...", "url": "https://stats.stackexchange.com/questions/247551/how-to-determine-the-confidence-of-a-neural-network-prediction", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/<b>question</b>s/247551", "snippet": "It sounds like you are looking for a prediction-interval, i.e., an interval that contains a prespecified percentage of future realizations.(Look at the tag wikis for prediction-interval and <b>confidence</b>-interval for the difference.). Your best bet is likely to work directly with NN architectures that do not output single point predictions, but entire predictive distributions.You can then directly extract desired prediction intervals (or mean, or median point predictions) from these distributions.", "dateLastCrawled": "2022-02-03T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the <b>Bayesian</b> trap? - Quora", "url": "https://www.quora.com/What-is-the-Bayesian-trap", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-<b>Bayesian</b>-trap", "snippet": "<b>Answer</b> (1 of 6): I\u2019ve been doing data analysis and reading about it for 25 years and hadn\u2019t heard the term, so I googled. I found the same video that Terry Moore found, and one site with a little bit of text. The \u201ctrap\u201d is well known, but it isn\u2019t <b>Bayesian</b> - Bayes Theorem provides the way out of...", "dateLastCrawled": "2022-01-15T03:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Brief <b>Introduction to Graphical Models and Bayesian Networks</b>", "url": "https://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html", "snippet": "Note that &quot;temporal <b>Bayesian</b> <b>network</b>&quot; would be a better name than &quot;dynamic <b>Bayesian</b> <b>network</b>&quot;, since it is assumed that the model structure does not change, but the term DBN has become entrenched. We also normally assume that the parameters do not change, i.e., the model is time-invariant. However, we <b>can</b> always add extra hidden nodes to represent the current &quot;regime&quot;, thereby creating mixtures of models to capture periodic non-stationarities. There are some cases where the size of the state ...", "dateLastCrawled": "2022-02-01T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Sampling from a <b>Bayesian</b> <b>network</b> with evidence in tensorflow ...", "url": "https://stackoverflow.com/questions/56426333/sampling-from-a-bayesian-network-with-evidence-in-tensorflow-probability", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/<b>question</b>s/56426333", "snippet": "Which is probably the simplest <b>Bayesian</b> <b>network</b> with two binary variables X and Y. The goal is to set evidence to either X or Y and sample from the posterior in order to estimate the probabilities. (Obviously, one <b>can</b> use rejection sampling by sampling first unconditioned and then throw away samples not consistent with the evidence, but it would be fairly inefficient.) <b>bayesian</b>-networks tensorflow-probability. Share. Improve this <b>question</b>. Follow asked Jun 3 &#39;19 at 11:22. John Doe John Doe ...", "dateLastCrawled": "2022-01-24T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian methods for neural networks</b> - FAQ. - Inference <b>Group</b>: Home", "url": "http://www.inference.org.uk/mackay/Bayes_FAQ.html", "isFamilyFriendly": true, "displayUrl": "www.inference.org.uk/mackay/Bayes_FAQ.html", "snippet": "I understand your <b>question</b>, but I think <b>the answer</b> is no, the addition of noise that I describe is a correct procedure for generating samples from the posterior distribution of the parameters (subject to the Gaussian assumption, etc., of course). The procedure should not be viewed as a bootstrap procedure. It is not intended as such. It is intended as a Monte Carlo procedure for obtaining samples from the <b>Bayesian</b> posterior distribution. Maybe I <b>can</b> back up my assertion with the aid of a toy ...", "dateLastCrawled": "2021-12-14T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "\u201cMachine <b>Learning Under a Modern Optimization Lens\u201d Under a Bayesian</b> ...", "url": "https://statmodeling.stat.columbia.edu/2019/11/26/machine-learning-under-a-modern-optimization-lens-under-a-bayesian-lens/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2019/11/26/machine-learning-under-a-modern...", "snippet": "The authors prove that a deep enough optimal classification tree <b>can</b> achieve the same prediction ability as a deep <b>neural</b> <b>network</b> \u2014 when the tree makes splits exactly according to the same <b>network</b> \u2014 whereas tree has a much better interpretability (evidently we could prove a multilevel model at the same setting will achieve a prediction ability no worse than that deep net).", "dateLastCrawled": "2022-01-31T08:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "126 questions with answers in <b>BAYESIAN NETWORK</b> | Science topic", "url": "https://www.researchgate.net/topic/Bayesian-Network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Bayesian-Network</b>", "snippet": "Dec 28, 2021. <b>Answer</b>. <b>Bayesian network</b> <b>can</b> use to identify the relationship between variables and to calculate probabilities. But If we consider down stream SC, it&#39;s mainly covering through 7 ...", "dateLastCrawled": "2022-01-29T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "241 questions with answers in <b>BAYESIAN</b> | Science topic", "url": "https://www.researchgate.net/topic/Bayesian/2", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Bayesian</b>/2", "snippet": "Several algorithms <b>can</b> be used for training a <b>neural</b> <b>network</b>; such as Levenberg-Marquardt, BFGS Quasi-Newton, Resilient Backpropagation, etc. The gradient method is distinguished by its simplicity ...", "dateLastCrawled": "2022-01-17T03:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "When to use <b>bootstrap</b> vs. <b>bayesian</b> technique? - Cross Validated", "url": "https://stats.stackexchange.com/questions/25286/when-to-use-bootstrap-vs-bayesian-technique", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/<b>question</b>s/25286", "snippet": "Cross Validated is a <b>question</b> and <b>answer</b> site for <b>people</b> interested in statistics, machine learning, data analysis, data mining, and data visualization. It only takes a minute to sign up. Sign up to join this community. Anybody <b>can</b> ask a <b>question</b> Anybody <b>can</b> <b>answer</b> The best answers are voted up and rise to the top Home Public; Questions; Tags Users Unanswered Teams. Stack Overflow for Teams \u2013 Collaborate and share knowledge with a private <b>group</b>. Create a free Team What is Teams? Teams ...", "dateLastCrawled": "2022-01-28T20:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "machine learning - Is it possible to train a <b>neural network</b> without ...", "url": "https://stats.stackexchange.com/questions/235862/is-it-possible-to-train-a-neural-network-without-backpropagation", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/<b>question</b>s/235862", "snippet": "As long as this is a community <b>question</b> , I <b>thought</b> I would add another response. &quot;Back Propagation&quot; is simply the gradient descent algorithm. It involves using only the first derivative of the function for which one is <b>trying</b> to find the local minima or maxima. There is another method called Newton&#39;s method or Newton-Raphson which involves calculating the Hessian and so uses second derivatives. It <b>can</b> succeed in instances in which gradient descent fails. I am told by others more ...", "dateLastCrawled": "2022-02-02T05:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is the <b>Bayesian</b> trap? - Quora", "url": "https://www.quora.com/What-is-the-Bayesian-trap", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-<b>Bayesian</b>-trap", "snippet": "<b>Answer</b> (1 of 6): I\u2019ve been doing data analysis and reading about it for 25 years and hadn\u2019t heard the term, so I googled. I found the same video that Terry Moore found, and one site with a little bit of text. The \u201ctrap\u201d is well known, but it isn\u2019t <b>Bayesian</b> - Bayes Theorem provides the way out of...", "dateLastCrawled": "2022-01-15T03:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why are <b>people</b> so opposed to <b>neural</b> networks/CNNs/deep learning ...", "url": "https://www.quora.com/Why-are-people-so-opposed-to-neural-networks-CNNs-deep-learning-techniques-and-are-there-alternatives-to-them-for-identifying-objects-in-images-that-achieve-the-same-speed-and-accuracy", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-are-<b>people</b>-so-opposed-to-<b>neural</b>-<b>networks</b>-CNNs-deep-learning...", "snippet": "<b>Answer</b> (1 of 10): I <b>can</b> understand what OP is saying, and unfortunately, I hear all the time similar critiques against deep learning. Really, <b>neural</b> networks are not black box approaches. There is no magic there, in fact, explaining how does a dual SVM works is significantly harder than explaini...", "dateLastCrawled": "2022-01-07T11:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian methods for neural networks</b> - FAQ. - Inference <b>Group</b>: Home", "url": "http://www.inference.org.uk/mackay/Bayes_FAQ.html", "isFamilyFriendly": true, "displayUrl": "www.inference.org.uk/mackay/Bayes_FAQ.html", "snippet": "I have read your introductory papers on the <b>Bayesian</b> framework for training multilayer perceptrons (&quot;<b>Bayesian</b> Interpolation&quot;, &quot;A Practical <b>Bayesian</b> Framework for Backpropagation Networks&quot;, <b>Neural</b> Computation 4 (1992)) with great interest, but have a <b>question</b> concerning the practical implementation. The scale parameters alpha and beta <b>can</b> be calculated via the number of free parameters, gamma= k-alpha*Trace(A^-1), according to 2*alpha*Ew(w_mp)=gamma, 2*beta*Ed(w_mp)=N-gamma (equations (4.8 ...", "dateLastCrawled": "2021-12-14T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What are the differences between <b>hidden Markov</b> models and <b>neural</b> networks?", "url": "https://stats.stackexchange.com/questions/20429/what-are-the-differences-between-hidden-markov-models-and-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/<b>question</b>s/20429", "snippet": "There are alternatives to <b>Hidden Markov</b> Models available, for example you might be able to use a more general <b>Bayesian</b> <b>Network</b>, a different topology or a Stochastic Context-Free Grammar (SCFG) if you believe that the problem lies within the HMMs lack of power to model your problem - that is, if you need an algorithm that is able to discriminate between more complex hypotheses and/or describe the behaviour of data that is much more complex.", "dateLastCrawled": "2022-01-26T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "126 questions with answers in <b>BAYESIAN NETWORK</b> | Science topic", "url": "https://www.researchgate.net/topic/Bayesian-Network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Bayesian-Network</b>", "snippet": "Dec 28, 2021. <b>Answer</b>. <b>Bayesian network</b> <b>can</b> use to identify the relationship between variables and to calculate probabilities. But If we consider down stream SC, it&#39;s mainly covering through 7 ...", "dateLastCrawled": "2022-01-29T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "\u201cMachine <b>Learning Under a Modern Optimization Lens\u201d Under a Bayesian</b> ...", "url": "https://statmodeling.stat.columbia.edu/2019/11/26/machine-learning-under-a-modern-optimization-lens-under-a-bayesian-lens/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2019/11/26/machine-learning-under-a-modern...", "snippet": "The authors prove that a deep enough optimal classification tree <b>can</b> achieve the same prediction ability as a deep <b>neural</b> <b>network</b> \u2014 when the tree makes splits exactly according to the same <b>network</b> \u2014 whereas tree has a much better interpretability (evidently we could prove a multilevel model at the same setting will achieve a prediction ability no worse than that deep net).", "dateLastCrawled": "2022-01-31T08:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>bayesian</b> - What is the difference between probabilistic programming vs ...", "url": "https://stackoverflow.com/questions/57300913/what-is-the-difference-between-probabilistic-programming-vs-probabilistic-machi", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/<b>question</b>s/57300913", "snippet": "I <b>guess</b> there is some vagueness between the two terms but my take on them is the following: ... A straightforward and generic <b>Bayesian</b> <b>network</b> algorithm would have to consider the large number of 2^N combinations of assignments to the disease variables in order to compute that <b>answer</b>. The probabilistic program representation, however, explicitly indicates that the conditional probabilities for disease[i] and male[i] are identical for all i. An inference algorithm <b>can</b> exploit that to compute ...", "dateLastCrawled": "2022-01-18T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Neural nets vs</b>. regression models | Statistical Modeling, Causal ...", "url": "https://statmodeling.stat.columbia.edu/2019/05/21/neural-nets-vs-statistical-models/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2019/05/21/<b>neural-nets-vs</b>-statistical-models", "snippet": "Deep <b>neural</b> nets, by which <b>people</b> mean nets with more than one hidden layer, are a form of <b>neural</b> <b>network</b>. Deep nets are computationally intractable for traditional statistical inference due to both multimodality and the scale of the likelihood function. To cope, machine learning researchers have layered heuristics on top of standard estimation techniques such as autoencoders, early stopping, etc. And because the form of the likelihood matters and generic networks don\u2019t work, they include ...", "dateLastCrawled": "2022-02-02T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Masters of suspicion: A <b>Bayesian decision model of motivated political</b> ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/jtsb.12274", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/jtsb.12274", "snippet": "The idea is that the person adopts <b>Bayesian</b> statistics to integrate the friends&#39; opinions plus her own prior <b>guess</b> about the house price (e.g., the person&#39;s own initial <b>guess</b> might be \u00a3300000). This integration results in a posterior estimate of the house price, corresponding to the final <b>guess</b> (formally, this is the conditional probability of the house price given knowledge of the opinions of the three friends: P(HP|F1, F2, F3)). Importantly, in this framework, the person <b>can</b> attribute ...", "dateLastCrawled": "2022-01-09T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Where should I place <b>dropout</b> layers in a <b>neural</b> <b>network</b>? - Cross Validated", "url": "https://stats.stackexchange.com/questions/240305/where-should-i-place-dropout-layers-in-a-neural-network", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/<b>question</b>s/240305", "snippet": "In the original paper that proposed <b>dropout</b> layers, by Hinton (2012), <b>dropout</b> (with p=0.5) was used on each of the fully connected (dense) layers before the output; it was not used on the convolutional layers.This became the most commonly used configuration. More recent research has shown some value in applying <b>dropout</b> also to convolutional layers, although at much lower levels: p=0.1 or 0.2. <b>Dropout</b> was used after the activation function of each convolutional layer: CONV-&gt;RELU-&gt;DROP.", "dateLastCrawled": "2022-02-02T16:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to <b>learn Bayesian time series analysis</b> - Quora", "url": "https://www.quora.com/How-can-I-learn-Bayesian-time-series-analysis", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>can</b>-I-<b>learn-Bayesian-time-series-analysis</b>", "snippet": "<b>Answer</b> (1 of 3): There are a few resources available. As Justin Rising mentioned, the David Barber et. al. book <b>Bayesian</b> Time Series Models, and a shorter introduction <b>can</b> be found in the Signal Processing Magazine article Graphical Models for Time-Series. You could have a look at the videos of...", "dateLastCrawled": "2022-01-17T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Questions about Excel and SQL in Data Analyst Internship", "url": "https://www.reddit.com/r/statistics/comments/75jp8u/questions_about_excel_and_sql_in_data_analyst/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/statistics/comments/75jp8u/<b>questions</b>_about_excel_and_sql_in...", "snippet": "This is a really good video that explains the differences between regular <b>neural</b> networks and <b>bayesian</b> <b>neural</b> networks. Apparently in <b>bayesian</b> <b>neural</b> networks, the weights aren&#39;t assigned a fixed value but instead each weight is assigned a probability distribution (e.g. each weight is given a normal probability distribution and we calculate the mean and variance).", "dateLastCrawled": "2021-04-20T06:41:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>machine</b> <b>learning</b> approach to <b>Bayesian</b> parameter estimation | npj ...", "url": "https://www.nature.com/articles/s41534-021-00497-w", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-021-00497-w", "snippet": "The parameter estimation discussed in this manuscript is divided in two parts: i) a <b>neural</b> <b>network</b> is trained and ii) <b>Bayesian</b> estimation performed on a test set, which we detail below.", "dateLastCrawled": "2022-02-03T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "9.7. <b>Bayesian</b> <b>neural</b> networks \u2014 <b>Learning</b> from data", "url": "https://furnstahl.github.io/Physics-8820/notebooks/Machine_learning/Bayesian_neural_networks_tif285.html", "isFamilyFriendly": true, "displayUrl": "https://furnstahl.github.io/.../<b>Machine</b>_<b>learning</b>/<b>Bayesian</b>_<b>neural</b>_<b>networks</b>_tif285.html", "snippet": "<b>Bayesian</b> <b>neural</b> networks differ from plain <b>neural</b> networks in that their weights are assigned a probability distribution instead of a single value or point estimate. These probability distributions describe the uncertainty in weights and can be used to estimate uncertainty in predictions. Training a <b>Bayesian</b> <b>neural</b> <b>network</b> via variational inference learns the parameters of these distributions instead of the weights directly.", "dateLastCrawled": "2021-12-21T06:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "34. <b>Bayesian</b> <b>neural</b> networks \u2014 <b>Learning</b> from data", "url": "https://physics-chalmers.github.io/tif285/doc/LectureNotes/_build/html/content/MachineLearning/BNN/bnn.html", "isFamilyFriendly": true, "displayUrl": "https://physics-chalmers.github.io/.../_build/html/content/<b>MachineLearning</b>/BNN/bnn.html", "snippet": "34. <b>Bayesian</b> <b>neural</b> networks\u00b6. The introduction part of this lecture is inspired by the chapter \u201c<b>Learning</b> as Inference\u201d in the excellent book Information Theory, Inference, and <b>Learning</b> Algorithms by David MacKay.. Some python libraries that are relevant for <b>Bayesian</b> <b>Neural</b> Networks (and part of the general trend towards Probabilistic Programming in <b>Machine</b> <b>Learning</b>) are:", "dateLastCrawled": "2022-01-13T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "<b>Bayesian</b> <b>neural</b> networks are best explained using an <b>analogy</b> example. Suppose that instead of a <b>neural</b> <b>network</b>, you have a prediction equation y = (8.5 * x1) + (9.5 * x2) + 2.5 where y is the predicted income of an employee, x1 is normalized age, and x2 is years of job tenure. The predicted income of a 30-year old who has been on the job for 4 years would be y = (8.5 * 3.0) + (9.5 * 4.0) + 2.5 = 64.5 = $64,500. If you feed the same (age, tenure) input of (3.0, 4.0) to the prediction equation ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bayesian</b> <b>Neural Network</b> Series Post 2: Background Knowledge | by Kumar ...", "url": "https://medium.com/neuralspace/bayesian-neural-network-series-post-2-background-knowledge-fdec6ac62d43", "isFamilyFriendly": true, "displayUrl": "https://medium.com/<b>neural</b>space/<b>bayesian</b>-<b>neural-network</b>-series-post-2-background...", "snippet": "I will try to brief the <b>neural</b> networks <b>analogy</b> with the brain and will spend more time explaining the Probabilistic <b>Machine</b> <b>Learning</b> segments that we will work on in future. Brain Analogies. A ...", "dateLastCrawled": "2022-01-30T12:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep <b>neural</b> <b>network</b> models, and it has been used for conducting ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bayesian</b> <b>Neural</b> Networks: 3 <b>Bayesian</b> CNN | by Adam Woolf | Towards Data ...", "url": "https://towardsdatascience.com/bayesian-neural-networks-3-bayesian-cnn-6ecd842eeff3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bayesian</b>-<b>neural</b>-<b>networks</b>-3-<b>bayesian</b>-cnn-6ecd842eeff3", "snippet": "This is the third chapter in the series on <b>Bayesian</b> Deep <b>Learning</b>. The previous article is available here. We already know that <b>neural</b> networks are arrogant. But another failing of standard <b>neural</b> nets is a susceptibility to being tricked. Imagine a CNN tasked with a morally questionable task like face recognition. It gets its input from a security camera. But what happens when the security camera sends a picture of a dog, a mannequin or a child\u2019s doll? The CNN will still output ...", "dateLastCrawled": "2022-01-30T07:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Bayesian</b> <b>Neural Networks</b>: An Introduction and Survey \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2006.12024/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2006.12024", "snippet": "<b>Neural Networks</b> (NNs) have provided state-of-the-art results for many challenging <b>machine</b> <b>learning</b> tasks such as detection, regression and classification across the domains of computer vision, speech recognition and natural language processing. Despite their success, they are often implemented in a frequentist scheme, meaning they are unable to reason about uncertainty in their predictions. This article introduces <b>Bayesian</b> <b>Neural Networks</b> (BNNs) and the seminal research regarding their ...", "dateLastCrawled": "2021-10-27T08:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Bayesian Belief Network in Artificial Intelligence</b> - Javatpoint", "url": "https://www.javatpoint.com/bayesian-belief-network-in-artificial-intelligence", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>bayesian-belief-network-in-artificial-intelligence</b>", "snippet": "<b>Bayesian Belief Network in artificial intelligence</b>. <b>Bayesian</b> belief <b>network</b> is key computer technology for dealing with probabilistic events and to solve a problem which has uncertainty. We can define a <b>Bayesian</b> <b>network</b> as: &quot;A <b>Bayesian</b> <b>network</b> is a probabilistic graphical model which represents a set of variables and their conditional ...", "dateLastCrawled": "2022-02-02T21:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bayesian neural network)  is like +(group of people trying to guess the answer to a question)", "+(bayesian neural network) is similar to +(group of people trying to guess the answer to a question)", "+(bayesian neural network) can be thought of as +(group of people trying to guess the answer to a question)", "+(bayesian neural network) can be compared to +(group of people trying to guess the answer to a question)", "machine learning +(bayesian neural network AND analogy)", "machine learning +(\"bayesian neural network is like\")", "machine learning +(\"bayesian neural network is similar\")", "machine learning +(\"just as bayesian neural network\")", "machine learning +(\"bayesian neural network can be thought of as\")", "machine learning +(\"bayesian neural network can be compared to\")"]}