{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "2D <b>Wasserstein loss for robust facial landmark detection</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0031320321001321", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320321001321", "snippet": "Novel method based on the <b>Wasserstein</b> <b>loss</b> to significantly improve the robustness of facial landmark detection. ... Landmark-wise CED of COFW \u2192 AFLW <b>cross-validation</b> with HRNet. Download : Download high-res image (1MB) Download : Download full-size image; Fig. 10. Cross-dataset validation of HRNet trained on WFLW (WFLW \u2192 300VW). From protocol 300W \u2192 WFLW , we find that using larger \u03c3 (L2 <b>Loss</b>, \u03c3 = 3) and <b>Wasserstein</b> <b>loss</b> (W <b>Loss</b>, \u03c3 = 1) can respectively improve the NME by 0.5 point ...", "dateLastCrawled": "2022-01-08T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Wasserstein Loss based Deep Object Detection</b>", "url": "https://www.researchgate.net/publication/343059928_Wasserstein_Loss_based_Deep_Object_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343059928_<b>Wasserstein_Loss_based_Deep_Object</b>...", "snippet": "Recently, the <b>Wasserstein</b> <b>loss</b> is adopted as an alternative to conventional cross-entropy <b>loss</b> to incorporate the inter-class correlations [29,37, 16, 33,30,40,13]. The restrictive partially ...", "dateLastCrawled": "2021-12-23T10:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Sample Out-of-Sample Inference Based on <b>Wasserstein</b> Distance (Journal ...", "url": "https://par.nsf.gov/biblio/10303857-sample-out-sample-inference-based-wasserstein-distance", "isFamilyFriendly": true, "displayUrl": "https://par.nsf.gov/biblio/10303857", "snippet": "This content will become publicly available on May 1, 2022. Sample Out-of-Sample Inference Based on <b>Wasserstein</b> Distance", "dateLastCrawled": "2022-01-29T07:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Correcting Nuisance Variation using Wasserstein Distance</b> | DeepAI", "url": "https://deepai.org/publication/correcting-nuisance-variation-using-wasserstein-distance", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>correcting-nuisance-variation-using-wasserstein-distance</b>", "snippet": "Figure 2: The <b>Wasserstein</b> <b>loss</b> function and the gradient penalty terms as a function of the number of steps trained on one of the 20 random train split subset of embeddings from images of cells from the BBBC021 image dataset, after the <b>Wasserstein</b> parameters have been pre-trained for 20000 steps.", "dateLastCrawled": "2021-12-10T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A <b>Robust Learning Approach for Regression Models</b> Based on ...", "url": "https://jmlr.csail.mit.edu/papers/volume19/17-295/17-295.pdf", "isFamilyFriendly": true, "displayUrl": "https://jmlr.csail.mit.edu/papers/volume19/17-295/17-295.pdf", "snippet": "1-<b>loss</b> function, and the radius of the <b>Wasserstein</b> set. This connection provides guidance on the selection of the regularization coe cient and may lead to signi cant computational savings compared to <b>cross-validation</b>. DRO essentially enables new and more accurate interpretations of the regularizer, and establishes its dependence on", "dateLastCrawled": "2022-01-26T11:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Conditional <b>Wasserstein</b> GAN-based Oversampling of Tabular Data for ...", "url": "https://www.arxiv-vanity.com/papers/2008.09202/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2008.09202", "snippet": "As the magnitude of the <b>Wasserstein</b> <b>loss</b> fluctuates during training, we scale the AC <b>loss</b> by a scale factor \u03bb A C which is continuously updated to ten percent of the absolute value of D (G (z)) for the current batch \u03bb A C = 0.1 | D (G (z)) | to ensure that minimising the <b>Wasserstein</b> <b>loss</b> is the primary objective of the generator. During backpropagation, the scale factor is treated as a constant. Furthermore, in training we cap the AC <b>loss</b> at", "dateLastCrawled": "2022-01-25T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>WASSERSTEIN ADVERSARIAL REGULARIZATION (WAR) ON LABEL</b> NOISE", "url": "https://openreview.net/pdf?id=SJldu6EtDS", "isFamilyFriendly": true, "displayUrl": "https://openreview.net/pdf?id=SJldu6EtDS", "snippet": "method <b>Wasserstein</b> Adversarial Regularization. Frogner et al. (2015) already used the <b>Wasserstein</b> distance as a <b>loss</b> in a learning system between the output of the model for multi-label learning. The interest of the <b>Wasserstein</b> distance is to take into consideration the geometry of the label space. We de\ufb01ne the proposed regularization term R", "dateLastCrawled": "2022-01-01T16:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[<b>D] Read-through: Wasserstein GAN</b> : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/5vlltu/d_readthrough_wasserstein_gan/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/MachineLearning/comments/5vlltu/<b>d_readthrough_wasserstein_gan</b>", "snippet": "The main idea in this paper is that the earth mover metric is a better <b>loss</b> function to train GANs. I don&#39;t understand the reason we&#39;ll enough apart from the fact that in traditional GAN you cannot train the discriminator up to convergence, which leads to a lot of the instability in the training. WGANs overcome this problem, leading to very stable training. 2. share. Report Save. level 2. 3 years ago \u00b7 edited 3 years ago. Please. WGAN is just a special case of LambGAN which implements ...", "dateLastCrawled": "2021-01-16T21:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>GitHub</b> - growingfuture/<b>Structure-sensitive-Multi-scale-Deep-Neural</b> ...", "url": "https://github.com/growingfuture/Structure-sensitive-Multi-scale-Deep-Neural-Network-for-Low-Dose-CT-Denoising", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/growingfuture/<b>Structure-sensitive-Multi-scale-Deep-Neural</b>-Network...", "snippet": "Additionally, L1 <b>loss</b> enjoys the same fine characteristics as L2 <b>loss</b>, <b>like</b> a fast convergence speed. Adversarial <b>loss</b>: The improved <b>Wasserstein</b> distance with the regularization term proposed in [43] is expressed as above. where the first two terms are computed for <b>Wasserstein</b> distance and the third term is the gradient penalty term. It is worth noting that z denotes G(y) for brevity. Structural <b>loss</b>: Medical images have strong 3D image correlations; their voxels demonstrate strong ...", "dateLastCrawled": "2022-01-18T22:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "From Learning to Rank to Unsupervised Translation: towards a deep ...", "url": "https://gguinet.github.io/post/semi-supervised/", "isFamilyFriendly": true, "displayUrl": "https://gguinet.github.io/post/semi-supervised", "snippet": "The pairwise logistic <b>loss</b> is a pairwise <b>loss</b> function that compares if pair of items are ordered in the right order. We can define it as: where $\\mathbb{I}_{x}$ is the indicator function. Finally, a listwise <b>loss</b> function <b>like</b> the Softmax cross-entropy can be defined as:", "dateLastCrawled": "2022-02-02T01:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Wasserstein Loss based Deep Object Detection</b>", "url": "https://www.researchgate.net/publication/343059928_Wasserstein_Loss_based_Deep_Object_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343059928_<b>Wasserstein_Loss_based_Deep_Object</b>...", "snippet": "Recently, the <b>Wasserstein</b> <b>loss</b> is adopted as an alternative to conventional cross-entropy <b>loss</b> to incorporate the inter-class correlations [29,37, 16, 33,30,40,13]. The restrictive partially ...", "dateLastCrawled": "2021-12-23T10:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "2D <b>Wasserstein loss for robust facial landmark detection</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0031320321001321", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320321001321", "snippet": "Using <b>Wasserstein</b> <b>loss</b> for HRM has two advantages: (1) It makes the regression sensitive to the global geometry, thus effectively penalizing predicted activations that appear far away from the ground truth position. (2) When training with the L 2 <b>loss</b>, the heatmap is not strictly considered as a distribution as no normalisation applied over the map. When training with the <b>Wasserstein</b> <b>loss</b>, the heatmaps are first passed through a softmax function. That means the sum of all pixel values of an ...", "dateLastCrawled": "2022-01-08T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Data augmentation-based conditional <b>Wasserstein</b> generative adversarial ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7924509/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7924509", "snippet": "All the methods were validated using 10-fold <b>cross-validation</b>. To demonstrate how the attack DR decreased as the gap between normal and malicious classes increased, we injected different ratios of the majority class in the training data to train the XGBoost detector model using AUC and DR criteria. The model tested on the fixed test dataset size of 30% each time. During the attack detection test, the results show that DR decreased from 96.59% with an injected ratio of 2% of the majority ...", "dateLastCrawled": "2021-09-21T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Correcting nuisance variation using <b>Wasserstein</b> distance [PeerJ]", "url": "https://peerj.com/articles/8594/", "isFamilyFriendly": true, "displayUrl": "https://peerj.com/articles/8594", "snippet": "One possible extension is to modify the form of the <b>loss</b> function by the following, which would more closely resemble finding the <b>Wasserstein</b> barycenter: (13) \u2211 i, j = 1 N W (\u03bd i, A d j (\u03bd j)) The difference between this and our presented method is that instead of comparing the pairwise transformed distributions, we compare the transformed distributions to the original distributions. One distinct advantage of this approach is that it avoids the \u201cshrinking to a point\u201d problem, and ...", "dateLastCrawled": "2021-11-20T17:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Correcting nuisance variation using <b>Wasserstein</b> distance. - Abstract ...", "url": "https://europepmc.org/article/MED/32161688", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/32161688", "snippet": "To achieve this, we minimize a <b>loss</b> function based on distances between marginal distributions (such as the <b>Wasserstein</b> distance) of embeddings across domains for each replicated treatment. For the dataset we present results with, the only replicated treatment happens to be the negative control treatment, for which we do not expect any treatment-induced cell morphology changes. We find that for our transformed embeddings (i) the underlying geometric structure is not only preserved but the ...", "dateLastCrawled": "2021-12-12T12:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Conditional <b>Wasserstein</b> GAN-based Oversampling of Tabular Data for ...", "url": "https://www.arxiv-vanity.com/papers/2008.09202/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2008.09202", "snippet": "As the magnitude of the <b>Wasserstein</b> <b>loss</b> fluctuates during training, ... having crosslayers parallel to a deep neural network allows the crosslayers to act <b>similar</b> to a shortcut connection. Shortcut connections are widely used in deep residual networks used for classification [he _deep_2015] and have been used to improve the generator of medGAN [choi_generating_2018]. We also use self-conditioning described in Section 4.2.2 in the generator to further allow the generator to model ...", "dateLastCrawled": "2022-01-25T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "ROBUST <b>WASSERSTEIN</b> PROFILE INFERENCE AND APPLICATIONS TO MACHINE LEARNING", "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/4024D05DE4681E67334E45D039295527/S0021900219000494a.pdf/robust-wasserstein-profile-inference-and-applications-to-machine-learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/4024D05DE4681E...", "snippet": "estimators without the use of <b>cross validation</b>. Numerical experiments are also given to validate our theoretical \ufb01ndings. Keywords: Distributionally robust optimization; <b>Wasserstein</b> distance; regularization; square-root LASSO; logistic regression; support vector machine; limit characterization of optimal <b>Wasserstein</b> ball radius and regularization parameter; empirical likelihood 2010 Mathematics Subject Classi\ufb01cation: Primary 60F05 Secondary 62J05; 62J12 1. Introduction Regularization has ...", "dateLastCrawled": "2022-01-23T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Robust Wasserstein profile inference and applications</b> to machine ...", "url": "https://www.cambridge.org/core/journals/journal-of-applied-probability/article/robust-wasserstein-profile-inference-and-applications-to-machine-learning/4024D05DE4681E67334E45D039295527", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/journal-of-applied-probability/article/robust...", "snippet": "In addition, we introduce RWPI (robust <b>Wasserstein</b> profile inference), a novel inference methodology which extends the use of methods inspired by empirical likelihood to the setting of optimal transport costs (of which <b>Wasserstein</b> distances are a particular case). We use RWPI to show how to optimally select the size of uncertainty regions, and as a consequence we are able to choose regularization parameters for these machine learning estimators without the use of <b>cross validation</b>. Numerical ...", "dateLastCrawled": "2022-01-26T00:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Estimation Stability with Cross Validation (ESCV</b>)", "url": "https://www.researchgate.net/publication/258817326_Estimation_Stability_with_Cross_Validation_ESCV", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../258817326_<b>Estimation_Stability_with_Cross_Validation_ESCV</b>", "snippet": "The Lasso&#39;s <b>cross-validation</b> (CV) procedure is an additional source of algorithmic instability, due to variability inherent to its resampling procedure [17]. Furthermore, Ali and Tibshirani ([1 ...", "dateLastCrawled": "2021-10-23T08:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "S2A: <b>Wasserstein</b> GAN <b>With Spatio-Spectral Laplacian Attention for Multi</b> ...", "url": "https://openaccess.thecvf.com/content_CVPRW_2020/papers/w11/Rout_S2A_Wasserstein_GAN_With_Spatio-Spectral_Laplacian_Attention_for_Multi-Spectral_Band_CVPRW_2020_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_CVPRW_2020/papers/w11/Rout_S2A_<b>Wasserstein</b>_GAN...", "snippet": "S2A: <b>Wasserstein</b> GAN <b>with Spatio-Spectral Laplacian Attention for Multi-Spectral</b> Band Synthesis Litu Rout Indranil Misra S Manthira Moorthi Debajyoti Dhar Signal and Image Processing Group Space Applications Centre Indian Space Research Organisation (lr, indranil, smmoorthi, deb)@sac.isro.gov.in Abstract Intersection of adversarial learning and satellite image processing is an emerging \ufb01eld in remote sensing. In this study, we intend to address synthesis of high resolution multi-spectral ...", "dateLastCrawled": "2022-01-31T11:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Correcting Nuisance Variation using Wasserstein Distance</b>", "url": "https://www.researchgate.net/publication/320867145_Correcting_Nuisance_Variation_using_Wasserstein_Distance", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320867145_Correcting_Nuisance_Variation_using...", "snippet": "PDF | Profiling cellular phenotypes from microscopic imaging <b>can</b> provide meaningful biological information resulting from various factors affecting the... | Find, read and cite all the research ...", "dateLastCrawled": "2021-10-13T03:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Using <b>Wasserstein</b> Generative Adversarial Networks for the Design ...", "url": "https://www.academia.edu/47485723/Using_Wasserstein_Generative_Adversarial_Networks_for_the_Design_of_Monte_Carlo_Simulations", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/47485723/Using_<b>Wasserstein</b>_Generative_Adversarial_Networks...", "snippet": "Using <b>Wasserstein</b> Generative Adversarial Networks for the Design of Monte Carlo Simulations. Jonas Metzger. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 37 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package. Translate PDF. Related Papers. Data augmentation-based conditional <b>Wasserstein</b> generative adversarial network-gradient penalty for XSS attack detection system. By Fawaz M . M ...", "dateLastCrawled": "2022-01-25T22:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Correcting Nuisance Variation using Wasserstein Distance</b> | DeepAI", "url": "https://deepai.org/publication/correcting-nuisance-variation-using-wasserstein-distance", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>correcting-nuisance-variation-using-wasserstein-distance</b>", "snippet": "<b>Correcting Nuisance Variation using Wasserstein Distance</b>. 11/02/2017 \u2219 by Gil Tabak, et al. \u2219 0 \u2219 share Profiling cellular phenotypes from microscopic imaging <b>can</b> provide meaningful biological information resulting from various factors affecting the cells. One motivating application is drug development: morphological cell features <b>can</b> be ...", "dateLastCrawled": "2021-12-10T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Set Representation Learning with Generalized Sliced-<b>Wasserstein</b> ...", "url": "https://deepai.org/publication/set-representation-learning-with-generalized-sliced-wasserstein-embeddings", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/set-representation-learning-with-generalized-sliced...", "snippet": "An increasing number of machine learning tasks deal with learning representations from set-structured data. Solutions to these problems involve the composition of permutation-equivariant modules (e.g., self-attention, or individual processing via feed-forward neural networks) and permutation-invariant modules (e.g., global average pooling, or pooling by multi-head attention).In this paper, we propose a geometrically-interpretable framework for learning representations from set-structured ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Using Wasserstein Generative Adversarial Networks for</b> the design of ...", "url": "https://www.sciencedirect.com/science/article/pii/S0304407621000440", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0304407621000440", "snippet": "GANs <b>can</b> <b>be thought</b> of as implicitly estimating the distribution, although they do not directly produce estimates of the density or distribution function at a particular point. Instead, they generate data from the estimated distribution. They do so by optimizing the parameters of a model for the distribution of the data generating process (DGP) called the generator, which is trained in a type of mini-max game against an adversarial model called the discriminator that attempts to distinguish ...", "dateLastCrawled": "2022-01-02T22:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Conditional Wasserstein GAN-based Oversampling</b> of Tabular Data ...", "url": "https://www.researchgate.net/publication/343825961_Conditional_Wasserstein_GAN-based_Oversampling_of_Tabular_Data_for_Imbalanced_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343825961_Conditional_<b>Wasserstein</b>_GAN-based...", "snippet": "to ensure that minimising the <b>Wasserstein</b> <b>loss</b> is the primary objective of the generator. During backpropagation, the During backpropagation, the scale factor is treated as a constant.", "dateLastCrawled": "2021-11-05T13:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Conditional <b>Wasserstein</b> GAN-based Oversampling of Tabular Data for ...", "url": "https://www.arxiv-vanity.com/papers/2008.09202/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2008.09202", "snippet": "The paper propoes an oversampling method based on a conditional <b>Wasserstein</b> GAN that <b>can</b> effectively model tabular datasets with numerical and categorical variables and pays special attention to the down-stream classification task through an auxiliary classifier <b>loss</b>. We benchmark our method against standard oversampling methods and the imbalanced baseline on seven real-world datasets. Empirical results evidence the competitiveness of GAN-based oversampling. \\setstretch. 1.4 \\keywords ...", "dateLastCrawled": "2022-01-25T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Semi-Supervised Multitask Learning on Multispectral Satellite Images ...", "url": "https://www.arxiv-vanity.com/papers/1902.11110/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1902.11110", "snippet": "<b>Wasserstein</b> Generative Adversarial Networks (GANs) for Predicting Poverty. Anthony Perez Stanford University Stanford, CA - 94305 Equal Contributions. Enrolled in CS 231N Convolutional Neural Networks for Visual Recognition during Spring 2017 at Stanford Swetava Ganguli 1 Stanford University Stanford, CA - 94305 Stefano Ermon Stanford University Stanford, CA - 94305 Assistant Professor, Department of Computer Science George Azzari Stanford University Stanford, CA - 94305 Research Associate ...", "dateLastCrawled": "2021-07-22T11:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Conditional density estimation and simulation through optimal</b> transport ...", "url": "https://link.springer.com/article/10.1007/s10994-019-05866-3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-019-05866-3", "snippet": "A methodology to estimate from samples the probability density of a random variable x conditional to the values of a set of covariates $$\\\\{z_{l}\\\\}$$ {zl} is proposed. The methodology relies on a data-driven formulation of the <b>Wasserstein</b> barycenter, posed as a minimax problem in terms of the conditional map carrying each sample point to the barycenter and a potential characterizing the inverse of this map. This minimax problem is solved through the alternation of a flow developing the map ...", "dateLastCrawled": "2022-02-01T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[<b>D] Applications of Optimal Transport</b>? : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/eqgvjx/d_applications_of_optimal_transport/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/MachineLearning/comments/eqgvjx/d_applications_of_optimal...", "snippet": "Now, as far as ML is concerned, if our distributions are supported in a small-dimensional feature space (say, R 2 to R 10), OT metrics provide a useful baseline: as illustrated in this tutorial, <b>Wasserstein</b>-like <b>loss</b> functions define much cleaner gradients than kernel MMDs and other similar formulas. This is important for generative modelling and 3D shape registration.", "dateLastCrawled": "2021-01-10T14:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "2D <b>Wasserstein loss for robust facial landmark detection</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0031320321001321", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320321001321", "snippet": "Novel method based on the <b>Wasserstein</b> <b>loss</b> to significantly improve the robustness of facial landmark detection. ... Landmark-wise CED of COFW \u2192 AFLW <b>cross-validation</b> with HRNet. Download : Download high-res image (1MB) Download : Download full-size image; Fig. 10. Cross-dataset validation of HRNet trained on WFLW (WFLW \u2192 300VW). From protocol 300W \u2192 WFLW , we find that using larger \u03c3 (L2 <b>Loss</b>, \u03c3 = 3) and <b>Wasserstein</b> <b>loss</b> (W <b>Loss</b>, \u03c3 = 1) <b>can</b> respectively improve the NME by 0.5 point ...", "dateLastCrawled": "2022-01-08T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Correcting nuisance variation using <b>Wasserstein</b> distance [PeerJ]", "url": "https://peerj.com/articles/8594/", "isFamilyFriendly": true, "displayUrl": "https://peerj.com/articles/8594", "snippet": "<b>Cross validation</b> and bootstrapping Early stopping by leave-one-compound-out <b>cross validation</b>. For the model with either early stopping or a regularization term, the hyperparameters (i.e., the stopping time step or the regularization weight) <b>can</b> be selected by a <b>cross validation</b> procedure to avoid overfitting (see Godinez et al. (2017) for an ...", "dateLastCrawled": "2021-11-20T17:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Correcting nuisance variation using <b>Wasserstein</b> distance. - Abstract ...", "url": "https://europepmc.org/article/MED/32161688", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/32161688", "snippet": "To achieve this, we minimize a <b>loss</b> function based on distances between marginal distributions (such as the <b>Wasserstein</b> distance) of embeddings across domains for each replicated treatment. For the dataset we present results with, the only replicated treatment happens to be the negative control treatment, for which we do not expect any treatment-induced cell morphology changes. We find that for our transformed embeddings (i) the underlying geometric structure is not only preserved but the ...", "dateLastCrawled": "2021-12-12T12:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Correcting Nuisance Variation using Wasserstein Distance</b> | DeepAI", "url": "https://deepai.org/publication/correcting-nuisance-variation-using-wasserstein-distance", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>correcting-nuisance-variation-using-wasserstein-distance</b>", "snippet": "<b>Correcting Nuisance Variation using Wasserstein Distance</b>. 11/02/2017 \u2219 by Gil Tabak, et al. \u2219 0 \u2219 share Profiling cellular phenotypes from microscopic imaging <b>can</b> provide meaningful biological information resulting from various factors affecting the cells. One motivating application is drug development: morphological cell features <b>can</b> be ...", "dateLastCrawled": "2021-12-10T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Wasserstein Loss based Deep Object Detection</b>", "url": "https://www.researchgate.net/publication/343059928_Wasserstein_Loss_based_Deep_Object_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343059928_<b>Wasserstein_Loss_based_Deep_Object</b>...", "snippet": "Recently, the <b>Wasserstein</b> <b>loss</b> is adopted as an alternative to conventional cross-entropy <b>loss</b> to incorporate the inter-class correlations [29,37, 16, 33,30,40,13]. The restrictive partially ...", "dateLastCrawled": "2021-12-23T10:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Data augmentation-based conditional <b>Wasserstein</b> generative adversarial ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7924509/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7924509", "snippet": "Oversampling <b>can</b> lead to overfitting, whereas undersampling may discard useful data, which subsequently leads to <b>loss</b> of information (Vluymans, 2019). To mitigate the challenges of limited and highly unbalanced XSS attack dataset, we proposed a data augmentation method based on the conditional GAN and <b>Wasserstein</b> GAN with a gradient penalty (C-WGAN-GP).", "dateLastCrawled": "2021-09-21T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Robust Wasserstein profile inference and applications</b> to machine ...", "url": "https://www.cambridge.org/core/journals/journal-of-applied-probability/article/robust-wasserstein-profile-inference-and-applications-to-machine-learning/4024D05DE4681E67334E45D039295527", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/journal-of-applied-probability/article/robust...", "snippet": "In addition, we introduce RWPI (robust <b>Wasserstein</b> profile inference), a novel inference methodology which extends the use of methods inspired by empirical likelihood to the setting of optimal transport costs (of which <b>Wasserstein</b> distances are a particular case). We use RWPI to show how to optimally select the size of uncertainty regions, and as a consequence we are able to choose regularization parameters for these machine learning estimators without the use of <b>cross validation</b>. Numerical ...", "dateLastCrawled": "2022-01-26T00:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "LCS graph kernel based on <b>Wasserstein</b> distance in longest common ...", "url": "https://www.sciencedirect.com/science/article/pii/S0165168421003182", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0165168421003182", "snippet": "To show improvement of OT framework (<b>Wasserstein</b> distance) <b>compared</b> to R-convolution framework, we implement our FLCS kernel based on the R-convolution framework, which we call FLCS-R Graph Kernel. The FLCS-R Graph Kernel on two graphs G 1 , G 2 is computed as k FLCS \u2212 R ( G 1 , G 2 ) = \u2211 x 1 \u2208 X 1 , x 2 \u2208 X 2 F sim ( x 1 , x 2 ) , where X 1 , X 2 is respective path sequence sets of G 1 , G 2 , and F sim is the path sequence similarity in Eq.", "dateLastCrawled": "2021-12-14T00:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "S2A: <b>Wasserstein</b> GAN <b>With Spatio-Spectral Laplacian Attention for Multi</b> ...", "url": "https://openaccess.thecvf.com/content_CVPRW_2020/papers/w11/Rout_S2A_Wasserstein_GAN_With_Spatio-Spectral_Laplacian_Attention_for_Multi-Spectral_Band_CVPRW_2020_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_CVPRW_2020/papers/w11/Rout_S2A_<b>Wasserstein</b>_GAN...", "snippet": "S2A: <b>Wasserstein</b> GAN <b>with Spatio-Spectral Laplacian Attention for Multi-Spectral</b> Band Synthesis Litu Rout Indranil Misra S Manthira Moorthi Debajyoti Dhar Signal and Image Processing Group Space Applications Centre Indian Space Research Organisation (lr, indranil, smmoorthi, deb)@sac.isro.gov.in Abstract Intersection of adversarial learning and satellite image processing is an emerging \ufb01eld in remote sensing. In this study, we intend to address synthesis of high resolution multi-spectral ...", "dateLastCrawled": "2022-01-31T11:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "NPG - Ensemble Riemannian data assimilation over the <b>Wasserstein</b> space", "url": "https://npg.copernicus.org/articles/28/295/2021/", "isFamilyFriendly": true, "displayUrl": "https://npg.copernicus.org/articles/28/295/2021", "snippet": "Abstract. In this paper, we present an ensemble data assimilation paradigm over a Riemannian manifold equipped with the <b>Wasserstein</b> metric. Unlike the Euclidean distance used in classic data assimilation methodologies, the <b>Wasserstein</b> metric <b>can</b> capture the translation and difference between the shapes of square-integrable probability distributions of the background state and observations. This enables us to formally penalize geophysical biases in state space with non-Gaussian distributions.", "dateLastCrawled": "2022-01-22T07:25:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to stabilize GAN training. Understand <b>Wasserstein</b> distance and ...", "url": "https://towardsdatascience.com/wasserstein-distance-gan-began-and-progressively-growing-gan-7e099f38da96", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>wasserstein</b>-distance-gan-began-and-progressively...", "snippet": "<b>Wasserstein</b> <b>loss</b> leads to a higher quality of the gradients to train G. ... Finally, one intuitive way to understand this paper is to make an <b>analogy</b> with the gradients on the history of in-layer activation functions. Specifically, the gradients of sigmoid and tanh activations that disappeared in favor of ReLUs, because of the improved gradients in the whole range of values. BEGAN (Boundary Equilibrium Generative Adversarial Networks 2017) We often see that the discriminator progresses too ...", "dateLastCrawled": "2022-01-25T18:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning Wasserstein Embeddings</b> | DeepAI", "url": "https://deepai.org/publication/learning-wasserstein-embeddings", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>learning-wasserstein-embeddings</b>", "snippet": "The <b>Wasserstein</b> distance received a lot of attention recently in the community of <b>machine</b> <b>learning</b>, especially for its principled way of comparing distributions. It has found numerous applications in several hard problems, such as domain adaptation, dimensionality reduction or generative models. However, its use is still limited by a heavy ...", "dateLastCrawled": "2022-01-05T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Learning</b> <b>Wasserstein</b> Embeddings - ResearchGate", "url": "https://www.researchgate.net/publication/320564581_Learning_Wasserstein_Embeddings", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320564581_<b>Learning</b>_<b>Wasserstein</b>_Embeddings", "snippet": "Designed through an <b>analogy</b> with ... Fast dictionary <b>learning</b> with a smoothed <b>wasserstein</b> <b>loss</b>. In AISTA TS, pages 630\u2013638, 2016. [32] F. Santambrogio. Introduction to optimal transport theory ...", "dateLastCrawled": "2021-12-13T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "deep <b>learning</b> - How can both generator and discriminator losses ...", "url": "https://datascience.stackexchange.com/questions/32699/how-can-both-generator-and-discriminator-losses-decrease", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/32699", "snippet": "In the widely used <b>analogy</b>: ... despite the WGAN having a different <b>loss</b> function, namely the <b>Wasserstein</b> distance, one should still not expect that the discriminator and generator simultaneously monotonically increase -- generally one of them &quot;wins&quot; the round and receives a lower portion of the <b>loss</b>. $\\endgroup$ \u2013 PSub. Mar 13 &#39;21 at 6:07 $\\begingroup$ @PSub You are completely misunderstanding the question. It&#39;s not a question about the small scale changes of the <b>loss</b> values. OP is asking ...", "dateLastCrawled": "2022-01-28T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding Generative Adversarial Networks (GANs) | by Joseph Rocca ...", "url": "https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-generative-adversarial-networks-<b>gan</b>s-cd6e...", "snippet": "in <b>machine</b> <b>learning</b>, the generative models try to generate data from a given (complex) probability distribution; deep <b>learning</b> generative models are modelled as neural networks (very complex functions) that take as input a simple random variable and that return a random variable that follows the targeted distribution (\u201ctransform method\u201d like) these generative networks can be trained \u201cdirectly\u201d (by comparing the distribution of generated data to the true distribution): this is the ...", "dateLastCrawled": "2022-02-03T05:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Tour of Generative Adversarial Network Models</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/tour-of-generative-adversarial-network-models/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>tour-of-generative-adversarial-network-models</b>", "snippet": "By <b>analogy</b> with auto-encoders, we propose Context Encoders \u2013 a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. \u2014 Context Encoders: Feature <b>Learning</b> by Inpainting, 2016. Example of the Context Encoders Encoder-Decoder Model Architecture. Taken from: Context Encoders: Feature <b>Learning</b> by Inpainting. The model is trained with a joint-<b>loss</b> that combines both the adversarial <b>loss</b> of generator and discriminator models ...", "dateLastCrawled": "2022-02-03T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Advanced <b>Machine</b> <b>Learning</b> - Computer Vision", "url": "https://www.vision.rwth-aachen.de/media/course/SS/2019/advanced-machine-learning/ml2_19-part17-gans-6on1.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.vision.rwth-aachen.de/media/course/SS/2019/advanced-<b>machine</b>-<b>learning</b>/ml2...", "snippet": "<b>Analogy</b>: police investigator \u2022Both generator and discriminator are deep networks We can train them with backprop. Image sources: www.bundesbank.de, weclipart.com, Kevin McGuiness 15 Advanced <b>Machine</b> <b>Learning</b> Part 17 \u2013Generative Adversarial Networks Training the Discriminator \u2022Procedure Fix generator weights Train discriminator to distinguish between real and generated images Image credit: Kevin McGuiness 16 Visual Computing Institute | Prof. Dr . Bastian Leibe Advanced <b>Machine</b> <b>Learning</b> ...", "dateLastCrawled": "2021-10-25T15:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[D] Is the <b>Wasserstein</b> distance really what we optimize in WGAN ...", "url": "https://www.reddit.com/r/MachineLearning/comments/ew2lzs/d_is_the_wasserstein_distance_really_what_we/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/ew2lzs/d_is_the_<b>wasserstein</b>_distance...", "snippet": "The &quot;genuine&quot; <b>Wasserstein</b> <b>loss</b> relies on optimal transport, a generalization of sorting to high-dimensional feature spaces. In a nutshell: OT relies on the matrix of distances between samples to define a &quot;least action&quot; matching between any two distributions. Now, unfortunately, in spaces of images, the L2 distance is (essentially) meaningless: natural images should not be compared with each other pixel-wise. As a consequence, the baseline <b>Wasserstein</b> distance between two batches of images is ...", "dateLastCrawled": "2021-09-30T11:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Dynamical machine learning volumetric reconstruction of</b> objects ...", "url": "https://www.nature.com/articles/s41377-021-00512-x", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41377-021-00512-x", "snippet": "I.K. and G.B. conceived the research and devised the dynamical <b>machine</b> <b>learning</b> concept; I.K. developed the <b>machine</b> <b>learning</b> algorithm and performed the simulations, the neural network training ...", "dateLastCrawled": "2022-02-02T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "SpringerLink - <b>Machine Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05924-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05924-1", "snippet": "for a given set \\({\\mathcal {F}}\\) of distributions, twice differentiable and convex <b>loss</b> \\(\\ell\\), and prediction \\(f_\\theta (x)\\).The set \\({\\mathcal {F}}\\) is the set of distributions on which one would like the estimator to achieve a guaranteed performance bound.. Causal inference can be seen to be a specific instance of distributional robustness, where we take \\({\\mathcal {F}}\\) to be the class of all distributions generated under do-interventions on the predictors X (Meinshausen 2018 ...", "dateLastCrawled": "2022-01-15T22:50:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(wasserstein loss)  is like +(cross-validation)", "+(wasserstein loss) is similar to +(cross-validation)", "+(wasserstein loss) can be thought of as +(cross-validation)", "+(wasserstein loss) can be compared to +(cross-validation)", "machine learning +(wasserstein loss AND analogy)", "machine learning +(\"wasserstein loss is like\")", "machine learning +(\"wasserstein loss is similar\")", "machine learning +(\"just as wasserstein loss\")", "machine learning +(\"wasserstein loss can be thought of as\")", "machine learning +(\"wasserstein loss can be compared to\")"]}