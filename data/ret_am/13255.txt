{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Regularization : What? Why? and How? (Part -1) | by Siddhant Rai ...", "url": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "isFamilyFriendly": true, "displayUrl": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "snippet": "The answer is two <b>convex</b> functions will always give a <b>convex</b> <b>function</b>, but a <b>convex</b> and non-<b>convex</b> together will give a non-<b>convex</b> one. But two non-<b>convex</b> might end up giving a <b>convex</b> surface ...", "dateLastCrawled": "2022-01-28T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Machine Learning Path (III). Linear Regression \u2014 Cost <b>Function</b> | by ...", "url": "https://medium.com/@maximilianhuang/machine-learning-cost-function-e0abba6180ee", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@maximilianhuang/machine-learning-cost-<b>function</b>-e0abba6180ee", "snippet": "Cost <b>function</b> is also a kind of <b>convex</b> <b>function</b>. The best <b>fit</b> of the hypothesis appears on the minimal global optimum of the <b>convex</b> . Solving the global optimum in the <b>convex</b> <b>function</b> is called ...", "dateLastCrawled": "2021-12-29T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Is the norm of a <b>convex</b> <b>function</b> <b>convex</b>? - <b>Mathematics Stack Exchange</b>", "url": "https://math.stackexchange.com/questions/1143285/is-the-norm-of-a-convex-function-convex", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/1143285/is-the-norm-of-a-<b>convex</b>-<b>function</b>-<b>convex</b>", "snippet": "No, not necessarily. Something that could occur is that part of your <b>convex</b> <b>function</b> lies under the x -axis, which is then mirrored in the x -axis by the norm. Take f ( x) = x 2 \u2212 10 for example. Share. Follow this answer to receive notifications. answered Feb 11 &#39;15 at 9:10.", "dateLastCrawled": "2022-01-26T01:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Shape Analysis &amp; Measurement - Purdue University", "url": "http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf", "isFamilyFriendly": true, "displayUrl": "www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf", "snippet": "to the area of a circle with the same <b>convex</b> perimeter: \u2013 This statistic equals 1 for a circular object and less than 1 for an object that departs from circularity, except that it is relatively insensitive to irregular boundaries. 2 4 roundness area <b>convex</b> perimeter \u03c0\u22c5 = 31 Circularity roundness=0.584 roundness=0.447. 32 Sphericity \u2022 Sphericity measures the degree to which an object approaches the shape of a \u201csphere\u201d. \u2013 For a circle, the value is the maximum of 1.0 sphericity ...", "dateLastCrawled": "2022-02-03T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "reference request - When is a min-max <b>function</b> <b>convex</b> - Mathematics ...", "url": "https://math.stackexchange.com/questions/3121791/when-is-a-min-max-function-convex", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/3121791/when-is-a-min-max-<b>function</b>-<b>convex</b>", "snippet": "1 Answer1. Show activity on this post. A sufficient condition is that g ( y, z) = max x \u2208 X L ( x, y, z) is <b>convex</b> (which requires Y and Z to be <b>convex</b>), since partial minimization of a <b>convex</b> <b>function</b> yields a <b>convex</b> <b>function</b>. A sufficient condition for g ( y, z) to be <b>convex</b> is if L ( x, y, z) is <b>convex</b> for each fixed x, since the maximum ...", "dateLastCrawled": "2022-01-25T10:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Proximal Gradient Descent</b> - Stanford Computer Science", "url": "https://cs.stanford.edu/~rpryzant/blog/prox/prox_grad_descent.html", "isFamilyFriendly": true, "displayUrl": "https://cs.stanford.edu/~rpryzant/blog/prox/prox_grad_descent.html", "snippet": "In <b>a perfect</b> world the <b>function</b> we are trying to optimize is <b>convex</b>, differentiable, and unconstrained. This means all we would need to do is basic <b>gradient descent</b>. In many real world applications, though, we don&#39;t have this luxury. A great example is the class of models with L1 regularization schemes <b>like</b> Lasso regression. This regularization method is an effective promoter of sparsity but it results in a loss <b>function</b> that is non-differentiable (aka it has kinks). This introduces a whole ...", "dateLastCrawled": "2022-02-03T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Basic Curve Fitting of Scientific Data with <b>Python</b> | by Naveen ...", "url": "https://towardsdatascience.com/basic-curve-fitting-of-scientific-data-with-python-9592244a2509", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/basic-curve-<b>fit</b>ting-of-scientific-data-with-<b>python</b>...", "snippet": "To use the curve_<b>fit</b> <b>function</b> we use the following import statement: # Import curve fitting package from scipy from scipy.optimize import curve_<b>fit</b>. I n this case, we are only using one specific <b>function</b> from the scipy package, so we can directly import just curve_<b>fit</b>. Exponential Fitting. Let\u2019s say we have a general exponential <b>function</b> of the following form, and we know this expression fits our data (where a and b are constants we will <b>fit</b>): General exponential <b>function</b>. First, we must ...", "dateLastCrawled": "2022-02-03T00:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "convexity - <b>Convex</b> vs <b>Strictly Quasiconvex Functions in Optimization</b> ...", "url": "https://or.stackexchange.com/questions/1470/convex-vs-strictly-quasiconvex-functions-in-optimization", "isFamilyFriendly": true, "displayUrl": "https://or.stackexchange.com/questions/1470", "snippet": "Many other <b>convex</b> problems that use well-known functions (<b>like</b> exponents, polynomials, and logarithms) are also polynomially solvable. Checking feasibility can be done by going over all individual constraints, and separating hyperplanes can be based on the gradients of the violated constraints. In practice, we have to take into account that software for more general problems is necessarily less specialized than the LP, SOCP, or SDP software, which may affect performance if you solve large ...", "dateLastCrawled": "2022-01-27T13:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "microeconomics - Relation between linear <b>utility</b> <b>function</b> and U=<b>max{x</b>,y ...", "url": "https://economics.stackexchange.com/questions/15766/relation-between-linear-utility-function-and-u-maxx-y", "isFamilyFriendly": true, "displayUrl": "https://economics.stackexchange.com/questions/15766/relation-between-linear-<b>utility</b>...", "snippet": "The reason is that U = <b>perfect</b>_subs is a (not-strictly) <b>convex</b> <b>utility</b> <b>function</b>, whereas U = <b>max</b> isn&#39;t. That is: the consumer is either indifferent between, or actually prefers, less extreme combinations to more extreme combinations for the former. As for the latter? Well, they just care about the <b>max</b>; they <b>like</b> extreme combinations (e.g, [C = m/p1, 0)]) That&#39;s why for U = <b>perfect</b>_subs with relative prices the same, both A = (100,0) and B = (\u00df(x1), (1-\u00df)x2) have the same <b>utility</b>. That is,B ...", "dateLastCrawled": "2022-01-27T03:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "optimization - Python - Optimizing a non-<b>convex</b> <b>function</b> that is ...", "url": "https://stackoverflow.com/questions/63593276/python-optimizing-a-non-convex-function-that-is-convex-when-adding-constrain", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/63593276/python-optimizing-a-non-<b>convex</b>-<b>function</b>...", "snippet": "Suppose I have an objective <b>function</b> f(x) that is non-<b>convex</b> (x can be a vector), but once I add constraints it becomes a <b>convex</b> problem. To show what i mean, consider this trivial example: let f(x) = cos(x). Clearly, cos(x) is not <b>convex</b>, but if i only consider x in [0, pi/2], then the <b>function</b> is <b>convex</b> when restricting x to these values.", "dateLastCrawled": "2022-01-26T05:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Regularization : What? Why? and How? (Part -1) | by Siddhant Rai ...", "url": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "isFamilyFriendly": true, "displayUrl": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "snippet": "The answer is two <b>convex</b> functions will always give a <b>convex</b> <b>function</b>, but a <b>convex</b> and non-<b>convex</b> together will give a non-<b>convex</b> one. But two non-<b>convex</b> might end up giving a <b>convex</b> surface ...", "dateLastCrawled": "2022-01-28T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Machine Learning Path (III). Linear Regression \u2014 Cost <b>Function</b> | by ...", "url": "https://medium.com/@maximilianhuang/machine-learning-cost-function-e0abba6180ee", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@maximilianhuang/machine-learning-cost-<b>function</b>-e0abba6180ee", "snippet": "Cost <b>function</b> is also a kind of <b>convex</b> <b>function</b>. The best <b>fit</b> of the hypothesis appears on the minimal global optimum of the <b>convex</b> . Solving the global optimum in the <b>convex</b> <b>function</b> is called ...", "dateLastCrawled": "2021-12-29T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Basic Curve Fitting of Scientific Data with <b>Python</b> | by Naveen ...", "url": "https://towardsdatascience.com/basic-curve-fitting-of-scientific-data-with-python-9592244a2509", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/basic-curve-<b>fit</b>ting-of-scientific-data-with-<b>python</b>...", "snippet": "Scatter plot of dummy power-law data with added Gaussian noise. <b>Similar</b> to the exponential fitting case, data in the form of a power-law <b>function</b> can be linearized by plotting on a logarithmic plot \u2014 this time, both the x and y-axes are scaled. # Set the x and y-axis scaling to logarithmic ax.set_xscale(&#39;log&#39;) ax.set_yscale(&#39;log&#39;) # Edit the major and minor tick locations of x and y axes ax.xaxis.set_major_locator(mpl.ticker.LogLocator(base=10.0)) ax.yaxis.set_major_locator(mpl.ticker ...", "dateLastCrawled": "2022-02-03T00:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Homework 1 Solutions</b>", "url": "https://www.cs.cmu.edu/~bapoczos/Classes/ML10715_2015Fall/assignments/hw1_sol.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~bapoczos/Classes/ML10715_2015Fall/assignments/hw1_sol.pdf", "snippet": "In gradient descent algorithm, convexity of the target <b>function</b> plays an important role in determining whether or not the algorithm will converge, the convergence rate and so on. We didn\u2019t cover too much about <b>convex</b> <b>function</b> in the class. So here we will go through some useful techniques for examining convexity of a <b>function</b>. 5", "dateLastCrawled": "2022-02-03T04:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "real analysis - A <b>function</b> is <b>convex</b> and concave, show that it has the ...", "url": "https://math.stackexchange.com/questions/1014813/a-function-is-convex-and-concave-show-that-it-has-the-form-fx-axb", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/1014813", "snippet": "<b>Mathematics Stack Exchange</b> is a question and answer site for people studying math at any level and professionals in related fields. It only takes a minute to sign up.", "dateLastCrawled": "2022-01-27T08:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Is the norm of a <b>convex</b> <b>function</b> <b>convex</b>? - <b>Mathematics Stack Exchange</b>", "url": "https://math.stackexchange.com/questions/1143285/is-the-norm-of-a-convex-function-convex", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/1143285/is-the-norm-of-a-<b>convex</b>-<b>function</b>-<b>convex</b>", "snippet": "No, not necessarily. Something that could occur is that part of your <b>convex</b> <b>function</b> lies under the x -axis, which is then mirrored in the x -axis by the norm. Take f ( x) = x 2 \u2212 10 for example. Share. Follow this answer to receive notifications. answered Feb 11 &#39;15 at 9:10.", "dateLastCrawled": "2022-01-26T01:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A test for linear versus <b>convex</b> regression <b>function</b> using shape ...", "url": "https://www.researchgate.net/publication/5207206_A_test_for_linear_versus_convex_regression_function_using_shape-restricted_regression", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/5207206_A_test_for_linear_versus_<b>convex</b>...", "snippet": "The shapereg <b>function</b> uses coneB to provide a least a least-squares estimator for a regression <b>function</b> with several choices of constraints including isotonic and <b>convex</b> regression <b>function</b>, as ...", "dateLastCrawled": "2021-12-16T10:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "python - B\u00e9zier curve fitting with SciPy - Stack Overflow", "url": "https://stackoverflow.com/questions/12643079/b%C3%A9zier-curve-fitting-with-scipy", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/12643079", "snippet": "My question <b>is similar</b> to this one: How can I <b>fit</b> a B\u00e9zier curve to a set of data?, except that they said they didn&#39;t want to use numpy. My preference would be to find what I need already implemented somewhere in scipy or numpy. Otherwise, I plan to implement the algorithm linked from one of the answers to that question, using numpy: An algorithm for automatically fitting digitized curves (pdf.page 622). Thank you for any suggestions! Edit: I understand that a cubic B\u00e9zier curve is not ...", "dateLastCrawled": "2022-01-27T15:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "microeconomics - Relation between linear <b>utility</b> <b>function</b> and U=<b>max{x</b>,y ...", "url": "https://economics.stackexchange.com/questions/15766/relation-between-linear-utility-function-and-u-maxx-y", "isFamilyFriendly": true, "displayUrl": "https://economics.stackexchange.com/questions/15766/relation-between-linear-<b>utility</b>...", "snippet": "The optimal choice set for a <b>max</b> <b>function</b> and a <b>perfect</b> substitutes <b>function</b> with equal relative prices share some solutions [i.e, boundary solutions], but in general, the indifference curves, and hence non-boundary solutions, are different. Main Idea. For both a <b>max</b>(x1 x2) and <b>perfect</b>_sub(x1 x2) <b>utility</b> <b>function</b>, the point, say, m/p1 (or m/p2) would maximize <b>utility</b>. So both <b>utility</b> functions share boundary solutions. But think about the IC of m/p1 for a perf_subs consumer and think about ...", "dateLastCrawled": "2022-01-27T03:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "neural network - <b>Sample</b> Importance (Training Weights) in Keras - Data ...", "url": "https://datascience.stackexchange.com/questions/31129/sample-importance-training-weights-in-keras", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/31129", "snippet": "This is a <b>similar</b> question xgboost: give more importance to recent samples but I would like an applicable answer to Keras . Penalizing neural networks for specific examples means give them a high probability to be included in the batches. there is no correspondence with XGboost here. side note: maybe you could try Training with a Curriculum. Gradually transforming the training task, from an easy one (maybe <b>convex</b>) where examples illustrate the simpler concepts, to the target one (with more ...", "dateLastCrawled": "2022-01-27T05:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Empirical Analysis, Evaluation, and Comparison of <b>Convex</b> Optimization ...", "url": "https://people.cs.vt.edu/tchlux/OptNotes/FinalProject/FinalPaper.txt.html", "isFamilyFriendly": true, "displayUrl": "https://people.cs.vt.edu/tchlux/OptNotes/FinalProject/FinalPaper.txt.html", "snippet": "For a strongly <b>convex</b> <b>function</b>, gradient descent <b>can</b> <b>be thought</b> of as a contraction over the gradient \\(\\nabla f\\), with the fixed-point \\(x^\\star\\) that satisfies \\(\\nabla f(x^\\star) = 0\\). Alternatively, gradient descent <b>can</b> <b>be thought</b> of as an iterative minimization of the original <b>function</b> \\(f\\) based on its first-order Taylor expansion: $$ f(x) \\approx f(x^{(k)}) + \\nabla f(x^{(k)})^T x $$ subject to the constraint that each iteration <b>can</b> only &quot;move&quot; a distance of \\(\\alpha^{(k)}/\\| f(x ...", "dateLastCrawled": "2021-12-16T02:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Can</b> it be proven that non-negative least squares is a perfectly <b>convex</b> ...", "url": "https://stats.stackexchange.com/questions/512158/can-it-be-proven-that-non-negative-least-squares-is-a-perfectly-convex-problem", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/512158/<b>can</b>-it-be-proven-that-non-negative...", "snippet": "<b>Can</b> it be proven that NNLS is a perfectly <b>convex</b> problem?. Myre writes in section 3 of his TNT-NN manuscript:. The NNLS objective <b>function</b> is a <b>convex</b> quadratic <b>function</b> with linear inequalities as constraints. The whole NNLS problem, therefore, is <b>convex</b> and any feasible solution <b>can</b> be found from another feasible point", "dateLastCrawled": "2022-01-13T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "real analysis - <b>Limit of a convex function</b> - <b>Mathematics Stack Exchange</b>", "url": "https://math.stackexchange.com/questions/3794828/limit-of-a-convex-function", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/3794828/<b>limit-of-a-convex-function</b>", "snippet": "Show activity on this post. I would need a check on the following exercise: Let f: R \u2192 R a <b>convex</b> <b>function</b>. Prove that lim x \u2192 \u221e f ( x) and lim x \u2192 \u2212 \u221e f ( x) exist. Show that if both the limits are finite, then f is constant. My attempt: i ) I know that if f is <b>convex</b>, then. f ( t x 1 + ( 1 \u2212 t) x 2) &lt; t f ( x 1) + ( 1 \u2212 t) f ...", "dateLastCrawled": "2022-01-25T14:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>probability of making a convex function from random sampling</b> ...", "url": "https://math.stackexchange.com/questions/2661320/probability-of-making-a-convex-function-from-random-sampling", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/2661320/<b>probability-of-making-a-convex</b>...", "snippet": "Then what is the probability I make a <b>convex</b> <b>function</b>? For this case, I would think we <b>can</b> make use of the idea of secant lines and how for a <b>convex</b> <b>function</b> they are above the graph. Or if you want for simplicity, to avoid some problems with creating graphs of functions, we <b>can</b> say the sampling procedure is simplified to sample exactly $1 ...", "dateLastCrawled": "2022-01-25T09:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "3. <b>Perfect</b> Separation is more likely with more dimensions - <b>Cross Validated</b>", "url": "https://stats.stackexchange.com/questions/469799/why-is-logistic-regression-particularly-prone-to-overfitting-in-high-dimensions", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/469799/why-is-logistic-regression...", "snippet": "Logistic regression is a <b>convex</b> optimization problem (the likelihood <b>function</b> is concave), and it&#39;s known to not have a finite solution when it <b>can</b> fully separate the data, so the loss <b>function</b> <b>can</b> only reach its lowest value asymptomatically as the weights tend to \u00b1 infinity. This has the effect of tightening decision boundaries around each data point when the data is separable, asymptotically overfitting on the training set.", "dateLastCrawled": "2022-01-24T09:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "microeconomics - Relation between linear <b>utility</b> <b>function</b> and U=<b>max{x</b>,y ...", "url": "https://economics.stackexchange.com/questions/15766/relation-between-linear-utility-function-and-u-maxx-y", "isFamilyFriendly": true, "displayUrl": "https://economics.stackexchange.com/questions/15766/relation-between-linear-<b>utility</b>...", "snippet": "The reason is that U = <b>perfect</b>_subs is a (not-strictly) <b>convex</b> <b>utility</b> <b>function</b>, whereas U = <b>max</b> isn&#39;t. That is: the consumer is either indifferent between, or actually prefers, less extreme combinations to more extreme combinations for the former. As for the latter? Well, they just care about the <b>max</b>; they like extreme combinations (e.g, [C = m/p1, 0)]) That&#39;s why for U = <b>perfect</b>_subs with relative prices the same, both A = (100,0) and B = (\u00df(x1), (1-\u00df)x2) have the same <b>utility</b>. That is,B ...", "dateLastCrawled": "2022-01-27T03:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>UML V: Convex Learning Problems</b> - LessWrong 2.0 viewer", "url": "https://www.greaterwrong.com/posts/FnFsLRj4Qybii22ae/uml-v-convex-learning-problems", "isFamilyFriendly": true, "displayUrl": "https://www.greaterwrong.com/posts/FnFsLRj4Qybii22ae/<b>uml-v-convex-learning-problems</b>", "snippet": "The main reason why convexity is a desirable property is that, for a <b>convex</b> <b>function</b>, ... (In that example, we <b>thought</b> of it as a set of functions, each of which fully determined by an element in [0, 1]; now we think of it as the set [0, 1] itself.) Each point-based loss <b>function</b> \u2113 (2) (x, y) is <b>convex</b> (and non-negative). However, for any number x \u2208 R +, the loss <b>function</b> \u2113 (2) (x, y) is defined by the rule \u2113 (2) (x, y) (\u03b1) = (\u03b1 \u22c5 x \u2212 y) 2, and the gradient of this <b>function</b> ...", "dateLastCrawled": "2021-12-21T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A test for linear versus <b>convex</b> regression <b>function</b> using shape ...", "url": "https://www.researchgate.net/publication/5207206_A_test_for_linear_versus_convex_regression_function_using_shape-restricted_regression", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/5207206_A_test_for_linear_versus_<b>convex</b>...", "snippet": "The shapereg <b>function</b> uses coneB to provide a least a least-squares estimator for a regression <b>function</b> with several choices of constraints including isotonic and <b>convex</b> regression <b>function</b>, as ...", "dateLastCrawled": "2021-12-16T10:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "CS 194-10, Fall 2011 Assignment 2 Solutions", "url": "https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/assignments/a2/a2-solution.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/assignments/a2/a2-solution.pdf", "snippet": "2 =0 axes in the original space\u2014this <b>can</b> <b>be thought</b> of as the limit of a hyperbolic separator with two branches. (b) Recall that the equation of the circle in the 2-dimensional plane is (x 1 \u2212a)2 +(x 2 \u2212b)2 \u2212r2 = 0. Expand out the formula and show that every circular region is linearly separable from the rest of the plane in the feature space (x 1,x 2,x2,x2 2). The circle equation expands into \ufb01ve terms 0 = x2 1+x 2 2 \u22122ax \u22122bx 2 +(a2 +b2 \u2212r2) corresponding to weights w = (2a ...", "dateLastCrawled": "2022-01-29T07:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why do we try to maximize Lagrangian in SVMs? - Computer Science Stack ...", "url": "https://cs.stackexchange.com/questions/77368/why-do-we-try-to-maximize-lagrangian-in-svms", "isFamilyFriendly": true, "displayUrl": "https://cs.stackexchange.com/questions/77368/why-do-we-try-to-maximize-lagrangian-in-svms", "snippet": "The maximization must be done here, but of the <b>function</b> \u0398 ( \u03b1) (the Lagrangian dual <b>function</b>). Here is some background on why we are maximizing: 1) Let p \u2217 be the optimal value of the problem of minimizing 1 2 \u2016 w \u2016 2 (the primal). The Lagrangian dual <b>function</b> has the property that L ( w, b, \u03b1) \u2264 p \u2217.", "dateLastCrawled": "2022-01-26T17:50:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Lecture 8: Regression", "url": "https://shuaili8.github.io/Teaching/CS410/L8_regression.pdf", "isFamilyFriendly": true, "displayUrl": "https://shuaili8.github.io/Teaching/CS410/L8_regression.pdf", "snippet": "\u2022Note that (\ud835\udf03)is a <b>convex</b> <b>function</b> in \ud835\udf03, so it has a unique minimal point 10. Interpretation Figure credit: Kevin Murphy 11. <b>Convex</b> set 12. <b>Convex</b> <b>function</b> 13 (\ud835\udf03)is <b>convex</b> \u2022 T=( U\u2212 T)2=( T\u2212 U)2is <b>convex</b> in T \u2022 \ud835\udf03= \ud835\udf03\u22a4 T 1\u2212 P\ud835\udf031+ P\ud835\udf032 = 1\u2212 P\ud835\udf031 \u22a4 T+ P\ud835\udf03 2 \u22a4 T \u22641\u2212 P \ud835\udf031 \u22a4 T+ \ud835\udf03 2 \u22a4 T =1\u2212 P \ud835\udf031 + (\ud835\udf032) \u2022The sum of <b>convex</b> functions is <b>convex</b> \u2022Thus (\ud835\udf03)is <b>convex</b> Check it by yourself ! Convexity of f 14. Minimal point (Normal ...", "dateLastCrawled": "2022-01-03T13:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "3. <b>Perfect</b> Separation is more likely with more dimensions - <b>Cross Validated</b>", "url": "https://stats.stackexchange.com/questions/469799/why-is-logistic-regression-particularly-prone-to-overfitting-in-high-dimensions", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/469799/why-is-logistic-regression...", "snippet": "Logistic regression is a <b>convex</b> optimization problem (the likelihood <b>function</b> is concave), and it&#39;s known to not have a finite solution when it <b>can</b> fully separate the data, so the loss <b>function</b> <b>can</b> only reach its lowest value asymptomatically as the weights tend to \u00b1 infinity. This has the effect of tightening decision boundaries around each data point when the data is separable, asymptotically overfitting on the training set.", "dateLastCrawled": "2022-01-24T09:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A test for linear versus <b>convex</b> regression <b>function</b> using shape ...", "url": "https://www.researchgate.net/publication/5207206_A_test_for_linear_versus_convex_regression_function_using_shape-restricted_regression", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/5207206_A_test_for_linear_versus_<b>convex</b>...", "snippet": "Likelihood ratio tests of constant vs. monotone regression <b>function</b>, as well as linear vs. <b>convex</b> regression <b>function</b> and other tests with shape-restricted alternatives, are known to have null ...", "dateLastCrawled": "2021-12-16T10:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "From <b>Convex</b> to Nonconvex: A Loss <b>Function</b> Analysis for Binary ...", "url": "https://www.researchgate.net/publication/220765404_From_Convex_to_Nonconvex_A_Loss_Function_Analysis_for_Binary_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220765404_From_<b>Convex</b>_to_Non<b>convex</b>_A_Loss...", "snippet": "The predictions are <b>compared</b> with an alternative <b>convex</b> fitting <b>function</b>, and a strong correlation is observed. The dependence of these results on the patients randomly selected for training and ...", "dateLastCrawled": "2021-12-10T05:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Shape Analysis &amp; Measurement - Purdue University", "url": "http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf", "isFamilyFriendly": true, "displayUrl": "www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf", "snippet": "object differs from a <b>convex</b> object. \u2013 A measure of convexity <b>can</b> be obtained by forming the ratio of the perimeter of an object\u2019s <b>convex</b> hull to the perimeter of the object itself: <b>convex</b> perimeter convexity perimeter = 34 Convexity \u2013 This will take the value of 1 for a <b>convex</b> object, and will be less than 1 if the object is not <b>convex</b>, such as one having an irregular boundary. convexity=1.0 convexity=0.483 convexity=0.349. 35 Aspect Ratio \u2022 The aspect ratio measures the ratio of ...", "dateLastCrawled": "2022-02-03T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Definition of stationary points for <b>convex</b> optimization - Mathematics ...", "url": "https://math.stackexchange.com/questions/2667568/definition-of-stationary-points-for-convex-optimization", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/.../definition-of-stationary-points-for-<b>convex</b>-optimization", "snippet": "Considering the following constrained optimization problem: Where f is a continuously differentiable <b>function</b> defined over the closed and <b>convex</b> set C \u2282 R n. Let f be a continuously differentiable <b>function</b> over closed set C . Then x \u2217 \u2208 C is called a <b>stationary point</b> of the minimization problem (P) if \u2207 f ( x \u2217) T ( x \u2212 x \u2217) \u2265 0 ...", "dateLastCrawled": "2022-01-27T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Estimation of low-rank tensors via <b>convex</b> optimization | DeepAI", "url": "https://deepai.org/publication/estimation-of-low-rank-tensors-via-convex-optimization", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/estimation-of-low-rank-tensors-via-<b>convex</b>-optimization", "snippet": "In addition, there are theoretical developments that (under some conditions) guarantee <b>perfect</b> reconstruction of a low-rank matrix from partial measurements via <b>convex</b> estimation [10, 32]. The key idea here is to replace the rank of a matrix (a non-<b>convex</b> <b>function</b>) by the so-called trace norm (also known as the nuclear norm) of the matrix. One goal of this paper is to extend the trace-norm regularization for more than two dimensions. There have recently been related work by Liu et al.", "dateLastCrawled": "2021-12-25T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Popular Optimization Algorithms in Machine Learning \u2014 A brief ...", "url": "https://medium.com/@aruncjohn/optimizers-in-machine-learning-a3e40a83686d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@aruncjohn/optimizers-in-machine-learning-a3e40a83686d", "snippet": "Let the regression <b>function</b> be a simple linear regression that <b>can</b> be expressed as y = w*X + b, where w and b are the respective weights and bias terms. w will be vectorized most times.", "dateLastCrawled": "2021-12-22T04:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Finding a global minimum of a smooth, bounded, non-<b>convex</b> 2D <b>function</b> ...", "url": "https://scicomp.stackexchange.com/questions/2249/finding-a-global-minimum-of-a-smooth-bounded-non-convex-2d-function-that-is-co", "isFamilyFriendly": true, "displayUrl": "https://scicomp.stackexchange.com/questions/2249/finding-a-global-minimum-of-a-smooth...", "snippet": "Since the <b>function</b> is not <b>convex</b> you will have to apply the usual tricks to make Newton&#39;s method converge (Levenberg-Marquardt modification, line search or trust region to globalize). If you <b>can</b>&#39;t get derivatives of your <b>function</b> try either computing it via finite differences or using a BFGS update. If you suspect that the problem has more than one local minimum, one would simply start Newton&#39;s method from a bunch of randomly or not quite so randomly chosen points and see where they converge.", "dateLastCrawled": "2022-01-27T10:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Is square root convex</b>? - Quora", "url": "https://www.quora.com/Is-square-root-convex", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Is-square-root-convex</b>", "snippet": "Answer (1 of 4): No, in the usual use of &quot;<b>convex</b>&quot; for functions, it&#39;s not. <b>Convex</b> for functions means that the line segment connecting any two points on the graph of the <b>function</b> lies above the graph. The reverse is true for concave, which is what the square root <b>function</b> is. The second derivat...", "dateLastCrawled": "2022-01-28T17:26:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "11.2. <b>Convexity</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_optimization/convexity.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_optimization/<b>convexity</b>.html", "snippet": "A twice-differentiable <b>function</b> is <b>convex</b> if and only if its Hessian (a matrix of second derivatives) is positive semidefinite. <b>Convex</b> constraints can be added via the Lagrangian. In practice we may simply add them with a penalty to the objective <b>function</b>. Projections map to points in the <b>convex</b> set closest to the original points.", "dateLastCrawled": "2022-01-30T21:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning</b> Paradigms in <b>Machine Learning</b> | by Dhairya Parikh ...", "url": "https://medium.datadriveninvestor.com/learning-paradigms-in-machine-learning-146ebf8b5943", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/<b>learning</b>-paradigms-in-<b>machine-learning</b>-146ebf8b5943", "snippet": "What the computer does is that it generates a <b>function</b> based on this data, which can be anything like a simple line, to a complex <b>convex</b> <b>function</b>, depending on the data provided. This is the most basic type of <b>learning</b> paradigm, and most algorithms we learn today are based on this type of <b>learning</b> pattern.", "dateLastCrawled": "2022-01-28T18:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "<b>Machine</b> <b>learning</b> terminology for model building and validation There seems to be an <b>analogy</b> between statistical modeling and <b>machine</b> <b>learning</b> that we will cover in subsequent chapters in depth. However, a quick view has been provided as follows: in statistical modeling, linear regression with two independent variables is trying to fit the best plane with\u2026", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Gradient</b> Descent: A Quick, Simple Introduction | Built In", "url": "https://builtin.com/data-science/gradient-descent", "isFamilyFriendly": true, "displayUrl": "https://builtin.com/data-science/<b>gradient</b>-descent", "snippet": "<b>Gradient</b> descent is an optimization algorithm that&#39;s used when training a <b>machine</b> <b>learning</b> model. It&#39;s based on a <b>convex</b> <b>function</b> and tweaks its parameters iteratively to minimize a given <b>function</b> to its local minimum.", "dateLastCrawled": "2022-02-02T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Introduction to <b>Machine</b> <b>Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-machine-learning-3/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-<b>machine</b>-<b>learning</b>-3", "snippet": "The loss <b>function</b> or cost <b>function</b> in <b>machine</b> <b>learning</b> is a <b>function</b> that maps the values of variables onto a real number intuitively representing some cost associated with the variable values. Optimization methods are applied to minimize the loss <b>function</b> by changing the parameter values, which is the central theme of <b>machine</b> <b>learning</b>.", "dateLastCrawled": "2022-01-28T18:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "Probability Estimation: when the output of the <b>function</b> is a probability. <b>Machine Learning</b> in Practice. <b>Machine learning</b> algorithms are only a very small part of using <b>machine learning</b> in practice as a data analyst or data scientist. In practice, the process often looks like: Start Loop Understand the domain, prior knowledge and goals. Talk to ...", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - How does Gradient Descent work? - Data Science Stack ...", "url": "https://datascience.stackexchange.com/questions/102509/how-does-gradient-descent-work", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/102509/how-does-gradient-descent-work", "snippet": "If the <b>function</b> we minimize was <b>convex</b>, it would not matter what we choose for initial values, as gradient descent would get us to the minimum no matter what. But as the dimensions of the model increase, it is extremely unlikely that we have a <b>convex</b> loss <b>function</b>. And in this case, initialization of the weight depends on the activation functions used in the model. As discussed in", "dateLastCrawled": "2022-01-16T12:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Regularization : What? Why? and How? (Part -1) | by Siddhant Rai ...", "url": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "isFamilyFriendly": true, "displayUrl": "https://medium.com/m<b>learning</b>-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "snippet": "In general <b>machine</b> <b>learning</b> sense, it is solving an objective <b>function</b> to perform maximum or minimum evaluation. In reality, optimization is lot more profound in usage. Then we have two terms ...", "dateLastCrawled": "2022-01-28T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - Cost <b>function</b> of neural network is non-<b>convex</b> ...", "url": "https://stats.stackexchange.com/questions/106334/cost-function-of-neural-network-is-non-convex", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/106334", "snippet": "$\\begingroup$ I mean, this is how it should be interpreted, not just an <b>analogy</b>. $\\endgroup$ \u2013 avocado. May 23 &#39;16 at 12:27 . 5 $\\begingroup$ @loganecolss You are correct that this is not the only reason why cost functions are non-<b>convex</b>, but one of the most obvious reasons. Depdending on the network and the training set, there might be other reasons why there are multiple minima. But the bottom line is: The permuation alone creates non-convexity, regardless of other effects. $\\endgroup ...", "dateLastCrawled": "2022-02-03T01:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to use Jax <b>to streamline machine learning optimization</b> | by Sam ...", "url": "https://medium.com/utility-machine-learning/using-jax-to-streamline-machine-learning-optimization-d0da2f53a9fb", "isFamilyFriendly": true, "displayUrl": "https://medium.com/utility-<b>machine</b>-<b>learning</b>/using-jax-to-streamline-<b>machine</b>-<b>learning</b>...", "snippet": "In this <b>analogy</b>, the person\u2019s elevation corresponds to the loss <b>function</b> they want to minimize, and the x and y coordinates of the direction they walk in represent the two parameters of this ...", "dateLastCrawled": "2021-09-30T11:29:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(convex function)  is like +(a perfect fit)", "+(convex function) is similar to +(a perfect fit)", "+(convex function) can be thought of as +(a perfect fit)", "+(convex function) can be compared to +(a perfect fit)", "machine learning +(convex function AND analogy)", "machine learning +(\"convex function is like\")", "machine learning +(\"convex function is similar\")", "machine learning +(\"just as convex function\")", "machine learning +(\"convex function can be thought of as\")", "machine learning +(\"convex function can be compared to\")"]}