{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How Reliable Is <b>Inter-Rater</b> Reliability? | Psychreg", "url": "https://www.psychreg.org/how-reliable-inter-rater-reliability/", "isFamilyFriendly": true, "displayUrl": "https://www.psychreg.org/how-reliable-<b>inter-rater</b>-reliability", "snippet": "<b>Inter-rater</b> unreliability seems built-in and inherent in any subjective evaluation. Even when the rating appears to be 100% \u2018right\u2019, it may be 100% \u2018wrong\u2019. If <b>inter-rater</b> reliability is high, it may be because we have asked the wrong question, or based the questions on a flawed construct. If <b>inter-rater</b> reliability is low, it may be ...", "dateLastCrawled": "2022-01-29T01:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Overview of Psychological Testing - Psychological Testing in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK305233/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK305233", "snippet": "<b>Inter-rater</b>: Consistency of test scores among independent judges; 3. Parallel or alternate forms: Consistency of scores across different forms of the test (stability and equivalence); and. 4. Internal consistency: Consistency of different items intended to measure the same thing within the test (homogeneity). A special case of internal consistency reliability is split-half where scores on two halves of a single test are compared and this comparison may be converted into an index of ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>agreement</b> statistics - Handling poor <b>inter-rater</b> reliability while ...", "url": "https://stats.stackexchange.com/questions/47864/handling-poor-inter-rater-reliability-while-minimizing-the-loss-of-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/47864/handling-poor-<b>inter-rater</b>-reliability...", "snippet": "Edit: For the purposes of building a tractable model, I am willing to assume that the inconsistencies arise &quot;randomly&quot;, e.g. due to randomly mis-<b>reading</b> the question or mis-clicking an answer on a tablet/computer, so that the errors could be conceived of as independent of any auxiliary variables, in contrast to the example given by @whuber in the comments.", "dateLastCrawled": "2022-01-20T13:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Intro to IO Psychology: Final Exam</b> Flashcards - Cram.com", "url": "https://www.cram.com/flashcards/intro-to-io-psychology-final-exam-2013706", "isFamilyFriendly": true, "displayUrl": "https://www.cram.com/flashcards/<b>intro-to-io-psychology-final-exam</b>-2013706", "snippet": "<b>Inter-rater</b> <b>agreement</b> (whether or not different job analysts agree in their ratings) was somewhat lower, depending upon the types of raters (e.g., analysts vs. SMEs) and the dimensions being rated. Correlations among ratings by different people ranged from .48 to .81. Wilson, Harvey, and Macy (1990) found that test-retest reliabilities varied considerably for different rating scales, while some reliabilities were very high, others were unacceptably low. Sanchez and Fraser (1992) found that ...", "dateLastCrawled": "2022-01-19T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Testing and Assessment - Reliability and Validity", "url": "https://www.hr-guide.com/Testing_and_Assessment/Reliability_and_Validity.htm", "isFamilyFriendly": true, "displayUrl": "https://www.hr-guide.com/Testing_and_Assessment/Reliability_and_Validity.htm", "snippet": "<b>Inter-rater</b> reliability indicates how consistent test scores are likely to be if the test is scored by two or more raters. On some tests, raters evaluate responses to questions and determine the score. Differences in judgments among raters are likely to produce variations in test scores. A high <b>inter-rater</b> reliability coefficient indicates that the judgment process is stable and the resulting scores are reliable. <b>Inter-rater</b> reliability coefficients are typically lower than other types of ...", "dateLastCrawled": "2022-02-02T22:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Achievement Test~ Characteristics and Construction Procedure | Dr. V.K ...", "url": "http://www.vkmaheshwari.com/WP/?p=181", "isFamilyFriendly": true, "displayUrl": "www.vkmaheshwari.com/WP/?p=181", "snippet": "\u2022 <b>Inter-rater</b> reliability: <b>inter-rater</b> reliability, <b>inter-rater</b> <b>agreement</b>, or concordance is the degree of <b>agreement</b> among raters. This type of reliability is assessed by having two or more independent judges score the test. The scores are then compared to determine the consistency of the raters estimates. One way to test <b>inter-rater</b> reliability is to have each rater assign each test item a score. For example, each rater might score items on a scale from 1 to 10. Next, you would calculate ...", "dateLastCrawled": "2022-01-27T15:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Brief Report Let me <b>read your mind: Personality judgments based on</b> a ...", "url": "https://www.researchgate.net/publication/237295549_Brief_Report_Let_me_read_your_mind_Personality_judgments_based_on_a_person's_natural_stream_of_thought", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/237295549_Brief_Report_Let_me_read_your_<b>mind</b>...", "snippet": "Indeed, a growing literature has demonstrated that observers who are otherwise unfamiliar with targets tend to demonstrate consensus (i.e., <b>inter-rater</b> <b>agreement</b>) in their perceptions of targets ...", "dateLastCrawled": "2022-01-11T08:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Would You Interview This Candidate</b>? | SmartRecruiters", "url": "https://www.smartrecruiters.com/blog/would-you-interview-this-candidate/", "isFamilyFriendly": true, "displayUrl": "https://www.smartrecruiters.com/blog/<b>would-you-interview-this-candidate</b>", "snippet": "The test I used to gauge <b>inter-rater</b> <b>agreement</b> is called Fleiss\u2019 kappa. The result is on the following scale of -1 to 1:-1 perfect disagreement; no rater agrees with any other; 0 random; the raters might as well have been flipping a coin; 1 perfect <b>agreement</b>; the raters all agree with one another", "dateLastCrawled": "2021-12-28T18:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Callous\u2010unemotional</b> traits and impulsivity: distinct longitudinal ...", "url": "https://acamh.onlinelibrary.wiley.com/doi/full/10.1111/jcpp.12445", "isFamilyFriendly": true, "displayUrl": "https://acamh.onlinelibrary.wiley.com/doi/full/10.1111/jcpp.12445", "snippet": "<b>Inter-rater</b> <b>agreement</b> was \u03ba = .70 (87% <b>agreement</b>). Maternal sensitivity. Ainsworth et al.&#39;s ... Neither researcher was involved coding <b>mind</b>-mindedness. <b>Inter-rater</b> reliability (intraclass correlation) was .83. Theory of <b>mind</b>. At Phase 2 (51 months), children completed a battery of ToM tasks based on Wellman and Liu : (a) diverse beliefs, (b) the relation between knowledge and access to information, (c) the relation between the appearance of a container and one&#39;s belief about its contents ...", "dateLastCrawled": "2021-12-01T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Chapter 10 Performance Management</b> - SlideShare", "url": "https://www.slideshare.net/Wisnudewobroto/chapter-10-performance-management", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/Wisnudewobroto/<b>chapter-10-performance-management</b>", "snippet": "Fundamentals of Human Resource Management, 10/e, DeCenzo/Robbins Chapter 10, slide 23 Factors That Can Distort Appraisals \u00d8use behavior-based measures, which are more job-related and elicit more <b>inter-rater</b> <b>agreement</b> than traits such as \u201cloyalty\u201d or \u201cfriendliness\u201d \u00d8 combine absolute and relative standards: absolute standards tend to be positively lenient; relative standards suffer when there is little variability \u00d8 provide ongoing feedback: expectations and disappointments should ...", "dateLastCrawled": "2022-02-01T07:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Overview of Psychological Testing - Psychological Testing in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK305233/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK305233", "snippet": "<b>Inter-rater</b>: Consistency of test scores among independent ... , evidence that scores on a test correlate relatively highly with scores on theoretically <b>similar</b> measures and relatively poorly with scores on theoretically dissimilar measures); 2. Content evidence of validity: The degree to which the test content represents the targeted subject matter and supports a test&#39;s use for its intended purposes; and. 3. Criterion-related evidence of validity: The degree to which the test&#39;s score ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Brief Report Let me <b>read your mind: Personality judgments based on</b> a ...", "url": "https://www.researchgate.net/publication/237295549_Brief_Report_Let_me_read_your_mind_Personality_judgments_based_on_a_person's_natural_stream_of_thought", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/237295549_Brief_Report_Let_me_read_your_<b>mind</b>...", "snippet": "Along <b>similar</b> lines, ... (i.e., <b>inter-rater</b> <b>agreement</b>) in their perceptions of targets&#39; traits on the basis of exposure to even minimal qualitative material. In addition, these observers ...", "dateLastCrawled": "2022-01-11T08:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Developing, evaluating, and refining an automatic generator of ...", "url": "https://www.cambridge.org/core/journals/natural-language-engineering/article/developing-evaluating-and-refining-an-automatic-generator-of-diagnostic-multiple-choice-cloze-questions-to-assess-childrens-comprehension-while-reading/8EAE0707139D12EB3D4E3EE6AE072AAA", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/natural-language-engineering/article/developing...", "snippet": "2.2 <b>Inter-rater</b> <b>agreement</b>. It is important to measure <b>inter-rater</b> reliability among human judges, especially on experimenter-designed measures such as the form we used. We used two <b>inter-rater</b> reliability metrics for measuring <b>inter-rater</b> <b>agreement</b> among more than two judges, Kendall&#39;s Coefficient of Concordance (Kendall and Smith Reference Kendall and Babington Smith 1939) and Fleiss\u2019 Kappa (Shrout and Fleiss Reference Shrout and Fleiss 1979). Fleiss\u2019 Kappa is a statistical measure of ...", "dateLastCrawled": "2021-12-24T21:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Achievement Test~ Characteristics and Construction Procedure | Dr. V.K ...", "url": "http://www.vkmaheshwari.com/WP/?p=181", "isFamilyFriendly": true, "displayUrl": "www.vkmaheshwari.com/WP/?p=181", "snippet": "\u2022 <b>Inter-rater</b> reliability: <b>inter-rater</b> reliability, <b>inter-rater</b> <b>agreement</b>, or concordance is the degree of <b>agreement</b> among raters. This type of reliability is assessed by having two or more independent judges score the test. The scores are then compared to determine the consistency of the raters estimates. One way to test <b>inter-rater</b> reliability is to have each rater assign each test item a score. For example, each rater might score items on a scale from 1 to 10. Next, you would calculate ...", "dateLastCrawled": "2022-01-27T15:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>agreement</b> statistics - Handling poor <b>inter-rater</b> reliability while ...", "url": "https://stats.stackexchange.com/questions/47864/handling-poor-inter-rater-reliability-while-minimizing-the-loss-of-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/47864/handling-poor-<b>inter-rater</b>-reliability...", "snippet": "Edit: For the purposes of building a tractable model, I am willing to assume that the inconsistencies arise &quot;randomly&quot;, e.g. due to randomly mis-<b>reading</b> the question or mis-clicking an answer on a tablet/computer, so that the errors could be conceived of as independent of any auxiliary variables, in contrast to the example given by @whuber in the comments.", "dateLastCrawled": "2022-01-20T13:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Callous\u2010unemotional</b> traits and impulsivity: distinct longitudinal ...", "url": "https://acamh.onlinelibrary.wiley.com/doi/full/10.1111/jcpp.12445", "isFamilyFriendly": true, "displayUrl": "https://acamh.onlinelibrary.wiley.com/doi/full/10.1111/jcpp.12445", "snippet": "<b>Inter-rater</b> <b>agreement</b> was \u03ba = .70 (87% <b>agreement</b>). Maternal sensitivity. Ainsworth et al.&#39;s ... Neither researcher was involved coding <b>mind</b>-mindedness. <b>Inter-rater</b> reliability (intraclass correlation) was .83. Theory of <b>mind</b>. At Phase 2 (51 months), children completed a battery of ToM tasks based on Wellman and Liu : (a) diverse beliefs, (b) the relation between knowledge and access to information, (c) the relation between the appearance of a container and one&#39;s belief about its contents ...", "dateLastCrawled": "2021-12-01T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Testing and Assessment - Reliability and Validity", "url": "https://www.hr-guide.com/Testing_and_Assessment/Reliability_and_Validity.htm", "isFamilyFriendly": true, "displayUrl": "https://www.hr-guide.com/Testing_and_Assessment/Reliability_and_Validity.htm", "snippet": "<b>Inter-rater</b> reliability indicates how consistent test scores are likely to be if ... the test may not be valid for different purposes. For example, the test you use to make valid predictions about <b>someone&#39;s</b> technical proficiency on the job may not be valid for predicting his or her leadership skills or absenteeism rate. This leads to the next principle of assessment. Similarly, a test&#39;s validity is established in reference to specific groups. These groups are called the reference groups. The ...", "dateLastCrawled": "2022-02-02T22:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "8/31 \u2013 <b>Sentence completion assessments for ego development, meaning</b> ...", "url": "http://integralleadershipreview.com/15642-sentence-completion-assessments-for-ego-development-meaning-making-and-wisdom-maturity-including-stages-overview-and-summary-this-article-began-as-a-series-of-short-white-papers-providing-various/", "isFamilyFriendly": true, "displayUrl": "integralleadershipreview.com/15642-<b>sentence-completion-assessments-for-ego-development</b>...", "snippet": "<b>Inter-rater</b> reliability. Analyzing text or other qualitative data to derive a categorization or quantitative score is complex and uncertain business, usually requiring human judgment. Researchers compensate for the variability and subjectivity of human scoring by using multiple raters and measuring their <b>agreement</b>. A method is more objective and valid if raters tend to come to the same conclusion, and is less valid and too subjective if raters come to different conclusions. In the WUSCT ...", "dateLastCrawled": "2022-01-30T06:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Callous-Unemotional <b>Traits and Impulsivity:Distinct Longitudinal</b> ...", "url": "https://www.researchgate.net/publication/280124836_Callous-Unemotional_Traits_and_ImpulsivityDistinct_Longitudinal_Relations_With_Mind-Mindedness_and_Understanding_of_Others", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/280124836", "snippet": "<b>Inter-rater</b> <b>agreement</b> ... coding <b>mind</b>-mindedness. <b>Inter-rater</b> reliability (intraclass . correlation) was .83. Theory of <b>mind</b>. At Phase 2 (51 months), children com-pleted a battery of ToM tasks ...", "dateLastCrawled": "2021-10-18T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Is matching people to DSM-V descriptions considered &#39;hard science&#39;? Is ...", "url": "https://www.quora.com/Is-matching-people-to-DSM-V-descriptions-considered-hard-science-Is-one-right-about-something-simply-because-they-associate-it-with-the-word-science", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-matching-people-to-DSM-V-descriptions-considered-hard-science...", "snippet": "Answer (1 of 8): I think that what your question is really trying to ask is if using the DSM-V is equivalent to medical testing, which is completely objective. The simple answer is no, it is not. In medical testing, there are completely objective tests such as respiration rates, pulse, oximetry, ...", "dateLastCrawled": "2022-01-19T00:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How Reliable Is <b>Inter-Rater</b> Reliability? | Psychreg", "url": "https://www.psychreg.org/how-reliable-inter-rater-reliability/", "isFamilyFriendly": true, "displayUrl": "https://www.psychreg.org/how-reliable-<b>inter-rater</b>-reliability", "snippet": "That is, high <b>inter-rater</b> reliability <b>can</b> demonstrate, red flag, that there are much, much more serious problems afoot. When is the method of rating used? Usually when objective facts and scientifically robust measures cannot be used, or are not available. When the matter being rated is subjective; a matter of opinion. Ratings are also used when it is not time or cost-effective to conduct objective or scientific assessment. Where there is room for opinion, there is near certainty of ...", "dateLastCrawled": "2022-01-29T01:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Psychometric Properties of the Theory of <b>Mind</b> Assessment Scale in a ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860419/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4860419", "snippet": "Overall, the <b>inter-rater</b> <b>agreement</b> was acceptable (Table (Table2). 2). In particular, scale A (first-person ToM: I\u2013Me) and scale D (second-order ToM: Other\u2013Me) displayed fair reliability (0.59 and 0.49 respectively) whereas scales B and C, respectively investigating allocentric third-person ToM (Other\u2013Self) and egocentric third-person ToM (I\u2013Other), showed moderate reliability (0.65 and 0.71, respectively). All the four scales provided good results for internal consistency. Cronbach ...", "dateLastCrawled": "2021-12-10T05:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>agreement</b> statistics - Handling poor <b>inter-rater</b> reliability while ...", "url": "https://stats.stackexchange.com/questions/47864/handling-poor-inter-rater-reliability-while-minimizing-the-loss-of-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/47864/handling-poor-<b>inter-rater</b>-reliability...", "snippet": "Edit: For the purposes of building a tractable model, I am willing to assume that the inconsistencies arise &quot;randomly&quot;, e.g. due to randomly mis-<b>reading</b> the question or mis-clicking an answer on a tablet/computer, so that the errors could be conceived of as independent of any auxiliary variables, in contrast to the example given by @whuber in the comments.", "dateLastCrawled": "2022-01-20T13:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Overview of Psychological Testing - Psychological Testing in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK305233/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK305233", "snippet": "<b>Inter-rater</b>: Consistency of test scores among independent judges; 3. Parallel or alternate forms: Consistency of scores across different forms of the test (stability and equivalence); and. 4. Internal consistency: Consistency of different items intended to measure the same thing within the test (homogeneity). A special case of internal consistency reliability is split-half where scores on two halves of a single test are compared and this comparison may be converted into an index of ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Frontiers | <b>Psychometric Properties of the Theory</b> of <b>Mind</b> Assessment ...", "url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00566/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00566", "snippet": "Th.o.m.a.s. scores show good <b>inter-rater</b> <b>agreement</b> and internal consistency; the scores increase with age. Evidence of criterion validity was found as Scale B scores were correlated with those of an independent instrument for the evaluation of ToM, the Strange Stories task. Confirmatory factor analysis showed good fit of the 4-factors theoretical model to the data, although the 4 factors were highly correlated. For each of the four scales, Rasch analyses showed that, with few exceptions ...", "dateLastCrawled": "2022-01-29T17:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Achievement Test~ Characteristics and Construction Procedure | Dr. V.K ...", "url": "http://www.vkmaheshwari.com/WP/?p=181", "isFamilyFriendly": true, "displayUrl": "www.vkmaheshwari.com/WP/?p=181", "snippet": "<b>inter-rater</b> reliability, <b>inter-rater</b> <b>agreement</b>, or concordance is the degree of <b>agreement</b> among raters. This type of reliability is assessed by having two or more independent judges score the test. The scores are then compared to determine the consistency of the raters estimates. One way to test <b>inter-rater</b> reliability is to have each rater assign each test item a score. For example, each rater might score items on a scale from 1 to 10. Next, you would calculate the correlation between the ...", "dateLastCrawled": "2022-01-27T15:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) A broad assessment of theory of <b>mind</b> in adolescence: The ...", "url": "https://www.academia.edu/21944389/A_broad_assessment_of_theory_of_mind_in_adolescence_The_complexity_of_mindreading", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/21944389/A_broad_assessment_of_theory_of_<b>mind</b>_in_adolescence...", "snippet": "<b>Inter-rater</b> reliability was evaluated on 30 randomly selected participants (15% of the total sample). The level of agree- ment between the scores assigned by the two judges was calculated using the Intraclass Correlation Coefficient (ICC), which provides a generalized measure of <b>inter-rater</b> concordance adjusted for chance <b>agreement</b> between measurements. The ICC was .70, which indicates a good <b>inter-rater</b> <b>agreement</b> (Altman, 1991). Once this first stage of work was done, the judges discussed ...", "dateLastCrawled": "2022-02-01T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Public Attitudes on the Ethics of Deceptively ... - <b>Wiley Online Library</b>", "url": "https://onlinelibrary.wiley.com/doi/full/10.1002/acp.3274", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1002/acp.3274", "snippet": "In total, 54% of participants described at least one of these considerations; <b>Inter-rater</b> <b>agreement</b> ranged from 75 to 96% across the categories (Gwet&#39;s AC 1 from .65 to .93). Gaining informed consent The most commonly mentioned circumstance was gaining consent: 23% of participants felt that the therapy could be (more) acceptable if it was possible to gain informed consent from patients or their families.", "dateLastCrawled": "2021-07-21T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Brief Report Let me <b>read your mind: Personality judgments based on</b> a ...", "url": "https://www.researchgate.net/publication/237295549_Brief_Report_Let_me_read_your_mind_Personality_judgments_based_on_a_person's_natural_stream_of_thought", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/237295549_Brief_Report_Let_me_read_your_<b>mind</b>...", "snippet": "Criteria used to estimate the accuracy of judgments were the <b>agreement</b> between self-report measures on HEXACO PI-R from people who wrote the texts and ratings from participants, as well as the ...", "dateLastCrawled": "2022-01-11T08:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Let professional education 5</b> - SlideShare", "url": "https://www.slideshare.net/RednaxelaNeyaca/let-professional-education-5", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/RednaxelaNeyaca/<b>let-professional-education-5</b>", "snippet": "A. silent <b>reading</b> B. skim <b>reading</b> C. oral <b>reading</b> D. scanning 73. Teacher M sees to it that her classroom is clean and orderly so her pupils will less likely disarrange seats and litter on the floor. On which <b>thought</b> is her action based? A. behaviorism B. existentialism C. progressivism D. reconstructionism 74. Inclusion is a basic right of every Filipino child as mandated in the Philippine Constitution, R.A. 7277 or the Magna Carta for Disabled Persons and EFA 2015. What fundamental changes ...", "dateLastCrawled": "2022-01-30T04:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Psychometric Properties of the Theory of <b>Mind</b> Assessment Scale in a ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860419/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4860419", "snippet": "Overall, the <b>inter-rater</b> <b>agreement</b> was acceptable (Table (Table2). 2). In particular, scale A (first-person ToM: I\u2013Me) and scale D (second-order ToM: Other\u2013Me) displayed fair reliability (0.59 and 0.49 respectively) whereas scales B and C, respectively investigating allocentric third-person ToM (Other\u2013Self) and egocentric third-person ToM (I\u2013Other), showed moderate reliability (0.65 and 0.71, respectively). All the four scales provided good results for internal consistency. Cronbach ...", "dateLastCrawled": "2021-12-10T05:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Overview of Psychological Testing - Psychological Testing in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK305233/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK305233", "snippet": "<b>Inter-rater</b>: Consistency of test scores among independent judges; 3. Parallel or alternate forms: Consistency of scores across different forms of the test (stability and equivalence); and. 4. Internal consistency: Consistency of different items intended to measure the same thing within the test (homogeneity). A special case of internal consistency reliability is split-half where scores on two halves of a single test are <b>compared</b> and this comparison may be converted into an index of ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Frontiers | <b>Psychometric Properties of the Theory</b> of <b>Mind</b> Assessment ...", "url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00566/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00566", "snippet": "Th.o.m.a.s. scores show good <b>inter-rater</b> <b>agreement</b> and internal consistency; the scores increase with age. Evidence of criterion validity was found as Scale B scores were correlated with those of an independent instrument for the evaluation of ToM, the Strange Stories task. Confirmatory factor analysis showed good fit of the 4-factors theoretical model to the data, although the 4 factors were highly correlated. For each of the four scales, Rasch analyses showed that, with few exceptions ...", "dateLastCrawled": "2022-01-29T17:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>agreement</b> statistics - Handling poor <b>inter-rater</b> reliability while ...", "url": "https://stats.stackexchange.com/questions/47864/handling-poor-inter-rater-reliability-while-minimizing-the-loss-of-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/47864/handling-poor-<b>inter-rater</b>-reliability...", "snippet": "Edit: For the purposes of building a tractable model, I am willing to assume that the inconsistencies arise &quot;randomly&quot;, e.g. due to randomly mis-<b>reading</b> the question or mis-clicking an answer on a tablet/computer, so that the errors could be conceived of as independent of any auxiliary variables, in contrast to the example given by @whuber in the comments.", "dateLastCrawled": "2022-01-20T13:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) \u201cIf it&#39;s in your <b>mind</b>, it&#39;s in your knowledge\u201d: Children&#39;s ...", "url": "https://www.academia.edu/11408490/_If_its_in_your_mind_its_in_your_knowledge_Childrens_developing_anatomy_of_identity", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/11408490/_If_its_in_your_<b>mind</b>_its_in_your_knowledge_Childrens...", "snippet": "<b>Inter-rater</b> <b>agreement</b> for coding was calculated by dividing the total number of agreements by the total number of coding decisions to be made (i.e., three times the total number of utterances). The resulting <b>inter-rater</b> <b>agreement</b> was 98%. Disagreements were resolved by discussion. 1.2. Results 1.2.1. Overall results Across all corpora and speakers, there were 185 references to <b>mind</b>, but only 36 references to brain. Of the 185 <b>mind</b> utterances, only a small proportion (.08) were uses of remind ...", "dateLastCrawled": "2021-12-21T01:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Psychometric Properties of the Theory of <b>Mind</b> Assessment Scale in a ...", "url": "https://docksci.com/psychometric-properties-of-the-theory-of-mind-assessment-scale-in-a-sample-of-ad_5a0c7429d64ab2130ebfa641.html", "isFamilyFriendly": true, "displayUrl": "https://docksci.com/psychometric-properties-of-the-theory-of-<b>mind</b>-assessment-scale-in...", "snippet": "In order to assess the <b>inter-rater</b> <b>agreement</b> an Intraclass Correlation Coefficient2 (ICC) was calculated on the 29% of the sample for which the Th.o.m.a.s. interviews had been encoded by two judges. As a rule of thumb, values between 0.41 and 0.60 stand for fair reliability, those between 0.61 and 0.80 for moderate reliability, and those between 0.81 and 0.90 for substantial reliability (Shrout, 1998). Cronbach\u2019s alpha was used to evaluate the internal consistency of the scores on the four ...", "dateLastCrawled": "2022-01-12T14:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Psychometric Properties of the Theory</b> of <b>Mind</b> Assessment Scale in ...", "url": "https://www.researchgate.net/publication/302399303_Psychometric_Properties_of_the_Theory_of_Mind_Assessment_Scale_in_a_Sample_of_Adolescents_and_Adults", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/302399303_Psychometric_Properties_of_the...", "snippet": "In order to assess the <b>inter-rater</b> <b>agreement</b> an Intraclass Correlation Coe\ufb03cient 2 (ICC) was calculated on the 29% of the sample for which the Th.o.m.a.s. interviews had been encoded", "dateLastCrawled": "2022-01-25T17:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Achievement Test~ Characteristics and Construction Procedure | Dr. V.K ...", "url": "http://www.vkmaheshwari.com/WP/?p=181", "isFamilyFriendly": true, "displayUrl": "www.vkmaheshwari.com/WP/?p=181", "snippet": "\u2022 <b>Inter-rater</b> reliability: <b>inter-rater</b> reliability, <b>inter-rater</b> <b>agreement</b>, or concordance is the degree of <b>agreement</b> among raters. This type of reliability is assessed by having two or more independent judges score the test. The scores are then <b>compared</b> to determine the consistency of the raters estimates. One way to test <b>inter-rater</b> reliability is to have each rater assign each test item a score. For example, each rater might score items on a scale from 1 to 10. Next, you would calculate ...", "dateLastCrawled": "2022-01-27T15:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Testing and Assessment - Reliability and Validity", "url": "https://www.hr-guide.com/Testing_and_Assessment/Reliability_and_Validity.htm", "isFamilyFriendly": true, "displayUrl": "https://www.hr-guide.com/Testing_and_Assessment/Reliability_and_Validity.htm", "snippet": "<b>Inter-rater</b> reliability indicates how consistent test scores are likely to be if the test is scored by two or more raters. On some tests, raters evaluate responses to questions and determine the score. Differences in judgments among raters are likely to produce variations in test scores. A high <b>inter-rater</b> reliability coefficient indicates that the judgment process is stable and the resulting scores are reliable. <b>Inter-rater</b> reliability coefficients are typically lower than other types of ...", "dateLastCrawled": "2022-02-02T22:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Research Methods and Statistical Terms Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/3176831/research-methods-and-statistical-terms-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/3176831/research-methods-and-statistical-terms-flash-cards", "snippet": "A research plan in which each step depends on the results of the field data obtained in the previous step. from the Greek word ethos; means either individual character, good or bad, or shared custom in a community. a citation style used widely in the humanities and in some social sciences; also known as MLA style.", "dateLastCrawled": "2020-10-23T22:57:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding Interobserver <b>Agreement</b>: The Kappa Statistic", "url": "http://web2.cs.columbia.edu/~julia/courses/CS6998/Interrater_agreement.Kappa_statistic.pdf", "isFamilyFriendly": true, "displayUrl": "web2.cs.columbia.edu/~julia/courses/CS6998/<b>Interrater</b>_<b>agreement</b>.Kappa_statistic.pdf", "snippet": "call the <b>analogy</b> of a target and how close we get to the bull\u2019s-eye (Figure 1). If we actually hit the bull\u2019s-eye (representing <b>agreement</b> with the gold standard), we are accurate. If all our shots land together, we have good precision (good reliability). If all our shots land together and we hit the bull\u2019s-eye, we are accurate as well as precise. It is possible, however, to hit the bull\u2019s-eye purely by chance. Referring to Figure 1, only the center black dot in target A is accurate ...", "dateLastCrawled": "2022-01-28T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Leveraging Inter-rater Agreement for Audio-Visual Emotion Recognition</b>", "url": "https://www.researchgate.net/publication/283487589_Leveraging_Inter-rater_Agreement_for_Audio-Visual_Emotion_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/283487589_Leveraging_<b>Inter-rater</b>_<b>Agreement</b>...", "snippet": "In <b>machine</b> <b>learning</b> tasks an actual \u2018ground truth\u2019 may not be available. Then, machines often have to rely on human labelling of data. This becomes challenging the more subjective the <b>learning</b> ...", "dateLastCrawled": "2021-08-28T14:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Multilingual <b>Twitter Sentiment Classification</b>: The Role of Human ... - PLOS", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0155036", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0155036", "snippet": "The researchers in the fields of <b>inter-rater</b> <b>agreement</b> and <b>machine</b> <b>learning</b> typically employ different evaluation measures. We report all the results in terms of four selected measures which we deem appropriate for the three-valued sentiment classification task (the details are in the Evaluation measures subsection in Methods). In this section, however, the results are summarized only in terms of Krippendorff\u2019s Alpha-reliability Alpha) , to highlight the main conclusions. Alpha is a ...", "dateLastCrawled": "2021-03-30T23:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>learning</b> glossary - DataTime", "url": "https://www.dtalg.com/article-1/", "isFamilyFriendly": true, "displayUrl": "https://www.dtalg.com/article-1", "snippet": "See also Cohen\u2019s kappa, which is one of the most popular <b>inter-rater</b> <b>agreement</b> measurements. intersection over union (IoU) #image. The intersection of two sets divided by their union. In <b>machine</b>-<b>learning</b> image-detection tasks, IoU is used to measure the accuracy of the model\u2019s predicted bounding box with respect to the ground-truth bounding ...", "dateLastCrawled": "2022-01-25T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Evaluating Crowdsourced Design Concepts With Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/336653474_Evaluating_Crowdsourced_Design_Concepts_With_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/336653474_Evaluating_Crowdsourced_Design...", "snippet": "<b>Inter-rater</b> <b>agreement</b> of the final huma n scores and ML metrics is then tested as a preliminary evaluation . The n the metri cs ar e used to select high scoring ideas from the", "dateLastCrawled": "2021-11-12T16:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Clinician perspectives on <b>machine</b> <b>learning</b> prognostic algorithms in the ...", "url": "https://link.springer.com/article/10.1007/s00520-021-06774-w", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00520-021-06774-w", "snippet": "<b>Machine</b> <b>learning</b> algorithms may accurately predict mortality risk in cancer, but it is unclear how oncology clinicians would use such algorithms in practice. The purpose of this qualitative study was to assess oncology clinicians\u2019 perceptions on the utility and barriers of <b>machine</b> <b>learning</b> prognostic algorithms to prompt advance care planning. Participants included medical oncology physicians and advanced practice providers (APPs) practicing in tertiary and community practices within a ...", "dateLastCrawled": "2022-01-30T10:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Analyzing and Interpreting Data From Rating Scales</b> | by Kevin C Lee ...", "url": "https://towardsdatascience.com/analyzing-and-interpreting-data-from-rating-scales-d169d66211db", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>analyzing-and-interpreting-data-from-rating-scales</b>-d169...", "snippet": "<b>Inter-Rater</b> Reliability. In B), we plot the pairwise correlations between the students with a heatmap. Most of the correlations are &gt; 0.6 with a few exceptions. A small number of respondents showing low correlations with others is acceptable as long as most students are able to respond similarly. P.S. The use of Pearson Correlation is only ...", "dateLastCrawled": "2022-01-29T00:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Art <b>and Science of Analyzing Software Data</b>", "url": "https://www.slideshare.net/timmenzies/the-art-and-science-of-analyzing-software-data", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/timmenzies/the-art-<b>and-science-of-analyzing-software-data</b>", "snippet": "Analyzing survey data \u2022 <b>Inter-rater</b> <b>agreement</b> \u2013 Coding is a subjective activity \u2013 Increase reliability by using multiple raters for entire data or a subset of the data \u2013 Cohen\u2019s Kappa or Fleiss\u2019 Kappa can be used to measure the <b>agreement</b> between multiple raters. \u2013 \u201cWe measured <b>inter-rater</b> <b>agreement</b> for the first author\u2019s categorization on a simple random sample of 100 cards with a closed card sort and two additional raters (third and fourth author); the Fleiss\u2019 Kappa ...", "dateLastCrawled": "2022-01-19T09:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Review of applications and challenges of quantitative systems ...", "url": "https://link.springer.com/article/10.1007%2Fs10928-021-09785-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10928-021-09785-6", "snippet": "<b>Machine</b> <b>learning</b> (ML), including deep <b>learning</b>, has had a growing and substantial impact on science ... and predictions were made public prior to the readouts of multiple phase 3 trials for CETP inhibitors with outcomes in <b>agreement</b> with the insights provided by the mechanistic modeling work [47,48,49]. For heart failure patients, reduced cardiac output and arterial filling pressure leads to congestion in the lungs and body, which causes short breath and fluid retention, contributing to ...", "dateLastCrawled": "2022-01-30T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Quadratic weighted kappa</b> strength of <b>agreement</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/46296/quadratic-weighted-kappa-strength-of-agreement", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/46296", "snippet": "In the case of the kappa-value there are some attempts to qualify how good or bad the agreements are. For example Landis &amp; Koch in the article The Measurement of Observer <b>Agreement</b> for Categorical Data talks about &quot;strength of <b>agreement</b>&quot; based on kappa values:. Kappa Strength of <b>agreement</b> ===== ===== 0.0-0.20 Slight 0.21-0.40 Fair 0.41-0.60 Moderate 0.61-0.80 Substantial 0.81-0.90 Almost perfect", "dateLastCrawled": "2022-01-20T17:56:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Reliability and Learnability of Human Bandit Feedback for Sequence-to ...", "url": "https://aclanthology.org/P18-1165.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/P18-1165.pdf", "snippet": "intra- and <b>inter-rater agreement is similar</b> for both tasks, with highest inter-rater reliability for stan-dardized 5-point ratings. In a next step, we address the issue of <b>machine</b> learnability of human rewards. We use deep learn- ing models to train reward estimators by regres-sion against cardinal feedback, and by \ufb01tting a Bradley-Terry model (Bradley and Terry,1952) to ordinal feedback. Learnability is understood by a slight misuse of the <b>machine</b> <b>learning</b> notion of learnability (Shalev ...", "dateLastCrawled": "2021-12-22T00:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "arXiv:1805.10627v3 [cs.CL] 13 Dec 2018", "url": "https://www.researchgate.net/profile/Joshua-Uyheng/publication/325413588_Reliability_and_Learnability_of_Human_Bandit_Feedback_for_Sequence-to-Sequence_Reinforcement_Learning/links/5ea04de5a6fdccd7cee0eebe/Reliability-and-Learnability-of-Human-Bandit-Feedback-for-Sequence-to-Sequence-Reinforcement-Learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/profile/Joshua-Uyheng/publication/325413588_Reliability...", "snippet": "\ufb01ed by bandit <b>learning</b> for neural <b>machine</b> trans-lation (NMT). Our aim is to show that successful <b>learning</b> from simulated bandit feedback (Sokolov et al.,2016b;Kreutzer et al.,2017;Nguyen et al ...", "dateLastCrawled": "2021-08-22T12:54:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(inter-rater agreement)  is like +(reading someone's mind)", "+(inter-rater agreement) is similar to +(reading someone's mind)", "+(inter-rater agreement) can be thought of as +(reading someone's mind)", "+(inter-rater agreement) can be compared to +(reading someone's mind)", "machine learning +(inter-rater agreement AND analogy)", "machine learning +(\"inter-rater agreement is like\")", "machine learning +(\"inter-rater agreement is similar\")", "machine learning +(\"just as inter-rater agreement\")", "machine learning +(\"inter-rater agreement can be thought of as\")", "machine learning +(\"inter-rater agreement can be compared to\")"]}