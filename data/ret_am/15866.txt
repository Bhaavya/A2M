{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Machine learning glossary - DataTime", "url": "https://www.dtalg.com/article-1/", "isFamilyFriendly": true, "displayUrl": "https://www.dtalg.com/article-1", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) ... mini-batch stochastic gradient descent estimates the gradient based on a small subset of the training data. <b>Regular</b> stochastic gradient descent uses a mini-batch of size 1. minimax loss. A loss function for generative adversarial networks, based on the cross-entropy between the distribution of generated data and real data. Minimax loss is used in the first paper to describe generative adversarial networks. minority class. The less common label in a ...", "dateLastCrawled": "2022-01-25T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Department of Mathematics arXiv:1809.04481v3 [cs.LG] 8 Jan 2019", "url": "https://arxiv.org/pdf/1809.04481.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/1809.04481.pdf", "snippet": "<b>Kernel</b> methods such as <b>kernel</b> <b>support</b> <b>vector</b> <b>machines</b> (<b>KSVMs</b>) have been widely and successfully used in classi\ufb01cation tasks (Steinwart and Christmann [2008]). The power of <b>kernel</b> methods comes from the fact that they implicitly map the data to a high dimensional, or even in\ufb01nite dimensional, feature space, where", "dateLastCrawled": "2021-09-13T11:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>ML Interview Questions</b> | PDF | Principal Component Analysis | Logistic ...", "url": "https://www.scribd.com/document/444350635/ML-interview-questions-docx", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/444350635/<b>ML-interview-questions</b>-docx", "snippet": "Some companies <b>like</b> their data scientists to be comfortable accessing data that ... (kNN) Learning <b>Vector</b> Quantization (LVQ) <b>Support</b> <b>Vector</b> <b>Machines</b> What is <b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>)? A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input dataset has a hundred features. To maximize the margin between positive ...", "dateLastCrawled": "2022-01-21T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Classification of Alzheimer Disease Based</b> on Structural Magnetic ...", "url": "https://www.researchgate.net/publication/259757152_Classification_of_Alzheimer_Disease_Based_on_Structural_Magnetic_Resonance_Imaging_by_Kernel_Support_Vector_Machine_Decision_Tree", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/259757152_Classification_of_Alzheimer_Disease...", "snippet": "Wu, K.-P. and S.-D. Wang, Choosing the <b>kernel</b> parameters for <b>support</b> <b>vector</b> <b>machines</b> by the inter- cluster distance in the feature space. Pattern Recognition, 2009.", "dateLastCrawled": "2022-01-15T22:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Ultimate Data Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-data-science-flash-cards", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input dataset has a hundred features. To maximize the margin between positive and negative classes, a KSVM could internally map those features into a million-dimension space. <b>KSVMs</b> uses a loss function called hinge loss. K-means. A ...", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Detection of Brain Tumor using Image Classification", "url": "https://www.researchgate.net/publication/327497285_Detection_of_Brain_Tumor_using_Image_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/327497285_Detection_of_Brain_Tumor_using...", "snippet": "The reduced features were submitted to a <b>kernel</b> <b>support</b> <b>vector</b> machine (KSVM). The strategy of K-fold stratified cross validation was used to enhance generalization of KSVM. We chose seven common ...", "dateLastCrawled": "2021-12-13T13:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Google Machine Learning Glossary</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/256349161/google-machine-learning-glossary-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/256349161/<b>google-machine-learning-glossary</b>-flash-cards", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMS</b>) A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input data set consists of a hundred features.", "dateLastCrawled": "2018-10-18T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deformable segmentation of 3-D ultrasound prostate images using ...", "url": "https://www.researchgate.net/publication/7254399_Deformable_segmentation_of_3-D_ultrasound_prostate_images_using_statistical_texture_matching_method", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/7254399_Deformable_segmentation_of_3-D...", "snippet": "Patient-specific Gabor features from the atlas database was used to train <b>kernel</b> <b>support</b> <b>vector</b> <b>machines</b> (<b>KSVMs</b>) [13]. In different work, Zhan et al. [14] proposed the use of a deformable for ...", "dateLastCrawled": "2022-01-09T00:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Classification of foreign fibers in cotton lint using machine ...", "url": "https://www.researchgate.net/publication/251524282_Classification_of_foreign_fibers_in_cotton_lint_using_machine_vision_and_multi-class_support_vector_machine", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/251524282_Classification_of_foreign_fibers_in...", "snippet": "<b>Support</b> <b>vector</b> <b>machines</b> (SVMs) are designed to solve the binary classification problems at the beginning, but in the real world, there are a lot of multiclassification cases. The ...", "dateLastCrawled": "2022-01-28T06:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "modeling - Forecasting time series based on a behavior of other one ...", "url": "https://stats.stackexchange.com/questions/14351/forecasting-time-series-based-on-a-behavior-of-other-one", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/14351", "snippet": "<b>support</b> <b>vector</b> <b>machines</b> for regression: but when I plotted the data on a scatter graph there isn&#39;t any clear relationship, so this made me think that the SVM approach would fail. time series analysis: this approach confused me because there isn&#39;t any obvious trends in the data. Can anyone offer any advice on what I approach I should take? time-series modeling forecasting. Share. Cite. Improve this question. Follow edited Aug 22 &#39;14 at 17:50. whuber \u2666. 277k 54 54 gold badges 625 625 silver ...", "dateLastCrawled": "2022-01-11T19:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>ITI-CERTH participation to TRECVID 2012</b> - NIST", "url": "https://www-nlpir.nist.gov/projects/tvpubs/tv12.papers/iti-certh.pdf", "isFamilyFriendly": true, "displayUrl": "https://www-nlpir.nist.gov/projects/tvpubs/tv12.papers/iti-certh.pdf", "snippet": "of subclass <b>kernel</b> <b>support</b> <b>vector</b> <b>machines</b> (<b>KSVMs</b>) in an ECOC framework for event detection exploiting visual information only. Furthermore, we investigate fusion strategies of the two systems in an intermediate semantic level or in score level (late fusion). In the MER task, a \\model <b>vector</b> approach&quot; is used to describe the semantic content of the videos, <b>similar</b> to the MED task, and a novel feature selection method is utilized to select the most discriminant concepts regarding the target ...", "dateLastCrawled": "2021-10-10T01:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Machine learning glossary - DataTime", "url": "https://www.dtalg.com/article-1/", "isFamilyFriendly": true, "displayUrl": "https://www.dtalg.com/article-1", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input dataset has a hundred features. To maximize the margin between positive and ...", "dateLastCrawled": "2022-01-25T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Data Science Glossary", "url": "https://aboutds.com/en/content/data-science-glossary", "isFamilyFriendly": true, "displayUrl": "https://aboutds.com/en/content/data-science-glossary", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) ... Squared hinge loss penalizes outliers more harshly than <b>regular</b> hinge loss. squared loss. The loss function used in linear regression. (Also known as L 2 Loss.) This function calculates the squares of the difference between a model&#39;s predicted value for a labeled example and the actual value of the label. Due to squaring, this loss function amplifies the influence of bad predictions. That is, squared loss reacts more strongly to outliers than L 1 ...", "dateLastCrawled": "2021-12-01T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Classification of Alzheimer Disease Based</b> on Structural Magnetic ...", "url": "https://www.researchgate.net/publication/259757152_Classification_of_Alzheimer_Disease_Based_on_Structural_Magnetic_Resonance_Imaging_by_Kernel_Support_Vector_Machine_Decision_Tree", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/259757152_Classification_of_Alzheimer_Disease...", "snippet": "Wu, K.-P. and S.-D. Wang, Choosing the <b>kernel</b> parameters for <b>support</b> <b>vector</b> <b>machines</b> by the inter- cluster distance in the feature space. Pattern Recognition, 2009.", "dateLastCrawled": "2022-01-15T22:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>ML Interview Questions</b> | PDF | Principal Component Analysis | Logistic ...", "url": "https://www.scribd.com/document/444350635/ML-interview-questions-docx", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/444350635/<b>ML-interview-questions</b>-docx", "snippet": "Instance based k-Nearest Neighbour (kNN) Learning <b>Vector</b> Quantization (LVQ) <b>Support</b> <b>Vector</b> <b>Machines</b> What is <b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>)? A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space.", "dateLastCrawled": "2022-01-21T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Ultimate Data Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-data-science-flash-cards", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input dataset has a hundred features.", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>ITI-CERTH participation to TRECVID 2012</b>", "url": "https://www.researchgate.net/publication/255946875_ITI-CERTH_participation_to_TRECVID_2012", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/255946875_<b>ITI-CERTH_participation_to_TRECVID_2012</b>", "snippet": "of sub class <b>kernel</b> <b>supp ort</b> <b>vector</b> <b>machines</b> (<b>KSVMs</b>) in an ECOC framework for ev ent detection exploiting visual information only . F urthermore, we inv estigate fusion strategies of the tw o systems", "dateLastCrawled": "2021-10-21T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fish age categorization from otolith images using</b> multi-class <b>support</b> ...", "url": "https://www.researchgate.net/publication/223310991_Fish_age_categorization_from_otolith_images_using_multi-class_support_vector_machines", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/223310991_Fish_age_categorization_from...", "snippet": "The reduced features are given to the machine learning algorithm called the <b>kernel</b> <b>support</b> <b>vector</b> machine to classify magnetic resonance images. The K-fold stratified cross validation scheme is ...", "dateLastCrawled": "2021-11-06T00:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Google Machine Learning Glossary</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/256349161/google-machine-learning-glossary-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/256349161/<b>google-machine-learning-glossary</b>-flash-cards", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMS</b>) ... Squared hinge loss penalizes outliers more harshly than <b>regular</b> hinge loss. Squared Loss. The loss function used in linear regression. (Also known as L2 Loss.) This function calculates the squares of the difference between a model&#39;s predicted value for a labeled example and the actual value of the label. Due to squaring, this loss function amplifies the influence of bad predictions. That is, squared loss reacts more strongly to outliers than L1 loss ...", "dateLastCrawled": "2018-10-18T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Freeopen - \u673a\u5668\u5b66\u4e60\u672f\u8bed\u8868", "url": "https://freeopen.github.io/posts/ml-glossary", "isFamilyFriendly": true, "displayUrl": "https://freeopen.github.io/posts/ml-glossary", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> use hyperplanes to separate positive classes from negative classes, ... <b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input data set consists of a hundred features. In order to maximize the margin between positive and negative classes, <b>KSVMs</b> could ...", "dateLastCrawled": "2021-07-31T01:13:00.0000000Z", "language": "zh_chs", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>ML Interview Questions</b> | PDF | Principal Component Analysis | Logistic ...", "url": "https://www.scribd.com/document/444350635/ML-interview-questions-docx", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/444350635/<b>ML-interview-questions</b>-docx", "snippet": "PCA <b>can</b> <b>be thought</b> of as fitting a p-dimensional ellipsoid to the data, ... (kNN) Learning <b>Vector</b> Quantization (LVQ) <b>Support</b> <b>Vector</b> <b>Machines</b> What is <b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>)? A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input dataset has a hundred features. To maximize the margin between positive and ...", "dateLastCrawled": "2022-01-21T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Fish age categorization from otolith images using</b> multi-class <b>support</b> ...", "url": "https://www.researchgate.net/publication/223310991_Fish_age_categorization_from_otolith_images_using_multi-class_support_vector_machines", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/223310991_Fish_age_categorization_from...", "snippet": "Afterwards, we constructed a <b>kernel</b> <b>support</b> <b>vector</b> machine (KSVM) with RBF <b>kernel</b>, using particle swarm optimization (PSO) to optimize the parameters C and \u03c3 . Fivefold cross-validation was ...", "dateLastCrawled": "2021-11-06T00:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Be the only one, not the best one :: &#39;Machine Learning&#39; \uce74\ud14c\uace0\ub9ac\uc758 \uae00 \ubaa9\ub85d (2 Page)", "url": "https://theonly1.tistory.com/category/Machine%20Learning?page=2", "isFamilyFriendly": true, "displayUrl": "https://theonly1.tistory.com/category/Machine Learning?page=2", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input data set consists of a hundred features. In order to maximize the margin between positive and negative classes, <b>KSVMs</b> could internally map those features into a million-dimension space. <b>KSVMs</b> uses a loss function called hinge loss ...", "dateLastCrawled": "2022-02-01T00:40:00.0000000Z", "language": "ko", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Predicting Prodromal Alzheimer&#39;s Disease in Subjects with Mild ...", "url": "https://www.researchgate.net/publication/271524401_Predicting_Prodromal_Alzheimer's_Disease_in_Subjects_with_Mild_Cognitive_Impairment_Using_Machine_Learning_Classification_of_Multimodal_Multicenter_Diffusion-Tensor_and_Magnetic_Resonance_Imaging_Data", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/271524401_Predicting_Prodromal_Alzheimer", "snippet": "ML techniques used included <b>support</b> <b>vector</b> <b>machines</b>, decision trees, neural networks, latent Dirichlet allocation, and clustering. Conclusions Overall, the application of ML to mental health has ...", "dateLastCrawled": "2021-11-14T08:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "[[es]] - anagora.org", "url": "https://anagora.org/es", "isFamilyFriendly": true, "displayUrl": "https://anagora.org/es", "snippet": "\u2945 related node [[2003 06 23 apple debuts ppc 970 <b>machines</b>]] pull \u2945 related node [[2003 07 08 small business directory service ideas maybe a beer]] pull \u2945 related node [[2003 08 01 is blogging breaking googles usefulness]] pull", "dateLastCrawled": "2022-01-26T15:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Machine learning glossary - DataTime", "url": "https://www.dtalg.com/article-1/", "isFamilyFriendly": true, "displayUrl": "https://www.dtalg.com/article-1", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) ... As a value to <b>be compared</b> against a. classification threshold. If the value is equal to or above the classification threshold, the system classifies the example as the positive class. Conversely, if the value is below the given threshold, the system classifies the example as the . negative class. For example, suppose the classification threshold is 0.82: Imagine an example that produces a raw prediction (y\u2032) of 2.6. The sigmoid of 2.6 is 0.93 ...", "dateLastCrawled": "2022-01-25T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Department of Mathematics arXiv:1809.04481v3 [cs.LG] 8 Jan 2019", "url": "https://arxiv.org/pdf/1809.04481.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/1809.04481.pdf", "snippet": "<b>Kernel</b> methods such as <b>kernel</b> <b>support</b> <b>vector</b> <b>machines</b> (<b>KSVMs</b>) have been widely and successfully used in classi\ufb01cation tasks (Steinwart and Christmann [2008]). The power of <b>kernel</b> methods comes from the fact that they implicitly map the data to a high dimensional, or even in\ufb01nite dimensional, feature space, where", "dateLastCrawled": "2021-09-13T11:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Support Vector Machines on Large</b> <b>Data Sets: Simple Parallel Approaches</b>", "url": "https://www.statistik.tu-dortmund.de/~bischl/mypapers/support_vector_machines_on_large_data_sets_simple_parallel_approaches.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.statistik.tu-dortmund.de/~bischl/mypapers/<b>support_vector_machines_on_large</b>...", "snippet": "3 Cascade <b>Support</b> <b>Vector</b> Machine The Cascade SVM is a stepwise procedure that combines the results of mul-tiple <b>regular</b> <b>support</b> <b>vector</b> <b>machines</b> to create one nal model. The main idea is to iteratively reduce a data set to its crucial data points before the last step. This is done by locating potential <b>support</b> vectors and removing all", "dateLastCrawled": "2022-01-09T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "WSEAS", "url": "https://wseas.org/wseas/cms.action?id=10183", "isFamilyFriendly": true, "displayUrl": "https://wseas.org/wseas/cms.action?id=10183", "snippet": "Abstract: This paper is denoted to study the effect of the group information of data in one-class <b>kernel</b> <b>support</b> <b>vector</b> <b>machines</b> (OC-<b>KSVMs</b>) for classification accuracy and time consumed of multi-class classification data. Two new classification methods based on OC-<b>KSVMs</b> are presented. One is OC-KSVM with maximum margin from the origin and group information of data (briefly, MMOC-KSVM+) and another is OC-KSVM with hypersphere and group information of data (briefly, HSOC-KSVM+). We proved ...", "dateLastCrawled": "2022-01-25T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Classification of Alzheimer Disease Based</b> on Structural Magnetic ...", "url": "https://www.researchgate.net/publication/259757152_Classification_of_Alzheimer_Disease_Based_on_Structural_Magnetic_Resonance_Imaging_by_Kernel_Support_Vector_Machine_Decision_Tree", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/259757152_Classification_of_Alzheimer_Disease...", "snippet": "Wu, K.-P. and S.-D. Wang, Choosing the <b>kernel</b> parameters for <b>support</b> <b>vector</b> <b>machines</b> by the inter- cluster distance in the feature space. Pattern Recognition, 2009.", "dateLastCrawled": "2022-01-15T22:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>ML Interview Questions</b> | PDF | Principal Component Analysis | Logistic ...", "url": "https://www.scribd.com/document/444350635/ML-interview-questions-docx", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/444350635/<b>ML-interview-questions</b>-docx", "snippet": "Instance based k-Nearest Neighbour (kNN) Learning <b>Vector</b> Quantization (LVQ) <b>Support</b> <b>Vector</b> <b>Machines</b> What is <b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>)? A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space.", "dateLastCrawled": "2022-01-21T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Ultimate Data Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-data-science-flash-cards", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input dataset has a hundred features. To maximize the margin between positive and negative classes, a KSVM could internally map those features into a million-dimension space. <b>KSVMs</b> uses a loss function called hinge loss. K-means. A ...", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>ITI-CERTH participation to TRECVID 2012</b>", "url": "https://www.researchgate.net/publication/255946875_ITI-CERTH_participation_to_TRECVID_2012", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/255946875_<b>ITI-CERTH_participation_to_TRECVID_2012</b>", "snippet": "of sub class <b>kernel</b> <b>supp ort</b> <b>vector</b> <b>machines</b> (<b>KSVMs</b>) in an ECOC framework for ev ent detection exploiting visual information only . F urthermore, we inv estigate fusion strategies of the tw o systems", "dateLastCrawled": "2021-10-21T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Classification of foreign fibers in cotton lint using machine ...", "url": "https://www.researchgate.net/publication/251524282_Classification_of_foreign_fibers_in_cotton_lint_using_machine_vision_and_multi-class_support_vector_machine", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/251524282_Classification_of_foreign_fibers_in...", "snippet": "<b>Support</b> <b>vector</b> <b>machines</b> (SVMs) are designed to solve the binary classification problems at the beginning, but in the real world, there are a lot of multiclassification cases. The ...", "dateLastCrawled": "2022-01-28T06:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Fish age categorization from otolith images using</b> multi-class <b>support</b> ...", "url": "https://www.researchgate.net/publication/223310991_Fish_age_categorization_from_otolith_images_using_multi-class_support_vector_machines", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/223310991_Fish_age_categorization_from...", "snippet": "Shapelet transformed data are classified using a number of techniques (Nearest-Neighbour, Naive-Bayes, C4.5, <b>Support</b> <b>Vector</b> <b>Machines</b>, Random and Rotation Forest) and <b>compared</b> to CSS classification ...", "dateLastCrawled": "2021-11-06T00:19:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>learning</b> glossary - DataTime", "url": "https://www.dtalg.com/article-1/", "isFamilyFriendly": true, "displayUrl": "https://www.dtalg.com/article-1", "snippet": "<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>) A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input dataset has a hundred features. To maximize the margin between positive and ...", "dateLastCrawled": "2022-01-25T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>ML Interview Questions</b> | PDF | Principal Component Analysis | Logistic ...", "url": "https://www.scribd.com/document/444350635/ML-interview-questions-docx", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/444350635/<b>ML-interview-questions</b>-docx", "snippet": "<b>Support</b> <b>Vector</b> <b>Machine</b> <b>Learning</b> Algorithm performs better in the reduced space. It is beneficial to ... <b>Learning</b> <b>Vector</b> Quantization (LVQ) <b>Support</b> <b>Vector</b> <b>Machines</b> What is <b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> (<b>KSVMs</b>)? A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input dataset has a hundred features. To maximize the margin ...", "dateLastCrawled": "2022-01-21T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Ultimate Data Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-data-science-flash-cards", "snippet": "For example, a line is a hyperplane in two dimensions and a plane is a hyperplane in three dimensions. More typically in <b>machine</b> <b>learning</b>, a hyperplane is the boundary separating a high-dimensional space. <b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b> use hyperplanes to separate positive classes from negative classes, often in a very high-dimensional space.", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Deformable segmentation of 3-D ultrasound prostate images using ...", "url": "https://www.researchgate.net/publication/7254399_Deformable_segmentation_of_3-D_ultrasound_prostate_images_using_statistical_texture_matching_method", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/7254399_Deformable_segmentation_of_3-D...", "snippet": "Patient-specific Gabor features from the atlas database was used to train <b>kernel</b> <b>support</b> <b>vector</b> <b>machines</b> (<b>KSVMs</b>) [13]. In different work, Zhan et al. [14] proposed the use of a deformable for ...", "dateLastCrawled": "2022-01-09T00:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "7 AI\u672f\u8bed\u673a\u5668\u4e4b\u5fc3\u5f00\u653e\u4eba\u5de5\u667a\u80fd\u4e13\u4e1a\u8bcd\u6c47\u96c6.docx-\u539f\u521b\u529b\u6587\u6863", "url": "https://max.book118.com/html/2021/0723/8143070031003124.shtm", "isFamilyFriendly": true, "displayUrl": "https://max.book118.com/html/2021/0723/8143070031003124.shtm", "snippet": "K <b>Kernel</b> \u652f\u6301\u5411\u91cf\u673a\uff08<b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b>/KSVM\uff09 \u4e00\u79cd\u5206\u7c7b\u7b97\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u5c06\u8f93\u5165\u6570\u636e\u5411\u91cf\u6620\u5c04\u5230\u66f4\u9ad8\u7ef4\u5ea6\u7684\u7a7a\u95f4\u4f7f\u6b63\u7c7b\u548c\u8d1f\u7c7b\u4e4b\u95f4\u7684\u8fb9\u9645\u6700\u5927\u5316\u3002\u4f8b\u5982\uff0c\u8003\u8651\u4e00\u4e2a\u8f93\u5165\u6570\u636e\u96c6\u5305\u542b\u4e00\u767e\u4e2a\u7279\u5f81\u7684\u5206\u7c7b\u95ee\u9898\u3002\u4e3a\u4e86\u4f7f\u6b63\u7c7b\u548c\u8d1f\u7c7b\u4e4b\u95f4\u7684\u95f4\u9694\u6700\u5927\u5316\uff0cKSVM \u4ece\u5185\u90e8\u5c06\u7279\u5f81\u6620\u5c04\u5230\u767e\u4e07\u7ef4\u5ea6\u7684\u7a7a\u95f4\u3002KSVM \u4f7f\u7528\u7684\u635f\u5931\u51fd\u6570\u53eb\u4f5c hinge \u635f\u5931\u3002 L L1 \u635f\u5931\u51fd\u6570\uff08L1 loss\uff09 \u635f\u5931\u51fd\u6570\u57fa\u4e8e\u6a21\u578b\u5bf9\u6807\u7b7e\u7684 ...", "dateLastCrawled": "2022-01-06T14:31:00.0000000Z", "language": "zh_chs", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Preoperative prediction of malignancy of</b> ovarian tumors using least ...", "url": "https://www.researchgate.net/publication/10607249_Preoperative_prediction_of_malignancy_of_ovarian_tumors_using_least_squares_support_vector_machines", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/10607249_Preoperative_prediction_of...", "snippet": "<b>Support</b> <b>vector</b> <b>machines</b> and <b>kernel</b> based <b>learning</b> (2 x 90 min.) 2. Case studies (45 min.) 3. Topics in complex networks, synchronization and cooperative behaviour (90 min.) \u2022 Emphasis on ...", "dateLastCrawled": "2021-11-13T19:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Data Science Glossary", "url": "https://aboutds.com/en/content/data-science-glossary", "isFamilyFriendly": true, "displayUrl": "https://aboutds.com/en/content/data-science-glossary", "snippet": "In <b>machine</b> <b>learning</b>, the gradient is the <b>vector</b> of partial derivatives of the model function. The gradient points in the direction of steepest ascent. gradient clipping . Capping gradient values before applying them. Gradient clipping helps ensure numerical stability and prevents exploding gradients. gradient descent. A technique to minimize loss by computing the gradients of loss with respect to the model&#39;s parameters, conditioned on training data. Informally, gradient descent iteratively ...", "dateLastCrawled": "2021-12-01T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "\u3010AI\u672f\u8bed\u3011\u673a\u5668\u4e4b\u5fc3\u5f00\u653e\u4eba\u5de5\u667a\u80fd\u4e13\u4e1a\u8bcd\u6c47\u96c6 - szoyea.com", "url": "http://szoyea.com/epdvnfou/0df5c887d42132e0ecc9d446142f6dfb", "isFamilyFriendly": true, "displayUrl": "szoyea.com/epdvnfou/0df5c887d42132e0ecc9d446142f6dfb", "snippet": "\u673a\u5668\u4e4b\u5fc3\u539f\u521b. \u673a\u5668\u4e4b\u5fc3\u7f16\u8f91\u90e8. \u4f5c\u4e3a\u6700\u65e9\u5173\u6ce8\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5a92\u4f53\uff0c\u673a\u5668\u4e4b\u5fc3\u5728\u7f16\u8bd1\u56fd\u5916\u6280\u672f\u535a\u5ba2\u3001\u8bba\u6587\u3001\u4e13\u5bb6\u89c2\u70b9\u7b49\u5185\u5bb9\u4e0a ...", "dateLastCrawled": "2021-12-16T02:47:00.0000000Z", "language": "zh_chs", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "\u673a\u5668\u5b66\u4e60\u82f1\u6587\u8bcd\u6c47 - CSDN", "url": "https://www.csdn.net/tags/MtTacg5sODYwNy1ibG9n.html", "isFamilyFriendly": true, "displayUrl": "https://www.csdn.net/tags/MtTacg5sODYwNy1ibG9n.html", "snippet": "\u6838\u652f\u6301\u5411\u91cf\u673a (KSVM, <b>Kernel</b> <b>Support</b> <b>Vector</b> <b>Machines</b>) \u4e00\u79cd\u5206\u7c7b\u7b97\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u5c06\u8f93\u5165\u6570\u636e\u5411\u91cf\u6620\u5c04\u5230\u66f4\u9ad8\u7ef4\u5ea6\u7684\u7a7a\u95f4\uff0c\u6765\u6700\u5927\u5316\u6b63\u7c7b\u522b\u548c\u8d1f\u7c7b\u522b\u4e4b\u95f4\u7684\u88d5\u5ea6\u3002\u4ee5\u67d0\u4e2a\u8f93\u5165\u6570\u636e\u96c6\u5305\u542b\u4e00\u767e\u4e2a\u7279\u5f81\u7684\u5206\u7c7b\u95ee\u9898\u4e3a\u4f8b\u3002\u4e3a\u4e86\u6700\u5927\u5316\u6b63\u7c7b\u522b\u548c\u8d1f\u7c7b\u522b\u4e4b\u95f4\u7684\u88d5\u5ea6\uff0cKSVM \u53ef\u4ee5\u5728\u5185\u90e8\u5c06\u8fd9\u4e9b\u7279\u5f81\u6620\u5c04\u5230\u767e\u4e07\u7ef4\u5ea6\u7684\u7a7a\u95f4\u3002KSVM \u4f7f\u7528\u5408\u9875\u635f\u5931\u51fd\u6570\u3002 L. L1 \u635f\u5931\u51fd\u6570 (L\u2081 loss) \u4e00\u79cd\u635f\u5931\u51fd\u6570\uff0c\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u7684\u503c ...", "dateLastCrawled": "2022-02-02T02:54:00.0000000Z", "language": "zh_chs", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(kernel support vector machines (ksvms))  is like +(regular support vector machines)", "+(kernel support vector machines (ksvms)) is similar to +(regular support vector machines)", "+(kernel support vector machines (ksvms)) can be thought of as +(regular support vector machines)", "+(kernel support vector machines (ksvms)) can be compared to +(regular support vector machines)", "machine learning +(kernel support vector machines (ksvms) AND analogy)", "machine learning +(\"kernel support vector machines (ksvms) is like\")", "machine learning +(\"kernel support vector machines (ksvms) is similar\")", "machine learning +(\"just as kernel support vector machines (ksvms)\")", "machine learning +(\"kernel support vector machines (ksvms) can be thought of as\")", "machine learning +(\"kernel support vector machines (ksvms) can be compared to\")"]}