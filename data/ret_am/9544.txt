{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Graphics Programming</b> - SJSU", "url": "http://www.cs.sjsu.edu/faculty/pearce/cs46a/graphics.htm", "isFamilyFriendly": true, "displayUrl": "www.cs.sjsu.edu/faculty/pearce/cs46a/graphics.htm", "snippet": "Use a <b>piece</b> of graph <b>paper</b> to represent the <b>bounding</b> <b>box</b> of your shape. Draw the shape on this <b>paper</b> using only ellipses, lines, and rectangles. Use this drawing to determine the sizes and positions of these component shapes relative to the graph <b>paper</b>. Step 2. Create a shape class: public class MyShape { private int xc, yc, width, height;", "dateLastCrawled": "2021-10-19T14:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bounding</b> Boxes - DataGenetics", "url": "https://www.datagenetics.com/blog/march12014/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.datagenetics.com/blog/march12014/index.html", "snippet": "The <b>bounding</b> <b>box</b> it produces is orthogonal to the axes and this has many great and useful properties (especially in computers, whose displays are typically mapped using a Cartesian grid). A very fast, first order \u2018hit-detection\u2019 algorithm employs this strategy. If you want to see if a point is, potentially, inside a complex shape then you can quickly check the shape\u2019s <b>bounding</b> <b>box</b>. If the test coordinate in question is outside the rectangular <b>bounding</b> <b>box</b> it is impossible for that ...", "dateLastCrawled": "2022-02-01T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Unity/<b>C# bounding box of object from</b> image - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/43400447/unity-c-bounding-box-of-object-from-image", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/43400447", "snippet": "What you want to achieve is possible only if the phone can first recognize some sort of a marker (could be a <b>piece</b> <b>of paper</b>). That would map the 3d environment to the real world environment. Otherwise you would have to guess the actual size (lets say in centimeters) of the object. You can never tell the size, because you do not know if the image is taken 10 cm. from the object or 1 m. from the object.", "dateLastCrawled": "2022-01-16T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Paper</b> Flower Shadow <b>Box</b> Ideas + Hand Lettered Designs! - Jennifer Maker", "url": "https://jennifermaker.com/paper-flower-shadow-box-ideas/", "isFamilyFriendly": true, "displayUrl": "https://jennifermaker.com/<b>paper</b>-flower-shadow-<b>box</b>-ideas", "snippet": "Materials to Make a 10\u2033 x 10\u2033 <b>Paper</b> Flower Shadow <b>Box</b>. View my Amazon shopping list with the exact items we used to make this project! One (1) 10\u201d x 10\u201d Shadowbox <b>Frame</b>. Twenty-Five (25) Sheets of 65 lb. Cardstock (8.5\u2033 x 11\u2033) \u2014 I used different shades of red \u2014 if you use 12\u2033 x 12\u2033 <b>paper</b>, you need fewer sheets.", "dateLastCrawled": "2022-02-03T01:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Tutorial - Boxes, Comments, Footnotes in LaTeX", "url": "https://www.docx2latex.com/tutorials/boxes-comments-LaTeX.html/", "isFamilyFriendly": true, "displayUrl": "https://www.docx2latex.com/<b>tutorials</b>/<b>box</b>es-comments-LaTeX.html", "snippet": "This command works exactly <b>like</b> the \\makebox command except, that it makes the <b>frame</b> around the <b>box</b>. 3. Paragraph Boxes . A paragraph <b>box</b> is specially used when the user is working within a tabular environment. It works <b>like</b> a paragraph whose width is given by the user. The command \\parbox typesets the content which is given in its second argument and its first argument gives the width of the <b>box</b>. The <b>box</b> that is generated is handled as a single character \\documentclass{article} \\usepackage ...", "dateLastCrawled": "2022-01-30T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Satisfaction of the Solar <b>Bounding</b> <b>Box</b> constraints", "url": "https://www.researchgate.net/publication/250306346_Satisfaction_of_the_Solar_Bounding_Box_constraints", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/250306346_Satisfaction_of_the_Solar_<b>Bounding</b>...", "snippet": "This <b>paper</b> aims to develop a morphological generator of urban rules of solar control based on a modeling approach of the Solar <b>Bounding</b> <b>Box</b> SBB. This is the optimum volume conditioned by both the ...", "dateLastCrawled": "2021-12-10T09:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Object Detection Using OpenCV</b> YOLO | Great Learning", "url": "https://www.mygreatlearning.com/blog/yolo-object-detection-using-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreatlearning.com/blog/yolo-<b>object-detection-using-opencv</b>", "snippet": "The predicted <b>bounding</b> boxes may look something <b>like</b> the following (the higher the confidence score, the fatter the <b>box</b> is drawn): Source: Original YOLO research <b>paper</b> Finally, the confidence score for the <b>bounding</b> <b>box</b> and the class prediction are combined into one final score that tells us the probability that this <b>bounding</b> <b>box</b> contains a specific type of object.", "dateLastCrawled": "2022-02-03T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to Make an Easy <b>Paper</b> Cut Out Effect In PowerPoint - PrettyWebz ...", "url": "https://prettywebz.com/paper-cut-out-effect/", "isFamilyFriendly": true, "displayUrl": "https://prettywebz.com/<b>paper</b>-cut-out-effect", "snippet": "Once we have this basic shapes here, noticed that on the outside, it looks <b>like</b> we laid a <b>piece</b> <b>of paper</b> on top of this pink, this is what we want. Now what we\u2019re going to do is right-click, copy, and paste the second heart. Use the <b>bounding</b> <b>box</b> handles to resize to adjust the size and nested inside the large heart shape. Once you have the smaller heart nested where you want it change the color. You can copy and paste another heart shape, shrink it down and nest it again. Do this as many ...", "dateLastCrawled": "2022-01-27T11:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Drawing a <b>rectangle</b> around all contours in OpenCV Python - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/40203932/drawing-a-rectangle-around-all-contours-in-opencv-python", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/40203932", "snippet": "i have a code which identifies contours after applying filters on video frames. Now in my case i get 3 contours and i show them by drawing rectangles around them, what i want to do is drawing a <b>rectangle</b> around all these 3 contour rectangles. <b>like</b> it will be a larger <b>rectangle</b>, containing 3 detected rectangles.", "dateLastCrawled": "2022-01-24T20:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "I&#39;ve got a bunch of different-colored circles in an image. How do I ...", "url": "https://www.quora.com/Ive-got-a-bunch-of-different-colored-circles-in-an-image-How-do-I-identify-each-of-those-circles-and-draw-a-bounding-box-using-a-mask-image-of-a-black-circle-Any-psuedo-algorithm-is-welcome", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Ive-got-a-bunch-of-different-colored-circles-in-an-image-How-do...", "snippet": "Answer (1 of 5): Are they overlapping? Can there be circles contained within each other? How were they acquired: were they images on an RGB camera (3-colour senor)? The first thing I might try to do might be use a Hough transform to detect circles. However, there needs to be segments of the arc ...", "dateLastCrawled": "2022-01-18T11:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bounding</b> Boxes, Segmentations and Object Coordinates: How Important Is ...", "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Behl_Bounding_Boxes_Segmentations_ICCV_2017_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_ICCV_2017/<b>papers</b>/Behl_<b>Bounding</b>_<b>Box</b>es...", "snippet": "in one <b>frame</b> should be mapped to an instance in the other <b>frame</b>. Furthermore, all pixels within an instance should move as one rigid entity. To obtain the <b>bounding</b> <b>box</b> or segmentation masks, we utilize an existing state-of-the-art approach - the multi-task network cascade (MNC) from Dai et al. [6]. In contrast", "dateLastCrawled": "2021-12-26T15:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bounding</b> Boxes - DataGenetics", "url": "https://www.datagenetics.com/blog/march12014/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.datagenetics.com/blog/march12014/index.html", "snippet": "The <b>bounding</b> <b>box</b> it produces is orthogonal to the axes and this has many great and useful properties (especially in computers, whose displays are typically mapped using a Cartesian grid). A very fast, first order \u2018hit-detection\u2019 algorithm employs this strategy. If you want to see if a point is, potentially, inside a complex shape then you can quickly check the shape\u2019s <b>bounding</b> <b>box</b>. If the test coordinate in question is outside the rectangular <b>bounding</b> <b>box</b> it is impossible for that ...", "dateLastCrawled": "2022-02-01T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bounding</b> Boxes, Segmentations and Object Coordinates: How Important is ...", "url": "https://hci.iwr.uni-heidelberg.de/vislearn/HTML/publications/papers/2017/instancesceneflow.pdf", "isFamilyFriendly": true, "displayUrl": "https://hci.iwr.uni-heidelberg.de/vislearn/HTML/publications/<b>papers</b>/2017/instancescene...", "snippet": "the front wheel in the \ufb01rst <b>frame</b> appears <b>similar</b> to the back 1. wheel in the second <b>frame</b>, resulting in wrong predictions. Furthermore, the small amount of texture and the re\ufb02ective car surface complicate the matching task. In this <b>paper</b>, we propose to exploit recognition to facil-itate this problem. In particular, we investigate the bene\ufb01ts of semantic grouping and \ufb01ne-grained geometric recogni-tion for this task as illustrated in Fig. 1. We will formu-late the output of the ...", "dateLastCrawled": "2021-08-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Introduction to Acceleration Structures (<b>Bounding</b> Volume)", "url": "https://www.scratchapixel.com/lessons/advanced-rendering/introduction-acceleration-structure/bounding-volume", "isFamilyFriendly": true, "displayUrl": "https://www.scratchapixel.com/.../introduction-acceleration-structure/<b>bounding</b>-volume", "snippet": "The <b>bounding box</b> of an object is usually computed when the object is built (for instance in the constructor of the polygon mesh class) and stored in a member variable of the object&#39;s class (each primitive type may require a different method to compute this <b>bounding box</b>. The <b>bounding</b> volume of a quadratic sphere for instance can be computed from its radius). The following code snippet from the ray tracer shows how we compute the <b>bounding box</b> of a polygon object (line 13). The bbox variable is ...", "dateLastCrawled": "2022-02-03T05:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "3D <b>Object detection using Deep Learning</b> | by Ganesh Prasanna | Medium", "url": "https://medium.com/@ganeshprasanna/3d-object-detection-using-deep-learning-166c557cf2ca", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@ganeshprasanna/3d-<b>object-detection-using-deep-learning</b>-166c557cf2ca", "snippet": "The 8 features listed below are used by many algorithm for object detection : 1) Class - (Car, Pedestrian, Cyclist, etc.) at index 1. 2) height of <b>bounding</b> <b>box</b> at index 9. 3) width of <b>bounding</b> <b>box</b> ...", "dateLastCrawled": "2022-01-18T17:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Mask R-CNN \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1703.06870/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/<b>papers</b>/1703.06870", "snippet": "We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for <b>bounding</b> <b>box</b> recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 ...", "dateLastCrawled": "2022-01-29T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Box059: Mining for Words \u2013 The <b>Bounding</b> <b>Box</b>", "url": "https://blog.tobiasrevell.com/2022/01/03/box059-mining-for-words/", "isFamilyFriendly": true, "displayUrl": "https://blog.tobiasrevell.com/2022/01/03/<b>box</b>059-mining-for-words", "snippet": "The <b>Bounding</b> <b>Box</b>. Navigation #247 (no title) Box059: Mining for Words 03.01.22 04.01.22. DS059: A large, steel gyroscope. At its centre is a disc with a miniature desert mountain landscape on it. On one of the rings rotating are a sun and moon made of neon that illuminate the landscape as the pass over. Around the gyroscope are two chairs and some file boxes. I\u2019ve been very much a \u2018fairweather\u2019 cyclist this winter. I failed to pick up my winter mojo so whereas last year I was giddily ...", "dateLastCrawled": "2022-02-02T18:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "I&#39;ve got a bunch of different-colored circles in an image. How do I ...", "url": "https://www.quora.com/Ive-got-a-bunch-of-different-colored-circles-in-an-image-How-do-I-identify-each-of-those-circles-and-draw-a-bounding-box-using-a-mask-image-of-a-black-circle-Any-psuedo-algorithm-is-welcome", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Ive-got-a-bunch-of-different-colored-circles-in-an-image-How-do...", "snippet": "Answer (1 of 5): Are they overlapping? Can there be circles contained within each other? How were they acquired: were they images on an RGB camera (3-colour senor)? The first thing I might try to do might be use a Hough transform to detect circles. However, there needs to be segments of the arc ...", "dateLastCrawled": "2022-01-18T11:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Using OpenCV to detect clothing buttons <b>on a piece</b> <b>of paper</b>", "url": "https://stackoverflow.com/questions/3252129/using-opencv-to-detect-clothing-buttons-on-a-piece-of-paper", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/3252129", "snippet": "check that the area of an ellipse PIab <b>is similar</b> to the Area of the contour using cvContourArea and also that both axis are <b>similar</b> a = b. (this will leave only circles) then you can do whatever you need. printContour, using cvPrintContour, use cvMinAreaRect2 to get button <b>bounding</b> <b>box</b>, etc", "dateLastCrawled": "2022-01-27T20:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "python - how to use a handwritten T shape which is on a body part as ...", "url": "https://stackoverflow.com/questions/55770089/how-to-use-a-handwritten-t-shape-which-is-on-a-body-part-as-the-target-and-paste", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/55770089", "snippet": "Firstly, you need to detect the <b>piece</b> <b>of paper</b>, as you know its color and aspect ration, you may use RGB/HSV thresholding for segmentation. You may also try using Deep/Machine Learning (some <b>similar</b> strategy like in R-CNN, HOG-SVM etc.), but it will take time. Then, you can use findContours() function from OpenCV to get the largest object. From ...", "dateLastCrawled": "2022-01-14T21:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to find upper left most corner of my Contour <b>Bounding</b> <b>Box</b> in Python ...", "url": "https://stackoverflow.com/questions/49315960/how-to-find-upper-left-most-corner-of-my-contour-bounding-box-in-python-opencv", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/49315960", "snippet": "What I&#39;m doing: I have a robotic arm and I want to find x,y coordinates for objects <b>on a piece</b> <b>of paper</b>.. I am able to find a contour of a sheet <b>of paper</b> and get its dimensions (h,w). I want the coordinates of my upper left corner so when I place objects onto my <b>piece</b> <b>of paper</b> I <b>can</b> get image coordinates relative to that point.", "dateLastCrawled": "2022-01-25T03:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "YOLO <b>object detection with OpenCV</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2018/11/12/yolo-<b>object-detection-with-opencv</b>", "snippet": "Scale <b>bounding</b> <b>box</b> coordinates so we <b>can</b> display them properly on our original image (Line 81). Extract coordinates and dimensions of the <b>bounding</b> <b>box</b> (Line 82). YOLO returns <b>bounding</b> <b>box</b> coordinates in the form: (centerX, centerY, width, and height). Use this information to derive the top-left (x, y)-coordinates of the <b>bounding</b> <b>box</b> (Lines 86 ...", "dateLastCrawled": "2022-02-02T04:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "c++ - Rectangle detection / tracking using <b>OpenCV</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/44522012/rectangle-detection-tracking-using-opencv", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/44522012", "snippet": "Grab a <b>frame</b>; Convert that <b>frame</b> to HSV; Binarize it (using the color that the user selected and the thresholds from the sliders) Apply morph ops (erode and dilate) Find contours; Get the smallest oriented bouding <b>box</b> of each contour; Take the largest of those <b>bounding</b> boxes as result; As you may noticed, I don&#39;t make an advantage of the knowledge about the actual shape of the <b>paper</b>, simply because I don&#39;t know how to use this information properly. I&#39;ve also <b>thought</b> about using the tracking ...", "dateLastCrawled": "2022-01-27T18:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "200 Practice <b>Questions</b> For Azure <b>AI-900</b> Fundamentals Exam | by Bhargav ...", "url": "https://medium.com/bb-tutorials-and-thoughts/200-practice-questions-for-azure-ai-900-fundamentals-exam-e981d28ce91d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/bb-tutorials-and-<b>thoughts</b>/200-practice-<b>questions</b>-for-azure-<b>ai-900</b>...", "snippet": "The probability score of the object classification (which you <b>can</b> interpret as the confidence of the predicted class being correct) The coordinates of a <b>bounding</b> <b>box</b> for each object. 95.", "dateLastCrawled": "2022-01-30T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Gentle Introduction to Object Recognition With Deep Learning", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/object-recognition-with-deep-learnin", "snippet": "For example, an image may be divided into a 7\u00d77 grid and each cell in the grid may predict 2 <b>bounding</b> boxes, resulting in 94 proposed <b>bounding</b> <b>box</b> predictions. The class probabilities map and the <b>bounding</b> boxes with confidences are then combined into a final set of <b>bounding</b> boxes and class labels. The image taken from the <b>paper</b> below summarizes the two outputs of the model.", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Fast Oriented Bounding Box Optimization on the Rotation Group</b> SO(3, R)", "url": "https://www.researchgate.net/publication/254006485_Fast_Oriented_Bounding_Box_Optimization_on_the_Rotation_Group_SO3_R", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/254006485_Fast_Oriented_<b>Bounding</b>_<b>Box</b>...", "snippet": "This part is selected through a <b>bounding</b> <b>box</b> selection mechanism, and the user <b>can</b> track the change-sets of the selected mesh subset, i.e., the user <b>can</b> see the difference between any consecutive ...", "dateLastCrawled": "2021-11-07T10:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Measuring size of objects in an image with OpenCV - You <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv", "snippet": "Now that we have our <b>bounding</b> <b>box</b> ordered, we <b>can</b> compute a series of midpoints: ... but you might be running into issues with I/O latency. I would also make sure that the camera you are using <b>can</b> read frames at a <b>frame</b> rate high enough to ensure you <b>can</b> (accurately) measure your objects. To reduce I/O latency, take a look at this tutorial. Jeff. July 28, 2017 at 4:13 pm. Hi Adrian, Awesome post \u2013 everything that I\u2019ve read on your blob has been very clear and useful! Super impressed \ud83d\ude42 ...", "dateLastCrawled": "2022-02-02T15:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Training EfficientDet Object Detection Model with</b> a Custom Dataset", "url": "https://blog.roboflow.com/training-efficientdet-object-detection-model-with-a-custom-dataset/", "isFamilyFriendly": true, "displayUrl": "https://blog.roboflow.com/<b>training-efficientdet-object-detection-model-with</b>-a-custom...", "snippet": "In this post, we explore a PyTorch implementation of EfficientDet on a custom dataset, demonstrating how you <b>can</b> do the same for your own dataset. Our Example Dataset. Our dataset contains 292 images of chess pieces on a chess board. Each chess <b>piece</b> is labeled with a <b>bounding</b> <b>box</b> describing the pieces class {white-knight, white-pawn, black ...", "dateLastCrawled": "2022-02-03T13:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Snapchat</b>\u2019s Filters: How computer vision recognizes your face | by James ...", "url": "https://medium.com/swlh/snapchats-filters-how-computer-vision-recognizes-your-face-9ce536206fa7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>snapchat</b>s-filters-how-computer-vision-recognizes-your-face-9ce...", "snippet": "The first step works like this: Given an input image or video <b>frame</b>, find out all present human faces and output their <b>bounding</b> <b>box</b> (i.e. The rectangle coordinates in the form: X , Y , Width ...", "dateLastCrawled": "2022-01-24T10:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>2D animation</b> - Animation Revolution - Baianat", "url": "https://www.baianat.com/books/animation-revolution/2d-animation", "isFamilyFriendly": true, "displayUrl": "https://www.baianat.com/books/animation-revolution/<b>2d-animation</b>", "snippet": "As you animate you may find that you need to adjust your timing, so a Key drawing you <b>thought</b> was going to hit at <b>frame</b> 35 actually ends up hitting on <b>frame</b> 39, and you will adjust the numbering on the drawings and the Ex-sheet. This is a good reason to use a light touch when first numbering your drawings and ex-sheet, so if you have to change the numbering a lot later on you won&#39;t have to spend a lot of effort erasing the numbers, if you kept them lightly penciled to begin with. Later when ...", "dateLastCrawled": "2022-02-03T05:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bounding</b> Boxes, Segmentations and Object Coordinates: How Important is ...", "url": "https://hci.iwr.uni-heidelberg.de/vislearn/HTML/publications/papers/2017/instancesceneflow.pdf", "isFamilyFriendly": true, "displayUrl": "https://hci.iwr.uni-heidelberg.de/vislearn/HTML/publications/<b>papers</b>/2017/instancescene...", "snippet": "In this <b>paper</b>, we focus on 3D scene \ufb02ow estimation for autonomous driving scenarios. More speci\ufb01cally, given two consecutive stereo images we want to predict the 3D mo-tion of every pixel. With the advent of challenging real-world benchmarks, such as the KITTI 2012 [10] and KITTI Joint \ufb01rst authors with equal contribution. 2D <b>Bounding</b> <b>Box</b> 2D Instance Segmentation 3D Object Coordinates Figure 1: Motivation. Top: Two consecutive frames (over-laid) from the KITTI 2015 scene \ufb02ow dataset ...", "dateLastCrawled": "2021-08-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Introduction to Acceleration Structures (<b>Bounding</b> Volume)", "url": "https://www.scratchapixel.com/lessons/advanced-rendering/introduction-acceleration-structure/bounding-volume", "isFamilyFriendly": true, "displayUrl": "https://www.scratchapixel.com/.../introduction-acceleration-structure/<b>bounding</b>-volume", "snippet": "The <b>bounding box</b> of an object is usually computed when the object is built (for instance in the constructor of the polygon mesh class) and stored in a member variable of the object&#39;s class (each primitive type may require a different method to compute this <b>bounding box</b>. The <b>bounding</b> volume of a quadratic sphere for instance <b>can</b> be computed from its radius). The following code snippet from the ray tracer shows how we compute the <b>bounding box</b> of a polygon object (line 13). The bbox variable is ...", "dateLastCrawled": "2022-02-03T05:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "BBregLocator: A Vulnerability Detection System Based on <b>Bounding</b> <b>Box</b> ...", "url": "https://www.researchgate.net/publication/353698245_BBregLocator_A_Vulnerability_Detection_System_Based_on_Bounding_Box_Regression", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353698245_BBregLocator_A_Vulnerability...", "snippet": "In this <b>paper</b>, we present a vulnerability detector that <b>can</b> simultaneously achieve a high detection capability and a high locating precision, dubbed Vulnerability Deep learning-based Locator ...", "dateLastCrawled": "2022-01-05T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Measuring size of objects in an image with OpenCV - You <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv", "snippet": "Measuring the size of an object (or objects) in an image has been a heavily requested tutorial on the <b>PyImageSearch</b> blog for some time now \u2014 and it feels great to get this post online and share it with you. Today\u2019s post is the second in a three part series on measuring the size of objects in an image and computing the distances between them.. Last week, we learned an important technique: how reliably order a set of rotated <b>bounding</b> <b>box</b> coordinates in a top-left, top-right, bottom-right ...", "dateLastCrawled": "2022-02-02T15:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Deep Learning (4/5): Convolutional Neural Networks", "url": "https://tiefenauer.github.io/ml/deep-learning/4", "isFamilyFriendly": true, "displayUrl": "https://tiefenauer.github.io/ml/deep-learning/4", "snippet": "An anchor <b>box</b> corresponds to a <b>bounding</b> <b>box</b> for a certain object that overlaps the <b>bounding</b> <b>box</b> of another object. An object is assigned to the anchor <b>box</b> with the highes IoU value (whereas previously the object was assigned to the grid cell that contained the object\u2019s midpoint). To predict more than one object per cell, the label-vectors need to be stacked on top of each other in the output. The following picture illustrates this for two anchor boxes (i.e. a YOLO-NN that <b>can</b> detect two ...", "dateLastCrawled": "2021-11-25T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Object Detection Using OpenCV</b> YOLO | Great Learning", "url": "https://www.mygreatlearning.com/blog/yolo-object-detection-using-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreatlearning.com/blog/yolo-<b>object-detection-using-opencv</b>", "snippet": "Coordinates of B <b>bounding</b> boxes -YOLO predicts 4 coordinates for each <b>bounding</b> <b>box</b> (bx,by,bw,bh) with respect to the corresponding grid cell. Here bx, by are the x and y coordinates of the midpoint of the object with respect to this grid. The value of bh is the ratio of the height of the <b>bounding</b> <b>box</b> to the height of the corresponding grid cell and bw is the ratio of the width of the <b>bounding</b> <b>box</b> to the width of the grid cell.", "dateLastCrawled": "2022-02-03T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "YOLO <b>object detection with OpenCV</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2018/11/12/yolo-<b>object-detection-with-opencv</b>", "snippet": "Scale <b>bounding</b> <b>box</b> coordinates so we <b>can</b> display them properly on our original image (Line 81). Extract coordinates and dimensions of the <b>bounding</b> <b>box</b> (Line 82). YOLO returns <b>bounding</b> <b>box</b> coordinates in the form: (centerX, centerY, width, and height). Use this information to derive the top-left (x, y)-coordinates of the <b>bounding</b> <b>box</b> (Lines 86 ...", "dateLastCrawled": "2022-02-02T04:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) Segmentation and Analysis of a Sketched Truss <b>Frame</b> Using ...", "url": "https://www.researchgate.net/publication/305398093_Segmentation_and_Analysis_of_a_Sketched_Truss_Frame_Using_Morphological_Image_Processing_Techniques", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/305398093_Segmentation_and_Analysis_of_a...", "snippet": "This <b>paper</b> is dedicated to the development of a methodology to automate analysis of a hand sketched or computer generated truss <b>frame</b> drawn <b>on a piece</b> <b>of paper</b>. First, we focus on the segmentation ...", "dateLastCrawled": "2021-12-20T10:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "I&#39;ve got a bunch of different-colored circles in an image. How do I ...", "url": "https://www.quora.com/Ive-got-a-bunch-of-different-colored-circles-in-an-image-How-do-I-identify-each-of-those-circles-and-draw-a-bounding-box-using-a-mask-image-of-a-black-circle-Any-psuedo-algorithm-is-welcome", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Ive-got-a-bunch-of-different-colored-circles-in-an-image-How-do...", "snippet": "Answer (1 of 5): Are they overlapping? <b>Can</b> there be circles contained within each other? How were they acquired: were they images on an RGB camera (3-colour senor)? The first thing I might try to do might be use a Hough transform to detect circles. However, there needs to be segments of the arc ...", "dateLastCrawled": "2022-01-18T11:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Mask R-CNN \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1703.06870/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/<b>papers</b>/1703.06870", "snippet": "Our models <b>can</b> run at about 200ms per <b>frame</b> on a GPU, and training on COCO takes one to two days on a single 8-GPU machine. We believe the fast train and test speeds, together with the framework\u2019s flexibility and accuracy, will benefit and ease future research on instance segmentation. Finally, we showcase the generality of our framework via the task of human pose estimation on the COCO keypoint dataset [22]. By viewing each keypoint as a one-hot binary mask, with minimal modification Mask ...", "dateLastCrawled": "2022-01-29T10:04:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "13.3. Object Detection and <b>Bounding</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0 ...", "url": "https://d2l.ai/chapter_computer-vision/bounding-box.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>bounding-box</b>.html", "snippet": "13.3.1. <b>Bounding</b> Boxes\u00b6. In object detection, we usually use a <b>bounding box</b> to describe the spatial location of an object. The <b>bounding box</b> is rectangular, which is determined by the \\(x\\) and \\(y\\) coordinates of the upper-left corner of the rectangle and the such coordinates of the lower-right corner. Another commonly used <b>bounding box</b> representation is the \\((x, y)\\)-axis coordinates of the <b>bounding box</b> center, and the width and height of the <b>box</b>. Here we define functions to convert ...", "dateLastCrawled": "2022-01-30T11:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "5 Main Types of <b>Machine</b> <b>Learning</b> Systems | by Jean de Dieu Nyandwi | Medium", "url": "https://jeande.medium.com/5-main-types-of-machine-learning-systems-fb07b0cc3d35", "isFamilyFriendly": true, "displayUrl": "https://jeande.medium.com/5-main-types-of-<b>machine</b>-<b>learning</b>-systems-fb07b0cc3d35", "snippet": "Semi-supervised <b>learning</b> is most notable in problems that involve working with massive datasets like internet image searches, image and audio recognition, and webpages classification. 4. Self-supervised <b>learning</b>. Self-supervised <b>learning</b> is one of the most exciting types of <b>machine</b> <b>learning</b> that is most applicable in computer vision and robotics.", "dateLastCrawled": "2022-01-25T04:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "In <b>machine-learning</b> image-detection tasks, IoU is used to measure the accuracy of the model\u2019s predicted <b>bounding</b> <b>box</b> with respect to the ground-truth <b>bounding</b> <b>box</b>. In this case, the IoU for the two boxes is the ratio between the overlapping area and the total area, and its value ranges from 0 (no overlap of predicted <b>bounding</b> <b>box</b> and ground-truth <b>bounding</b> <b>box</b>) to 1 (predicted <b>bounding</b> <b>box</b> and ground-truth <b>bounding</b> <b>box</b> have the exact same coordinates).", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "13.4. <b>Anchor</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/anchor.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>anchor</b>.html", "snippet": "In order to train an object detection model, we need class and offset labels for each <b>anchor</b> <b>box</b>, where the former is the class of the object relevant to the <b>anchor</b> <b>box</b> and the latter is the offset of the ground-truth <b>bounding</b> <b>box</b> relative to the <b>anchor</b> <b>box</b>. During the prediction, for each image we generate multiple <b>anchor</b> boxes, predict classes and offsets for all the <b>anchor</b> boxes, adjust their positions according to the predicted offsets to obtain the predicted <b>bounding</b> boxes, and finally ...", "dateLastCrawled": "2022-01-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> in <b>Computer Vision</b> - Princeton University", "url": "https://www.cs.princeton.edu/courses/archive/spring07/cos424/lectures/li-guest-lecture.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.princeton.edu/courses/archive/spring07/cos424/lectures/li-guest-lecture.pdf", "snippet": "<b>Machine</b> <b>learning</b> Speech Information retrieval Maths Computer Science Information Engineering Physics Biology Robotics Cognitive sciences Psychology. Quiz? What about this? A picture is worth a thousand words.--- Confucius or Printers\u2019 Ink Ad (1921) horizontal lines vertical blue on the top porous oblique white shadow to the left textured large green patches A picture is worth a thousand words.--- Confucius or Printers\u2019 Ink Ad (1921) A picture is worth a thousand words.--- Confucius or ...", "dateLastCrawled": "2022-01-29T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Deep-<b>Learning</b> Model with <b>Task-Specific Bounding Box Regressors</b> and ...", "url": "https://www.mdpi.com/1424-8220/20/18/5269/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/20/18/5269/htm", "snippet": "This paper proposes a deep-<b>learning</b> model with <b>task-specific bounding box regressors</b> (TSBBRs) and conditional back-propagation mechanisms for detection of objects in motion for advanced driver assistance system (ADAS) applications. The proposed model separates the object detection networks for objects of different sizes and applies the proposed algorithm to achieve better detection results for both larger and tinier objects. For larger objects, a neural network with a larger visual receptive ...", "dateLastCrawled": "2022-01-01T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning and its Applications</b> - SlideShare", "url": "https://www.slideshare.net/ganeshn9/machine-learning-and-its-applications-138639251", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ganeshn9/<b>machine-learning-and-its-applications</b>-138639251", "snippet": "Problem Solving Approach - Example \u2022 In a <b>machine</b> <b>learning</b> approach, we will divide problem in to two parts \u2013 object detection and object recognition \u2022 We will use an algorithm like <b>bounding</b> <b>box</b> detection as an example to scan through image and detect all objects then use object recognition algorithm to recognize relevant objects \u2022 When ...", "dateLastCrawled": "2022-01-30T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Why <b>Deep Learning</b> over Traditional <b>Machine</b> <b>Learning</b>? | by Sambit ...", "url": "https://towardsdatascience.com/why-deep-learning-is-needed-over-traditional-machine-learning-1b6a99177063", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/why-<b>deep-learning</b>-is-needed-over-traditional-<b>machine</b>...", "snippet": "In a simpler way, <b>Machine</b> <b>Learning</b> is set of algorithms that parse data, learn from them, and then apply what they\u2019ve learned to make ... \u201cThe <b>analogy</b> to <b>deep learning</b> is that the rocket engine is the <b>deep learning</b> models and the fuel is the huge amounts of data we can feed to these algorithms.\u201d <b>Deep Learning</b> requires high-end machines contrary to traditional <b>Machine</b> <b>Learning</b> algorithms. GPU has become a integral part now to execute any <b>Deep Learning</b> algorithm. In traditional <b>Machine</b> ...", "dateLastCrawled": "2022-01-30T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> <b>Learning</b> in Computer Vision", "url": "https://www.slideshare.net/butest/machine-learning-in-computer-vision-3860041", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/butest/<b>machine</b>-<b>learning</b>-in-computer-vision-3860041", "snippet": "<b>Learning</b> \u2013 Unclear how to model categories, so we learn what distinguishes them rather than manually specify the difference -- hence current interest in <b>machine</b> <b>learning</b>) \u2013 What are you maximizing? Likelihood (Gen.) or performances on train/validation set (Disc.) \u2013 Level of supervision \u2022 Manual segmentation; <b>bounding</b> <b>box</b>; image labels; noisy labels \u2013 Batch/incremental (on category and image level; user-feedback ) \u2013 Training images: \u2022 Issue of overfitting \u2022 Negative images for ...", "dateLastCrawled": "2022-01-28T18:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Deep <b>Learning</b>(.ai) <b>Dictionary</b> | by Jan Zawadzki | Towards Data Science", "url": "https://towardsdatascience.com/the-deep-learning-ai-dictionary-ade421df39e4", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-deep-<b>learning</b>-ai-<b>dictionary</b>-ade421df39e4", "snippet": "The ball rolling downhill is an <b>analogy</b> to gradient descent finding the local minimum. Neural Network \u2014 A <b>machine</b> <b>learning</b> model which transforms inputs. A vanilla neural network has an input, hidden, and output layer. Neural Networks have become the tool of choice for finding complex patterns in data. Non-Max Suppression \u2014 Algorithm used as a part of YOLO. It helps detect the correct <b>bounding</b> <b>box</b> of an object by eliminating overlapping <b>bounding</b> boxes with a lower confidence of ...", "dateLastCrawled": "2022-01-26T04:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Solved: <b>Checking in features</b> - <b>Autodesk</b> Community", "url": "https://forums.autodesk.com/t5/autocad-map-3d-forum/checking-in-features/td-p/6270481", "isFamilyFriendly": true, "displayUrl": "https://<b>forums.autodesk.com</b>/t5/autocad-map-3d-forum/<b>checking-in-features</b>/td-p/6270481", "snippet": "The &quot;<b>bounding box&quot; is like</b> a spatial filter defining the lef bottom and the right upper corner for legal objects. Are you working with UTM coordinates without zone information e.g. 32(N) and inside the shape it is define with 32(N)? 32(N) means a addition of 32000000 to the x-value. When that is true you are out of the bounding box and your ...", "dateLastCrawled": "2022-01-25T23:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "arXiv:2007.04499v1 [cs.RO] 9 Jul 2020", "url": "https://arxiv.org/pdf/2007.04499.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/2007.04499.pdf", "snippet": "contains the observed object, and the <b>bounding box is similar</b> for each valid object detected. However, for robotic grasping, there may be several methods to grasp an object. But it is essential to pick the one with the highest grasp success or with the most stable grasp, thus relying on <b>machine</b> <b>learning</b> techniques to \ufb01nd the best possible grasp. The use of convolutional neural networks is a popular technique used for <b>learning</b> features and visual models that uses a sliding window detection ...", "dateLastCrawled": "2020-07-12T09:31:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "YOLOv3 Tutorial: Understanding What is YOLOv3 and How it works?", "url": "https://bestinau.com.au/yolov3-architecture-best-model-in-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://bestinau.com.au/<b>yolov3-architecture-best-model-in-object-detection</b>", "snippet": "In many <b>machine</b> <b>learning</b> models (Logistic Regression, SVMs), in loss functions we have loss as well as a regularizer multiplied by. The job of this is to make a choice between minimizing loss and regularizing the model. Because of the scale of these two numbers being different, it is sensible to actually weigh them differently. Initially, they didn\u2019t do it and weren\u2019t getting good performance, but later thought that if they could create a weighted model, that might do the trick. These ...", "dateLastCrawled": "2022-02-02T01:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Using AI to Detect Social Distancing Violations - <b>Deep Learning Analytics</b>", "url": "https://deeplearninganalytics.org/using-ai-to-detect-social-distancing-violations/", "isFamilyFriendly": true, "displayUrl": "https://<b>deeplearninganalytics</b>.org/using-ai-to-detect-social-distancing-violations", "snippet": "Each track is basically a bounding box with an ID. So a <b>bounding box can be compared to</b> another bounding using the euclidean distance between them. Now we start our modeling. The code for that is shared below. This is the same code as in my Github. Modeling Social Distancing. The main steps that are run for every frame are: Compare the pixel distance between each track and every other track; If distance &lt; proximity threshold then, two people are too close to each other. So put safe =1 in the ...", "dateLastCrawled": "2022-01-31T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Using AI to Detect <b>Social Distancing</b> Violations | by Priya Dwivedi ...", "url": "https://medium.com/swlh/using-ai-to-detect-social-distancing-violations-4707301844be", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/using-ai-to-detect-<b>social-distancing</b>-violations-4707301844be", "snippet": "At Deep <b>Learning</b> Analytics, we are very passionate about using data science and <b>machine</b> <b>learning</b> to solve problems. Please reach out to us if you are looking for data science help in fighting this ...", "dateLastCrawled": "2022-01-28T16:11:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(bounding box)  is like +(frame on a piece of paper)", "+(bounding box) is similar to +(frame on a piece of paper)", "+(bounding box) can be thought of as +(frame on a piece of paper)", "+(bounding box) can be compared to +(frame on a piece of paper)", "machine learning +(bounding box AND analogy)", "machine learning +(\"bounding box is like\")", "machine learning +(\"bounding box is similar\")", "machine learning +(\"just as bounding box\")", "machine learning +(\"bounding box can be thought of as\")", "machine learning +(\"bounding box can be compared to\")"]}