{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Language</b> Translation with Machine Learning - DataFlair", "url": "https://data-flair.training/blogs/language-translation-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://data-flair.training/blogs/<b>language</b>-translation-ma", "snippet": "We all know about Google Translate which allows us to convert <b>from one</b> <b>language</b> <b>to another</b> and it\u2019s very useful for learning and understanding new languages. About <b>Language</b> Translator Project: In this machine learning project, we will develop a <b>Language</b> Translator App using a many-to-many <b>encoder</b>-decoder sequence model. We will train our model using LSTM which will convert English to French <b>language</b> where English will be input <b>text</b> and French will be the target <b>text</b>. For this, we will be ...", "dateLastCrawled": "2022-02-02T09:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Translation in NLP: Examples, Flow</b> &amp; Models | upGrad blog", "url": "https://www.upgrad.com/blog/machine-translation-in-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/machine-translation-in-nlp", "snippet": "Machine translation, also known as robotized interpretation, is the process in which computers or machines independently and quickly translate vast volumes of <b>text</b> from a particular source <b>language</b> to a target <b>language</b> without any effort put in by human beings. In other words, machine translation functions by employing an application that helps translate <b>text</b> <b>from one</b> input <b>language</b> <b>to another</b>. There are four different types of machine translation in NLP: statistical machine translation ...", "dateLastCrawled": "2022-02-02T16:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Transformers BART Model Explained for <b>Text</b> Summarization", "url": "https://www.projectpro.io/article/transformers-bart-model-explained/553", "isFamilyFriendly": true, "displayUrl": "https://www.projectpro.io/article/transformers-bart-model-explained/553", "snippet": "This type of model is relevant for machine translation (<b>translating</b> <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>), question-answering (producing answers for a given question on a specific corpus), <b>text</b> summarization (giving a summary of or paraphrasing a long <b>text</b> document), or sequence classification (categorizing input <b>text</b> sentences or tokens). <b>Another</b> task is sentence entailment which, given two or more sentences, evaluates whether the sentences are logical extensions or are logically related to a ...", "dateLastCrawled": "2022-02-03T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Neural Machine Translation Using Sequence to Sequence Model | by Aditya ...", "url": "https://medium.com/geekculture/neural-machine-translation-using-sequence-to-sequence-model-164a5905bcd7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/neural-machine-translation-using-sequence-to-sequence...", "snippet": "It is simply an automatic translation of <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>. In this article we will discuss little bit of <b>encoder</b>-decoder. Then we will walkthrough code of Neural machine translation.", "dateLastCrawled": "2022-02-03T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Facebook&#39;s TransCoder can Translate Code <b>from one</b> <b>Language</b> <b>to Another</b> ...", "url": "https://machinelearningknowledge.ai/facebooks-transcoder-can-translate-code-from-one-language-to-another/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningknowledge.ai/facebooks-transcoder-can-translate-code-<b>from-one</b>...", "snippet": "At the core, TransCoder leverages neural machine translation for <b>translating</b> <b>text</b> available in <b>one</b> natural <b>language</b> <b>to another</b>. Facebook trained the Deep Learning model on almost 3 million open-source projects. To achieve high-performance standards, the researchers\u2019 team at Facebook had built a dataset of 852 functions and related unit tests. This dataset was used as a validation set for the target languages which were Java, Python, and C++. Astonishingly, TransCoder\u2019s performance on the ...", "dateLastCrawled": "2021-12-22T02:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Machine Translation Models \u2014 NVIDIA NeMo 1.5.0 documentation", "url": "https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/v1.5.0/nlp/machine_translation.html", "isFamilyFriendly": true, "displayUrl": "https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/v1.5.0/nlp/machine...", "snippet": "Machine translation is the task of <b>translating</b> <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>. For example, from English to Spanish. Models are based on the Transformer sequence-to-sequence architecture For example, from English to Spanish.", "dateLastCrawled": "2022-01-30T15:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Tutorial on Sequential Machine Learning", "url": "https://analyticsindiamag.com/a-tutorial-on-sequential-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/a-tutorial-on-sequential-machine-learning", "snippet": "The goal is to create a computer program that can quickly and accurately translate a <b>text</b> <b>from one</b> <b>language</b> (source) into <b>another</b> <b>language</b> (target) (the target) The <b>encoder</b>-decoder model is the fundamental architecture utilized for MT using the neural network model: The <b>encoder</b> section summarizes the data in the source sentence. Based on the encoding, the decoder component generates the target-<b>language</b> output in a step-by-step manner. Basic Structure of Single-layer Autoencoder. The ...", "dateLastCrawled": "2022-02-02T16:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Natural <b>language</b> processing (NLP) and its use in machine translation", "url": "https://www.qblocks.cloud/blog/natural-language-processing-machine-translation", "isFamilyFriendly": true, "displayUrl": "https://www.qblocks.cloud/blog/natural-<b>language</b>-processing-machine-translation", "snippet": "Machine Translation as discussed earlier, translates the meaningful <b>text</b> of <b>one</b> <b>language</b> <b>to another</b> <b>language</b>, with no human involvement. Machine Translation is evaluated on the BLEU(BiLingual Evaluation Understudy) score. BLEU is a metric for automatically evaluating machine-translated <b>text</b>. The score is between 0-1, the higher the score the better the machine translation.", "dateLastCrawled": "2022-01-29T16:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Language</b> <b>Translation</b> with RNNs. Build a recurrent neural network (RNN ...", "url": "https://towardsdatascience.com/language-translation-with-rnns-d84d43b40571", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>language</b>-<b>translation</b>-with-rnns-d84d43b40571", "snippet": "The ability to communicate with <b>one</b> <b>another</b> is a fundamental part of being human. There are nearly 7,000 different languages worldwide. As our world becomes increasingly connected, <b>language</b> <b>translation</b> provides a critical cultural and economic bridge between people from different countries and ethnic groups. Some of the more obvious use-cases include: business: international trade, investment, contracts, finance; commerce: travel, purchase of foreign goods and services, customer support ...", "dateLastCrawled": "2022-02-02T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "terminology - Is there a term for <b>translating</b> a word to a <b>language</b> that ...", "url": "https://linguistics.stackexchange.com/questions/36683/is-there-a-term-for-translating-a-word-to-a-language-that-has-a-different-alphab", "isFamilyFriendly": true, "displayUrl": "https://<b>linguistics.stackexchange</b>.com/questions/36683/is-there-a-term-for-<b>translating</b>...", "snippet": "No, there&#39;s no special word, except transliterate, which refers to makeshift spelling for sounds that don&#39;t exist in the target <b>language</b>.<b>Like</b> putting an H after P, T, \u1e6c, C, K in transliterating Hindi aspirated stops. Transliterating <b>from one</b> alphabet <b>to another</b> (<b>like</b> Russian to English) is hard enough, but transliterating from an abjad <b>like</b> Arabic or an abugida <b>like</b> Hindi to an alphabet <b>like</b> English is very complicated.", "dateLastCrawled": "2022-01-24T01:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Neural Machine Translation Using Sequence to Sequence Model | by Aditya ...", "url": "https://medium.com/geekculture/neural-machine-translation-using-sequence-to-sequence-model-164a5905bcd7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/neural-machine-translation-using-sequence-to-sequence...", "snippet": "It is simply an automatic translation of <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>. In this article we will discuss little bit of <b>encoder</b>-decoder. Then we will walkthrough code of Neural machine translation.", "dateLastCrawled": "2022-02-03T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Translation Models</b> \u2014 NVIDIA NeMo 1.6.1 documentation", "url": "https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/machine_translation.html", "isFamilyFriendly": true, "displayUrl": "https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/machine...", "snippet": "Machine translation is the task of <b>translating</b> <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>. For example, from English to Spanish. Models are based on the Transformer sequence-to-sequence architecture For example, from English to Spanish.", "dateLastCrawled": "2022-02-02T13:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Translation in NLP: Examples, Flow</b> &amp; Models | upGrad blog", "url": "https://www.upgrad.com/blog/machine-translation-in-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/machine-translation-in-nlp", "snippet": "Machine translation, also known as robotized interpretation, is the process in which computers or machines independently and quickly translate vast volumes of <b>text</b> from a particular source <b>language</b> to a target <b>language</b> without any effort put in by human beings. In other words, machine translation functions by employing an application that helps translate <b>text</b> <b>from one</b> input <b>language</b> <b>to another</b>. There are four different types of machine translation in NLP: statistical machine translation ...", "dateLastCrawled": "2022-02-02T16:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Transformers BART Model Explained for <b>Text</b> Summarization", "url": "https://www.projectpro.io/article/transformers-bart-model-explained/553", "isFamilyFriendly": true, "displayUrl": "https://www.projectpro.io/article/transformers-bart-model-explained/553", "snippet": "This type of model is relevant for machine translation (<b>translating</b> <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>), question-answering (producing answers for a given question on a specific corpus), <b>text</b> summarization (giving a summary of or paraphrasing a long <b>text</b> document), or sequence classification (categorizing input <b>text</b> sentences or tokens). <b>Another</b> task is sentence entailment which, given two or more sentences, evaluates whether the sentences are logical extensions or are logically related to a ...", "dateLastCrawled": "2022-02-03T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Machine Translation Models \u2014 NVIDIA NeMo 1.5.0 documentation", "url": "https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/v1.5.0/nlp/machine_translation.html", "isFamilyFriendly": true, "displayUrl": "https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/v1.5.0/nlp/machine...", "snippet": "Machine translation is the task of <b>translating</b> <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>. For example, from English to Spanish. Models are based on the Transformer sequence-to-sequence architecture For example, from English to Spanish.", "dateLastCrawled": "2022-01-30T15:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Natural <b>language</b> processing (NLP) and its use in machine translation", "url": "https://www.qblocks.cloud/blog/natural-language-processing-machine-translation", "isFamilyFriendly": true, "displayUrl": "https://www.qblocks.cloud/blog/natural-<b>language</b>-processing-machine-translation", "snippet": "Machine Translation: Machine Translation simply refers to converting <b>one</b> human <b>language</b> <b>to another</b> based on context, grammar, etc. Google translator is the widely used software by Google to translate human languages. If you are a traveler, you must have used the google translator app. 2. Spam Detection: Spam detection implies recognizing messages or emails by understanding content, context altogether and move those messages or emails into spam envelopes so that you can avoid content that you ...", "dateLastCrawled": "2022-01-29T16:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "NMT based <b>Similar</b> <b>Language</b> Translation for Hindi - Marathi", "url": "https://aclanthology.org/2020.wmt-1.48.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2020.wmt-1.48.pdf", "snippet": "<b>Language</b> Processing which aims to translate a <b>text</b> <b>from one</b> natural <b>language</b> (i.e Hindi) <b>to another</b> (i.e Marathi). The meaning of the resulting translated <b>text</b> must be fully preserved as the source <b>text</b> in the target <b>language</b>. For the translation task, different types of ma-chine translation systems have been developed and", "dateLastCrawled": "2022-01-28T19:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Encoder</b>-Decoder <b>Models for Natural Language Processing</b> | Baeldung on ...", "url": "https://www.baeldung.com/cs/nlp-encoder-decoder-models", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/cs/nlp-<b>encoder</b>-decoder-models", "snippet": "The <b>encoder</b> produced state representing the sentence in the source <b>language</b> (English): I love learning.. Then, the decoder unfolded that state into the target <b>language</b> (Spanish): Amo el aprendizaje.. could be considered a vectorized representation of the whole sequence or, in other words, we could use an <b>encoder</b> as a rough mean to obtain embeddings from a <b>text</b> of arbitrary length, but this is not the proper way to do it, as we\u2019ll see in <b>another</b> tutorial. 2.3.", "dateLastCrawled": "2022-02-03T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Language</b> <b>Translation</b> with RNNs. Build a recurrent neural network (RNN ...", "url": "https://towardsdatascience.com/language-translation-with-rnns-d84d43b40571", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>language</b>-<b>translation</b>-with-rnns-d84d43b40571", "snippet": "The pipeline accepts English <b>text</b> as input and returns the French <b>translation</b>. The goal is to achieve the highest <b>translation</b> accuracy possible. Why Machine <b>Translation</b> Matters . The ability to communicate with <b>one</b> <b>another</b> is a fundamental part of being human. There are nearly 7,000 different languages worldwide. As our world becomes increasingly connected, <b>language</b> <b>translation</b> provides a critical cultural and economic bridge between people from different countries and ethnic groups. Some of ...", "dateLastCrawled": "2022-02-02T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Is the race over for <b>Seq2Seq</b> models? | by Thushan Ganegedara | Towards ...", "url": "https://towardsdatascience.com/is-the-race-over-for-seq2seq-models-adef2b24841c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/is-the-race-over-for-<b>seq2seq</b>-models-adef2b24841c", "snippet": "<b>Text</b> summarization; Question answering; are few examples that can capitalize on such a model. These applications have a very unique problem formulation requiring the ability to map an arbitrarily long source sequence to an arbitrary-length target sequence. For example, if you imagine a English to French translation, there is no <b>one</b>-to-<b>one</b> mapping between words in two languages. Often, <b>translating</b> <b>from one</b> <b>language</b> <b>to another</b> requires learning copious complex features (<b>one</b>-to-many, many-to ...", "dateLastCrawled": "2022-02-02T02:57:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Speech to Speech Translation using <b>Encoder</b> Decoder Architecture", "url": "https://www.irjet.net/archives/V7/i3/IRJET-V7I3779.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.irjet.net/archives/V7/i3/IRJET-V7I3779.pdf", "snippet": "The <b>Encoder</b> network here outputs a <b>Thought</b> Vector which is an array of float point numbers roughly between -1 and 1 which summarizes the contents or the meaning or the intentions of the input <b>text</b>. We then use this <b>Thought</b> Vector as the initial state of the recurrent units in the decoder part of the network and then we start by inputting a marker which have taken \u201cssss because it does exist in vocabulary for the dataset and given this initial state which is the <b>thought</b> vector summarizing ...", "dateLastCrawled": "2021-08-26T19:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Word Level English <b>to Marathi Neural Machine Translation using</b> <b>Encoder</b> ...", "url": "https://towardsdatascience.com/word-level-english-to-marathi-neural-machine-translation-using-seq2seq-encoder-decoder-lstm-model-1a913f2dc4a7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/word-level-english-to-marathi-neural-machine...", "snippet": "We will take the problem of Machine Translation (<b>translating</b> a <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>, in our case from English to Marathi) as the running example in this blog. However the technical details apply to any sequence to sequence problem in general.", "dateLastCrawled": "2022-01-30T19:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Neural <b>Machine Translation</b>. <b>Machine Translation</b> using Recurrent\u2026 | by ...", "url": "https://towardsdatascience.com/neural-machine-translation-15ecf6b0b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-<b>machine-translation</b>-15ecf6b0b", "snippet": "<b>Machine Translation</b> (MT) is a subfield of computational linguistics that is focused on <b>translating</b> <b>t e xt</b> <b>from one</b> <b>language</b> <b>to another</b>. With the power of deep learning, Neural <b>Machine Translation</b> (NMT) has arisen as the most powerful algorithm to perform this task. While Google Translate is the leading industry example of NMT, tech companies all over the globe are going all in on NMT. This state-of-the-art algorithm is an application of deep learning in which massive datasets of translated ...", "dateLastCrawled": "2022-02-03T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Communication Elements 9 Elements of Communication</b> Process", "url": "https://newsmoor.com/communication-elements-9-components-of-basic-communication-process/", "isFamilyFriendly": true, "displayUrl": "https://newsmoor.com/communication-elements-9-comp<b>one</b>nts-of-basic-communication-process", "snippet": "Decoding is \u201cthe process of\u201d <b>translating</b> an encoded symbol into the ordinary understandable <b>language</b> in contrast to the <b>encoder</b>. In this process, the receiver converts the symbols into thoughts received from the sender. Decoding is the opposite process of encoding to get the meaning of the message. Example of Decoding in Communication. For example, Ela has transformed his <b>thought</b> into words to convey the message to her husband called encoding. At the same time, her husband converts those ...", "dateLastCrawled": "2022-02-02T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The 5 step <b>Language Translation Process</b> the professionals use", "url": "https://www.pactranz.com/language-translation-process/", "isFamilyFriendly": true, "displayUrl": "https://www.pactranz.com/<b>language-translation-process</b>", "snippet": "That\u2019s because <b>translating</b> is a mentally demanding task. So demanding that a thorough and disciplined translation process is needed to perform it well. The best-practice <b>language translation process</b> involves these 5 steps: 1. Scope out the <b>text</b> to be translated 2. Initial translation 3. Review the accuracy of the translation 4. Take a break 5. Refine translation wording Let\u2019s flesh what each step involves and why it\u2019s necessary. The multi-step translation process professional ...", "dateLastCrawled": "2022-02-03T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Transformers BART Model Explained for <b>Text</b> Summarization", "url": "https://www.projectpro.io/article/transformers-bart-model-explained/553", "isFamilyFriendly": true, "displayUrl": "https://www.projectpro.io/article/transformers-bart-model-explained/553", "snippet": "This means that a fine-tuned BART model <b>can</b> take a <b>text</b> sequence (for example, English) as input and produce a different <b>text</b> sequence at the output (for example, French). This type of model is relevant for machine translation (<b>translating</b> <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>), question-answering (producing answers for a given question on a specific corpus), <b>text</b> summarization (giving a summary of or paraphrasing a long <b>text</b> document), or sequence classification (categorizing input <b>text</b> ...", "dateLastCrawled": "2022-02-03T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Language</b> To <b>Language</b> Translation System Using LSTM", "url": "http://d.researchbib.com/f/enq3q3YaqupaAyYz9lMl9WFxSHD1ASY3A0LKEcLl9jMTLiMzyfMF9cnzS0L3AyZGxkZQDlZQVkYaOxMt.pdf", "isFamilyFriendly": true, "displayUrl": "d.researchbib.com/f/enq3q3YaqupaAyYz9lMl9WFxSHD1ASY3A0LKEcLl9jMTLiMzyfMF9cnzS0L3...", "snippet": "the <b>text</b> in <b>one</b> <b>language</b> into a <b>text</b> in <b>another</b>, and Speech Synthesis Technology, which converts the translated <b>text</b> into a speech. Furthermore, in the <b>Language</b> to <b>Language</b> Translation System, natural <b>language</b> understanding technology and user interface-related technology integrated with the User Interface play an important role. <b>Language</b> Translation Technology is currently available as a product that immediately translates multilingual conversations in free form. Continuous speech is ...", "dateLastCrawled": "2022-01-09T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "For AI, <b>translation is about</b> more than <b>language</b>", "url": "http://cachestocaches.com/2018/9/ai-translation-more-language/", "isFamilyFriendly": true, "displayUrl": "cachestocaches.com/2018/9/ai-translation-more-<b>language</b>", "snippet": "Translation is not at all limited to <b>language</b>: translation <b>from one</b> image &quot;<b>language</b>&quot; <b>to another</b> has been an area of active research in computer vision for the last few years. Though many problems in computer vision, like edge-detection, <b>can</b> <b>be thought</b> of as &quot;translation&quot;, only recently have modern deep learning techniques enabled image-to-image translation that are capable of relating color, texture, and even style between different groups of images. This more-modern notion of", "dateLastCrawled": "2021-12-07T20:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "MUCS@ - Machine Translation for Dravidian Languages using Stacked Long ...", "url": "https://aclanthology.org/2021.dravidianlangtech-1.50.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.dravidianlangtech-1.50.pdf", "snippet": "does translation of information <b>from one</b> natural <b>language</b> <b>to another</b> natural <b>language</b> by retaining the meaning of source context. Initially, MT task was treated with dictionary matching techniques and upgraded slowly to rule-based approaches (Dove et al.,2012). In order to address information acquisition, corpus-based methods have become popular and bilingual parallel corpora have been used to acquire knowledge for translation (Britz et al.,2017). Hybrid MT approaches have also be-come ...", "dateLastCrawled": "2021-09-20T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "GitHub - pandeyanuradha/Chatbot-for-mental-health", "url": "https://github.com/pandeyanuradha/Chatbot-for-mental-health", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/pandeyanuradha/Chatbot-for-mental-health", "snippet": "Machine Translation techniques are typically used in generative models, but instead of <b>translating</b> <b>from one</b> <b>language</b> <b>to another</b>, we &quot;translate&quot; from input to output (response). Generative models are used for the creation because they learn from scratch. Overview of the bots trained . The dataset was picked up from kaggle - Mental Health FAQ. This dataset consists of 98 FAQs about Mental Health. It consists of 3 columns - QuestionID, Questions, Answers. Note that for training the retrieval ...", "dateLastCrawled": "2022-01-29T15:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Translation</b>. A literature review on Statistical MT\u2026 | by Chao ...", "url": "https://towardsdatascience.com/machine-translation-b0f0dbcef47c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine-translation</b>-b0f0dbcef47c", "snippet": "<b>Machine Translation</b> is the task of <b>translating</b> a sentence <b>from one</b> <b>language</b> (the source <b>language</b>) to a sentence in <b>another</b> <b>language</b> (the target <b>language</b>). It is the sub-field of computational linguistics that aims to utilize computing devices to automatically translate <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>. <b>Machine Translation</b> research began in the early 1950s (Cold War period). During that time, there is a need to translate Russian documents into English. Since there are not many Russian ...", "dateLastCrawled": "2022-01-31T10:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Translation of Sign <b>Language</b> Glosses to <b>Text</b> Using Sequence-to-Sequence ...", "url": "http://xanthippi.ceid.upatras.gr/HealthSign/resources/Publications/sitis_paper_25_10.pdf", "isFamilyFriendly": true, "displayUrl": "xanthippi.ceid.upatras.gr/HealthSign/resources/Publications/sitis_paper_25_10.pdf", "snippet": "<b>Translating</b> <b>text</b> from a <b>language</b> <b>to another</b> using sequence-to-sequence (or <b>encoder</b>-decoder) models was \ufb01rstly proposed by Kalchbrenner and Blunsom [2], Sutskever et al. [3] and Cho et al. [4]. Let us explain how these models work and achieve translation. These models, try to learn-encode information of the whole input sequence and pass this encoded message to the decoder to produce the expected word in each time step. Having a sequence in the input and output, means that there is a ...", "dateLastCrawled": "2021-12-24T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Intuitive Deep Learning Part 3</b>: <b>RNNs for Natural Language Processing</b> ...", "url": "https://medium.com/intuitive-deep-learning/intuitive-deep-learning-part-3-rnns-for-natural-language-processing-4f4b0bcbee80", "isFamilyFriendly": true, "displayUrl": "https://medium.com/intuitive-deep-learning/<b>intuitive-deep-learning-part-3</b>-rnns-for...", "snippet": "How do we use Deep Learning to translate <b>text</b> <b>from one</b> <b>language</b> <b>to another</b>? Joseph Lee Wei En . Follow. Feb 2, 2019 \u00b7 15 min read. This is the fourth post in the introductory series of Intuitive ...", "dateLastCrawled": "2021-12-21T05:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Translation</b>: Everything You Need to Know", "url": "https://lilt.com/machine-translation", "isFamilyFriendly": true, "displayUrl": "https://lilt.com/<b>machine-translation</b>", "snippet": "Machine <b>language</b> translation is the process of converting <b>text</b> <b>from one</b> <b>language</b> <b>to another</b> through automatic translation software. A translation machine automatically translates complex expressions and idioms <b>from one</b> <b>language</b> <b>to another</b>. While the concept seems straightforward, its execution <b>can</b> be daunting due to differences in the syntax, semantics, and grammar of various languages around the world. Whether the translator is a human or a machine, the <b>text</b> needs to be broken down into ...", "dateLastCrawled": "2022-01-31T16:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "ICON2021 SSMT Tutorial", "url": "https://www.cfilt.iitb.ac.in/events/ICON2021_SSMT_Tutorial.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cfilt.iitb.ac.in/events/ICON2021_SSMT_Tutorial.pdf", "snippet": "\u2013 To translate speech input in <b>one</b> <b>language</b> into speech in <b>another</b> <b>language</b> without relying on the intermediate step of <b>text</b> generation. \u2022 Motivation \u2013 Lower computational costs and inference latency as <b>compared</b> to the cascaded systems. \u2013 To provide a translation support for languages that do not have a writing system. 14", "dateLastCrawled": "2022-01-23T01:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Encoder</b> and decoder with different number of layers. | Download ...", "url": "https://researchgate.net/figure/Encoder-and-decoder-with-different-number-of-layers_fig1_316821219", "isFamilyFriendly": true, "displayUrl": "https://researchgate.net/figure/<b>Encoder</b>-and-decoder-with-different-number-of-layers...", "snippet": "Transforming <b>text</b> <b>from one</b> <b>language</b> <b>to another</b> by using computer systems automatically or with little human interventions is known as Machine Translation System (MTS). Divergence among natural ...", "dateLastCrawled": "2021-09-23T18:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "mRASP2: multilingual NMT Advances via Contrastive Learning | by Xiao ...", "url": "https://medium.com/@panxiao1994/mrasp2-multilingual-nmt-advances-via-contrastive-learning-ac8c4c35d63", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@panxiao1994/mrasp2-multilingual-nmt-advances-via-contrastive...", "snippet": "\u201cThe translation process of <b>encoder</b>-decoder\u201d is very similar to that of human beings: for humans, <b>translating</b> a sentence <b>from one</b> <b>language</b> <b>to another</b> is to first understand the meaning of the ...", "dateLastCrawled": "2021-12-04T01:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "GitHub - <b>AmrHendy/programming-language-translator</b>: An easy way to use ...", "url": "https://github.com/AmrHendy/programming-language-translator", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/AmrHendy/programming-<b>language</b>-translator", "snippet": "TransCoder is inspired by other neural machine translation (NMT) systems that use deep-learning to translate <b>text</b> <b>from one</b> natural <b>language</b> <b>to another</b> and is trained only on monolingual source data. To compare the performance of the model, the Facebook team collected a validation set of 852 functions and associated unit tests in each of the system&#39;s target languages: Java, Python, and C++. <b>Compared</b> to existing systems, TransCoder performed better on this validation set than existing ...", "dateLastCrawled": "2022-02-01T01:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Machine translation of cortical activity to <b>text</b> with an <b>encoder</b> ...", "url": "https://www.nature.com/articles/s41593-020-0608-8", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41593-020-0608-8", "snippet": "a, WERs for <b>one</b> participant under the <b>encoder</b>\u2013decoder (first bar), four crippled variants thereof (bars 2\u20134 and 6) and a state-of-the-art sentence classifier based on ECoG-to-phoneme Viterbi ...", "dateLastCrawled": "2022-02-01T20:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Text</b> size in translation - W3", "url": "https://www.w3.org/International/articles/article-text-size", "isFamilyFriendly": true, "displayUrl": "https://www.w3.org/International/articles/article-<b>text</b>-size", "snippet": "When <b>text</b> is translated <b>from one</b> <b>language</b> <b>to another</b>, the length of the source and translated <b>text</b> is likely to be different. There are some ways in which these differences in length <b>can</b> be systematic. This article provides background material that will briefly explore some of these systematic differences. Other articles will deal with specific implications for the design of Web pages and proposed solutions. In general, the more flexibly you <b>can</b> design your layout, the better. Allow <b>text</b> to ...", "dateLastCrawled": "2022-02-01T12:24:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "9.6. <b>Encoder-Decoder</b> Architecture \u2014 Dive into Deep <b>Learning</b> 0.17.2 ...", "url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_recurrent-modern/<b>encoder-decoder</b>.html", "snippet": "<b>Encoder-Decoder</b> Architecture \u2014 Dive into Deep <b>Learning</b> 0.17.0 documentation. 9.6. <b>Encoder-Decoder</b> Architecture. As we have discussed in Section 9.5, <b>machine</b> translation is a major problem domain for sequence transduction models, whose input and output are both variable-length sequences. To handle this type of inputs and outputs, we can design ...", "dateLastCrawled": "2022-01-30T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Solving Word <b>Analogies: A Machine Learning Perspective</b> | Request PDF", "url": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_Machine_Learning_Perspective", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_<b>Machine</b>...", "snippet": "We introduce a supervised corpus-based <b>machine</b> <b>learning</b> algorithm for classifying analogous word pairs, and we show that it can solve multiple-choice SAT <b>analogy</b> questions, TOEFL synonym questions ...", "dateLastCrawled": "2021-10-16T21:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Usage: In fraud detection, use Auto-<b>Encoder</b> to compress all data to dense vector, then kNN is used to detect outliers; Reinforcement <b>Learning</b> Definitions. Reinforcement <b>learning</b> (RL) is an area of <b>machine</b> <b>learning</b> that focuses on how agent to act in an environment in order to maximize some given reward. Markov Decision Processes (MDPs) Components", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Titanic \u2014 Predicting Survival rates using <b>Machine</b> <b>Learning</b> | by Punith ...", "url": "https://medium.com/codex/titanic-predicting-survival-rates-using-machine-learning-3e83c56af29f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/codex/titanic-predicting-survival-rates-using-<b>machine</b>-<b>learning</b>-3e83...", "snippet": "Label <b>Encoder</b> refers to converting the labels into numeric form so as to convert it into the <b>machine</b> readable form. <b>Machine</b> <b>learning</b> algorithms can then decide in a better way on how those labels ...", "dateLastCrawled": "2022-02-03T01:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning to Generate Long-term Future via Hierarchical</b> Prediction", "url": "http://proceedings.mlr.press/v70/villegas17a.html", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v70/villegas17a.html", "snippet": "Our model is built with a combination of LSTM and <b>analogy</b> based <b>encoder</b>-decoder convolutional neural networks, which independently predict the video structure and generate the future frames, respectively. In experiments, our model is evaluated on the Human3.6M and Penn Action datasets on the task of long-term pixel-level video prediction of humans performing actions and demonstrate significantly better results than the state-of-the-art.} } Copy to Clipboard Download. Endnote %0 Conference ...", "dateLastCrawled": "2022-01-29T17:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The conceptual arithmetics of concepts | by Assaad MOAWAD | DataThings ...", "url": "https://medium.com/datathings/the-conceptual-arithmetics-of-concepts-369df29e4e0f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/datathings/the-conceptual-arithmetics-of-concepts-369df29e4e0f", "snippet": "<b>Machine</b> <b>learning</b> field is an amazing and very fast evolving domain. However, it is still hard to use it in its current state due to its cost and complexity. With time, we will have more and more ...", "dateLastCrawled": "2022-01-04T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Transformers in NLP: A beginner friendly explanation | Towards Data Science", "url": "https://towardsdatascience.com/transformers-89034557de14", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>transformer</b>s-89034557de14", "snippet": "<b>Encoder</b>-Decoder Attention: Attention between the input sequence and the output sequence. ... If you are looking for an <b>analogy</b> between self attention and attention, think of z serving the purpose of context vectors and not global alignment weights. The <b>Transformer</b>. \u26a0\ufe0f A word of caution: the contents of this image may appear exponentially more complicated than they are. We will break this scary beast down into small baby beasts and it will all make sense. (I promise #2) (left) The ...", "dateLastCrawled": "2022-02-02T13:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Gentle Introduction to <b>Long Short-Term Memory</b> Networks by the Experts", "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>long-short-term-memory</b>-networks...", "snippet": "<b>Long Short-Term Memory</b> (LSTM) networks are a type of recurrent neural network capable of <b>learning</b> order dependence in sequence prediction problems. This is a behavior required in complex problem domains like <b>machine</b> translation, speech recognition, and more. LSTMs are a complex area of deep <b>learning</b>. It can be hard to get your hands around what LSTMs are, and how terms like bidirectional", "dateLastCrawled": "2022-01-31T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - What is an <b>autoencoder</b>? - Data Science Stack Exchange", "url": "https://datascience.stackexchange.com/questions/80389/what-is-an-autoencoder", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/80389", "snippet": "I am a student and I am studying <b>machine</b> <b>learning</b>. I am focusing on deep generative models, and in particular to autoencoders and variational autoencoders (VAE).. I am trying to understand the concept, but I am having some problems. So far, I have understood that an <b>autoencoder</b> takes an input, for example an image, and wants to reduce this image into a latent space, which should contain the underlying features of the dataset, with an operation of encoding, then, with an operation of decoding ...", "dateLastCrawled": "2022-01-26T06:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Dive into Deep <b>Learning</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "http://d2l.ai/", "isFamilyFriendly": true, "displayUrl": "d2l.ai", "snippet": "[Dec 2021] We added a new option to run this book for free: check out SageMaker Studio Lab. [Jul 2021] We have improved the content and added TensorFlow implementations up to Chapter 11. To keep track of the latest updates, just follow D2L&#39;s open-source project. [Jan 2021] Check out the brand-new Chapter: Attention Mechanisms.We have also added PyTorch implementations.", "dateLastCrawled": "2022-01-30T00:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Gentle Introduction to <b>LSTM Autoencoders</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/lstm-autoencoders/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>lstm-autoencoders</b>", "snippet": "This is challenging because <b>machine</b> <b>learning</b> algorithms, and neural networks in particular, are designed to work with fixed length inputs. Another challenge with sequence data is that the temporal ordering of the observations can make it challenging to extract features suitable for use as input to supervised <b>learning</b> models, often requiring deep expertise in the domain or in the field of signal processing. Finally, many predictive modeling problems involving sequences require a prediction ...", "dateLastCrawled": "2022-02-03T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>machine</b> <b>learning</b> - <b>Parameters tuning for auto-encoders</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/235114/parameters-tuning-for-auto-encoders", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/235114/<b>parameters-tuning-for-auto-encoders</b>", "snippet": "Actually, the cost function of a sparse auto-<b>encoder is like</b>. I tested with my datasets, it seems that all these four parameters have impact on the final results. Are there any general rules of &#39;optimal&#39; settings of these four parameters? When I was using Support Vector <b>Machine</b> based classifier, there is a &#39;grid search&#39; method to optimize the two hyper-parameters of the SVM. Are there any similar method available for (sparse) auto-encoders? As far as I see, grid search is feasible to ...", "dateLastCrawled": "2022-01-28T00:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Summary of \u2014 <b>SegNet</b>: <b>A Deep Convolutional Encoder-Decoder</b> Architecture ...", "url": "https://towardsdatascience.com/summary-of-segnet-a-deep-convolutional-encoder-decoder-architecture-for-image-segmentation-75b2805d86f5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/summary-of-<b>segnet</b>-<b>a-deep-convolutional-encoder-decoder</b>...", "snippet": "Fig 3: Encoder architecture. Each <b>encoder is like</b> Fig 3. The novelty is in the subsampling stage, Max-pooling is used to achieve translation invariance over small spatial shifts in the image, combine that with Subsampling and it leads to each pixel governing a larger input image context (spatial window). These methods achieve better classification accuracy but reduce the feature map size, this leads to lossy image representation with blurred boundaries which is not ideal for segmentation ...", "dateLastCrawled": "2022-01-30T01:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>comprehensive novel model for network speech anomaly detection system</b> ...", "url": "https://link.springer.com/article/10.1007/s10772-020-09693-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10772-020-09693-z", "snippet": "Nowadays, <b>Machine</b> <b>learning</b> algorithms made a revolution in the area of human computer interaction and achieved significant advancement in imitating human brain exactly. Convolutional Neural Network (CNN) is a powerful <b>learning</b> algorithm in deep <b>learning</b> model for improving the <b>machine</b> <b>learning</b> ability in order to achieve high attack classification accuracy and low false alarm rate. In this article, an overview of deep <b>learning</b> methodologies for commonly used NIDS such as Auto Encoder (AE ...", "dateLastCrawled": "2022-01-12T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>machine</b> <b>learning</b> - What is the input for the prior model of VQ-VAE ...", "url": "https://ai.stackexchange.com/questions/17203/what-is-the-input-for-the-prior-model-of-vq-vae", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/17203", "snippet": "<b>machine</b>-<b>learning</b> generative-model variational-autoencoder. Share. Improve this question. Follow asked Dec 22 &#39;19 at 6:08. Diego Gomez Diego Gomez. 393 3 3 silver badges 9 9 bronze badges $\\endgroup$ Add a comment | 1 Answer Active Oldest Votes. 0 $\\begingroup$ Some notes about VQ-VAE: In the paper, they used PixelCNN to learn the prior. PixelCNN is trained on images. The discrete latent variables are just the indices of the embedding vectors. For example, you can put your embedding vectors ...", "dateLastCrawled": "2022-01-07T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "[2110.15444] 10 Security and Privacy Problems in Self-Supervised <b>Learning</b>", "url": "https://arxiv.org/abs/2110.15444", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2110.15444", "snippet": "The pre-trained <b>encoder is like</b> an &quot;operating system&quot; of the AI ecosystem. Specifically, the encoder can be used as a feature extractor for many downstream tasks with little or no labeled training data. Existing studies on self-supervised <b>learning</b> mainly focused on pre-training a better encoder to improve its performance on downstream tasks in non-adversarial settings, leaving its security and privacy in adversarial settings largely unexplored. A security or privacy issue of a pre-trained ...", "dateLastCrawled": "2021-12-28T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "ML-Leaks: Model <b>and Data Independent Membership Inference Attacks and</b> ...", "url": "https://www.researchgate.net/publication/348915478_ML-Leaks_Model_and_Data_Independent_Membership_Inference_Attacks_and_Defenses_on_Machine_Learning_Models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/348915478_ML-Leaks_Model_and_Data_Independent...", "snippet": "In particular, self-supervised <b>learning</b> aims to pre-train an encoder using a large amount of unlabeled data. The pre-trained <b>encoder is like</b> an &quot;operating system&quot; of the AI ecosystem. In ...", "dateLastCrawled": "2021-12-01T06:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[2110.15444v2] 10 Security and Privacy Problems in Self-Supervised <b>Learning</b>", "url": "https://arxiv.org/abs/2110.15444v2", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2110.15444v2", "snippet": "Self-supervised <b>learning</b> has achieved revolutionary progress in the past several years and is commonly believed to be a promising approach for general-purpose AI. In particular, self-supervised <b>learning</b> aims to pre-train an encoder using a large amount of unlabeled data. The pre-trained <b>encoder is like</b> an &quot;operating system&quot; of the AI ecosystem. Specifically, the encoder can be used as a feature extractor for many downstream tasks with little or no labeled training data. Existing studies on ...", "dateLastCrawled": "2021-11-08T02:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "probability - why a denoising auto-<b>encoder is like</b> performing ...", "url": "https://math.stackexchange.com/questions/2318301/why-a-denoising-auto-encoder-is-like-performing-stochastic-gradient-this-on-this", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/2318301", "snippet": "why a denoising auto-<b>encoder is like</b> performing stochastic gradient this on this expression? Ask Question Asked 4 years, 7 months ago. Active 4 years, 7 months ago. Viewed 665 times 2 1 $\\begingroup$ I was reading ...", "dateLastCrawled": "2022-01-24T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Convolutional Coding</b> - GaussianWaves", "url": "https://www.gaussianwaves.com/2010/06/convolutional-coding-2/", "isFamilyFriendly": true, "displayUrl": "https://www.gaussianwaves.com/2010/06/<b>convolutional-coding</b>-2", "snippet": "Till now the <b>encoder is like</b> a black box to us in the sense that we don\u2019t know how the memory elements are utilized to generate the output bits from the input. To fully understand the encoder structure we need something called \u201cgenerator polynomials\u201d that tell us how the memory elements are linked to achieve encoding. The generator polynomials for a specific convolutional encoder set (n,k,L) are usually found through simulation. The set (n,k,L) along with n generator polynomials ...", "dateLastCrawled": "2022-01-09T00:08:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Categorical Encoding with CatBoost Encoder</b> - GeeksforGeeks", "url": "https://www.geeksforgeeks.org/categorical-encoding-with-catboost-encoder/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/<b>categorical-encoding-with-catboost-encoder</b>", "snippet": "Many <b>machine</b> <b>learning</b> algorithms require data to be numeric. So, before training a model, we need to convert categorical data into numeric form. There are various categorical encoding methods available. Catboost is one of them. Catboost is a target-based categorical encoder. It is a supervised encoder that encodes categorical columns according to the target value. It supports binomial and continuous targets. Target encoding is a popular technique used for categorical encoding. It replaces a ...", "dateLastCrawled": "2022-02-03T12:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Implementing an <b>Autoencoder</b> in TensorFlow 2.0 | by Abien Fred Agarap ...", "url": "https://towardsdatascience.com/implementing-an-autoencoder-in-tensorflow-2-0-5e86126e9f7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/implementing-an-<b>autoencoder</b>-in-tensorflow-2-0-5e86126e9f7", "snippet": "We deal with huge amount of data in <b>machine</b> <b>learning</b> which naturally leads to more computations. However, we can also just pick the parts of the data that contribute the most to a model\u2019s <b>learning</b>, thus leading to less computations. The process of choosing the important parts of the data is known as feature selection, which is among the number of use cases for an <b>autoencoder</b>. But what exactly is an <b>autoencoder</b>? Well, let\u2019s first recall that a neural network is a computational model that ...", "dateLastCrawled": "2022-02-03T07:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "An Introduction to Generative <b>Deep Learning</b> | by Anil Chandra Naidu ...", "url": "https://medium.com/analytics-vidhya/an-introduction-to-generative-deep-learning-792e93d1c6d4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/an-introduction-to-generative-<b>deep-learning</b>-792e93...", "snippet": "An autoencoder is a type of ANN used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for ...", "dateLastCrawled": "2022-01-29T19:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Implementing an <b>Autoencoder</b> in TensorFlow 2.0 - Abien Fred Agarap", "url": "https://afagarap.github.io/2019/03/20/implementing-autoencoder-in-tensorflow-2.0.html", "isFamilyFriendly": true, "displayUrl": "https://afagarap.github.io/2019/03/20/implementing-<b>autoencoder</b>-in-tensorflow-2.0.html", "snippet": "Google announced a major upgrade on the world\u2019s most popular open-source <b>machine</b> <b>learning</b> library, TensorFlow, with a promise of focusing on simplicity and ease of use, eager execution, intuitive high-level APIs, and flexible model building on any platform. This post is a humble attempt to contribute to the body of working TensorFlow 2.0 examples. Specifically, we shall discuss the subclassing API implementation of an <b>autoencoder</b>. To install TensorFlow 2.0, use the following pip install ...", "dateLastCrawled": "2022-01-31T12:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Encoding</b> <b>categorical</b> variables - Stacked Turtles", "url": "https://kiwidamien.github.io/encoding-categorical-variables.html", "isFamilyFriendly": true, "displayUrl": "https://kiwidamien.github.io/<b>encoding</b>-<b>categorical</b>-variables.html", "snippet": "The way you encode <b>categorical</b> variables changes how effective your <b>machine</b> <b>learning</b> algorithm is. This article will go over some common <b>encoding</b> techniques, as well as their advantages and disadvantages. Some terminology. Levels: A levels of a non-numeric feature are the number of distinct values. The examples listed above are all examples of levels. The number of levels can vary wildly: the number of races for a patient is typically four (asian, black, hispanic, and white), the number of ...", "dateLastCrawled": "2022-01-30T23:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Network of Networks \u2014 A Neural-Symbolic Approach to Inverse-Graphics ...", "url": "https://towardsdatascience.com/network-of-networks-a-neural-symbolic-approach-to-inverse-graphics-acf3998ab3d", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/network-of-networks-a-neural-symbolic-approach-to...", "snippet": "The most common place one finds this kind of approach is in automated <b>machine</b> <b>learning</b> ... We assume, at least at the beginning, that our <b>encoder is similar</b> to a mean function. Obviously, with such a general mean function, any configuration of [Triangle] and [Square] would make a valid [House]. We don\u2019t want that. Let\u2019s again create an encoder-decoder pair with an agreement function. This time, we need to train the decoder instead of the encoder, but we\u2019ll train it on real houses. Now ...", "dateLastCrawled": "2022-01-31T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Hands-on with Feature Engineering Techniques</b>: Advanced Methods | by ...", "url": "https://heartbeat.comet.ml/hands-on-with-feature-engineering-advanced-methods-in-python-for-machine-learning-e05bf12da06a", "isFamilyFriendly": true, "displayUrl": "https://heartbeat.comet.ml/<b>hands-on-with-feature-engineering</b>-advanced-methods-in...", "snippet": "This post is a part of a series about <b>feature engineering techniques</b> for <b>machine</b> <b>learning</b> with Python. You can check out the rest of the articles: <b>Hands-on with Feature Engineering Techniques</b>: Broad Introduction. <b>Hands-on with Feature Engineering Techniques</b>: Variable Types. <b>Hands-on with Feature Engineering Techniques</b>: Common Issues in Datasets. <b>Hands-on with Feature Engineering Techniques</b>: Imputing Missing Values. <b>Hands-on with Feature Engineering Techniques</b>: Encoding Categorical Variables ...", "dateLastCrawled": "2022-02-01T14:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fully Convolutional Refined Auto-Encoding Generative Adversarial ...", "url": "https://becominghuman.ai/3d-multi-object-gan-7b7cee4abf80", "isFamilyFriendly": true, "displayUrl": "https://becominghuman.ai/<b>3d-multi-object-gan</b>-7b7cee4abf80", "snippet": "The basic architecture of <b>encoder is similar</b> to discriminator network of 3DGAN[1]. The difference is the last layer which is 1x1x1 fully convolution.-Generator. The basic architecture of generator is also similar to 3DGAN[1] as above figure. The difference is the last layer which has 12 channels and is activated by softmax. Also, the first layer of latent space is flatten. -Discriminator. The basic architecture of discriminator is also similar to 3DGAN[1]. The difference is the activation ...", "dateLastCrawled": "2022-01-26T00:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Frontiers | Deep <b>Learning</b> for Understanding <b>Satellite Imagery</b>: An ...", "url": "https://www.frontiersin.org/articles/10.3389/frai.2020.534696/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/frai.2020.534696", "snippet": "The left half of the network (<b>encoder) is similar</b> to a CNN, tasked with coming up with a low dimensional dense representation of the input, and the right side (decoder) then up-samples the learned feature representations to the same shape as the input. The shortcut connections let information flow from the encoder to the decoder and help the network keeping spatial information. As the work of Li et al. (2017) has impressively shown, U-Nets benefit greatly from a deeper model architecture. It ...", "dateLastCrawled": "2022-01-31T16:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Deep <b>learning for smart manufacturing: Methods and applications</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0278612518300037", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0278612518300037", "snippet": "Typical <b>machine</b> <b>learning</b> techniques are reviewed in [, ] for intelligent manufacturing, and their strengths and weaknesses are also discussed in a wide range of manufacturing applications. A comparative study of <b>machine</b> <b>learning</b> algorithms including Artificial Neural Network, Support Vector <b>Machine</b>, and Random Forest is performed for machining tool wear prediction. The schemes, techniques and paradigm of developing decision making support systems are reviewed for the monitoring of machining ...", "dateLastCrawled": "2022-02-02T21:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Encoder G25 G27 60 Slot - lgpfc.co.uk", "url": "https://lgpfc.co.uk/Encoder-G25-g27-60-Slot", "isFamilyFriendly": true, "displayUrl": "https://lgpfc.co.uk/Encoder-G25-g27-60-Slot", "snippet": "This gameplay is based on the traditional, casino-style slot <b>machine</b>. At the same time, each Online Encoder G25 G27 60 Slot Slots game will have its own unique set of individual rules and characteristics. Before playing any new Online Encoder G25 G27 60 Slot Slots game, you should become familiar with how the game works by trying the free demo version and having a close look at the game\u2019s paytable. Sports. Canada. The Canadian regulatory environment is <b>just as Encoder</b> G25 G27 60 Slot ...", "dateLastCrawled": "2022-01-16T21:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Google AI</b> Blog: July 2019", "url": "https://ai.googleblog.com/2019/07/", "isFamilyFriendly": true, "displayUrl": "https://ai.googleblog.com/2019/07", "snippet": "Such a multitask trained <b>encoder can be thought of as</b> <b>learning</b> a latent representation of the input that maintains information about the underlying linguistic content. Overview of the Parrotron model architecture. An input speech spectrogram is passed through encoder and decoder neural networks to generate an output spectrogram in a new voice. Case Studies To demonstrate a proof of concept, we worked with our fellow Google research scientist and mathematician Dimitri Kanevsky, who was born ...", "dateLastCrawled": "2022-01-29T22:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Google AI Blog: Parrotron: New Research into Improving Verbal ...", "url": "https://ai.googleblog.com/2019/07/parrotron-new-research-into-improving.html", "isFamilyFriendly": true, "displayUrl": "https://ai.googleblog.com/2019/07/parrotron-new-research-into-improving.html", "snippet": "Such a multitask trained <b>encoder can be thought of as</b> <b>learning</b> a latent representation of the input that maintains information about the underlying linguistic content. Overview of the Parrotron model architecture. An input speech spectrogram is passed through encoder and decoder neural networks to generate an output spectrogram in a new voice. Case Studies To demonstrate a proof of concept, we worked with our fellow Google research scientist and mathematician Dimitri Kanevsky, who was born ...", "dateLastCrawled": "2022-01-19T04:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Seq2seq and <b>Attention</b> - GitHub Pages", "url": "https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html", "isFamilyFriendly": true, "displayUrl": "https://lena-voita.github.io/nlp_course/seq2seq_and_<b>attention</b>.html", "snippet": "Intuitively, Transformer&#39;s <b>encoder can be thought of as</b> a sequence of reasoning steps (layers). At each step, tokens look at each other (this is where we need <b>attention</b> - self-<b>attention</b>), exchange information and try to understand each other better in the context of the whole sentence. This happens in several layers (e.g., 6).", "dateLastCrawled": "2022-02-02T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Using <b>Bidirectional</b> Generative Adversarial Networks to estimate Value ...", "url": "https://towardsdatascience.com/using-bidirectional-generative-adversarial-networks-to-estimate-value-at-risk-for-market-risk-c3dffbbde8dd", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-<b>bidirectional</b>-generative-adversarial-networks-to...", "snippet": "Note that given an optimal discriminator, the objective function of the generator and <b>encoder can be thought of as</b> that of an autoencoder, where the generator plays the role of a decoder. The objective function of the generator and encoder is simply to minimize the objective function of the discriminator, i.e., we have not explicitly specified the structure of the reconstruction loss as one might do so with an autoencoder. This implicit minimization of the reconstruction loss is yet another ...", "dateLastCrawled": "2022-01-31T10:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Distributed Coding</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/engineering/distributed-coding", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/engineering/<b>distributed-coding</b>", "snippet": "A Wyner\u2013Ziv <b>encoder can be thought of as</b> a quantizer followed by a Slepian\u2013Wolf encoder. In cases of images and video, existing <b>distributed coding</b> schemes add the Wyner\u2013Ziv encoder into the standard transform coding structure. As with the centralized case, a linear transform is independently applied to each image or video frame. Each transform coefficient is still treated independently, but it is fed into a Wyner\u2013Ziv coder instead of a scalar quantizer and an entropy coder. We refer ...", "dateLastCrawled": "2022-01-04T19:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Parrotron: An End-to-End Speech-to-Speech Conversion Model and its ...", "url": "https://deepai.org/publication/parrotron-an-end-to-end-speech-to-speech-conversion-model-and-its-applications-to-hearing-impaired-speech-and-speech-separation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/parrotron-an-end-to-end-speech-to-speech-conversion...", "snippet": "We apply more modern <b>machine</b> <b>learning</b> techniques to this problem, and demonstrate that, given sufficient training data, ... Such a multitask trained <b>encoder can be thought of as</b> <b>learning</b> a latent representation of the input that maintains information about the underlying transcript, i.e. one that is closer to the latent representation learned within a TTS sequence-to-sequence network. The decoder input is created by concatenating a 64-dim embedding for the grapheme emitted at the previous ...", "dateLastCrawled": "2022-01-18T09:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Distributed Source Coding: Theory, Algorithms and Applications</b> - PDF ...", "url": "https://epdf.pub/distributed-source-coding-theory-algorithms-and-applications.html", "isFamilyFriendly": true, "displayUrl": "https://epdf.pub/<b>distributed-source-coding-theory-algorithms-and-applications</b>.html", "snippet": "A Wyner\u2013Ziv <b>encoder can be thought of as</b> a quantizer followed by a Slepian\u2013Wolf encoder. In cases of images and video, existing distributed coding schemes add the Wyner\u2013 Ziv encoder into the standard transform coding structure. As with the centralized case, a linear transform is independently applied to each image or video frame. Each transform coef\ufb01cient is still treated independently, but it is fed into a Wyner\u2013Ziv coder instead of a scalar quantizer and an entropy coder. We ...", "dateLastCrawled": "2021-12-28T03:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Hands-On <b>Convolutional Neural Networks with TensorFlow</b>: Solve computer ...", "url": "https://dokumen.pub/hands-on-convolutional-neural-networks-with-tensorflow-solve-computer-vision-problems-with-modeling-in-tensorflow-and-python-9781789132823-1789132827.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/hands-on-<b>convolutional-neural-networks-with-tensorflow</b>-solve...", "snippet": "In the <b>machine</b> <b>learning</b> stage, all the feature vectors will be given to a <b>machine</b> <b>learning</b> system that creates a model. We hope that this model can generalize and is able to predict the digit for any future images given to the system that it wasn\u2019t trained on. An integral part of an ML system is evaluation. When we evaluate our model, we see how well our model has done in a particular task. In our example, we would look at how accurately it can predict the digit from the image. Accuracy of ...", "dateLastCrawled": "2022-01-24T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Parrotron: An End-to-End Speech-to-Speech Conversion Model and ...", "url": "https://www.researchgate.net/publication/335829307_Parrotron_An_End-to-End_Speech-to-Speech_Conversion_Model_and_its_Applications_to_Hearing-Impaired_Speech_and_Speech_Separation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335829307_Parrotron_An_End-to-End_Speech-to...", "snippet": "W.-c. W oo, \u201cConvolutional LSTM network: A <b>machine</b> <b>learning</b> approach for precipitation nowcasting,\u201d in Advances in Neural Information Processing Systems , 2015, pp. 802\u2013810.", "dateLastCrawled": "2022-01-29T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Error Diagnosis of Deep Monocular Depth Estimation Models", "url": "http://vision.soic.indiana.edu/papers/errordiagnosis2021iros.pdf", "isFamilyFriendly": true, "displayUrl": "vision.soic.indiana.edu/papers/errordiagnosis2021iros.pdf", "snippet": "<b>Machine</b> <b>learning</b>-based approaches such as Make3D [6], and more recent techniques based on deep <b>learning</b> [7], [8], have shown signi\ufb01cant promise. These techniques take a variety of approaches. For example, instead of directly estimating depth, BTS [9] estimates the parameters of local planes at various scales. The model is trained using only ground truth depth, as the local plane parameters are learned implicitly by the net-work. PlaneRCNN [10], another state-of-the-art technique, estimates ...", "dateLastCrawled": "2021-09-30T12:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Automatic <b>Machine</b> Translation Evaluation in Many Languages via Zero ...", "url": "https://aclanthology.org/2020.emnlp-main.8.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2020.emnlp-main.8.pdf", "snippet": "We frame the task of <b>machine</b> translation evaluation as one of scoring <b>machine</b> transla-tion output with a sequence-to-sequence para-phraser, conditioned on a human reference. We propose training the paraphraser as a multi-lingual NMT system, treating paraphrasing as a zero-shot translation task (e.g., Czech to Czech). This results in the paraphraser\u2019s out-put mode being centered around a copy of the input sequence, which represents the best case scenario where the MT system output matches a ...", "dateLastCrawled": "2022-01-21T14:24:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(encoder)  is like +(translating text from one language to another)", "+(encoder) is similar to +(translating text from one language to another)", "+(encoder) can be thought of as +(translating text from one language to another)", "+(encoder) can be compared to +(translating text from one language to another)", "machine learning +(encoder AND analogy)", "machine learning +(\"encoder is like\")", "machine learning +(\"encoder is similar\")", "machine learning +(\"just as encoder\")", "machine learning +(\"encoder can be thought of as\")", "machine learning +(\"encoder can be compared to\")"]}