{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) for object detection - PyImageSearch", "url": "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2016/11/07/<b>intersection</b>-<b>over</b>-<b>union</b>-<b>iou</b>-for-object-detection", "snippet": "Figure 2: Computing the <b>Intersection</b> <b>over</b> <b>Union</b> is as simple as dividing the area of <b>overlap</b> between the bounding boxes by the area of <b>union</b> (thank you to the excellent Pittsburg HW4 assignment for the inspiration for this figure). Examining this equation you can see that <b>Intersection</b> <b>over</b> <b>Union</b> is simply a ratio. In the numerator we compute the area of <b>overlap</b> between the predicted bounding box and the ground-truth bounding box.. The denominator is the area of <b>union</b>, or more simply, the ...", "dateLastCrawled": "2022-02-02T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>IoU</b> a better detection evaluation metric | by ... - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/iou-a-better-detection-evaluation-metric-45a511185be1", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/<b>iou</b>-a-better-detection-evaluation-metric-45a511185be1", "snippet": "<b>IoU</b>. <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) is used when calculating mAP. It is a number from 0 to 1 that specifies the amount of <b>overlap</b> between the predicted and ground truth bounding box. an <b>IoU</b> of 0 means that there is no <b>overlap</b> between the boxes; an <b>IoU</b> of 1 means that the <b>union</b> of the boxes is the same as their <b>overlap</b> indicating that they are completely overlapping . <b>IoU</b> is an important accuracy <b>measure</b> to track when gathering human annotations. The industry best practice is to include a ...", "dateLastCrawled": "2022-01-31T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to vectorize <b>pairwise</b> (dis)<b>similarity</b> metrics - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/how-to-vectorize-pairwise-dis-similarity-metrics-5d522715fb4e", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/how-to-vectorize-<b>pairwise</b>-dis-<b>similarity</b>-metrics-5d...", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) is a <b>measure</b> of the degree to which <b>two</b> boxes <b>overlap</b>. Assume you have <b>two</b> boxes, each parameterized by its top left corner (x1, y1) and bottom right corner (x2, y2). <b>IoU</b> is the area of the <b>intersection</b> between the <b>two</b> boxes divided by the area of the <b>union</b> between the <b>two</b> boxes.", "dateLastCrawled": "2022-02-03T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>What is intersection over union in deep</b> learning? - Quora", "url": "https://www.quora.com/What-is-intersection-over-union-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-intersection-over-union-in-deep</b>-learning", "snippet": "Answer (1 of 2): Generally <b>Intersection</b> <b>over</b> <b>union</b>(<b>IOU</b>) is a <b>measure</b> of <b>overlap</b> between <b>two</b> bounding box . In computer vision it is used for correctly detecting an object.To know object detection first you have to know about object localization . Object localization refers to figuring out where i...", "dateLastCrawled": "2022-01-19T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Object Detection and Classification using R</b>-CNNs | Telesens", "url": "https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/", "isFamilyFriendly": true, "displayUrl": "https://www.telesens.co/2018/03/11/<b>object-detection-and-classification-using-r</b>-cnns", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) <b>Overlap</b>: We need some <b>measure</b> of how close a given bounding box is to another bounding box that is independent of the units used (pixels etc) to <b>measure</b> the dimensions of a bounding box. This <b>measure</b> should be intuitive (<b>two</b> coincident bounding boxes should have an <b>overlap</b> of 1 and <b>two</b> non-overlapping boxes should have an <b>overlap</b> of 0) and fast and easy to calculate. A commonly used <b>overlap</b> <b>measure</b> is the \u201c<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) <b>overlap</b>, calculated as ...", "dateLastCrawled": "2022-01-31T21:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 5, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Jaccard index</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Jaccard_index", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Jaccard_index</b>", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> as a similarity <b>measure</b> for object detection on images - an important task in computer vision. The <b>Jaccard index</b>, also known as the Jaccard similarity coefficient, is a statistic used for gauging the similarity and diversity of sample <b>sets</b>. It was developed by Paul Jaccard, originally giving the French name coefficient de communaut\u00e9, and independently formulated again by T. Tanimoto. Thus, the Tanimoto index or Tanimoto coefficient are also used in some fields ...", "dateLastCrawled": "2022-02-02T23:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A 2021 <b>guide to Semantic Segmentation</b> - Nanonets", "url": "https://nanonets.com/blog/semantic-image-segmentation-2020/", "isFamilyFriendly": true, "displayUrl": "https://nanonets.com/blog/semantic-image-segmentation-2020", "snippet": "<b>IOU</b> is defined as the ratio of <b>intersection</b> of ground truth and predicted segmentation outputs <b>over</b> their <b>union</b>. If we are calculating for multiple classes, <b>IOU</b> of each class is calculated and their mean is taken. It is a better metric compared to pixel accuracy as if every pixel is given as background in a 2 class input the <b>IOU</b> value is (90/100+0/100)/2 i.e 45% <b>IOU</b> which gives a better representation as compared to 90% accuracy.", "dateLastCrawled": "2022-02-03T15:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What are <b>the best performance evaluation metrics for image</b> ... - Quora", "url": "https://www.quora.com/What-are-the-best-performance-evaluation-metrics-for-image-segmentation", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>the-best-performance-evaluation-metrics-for-image</b>...", "snippet": "Answer (1 of 4): <b>Intersection</b>-<b>Over</b>-<b>Union</b> (<b>IoU</b>, Jaccard Index) The <b>Intersection</b>-<b>Over</b>-<b>Union</b> (<b>IoU</b>), also known as the Jaccard Index, is one of the most commonly used metrics in semantic segmentation\u2026 and for good reason. The <b>IoU</b> is a very straightforward metric that\u2019s extremely effective. Simply p...", "dateLastCrawled": "2022-01-19T23:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Replacing YoloV3 Backbone with <b>ChexNet</b> for Pneumonia Detection | by ...", "url": "https://medium.com/analytics-vidhya/replacing-yolov3-backbone-with-chexnet-for-pneumonia-detection-a29434a698b7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/replacing-yolov3-backbone-with-<b>chexnet</b>-for...", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>):-<b>Intersection</b> <b>over</b> <b>Union</b> is a <b>measure</b> of the magnitude of the <b>overlap</b> between <b>two</b> bounding boxes (or, in the more general case, <b>two</b> objects).", "dateLastCrawled": "2022-01-14T18:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Semantic Segmentation</b> on Aerial Images using fastai | by Jhansi Anumula ...", "url": "https://medium.com/swlh/semantic-segmentation-on-aerial-images-using-fastai-a2696e4db127", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>semantic-segmentation</b>-on-aerial-images-using-fastai-a2696e4db127", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> is simply an evaluation metric. Any algorithm that provides predicted bounding boxes as output can be evaluated using <b>IoU</b>. More formally, in order to apply <b>Intersection</b> ...", "dateLastCrawled": "2022-01-27T11:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) for object detection - PyImageSearch", "url": "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2016/11/07/<b>intersection</b>-<b>over</b>-<b>union</b>-<b>iou</b>-for-object-detection", "snippet": "Figure 2: Computing the <b>Intersection</b> <b>over</b> <b>Union</b> is as simple as dividing the area of <b>overlap</b> between the bounding boxes by the area of <b>union</b> (thank you to the excellent Pittsburg HW4 assignment for the inspiration for this figure). Examining this equation you can see that <b>Intersection</b> <b>over</b> <b>Union</b> is simply a ratio. In the numerator we compute the area of <b>overlap</b> between the predicted bounding box and the ground-truth bounding box.. The denominator is the area of <b>union</b>, or more simply, the ...", "dateLastCrawled": "2022-02-02T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>IoU</b> a better detection evaluation metric | by ... - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/iou-a-better-detection-evaluation-metric-45a511185be1", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/<b>iou</b>-a-better-detection-evaluation-metric-45a511185be1", "snippet": "<b>IoU</b>. <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) is used when calculating mAP. It is a number from 0 to 1 that specifies the amount of <b>overlap</b> between the predicted and ground truth bounding box. an <b>IoU</b> of 0 means that there is no <b>overlap</b> between the boxes; an <b>IoU</b> of 1 means that the <b>union</b> of the boxes is the same as their <b>overlap</b> indicating that they are completely overlapping . <b>IoU</b> is an important accuracy <b>measure</b> to track when gathering human annotations. The industry best practice is to include a ...", "dateLastCrawled": "2022-01-31T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Mask Detection using YOLOv5. Explanation of key concepts followed by ...", "url": "https://towardsdatascience.com/mask-detection-using-yolov5-ae40979227a6", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/mask-detection-using-yolov5-ae40979227a6", "snippet": "This is where <b>Intersection</b> <b>over</b> <b>Union</b>(<b>IoU</b>) comes into play. Generally, <b>IoU</b> is a <b>measure</b> of <b>overlap</b> between <b>two</b> bounding boxes: algorithm predicted bounding box and ground truth bounding box. Image by Author. The formula for <b>IoU</b> is the size of the <b>intersection</b> divided by the size of the <b>union</b> of both bounding boxes. The threshold for <b>IoU</b> is around 0.5. IoUs with values \u2265 0.5 are deemed \u201ccorrect\u201d predictions. Non-max suppression. With reference to the bounding box image below, cells ...", "dateLastCrawled": "2022-01-31T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 3, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Jaccard index</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Jaccard_index", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Jaccard_index</b>", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> as a similarity <b>measure</b> for object detection on images - an important task in computer vision. The <b>Jaccard index</b>, also known as the Jaccard similarity coefficient, is a statistic used for gauging the similarity and diversity of sample <b>sets</b>. It was developed by Paul Jaccard, originally giving the French name coefficient de communaut\u00e9, and independently formulated again by T. Tanimoto. Thus, the Tanimoto index or Tanimoto coefficient are also used in some fields ...", "dateLastCrawled": "2022-02-02T23:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Generalized Intersection Over Union: A Metric</b> and a Loss for Bounding ...", "url": "https://www.researchgate.net/publication/338513354_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_Bounding_Box_Regression", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338513354_<b>Generalized_Intersection_Over_Union</b>...", "snippet": "The quality is measured in terms of the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) score, which indicates how <b>well</b> <b>two</b> bounding boxes <b>overlap</b> [44]. Finally, the quality of the segmentation annotation, a ...", "dateLastCrawled": "2021-11-30T20:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Mystery of Object Detection</b> \u2013 Blog", "url": "https://dudeperf3ct.github.io/object/detection/2019/01/07/Mystery-of-Object-Detection/", "isFamilyFriendly": true, "displayUrl": "https://dudeperf3ct.github.io/object/detection/2019/01/07/<b>Mystery-of-Object-Detection</b>", "snippet": "Typical training routine in all object detection algorithm consists of calculating <b>Intersection</b> <b>Over</b> <b>Union</b> (<b>IOU</b>), Non-max suppression (NMS) and loss. We will discuss about it below. <b>Intersection</b> <b>Over</b> <b>Union</b> (<b>IOU</b>) In the numerator we compute the area of <b>overlap</b> between the predicted bounding box and the ground-truth bounding box. The denominator is the area of <b>union</b>, or more simply, the area encompassed by both the predicted bounding box and the ground-truth bounding box. Dividing the area of ...", "dateLastCrawled": "2022-01-31T10:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Object Detection and Classification using R</b>-CNNs | Telesens", "url": "https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/", "isFamilyFriendly": true, "displayUrl": "https://www.telesens.co/2018/03/11/<b>object-detection-and-classification-using-r</b>-cnns", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) <b>Overlap</b>: We need some <b>measure</b> of how close a given bounding box is to another bounding box that is independent of the units used (pixels etc) <b>to measure</b> the dimensions of a bounding box. This <b>measure</b> should be intuitive (<b>two</b> coincident bounding boxes should have an <b>overlap</b> of 1 and <b>two</b> non-overlapping boxes should have an <b>overlap</b> of 0) and fast and easy to calculate. A commonly used <b>overlap</b> <b>measure</b> is the \u201c<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) <b>overlap</b>, calculated as ...", "dateLastCrawled": "2022-01-31T21:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>What is intersection over union in deep</b> learning? - Quora", "url": "https://www.quora.com/What-is-intersection-over-union-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-intersection-over-union-in-deep</b>-learning", "snippet": "Answer (1 of 2): Generally <b>Intersection</b> <b>over</b> <b>union</b>(<b>IOU</b>) is a <b>measure</b> of <b>overlap</b> between <b>two</b> bounding box . In computer vision it is used for correctly detecting an object.To know object detection first you have to know about object localization . Object localization refers to figuring out where i...", "dateLastCrawled": "2022-01-19T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Object Detection on SpaceNet</b>. This post presents a walk through of an ...", "url": "https://medium.com/the-downlinq/object-detection-on-spacenet-5e691961d257", "isFamilyFriendly": true, "displayUrl": "https://medium.com/the-downlinq/<b>object-detection-on-spacenet</b>-5e691961d257", "snippet": "Recall that the Jacquard Index (<b>Intersection</b> <b>over</b> <b>Union</b>, <b>IoU</b>) between <b>two</b> <b>sets</b>, A and B, is defined as: The scoring algorithm that we implement is based on Algorithm 2 from the ILSVRC documentation .", "dateLastCrawled": "2022-01-05T01:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What are <b>the best performance evaluation metrics for image</b> ... - Quora", "url": "https://www.quora.com/What-are-the-best-performance-evaluation-metrics-for-image-segmentation", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>the-best-performance-evaluation-metrics-for-image</b>...", "snippet": "Answer (1 of 4): <b>Intersection</b>-<b>Over</b>-<b>Union</b> (<b>IoU</b>, Jaccard Index) The <b>Intersection</b>-<b>Over</b>-<b>Union</b> (<b>IoU</b>), also known as the Jaccard Index, is one of the most commonly used metrics in semantic segmentation\u2026 and for good reason. The <b>IoU</b> is a very straightforward metric that\u2019s extremely effective. Simply p...", "dateLastCrawled": "2022-01-19T23:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>What is intersection over union in deep</b> learning? - Quora", "url": "https://www.quora.com/What-is-intersection-over-union-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-intersection-over-union-in-deep</b>-learning", "snippet": "Answer (1 of 2): Generally <b>Intersection</b> <b>over</b> <b>union</b>(<b>IOU</b>) is a <b>measure</b> of <b>overlap</b> between <b>two</b> bounding box . In computer vision it is used for correctly detecting an object.To know object detection first you have to know about object localization . Object localization refers to figuring out where i...", "dateLastCrawled": "2022-01-19T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Predicting local material thickness from steady-state ultrasonic ...", "url": "https://www.sciencedirect.com/science/article/pii/S0041624X2100278X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0041624X2100278X", "snippet": "The real and imaginary parts <b>can</b> <b>be thought</b> of as <b>two</b> snapshots of the steady-state response, ... The <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) value is the most commonly reported metric when evaluating the performance of image segmentation models. The <b>IoU</b> value is a <b>measure</b> of how much <b>overlap</b> there is between a predicted image and the ground truth image, with higher values tending to more accurate prediction results. For binary images, the <b>IoU</b> value is defined as: (4) <b>I o U</b> = T P T P + F P + F N where ...", "dateLastCrawled": "2022-02-03T05:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>python</b> - <b>Intersection</b> <b>over</b> <b>Union</b> for rotated rectangles - Code Review ...", "url": "https://codereview.stackexchange.com/questions/204017/intersection-over-union-for-rotated-rectangles", "isFamilyFriendly": true, "displayUrl": "https://codereview.stackexchange.com/questions/204017", "snippet": "Then you check each anchor box against all of the red rectangles that are overlapping the same tiles as the anchor box itself is overlapping. For example, if you use tiles of size 100\u00d7100, then most boxes will <b>overlap</b> roughly only 2 tiles. That means, with 756 boxes in a 768x768 domain, there are approximately 2 * 756 * 100\u00b2/768\u00b2 \u2248 25 ...", "dateLastCrawled": "2022-01-24T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A 2021 <b>guide to Semantic Segmentation</b> - Nanonets", "url": "https://nanonets.com/blog/semantic-image-segmentation-2020/", "isFamilyFriendly": true, "displayUrl": "https://nanonets.com/blog/semantic-image-segmentation-2020", "snippet": "<b>IOU</b> is defined as the ratio of <b>intersection</b> of ground truth and predicted segmentation outputs <b>over</b> their <b>union</b>. If we are calculating for multiple classes, <b>IOU</b> of each class is calculated and their mean is taken. It is a better metric compared to pixel accuracy as if every pixel is given as background in a 2 class input the <b>IOU</b> value is (90/100+0/100)/2 i.e 45% <b>IOU</b> which gives a better representation as compared to 90% accuracy.", "dateLastCrawled": "2022-02-03T15:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "image processing - <b>Compare two bounding boxes with each other</b> Matlab ...", "url": "https://stackoverflow.com/questions/22314949/compare-two-bounding-boxes-with-each-other-matlab", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/22314949", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> is an evaluation metric used to <b>measure</b> the accuracy of an object detector on a particular dataset. More formally, in order to apply <b>Intersection</b> <b>over</b> <b>Union</b> to evaluate an (arbitrary) object detector we need: The ground-truth bounding boxes (i.e., the hand labeled bounding boxes from the testing set that specify where in the image our object is). The predicted bounding boxes from our model. Below I have included a visual example of a ground-truth bounding box versus a ...", "dateLastCrawled": "2022-01-16T02:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Bird Box. Predicting <b>Bounding</b> Boxes using ... - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/bird-box-1d31bad4c9c7", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/bird-box-1d31bad4c9c7", "snippet": "The typical <b>measure</b> for this <b>overlap</b> is <b>IoU</b> (<b>Intersection</b> <b>over</b> <b>Union</b>, which is exactly what it sounds like: the area of the <b>overlap</b> of the <b>two</b> boxes divided by their conbined area). Typical bounds are <b>IoU</b> &gt; 0.7 for positive and <b>IoU</b> &lt; 0.3 for negative. Before GAP is performed, the final output tensor could be seen as a grid of feature vectors, each one predicting the presence of an object in a small portion of the image. A very simple (a little too simple) object detection model could then ...", "dateLastCrawled": "2022-01-29T03:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Automatic <b>segmentation</b> of fish using deep learning with application to ...", "url": "https://academic.oup.com/icesjms/article/77/4/1354/5602457", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/icesjms/article/77/4/1354/5602457", "snippet": "A standard set of metrics [<b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) and pixel accuracy] is used to quantify the <b>segmentation</b> results, since they are the de facto evaluation metrics used in object detection. <b>IoU</b>, also referred as Jaccard index, is an evaluation metric used to <b>measure</b> the accuracy of object <b>segmentation</b> on a particular dataset. <b>IoU</b> is often computed using the bounding box predicted by the CNN detector and the ground-truth (i.e. hand labelled) bounding box. In our case, since our detector ...", "dateLastCrawled": "2022-01-11T18:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Ultrasound Nerve Segmentation. <b>Can</b> Artificial Intelligence predict the ...", "url": "https://rakeshreddy95.medium.com/ultrasonic-nerve-segmentation-4f9454e8f8f", "isFamilyFriendly": true, "displayUrl": "https://rakeshreddy95.<b>medium</b>.com/<b>ultrasonic-nerve-segmentation</b>-4f9454e8f8f", "snippet": "As discussed in the Business problem we <b>can</b> take the 2 metrics either <b>IoU</b> or Dice coefficient to <b>measure</b> how <b>well</b> we are segmenting the nerve. The Dice coefficient <b>can</b> be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by: Metric. where X is the predicted set of pixels and Y is the ground truth. The Dice coefficient is defined to be 1 when both X and Y are empty. The leaderboard score is the mean of the Dice ...", "dateLastCrawled": "2022-01-26T19:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "TensorRT 4.0.1 - NVIDIA Developer Forums - NVIDIA Developer Forums", "url": "https://forums.developer.nvidia.com/t/tensorrt-4-0-1-int8-precision-vs-fp32-precision-objects-detections-inference-results/83864", "isFamilyFriendly": true, "displayUrl": "https://forums.developer.nvidia.com/t/tensorrt-4-0-1-int8-precision-vs-fp32-precision...", "snippet": "Is <b>IoU</b> is <b>Intersection</b> <b>over</b> <b>Union</b>? <b>Can</b> you explain please how <b>can</b> I use the <b>IoU</b> to <b>measure</b> the difference between Int8 &amp; fp32? Attached is a zip file that contains all CNN inference Int8 bits mode and fp32 bits mode outputs. Thanks, TRT6_fp32bits_VS_Int8bits.zip (6.84 MB) AastaLLL November 26, 2019, 7:47am #11. Hi, There are some quantization and approximation steps inside the INT8 mode. Due to these steps, the INT8 operation is expected to be lossy, indicating that the output won\u2019t be ...", "dateLastCrawled": "2021-12-24T14:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>DeepBlueBerry: Quantification of Blueberries in</b> the Wild Using ...", "url": "https://www.researchgate.net/publication/334998795_DeepBlueBerry_Quantification_of_Blueberries_in_the_Wild_Using_Instance_Segmentation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334998795_DeepBlueBerry_Quantification_of...", "snippet": "<b>Union</b> (<b>IoU</b>) <b>measure</b> is used [39]. The <b>IoU</b> measures the . <b>overlap</b> between <b>two</b> boundaries. This is used to <b>measure</b> how. much the boundary predicted by the algorithm overlaps with. the ground truth ...", "dateLastCrawled": "2022-01-31T22:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) for object detection - PyImageSearch", "url": "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2016/11/07/<b>intersection</b>-<b>over</b>-<b>union</b>-<b>iou</b>-for-object-detection", "snippet": "Figure 2: Computing the <b>Intersection</b> <b>over</b> <b>Union</b> is as simple as dividing the area of <b>overlap</b> between the bounding boxes by the area of <b>union</b> (thank you to the excellent Pittsburg HW4 assignment for the inspiration for this figure). Examining this equation you <b>can</b> see that <b>Intersection</b> <b>over</b> <b>Union</b> is simply a ratio. In the numerator we compute the area of <b>overlap</b> between the predicted bounding box and the ground-truth bounding box.. The denominator is the area of <b>union</b>, or more simply, the ...", "dateLastCrawled": "2022-02-02T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>IoU</b> a better detection evaluation metric | by ... - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/iou-a-better-detection-evaluation-metric-45a511185be1", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/<b>iou</b>-a-better-detection-evaluation-metric-45a511185be1", "snippet": "<b>IoU</b>. <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) is used when calculating mAP. It is a number from 0 to 1 that specifies the amount of <b>overlap</b> between the predicted and ground truth bounding box. an <b>IoU</b> of 0 means that there is no <b>overlap</b> between the boxes; an <b>IoU</b> of 1 means that the <b>union</b> of the boxes is the same as their <b>overlap</b> indicating that they are completely overlapping . <b>IoU</b> is an important accuracy <b>measure</b> to track when gathering human annotations. The industry best practice is to include a ...", "dateLastCrawled": "2022-01-31T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Generalized <b>Intersection over Union</b>: A Metric and A Loss for Bounding ...", "url": "https://deepai.org/publication/generalized-intersection-over-union-a-metric-and-a-loss-for-bounding-box-regression", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/generalized-<b>intersection-over-union</b>-a-metric-and-a-loss...", "snippet": "<b>Intersection over Union</b> (<b>IoU</b>) is the most popular evaluation metric used in the object detection benchmarks. However, there is a gap between optimizing the commonly used distance losses for regressing the parameters of a bounding box and maximizing this metric value. The optimal objective for a metric is the metric itself. In the case of axis-aligned 2D bounding boxes, it <b>can</b> be shown that <b>IoU</b> <b>can</b> be directly used as a regression loss. However, <b>IoU</b> has a plateau making it infeasible to ...", "dateLastCrawled": "2021-12-09T22:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Image Segmentation Techniques for Weed or Crop Detection", "url": "https://omdena.com/blog/image-segmentation-techniques-for-weed-or-crop-detection/", "isFamilyFriendly": true, "displayUrl": "https://omdena.com/blog/image-segmentation-techniques-for-weed-or-crop-detection", "snippet": "<b>Intersection</b> <b>Over</b> <b>Union</b> (<b>IoU</b>) <b>IoU</b> is the area of <b>overlap</b> between the predicted segmentation and the ground truth divided by the area of <b>union</b> between the predicted segmentation and the ground truth. This metric ranges from 0\u20131 with 0 signifying no <b>overlap</b> and 1 signifying perfectly overlapping segmentation. For binary (<b>two</b> classes) or multi-class segmentation, the mean <b>IoU</b> of the image is calculated by taking the <b>IoU</b> of each class and averaging them. <b>IoU</b> is generally considered the leading ...", "dateLastCrawled": "2022-01-23T17:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Object Detection and Classification using R</b>-CNNs | Telesens", "url": "https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/", "isFamilyFriendly": true, "displayUrl": "https://www.telesens.co/2018/03/11/<b>object-detection-and-classification-using-r</b>-cnns", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) <b>Overlap</b>: We need some <b>measure</b> of how close a given bounding box is to another bounding box that is independent of the units used (pixels etc) <b>to measure</b> the dimensions of a bounding box. This <b>measure</b> should be intuitive (<b>two</b> coincident bounding boxes should have an <b>overlap</b> of 1 and <b>two</b> non-overlapping boxes should have an <b>overlap</b> of 0) and fast and easy to calculate. A commonly used <b>overlap</b> <b>measure</b> is the \u201c<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) <b>overlap</b>, calculated as ...", "dateLastCrawled": "2022-01-31T21:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>python</b> - <b>Intersection</b> <b>over</b> <b>Union</b> for rotated rectangles - Code Review ...", "url": "https://codereview.stackexchange.com/questions/204017/intersection-over-union-for-rotated-rectangles", "isFamilyFriendly": true, "displayUrl": "https://codereview.stackexchange.com/questions/204017", "snippet": "Problem Statement I am trying to find the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) metric for one to several rotated rectangles <b>compared</b> to many different rotated rectangles. Here are some images to help . Stack Exchange Network. Stack Exchange network consists of 178 Q&amp;A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers. Visit Stack Exchange. Loading\u2026 0 +0; Tour Start here for a quick overview of ...", "dateLastCrawled": "2022-01-24T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Replacing YoloV3 Backbone with <b>ChexNet</b> for Pneumonia Detection | by ...", "url": "https://medium.com/analytics-vidhya/replacing-yolov3-backbone-with-chexnet-for-pneumonia-detection-a29434a698b7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/replacing-yolov3-backbone-with-<b>chexnet</b>-for...", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>):-<b>Intersection</b> <b>over</b> <b>Union</b> is a <b>measure</b> of the magnitude of the <b>overlap</b> between <b>two</b> bounding boxes (or, in the more general case, <b>two</b> objects).", "dateLastCrawled": "2022-01-14T18:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>What is intersection over union in deep</b> learning? - Quora", "url": "https://www.quora.com/What-is-intersection-over-union-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-intersection-over-union-in-deep</b>-learning", "snippet": "Answer (1 of 2): Generally <b>Intersection</b> <b>over</b> <b>union</b>(<b>IOU</b>) is a <b>measure</b> of <b>overlap</b> between <b>two</b> bounding box . In computer vision it is used for correctly detecting an object.To know object detection first you have to know about object localization . Object localization refers to figuring out where i...", "dateLastCrawled": "2022-01-19T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What are <b>the best performance evaluation metrics for image</b> ... - Quora", "url": "https://www.quora.com/What-are-the-best-performance-evaluation-metrics-for-image-segmentation", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>the-best-performance-evaluation-metrics-for-image</b>...", "snippet": "Answer (1 of 4): <b>Intersection</b>-<b>Over</b>-<b>Union</b> (<b>IoU</b>, Jaccard Index) The <b>Intersection</b>-<b>Over</b>-<b>Union</b> (<b>IoU</b>), also known as the Jaccard Index, is one of the most commonly used metrics in semantic segmentation\u2026 and for good reason. The <b>IoU</b> is a very straightforward metric that\u2019s extremely effective. Simply p...", "dateLastCrawled": "2022-01-19T23:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Similarity in graphs: <b>Jaccard</b> versus the <b>Overlap</b> Coefficient | by Brad ...", "url": "https://medium.com/rapids-ai/similarity-in-graphs-jaccard-versus-the-overlap-coefficient-610e083b877d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/rapids-ai/similarity-in-graphs-<b>jaccard</b>-versus-the-<b>overlap</b>...", "snippet": "Given <b>two</b> <b>sets</b>, A and B, the <b>Jaccard</b> Similarity is defined as the size of the <b>intersection</b> of set A and set B (i.e. the number of common elements) <b>over</b> the size of the <b>union</b> of set A and set B (i ...", "dateLastCrawled": "2022-02-02T07:17:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "13.4. <b>Anchor</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/anchor.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>anchor</b>.html", "snippet": "<b>Intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>), also known as Jaccard index, measures the similarity of two bounding boxes. It is the ratio of their <b>intersection</b> area to their <b>union</b> area. In a training set, we need two types of labels for each <b>anchor</b> box. One is the class of the object relevant to the <b>anchor</b> box and the other is the offset of the ground-truth ...", "dateLastCrawled": "2022-01-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep Hybrid Convolutional Neural Network for Segmentation of Melanoma ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8592765/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8592765", "snippet": "<b>Machine</b> <b>learning</b> algorithms have been widely used in cancer research [2 ... <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) is a task outputting a prediction range. In order for <b>IoU</b> to be used to detect objects of any size and shape, it is necessary to mark the range of the detected object in the training set image and measure the correlation between the ground-truth and the prediction. <b>IoU</b> = TP TP + FP + FN. (6) 3. Experiment. 3.1. Dataset. 3.1.1. International Skin Imaging Collaboration 2018 Dataset . The ...", "dateLastCrawled": "2021-11-20T10:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "The <b>intersection</b> of two sets divided by their <b>union</b>. In <b>machine-learning</b> image-detection tasks, <b>IoU</b> is used to measure the accuracy of the model\u2019s predicted bounding box with respect to the ground-truth bounding box. In this case, the <b>IoU</b> for the two boxes is the ratio between the overlapping area and the total area, and its value ranges from ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>What is intersection over union in deep</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-intersection-over-union-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-intersection-over-union-in-deep</b>-<b>learning</b>", "snippet": "Answer (1 of 2): Generally <b>Intersection</b> <b>over</b> <b>union</b>(<b>IOU</b>) is a measure of overlap between two bounding box . In computer vision it is used for correctly detecting an object.To know object detection first you have to know about object localization . Object localization refers to figuring out where i...", "dateLastCrawled": "2022-01-19T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Crack identification for bridge condition monitoring using deep ...", "url": "https://www.jvejournals.com/article/22032", "isFamilyFriendly": true, "displayUrl": "https://www.jvejournals.com/article/22032", "snippet": "By that <b>analogy</b>, several different CNN models are obtained and the accuracy of patch classification could be improved by using all models together. Finally, 80 test images are processed by the feedback-update CNN models and FCN model with a sliding window technique to generate crack identification results. <b>Intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) is calculated as an index to quantificationally evaluate the accuracy of the proposed method. Orthotropic steel bridge decks and steel box girders are key ...", "dateLastCrawled": "2021-12-22T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Visual Chunking: A List Prediction Framework for Region-Based Object ...", "url": "https://www.ri.cmu.edu/pub_files/2015/5/VC_icra.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ri.cmu.edu/pub_files/2015/5/VC_icra.pdf", "snippet": "as a natural extension of the <b>intersection</b> <b>over</b> <b>union</b> metric (<b>IoU</b>) (described in Section III-A), and develop an algorithm that targets this criterion. This approach uses recent work Fig. 1: Visual Chunking run on test data. The rst prediction is shown in red, the second in green, the third in blue, and the fourth in yellow.", "dateLastCrawled": "2021-07-17T04:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep Hybrid Convolutional Neural Network for Segmentation of Melanoma ...", "url": "https://www.hindawi.com/journals/cin/2021/9409508/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/cin/2021/9409508", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) is a task outputting a prediction range. In order for <b>IoU</b> to be used to detect objects of any size and shape, it is necessary to mark the range of the detected object in the training set image and measure the correlation between the ground-truth and the prediction. 3. Experiment 3.1. Dataset 3.1.1. International ...", "dateLastCrawled": "2021-12-28T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Unraveling the deep <b>learning</b> gearbox in optical coherence tomography ...", "url": "https://www.nature.com/articles/s42003-021-01697-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42003-021-01697-y", "snippet": "In that previous study, the <b>intersection</b> <b>over</b> <b>union</b> (<b>IOU</b>) scores was applied. In the proposed analysis in cynomolgus monkeys, that score was changed to the Hamming distance metric to additionally ...", "dateLastCrawled": "2022-01-31T21:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Unsupervised part representation by Flow Capsules \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2011.13920/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2011.13920", "snippet": "Tab. 3 compares the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) of our masks against PSD and R-NEM (van2018relational). Although PSD receives the ground truth optical flow during training, FlowCapsules consistently have better or equal IoUs during testing on both the Geo and Exercise datasets. One other significant difference between PSD and FlowCapsules lies in how they generate the masks. FlowCapsules generate the", "dateLastCrawled": "2022-01-06T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Calculating IOU of masks using tensorflow</b> : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/ns8c8q/calculating_iou_of_masks_using_tensorflow/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/ns8c8q/calculating_<b>iou</b>_of_masks...", "snippet": "<b>Calculating IOU of masks using tensorflow</b>. Hello! I&#39;m trying to speed up a process from my computer vision pipeline where I calculate <b>IOU</b> of two binary masks by using tensorflow 1.15. I&#39;ll post a snippet of code showing how I&#39;m doing it with numpy and how I&#39;m trying to do it with tensorflow, so far tensorflow is waaaay slower and was hoping someone could point out why that is happening. ...", "dateLastCrawled": "2021-12-28T03:28:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(intersection over union (iou))  is like +(measure of how well two sets of data overlap)", "+(intersection over union (iou)) is similar to +(measure of how well two sets of data overlap)", "+(intersection over union (iou)) can be thought of as +(measure of how well two sets of data overlap)", "+(intersection over union (iou)) can be compared to +(measure of how well two sets of data overlap)", "machine learning +(intersection over union (iou) AND analogy)", "machine learning +(\"intersection over union (iou) is like\")", "machine learning +(\"intersection over union (iou) is similar\")", "machine learning +(\"just as intersection over union (iou)\")", "machine learning +(\"intersection over union (iou) can be thought of as\")", "machine learning +(\"intersection over union (iou) can be compared to\")"]}