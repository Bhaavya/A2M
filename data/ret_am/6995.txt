{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning strategies for systems with invariance properties</b> ...", "url": "https://www.researchgate.net/publication/302059529_Machine_learning_strategies_for_systems_with_invariance_properties", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/302059529_<b>Machine</b>_<b>learning</b>_strategies_for...", "snippet": "Two <b>different</b> methods for teaching a <b>machine</b> <b>learning</b> model an <b>invariance</b> property are compared. In the first method, a basis of invariant inputs is constructed, and the <b>machine</b> <b>learning</b> model is ...", "dateLastCrawled": "2021-10-21T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b> Techniques for Biomedical Image Segmentation: An ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7338207/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7338207", "snippet": "In addition, we discuss several challenges related to the training <b>of different</b> <b>machine</b> <b>learning</b> models, and we present some heuristics to address those challenges. 1. Introduction. Segmentation is the process of clustering an image into several coherent sub-regions according to the extracted features, e.g., color, or texture attributes, and classifying each sub-region into one of the pre-determined classes. Segmentation can also be viewed as a form of image compression which is a crucial ...", "dateLastCrawled": "2022-01-28T19:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Knowledge as <b>Invariance</b> -- History and Perspectives of Knowledge ...", "url": "https://www.researchgate.net/publication/347535121_Knowledge_as_Invariance_--_History_and_Perspectives_of_Knowledge-augmented_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/347535121_Knowledge_as_<b>Invariance</b>_--_History...", "snippet": "PDF | Research in <b>machine</b> <b>learning</b> is at a turning point. While supervised deep <b>learning</b> has conquered the field at a breathtaking pace and demonstrated... | Find, read and cite all the research ...", "dateLastCrawled": "2022-01-13T21:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 3, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Convolutional neural network</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Convolutional_neural_network", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Convolutional_neural_network</b>", "snippet": "In deep <b>learning</b>, a <b>convolutional neural network</b> (CNN, or ConvNet) is a class of artificial neural network, most commonly applied to analyze visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are only ...", "dateLastCrawled": "2022-02-02T05:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How Do <b>Convolutional Layers</b> Work in Deep <b>Learning</b> Neural Networks?", "url": "https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>convolutional</b>", "snippet": "<b>Learning</b> a single filter specific to a <b>machine</b> <b>learning</b> task is a powerful technique. Yet, <b>convolutional</b> neural networks achieve much more in practice. Multiple Filters. <b>Convolutional</b> neural networks do not <b>learn</b> a single filter; they, in fact, <b>learn</b> multiple features in parallel for a given input. For example, it is common for a <b>convolutional</b> layer <b>to learn</b> from 32 to 512 filters in parallel for a given input. This gives the model 32, or even 512, <b>different</b> ways of extracting features from ...", "dateLastCrawled": "2022-02-02T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Artificial Intelligence in Medical Imaging of the Breast", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8339920/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8339920", "snippet": "As a branch of computer science, it attempts to produce a new kind of intelligent <b>machine</b> that responds <b>like</b> a human brain; its application field is very wide and includes robots, image recognition, language recognition, natural language processing, <b>data</b> mining, pattern recognition and expert system, etc. (14, 15). In the medical field, AI can be applied to health management, clinical decision support, medical imaging, disease screening and early disease prediction, medical records ...", "dateLastCrawled": "2022-02-03T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Recent <b>advances and applications of machine learning in</b> solid-state ...", "url": "https://www.nature.com/articles/s41524-019-0221-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41524-019-0221-0", "snippet": "The success of deep <b>learning</b> is rooted in <b>the ability</b> of deep neural networks <b>to learn</b> descriptors of <b>data</b> with <b>different</b> levels of abstraction without human intervention. 55,57 This is, of course ...", "dateLastCrawled": "2022-02-01T12:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Supervised Learning</b> with scikit-<b>learn</b> - GitHub Pages", "url": "https://trenton3983.github.io/files/projects/2020-10-14_supervised_learning_sklearn/2020-10-14_supervised_learning_sklearn.html", "isFamilyFriendly": true, "displayUrl": "https://trenton3983.github.io/files/projects/2020-10-14_<b>supervised_learning</b>_sk<b>learn</b>/...", "snippet": "Notebook Author: Trenton McKinney Course: DataCamp: <b>Supervised Learning</b> with scikit-<b>learn</b> This notebook was created as a reproducible reference.; The material is from the course. The course website uses scikit-<b>learn</b> v0.19.2, pandas v0.19.2, and numpy v1.17.4; This notebook uses v0.24.1, v1.2.3, and v1.19.2 respectively, so there are differences in model performance compared to the course.; I completed the exercises; If you find the content beneficial, consider a DataCamp Subscription.; I ...", "dateLastCrawled": "2022-02-02T20:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning Exam 2</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/459481663/machine-learning-exam-2-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/459481663/<b>machine-learning-exam-2</b>-flash-cards", "snippet": "D) It is an arbitrary value. Solution: A. Since MLP is a fully connected directed graph, the number of connections are a multiple of number of nodes in input layer and hidden layer. The input image has been converted into a matrix of <b>size</b> 28 X 28 and a kernel/filter of <b>size</b> 7 X 7 with a stride of 1.", "dateLastCrawled": "2022-01-02T18:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Applications of Deep <b>Learning</b> to Ocean <b>Data</b> Inference and Subgrid ...", "url": "https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018MS001472", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018MS001472", "snippet": "A <b>machine</b> <b>learning</b> <b>algorithm</b> trained on region-limited <b>data</b> would have to adapt to new regions with <b>different</b> physics; ... that is, how important local versus nonlocal information is for <b>different</b> regions. We therefore construct three <b>different</b> <b>data</b> sets from the QG model <b>data</b>, one for each region being studied. We choose regions which differ most in their dynamical behavior, and are shown in Figure 1a: Region 1 is near the jet separation point of the western boundary, where there is a ...", "dateLastCrawled": "2022-02-02T19:08:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> Techniques for Biomedical Image Segmentation: An ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7338207/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7338207", "snippet": "In addition, we discuss several challenges related to the training <b>of different</b> <b>machine</b> <b>learning</b> models, and we present some heuristics to address those challenges. 1. Introduction . Segmentation is the process of clustering an image into several coherent sub-regions according to the extracted features, e.g., color, or texture attributes, and classifying each sub-region into one of the pre-determined classes. Segmentation can also be viewed as a form of image compression which is a crucial ...", "dateLastCrawled": "2022-01-28T19:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "An Introductory Review of Deep <b>Learning</b> for Prediction Models With Big <b>Data</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7861305/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7861305", "snippet": "For instance, the sparse coding model by Olshausen and Field was shown to be <b>similar</b> to the coding of images in the human visual cortex (Tosic and Frossard, 2011) and an application of this model can be found in Charles et al. , where an unsupervised <b>learning</b> approach was used <b>to learn</b> an optimal sparse coding dictionary for the classification of high spectral imagery (HIS) <b>data</b>. Some may consider this model as an XAI model because of the similarity to the working mechanism of the human ...", "dateLastCrawled": "2022-01-10T22:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine learning strategies for systems with invariance properties</b> ...", "url": "https://www.researchgate.net/publication/302059529_Machine_learning_strategies_for_systems_with_invariance_properties", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/302059529_<b>Machine</b>_<b>learning</b>_strategies_for...", "snippet": "Two <b>different</b> methods for teaching a <b>machine</b> <b>learning</b> model an <b>invariance</b> property are compared. In the first method, a basis of invariant inputs is constructed, and the <b>machine</b> <b>learning</b> model is ...", "dateLastCrawled": "2021-10-21T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Atrous Convolutions &amp; U-Net Architectures for Deep <b>Learning</b>: A Brief ...", "url": "https://james-montantes-exxact.medium.com/atrous-convolutions-u-net-architectures-for-deep-learning-a-brief-history-e00391c77838?source=post_internal_links---------0----------------------------", "isFamilyFriendly": true, "displayUrl": "https://james-montantes-exxact.medium.com/atrous-convolutions-u-net-architectures-for...", "snippet": "One way that conv-nets achieve what\u2019s known as translation <b>invariance</b> \u2014 the <b>ability</b> to recognize an object regardless of where it appears in an image \u2014 is by sequentially reducing the image dimensions in both x and y dimensions (pooling) while increasing the depth (e.g. by increasing the number of convolutional kernels). Applied sequentially in deep nets, this is one reason that conv-nets perform so well at image classification. But for semantic segmentation we don\u2019t want translation ...", "dateLastCrawled": "2022-01-20T23:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Supervised Learning</b> with scikit-<b>learn</b> - GitHub Pages", "url": "https://trenton3983.github.io/files/projects/2020-10-14_supervised_learning_sklearn/2020-10-14_supervised_learning_sklearn.html", "isFamilyFriendly": true, "displayUrl": "https://trenton3983.github.io/files/projects/2020-10-14_<b>supervised_learning</b>_sk<b>learn</b>/...", "snippet": "Notebook Author: Trenton McKinney Course: DataCamp: <b>Supervised Learning</b> with scikit-<b>learn</b> This notebook was created as a reproducible reference.; The material is from the course. The course website uses scikit-<b>learn</b> v0.19.2, pandas v0.19.2, and numpy v1.17.4; This notebook uses v0.24.1, v1.2.3, and v1.19.2 respectively, so there are differences in model performance compared to the course.; I completed the exercises; If you find the content beneficial, consider a DataCamp Subscription.; I ...", "dateLastCrawled": "2022-02-02T20:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Applied Deep <b>Learning</b> - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/applied-deep-<b>learning</b>-part-4-convolutional-neural...", "snippet": "The common case in most <b>machine</b> <b>learning</b> applications, especially in image classification tasks is that obtaining new training <b>data</b> is not easy. Therefore we need to make do with the training set at hand. <b>Data</b> augmentation is a way to generate more training <b>data</b> from our current set. It enriches or \u201caugments\u201d the training <b>data</b> by generating new examples via random transformation of existing ones. This way we artificially boost the <b>size</b> of the training set, reducing overfitting. So <b>data</b> ...", "dateLastCrawled": "2022-01-31T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Distilling Inductive Biases | Samira Abnar", "url": "https://samiraabnar.github.io/articles/2020-05/indist", "isFamilyFriendly": true, "displayUrl": "https://samiraabnar.github.io/articles/2020-05/indist", "snippet": "Distilling Inductive Biases 27 MAY 2020 \u2022 13 mins read No free lunch theorem states that for any <b>learning</b> <b>algorithm</b>, any improvement on performance over one class of problems is balanced out by a decrease in the performance over another class (Wolpert &amp; Macready, 1997).In other words, there is no \u201cone <b>size</b> fits all\u201d <b>learning</b> <b>algorithm</b>. We can see this in practice in the deep <b>learning</b> world. Among the various neural network architectures, each of them are better or worse for solving ...", "dateLastCrawled": "2022-01-30T15:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Choosing the right molecular <b>machine</b> <b>learning</b> potential - Chemical ...", "url": "https://pubs.rsc.org/en/content/articlelanding/2021/sc/d1sc03564a#!", "isFamilyFriendly": true, "displayUrl": "https://pubs.rsc.org/en/content/articlelanding/2021/sc/d1sc03564a", "snippet": "A <b>similar</b> concept but with <b>different</b> descriptors is used in DPMD, another successful example of an NN-fLD MLP. 47 DPMD belongs to the first generation of deep <b>learning</b> models for molecular simulations, which have been continuously improved from both an efficiency 87 and accuracy 75 perspective. The descriptors in DPMD are defined in a local coordinate system, which gives some flexibility in generating them.", "dateLastCrawled": "2022-02-02T19:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning Exam 2</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/459481663/machine-learning-exam-2-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/459481663/<b>machine-learning-exam-2</b>-flash-cards", "snippet": "D) It is an arbitrary value. Solution: A. Since MLP is a fully connected directed graph, the number of connections are a multiple of number of nodes in input layer and hidden layer. The input image has been converted into a matrix of <b>size</b> 28 X 28 and a kernel/filter of <b>size</b> 7 X 7 with a stride of 1.", "dateLastCrawled": "2022-01-02T18:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "AI <b>applications to medical images: From machine learning</b> to deep ...", "url": "https://www.sciencedirect.com/science/article/pii/S1120179721000946", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1120179721000946", "snippet": "In AI-based classification systems, the most popular among <b>learning</b> processes is supervised <b>learning</b>, in which the training of the classification model is performed by presenting \u201clabeled\u201d training <b>data</b> (<b>data</b> samples coupled to their corresponding class or label of interest) to the <b>learning</b> system. The task of the <b>learning</b> system is then to find a relation that maps each input of the training set (the <b>data</b>) into an output (the label). In medicine, input <b>data</b> can include medical images or ...", "dateLastCrawled": "2022-01-20T00:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Brain-Computer Interface: Advancement and Challenges", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8433803/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8433803", "snippet": "It is a spatial filter that <b>can</b> <b>be thought</b> of as the subtraction of shared EEG activity, retaining only the idle ... BCIs, where even the integration of unique feature sets, such as covariance matrices with domain adaptation algorithms, <b>can</b> strengthen the <b>invariance</b> performance of BCIs. 10.2.7. Performance Evaluation Metrics . A variety of performance evaluation measures are used to evaluate BCI systems. However, when <b>different</b> evaluation metrics are used to assess BCI systems, it is nearly ...", "dateLastCrawled": "2022-02-03T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How does the brain solve visual object recognition?", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3306444/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3306444", "snippet": "Core object recognition. is the <b>ability</b> to rapidly (&lt;200 ms viewing duration) discriminate a given visual object (e.g., a car, top row) from all other possible visual objects (e.g. bottom row) without any object-specific or location-specific pre-cuing (e.g. (DiCarlo and Cox, 2007).Primates perform this task remarkably well, even in the face of identity-preserving transformations (e.g., changes in object position, <b>size</b>, viewpoint, and visual context).", "dateLastCrawled": "2022-02-03T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How Does <b>Our Visual System Achieve Shift and Size Invariance</b>? | Request PDF", "url": "https://www.researchgate.net/publication/2460202_How_Does_Our_Visual_System_Achieve_Shift_and_Size_Invariance", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/2460202_How_Does_Our_Visual_System_Achieve...", "snippet": "A new <b>algorithm</b> for <b>learning</b> <b>invariance</b> manifolds is introduced that allows a neuron <b>to learn</b> a non-linear transfer function to extract invariant or rather slowly varying features from a vectorial ...", "dateLastCrawled": "2021-11-07T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 3, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Artificial neural network</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Artificial_neural_network", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Artificial_neural_network</b>", "snippet": "This <b>can</b> <b>be thought</b> of as <b>learning</b> with a &quot;teacher&quot;, in the form of a function that provides continuous feedback on the quality of solutions obtained thus far. Unsupervised <b>learning</b>. In unsupervised <b>learning</b>, input <b>data</b> is given along with the cost function, some function of the <b>data</b> and the network&#39;s output. The cost function is dependent on the task (the model domain) and any a priori assumptions (the implicit properties of the model, its parameters and the observed variables). As a ...", "dateLastCrawled": "2022-02-03T16:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Applied Deep <b>Learning</b> - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/applied-deep-<b>learning</b>-part-4-convolutional-neural...", "snippet": "The common case in most <b>machine</b> <b>learning</b> applications, especially in image classification tasks is that obtaining new training <b>data</b> is not easy. Therefore we need to make do with the training set at hand. <b>Data</b> augmentation is a way to generate more training <b>data</b> from our current set. It enriches or \u201caugments\u201d the training <b>data</b> by generating new examples via random transformation of existing ones. This way we artificially boost the <b>size</b> of the training set, reducing overfitting. So <b>data</b> ...", "dateLastCrawled": "2022-01-31T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Supervised Learning</b> with scikit-<b>learn</b> - GitHub Pages", "url": "https://trenton3983.github.io/files/projects/2020-10-14_supervised_learning_sklearn/2020-10-14_supervised_learning_sklearn.html", "isFamilyFriendly": true, "displayUrl": "https://trenton3983.github.io/files/projects/2020-10-14_<b>supervised_learning</b>_sk<b>learn</b>/...", "snippet": "Notebook Author: Trenton McKinney Course: DataCamp: <b>Supervised Learning</b> with scikit-<b>learn</b> This notebook was created as a reproducible reference.; The material is from the course. The course website uses scikit-<b>learn</b> v0.19.2, pandas v0.19.2, and numpy v1.17.4; This notebook uses v0.24.1, v1.2.3, and v1.19.2 respectively, so there are differences in model performance compared to the course.; I completed the exercises; If you find the content beneficial, consider a DataCamp Subscription.; I ...", "dateLastCrawled": "2022-02-02T20:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Tutorial 1: Un/Self-supervised <b>learning</b> methods \u2014 Neuromatch Academy ...", "url": "https://deeplearning.neuromatch.io/tutorials/W3D1_UnsupervisedAndSelfSupervisedLearning/student/W3D1_Tutorial1.html", "isFamilyFriendly": true, "displayUrl": "https://deep<b>learning</b>.neuromatch.io/tutorials/W3D1_UnsupervisedAndSelfSupervised...", "snippet": "Args: Required: proj_feat1: 2D torch.Tensor Projected features for first image with augmentations (<b>size</b>: batch_<b>size</b> x feat_<b>size</b>) proj_feat2: 2D torch.Tensor Projected features for second image with augmentations (<b>size</b>: batch_<b>size</b> x feat_<b>size</b>) Optional: temperature: Float relaxation temperature (default: 0.5) l2 normalization along with temperature effectively weights <b>different</b> examples, and an appropriate temperature <b>can</b> help the model <b>learn</b> from hard negatives.", "dateLastCrawled": "2022-02-02T13:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Causality for <b>Machine</b> <b>Learning</b>", "url": "https://ff13.fastforwardlabs.com/", "isFamilyFriendly": true, "displayUrl": "https://ff13.fastforwardlabs.com", "snippet": "Many current state-of-the-art <b>machine</b> <b>learning</b> approaches assume that the trained model will be applied to <b>data</b> that looks the same as the training <b>data</b>. These models are trained on highly specific tasks, like recognizing dogs in images or identifying fraud in banking transactions. In real life, though, the <b>data</b> on which we predict is often <b>different</b> from the <b>data</b> on which we train, even when the task is the same. For example, training <b>data</b> is often subject to some form of selection bias ...", "dateLastCrawled": "2022-02-01T19:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Beginner&#39;s Guide to Generative Adversarial Networks (GANs) | Pathmind", "url": "https://wiki.pathmind.com/generative-adversarial-network-gan", "isFamilyFriendly": true, "displayUrl": "https://wiki.pathmind.com/generative-adversarial-<b>network</b>-gan", "snippet": "You <b>can</b> think of a GAN as the opposition of a counterfeiter and a cop in a game of cat and mouse, where the counterfeiter is <b>learning</b> to pass false notes, and the cop is <b>learning</b> to detect them. Both are dynamic; i.e. the cop is in training, too (to extend the analogy, maybe the central bank is flagging bills that slipped through), and each side comes <b>to learn</b> the other\u2019s methods in a constant escalation.", "dateLastCrawled": "2022-02-02T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning Exam 2</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/459481663/machine-learning-exam-2-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/459481663/<b>machine-learning-exam-2</b>-flash-cards", "snippet": "D) It is an arbitrary value. Solution: A. Since MLP is a fully connected directed graph, the number of connections are a multiple of number of nodes in input layer and hidden layer. The input image has been converted into a matrix of <b>size</b> 28 X 28 and a kernel/filter of <b>size</b> 7 X 7 with a stride of 1.", "dateLastCrawled": "2022-01-02T18:21:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> Techniques for Biomedical Image Segmentation: An ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7338207/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7338207", "snippet": "Segmentation methods based on deep <b>learning</b> <b>can</b> be handled by supervised <b>learning</b> with adequate training <b>data</b> 64,65,66. To build a reliable segmentation model, a prerequisite is the availability of a large amount of labeled training <b>data</b>. In practice, medical <b>data</b> is generally scarce and curation of annotated <b>data</b> has been one of the bottleneck problems in the widespread use of supervised deep <b>learning</b> in medicine.", "dateLastCrawled": "2022-01-28T19:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Artificial Intelligence in Medical Imaging of the Breast", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8339920/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8339920", "snippet": "Artificial intelligence (AI) is commonly defined as \u201ca system\u2019s <b>ability</b> to correctly interpret external <b>data</b>, <b>to learn</b> from such <b>data</b>, and to use those learnings to achieve specific goals and tasks through flexible adaptation\u201d. Over the past 50 years, the dramatic growth of computer functions related to big <b>data</b> intrusion has pushed AI applications into new areas . Currently, AI <b>can</b> be found in voice recognition, face recognition, driverless cars and other new technologies, and the ...", "dateLastCrawled": "2022-02-03T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Distilling Inductive Biases | Samira Abnar", "url": "https://samiraabnar.github.io/articles/2020-05/indist", "isFamilyFriendly": true, "displayUrl": "https://samiraabnar.github.io/articles/2020-05/indist", "snippet": "Translation <b>invariance</b> of CNNs improves their generalization and makes them <b>data</b> efficient <b>compared</b> to fully connected networks. For example, if, during training, a CNN has only seen pictures of cats where the cat is located at the centre of the image, it <b>can</b> correctly classify cats at test time independent of their position in the image. In the lack of this <b>inductive bias</b>, the model needs to see examples of cats at <b>different</b> positions to be able to correctly classify them at test time. On ...", "dateLastCrawled": "2022-01-30T15:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>learning</b> for <b>landslides</b> prevention: a survey | SpringerLink", "url": "https://link.springer.com/article/10.1007/s00521-020-05529-8", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-020-05529-8", "snippet": "At least 80% of <b>machine</b> <b>learning</b> is <b>data</b> preprocessing, which means that the performance of <b>machine</b> <b>learning</b> methods depends on the <b>data</b> quality. With advances in a variety of location-aware sensors and model simulations, available <b>data</b> volumes in the <b>landslides</b> prevention domain are exponentially increasing with increasing spatial, temporal, and spectral resolutions. These continuous cumulative datasets provide applications for <b>machine</b> <b>learning</b> with more opportunities. Overall, in the ...", "dateLastCrawled": "2022-02-01T20:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Recent <b>advances and applications of machine learning in</b> solid-state ...", "url": "https://www.nature.com/articles/s41524-019-0221-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41524-019-0221-0", "snippet": "The success of deep <b>learning</b> is rooted in the <b>ability</b> of deep neural networks <b>to learn</b> descriptors of <b>data</b> with <b>different</b> levels of abstraction without human intervention. 55,57 This is, of course ...", "dateLastCrawled": "2022-02-01T12:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>learning</b> of materials design and state prediction for lithium ...", "url": "https://www.sciencedirect.com/science/article/pii/S1004954121001543", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1004954121001543", "snippet": "<b>Machine</b> <b>learning</b>, one of the core technologies of artificial intelligence, is rapidly changing many fields with its <b>ability</b> <b>to learn</b> from historical <b>data</b> and solve complex tasks, and it has emerged as a new technique for solving current research problems in the field of lithium ion batteries. This review begins with the introduction of the conceptual framework of <b>machine</b> <b>learning</b> and the general process of its application, then reviews some of the progress made by <b>machine</b> <b>learning</b> in both ...", "dateLastCrawled": "2022-01-28T22:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Supervised Learning</b> with scikit-<b>learn</b> - GitHub Pages", "url": "https://trenton3983.github.io/files/projects/2020-10-14_supervised_learning_sklearn/2020-10-14_supervised_learning_sklearn.html", "isFamilyFriendly": true, "displayUrl": "https://trenton3983.github.io/files/projects/2020-10-14_<b>supervised_learning</b>_sk<b>learn</b>/...", "snippet": "Notebook Author: Trenton McKinney Course: DataCamp: <b>Supervised Learning</b> with scikit-<b>learn</b> This notebook was created as a reproducible reference.; The material is from the course. The course website uses scikit-<b>learn</b> v0.19.2, pandas v0.19.2, and numpy v1.17.4; This notebook uses v0.24.1, v1.2.3, and v1.19.2 respectively, so there are differences in model performance <b>compared</b> to the course.; I completed the exercises; If you find the content beneficial, consider a DataCamp Subscription.; I ...", "dateLastCrawled": "2022-02-02T20:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Applied Deep <b>Learning</b> - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/applied-deep-<b>learning</b>-part-4-convolutional-neural...", "snippet": "The common case in most <b>machine</b> <b>learning</b> applications, especially in image classification tasks is that obtaining new training <b>data</b> is not easy. Therefore we need to make do with the training set at hand. <b>Data</b> augmentation is a way to generate more training <b>data</b> from our current set. It enriches or \u201caugments\u201d the training <b>data</b> by generating new examples via random transformation of existing ones. This way we artificially boost the <b>size</b> of the training set, reducing overfitting. So <b>data</b> ...", "dateLastCrawled": "2022-01-31T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Machine Vision based Fruit Classification and Grading</b> - A Review", "url": "https://www.researchgate.net/publication/318486455_Machine_Vision_based_Fruit_Classification_and_Grading_-_A_Review", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/318486455", "snippet": "<b>size</b> <b>can</b> be extrac ted to obtain a non-destructive type of fruit . ... extraction techniques and <b>machine</b> <b>learning</b> algorithms are . ... <b>different</b> <b>size</b> measures, which are m ost commonly used, ...", "dateLastCrawled": "2022-02-02T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning Exam 2</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/459481663/machine-learning-exam-2-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/459481663/<b>machine-learning-exam-2</b>-flash-cards", "snippet": "D) It is an arbitrary value. Solution: A. Since MLP is a fully connected directed graph, the number of connections are a multiple of number of nodes in input layer and hidden layer. The input image has been converted into a matrix of <b>size</b> 28 X 28 and a kernel/filter of <b>size</b> 7 X 7 with a stride of 1.", "dateLastCrawled": "2022-01-02T18:21:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "[2109.12926v1] ML4ML: Automated <b>Invariance</b> Testing for <b>Machine</b> <b>Learning</b> ...", "url": "https://arxiv.org/abs/2109.12926v1", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2109.12926v1", "snippet": "In <b>machine</b> <b>learning</b> workflows, determining <b>invariance</b> qualities of a model is a common testing procedure. In this paper, we propose an automatic testing framework that is applicable to a variety of <b>invariance</b> qualities. We draw an <b>analogy</b> between <b>invariance</b> testing and medical image analysis and propose to use variance matrices as ``imagery&#39;&#39; testing data. This enables us to employ <b>machine</b> <b>learning</b> techniques for analysing such ``imagery&#39;&#39; testing data automatically, hence facilitating ML4ML ...", "dateLastCrawled": "2022-01-20T15:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "ML4ML: Automated <b>Invariance</b> Testing for <b>Machine</b> <b>Learning</b> Models - NASA/ADS", "url": "https://ui.adsabs.harvard.edu/abs/2021arXiv210912926L/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2021arXiv210912926L/abstract", "snippet": "In <b>machine</b> <b>learning</b> workflows, determining <b>invariance</b> qualities of a model is a common testing procedure. In this paper, we propose an automatic testing framework that is applicable to a variety of <b>invariance</b> qualities. We draw an <b>analogy</b> between <b>invariance</b> testing and medical image analysis and propose to use variance matrices as ``imagery&#39;&#39; testing data. This enables us to employ <b>machine</b> <b>learning</b> techniques for analysing such ``imagery&#39;&#39; testing data automatically, hence facilitating ML4ML ...", "dateLastCrawled": "2021-11-01T00:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Size</b>\u2010Extensive <b>Molecular Machine Learning with Global Representations</b> ...", "url": "https://chemistry-europe.onlinelibrary.wiley.com/doi/full/10.1002/syst.201900052", "isFamilyFriendly": true, "displayUrl": "https://chemistry-europe.onlinelibrary.wiley.com/doi/full/10.1002/syst.201900052", "snippet": "1 Introduction. In recent years, <b>machine</b>-<b>learning</b> (ML) methods are increasingly applied to the prediction of molecular properties such as atomization and orbital energies, dipole moments and ionization potentials. 1-9 One of the main promises of ML in chemistry is that it allows surpassing the <b>size</b> and time scales accessible to accurate first-principles electronic structure calculations, e. g. based on density-functional theory (DFT).This is particularly relevant in a high-throughput setting ...", "dateLastCrawled": "2022-01-16T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Machine</b> <b>Learning</b>, <b>Machine</b> Vision, and the Brain | Christian ...", "url": "https://www.academia.edu/8040540/Machine_Learning_Machine_Vision_and_the_Brain", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/8040540/<b>Machine</b>_<b>Learning</b>_<b>Machine</b>_Vision_and_the_Brain", "snippet": "In fact, the <b>invariance</b> of the view-tuned neurons to image-plane trans- formation and to changes in illumination has been tested experimentally by Logothetis, Pauls, and Poggio (1995) who report an average rotation <b>invariance</b> over 30 degrees, translation <b>invariance</b> over 2 degrees, and <b>size</b> <b>invariance</b> of up to 1 octave around the training view. These recent data put in sharp focus and in quantitative terms the question of the circuitry underlying the properties of the view-tuned cells. The ...", "dateLastCrawled": "2022-01-26T21:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Size\u00e2 Extensive Molecular <b>Machine</b> <b>Learning</b> with Global Representations", "url": "https://chemistry-europe.onlinelibrary.wiley.com/doi/pdf/10.1002/syst.201900052", "isFamilyFriendly": true, "displayUrl": "https://chemistry-europe.onlinelibrary.wiley.com/doi/pdf/10.1002/syst.201900052", "snippet": "<b>Size</b>-Extensive Molecular <b>Machine</b> <b>Learning</b> with Global Representations** Hyunwook Jung+,[a, b] Sina Stocker+,[a] Christian Kunkel,[a] Harald Oberhofer,[a] Byungchan Han,[b] Karsten Reuter,[a] and Johannes T. Margraf*[a] <b>Machine</b> <b>learning</b> (ML) models are increasingly used in combi-nation with electronic structure calculations to predict molec-ular properties at a much lower computational cost in high-throughput settings. Such ML models require representations thatencode themolecular structure ...", "dateLastCrawled": "2022-01-30T02:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Integrating <b>Machine Learning</b> with Physics-Based Modeling | DeepAI", "url": "https://deepai.org/publication/integrating-machine-learning-with-physics-based-modeling", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/integrating-<b>machine-learning</b>-with-physics-based-modeling", "snippet": "Instead, data generation and training is an interactive process: Data is generated and labeled on the fly as model training proceeds. In <b>analogy</b> with multi-scale modeling, we refer to the former class of problems \u201csequential <b>machine learning</b>\u201d problems and the latter kind \u201cconcurrent <b>machine learning</b>\u201d problems.", "dateLastCrawled": "2022-01-27T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Perceptual invariance</b> in <b>Humans and Machines</b> | The Center for Brains ...", "url": "https://cbmm.mit.edu/video/perceptual-invariance-humans-and-machines", "isFamilyFriendly": true, "displayUrl": "https://cbmm.mit.edu/video/<b>perceptual-invariance</b>-<b>humans-and-machines</b>", "snippet": "I&#39;d argue that adversarial images is not just probably one of the most important problems in current <b>machine</b> <b>learning</b> or computer vision, but probably vision science. I feel like-- and I&#39;m stepping aside from the whole theme of <b>perceptual invariance</b>, and metamers, and foveation, and vision-- but I think if you go back to how advances in vision have happened over the years, over the past maybe 50 years or 60, there&#39;s discoveries that have been made from single cell electrophysiology. For ...", "dateLastCrawled": "2021-12-15T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Training Invariant Support Vector Machines</b>", "url": "https://people.eecs.berkeley.edu/~malik/cs294/decoste-scholkopf.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.eecs.berkeley.edu/~malik/cs294/decoste-scholkopf.pdf", "snippet": "<b>Machine</b> <b>Learning</b>, 46, 161\u2013190, 2002 c 2002 Kluwer Academic Publishers. Manufactured in The Netherlands. <b>Training Invariant Support Vector Machines</b> DENNIS DECOSTE decoste@aig.jpl.nasa.gov Jet Propulsion Laboratory, MS 126-347, 4800 Oak Grove Drive, Pasadena, CA 91109, USA; California Institute of Technology BERNHARD SCHOLKOPF bs@conclu.de\u00a8 Max-Planck-Institut fuer biologische Kybernetik, Spemannstr. 38, 72076 Tubingen, Germany\u00a8 Editor: Nello Cristianini Abstract. Practical experience has ...", "dateLastCrawled": "2022-01-30T19:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Model 1: accuracy = 92%. Model 2: accuracy = 95%. Model 2 has higher accuracy than model 1, but model 2 is useless. This is called accuracy paradox, which means the model with higher accuracy may not have better generalization power. In general, when TP &lt; FP, the accuracy will always increase when we change the classifier to always output &#39;negative&#39;.Conversely, when TN &lt; FN, the same will happen when we change the classifier to always output &#39;positive&#39; [1].. Recall@k", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "13_CNN1___MachineLearningCOMP5450_Fall2019.pdf - <b>Machine</b> <b>Learning</b> Dr ...", "url": "https://www.coursehero.com/file/75577826/13-CNN1-MachineLearningCOMP5450-Fall2019pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/75577826/13-CNN1-<b>MachineLearning</b>COMP5450-Fall2019pdf", "snippet": "13_CNN1___MachineLearningCOMP5450_Fall2019.pdf - <b>Machine</b> <b>Learning</b> Dr Jerome J Braun This Lecture Convolutional Neural Networks I Course <b>Machine</b> <b>Learning</b>. 13_CNN1___MachineLearningCOMP5450_Fall2019.pdf - <b>Machine</b>... School University of Massachusetts, Lowell; Course Title COMP 5450; Type. Notes. Uploaded By PrivateHeat13048. Pages 34 This preview shows page 1 - 8 out of 34 pages. Students who viewed this also studied. SRI SAIRAM ENGINEERING COLLEGE \u2022 MATH 2335. Week 3 quiz. 7 pages. Week 3 ...", "dateLastCrawled": "2022-01-19T01:07:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(size invariance)  is like +(the ability of a machine learning algorithm to learn from data of different sizes)", "+(size invariance) is similar to +(the ability of a machine learning algorithm to learn from data of different sizes)", "+(size invariance) can be thought of as +(the ability of a machine learning algorithm to learn from data of different sizes)", "+(size invariance) can be compared to +(the ability of a machine learning algorithm to learn from data of different sizes)", "machine learning +(size invariance AND analogy)", "machine learning +(\"size invariance is like\")", "machine learning +(\"size invariance is similar\")", "machine learning +(\"just as size invariance\")", "machine learning +(\"size invariance can be thought of as\")", "machine learning +(\"size invariance can be compared to\")"]}