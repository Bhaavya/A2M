{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What <b>is fine tuning in biology? - Quora</b>", "url": "https://www.quora.com/What-is-fine-tuning-in-biology", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-<b>is-fine-tuning-in-biology</b>", "snippet": "Answer (1 of 2): It\u2019s typically used in two senses: 1. A flimsy argument by Intelligent Design/Creationist sorts, as in, \u201chow could the mammalian eye have come to be without Yahweh?\u201d And educated people need to answer them with a gentle explanation, as to a 4-year-old, that Santa didn\u2019t make you...", "dateLastCrawled": "2022-01-06T18:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Java Virtual <b>Machine</b> (JVM) Performance <b>Tuning</b> Tutorial - <b>Sematext</b>", "url": "https://sematext.com/blog/jvm-performance-tuning/", "isFamilyFriendly": true, "displayUrl": "https://<b>sematext</b>.com/blog/jvm-performance-<b>tuning</b>", "snippet": "The way to do that is by peaking into and <b>fine</b>-<b>tuning</b> the Java Virtual <b>Machine</b> (JVM). However, that\u2019s easier said than done. ... Java virtual <b>machine</b> <b>tuning</b> is the process of <b>adjusting</b> the default parameters to match our application needs. This includes simple adjustments <b>like</b> the size of the heap, through choosing the right garbage collector to using optimized versions of getters. App Optimization Considers All Performance Layers. Although critical, <b>tuning</b> JVM is not enough to ensure ...", "dateLastCrawled": "2022-01-30T01:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Fine</b> <b>Tuning</b> Your JetSki: All You Need to Know About Carburetors ...", "url": "https://media.vintagejetski.com/fine-tuning-your-jetski/", "isFamilyFriendly": true, "displayUrl": "https://media.vintagejetski.com/<b>fine</b>-<b>tuning</b>-your-jetski", "snippet": "Power <b>tuning</b> \u2013 Many shops offer \u201cpower <b>tuning</b>\u201d as a means of <b>adjusting</b> carburetion. The boat is held stationary in a test tank or on a trailer backed into the water so that adjustments can be made while the engine is running under a load. This type of <b>tuning</b> is adequate for getting carburetion close, however it is by no means an effective way to achieve the ideal mid-range or full throttle carb settings. Power <b>tuning</b> does not simulate the added loads of the water drag on the hull ...", "dateLastCrawled": "2022-02-03T15:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fine</b> <b>tuning</b> a classifier in scikit-learn | by Kevin Arvai | Towards ...", "url": "https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>fine</b>-<b>tuning</b>-a-classifier-in-scikit-learn-66e048c21e65", "snippet": "<b>Fine</b> <b>tuning</b> a classifier in scikit-learn. Kevin Arvai. Jan 24, 2018 \u00b7 6 min read. It\u2019s easy to understand that many <b>machine</b> learning problems benefit from either precision or recall as their optimal performance metric but implementing the concept requires knowledge of a detailed process. My first few attempts to <b>fine</b>-tune models for recall ...", "dateLastCrawled": "2022-02-02T02:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "object detection - <b>Fine-tuning and transfer learning by the example</b> of ...", "url": "https://stackoverflow.com/questions/55118883/fine-tuning-and-transfer-learning-by-the-example-of-yolo", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/55118883", "snippet": "<b>machine</b>-learning object-detection yolo transfer-learning. Share. Follow edited Aug 3 &#39;20 at 11:27. David Buck . 3,486 33 33 gold badges 27 27 silver badges 34 34 bronze badges. asked Mar 12 &#39;19 at 10:09. kaktus kaktus. 89 1 1 gold badge 1 1 silver badge 9 9 bronze badges. Add a comment | 2 Answers Active Oldest Votes. 3 If you are using AlexeyAB&#39;s darknet repo (not darkflow), he suggests to do <b>Fine</b>-<b>Tuning</b> instead of Transfer Learning by setting this param in cfg file : stopbackward=1. Then ...", "dateLastCrawled": "2022-01-26T11:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Fine-tuning a high performance machine</b> | Turning Myself from Fat to Fit", "url": "https://turningfattofit.wordpress.com/2010/09/12/fine-tuning-a-high-performance-machine/", "isFamilyFriendly": true, "displayUrl": "https://turningfattofit.wordpress.com/2010/09/12/<b>fine-tuning-a-high-performance-machine</b>", "snippet": "<b>Fine-tuning a high performance machine</b> 12 September 2010 Matt archery tarkwin, tech Comments Off on <b>Fine-tuning a high performance machine</b>. Flickr CC-BY ladymixy-uk. September is the end of the summer/outdoor season for archery in England as autumn is now in full flow, the nights are coming sooner and ending later, and the cold, wind and rain are on the way. (More than usual, anyway). Archery clubs throughout the land are preparing for the start of the indoor season, where we all stand in ...", "dateLastCrawled": "2021-12-28T00:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>SVM Hyperparameter Tuning using GridSearchCV | ML</b> - GeeksforGeeks", "url": "https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/<b>svm-hyperparameter-tuning-using-gridsearchcv-ml</b>", "snippet": "<b>SVM Hyperparameter Tuning using GridSearchCV | ML</b>. <b>A Machine</b> Learning model is defined as a mathematical model with a number of parameters that need to be learned from the data. However, there are some parameters, known as Hyperparameters and those cannot be directly learned. They are commonly chosen by humans based on some intuition or hit and ...", "dateLastCrawled": "2022-02-02T15:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fine tuning the bed levelling procedure</b>. - Ultimaker Cura - Ultimaker ...", "url": "https://community.ultimaker.com/topic/5855-fine-tuning-the-bed-levelling-procedure/", "isFamilyFriendly": true, "displayUrl": "https://community.ultimaker.com/topic/5855-<b>fine-tuning-the-bed-levelling-procedure</b>", "snippet": "It&#39;s exactly the feature you describe. I think it is in the tune menu and called something <b>like</b> z-tweak. I don&#39;t think it&#39;s available for um2. Please update your profile to say what printer/printers you have. Link to post Share on other sites. More sharing options... donmilne 2 Posted July 5, 2014. donmilne. Member; 2 424 posts; Author; Share; Posted July 5, 2014 \u00b7 <b>Fine tuning the bed levelling procedure</b>. I have a UM2. I don&#39;t see anything in my profile to indicate my printer. I&#39;m afraid ...", "dateLastCrawled": "2022-01-16T15:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[D] What are the best practices for <b>fine</b>-<b>tuning</b> ResNet? : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/ncf0a6/d_what_are_the_best_practices_for_finetuning/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/ncf0a6/d_what_are_the_best_practices_for_<b>finetuning</b>", "snippet": "3. level 2. sobe86. \u00b7 3m. Upsampling the minority class can work a lot better than loss <b>adjusting</b> if they are so rare that you&#39;re not seeing at least one per minibatch - model can end up basically ignoring it completely. Also it will converge much faster. 1. level 1. deephugs.", "dateLastCrawled": "2021-08-11T11:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>parameter tuning in machine learning? - Quora</b>", "url": "https://www.quora.com/What-is-parameter-tuning-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>parameter-tuning-in-machine-learning</b>", "snippet": "Answer (1 of 3): Hyperparameters contain the data that govern the training process itself. Your training application handles three categories of data as it trains your model: * Your input data (also called training data) is a collection of individual records (instances) containing the features...", "dateLastCrawled": "2022-01-17T00:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>fine tuning</b> in economics? - FindAnyAnswer.com", "url": "https://findanyanswer.com/what-is-fine-tuning-in-economics", "isFamilyFriendly": true, "displayUrl": "https://findanyanswer.com/what-is-<b>fine-tuning</b>-in-economics", "snippet": "<b>Fine Tuning</b>. <b>Fine tuning</b> refers to the process of adjustment that brings equilibrium in the economy. The economy is a dynamic one. In these situations, government authorities change some factors so that the economy would reaches to the equilibrium level. This process of changes in the factors is known as <b>fine tuning</b>.", "dateLastCrawled": "2022-01-28T15:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>the difference between Transfer Learning vs</b> <b>Fine</b> <b>Tuning</b> vs ...", "url": "https://www.researchgate.net/post/What-is-the-difference-between-Transfer-Learning-vs-Fine-Tuning-vs-Learning-from-scratch", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What-is-<b>the-difference-between-Transfer-Learning-vs</b>...", "snippet": "<b>Fine</b>-<b>tuning</b> is the small improvement made to NN by <b>adjusting</b> hyperparameters like learning rate, method of parameter initialization, etc. Transfer learning, on the other hand, is the technique in ...", "dateLastCrawled": "2022-01-30T04:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>A comparative study of</b> <b>fine</b>-<b>tuning</b> deep learning models for plant ...", "url": "https://www.sciencedirect.com/science/article/pii/S0168169917313303", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0168169917313303", "snippet": "<b>Fine</b>-<b>tuning</b> the models. <b>Fine</b>-<b>tuning</b> is a concept of transfer learning. Transfer learning is <b>a machine</b> learning technique, where knowledge gain during training in one type of problem is used to train in other related task or domain (Pan and Fellow, 2009). In deep learning, the first few layers are trained to identify features of the task. During ...", "dateLastCrawled": "2022-01-26T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fine</b>-<b>Tuning</b> NLP Models With Hugging Face | by Kedion | Medium", "url": "https://kedion.medium.com/fine-tuning-nlp-models-with-hugging-face-f92d55949b66", "isFamilyFriendly": true, "displayUrl": "https://kedion.medium.com/<b>fine</b>-<b>tuning</b>-nlp-models-with-hugging-face-f92d55949b66", "snippet": "Generally, <b>fine</b>-<b>tuning</b> involves the following steps: Collecting data for training. Selecting a model that has been pre-trained on data that\u2019s <b>similar</b> to your dataset. Preprocessing data in accordance with the model\u2019s expected input format. <b>Fine</b>-<b>tuning</b> and training our model until we achieve sufficient performance. Note that with transfer learning, pre-trained models aren\u2019t fully retrained \u2014 only the output layers are trained on the new dataset, while the rest is left as-is. This is ...", "dateLastCrawled": "2022-02-02T11:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Fine</b> <b>tuning</b> a classifier in scikit-learn | by Kevin Arvai | Towards ...", "url": "https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>fine</b>-<b>tuning</b>-a-classifier-in-scikit-learn-66e048c21e65", "snippet": "<b>Fine</b> <b>tuning</b> a classifier in scikit-learn. Kevin Arvai. Jan 24, 2018 \u00b7 6 min read. It\u2019s easy to understand that many <b>machine</b> learning problems benefit from either precision or recall as their optimal performance metric but implementing the concept requires knowledge of a detailed process. My first few attempts to <b>fine</b>-tune models for recall ...", "dateLastCrawled": "2022-02-02T02:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Fine Tuning Bread Machine Mixes</b> - <b>EzineArticles</b>", "url": "https://ezinearticles.com/?Fine-Tuning-Bread-Machine-Mixes&id=24134", "isFamilyFriendly": true, "displayUrl": "https://<b>ezinearticles.com</b>/?<b>Fine-Tuning-Bread-Machine-Mixes</b>&amp;id=24134", "snippet": "The other method for <b>fine</b> <b>tuning</b> is <b>adjusting</b> the temperature of the water. All of our bread <b>machine</b> mixes are developed with water at 80 degrees and a specified water temperature range of 75 to 85 degrees. As a rule of thumb, if your kitchen is chilly, use water at 85 degrees. If hot, use water at 75 degrees. Increasing or decreasing the water temperature will change the rate of the yeast growth substantially. So if the dough ball indicates the right consistency, then you can speed or ...", "dateLastCrawled": "2022-01-19T14:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Fine-tuning with Keras and Deep Learning</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2019/06/03/<b>fine-tuning-with-keras-and-deep-learning</b>", "snippet": "Figure 1: <b>Fine-tuning with Keras and deep learning</b> using Python involves retraining the head of a network to recognize classes it was not originally intended for. Note: The following section has been adapted from my book, Deep Learning for Computer Vision with Python.For the full set of chapters on transfer learning and <b>fine</b>-<b>tuning</b>, please refer to the text. Earlier in this series of posts on transfer learning, we learned how to treat a pre-trained Convolutional Neural Network as a feature ...", "dateLastCrawled": "2022-02-02T20:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fine</b>-<b>tuning</b> BERT and RoBERTa for high accuracy text <b>classification</b> in ...", "url": "https://towardsdatascience.com/fine-tuning-bert-and-roberta-for-high-accuracy-text-classification-in-pytorch-c9e63cf64646", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>fine</b>-<b>tuning</b>-bert-and-roberta-for-high-accuracy-text...", "snippet": "During <b>fine</b> <b>tuning</b> stage, additional layers can be added to the model for specific tasks, which can be different from those for which the model was initially trained. This technique is related to transfer learning, a concept applied to areas of <b>machine</b> learning beyond NLP (see here and here for a quick intro).", "dateLastCrawled": "2022-01-28T08:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "computer vision - <b>Fine Tuning</b> vs. Transferlearning vs. Learning from ...", "url": "https://stats.stackexchange.com/questions/343763/fine-tuning-vs-transferlearning-vs-learning-from-scratch", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/343763", "snippet": "In <b>Fine-tuning</b>, an approach of Transfer Learning, we have a dataset, and we use let&#39;s say 90% of it in training. Then, we train the same model with the remaining 10%. Usually, we change the learning rate to a smaller one, so it does not have a significant impact on the already adjusted weights. You can also have a base model working for a <b>similar</b> task and then freezing some of the layers to keep the old knowledge when performing the new training session with the new data. The output layer ...", "dateLastCrawled": "2022-01-23T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>parameter tuning in machine learning? - Quora</b>", "url": "https://www.quora.com/What-is-parameter-tuning-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>parameter-tuning-in-machine-learning</b>", "snippet": "Answer (1 of 3): Hyperparameters contain the data that govern the training process itself. Your training application handles three categories of data as it trains your model: * Your input data (also called training data) is a collection of individual records (instances) containing the features...", "dateLastCrawled": "2022-01-17T00:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>fine tuning</b> in economics? - FindAnyAnswer.com", "url": "https://findanyanswer.com/what-is-fine-tuning-in-economics", "isFamilyFriendly": true, "displayUrl": "https://findanyanswer.com/what-is-<b>fine-tuning</b>-in-economics", "snippet": "<b>Fine Tuning</b>. <b>Fine tuning</b> refers to the process of adjustment that brings equilibrium in the economy. The economy is a dynamic one. In these situations, government authorities change some factors so that the economy would reaches to the equilibrium level. This process of changes in the factors is known as <b>fine tuning</b>.", "dateLastCrawled": "2022-01-28T15:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Adjusting</b> Behavior to Changing Environmental Demands with Development", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3751996/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3751996", "snippet": "This experiential dependent <b>fine</b>-<b>tuning</b> proceeds more slowly in the less mature system as evidenced by a similar imbalance during adolescence as described earlier (Chein et al., 2011; Galvan et al., 2006; Somerville et al., 2011). Both examples show how cognitive control may be particularly vulnerable in the context of rare reward-related cues and alter behavioral flexibility of the individual.", "dateLastCrawled": "2022-01-29T14:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "computer vision - <b>Fine Tuning</b> vs. Transferlearning vs. Learning from ...", "url": "https://stats.stackexchange.com/questions/343763/fine-tuning-vs-transferlearning-vs-learning-from-scratch", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/343763", "snippet": "In <b>Fine-tuning</b>, an approach of Transfer Learning, we have a dataset, and we use let&#39;s say 90% of it in training. Then, we train the same model with the remaining 10%. Usually, we change the learning rate to a smaller one, so it does not have a significant impact on the already adjusted weights. You <b>can</b> also have a base model working for a similar task and then freezing some of the layers to keep the old knowledge when performing the new training session with the new data. The output layer ...", "dateLastCrawled": "2022-01-23T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Change input shape dimensions for <b>fine</b>-<b>tuning</b> with Keras - PyImageSearch", "url": "https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-<b>fine</b>-<b>tuning</b>...", "snippet": "This code would typically be utilized when you\u2019re performing transfer learning either via feature extraction or <b>fine</b>-<b>tuning</b>. Finally, we <b>can</b> update our code to include an input_tensor dimension: model = VGG16(weights=&quot;imagenet&quot;, include_top=False, input_tensor=Input(shape=(224, 224, 3))) We\u2019re still loading VGG16 with weights pre-trained on ImageNet and we\u2019re still leaving off the FC layer heads\u2026but now we\u2019re specifying an input shape of 224\u00d7224x3 (which are the input image ...", "dateLastCrawled": "2022-02-01T06:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is model <b>tuning</b> in <b>machine</b> learning? - Quora", "url": "https://www.quora.com/What-is-model-tuning-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-model-<b>tuning</b>-in-<b>machine</b>-learning", "snippet": "Answer (1 of 2): <b>Tuning</b> is the process of maximizing a model&#39;s performance without overfitting or creating too high of a variance. In <b>machine</b> learning, this is accomplished by selecting appropriate \u201chyperparameters.\u201d Hyperparameters <b>can</b> <b>be thought</b> of as the \u201cdials\u201d or \u201cknobs\u201d of <b>a machine</b> learnin...", "dateLastCrawled": "2022-01-06T05:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Seymour Duncan</b> <b>Fine</b>-<b>Tuning</b> Pickup Height and Other Passive Humbucker ...", "url": "https://www.seymourduncan.com/blog/latest-updates/fine-tuning-the-adjustment-of-passive-humbuckers", "isFamilyFriendly": true, "displayUrl": "https://<b>www.seymourduncan.com</b>/blog/latest-updates/<b>fine</b>-<b>tuning</b>-the-adjustment-of...", "snippet": "I though all this was about <b>adjusting</b> guitar pickups and <b>fine</b> <b>tuning</b> their sensitivity through <b>adjusting</b> the screws, not a gramm ar lesson, but thanks, I got both lessons as a bonus, Now I <b>can</b> say Im a grand parent! Yea! Log in to Reply. Gary Vogel says: March 18, 2013 at 5:33 pm . This may be a personal crusade or simply tilting at windmills due to the huge misuse of this by even some experts, but\u2026the correct term for magnetic or acoustic or any physical attenuation of cyclical energy is ...", "dateLastCrawled": "2022-02-01T21:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[D] What are the best practices for <b>fine</b>-<b>tuning</b> ResNet? : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/ncf0a6/d_what_are_the_best_practices_for_finetuning/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/ncf0a6/d_what_are_the_best_practices_for_<b>finetuning</b>", "snippet": "3. level 2. sobe86. \u00b7 3m. Upsampling the minority class <b>can</b> work a lot better than loss <b>adjusting</b> if they are so rare that you&#39;re not seeing at least one per minibatch - model <b>can</b> end up basically ignoring it completely. Also it will converge much faster. 1. level 1. deephugs.", "dateLastCrawled": "2021-08-11T11:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Calibrate Your Printer to Get</b> Correct Color", "url": "https://www.thoughtco.com/calibrate-your-printer-1073954", "isFamilyFriendly": true, "displayUrl": "https://www.<b>thought</b>co.com/calibrate-your-printer-1073954", "snippet": "Within the printer driver are controls for <b>fine</b>-<b>tuning</b> the overall appearance of color from your printer. Depending on your needs, this may be sufficient to get the color you want. If you want to move beyond the basics of color calibration, you have two general methods to select from: visual and mechanical. The more expensive and accurate option is to use a hardware device that <b>can</b> read the output from your printer and make adjustments as necessary. For most people, visual calibration or the ...", "dateLastCrawled": "2022-02-02T07:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Adjusting</b> a <b>turntable</b> to the &#39;exact&#39; speed...<b>can</b> this be done ...", "url": "https://forums.digitalspy.com/discussion/1153129/adjusting-a-turntable-to-the-exact-speed-can-this-be-done", "isFamilyFriendly": true, "displayUrl": "https://forums.digitalspy.com/discussion/1153129/<b>adjusting</b>-a-<b>turntable</b>-to-the-exact...", "snippet": "At 33 1/3 (LP) speed it should be 8 1/3 (you <b>can</b> gauge the 1/3 roughly) Adjust speed accordingly. then if you want to <b>fine</b> tune count the no of revs made in a minute, should be 33 1/3 or thereabouts. For the singles (45) speed the 15 sec figure is 11 1/4 revs per 15 secs, 45 revs per minute. 0.", "dateLastCrawled": "2022-01-29T04:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Adjusting a lathe to cut straight</b> - <b>Practical Machinist</b>", "url": "https://www.practicalmachinist.com/vb/general/adjusting-lathe-cut-straight-304890/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.practicalmachinist.com</b>/vb/general/<b>adjusting</b>-lathe-cut-straight-304890", "snippet": "The members <b>can</b> go back in the archives and see what I have been writing about <b>machine</b> bed alignment, <b>machine</b> rebuilding and teaching people the correct way because I am a Professional. I will be teaching a class next week for the US Corp of Engineers, Going to teach a 2 week class in July at a large corporation, scrape <b>a machine</b> in Texas in August, go to Germany and teach and consult in <b>machine</b> building / rebuilding October and November, etc. I don&#39;t have to pretend and BS people about such ...", "dateLastCrawled": "2021-10-29T10:51:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>A comparative study of</b> <b>fine</b>-<b>tuning</b> deep learning models for plant ...", "url": "https://www.sciencedirect.com/science/article/pii/S0168169917313303", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0168169917313303", "snippet": "<b>Fine</b>-<b>tuning</b> the models. <b>Fine</b>-<b>tuning</b> is a concept of transfer learning. Transfer learning is <b>a machine</b> learning technique, where knowledge gain during training in one type of problem is used to train in other related task or domain (Pan and Fellow, 2009). In deep learning, the first few layers are trained to identify features of the task. During ...", "dateLastCrawled": "2022-01-26T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "computer vision - <b>Fine Tuning</b> vs. Transferlearning vs. Learning from ...", "url": "https://stats.stackexchange.com/questions/343763/fine-tuning-vs-transferlearning-vs-learning-from-scratch", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/343763", "snippet": "In <b>Fine-tuning</b>, an approach of Transfer Learning, we have a dataset, and we use let&#39;s say 90% of it in training. Then, we train the same model with the remaining 10%. Usually, we change the learning rate to a smaller one, so it does not have a significant impact on the already adjusted weights. You <b>can</b> also have a base model working for a similar task and then freezing some of the layers to keep the old knowledge when performing the new training session with the new data. The output layer ...", "dateLastCrawled": "2022-01-23T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Fine</b> <b>tuning</b> a classifier in scikit-learn | by Kevin Arvai | Towards ...", "url": "https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>fine</b>-<b>tuning</b>-a-classifier-in-scikit-learn-66e048c21e65", "snippet": "<b>Fine</b> <b>tuning</b> a classifier in scikit-learn. Kevin Arvai. Jan 24, 2018 \u00b7 6 min read. It\u2019s easy to understand that many <b>machine</b> learning problems benefit from either precision or recall as their optimal performance metric but implementing the concept requires knowledge of a detailed process. My first few attempts to <b>fine</b>-tune models for recall ...", "dateLastCrawled": "2022-02-02T02:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Man vs <b>machine: comparing artificial and biological neural networks</b> ...", "url": "https://news.sophos.com/en-us/2017/09/21/man-vs-machine-comparing-artificial-and-biological-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://news.sophos.com/en-us/2017/09/21/man-vs-<b>machine</b>-comparing-artificial-and...", "snippet": "This process is called <b>fine</b>-<b>tuning</b> and consists of <b>adjusting</b> the weights from a pre-trained network topology at a relatively slow learning rate to perform well on newly supplied input training data. We <b>can</b> also effortlessly replicate ANNs, but we have a while to go before we <b>can</b> do that for a human brain. Whether training from scratch or <b>fine</b>-<b>tuning</b>, the weight update process begins by passing data through the neural network, measuring the outcome, and modifying the weights accordingly. This ...", "dateLastCrawled": "2022-02-02T14:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Change input shape dimensions for <b>fine</b>-<b>tuning</b> with Keras - PyImageSearch", "url": "https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-<b>fine</b>-<b>tuning</b>...", "snippet": "<b>Fine</b>-<b>tuning</b> a CNN using the updated input dimensions Figure 4: Changing Keras input shape dimensions for <b>fine</b>-<b>tuning</b> produced the following accuracy/loss training plot. To <b>fine</b>-tune our CNN using the updated input dimensions first make sure you\u2019ve used the \u201cDownloads\u201d section of this guide to download the (1) source code and (2) example dataset.", "dateLastCrawled": "2022-02-01T06:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Microfabricated Bandpass Filter with Coarse-<b>Tuning</b> and <b>Fine</b>-<b>Tuning</b> ...", "url": "https://www.mdpi.com/2072-666X/13/1/123/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-666X/13/1/123/htm", "snippet": "In this paper, a bandpass filter (BPF) was developed utilizing GaAs-based integrated passive device technology which comprises an asymmetrical spiral inductor and an interleaved array capacitor, possessing two <b>tuning</b> modes: coarse-<b>tuning</b> and <b>fine</b>-<b>tuning</b>. By altering the number of layers and radius of the GaAs substrate metal spheres, capacitance variation from 0.071 to 0.106 pF for coarse-<b>tuning</b>, and of 0.0015 pF for <b>fine</b>-<b>tuning</b>, <b>can</b> be achieved. Five air bridges were employed in the ...", "dateLastCrawled": "2022-02-01T00:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "EP3248148A1 - Model compression and <b>fine</b>-<b>tuning</b> - Google Patents", "url": "https://patents.google.com/patent/EP3248148A1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/EP3248148A1/en", "snippet": "[0088] During <b>fine</b>-<b>tuning</b>, we may choose to <b>fine</b>-tune only the new compressed layers or all the layers together (which may be referred to as full stack <b>fine</b>-<b>tuning</b>) or a subset of the compressed and uncompressed layers. The compressed layers as shown for example in FIGURES 5B and 6B are another instance of the fully-connected layer type as shown, respectively, in FIGURES 5A and 6A. Thus, the design or", "dateLastCrawled": "2021-11-25T18:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Evaluating Machine Learning Model Performance</b> | Engineering Education ...", "url": "https://www.section.io/engineering-education/evaluating-ml-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://www.section.io/engineering-education/evaluating-ml-model-performance", "snippet": "It includes a set of input examples that will be used to train a model by <b>adjusting</b> the parameters of the set. Validation set \u2013 is a subset of a dataset whose purpose is to assess the performance of the model built, during the training phase. It periodically evaluates a model and allows for <b>fine</b>-<b>tuning</b> of the parameters of the model.", "dateLastCrawled": "2022-01-23T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[D] What are the best practices for <b>fine</b>-<b>tuning</b> ResNet? : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/ncf0a6/d_what_are_the_best_practices_for_finetuning/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/ncf0a6/d_what_are_the_best_practices_for_<b>finetuning</b>", "snippet": "3. level 2. sobe86. \u00b7 3m. Upsampling the minority class <b>can</b> work a lot better than loss <b>adjusting</b> if they are so rare that you&#39;re not seeing at least one per minibatch - model <b>can</b> end up basically ignoring it completely. Also it will converge much faster. 1. level 1. deephugs.", "dateLastCrawled": "2021-08-11T11:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Cross-Validation</b> and Hyperparameter <b>Tuning</b>: How to Optimise your ...", "url": "https://towardsdatascience.com/cross-validation-and-hyperparameter-tuning-how-to-optimise-your-machine-learning-model-13f005af9d7d", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>cross-validation</b>-and-hyperparameter-<b>tuning</b>-how-to...", "snippet": "Now that we know what <b>Cross-Validation</b> is and why it is important let\u2019s see if we <b>can</b> get more out of our models by <b>tuning</b> the hyperparameters. Hyperparameter <b>Tuning</b>. Unlike model parameters, which are learned during model training and <b>can</b> not be set arbitrarily, hyperparameters are parameters that <b>can</b> be set by the user before training <b>a Machine</b> Learning model. Examples of hyperparameters in a Random Forest are the number of decision trees to have in the forest, the maximum number of ...", "dateLastCrawled": "2022-02-02T15:32:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Transfer Learning/Fine-Tuning a</b> Deep <b>Learning</b> Model - <b>Machine</b> <b>Learning</b>", "url": "https://datastronomy.com/eli5-transfer-learning-fine-tuning-a-deep-learning-model/", "isFamilyFriendly": true, "displayUrl": "https://datastronomy.com/<b>eli5-transfer-learning-fine-tuning-a</b>-deep-<b>learning</b>-model", "snippet": "What you just did was the human equivalent of transfer <b>learning</b>. You took a trained brain\u2014or stepping back from our <b>analogy</b>, a neural net\u2014and you adapted it to a specialized problem. Transfer <b>learning</b>, or <b>fine</b>-<b>tuning</b>, is a process whereby you take a deep <b>learning</b> model that has been trained on lots of data (1M+ examples) and continue training it on a smaller dataset to \u201coverfit\u201d it to that particular class of problem. The model becomes inferior at its original task and better at the ...", "dateLastCrawled": "2022-01-19T02:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What Is <b>Machine</b> <b>Learning</b> (Explained in 5 Minutes) | 365 Data Science", "url": "https://365datascience.com/trending/machine-learning-explained-in-5-minutes/", "isFamilyFriendly": true, "displayUrl": "https://365datascience.com/trending/<b>machine</b>-<b>learning</b>-explained-in-5-minutes", "snippet": "So, very often the art of the data scientist and <b>Machine</b> <b>Learning</b> engineer professions is in the <b>fine</b>-<b>tuning</b> of an already well-performing model. In some cases, a 0.1% improvement in accuracy could be of important significance \u2013 especially when the ML model is applied in areas like healthcare , fraud prevention , and self-driving vehicles.", "dateLastCrawled": "2022-01-26T20:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "13.2. <b>Fine</b>-<b>Tuning</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/fine-tuning.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>fine</b>-<b>tuning</b>.html", "snippet": "13.2.1. Steps\u00b6. In this section, we will introduce a common technique in transfer <b>learning</b>: <b>fine</b>-<b>tuning</b>.As shown in Fig. 13.2.1, <b>fine</b>-<b>tuning</b> consists of the following four steps:. Pretrain a neural network model, i.e., the source model, on a source dataset (e.g., the ImageNet dataset).. Create a new neural network model, i.e., the target model.This copies all model designs and their parameters on the source model except the output layer.", "dateLastCrawled": "2022-02-02T04:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fine-tuning with Keras and Deep Learning</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2019/06/03/<b>fine-tuning-with-keras-and-deep-learning</b>", "snippet": "A standard <b>machine</b> <b>learning</b> classifier (in our case, Logistic Regression), was trained on top of the CNN features, exactly as we would do with hand-engineered features such as SIFT, HOG, LBPs, etc. This approach to transfer <b>learning</b> is called feature extraction. But there is another type of transfer <b>learning</b>, one that can actually outperform the feature extraction method. This method is called <b>fine</b>-<b>tuning</b> and requires us to perform \u201cnetwork surgery\u201d. First, we take a scalpel and cut off ...", "dateLastCrawled": "2022-02-02T20:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "TRANSFER <b>LEARNING</b> AND <b>FINE</b> <b>TUNING</b> OF NEURAL NETWORKS", "url": "https://www.indusmic.com/post/transfer-learning-and-fine-tuning-of-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://www.indusmic.com/post/transfer-<b>learning</b>-and-<b>fine</b>-<b>tuning</b>-of-neural-networks", "snippet": "Author: Parakh Jain Human beings are able to learn, detect objects and classify them with their eyes. If we want to learn the difference between objects like cars and trucks. First we need to see the images of cars and trucks and will learn from the images. Only then we are able to distinguish between cars and trucks. Similarly, a <b>machine</b> needs data from which it can learn and make able to distinguish and classify images. Training a Model from Scratch <b>Learning</b> from scratch means building a netwo", "dateLastCrawled": "2022-01-31T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Transfer <b>Learning</b>: The Highest Leverage Deep <b>Learning</b> Skill You Can Learn", "url": "https://www.the-analytics.club/transfer-learning", "isFamilyFriendly": true, "displayUrl": "https://www.the-analytics.club/transfer-<b>learning</b>", "snippet": "<b>Fine</b>-<b>Tuning</b>: If you are already training your own deep <b>learning</b> models or want to <b>fine</b>-tune the output of an existing model for your dataset, this approach could be a good fit for you. By using a smaller model to learn from the larger one, you can benefit from any of the work that has already been done by the larger model without having to go through all of the hassles of training it yourself. As a result, this approach is faster and more efficient than feature extraction alone.", "dateLastCrawled": "2022-01-29T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - <b>Fine</b>-<b>tuning</b> Glove Embeddings - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/50909726/fine-tuning-glove-embeddings", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/50909726", "snippet": "<b>Fine</b>-<b>tuning</b> word2vec embeddings has proven very efficient for me in a various NLP tasks, ... Also, Glove is very good at <b>analogy</b>, and performs well on the word2vec dataset. Share. Follow edited Sep 1 &#39;21 at 9:34. Timbus Calin . 10.7k 3 3 gold badges 29 29 silver badges 46 46 bronze badges. answered Sep 1 &#39;21 at 9:23. kiriloff kiriloff. 23.7k 33 33 gold badges 137 137 silver badges 210 210 bronze badges. 4. Very suggestive explanation and summary in short time. \u2013 Timbus Calin. Sep 1 &#39;21 at ...", "dateLastCrawled": "2022-01-15T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Should I Learn Machine Learning</b>? | GenUI", "url": "https://www.genui.com/resources/ml-for-developers", "isFamilyFriendly": true, "displayUrl": "https://www.genui.com/resources/ml-for-developers", "snippet": "It\u2019s no longer necessary to have an advanced degree in data science to make use of <b>machine</b> <b>learning</b>. The <b>analogy</b> we like to give is with databases. Every seasoned developer knows about databases, both SQL and NoSQL, and knows enough about them to use them effectively in typical projects. Yes, there\u2019s a subset of projects, of such complexity or scale, where average database knowledge is not enough. In those cases, expert knowledge of things like performance <b>tuning</b> and database ...", "dateLastCrawled": "2022-01-30T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How <b>to use ConvNets in different ways - a brief analogy</b> | by Himanshu ...", "url": "https://medium.com/voice-tech-podcast/how-to-use-convnets-in-different-ways-a-brief-analogy-1b69c3e88f3b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/.../how-<b>to-use-convnets-in-different-ways-a-brief-analogy</b>-1b69c3e88f3b", "snippet": "<b>Fine</b>-<b>tuning</b> the Pre-trained ConvNets \u2014 Transfer <b>Learning</b>. <b>Fine</b>-<b>tuning</b> means taking weights of a trained neural network and use it as initialization for a new model being trained on data from the ...", "dateLastCrawled": "2021-05-19T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Face Recognition using <b>Transfer Learning</b> | by Chirag Goel | Medium", "url": "https://medium.com/@chiraggoelit/face-recognition-using-transfer-learning-9986728c443d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@chiraggoelit/face-recognition-using-<b>transfer-learning</b>-9986728c443d", "snippet": "One of the popular <b>Machine</b> <b>Learning</b> Algorithms for Face Recognition is LBPH. Concept of <b>Transfer Learning</b> and <b>Fine</b> <b>Tuning</b> . <b>Transfer Learning</b>. <b>Transfer learning</b> is a method by which we can utilize ...", "dateLastCrawled": "2022-01-29T16:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What Is Fine Tuning In <b>Machine</b> <b>Learning</b>? \u2013 chetumenu.com", "url": "https://chetumenu.com/what-is-fine-tuning-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://chetumenu.com/what-is-fine-tuning-in-<b>machine</b>-<b>learning</b>", "snippet": "Related Question for What Is Fine Tuning In <b>Machine</b> <b>Learning</b>? What is Pretraining and fine tuning? 1. The answer is a mere difference in the terminology used. When the model is trained on a large generic corpus, it is called &#39;pre-training&#39;. When it is adapted to a particular task or dataset it is called as &#39;fine-tuning&#39;. Is fine tuning necessary? A Simple Fine-tuning Is All You Need: Towards Robust Deep <b>Learning</b> Via Adversarial Fine-tuning. Adversarial Training (AT) with Projected Gradient ...", "dateLastCrawled": "2021-12-16T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>the difference between Transfer Learning vs</b> Fine Tuning vs ...", "url": "https://www.researchgate.net/post/What-is-the-difference-between-Transfer-Learning-vs-Fine-Tuning-vs-Learning-from-scratch", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What-is-<b>the-difference-between-Transfer-Learning-vs</b>...", "snippet": "<b>Fine tuning is like</b> optimization. We optimize the network to achieve the optimal results. May be we can change the number of layers used, no of filters, <b>learning</b> rate and we have many parameters ...", "dateLastCrawled": "2022-01-30T04:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Gentle Introduction to <b>Transfer Learning</b> in NLP | by Neil Sinclair ...", "url": "https://towardsdatascience.com/a-gentle-introduction-to-transfer-learning-in-nlp-b71e87241d66", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-gentle-introduction-to-<b>transfer-learning</b>-in-nlp-b71e...", "snippet": "To give you a sense of the difference between fine-tuning and training a model, <b>fine-tuning is like</b> taking your car to the mechanic and getting new spark plugs whereas training/pre-training is like getting a whole new engine. As a concrete example, let\u2019s say you run a large food delivery company and you want to get the sentiment (positive or negative intention) of tweets people make about your company so you can quickly attend to the negative ones. Considering you have enough tweets to ...", "dateLastCrawled": "2022-02-02T23:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Philosophers On GPT-3 (updated with replies by GPT-3) | <b>Daily Nous</b>", "url": "https://dailynous.com/2020/07/30/philosophers-gpt-3/", "isFamilyFriendly": true, "displayUrl": "https://<b>dailynous</b>.com/2020/07/30/philosophers-gpt-3", "snippet": "<b>Fine-tuning is like</b> cramming for an exam. The benefit of this is that you do much better in that one exam, but you can end up performing worse on others as a result. In-context <b>learning</b> is like taking the exam after looking at the instructions and some sample questions. GPT-3 might not reach the performance of a student that crams for one particular exam if it doesn\u2019t cram too, but it can wander into a series of exam rooms and perform pretty well from just looking at the paper. It performs ...", "dateLastCrawled": "2022-02-02T10:11:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>learning</b> \u2014 Deep Boltzmann <b>Machine</b> (DBM) | by Renu Khandelwal ...", "url": "https://medium.datadriveninvestor.com/deep-learning-deep-boltzmann-machine-dbm-e3253bb95d0f", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/deep-<b>learning</b>-deep-boltzmann-<b>machine</b>-dbm-e3253bb...", "snippet": "Boltzmann <b>machine</b> uses randomly initialized Markov chains to approximate the gradient of the likelihood function which is too slow to be practical. DBM uses greedy layer by layer pre training to speed up <b>learning</b> the weights. It relies on <b>learning</b> stacks of Restricted Boltzmann <b>Machine</b> with a small modification using contrastive divergence.", "dateLastCrawled": "2022-01-31T21:17:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(fine tuning)  is like +(adjusting a machine)", "+(fine tuning) is similar to +(adjusting a machine)", "+(fine tuning) can be thought of as +(adjusting a machine)", "+(fine tuning) can be compared to +(adjusting a machine)", "machine learning +(fine tuning AND analogy)", "machine learning +(\"fine tuning is like\")", "machine learning +(\"fine tuning is similar\")", "machine learning +(\"just as fine tuning\")", "machine learning +(\"fine tuning can be thought of as\")", "machine learning +(\"fine tuning can be compared to\")"]}