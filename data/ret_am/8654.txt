{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Types of Algorithms With Different <b>Machine Learning</b> <b>Algorithm</b> Examples", "url": "https://www.analytixlabs.co.in/blog/types-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analytixlabs.co.in/blog/types-of-<b>machine-learning</b>", "snippet": "Linear Regression is <b>a Machine Learning</b> <b>algorithm</b> that maps numeric inputs to numeric outputs, by fitting a line <b>into</b> the <b>data</b> points. Simply put, Linear Regression is a way of modeling the relationship between one or more independent variables in a way that they come together to form a driving force for the dependent <b>numerical</b> variable. It is typically identified by the linear equation:", "dateLastCrawled": "2022-01-31T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Top 45 <b>Machine</b> <b>Learning</b> Interview Questions Answered for 2022 | Simplilearn", "url": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/machine-learning-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/<b>machine</b>-<b>learning</b>-tutorial/<b>machine</b>-<b>learning</b>...", "snippet": "<b>Machine</b> <b>Learning</b> Deep <b>Learning</b>; <b>Enables</b> machines to take decisions on their own, based on past <b>data</b>; It needs only a small amount of <b>data</b> for training ; Works well on the low-end system, so <b>you</b> don&#39;t need large machines Most <b>features</b> need to be identified in advance and manually coded; The problem is divided <b>into</b> two parts and solved individually and then combined; <b>Enables</b> machines to take decisions with the help of artificial neural networks; It needs a large amount of training <b>data</b> Needs ...", "dateLastCrawled": "2022-02-02T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Featurization with <b>automated machine learning</b> - Azure <b>Machine Learning</b> ...", "url": "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features", "isFamilyFriendly": true, "displayUrl": "https://docs.microsoft.com/en-us/azure/<b>machine-learning</b>/how-to-configure-auto-<b>features</b>", "snippet": "In Azure <b>Machine Learning</b>, <b>data</b>-scaling and normalization techniques are applied to make feature engineering easier. ... Transform numeric <b>features</b> that have few unique values <b>into</b> <b>categorical</b> <b>features</b>. One-hot encoding is used for low-cardinality <b>categorical</b> <b>features</b>. One-hot-hash encoding is used for high-cardinality <b>categorical</b> <b>features</b>. Word embeddings: A text featurizer converts vectors of text tokens <b>into</b> sentence vectors by using a pre-trained model. Each word&#39;s embedding vector in a ...", "dateLastCrawled": "2022-02-02T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A guide to <b>the top machine learning algorithms</b> | by Brian Mwangi ...", "url": "https://heartbeat.comet.ml/a-guide-to-the-top-machine-learning-algorithms-722d713b9b44", "isFamilyFriendly": true, "displayUrl": "https://heartbeat.comet.ml/a-guide-to-<b>the-top-machine-learning-algorithms</b>-722d713b9b44", "snippet": "\u201c<b>Machine</b> <b>Learning</b> is using <b>data</b> to answer questions\u201d \u2014 Yufeng Guo. At its core, <b>machine</b> <b>learning</b> is about creating algorithms (sets of rules) that learn complex functions or patterns from <b>data</b> to make predictions. Each <b>machine</b> <b>learning</b> <b>algo r ithm</b> has its own strengths and weaknesses. Some models are easier to understand or interpret but lack predictive power, while others have accurate predictions but lack interpretability. Broadly speaking, <b>machine</b> <b>learning</b> is best suited for ...", "dateLastCrawled": "2022-01-16T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> \u00b7 Issue #681 \u00b7 codeanit/til \u00b7 GitHub", "url": "https://github.com/codeanit/til/issues/681", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/codeanit/til/issues/681", "snippet": "<b>Data</b> vectorization: A process that converts non-numeric <b>data</b> <b>into</b> a <b>numerical</b> format so that it can be used by <b>a machine</b> <b>learning</b> model. Silhouette coefficient: A score from -1 to 1 describing the clusters found during modeling. A score near zero indicates overlapping clusters, and scores less than zero indicate <b>data</b> points assigned to incorrect clusters. A score approaching 1 indicates successful identification of discrete non-overlapping clusters. Stop words: A list of words removed by ...", "dateLastCrawled": "2022-01-05T20:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Artificial Neural Networks</b> - Javatpoint", "url": "https://www.javatpoint.com/keras-artificial-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/keras-<b>artificial-neural-networks</b>", "snippet": "Gradient descent is an optimization <b>algorithm</b> that is utilized to minimize the cost function used in various <b>machine</b> <b>learning</b> algorithms so as to update the parameters of the <b>learning</b> model. In linear regression, these parameters are coefficients, whereas, in the neural network, they are weights. Procedure: It all starts with the coefficient&#39;s initial value or function&#39;s coefficient that may be either 0.0 or any small arbitrary value. coefficient = 0.0 For estimating the cost of the ...", "dateLastCrawled": "2022-02-02T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Keras: Feature extraction on large datasets with</b> Deep <b>Learning</b> ...", "url": "https://www.pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2019/05/27/<b>keras-feature-extraction-on-large-datasets</b>...", "snippet": "Figure 2: The process of incremental <b>learning</b> plays a role in deep <b>learning</b> <b>feature extraction on large datasets</b>. When your entire dataset does not fit <b>into</b> memory <b>you</b> need to perform incremental <b>learning</b> (sometimes called \u201conline <b>learning</b>\u201d).. Incremental <b>learning</b> <b>enables</b> <b>you</b> to train your model on small subsets of the <b>data</b> called batches.. Using incremental <b>learning</b> the training process becomes:", "dateLastCrawled": "2022-02-03T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Video classification with Keras and Deep <b>Learning</b> - <b>You</b> can master ...", "url": "https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2019/07/15/video-classification-with-keras-and-deep-<b>learning</b>", "snippet": "Video Classification with Keras and Deep <b>Learning</b>. 2020-06-12 Update: This blog post is now TensorFlow 2+ compatible! Videos can be understood as a series of individual images; and therefore, many deep <b>learning</b> practitioners would be quick to treat video classification as performing image classification a total of N times, where N is the total number of frames in a video.. There\u2019s a problem with that approach though.", "dateLastCrawled": "2022-02-03T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is XGBoost still the go-to <b>tool for machine learning on tabular data</b> ...", "url": "https://www.quora.com/Is-XGBoost-still-the-go-to-tool-for-machine-learning-on-tabular-data", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-XGBoost-still-the-go-to-<b>tool-for-machine-learning-on-tabular-data</b>", "snippet": "Answer (1 of 4): Yep. Don\u2019t forget Microsoft\u2019s newest addition to the race\u2026 lightGBM. It\u2019s a little faster and I\u2019ve seen it score a little better than XG. They are both boosters but the trees are built a little differently. When I\u2019m building models on STRUCTURED <b>data</b> I test using both of them. ...", "dateLastCrawled": "2022-01-23T20:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine</b> <b>Learning</b> with Apache Spark 101 | by Matteo Tortella | Medium", "url": "https://medium.com/@matteotortella4/machine-learning-with-apache-spark-101-8f57c27ae9b0", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@matteotortella4/<b>machine</b>-<b>learning</b>-with-apache-spark-101-8f57c27ae9b0", "snippet": "In order for us to run our model, we need <b>to turn</b> the months variable <b>into</b> a dummy variable. In ml this is a 2-step process that first requires turning the <b>categorical</b> variable <b>into</b> a <b>numerical</b> ...", "dateLastCrawled": "2021-10-05T03:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Types of Algorithms With Different <b>Machine Learning</b> <b>Algorithm</b> Examples", "url": "https://www.analytixlabs.co.in/blog/types-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analytixlabs.co.in/blog/types-of-<b>machine-learning</b>", "snippet": "The <b>machine learning</b> <b>algorithm</b> learns the patterns, creates an equation, and then finally it is able to know the price of a newly constructed house for which we know every information except of course the price. Commonly used Supervised <b>Learning</b> Algorithms. We have seen how supervised <b>learning</b> algorithms can help us predict a value and an event, various forms of supervised <b>learning</b> algorithms are designed to solve those business problems. 1. Linear Regression. Linear Regression is a <b>Machine</b> ...", "dateLastCrawled": "2022-01-31T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Offensive Language and Hate Speech Detection with Deep <b>Learning</b> and ...", "url": "https://deepai.org/publication/offensive-language-and-hate-speech-detection-with-deep-learning-and-transfer-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/offensive-language-and-hate-speech-detection-with-deep...", "snippet": "Shallow <b>machine</b> <b>learning</b> models such as decision trees, Na\u00efve Bayes, KNN, random forest etc. use bag of words, n-rams, lexical <b>features</b>, meta <b>data</b> to extract the <b>features</b> whereas deep <b>machine</b> <b>learning</b> models use word embeddings that are fed <b>into</b> neural networks such as CNN, RNN, LSTM, transformers etc. The deep <b>learning</b> models are capable of <b>learning</b> the <b>features</b> from the raw <b>data</b> which helps to better extract the context for the problem on hand and hence results in much better performance ...", "dateLastCrawled": "2022-01-27T02:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> \u00b7 Issue #681 \u00b7 codeanit/til \u00b7 GitHub", "url": "https://github.com/codeanit/til/issues/681", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/codeanit/til/issues/681", "snippet": "<b>Data</b> vectorization: A process that converts non-numeric <b>data</b> <b>into</b> a <b>numerical</b> format so that it can be used by a <b>machine</b> <b>learning</b> model. Silhouette coefficient: A score from -1 to 1 describing the clusters found during modeling. A score near zero indicates overlapping clusters, and scores less than zero indicate <b>data</b> points assigned to incorrect clusters. A score approaching 1 indicates successful identification of discrete non-overlapping clusters. Stop words: A list of words removed by ...", "dateLastCrawled": "2022-01-05T20:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "AWS <b>Machine</b> <b>Learning</b> | Zacks Blog", "url": "https://zacks.one/aws-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://zacks.one/aws-<b>machine</b>-<b>learning</b>", "snippet": "<b>Transformer</b>: A more modern replacement for RNN/LSTMs, the <b>transformer</b> architecture <b>enables</b> training over larger datasets involving sequences of <b>data</b>. <b>Machine</b> <b>Learning</b> Using Python Libraries. For more classical models (linear, tree-based) as well as a set of common ML-related tools, take a look at scikit-learn. The web documentation for this library is also organized for those getting familiar with space and can be a great place to get familiar with some extremely useful tools and techniques ...", "dateLastCrawled": "2022-01-26T13:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Top 45 <b>Machine</b> <b>Learning</b> Interview Questions Answered for 2022 | Simplilearn", "url": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/machine-learning-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/<b>machine</b>-<b>learning</b>-tutorial/<b>machine</b>-<b>learning</b>...", "snippet": "<b>Machine</b> <b>Learning</b> Deep <b>Learning</b>; <b>Enables</b> machines to take decisions on their own, based on past <b>data</b>; It needs only a small amount of <b>data</b> for training ; Works well on the low-end system, so <b>you</b> don&#39;t need large machines Most <b>features</b> need to be identified in advance and manually coded; The problem is divided <b>into</b> two parts and solved individually and then combined; <b>Enables</b> machines to take decisions with the help of artificial neural networks; It needs a large amount of training <b>data</b> Needs ...", "dateLastCrawled": "2022-02-02T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A guide to <b>machine</b> <b>learning</b> for biologists | Nature Reviews Molecular ...", "url": "https://www.nature.com/articles/s41580-021-00407-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41580-021-00407-0", "snippet": "Unless publicly available <b>data</b> are being used, it is rare that one research group will have the expertise and resources to both collect <b>data</b> for a <b>machine</b> <b>learning</b> study and also apply the most ...", "dateLastCrawled": "2022-02-02T20:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b> with Apache Spark 101 | by Matteo Tortella | Medium", "url": "https://medium.com/@matteotortella4/machine-learning-with-apache-spark-101-8f57c27ae9b0", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@matteotortella4/<b>machine</b>-<b>learning</b>-with-apache-spark-101-8f57c27ae9b0", "snippet": "In order for us to run our model, we need <b>to turn</b> the months variable <b>into</b> a dummy variable. In ml this is a 2-step process that first requires turning the <b>categorical</b> variable <b>into</b> a <b>numerical</b> ...", "dateLastCrawled": "2021-10-05T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Artificial Neural Networks</b> - Javatpoint", "url": "https://www.javatpoint.com/keras-artificial-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/keras-<b>artificial-neural-networks</b>", "snippet": "Gradient descent is an optimization <b>algorithm</b> that is utilized to minimize the cost function used in various <b>machine</b> <b>learning</b> algorithms so as to update the parameters of the <b>learning</b> model. In linear regression, these parameters are coefficients, whereas, in the neural network, they are weights. Procedure: It all starts with the coefficient&#39;s initial value or function&#39;s coefficient that may be either 0.0 or any small arbitrary value. coefficient = 0.0 For estimating the cost of the ...", "dateLastCrawled": "2022-02-02T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Video classification with Keras and Deep <b>Learning</b> - <b>You</b> can master ...", "url": "https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2019/07/15/video-classification-with-keras-and-deep-<b>learning</b>", "snippet": "Video Classification with Keras and Deep <b>Learning</b>. 2020-06-12 Update: This blog post is now TensorFlow 2+ compatible! Videos can be understood as a series of individual images; and therefore, many deep <b>learning</b> practitioners would be quick to treat video classification as performing image classification a total of N times, where N is the total number of frames in a video.. There\u2019s a problem with that approach though.", "dateLastCrawled": "2022-02-03T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Keras: Feature extraction on large datasets with</b> Deep <b>Learning</b> ...", "url": "https://www.pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2019/05/27/<b>keras-feature-extraction-on-large-datasets</b>...", "snippet": "Figure 2: The process of incremental <b>learning</b> plays a role in deep <b>learning</b> <b>feature extraction on large datasets</b>. When your entire dataset does not fit <b>into</b> memory <b>you</b> need to perform incremental <b>learning</b> (sometimes called \u201conline <b>learning</b>\u201d).. Incremental <b>learning</b> <b>enables</b> <b>you</b> to train your model on small subsets of the <b>data</b> called batches.. Using incremental <b>learning</b> the training process becomes:", "dateLastCrawled": "2022-02-03T02:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> \u00b7 Issue #681 \u00b7 codeanit/til \u00b7 GitHub", "url": "https://github.com/codeanit/til/issues/681", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/codeanit/til/issues/681", "snippet": "<b>Data</b> vectorization: A process that converts non-numeric <b>data</b> <b>into</b> a <b>numerical</b> format so that it <b>can</b> be used by a <b>machine</b> <b>learning</b> model. Silhouette coefficient: A score from -1 to 1 describing the clusters found during modeling. A score near zero indicates overlapping clusters, and scores less than zero indicate <b>data</b> points assigned to incorrect clusters. A score approaching 1 indicates successful identification of discrete non-overlapping clusters. Stop words: A list of words removed by ...", "dateLastCrawled": "2022-01-05T20:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Offensive Language and Hate Speech Detection with Deep <b>Learning</b> and ...", "url": "https://deepai.org/publication/offensive-language-and-hate-speech-detection-with-deep-learning-and-transfer-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/offensive-language-and-hate-speech-detection-with-deep...", "snippet": "Shallow <b>machine</b> <b>learning</b> models such as decision trees, Na\u00efve Bayes, KNN, random forest etc. use bag of words, n-rams, lexical <b>features</b>, meta <b>data</b> to extract the <b>features</b> whereas deep <b>machine</b> <b>learning</b> models use word embeddings that are fed <b>into</b> neural networks such as CNN, RNN, LSTM, transformers etc. The deep <b>learning</b> models are capable of <b>learning</b> the <b>features</b> from the raw <b>data</b> which helps to better extract the context for the problem on hand and hence results in much better performance ...", "dateLastCrawled": "2022-01-27T02:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "1. Introduction \u2014 <b>Dive into Deep Learning</b> 0.17.2 documentation", "url": "https://www.d2l.ai/chapter_introduction/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.d2l.ai/chapter_introduction/index.html", "snippet": "As a <b>machine</b> <b>learning</b> <b>algorithm</b> accumulates more experience, typically in the form of observational <b>data</b> or interactions with an environment, its performance improves. Contrast this with our deterministic e-commerce platform, which performs according to the same business logic, no matter how much experience accrues, until the developers themselves learn and decide that it is time to update the software. In this book, we will teach <b>you</b> the fundamentals of <b>machine</b> <b>learning</b>, and focus in ...", "dateLastCrawled": "2022-02-01T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>data</b>-science-interviews/theory.md at master \u00b7 alexeygrigorev/<b>data</b> ...", "url": "https://github.com/alexeygrigorev/data-science-interviews/blob/master/theory.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>alexeygrigorev/data-science-interviews</b>/blob/master/theory.md", "snippet": "<b>Machine</b> <b>learning</b> classification algorithms predict a class based on a <b>numerical</b> feature representation. This means that in order to use <b>machine</b> <b>learning</b> for text classification, we need to extract <b>numerical</b> <b>features</b> from our text <b>data</b> first before we <b>can</b> apply <b>machine</b> <b>learning</b> algorithms. Common approaches to extract <b>numerical</b> <b>features</b> from ...", "dateLastCrawled": "2022-02-01T23:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "14 Different Types of <b>Learning</b> in <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/types-of-learning-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/types-of-<b>learning</b>-in-<b>machine-learning</b>", "snippet": "<b>Machine learning</b> is a large field of study that overlaps with and inherits ideas from many related fields such as artificial intelligence. The focus of the field is <b>learning</b>, that is, acquiring skills or knowledge from experience. Most commonly, this means synthesizing useful concepts from historical <b>data</b>. As such, there are many different types of <b>learning</b> that <b>you</b> may encounter as a", "dateLastCrawled": "2022-02-02T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A guide to <b>machine</b> <b>learning</b> for biologists | Nature Reviews Molecular ...", "url": "https://www.nature.com/articles/s41580-021-00407-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41580-021-00407-0", "snippet": "<b>Machine</b> <b>learning</b> is becoming a widely used tool for the analysis of biological <b>data</b>. However, for experimentalists, proper use of <b>machine</b> <b>learning</b> methods <b>can</b> be challenging. This Review provides ...", "dateLastCrawled": "2022-02-02T20:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Making AI meaningful again</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s11229-019-02192-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-019-02192-y", "snippet": "The <b>data</b> input must be abundant, since a <b>machine</b>-<b>learning</b> <b>algorithm</b> is a stochastic model that needs to represent as much as possible of the variance which characterises the situation in which the model is to be used. Because in language applications the overall complexity of the relationship between input and output is typically very high, the models will need many parameters. For mathematical reasons these parameters <b>can</b> only be estimated (through the type of optimisation process otherwise ...", "dateLastCrawled": "2022-01-17T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Keras: Feature extraction on large datasets with</b> Deep <b>Learning</b> ...", "url": "https://www.pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2019/05/27/<b>keras-feature-extraction-on-large-datasets</b>...", "snippet": "Figure 2: The process of incremental <b>learning</b> plays a role in deep <b>learning</b> <b>feature extraction on large datasets</b>. When your entire dataset does not fit <b>into</b> memory <b>you</b> need to perform incremental <b>learning</b> (sometimes called \u201conline <b>learning</b>\u201d).. Incremental <b>learning</b> <b>enables</b> <b>you</b> to train your model on small subsets of the <b>data</b> called batches.. Using incremental <b>learning</b> the training process becomes:", "dateLastCrawled": "2022-02-03T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Video classification with Keras and Deep <b>Learning</b> - <b>You</b> <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2019/07/15/video-classification-with-keras-and-deep-<b>learning</b>", "snippet": "Video Classification with Keras and Deep <b>Learning</b>. 2020-06-12 Update: This blog post is now TensorFlow 2+ compatible! Videos <b>can</b> be understood as a series of individual images; and therefore, many deep <b>learning</b> practitioners would be quick to treat video classification as performing image classification a total of N times, where N is the total number of frames in a video.. There\u2019s a problem with that approach though.", "dateLastCrawled": "2022-02-03T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>High-Throughput Machine-Learning-Driven Synthesis</b> of Full-Heusler ...", "url": "https://www.researchgate.net/publication/316678049_High-Throughput_Machine-Learning-Driven_Synthesis_of_Full-Heusler_Compounds", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/316678049_High-Throughput_<b>Machine</b>-<b>Learning</b>...", "snippet": "As <b>data</b>-driven methods rise in popularity in materials science applications, a key question is how these <b>machine</b> <b>learning</b> models <b>can</b> be used to understand microstructure. Given the importance of ...", "dateLastCrawled": "2021-12-29T01:51:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> and Deep <b>Learning</b> in Molecular and Genetic Aspects of Sleep ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8116376/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8116376", "snippet": "Supervised <b>learning</b> assumes <b>you</b> have a training dataset with known labels (whether <b>categorical</b> or <b>numerical</b>) and the task of the <b>algorithm</b> is then to identify the same labels in new <b>data</b>. In the field of sleep research, an example for this is the identification of various breathing events during sleep from a PSG recording. During training time, the <b>algorithm</b> is presented with PSG <b>data</b> overlayed with annotations reflecting scored apneas and hypopneas, and it is trained to identify similar ...", "dateLastCrawled": "2022-01-29T00:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b> \u00b7 Issue #681 \u00b7 codeanit/til \u00b7 GitHub", "url": "https://github.com/codeanit/til/issues/681", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/codeanit/til/issues/681", "snippet": "<b>Data</b> vectorization: A process that converts non-numeric <b>data</b> <b>into</b> a <b>numerical</b> format so that it <b>can</b> be used by a <b>machine</b> <b>learning</b> model. Silhouette coefficient: A score from -1 to 1 describing the clusters found during modeling. A score near zero indicates overlapping clusters, and scores less than zero indicate <b>data</b> points assigned to incorrect clusters. A score approaching 1 indicates successful identification of discrete non-overlapping clusters. Stop words: A list of words removed by ...", "dateLastCrawled": "2022-01-05T20:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Offensive Language and Hate Speech Detection with Deep <b>Learning</b> and ...", "url": "https://deepai.org/publication/offensive-language-and-hate-speech-detection-with-deep-learning-and-transfer-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/offensive-language-and-hate-speech-detection-with-deep...", "snippet": "Shallow <b>machine</b> <b>learning</b> models such as decision trees, Na\u00efve Bayes, KNN, random forest etc. use bag of words, n-rams, lexical <b>features</b>, meta <b>data</b> to extract the <b>features</b> whereas deep <b>machine</b> <b>learning</b> models use word embeddings that are fed <b>into</b> neural networks such as CNN, RNN, LSTM, transformers etc. The deep <b>learning</b> models are capable of <b>learning</b> the <b>features</b> from the raw <b>data</b> which helps to better extract the context for the problem on hand and hence results in much better performance ...", "dateLastCrawled": "2022-01-27T02:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "14 Different Types of <b>Learning</b> in <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/types-of-learning-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/types-of-<b>learning</b>-in-<b>machine-learning</b>", "snippet": "<b>Machine learning</b> is a large field of study that overlaps with and inherits ideas from many related fields such as artificial intelligence. The focus of the field is <b>learning</b>, that is, acquiring skills or knowledge from experience. Most commonly, this means synthesizing useful concepts from historical <b>data</b>. As such, there are many different types of <b>learning</b> that <b>you</b> may encounter as a", "dateLastCrawled": "2022-02-02T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A guide to <b>machine</b> <b>learning</b> for biologists | Nature Reviews Molecular ...", "url": "https://www.nature.com/articles/s41580-021-00407-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41580-021-00407-0", "snippet": "<b>Machine</b> <b>learning</b> is becoming a widely used tool for the analysis of biological <b>data</b>. However, for experimentalists, proper use of <b>machine</b> <b>learning</b> methods <b>can</b> be challenging. This Review provides ...", "dateLastCrawled": "2022-02-02T20:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>Learning</b> with Apache Spark 101 | by Matteo Tortella | Medium", "url": "https://medium.com/@matteotortella4/machine-learning-with-apache-spark-101-8f57c27ae9b0", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@matteotortella4/<b>machine</b>-<b>learning</b>-with-apache-spark-101-8f57c27ae9b0", "snippet": "<b>Machine</b> <b>Learning</b> with Apache Spark 101. In the information age, <b>data</b> in huge quantities has become available to analysts and decision-makers. Due to a vast increase in the amount of such <b>data</b> in ...", "dateLastCrawled": "2021-10-05T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A guide to <b>the top machine learning algorithms</b> | by Brian Mwangi ...", "url": "https://heartbeat.comet.ml/a-guide-to-the-top-machine-learning-algorithms-722d713b9b44", "isFamilyFriendly": true, "displayUrl": "https://heartbeat.comet.ml/a-guide-to-<b>the-top-machine-learning-algorithms</b>-722d713b9b44", "snippet": "It <b>can</b> handle both <b>categorical</b> and <b>numerical</b> variables. It saves on <b>data</b> preparation time as it is not sensitive to missing values and outliers. Disadvantages of decision trees . Decision trees lose their predictive power from not collecting other overlapping <b>features</b>. Don\u2019t fit well for continuous variables resulting in instability. Creating large decision trees that contain several branches is complex and time-consuming and doesn\u2019t generalize well to future <b>data</b>. Applications of ...", "dateLastCrawled": "2022-01-16T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine learning for internet of things data analysis</b>: a survey ...", "url": "https://www.sciencedirect.com/science/article/pii/S235286481730247X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S235286481730247X", "snippet": "<b>Data</b> science is the combination of different scientific fields that uses <b>data</b> mining, <b>machine</b> <b>learning</b>, and other techniques to find patterns and new insights from <b>data</b>. These techniques include a broad range of algorithms applicable in different domains. The process of applying <b>data</b> analytics methods to particular areas involves defining <b>data</b> types such as volume, variety, and velocity; <b>data</b> models such as neural networks, classification, and clustering methods, and applying efficient ...", "dateLastCrawled": "2022-01-29T16:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Video classification with Keras and Deep <b>Learning</b> - <b>You</b> <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2019/07/15/video-classification-with-keras-and-deep-<b>learning</b>", "snippet": "Video Classification with Keras and Deep <b>Learning</b>. 2020-06-12 Update: This blog post is now TensorFlow 2+ compatible! Videos <b>can</b> be understood as a series of individual images; and therefore, many deep <b>learning</b> practitioners would be quick to treat video classification as performing image classification a total of N times, where N is the total number of frames in a video.. There\u2019s a problem with that approach though.", "dateLastCrawled": "2022-02-03T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Vulnerability Prediction From Source Code Using <b>Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/343664073_Vulnerability_Prediction_From_Source_Code_Using_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343664073_Vulnerability_Prediction_From...", "snippet": "Processing time per sample during training for the AST depths of 6,8,10 and 12 resulting in the <b>numerical</b> array size of 381, 1533, 6141, and 24573 respectively.", "dateLastCrawled": "2022-02-01T09:32:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Introduction to Transformers in Machine Learning</b>", "url": "https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/.../12/28/<b>introduction-to-transformers-in-machine-learning</b>", "snippet": "When you talk about <b>Machine</b> <b>Learning</b> in Natural Language Processing these days, all you hear is one thing \u2013 Transformers. Models based on this Deep <b>Learning</b> architecture have taken the NLP world by storm since 2017. In fact, they are the go-to approach today, and many of the approaches build on top of the original <b>Transformer</b>, one way or another. Transformers are however not simple. The original <b>Transformer</b> architecture is quite complex and the same is true for many of the spin-off ...", "dateLastCrawled": "2022-02-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Transformer</b> Neural Network In Deep <b>Learning</b> - Overview - GeeksforGeeks", "url": "https://www.geeksforgeeks.org/transformer-neural-network-in-deep-learning-overview/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/<b>transformer</b>-neural-network-in-deep-<b>learning</b>-overview", "snippet": "Well, Deep <b>Learning</b> is a part of a broad family of ML methods, which are based on <b>learning</b> data patterns in opposition to what a <b>Machine</b> <b>Learning</b> algorithm does. In <b>Machine</b> <b>Learning</b> we have algorithms for a specific task. Here, the Deep <b>Learning</b> algorithm can be supervised semi-supervised or unsupervised. As mentioned earlier, Deep <b>Learning</b> is inspired by the human brain and how it perceives information through the interaction of neurons. So let\u2019s see what exactly can we do with Deep ...", "dateLastCrawled": "2022-02-02T11:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Transformers In <b>Machine</b> <b>Learning</b> - Pianalytix", "url": "https://pianalytix.com/transformers-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://pianalytix.com/<b>transformers</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "The word <b>transformer</b> might be familiar to you as you have heard it before in the movies or learned about it in the physics class but here in <b>machine</b> <b>learning</b> it has a whole different meaning. Transformers are in use areas of <b>machine</b> <b>learning</b> such as natural language processing(NLP) where the model needs to remember the significance of input data. Let\u2019s start by understanding why we use transformers in the first place when we have RNN\u2019s? Why should we use Transformers? Have you ever ...", "dateLastCrawled": "2022-01-03T10:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "PyTorch Transformers and <b>Learning</b> <b>Machine</b> <b>Learning</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2021/02/04/pytorch-transformers-and-learning-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/02/04/pytorch-<b>transformers</b>-and-<b>learning</b>...", "snippet": "PyTorch Transformers and <b>Learning</b> <b>Machine</b> <b>Learning</b>. Posted on February 4, 2021 by jamesdmccaffrey. I\u2019ve been studying neural <b>Transformer</b> architecture for several months. Yesterday, I reached a major milestone when I successfully got a rudimentary prediction model running for the IMDB dataset to predict if a movie review is positive or negative.", "dateLastCrawled": "2022-01-08T13:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What are Transformers?. John Inacay, Michael Wang, and Wiley\u2026 | by Deep ...", "url": "https://deepganteam.medium.com/what-are-transformers-b687f2bcdf49", "isFamilyFriendly": true, "displayUrl": "https://deepganteam.medium.com/what-are-<b>transformers</b>-b687f2bcdf49", "snippet": "In the case of using <b>transformer</b> based architectures such as BERT, transfer <b>learning</b> is commonly used to adapt or fine tune a network to a new task. Some examples of potential applications are sentiment classification and <b>machine</b> translation (translating english to french). Transfer <b>learning</b> is the process of taking a network that has already been pretrained on a task (for example BERT was trained on the problem of language modeling with a large dataset) and fine tuning it on a specific task ...", "dateLastCrawled": "2022-01-27T17:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Transformers - A Mechanical Gear Analogy</b> - Wisc-Online OER", "url": "https://www.wisc-online.com/learn/career-clusters/stem/ace4003/transformers---a-mechanical-gear-analogy", "isFamilyFriendly": true, "displayUrl": "https://www.wisc-online.com/.../stem/ace4003/<b>transformers---a-mechanical-gear-analogy</b>", "snippet": "<b>Transformers - A Mechanical Gear Analogy</b>. By Roger Brown. Learners read an <b>analogy</b> comparing an electrical <b>transformer</b> to mechanical gears. Download Object.", "dateLastCrawled": "2022-02-02T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Transformers in NLP: A beginner friendly explanation | Towards Data Science", "url": "https://towardsdatascience.com/transformers-89034557de14", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>transformers</b>-89034557de14", "snippet": "If you are looking for an <b>analogy</b> between self attention and attention, think of z serving the purpose of context vectors and not global alignment weights. The <b>Transformer</b> . \u26a0\ufe0f A word of caution: the contents of this image may appear exponentially more complicated than they are. We will break this scary beast down into small baby beasts and it will all make sense. (I promise #2) (left) The <b>Transformer</b> architecture. Source: paper. (right) An abstracted version of the same for better ...", "dateLastCrawled": "2022-02-02T13:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Transformer</b> Implementation for TimeSeries Forecasting | by Natasha ...", "url": "https://medium.com/mlearning-ai/transformer-implementation-for-time-series-forecasting-a9db2db5c820", "isFamilyFriendly": true, "displayUrl": "https://medium.com/m<b>learning</b>-ai/<b>transformer</b>-implementation-for-time-series-forecasting...", "snippet": "<b>Transformer</b>-decoder Architecture. The input to the <b>transformer</b> is a given time series (either univariate or multivariate), shown in green below. The target is then the sequence shifted once to the ...", "dateLastCrawled": "2022-02-02T08:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Pipeline</b>, ColumnTransformer and FeatureUnion explained | by Zolzaya ...", "url": "https://towardsdatascience.com/pipeline-columntransformer-and-featureunion-explained-f5491f815f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>pipeline</b>-column<b>transformer</b>-and-featureunion-explained-f...", "snippet": "<b>Transformer</b>: A <b>transformer</b> refers to an object with fit() and transform() method that cleans, reduces, expands or generates features. Simply put, transformers help you transform your data towards a desired format for a <b>machine</b> <b>learning</b> model. OneHotEncoder and MinMaxScaler are examples of transformers. Estimator: An estimator refers to a <b>machine</b> <b>learning</b> model. It is an object with fit() and predict() method. We will use estimator and model interchangeably throughout this post. Here are some ...", "dateLastCrawled": "2022-01-30T06:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Difference between fit() , <b>transform</b>() and fit_<b>transform</b>() method in ...", "url": "https://medium.com/nerd-for-tech/difference-fit-transform-and-fit-transform-method-in-scikit-learn-b0a4efcab804", "isFamilyFriendly": true, "displayUrl": "https://medium.com/nerd-for-tech/difference-fit-<b>transform</b>-and-fit-<b>transform</b>-method-in...", "snippet": "<b>Machine</b> <b>Learning</b>. Scikit-learn (Sklearn) is the most useful and robust library for <b>machine</b> <b>learning</b> in Python. It is characterized by a clean, uniform, and streamlined API.", "dateLastCrawled": "2022-02-02T18:52:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "If you know <b>SQL, you probably understand Transformer, BERT and</b> GPT ...", "url": "https://towardsdatascience.com/if-you-know-sql-you-probably-understand-transformer-bert-and-gpt-7b197cb48d24", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/if-you-know-<b>sql-you-probably-understand-transformer</b>...", "snippet": "A Transformer has multiple heads of attention, and stacks attention over attention, and so you can imagine that <b>Transformer is like</b> groups of smart analysts who collaboratively uses advanced semantic SQL iteratively to dig out insight from a super large database; when multiple middle level managers receive the insight from their direct reports, they present the finding to their managers (tougher than dual reporting), who ultimately distill so before passing to the CEO. From Transformer to ...", "dateLastCrawled": "2022-01-25T21:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "An Example Of <b>Using The PyTorch masked_fill() Function</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2020/09/17/an-example-of-using-the-pytorch-masked_fill-function/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2020/09/17/an-example-of-using-the-pytorch-masked...", "snippet": "I\u2019m doing a deep dive into the <b>machine</b> <b>learning</b> Attention mechanism and the Transformer architecture. In some ways, this is among the most difficult code I\u2019ve ever come across in my entire career. A Transformer is a deep neural system that can solve natural language processing problems, like translating English to German. If a standard deep neural network is like adding 2 + 2, then a <b>Transformer is like</b> advanced multi-variate Calculus. Because of the complexity, I know from painful past ...", "dateLastCrawled": "2022-01-27T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Best Stick Welder</b> (SMAW) - Arc DC Inverter <b>Machine</b> Reviews", "url": "https://weldingpros.net/best-stick-welder-reviews/", "isFamilyFriendly": true, "displayUrl": "https://weldingpros.net/<b>best-stick-welder</b>-reviews", "snippet": "Choosing between an Inverter or a <b>Transformer is like</b> picking from being modern or old-school. Inverters are modern machines with constantly incising build quality that are light and efficient. They can be set to weld in different styles. You can use one to weld a wider range of metals as well. They have overheating and overload protection. Transformers are traditional welders. They are mostly used for industrial-grade stick welding and other heavy-duty work.", "dateLastCrawled": "2022-01-30T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "an autodidact meets a dilettante... | \u2018Rise above yourself and grasp ...", "url": "https://ussromantics.com/", "isFamilyFriendly": true, "displayUrl": "https://ussromantics.com", "snippet": "If a <b>machine</b> is constructed to rotate a magnetic field around a set of stationary wire coils with the turning ... Jacinta: Well, we seem to be <b>learning</b> something. This is better than a historical account it seems. But there are still so many problems. The \u2018electricity explained\u2019 video you\u2019ve been describing says that the negative point is the source. So it\u2019s saying negative to positive, simply ignoring the positive to negative convention. Perhaps we should too, but the video makes no ...", "dateLastCrawled": "2022-01-30T09:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 4, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "User blog:The Pro-Wrestler/Magnificent Baddie Proposal: Megatron (Beast ...", "url": "https://magnificentbaddie.fandom.com/wiki/User_blog:The_Pro-Wrestler/Magnificent_Baddie_Proposal:_Megatron_(Beast_Wars)", "isFamilyFriendly": true, "displayUrl": "https://magnificentbaddie.fandom.com/wiki/User_blog:The_Pro-Wrestler/Magnificent...", "snippet": "Upon <b>learning</b> of the Maximals&#39; survival, Megatron sends the Vehicons to deal with them, putting them on the run for most of the series. Eventually, Optimus enters the citadel and meets Megatron, who reveals himself as the new leader of Cybertron. Megatron then is angered by his drones&#39; failure, revealing he still has an organic beast mode, which Megatron is desperate to remove due to how it obstructs hs control voer Cybertron. Megatron despite this, while not winning this encounter, didn&#39;t ...", "dateLastCrawled": "2022-02-03T05:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Transformer</b> vs RNN and CNN for Translation Task | by Yacine BENAFFANE ...", "url": "https://medium.com/analytics-vidhya/transformer-vs-rnn-and-cnn-18eeefa3602b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>transformer</b>-vs-rnn-and-cnn-18eeefa3602b", "snippet": "<b>Learning</b> long-range dependencies is a major challenge in many sequence transductions tasks. A key factor affecting the ability to learn from such dependencies is the length of paths that forward ...", "dateLastCrawled": "2022-01-29T16:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Optimizing NVIDIA AI Performance for</b> MLPerf v0.7 Training | NVIDIA ...", "url": "https://developer.nvidia.com/blog/optimizing-ai-performance-for-mlperf-v0-7-training/", "isFamilyFriendly": true, "displayUrl": "https://developer.nvidia.com/blog/optimizing-ai-performance-for-mlperf-v0-7-training", "snippet": "The Transformer neural <b>machine</b> translation benchmark benefits from several key improvements in MLPerf v0.7. Like BERT, Transformer relies on MHA modules in all its macro-layers. The MHA structure in BERT and <b>Transformer is similar</b>, so Transformer also enjoys the performance benefits of apex.multihead_attn described earlier. Second, the large-scale Transformer submissions benefit from the distributed optimizer implementation previously described in the At scale section, as weight update time ...", "dateLastCrawled": "2022-01-27T02:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "RetroPrime: A <b>Diverse, plausible and Transformer-based method</b> for ...", "url": "https://www.sciencedirect.com/science/article/pii/S1385894721014303", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1385894721014303", "snippet": "At present, purely <b>machine</b>-<b>learning</b> retrosynthesis models are classified into two categories : the template-based , , ... S-<b>Transformer is similar</b> to the Seq2Seq translation model but using a single-stage transformer instead of LSTM architecture at the core. G2Gs and GraphRetro are template-free approaches using graph neural networks to predict retrosynthesis. Under the premise of the model without correction methods, GraphRetro achieved state-of-the-art Top-n accuracy in the USPTO-50 K ...", "dateLastCrawled": "2022-01-28T11:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Natural Language to Code Using Transformers", "url": "https://arxiv.org/pdf/2202.00367", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/2202.00367", "snippet": "There have been multiple deep <b>learning</b> based approaches to semantic parsing (Jia and Liang, 2016;Yin and Neubig,2017;Rabinovich et al., 2017;Dong and Lapata,2018) using attention- based encoder decoder architectures. All these ap-proaches use one or more LSTM layers with a suit-able attention mechanism as the deep architecture. Transformers (Vaswani et al.,2017) are an alter-native to these LSTM based architectures. Trans-formers have been successfully applied in <b>machine</b> translation beating ...", "dateLastCrawled": "2022-02-02T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "High-Level History of NLP Models. How we arrived at our current state ...", "url": "https://towardsdatascience.com/high-level-history-of-nlp-models-bc8c8b142ef7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/high-level-history-of-nlp-<b>model</b>s-bc8c8b142ef7", "snippet": "NLP technology has progressed so rapidly that data scientists must continually learn new <b>machine</b> <b>learning</b> techniques and <b>model</b> architectures. Thankfully, since the development of the current state of the art NLP architecture, attention based models, progress in the NLP field seems to have slowed momentarily. Data scientists finally have a moment to catch up! But ho w did we arrive at our current state in NLP? The first big advancement came in 2013 with the breakthrough research of Word2Vec ...", "dateLastCrawled": "2022-01-30T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Transformers</b> - SlideShare", "url": "https://www.slideshare.net/AbhijitJadhav9/transformers-69559748", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/AbhijitJadhav9/<b>transformers</b>-69559748", "snippet": "An Auto Transformer is a transformer with only one winding wound on a laminated core. An auto <b>transformer is similar</b> to a two winding transformer but differ in the way the primary and secondary winding are interrelated. A part of the winding is common to both primary and secondary sides. On load condition, a part of the load current is obtained ...", "dateLastCrawled": "2022-01-30T17:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Autotransformer: What is it? (Definition, Theory &amp; Diagram ...", "url": "https://www.electrical4u.com/what-is-auto-transformer/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>electrical4u</b>.com/what-is-auto-transformer", "snippet": "An auto <b>transformer is similar</b> to a two winding transformer but varies in the way the primary and secondary winding of the transformer are interrelated. Autotransformer Theory. In an auto transformer, one single winding is used as primary winding as well as secondary winding. But in two windings transformer two different windings are used for primary and secondary purpose. A circuit diagram of auto transformer is shown below. The winding AB of total turns N 1 is considered as primary winding ...", "dateLastCrawled": "2022-02-02T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Electromagnetic</b> Induction: <b>Conductor</b> to <b>Conductor</b> &amp; Transformers ...", "url": "https://study.com/academy/lesson/electromagnetic-induction-conductor-to-conductor-transformers.html", "isFamilyFriendly": true, "displayUrl": "https://study.com/academy/lesson/<b>electromagnetic</b>-induction-<b>conductor</b>-to-<b>conductor</b>...", "snippet": "<b>Electromagnetic</b> induction is the production of electromotive force by moving a magnetic field across an electric <b>conductor</b>. Learn more about mutual inductance, its applications, and transformers.", "dateLastCrawled": "2022-02-03T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Attention, please! A <b>survey of Neural Attention Models in Deep Learning</b> ...", "url": "https://deepai.org/publication/attention-please-a-survey-of-neural-attention-models-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/attention-please-a-<b>survey-of-neural-attention-models</b>-in...", "snippet": "Since 2019 these networks have stood out as a new research branch because they represent state-of-the-art generalization on neural <b>machine</b> translation, <b>learning</b> on graphs, and visual question answering tasks while keeping the neural representations compact. Since 2019, GATs have also received much attention due to their ability to learn complex relationships or interactions in a wide spectrum of problems ranging from biology, particle physics, social networks to recommendation systems. To ...", "dateLastCrawled": "2022-01-21T20:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Regenerative braking</b> - SlideShare", "url": "https://www.slideshare.net/sangeethvrn/regenerative-braking-52461967", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/sangeethvrn/<b>regenerative-braking</b>-52461967", "snippet": "The exciter voltage antihunting or damping <b>transformer is similar</b> to those in dc systems and performs the same function. The DC output voltage from the half or full-wave rectifiers contains ripple superimposed onto the DC voltage and that as the load value changes so to does the average output voltage. By connecting a simple zener stabilizer circuit as shown below across the output of the rectifier, a more stable output voltage can be produced. 2.5.1 ZENER DIODE REGULATOR Fig 2.7 Zener Diode ...", "dateLastCrawled": "2022-01-31T14:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Improving Abstractive Dialogue Summarization with Graph ...", "url": "https://www.researchgate.net/publication/346493879_Improving_Abstractive_Dialogue_Summarization_with_Graph_Structures_and_Topic_Words", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/346493879_Improving_Abstractive_Dialogue...", "snippet": "between <b>just as Transformer</b> (V asw ani et al., 2017). Formally, the output of the linear transformation. layer is de\ufb01ned as: f l = ReLU g l w l. 1 + b l. 1 w l. 2 + b l. 2 (3) where w 1, and w 2 ...", "dateLastCrawled": "2021-12-29T10:32:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Using scikit-learn Pipelines and FeatureUnions", "url": "http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html", "isFamilyFriendly": true, "displayUrl": "zacstewart.com/2014/08/05/<b>pipeline</b>s-of-featureunions-of-<b>pipeline</b>s.html", "snippet": "A <b>transformer can be thought of as</b> a data in, data out black box. Generally, they accept a matrix as input and return a matrix of the same shape as output. That makes it easy to reorder and remix them at will. However, I often use Pandas DataFrames, and expect one as input to a transformer. For example, the ColumnExtractor is for extracting columns from a DataFrame. Sometimes transformers are very simple, like HourOfDayTransformer, which just extracts the hour components out of a vector of ...", "dateLastCrawled": "2022-01-31T05:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Transformer Basics and Transformer Principles", "url": "https://www.electronics-tutorials.ws/transformer/transformer-basics.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.electronics-tutorials.ws</b>/transformer/transformer-basics.html", "snippet": "The Voltage <b>Transformer can be thought of as</b> an electrical component rather than an electronic component. A transformer basically is very simple static (or stationary) electro-magnetic passive electrical device that works on the principle of Faraday\u2019s law of induction by converting electrical energy from one value to another. The transformer does this by linking together two or more electrical circuits using a common oscillating magnetic circuit which is produced by the transformer itself ...", "dateLastCrawled": "2022-02-03T05:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Direct Fit to Nature: An <b>Evolutionary Perspective on Biological and</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S089662731931044X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S089662731931044X", "snippet": "In simple terms, the <b>transformer can be thought of as</b> a coupled encoder and decoder where the input to the decoder is shifted to the subsequent element (i.e., the next word or byte). Critically, both the encoder and decoder components are able to selectively attend to elements at nearby positions in the sequence, effectively incorporating contextual information. The model is trained on over 8 million documents for a total of 40 gigabytes of text. Despite the self-supervised sequence-to ...", "dateLastCrawled": "2022-01-05T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Learn Electronics With Arduino [PDF] [18use4ctqge8]", "url": "https://vdoc.pub/documents/learn-electronics-with-arduino-18use4ctqge8", "isFamilyFriendly": true, "displayUrl": "https://vdoc.pub/documents/learn-electronics-with-arduino-18use4ctqge8", "snippet": "Basically, a <b>transformer can be thought of as</b> two inductors placed in parallel, with a piece of metal separating them. When a voltage source is applied to one coil, the energy stored (electrical current) is transferred to the other inductor through magnetic coupling. The metal piece separating them enhances the magnetic \ufb01eld based on its permeability (magnetic properties). If an ammeter is attached to the second inductor\u2019s coil, the electrical current can be measured and observed on it ...", "dateLastCrawled": "2022-01-29T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Transformer Training Pdf</b> - XpCourse", "url": "https://www.xpcourse.com/transformer-training-pdf", "isFamilyFriendly": true, "displayUrl": "https://www.xpcourse.com/<b>transformer-training-pdf</b>", "snippet": "<b>machine</b> <b>learning</b> model A transformer is a deep <b>learning</b> model that adopts the mechanism of attention, differentially weighing the significance of each part of the input data. It is used primarily in the field of natural language processing and in computer vision.", "dateLastCrawled": "2021-12-30T13:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Electrical Machines Transformers Question Paper And Answers", "url": "https://sig.cruzroja.org.hn/k/images/A4Z3T5/electrical-machines-transformers-question-paper-and-answers_pdf", "isFamilyFriendly": true, "displayUrl": "https://sig.cruzroja.org.hn/k/images/A4Z3T5/electrical-<b>machines</b>-transformers-question...", "snippet": "The Voltage <b>Transformer can be thought of as</b> an electrical component rather than an electronic component. A transformer basically is very simple static (or stationary) electro-magnetic passive electrical device that works on the principle of Faraday\u2019s law of induction by converting electrical energy from one value to another. (PDF) Electrical Power Equipment Maintenance and Testing Electrical Power Equipment Maintenance and Testing - 2nd Edition. Dnpc Dtn. Download Download PDF. Full PDF ...", "dateLastCrawled": "2021-11-23T16:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Syntax-Infused Transformer and BERT models for <b>Machine</b> Translation and ...", "url": "https://deepai.org/publication/syntax-infused-transformer-and-bert-models-for-machine-translation-and-natural-language-understanding", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/syntax-infused-transformer-and-bert-models-for-<b>machine</b>...", "snippet": "Syntax-Infused Transformer and BERT models for <b>Machine Translation and Natural Language Understanding</b>. 11/10/2019 \u2219 by Dhanasekar Sundararaman, et al. \u2219 Duke University \u2219 0 \u2219 share Attention-based models have shown significant improvement over traditional algorithms in several NLP tasks. The Transformer, for instance, is an illustrative example that generates abstract representations of tokens inputted to an encoder based on their relationships to all tokens in a sequence. Recent ...", "dateLastCrawled": "2021-12-08T21:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Length-Adaptive Transformer: Train Once with Length</b> Drop, Use Anytime ...", "url": "https://deepai.org/publication/length-adaptive-transformer-train-once-with-length-drop-use-anytime-with-search", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>length-adaptive-transformer-train-once-with-length</b>-drop...", "snippet": "The proposed extension enables us to train a large-scale transformer, called Length-Adaptive Transformer, once and uses it for various inference scenarios without re-training it. To do so, we train a transformer with LengthDrop, a structural variant of dropout, which stochastically determines the length of a sequence at each layer.", "dateLastCrawled": "2021-11-28T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Exercise equipment for electrical energy generation</b>- A Report", "url": "https://www.slideshare.net/sangeethvrn/exercise-equipment-for-electrical-energy-generation-a-report", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/sangeethvrn/<b>exercise-equipment-for-electrical-energy</b>...", "snippet": "The Voltage <b>Transformer can be thought of as</b> an electrical component rather than an electronic component. Fig 3.14 Step-Up Transformer A transformer basically is very simple static (or stationary) electro-magnetic passive electrical device that works on the principle of Faraday\u2019s law of induction by converting electrical energy from one value to another. On a step-up transformer there are more turns on the secondary coil than the primary coil. The transformer does this by linking together ...", "dateLastCrawled": "2022-02-03T19:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Inplant training about</b> 110kv/11kv substation", "url": "https://www.slideshare.net/shivashankar307/inplant-training-about-substation", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/shivashankar307/<b>inplant-training-about</b>-substation", "snippet": "The Voltage <b>Transformer can be thought of as</b> an electrical component rather than an electronic component. A transformer basically is very simple static (or stationary) electro- magnetic passive electrical device that works on the principle of Faraday\u201fs law of induction by converting electrical energy from one value to another. The transformer does this by linking together two or more electrical circuits using a common oscillating magnetic circuit which is produced by the transformer itself ...", "dateLastCrawled": "2022-02-02T20:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Predictive Maintenance of Power Grid Assets</b> | OTELLO Energy", "url": "https://otelloenergy.com/predictive-maintenance-of-power-grid-assets/", "isFamilyFriendly": true, "displayUrl": "https://otelloenergy.com/<b>predictive-maintenance-of-power-grid-assets</b>", "snippet": "An open standard API for connecting to serverless modeling applications, <b>Machine</b> <b>Learning</b> services, and other computational tools for further processing and data modeling. An example of using Digital Twin technologies for preventative maintenance application in the power grid. The OTELLO VectoIII\u00ae is often installed close to a transformer in a sub-station or mini sub-station. With oil pressure, oil acidity, moisture, temperature, and vibration sensors connected to a transformer, the real ...", "dateLastCrawled": "2022-02-02T16:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Why does the input <b>stator current of an induction motor increase as the</b> ...", "url": "https://www.quora.com/Why-does-the-input-stator-current-of-an-induction-motor-increase-as-the-load-is-increased", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-does-the-input-<b>stator-current-of-an-induction</b>-motor-increase...", "snippet": "Answer (1 of 7): The principle of induction motor is analogous to that of a transformer. you might know about the LENZ\u2019S law. it says that whenever emf will get induced in a coil ,it will oppose the cause which produced that emf. say at a certain load X the total flux in <b>machine</b> is Y and the emf...", "dateLastCrawled": "2022-01-20T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Why does starting torque decrease if resistance</b> is added to the stator ...", "url": "https://www.quora.com/Why-does-starting-torque-decrease-if-resistance-is-added-to-the-stator-of-a-3-phase-induction-motor", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Why-does-starting-torque-decrease-if-resistance</b>-is-added-to-the...", "snippet": "Answer: When starting an electric motor that is under load, you don\u2019t want the motor to start at full speed and full torque, as that could have harmful effects on the mechanical components of the load. There are MANY methods to reduce starting speed and starting torque of an electric motor, addin...", "dateLastCrawled": "2022-01-15T14:08:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(transformer)  is like +(a machine learning algorithm that enables you to turn categorical data into numerical features)", "+(transformer) is similar to +(a machine learning algorithm that enables you to turn categorical data into numerical features)", "+(transformer) can be thought of as +(a machine learning algorithm that enables you to turn categorical data into numerical features)", "+(transformer) can be compared to +(a machine learning algorithm that enables you to turn categorical data into numerical features)", "machine learning +(transformer AND analogy)", "machine learning +(\"transformer is like\")", "machine learning +(\"transformer is similar\")", "machine learning +(\"just as transformer\")", "machine learning +(\"transformer can be thought of as\")", "machine learning +(\"transformer can be compared to\")"]}