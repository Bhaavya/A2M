{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Evolution of responses to (un)<b>fairness</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4451566/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4451566", "snippet": "The hallmark of the human sense of <b>fairness</b> is the idea of impartiality; that is, human <b>fairness</b> or justice is based on the idea of appropriate outcomes applied to everyone within the community, not just a few individuals, and, in particular, not just oneself. Thus, outcomes are judged against a standard, or an ideal. There is variation in this ideal across cultures or situations, but there is consistency within a given context. This complete sense of <b>fairness</b> likely requires abstraction at ...", "dateLastCrawled": "2022-01-07T20:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Justice- and fairness</b>-related behaviors in nonhuman primates | <b>PNAS</b>", "url": "https://www.pnas.org/content/110/Supplement_2/10416", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/110/Supplement_2/10416", "snippet": "<b>Justice- and Fairness</b>-Related Behavior in Other Species. One hypothesis for the evolution of <b>fairness</b> is that <b>recognizing</b> inequities helped individuals ascertain the value of their partners in cooperative interactions (8, 11). Individuals should not continue to work with others if they do not, on average, benefit from the relationship. Whether ...", "dateLastCrawled": "2022-01-22T04:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>The Measure and Mismeasure of Fairness</b>: A Critical Review of Fair ...", "url": "https://www.5harad.com/papers/fair-ml.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.5harad.com/papers/fair-ml.pdf", "snippet": "<b>The Measure and Mismeasure of Fairness</b>: A Critical Review of Fair Machine Learning Sam Corbett-Davies Stanford University Sharad Goel Stanford University September 11, 2018 Abstract The nascent eld of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last several years, three formal de nitions of <b>fairness</b> have gained promi-nence: (1) anti-classi cation, meaning that protected attributes|<b>like</b> race, gender, and their proxies|are not explicitly ...", "dateLastCrawled": "2022-01-28T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Revealing Unfairness in social media contributors\u2019 attention to ...", "url": "https://www.sciencedirect.com/science/article/pii/S2212420921001266", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2212420921001266", "snippet": "<b>Recognizing</b> the tremendous potential of social media for improving public information and warning, a ... <b>individual</b> <b>fairness</b> does not consider sensitive attributes, which is the focus of this study. Suppose SNs with similar impact scores are receiving similar mentions in general, which achieved <b>individual</b> <b>fairness</b>, we still lack information about the extent to which some SNs with vulnerable populations are neglected by the influential users. Similarly, the causality <b>fairness</b> aspect does not ...", "dateLastCrawled": "2021-11-18T13:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "4. <b>Fairness</b> Pre-Processing - Practical <b>Fairness</b> [Book]", "url": "https://www.oreilly.com/library/view/practical-fairness/9781492075721/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/practical-<b>fairness</b>/9781492075721/ch04.html", "snippet": "Learned fair representations aim for a middle ground between group <b>fairness</b> and <b>individual</b> <b>fairness</b> by turning <b>fairness</b> pre-processing into an optimization problem, where different terms in the optimization relate to group <b>fairness</b> and <b>individual</b> <b>fairness</b>. A third term represents a typical loss function and so relates to accuracy. 7. So far I\u2019ve described the goals of the optimization, but I have not discussed what is being optimized\u2014namely, mathematical representations of the data. The ...", "dateLastCrawled": "2022-01-13T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "3. Fair Data \u2013 Practical <b>Fairness</b> \u2013 Dev Tutorials", "url": "https://goois.net/3-fair-data-practical-fairness.html", "isFamilyFriendly": true, "displayUrl": "https://goois.net/3-fair-data-practical-<b>fairness</b>.html", "snippet": "These methodologies generally rely on choosing a <b>fairness</b> metric, generally one that is group-oriented rather than <b>individual</b>-oriented, and selecting a <b>fairness</b> metric to equalize between groups. Even in the case of a black-box model, such models can be retrofitted for <b>fairness</b> in post-processing by choosing different thresholds and scoring criteria, or different probabilities of label swapping or categorizations, according to different groups. The methodologies generally work by identifying ...", "dateLastCrawled": "2021-12-07T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "On <b>the (im)possibility of fairness</b> | DeepAI", "url": "https://deepai.org/publication/on-the-im-possibility-of-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/on-<b>the-im-possibility-of-fairness</b>", "snippet": "A parallel debate is ongoing within the computer science community, including discussions of <b>individual</b> <b>fairness</b> vs. group <b>fairness</b> (e.g., disparate impact\u2019s four-fifths rule and a difference formulation of a discrimination score [3, 13, 14, 20, 25]). These discussions reveal differences in the understood meaning of \u201c<b>fairness</b>\u201d in decision-making centering around two different interpretations of the extent to which factors outside of an <b>individual</b>\u2019s control should be factored into ...", "dateLastCrawled": "2021-12-06T10:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "1. <b>Fairness</b>, Technology, and the Real World - <b>Practical Fairness</b> [Book]", "url": "https://www.oreilly.com/library/view/practical-fairness/9781492075721/ch01.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/<b>practical-fairness</b>/9781492075721/ch01.html", "snippet": "We in the US, as in other parts of the world, also recognize other elements of <b>fairness</b>, such as a social environment that respects <b>individual</b> rights to privacy and <b>individual</b> and community needs for security. The concepts explored in this book are of universal interest; all societies ask the same fundamental questions about <b>fairness</b>, even if the dominant or preferred answer in a specific situation varies with culture or geography.", "dateLastCrawled": "2021-12-17T10:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>An Exploratory Study of &quot;Fairness</b>&quot; \u2014American and Japanese University ...", "url": "https://www.immi.se/intercultural/nr14/kobayashi.htm", "isFamilyFriendly": true, "displayUrl": "https://www.immi.se/intercultural/nr14/kobayashi.htm", "snippet": "Get used to it,&quot; <b>indicating</b> a gap between an ideal (<b>fairness</b>) and reality (unfairness). Also, one American student stated: &quot;I have sometimes been ostracized by fellow students because I occasionally try to impress the instructor with my knowledge of the subject. I feel that they treat me unfairly.&quot; This statement would not be surprising if it had been made about Japanese society where there is a well-known proverb: &quot;The nail that sticks up will be hammered down.&quot; Even though Americans admire ...", "dateLastCrawled": "2022-02-03T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Entry to Practice Reviews Guide</b>", "url": "https://www.fairnesscommissioner.ca/en/Compliance/Strategy/Pages/Entry-to-Practice-Reviews-Guide.aspx", "isFamilyFriendly": true, "displayUrl": "https://www.<b>fairness</b>commissioner.ca/en/Compliance/Strategy/Pages/Entry-to-Practice...", "snippet": "The <b>Fairness</b> Commissioner is committed to a respectful, collaborative relationship with regulatory bodies, <b>recognizing</b> their distinct roles. Before requiring a mandatory Entry-to-Practice Review, the Commissioner or OFC staff meet with the regulator to discuss timing, focus and scope. During the review, regulators are encouraged to keep in touch with their contacts at the OFC to discuss how the review is progressing and to raise any questions about the process.", "dateLastCrawled": "2021-12-09T14:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Fairness</b> metrics and bias mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "<b>Individual</b> <b>Fairness</b> (formerly <b>Fairness</b> Through Awareness) This states that any two individuals who are <b>similar</b>, as defined by a similarity metric (considered as ground truth, e.g., inverse distance metrics) should receive <b>similar</b> treatment. Binns, 2020, Dwork et al., 2012, Kusner et al., 2017: <b>Fairness</b> Through Unawareness", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Evolution of responses to (un)<b>fairness</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4451566/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4451566", "snippet": "The hallmark of the human sense of <b>fairness</b> is the idea of impartiality; that is, human <b>fairness</b> or justice is based on the idea of appropriate outcomes applied to everyone within the community, not just a few individuals, and, in particular, not just oneself. Thus, outcomes are judged against a standard, or an ideal. There is variation in this ideal across cultures or situations, but there is consistency within a given context. This complete sense of <b>fairness</b> likely requires abstraction at ...", "dateLastCrawled": "2022-01-07T20:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Revealing Unfairness in social media contributors\u2019 attention to ...", "url": "https://www.sciencedirect.com/science/article/pii/S2212420921001266", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2212420921001266", "snippet": "<b>Recognizing</b> the tremendous potential of social media for improving public information and warning, a ... <b>Individual</b> <b>fairness</b> : <b>similar</b> entities will receive <b>similar</b> prediction results, regardless of the sensitive attributes. \u2022 Causality <b>fairness</b> : sensitive attributes are excluded from the decision-making logic chain. This study focuses on assessing the <b>fairness</b> of the attention of the influential contributor according to the aspect of \u201cgroup <b>fairness</b>.\u201d Based on its rationale, neither ...", "dateLastCrawled": "2021-11-18T13:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Evolution of responses to (un)<b>fairness</b>", "url": "https://www.science.org/doi/10.1126/science.1251776", "isFamilyFriendly": true, "displayUrl": "https://www.science.org/doi/10.1126/science.1251776", "snippet": "<b>Individual</b> A received high-level rewards, and <b>individual</b> B received low-level rewards. Individuals who recognize when they receive less than another may react against this situation so as to maintain beneficial outcomes of cooperation, for instance, by finding a new cooperative partner. As reliance on cooperation increases, individuals also benefit from <b>recognizing</b> when they receive more, as this allows them to forestall first-order IA reactions in their partners and thereby maintain a ...", "dateLastCrawled": "2022-02-02T21:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Justice- and fairness</b>-related behaviors in nonhuman primates | <b>PNAS</b>", "url": "https://www.pnas.org/content/110/Supplement_2/10416", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/110/Supplement_2/10416", "snippet": "<b>Justice- and Fairness</b>-Related Behavior in Other Species. One hypothesis for the evolution of <b>fairness</b> is that <b>recognizing</b> inequities helped individuals ascertain the value of their partners in cooperative interactions (8, 11). Individuals should not continue to work with others if they do not, on average, benefit from the relationship. Whether ...", "dateLastCrawled": "2022-01-22T04:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>The Measure and Mismeasure of Fairness</b>: A Critical Review of Fair ...", "url": "https://www.5harad.com/papers/fair-ml.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.5harad.com/papers/fair-ml.pdf", "snippet": "<b>The Measure and Mismeasure of Fairness</b>: A Critical Review of Fair Machine Learning Sam Corbett-Davies Stanford University Sharad Goel Stanford University September 11, 2018 Abstract The nascent eld of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last several years, three formal de nitions of <b>fairness</b> have gained promi-nence: (1) anti-classi cation, meaning that protected attributes|like race, gender, and their proxies|are not explicitly ...", "dateLastCrawled": "2022-01-28T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "4. <b>Fairness</b> Pre-Processing - Practical <b>Fairness</b> [Book]", "url": "https://www.oreilly.com/library/view/practical-fairness/9781492075721/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/practical-<b>fairness</b>/9781492075721/ch04.html", "snippet": "Note that for reading this and <b>similar</b> documentation, ... Learned fair representations aim for a middle ground between group <b>fairness</b> and <b>individual</b> <b>fairness</b> by turning <b>fairness</b> pre-processing into an optimization problem, where different terms in the optimization relate to group <b>fairness</b> and <b>individual</b> <b>fairness</b>. A third term represents a typical loss function and so relates to accuracy. 7. So far I\u2019ve described the goals of the optimization, but I have not discussed what is being ...", "dateLastCrawled": "2022-01-13T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "On <b>the (im)possibility of fairness</b> | DeepAI", "url": "https://deepai.org/publication/on-the-im-possibility-of-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/on-<b>the-im-possibility-of-fairness</b>", "snippet": "A parallel debate is ongoing within the computer science community, including discussions of <b>individual</b> <b>fairness</b> vs. group <b>fairness</b> (e.g., disparate impact\u2019s four-fifths rule and a difference formulation of a discrimination score [3, 13, 14, 20, 25]). These discussions reveal differences in the understood meaning of \u201c<b>fairness</b>\u201d in decision-making centering around two different interpretations of the extent to which factors outside of an <b>individual</b>\u2019s control should be factored into ...", "dateLastCrawled": "2021-12-06T10:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deciding to Defer: The Importance of <b>Fairness</b> in Resolving ...", "url": "https://www.cambridge.org/core/journals/international-organization/article/deciding-to-defer-the-importance-of-fairness-in-resolving-transnational-jurisdictional-conflicts/44A3B18D5CA99056BA451B738FAB09D8", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/international-organization/article/deciding-to...", "snippet": "This argument comports with psychological research <b>indicating</b> the subjective nature of <b>fairness</b> perceptions: individuals tend to judge <b>fairness</b> based on their own dispositions and circumstances. Footnote 46. Next, we argue that the <b>fairness</b> assessment includes both procedural <b>fairness</b> and substantive <b>fairness</b>. Footnote 47 Procedural considerations are commonly subsumed under the notion of the rule of law. These include issues such as the independence of the judiciary and regulatory agencies ...", "dateLastCrawled": "2022-01-19T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>An Exploratory Study of &quot;Fairness</b>&quot; \u2014American and Japanese University ...", "url": "https://www.immi.se/intercultural/nr14/kobayashi.htm", "isFamilyFriendly": true, "displayUrl": "https://www.immi.se/intercultural/nr14/kobayashi.htm", "snippet": "Get used to it,&quot; <b>indicating</b> a gap between an ideal (<b>fairness</b>) and reality (unfairness). Also, one American student stated: &quot;I have sometimes been ostracized by fellow students because I occasionally try to impress the instructor with my knowledge of the subject. I feel that they treat me unfairly.&quot; This statement would not be surprising if it had been made about Japanese society where there is a well-known proverb: &quot;The nail that sticks up will be hammered down.&quot; Even though Americans admire ...", "dateLastCrawled": "2022-02-03T12:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Evolution of responses to (un)<b>fairness</b>", "url": "https://www.science.org/doi/10.1126/science.1251776", "isFamilyFriendly": true, "displayUrl": "https://www.science.org/doi/10.1126/science.1251776", "snippet": "The hallmark of the human sense of <b>fairness</b> is the idea of impartiality; that is, human <b>fairness</b> or justice is based on the idea of appropriate outcomes applied to everyone within the community, not just a few individuals, and, in particular, not just oneself. Thus, outcomes are judged against a standard, or an ideal. There is variation in this ideal across cultures or situations, but there is consistency within a given context. This complete sense of <b>fairness</b> likely requires abstraction at ...", "dateLastCrawled": "2022-02-02T21:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>The Measure and Mismeasure of Fairness</b>: A Critical Review of Fair ...", "url": "https://www.5harad.com/papers/fair-ml.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.5harad.com/papers/fair-ml.pdf", "snippet": "<b>indicating</b> problems with an algorithm\u2019s design or with the data on which it was trained. However, we show, perhaps surprisingly, that all three of these popular de nitions of algorithmic <b>fairness</b>|anti-classi cation, classi cation parity, and calibration|su er from deep statistical limitations. In particular, they are poor measures for detecting discriminatory algorithms and, even more importantly, designing algorithms to sat-isfy these de nitions <b>can</b>, perversely, negatively impact the well ...", "dateLastCrawled": "2022-01-28T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "4. <b>Fairness</b> Pre-Processing - Practical <b>Fairness</b> [Book]", "url": "https://www.oreilly.com/library/view/practical-fairness/9781492075721/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/practical-<b>fairness</b>/9781492075721/ch04.html", "snippet": "Chapter 4. <b>Fairness</b> Pre-Processing. As discussed in the previous chapter, <b>fairness</b> <b>can</b> affect three stages of the data modeling pipeline. This chapter focuses on the earliest stage, adjusting the way that data is translated into inputs for a machine learning training process, also called pre-processing the data.. The advantages of pre-processing a data set are numerous.", "dateLastCrawled": "2022-01-13T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fairness</b> metrics and bias mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "Depending on the <b>fairness</b> metric that is considered most useful for a given scenario, this comparison <b>can</b> help a recommender system developer to select the appropriate algorithm while achieving the best <b>fairness</b> in recommendations. On the other hand, these results reflect the complexity of considering different types of <b>fairness</b> definitions and mitigation strategies, and also underline that achieving a good result in one <b>fairness</b> metric (e.g., ItemItem approaches lead to lower Value ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "3. Fair Data \u2013 Practical <b>Fairness</b> \u2013 Dev Tutorials", "url": "https://goois.net/3-fair-data-practical-fairness.html", "isFamilyFriendly": true, "displayUrl": "https://goois.net/3-fair-data-practical-<b>fairness</b>.html", "snippet": "These methodologies generally rely on choosing a <b>fairness</b> metric, generally one that is group-oriented rather than <b>individual</b>-oriented, and selecting a <b>fairness</b> metric to equalize between groups. Even in the case of a black-box model, such models <b>can</b> be retrofitted for <b>fairness</b> in post-processing by choosing different thresholds and scoring criteria, or different probabilities of label swapping or categorizations, according to different groups. The methodologies generally work by identifying ...", "dateLastCrawled": "2021-12-07T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "1. <b>Fairness</b>, Technology, and the Real World - <b>Practical Fairness</b> [Book]", "url": "https://www.oreilly.com/library/view/practical-fairness/9781492075721/ch01.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/<b>practical-fairness</b>/9781492075721/ch01.html", "snippet": "We in the US, as in other parts of the world, also recognize other elements of <b>fairness</b>, such as a social environment that respects <b>individual</b> rights to privacy and <b>individual</b> and community needs for security. The concepts explored in this book are of universal interest; all societies ask the same fundamental questions about <b>fairness</b>, even if the dominant or preferred answer in a specific situation varies with culture or geography.", "dateLastCrawled": "2021-12-17T10:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "WHO\u2019S THE FAIREST OF THEM ALL?:", "url": "http://www.dattnerconsulting.com/papernarcissism.doc", "isFamilyFriendly": true, "displayUrl": "www.dattnerconsulting.com/papernarcissism.doc", "snippet": "Overly positive self-ratings of <b>fairness</b> <b>can</b> also be considered within larger frameworks such as the actor-observer effect, which involves different <b>patterns</b> of attributions for self versus others (Miller and Ross, 1975) or self-enhancement biases, which cause individuals to rate themselves more highly than others rate them on a wide variety of evaluative dimensions (Taylor and Brown, 1988). Both the actor-observer effect and self-enhancement biases have been explained in terms of self ...", "dateLastCrawled": "2021-08-26T17:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Ethical and legal considerations of artificial intelligence and ...", "url": "https://link.springer.com/article/10.1057/s41272-019-00225-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1057/s41272-019-00225-2", "snippet": "Yet redefining <b>fairness</b> <b>can</b> be difficult when an algorithm mistakes misfortune for missed opportunity. During 2 days, November 8\u20139, 2018, following the initial breakout of California\u2019s deadliest wildfire, online price trackers noted that the Amazon.com direct (not third party) prices for a First Alert fire extinguisher and ResQLadder fire escape ladder increased by 18.3% and 22%, respectively. A spokesperson for Amazon.com dismissed the possibility of surge pricing, yet no price ...", "dateLastCrawled": "2022-02-02T23:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "System to Integrate <b>Fairness</b> Transparently: An Industry Approach", "url": "https://www.arxiv-vanity.com/papers/2006.06082/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2006.06082", "snippet": "Numerous Machine Learning (ML) bias-related problems have generated significant press in recent years. This has led to scrutiny of corporate failure regarding how to incorporate human oversight in thorough evaluation and prevention of bias. Companies have a responsibility to monitor ML processes for bias and mitigate any bias detected, ensure business product integrity, preserve customer loyalty, and protect brand image. In this paper, we propose SIFT (System to Integrate <b>Fairness</b> ...", "dateLastCrawled": "2021-09-16T01:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>An Exploratory Study of &quot;Fairness</b>&quot; \u2014American and Japanese University ...", "url": "https://www.immi.se/intercultural/nr14/kobayashi.htm", "isFamilyFriendly": true, "displayUrl": "https://www.immi.se/intercultural/nr14/kobayashi.htm", "snippet": "In contrast, while some Japanese students (n = 53), responded that they <b>thought</b> it was unfair for the student not to have followed the teacher\u2019s advice, a large number of Japanese students\u2019 responses (n = 89) were clustered in the middle <b>indicating</b> some ambivalence. Even though responses to a number of questions did not reveal a significant difference between the two groups, the corresponding written answers did indicate some cultural differences in the way <b>fairness</b> is perceived.", "dateLastCrawled": "2022-02-03T12:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Evolution of responses to (un)<b>fairness</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4451566/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4451566", "snippet": "The human sense of <b>fairness</b> is an evolutionary puzzle. To study this, we <b>can</b> look to other species, in which this <b>can</b> be translated empirically into responses to reward distribution. Passive and active protest against receiving less than a partner for the same task is widespread in species that cooperate outside kinship and mating bonds. There is less evidence that nonhuman species seek to equalize outcomes to their own detriment, yet the latter has been documented in our closest relatives ...", "dateLastCrawled": "2022-01-07T20:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "4. <b>Fairness</b> Pre-Processing - Practical <b>Fairness</b> [Book]", "url": "https://www.oreilly.com/library/view/practical-fairness/9781492075721/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/practical-<b>fairness</b>/9781492075721/ch04.html", "snippet": "Chapter 4. <b>Fairness</b> Pre-Processing. As discussed in the previous chapter, <b>fairness</b> <b>can</b> affect three stages of the data modeling pipeline. This chapter focuses on the earliest stage, adjusting the way that data is translated into inputs for a machine learning training process, also called pre-processing the data.. The advantages of pre-processing a data set are numerous.", "dateLastCrawled": "2022-01-13T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "3. Fair Data \u2013 Practical <b>Fairness</b> \u2013 Dev Tutorials", "url": "https://goois.net/3-fair-data-practical-fairness.html", "isFamilyFriendly": true, "displayUrl": "https://goois.net/3-fair-data-practical-<b>fairness</b>.html", "snippet": "These methodologies generally rely on choosing a <b>fairness</b> metric, generally one that is group-oriented rather than <b>individual</b>-oriented, and selecting a <b>fairness</b> metric to equalize between groups. Even in the case of a black-box model, such models <b>can</b> be retrofitted for <b>fairness</b> in post-processing by choosing different thresholds and scoring criteria, or different probabilities of label swapping or categorizations, according to different groups. The methodologies generally work by identifying ...", "dateLastCrawled": "2021-12-07T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fairness</b> metrics and bias mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "Depending on the <b>fairness</b> metric that is considered most useful for a given scenario, this comparison <b>can</b> help a recommender system developer to select the appropriate algorithm while achieving the best <b>fairness</b> in recommendations. On the other hand, these results reflect the complexity of considering different types of <b>fairness</b> definitions and mitigation strategies, and also underline that achieving a good result in one <b>fairness</b> metric (e.g., ItemItem approaches lead to lower Value ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "2. Understanding <b>Fairness</b> and the Data Science Pipeline \u2013 Practical ...", "url": "https://goois.net/2-understanding-fairness-and-the-data-science-pipeline-practical-fairness.html", "isFamilyFriendly": true, "displayUrl": "https://goois.net/2-understanding-<b>fairness</b>-and-the-data-science-pipeline-practical...", "snippet": "This is not formally a <b>fairness</b> metric but <b>can</b> be used as a metric both to optimize for training and to indicate the relative <b>fairness</b> of a model. A strength of this metric is that it recognizes the tension between <b>fairness</b> and accuracy and to some extent leaves a model free to find a solution that is strong in terms of both. This recognizes that we want to maximize accuracy and minimize unfairness at the same time and effectively makes this a single metric. As discussed in earlier chapters ...", "dateLastCrawled": "2022-01-13T00:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "WHO\u2019S THE FAIREST OF THEM ALL?:", "url": "http://www.dattnerconsulting.com/papernarcissism.doc", "isFamilyFriendly": true, "displayUrl": "www.dattnerconsulting.com/papernarcissism.doc", "snippet": "Overly positive self-ratings of <b>fairness</b> <b>can</b> also be considered within larger frameworks such as the actor-observer effect, which involves different <b>patterns</b> of attributions for self versus others (Miller and Ross, 1975) or self-enhancement biases, which cause individuals to rate themselves more highly than others rate them on a wide variety of evaluative dimensions (Taylor and Brown, 1988). Both the actor-observer effect and self-enhancement biases have been explained in terms of self ...", "dateLastCrawled": "2021-08-26T17:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "1. <b>Fairness</b>, Technology, and the Real World - <b>Practical Fairness</b> [Book]", "url": "https://www.oreilly.com/library/view/practical-fairness/9781492075721/ch01.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/<b>practical-fairness</b>/9781492075721/ch01.html", "snippet": "We in the US, as in other parts of the world, also recognize other elements of <b>fairness</b>, such as a social environment that respects <b>individual</b> rights to privacy and <b>individual</b> and community needs for security. The concepts explored in this book are of universal interest; all societies ask the same fundamental questions about <b>fairness</b>, even if the dominant or preferred answer in a specific situation varies with culture or geography.", "dateLastCrawled": "2021-12-17T10:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Individual</b> differences in the early recognition of moral information in ...", "url": "https://www.nature.com/articles/s41598-017-01623-5", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-017-01623-5", "snippet": "The variation in the early moral effect manifested in the RP <b>can</b> largely be explained by the <b>individual</b> differences in moral preferences in the harm and care foundation. On the one hand, larger ...", "dateLastCrawled": "2022-01-30T21:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Revealing Unfairness in social media contributors\u2019 attention to ...", "url": "https://www.sciencedirect.com/science/article/pii/S2212420921001266", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2212420921001266", "snippet": "Based on its rationale, neither <b>individual</b> <b>fairness</b> nor causality <b>fairness</b> fit the problem setting of assessing the <b>fairness</b> of attention of the influential contributor. First, <b>individual</b> <b>fairness</b> does not consider sensitive attributes, which is the focus of this study. Suppose SNs with similar impact scores are receiving similar mentions in general, which achieved <b>individual</b> <b>fairness</b>, we still lack information about the extent to which some SNs with vulnerable populations are neglected by ...", "dateLastCrawled": "2021-11-18T13:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Individual substance abuse, perceived workplace fairness</b> and ...", "url": "https://www.researchgate.net/publication/344388557_Individual_substance_abuse_perceived_workplace_fairness_and_organisational_factors_as_predictors_of_absenteeism_among_civil_servants_in_Oyo_State", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344388557_<b>Individual</b>_substance_abuse...", "snippet": "The present paper intends to explore <b>individual</b> and organisational factors (<b>substance abuse, perceived workplace fairness</b>, work stress, and co-worker support) that predict absenteeism among civil ...", "dateLastCrawled": "2022-01-27T14:41:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Practical <b>Individual</b> <b>Fairness</b> Algorithms \u2013 Toronto <b>Machine</b> <b>Learning</b>", "url": "https://www.torontomachinelearning.com/events/practical-individual-fairness-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.toronto<b>machinelearning</b>.com/events/practical-<b>individual</b>-<b>fairness</b>-algorithms", "snippet": "<b>Individual</b> <b>Fairness</b> (IF) is a very intuitive and desirable notion of <b>fairness</b>: we want ML models to treat similar individuals similarly, that is, to be fair for every person. For example, two resumes of individuals that only differ in their name and gender pronouns should be treated similarly by the model. Despite the intuition, training ML/AI models that abide by this rule in theory and in practice poses several challenges. In this talk, I will introduce a notion of Distributional ...", "dateLastCrawled": "2021-12-31T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Finding the <b>fairness</b> in ethical <b>machine</b> <b>learning</b> - Taylor Fry", "url": "https://taylorfry.nz/articles/finding-the-fairness-in-ethical-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://taylorfry.nz/articles/finding-the-<b>fairness</b>-in-ethical-<b>machine</b>-<b>learning</b>", "snippet": "Likewise, <b>machine</b> <b>learning</b> infrastructure is also missing, specifically, regulating the use of <b>machine</b> <b>learning</b> to ensure it\u2019s used in an ethical and beneficial way, rather than used by a small number for their advantage at the significant disadvantage of the majority. It\u2019s important we all continue to have this conversation together, and take action at <b>individual</b>, organisational, governmental and global levels to bring about a future where AI is used to help not hinder.", "dateLastCrawled": "2022-01-07T11:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Residual Unfairness in Fair <b>Machine</b> <b>Learning</b> from Prejudiced Data", "url": "http://proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "snippet": "Recent work on <b>fairness</b> in <b>machine</b> <b>learning</b> proposes and analyzes competing criteria for assessing the <b>fairness</b> of <b>ma-chine</b> <b>learning</b> algorithms, where some adjustments attempt to equalize accuracy metrics across groups (Corbett-Davies etal.,2017;Kleinbergetal.,2017;Hardtetal.,2016). Other work studies how historical prejudices may be re\ufb02ected in training data such that algorithmic systems might replicate historical biases (Angwin et al., 2016; Lum &amp; Isaac, 2016; Kilbertus et al., 2017). We ...", "dateLastCrawled": "2022-01-31T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "RStudio AI Blog: Starting to think about AI <b>Fairness</b>", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-<b>fairness</b>", "snippet": "Papers on <b>fairness</b> in <b>machine</b> <b>learning</b>, as is common in fields like computer science, abound with formulae. Even the papers referenced here, though selected not for their theorems and proofs but for the ideas they harbor, are no exception. But to start thinking about <b>fairness</b> as it might apply to an ML process at hand, common language \u2013 and common sense \u2013 will do just fine. If, after analyzing your use case, you judge that the more technical results are relevant to the process in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to <b>Create Unbiased ML Models | Deepchecks</b>", "url": "https://deepchecks.com/how-to-create-unbiased-ml-models/", "isFamilyFriendly": true, "displayUrl": "https://deepchecks.com/how-to-create-unbiased-ml-models", "snippet": "\u201cIn <b>machine</b> <b>learning</b>, a given algorithm is said to be fair, or to have <b>fairness</b>, if its results are independent of given variables, especially those considered sensitive, such as the traits of individuals which should not correlate with the outcome (i.e. gender, ethnicity, sexual orientation, disability, etc.).\u201d \u201c<b>Fairness</b>\u201d, Wikipedia", "dateLastCrawled": "2022-01-13T06:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b> and Theological Traditions of <b>Analogy</b> - Davison - 2021 ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "snippet": "12 <b>Machine</b> <b>Learning</b>, <b>Analogy</b>, and God. The texts considered in this article come from theological sources. They have offered ways to think analogically about features of the world, in this case the similarities we are beginning to see between capacities in <b>machine</b> <b>learning</b> and those in human beings and other animals. Much of the mediaeval ...", "dateLastCrawled": "2021-04-16T10:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fairness</b> Through Awareness", "url": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "snippet": "this <b>individual</b>-based <b>fairness</b>, we assume a distance metric that de\ufb01nes the similarity between the individuals. This is the source of \u201cawareness\u201d in the title of this paper. We formalize this guiding principle as a Lipschitz condition on the classi\ufb01er. In our approach a classi\ufb01er is a randomized mapping from individuals to outcomes, or equivalently, a mapping from individuals to distributions over outcomes. The Lipschitz condition requires that any two individuals x;ythat are at ...", "dateLastCrawled": "2022-01-29T03:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "An evaluation of scanpath-comparison and <b>machine</b>-<b>learning</b> ...", "url": "https://link.springer.com/article/10.3758/s13428-016-0788-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.3758/s13428-016-0788-z", "snippet": "The bottom line is that scanpath-comparison algorithms and the <b>machine</b>-<b>learning</b> techniques that accompany them are powerful tools to study the dynamics of <b>analogy</b> making. In building models of <b>analogy</b> making, we want to know what the models predict and how they make those predictions. Although the tools presented in this article are more involved with prediction than with explanation, the two are hardly unrelated, especially when we know the bases of the predictions. Our overarching goal has ...", "dateLastCrawled": "2021-11-05T03:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The UX of AI Part I: Ants in Your Pants or Ants in Your Brain? | by zac ...", "url": "https://medium.com/@ZacTaschdjian/the-ux-of-ai-part-i-ants-in-your-pants-or-ants-in-your-brain-3cfef7990e7a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@ZacTaschdjian/the-ux-of-ai-part-i-ants-in-your-pants-or-ants-in...", "snippet": "The UX of AI Part II: Inscrutability in Deep Reinforcement <b>Learning</b> Neural Networks. Paper 1 is \u201cTransparency and Explanation in Deep Reinforcement <b>Learning</b> Neural Networks\u201d(Iyar, et. al. 2018 ...", "dateLastCrawled": "2022-01-22T22:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Making Fair ML Software using Trustworthy Explanation", "url": "https://www.researchgate.net/profile/Kewen-Peng-4/publication/342733939_Making_Fair_ML_Software_using_Trustworthy_Explanation/links/5fe0ddcea6fdccdcb8ef5a11/Making-Fair-ML-Software-using-Trustworthy-Explanation.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/profile/Kewen-Peng-4/publication/342733939_Making_Fair_ML...", "snippet": "<b>Machine</b> <b>learning</b> software is being used in many applications (fi-nance, hiring, admissions, criminal justice) having huge social im-pact. But sometimes the behavior of this software is biased and ...", "dateLastCrawled": "2021-09-29T17:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Making Fair <b>ML Software using Trustworthy Explanation</b> | DeepAI", "url": "https://deepai.org/publication/making-fair-ml-software-using-trustworthy-explanation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/making-fair-<b>ml-software-using-trustworthy-explanation</b>", "snippet": "<b>Machine</b> <b>learning</b> software is being used in many applications (finance, hiring, admissions, criminal justice) having a huge social impact. But sometimes the behavior of this software is biased and it shows discrimination based on some sensitive attributes such as sex, race, etc. Prior works concentrated on finding and mitigating bias in ML models.", "dateLastCrawled": "2022-01-24T00:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Making fair ML software using trustworthy explanation", "url": "https://www.researchgate.net/publication/348827111_Making_fair_ML_software_using_trustworthy_explanation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/348827111_Making_fair_ML_software_using...", "snippet": "PDF | On Dec 21, 2020, Joymallya Chakraborty and others published Making fair ML software using trustworthy explanation | Find, read and cite all the research you need on ResearchGate", "dateLastCrawled": "2021-11-13T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Service-Oriented Computing: 18th International Conference, ICSOC 2020 ...", "url": "https://dokumen.pub/service-oriented-computing-18th-international-conference-icsoc-2020-dubai-united-arab-emirates-december-1417-2020-proceedings-1st-ed-9783030653095-9783030653101.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/service-oriented-computing-18th-international-conference-icsoc...", "snippet": "In a Fog environment, a Kubernetes Node is a worker <b>machine</b>, and it may be a virtual <b>machine</b> or a physical <b>machine</b> that corresponds to a node, a.k.a., Fog node. A set of Kubernetes Nodes makes up a Kubernetes cluster. A Kubernetes cluster corresponds to a set of fog nodes. Each microservice can be containerized and, therefore, it belongs to a single Docker container. A Kubernetes Pod is a group of containers with shared network and storage, that are always coscheduled and co-located. Finally ...", "dateLastCrawled": "2021-12-24T17:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Counterfactual Fairness: Unidentification, Bound and Algorithm ...", "url": "https://www.researchgate.net/publication/334843895_Counterfactual_Fairness_Unidentification_Bound_and_Algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334843895_Counterfactual_Fairness_Un...", "snippet": "Fairness in <b>machine</b> <b>learning</b> has been a research subject with rapid growth recently. Many different definitions of fairness have been designed to fit different settings, e.g., equality of ...", "dateLastCrawled": "2021-12-23T12:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Putting <b>Fairness Principles into Practice: Challenges, Metrics</b>, and ...", "url": "https://deepai.org/publication/putting-fairness-principles-into-practice-challenges-metrics-and-improvements", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/putting-<b>fairness-principles-into-practice-challenges</b>...", "snippet": "By almost every measure, there has been an explosion in attention and research on <b>machine</b> <b>learning</b> fairness: there is a quickly growing amount of research on how to define, measure, and address <b>machine</b> <b>learning</b> fairness, and products are evaluated with these concerns in mind. Despite this significant attention, there has been much less published work detailing how fairness concerns are measured and addressed by product teams in industry. In this paper, we hope to shed light on the challenges ...", "dateLastCrawled": "2022-01-23T04:12:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(individual fairness)  is like +(recognizing patterns indicating fairness)", "+(individual fairness) is similar to +(recognizing patterns indicating fairness)", "+(individual fairness) can be thought of as +(recognizing patterns indicating fairness)", "+(individual fairness) can be compared to +(recognizing patterns indicating fairness)", "machine learning +(individual fairness AND analogy)", "machine learning +(\"individual fairness is like\")", "machine learning +(\"individual fairness is similar\")", "machine learning +(\"just as individual fairness\")", "machine learning +(\"individual fairness can be thought of as\")", "machine learning +(\"individual fairness can be compared to\")"]}