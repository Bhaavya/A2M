{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b> in A.I. &amp; <b>Machine</b> <b>Learning</b> Examples \u2013 Tanner Abraham", "url": "https://tannerabraham.com/bias-in-machine-learning-and-ai-examples/", "isFamilyFriendly": true, "displayUrl": "https://tannerabraham.com/<b>bias</b>-in-<b>machine</b>-<b>learning</b>-and-ai-examples", "snippet": "These biases include sample <b>bias</b>, reporting <b>bias</b>, prejudice <b>bias</b>, confirmation <b>bias</b>, group attribution <b>bias</b>, <b>algorithm</b> <b>bias</b>, measurement <b>bias</b>, recall <b>bias</b>, exclusion <b>bias</b>, and automation <b>bias</b>. <b>Machine</b> <b>learning</b> is highly susceptible to many forms of <b>bias</b> that can undermine model performance. After all, AI is assembled by humans, and humans are ...", "dateLastCrawled": "2022-01-28T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b> Fairness: Types of <b>Bias</b> | by Svs Nagesh | Medium", "url": "https://nageshsomayajula.medium.com/machine-learning-fairness-types-of-bias-82bcf3df2d47", "isFamilyFriendly": true, "displayUrl": "https://nageshsomayajula.medium.com/<b>machine</b>-<b>learning</b>-fairness-types-of-<b>bias</b>-82bcf3df2d47", "snippet": "AI a p plications are <b>like</b> a small kid, we must train with the right data otherwise they can be misguided, and correcting machines or AI applications will be big challenging, for kids also (pun intended). The AI systems themselves will construct models that will explain how it works and follow anti-<b>bias</b> rules. In the <b>machine</b>, <b>learning</b> <b>bias</b> is one of the most common problems and every <b>algorithm</b> falls trap on this various kind of <b>bias</b>, let\u2019s discuss in detail various types of <b>bias</b> and how to ...", "dateLastCrawled": "2022-01-30T12:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Unfair biases in Machine Learning: what, why, where</b> and how to ...", "url": "https://www.mlsecurity.ai/post/unfair-biases-in-machine-learning-what-why-where-and-how-to-obliterate-them", "isFamilyFriendly": true, "displayUrl": "https://www.mlsecurity.ai/post/<b>unfair-biases-in-machine-learning-what-why-where</b>-and...", "snippet": "An overview of <b>machine</b> <b>learning</b> fairness This article introduces <b>machine</b> <b>learning</b> fairness, to give the reader a vision of the whole problem. To be fair, this study is tinted by my own biased understanding of the field. My goal here is to ask the right questions above all. It is a vast field and when it seems important, I give links to much more in-depth studies which describe in detail the causes, the effects and the measures of fairness. In 2016, the risk assessment AI software named COMPAS wa", "dateLastCrawled": "2022-02-01T14:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Unfair biases in <b>Machine Learning</b>: what, why, where and how to ...", "url": "https://medium.com/disaitek/unfair-biases-in-machine-learning-what-why-where-and-how-to-obliterate-them-1d6e682ac556", "isFamilyFriendly": true, "displayUrl": "https://medium.com/disaitek/unfair-<b>bias</b>es-in-<b>machine-learning</b>-what-why-where-and-how...", "snippet": "For instance, in one case of hiring <b>machine learning</b> system the age <b>bias</b> seems unfair but in a model involved in predicting the survival of a patient which has the COVID-19, age seems to be an ...", "dateLastCrawled": "2022-01-29T21:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Biases in <b>machine</b> <b>learning</b> models and big data analytics: The ...", "url": "http://international-review.icrc.org/articles/biases-machine-learning-big-data-analytics-ihl-implications-913", "isFamilyFriendly": true, "displayUrl": "international-review.icrc.org/articles/<b>bias</b>es-<b>machine</b>-<b>learning</b>-big-data-analytics-ihl...", "snippet": "Advances in mobile phone technology and social media have created a world where the volume of information generated and shared is outpacing the ability of humans to review and use that data. <b>Machine</b> <b>learning</b> (ML) models and \u201cbig data\u201d analytical tools have the power to ease that burden by making sense of this information and providing insights that might not otherwise exist. In the context of international criminal and human rights law, ML is being used for a variety of purposes ...", "dateLastCrawled": "2022-02-01T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "linkedin-skill-assessments-quizzes/<b>machine</b>-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/.../blob/master/<b>machine</b>-<b>learning</b>/<b>machine</b>-<b>learning</b>-quiz.md", "snippet": "Higher K values lower the variance but increase the <b>bias</b>. Q33. Your <b>machine</b> <b>learning</b> system is attempting to describe a hidden structure from unlabeled data. How would you describe this <b>machine</b> <b>learning</b> method? supervised <b>learning</b> ; unsupervised <b>learning</b>; reinforcement <b>learning</b>; semi-unsupervised <b>learning</b>; Q34. You work for a large credit card processing company that wants to create targeted promotions for its customers. The data science team created a <b>machine</b> <b>learning</b> system that groups ...", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Chapter 11 Bias and Fairness</b> | Big Data and Social Science", "url": "https://textbook.coleridgeinitiative.org/chap-bias.html", "isFamilyFriendly": true, "displayUrl": "https://textbook.coleridgeinitiative.org/chap-<b>bias</b>.html", "snippet": "Section <b>bias</b> examples provided some examples for how <b>bias</b> might be introduced in the process of using <b>machine</b> <b>learning</b> to work with a dataset. While far from exhaustive as a source of potential <b>bias</b> in an overall application, these biases can be more readily measured and addressed through choices made during data preparation, modeling, and model selection. This section focuses on detecting and understanding biases introduced at this stage of the process.", "dateLastCrawled": "2022-01-30T01:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Biased Algorithms Learn From Biased Data: 3 Kinds Biases Found In AI ...", "url": "https://www.forbes.com/sites/cognitiveworld/2020/02/07/biased-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.forbes.com</b>/sites/cognitiveworld/2020/02/07/<b>bias</b>ed-<b>algorithms</b>", "snippet": "It happens because of something that is mounting alarm: algorithmic <b>bias</b>. Algorithms are the foundation of <b>machine</b> <b>learning</b>. They are what drives intelligent machines to make decisions. These ...", "dateLastCrawled": "2022-01-30T20:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Comparing <b>Machine</b> <b>Learning</b> Algorithms on a single Dataset ...", "url": "https://medium.com/@vaibhavpaliwal/comparing-machine-learning-algorithms-on-a-single-dataset-classification-46ffc5d3f278", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@vaibhavpaliwal/comparing-<b>machine</b>-<b>learning</b>-<b>algorithms</b>-on-a-single...", "snippet": "It is a supervised <b>machine</b> <b>learning</b> <b>algorithm</b> that is mainly used to classify data into different classes. Unlike most algorithms, SVM makes use of a hyperplane which acts as a decision boundary ...", "dateLastCrawled": "2022-01-30T10:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Comparison of <b>machine</b> <b>learning</b> and logistic regression models in ...", "url": "https://www.sciencedirect.com/science/article/pii/S1386505621001106", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1386505621001106", "snippet": "<b>Machine</b> <b>learning</b> performance to predict acute kidney injury is variable and depends on the predictor variables included in the model as well as the type of <b>algorithm</b> deployed. While common biomarkers (creatinine, BUN) for acute kidney injury were important for model performance, there are a large number of predictor variables that have been identified and are currently being used in <b>machine</b> <b>learning</b> models.", "dateLastCrawled": "2022-01-27T13:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b> in A.I. &amp; <b>Machine</b> <b>Learning</b> Examples \u2013 Tanner Abraham", "url": "https://tannerabraham.com/bias-in-machine-learning-and-ai-examples/", "isFamilyFriendly": true, "displayUrl": "https://tannerabraham.com/<b>bias</b>-in-<b>machine</b>-<b>learning</b>-and-ai-examples", "snippet": "<b>Bias</b> in A.I. &amp; <b>Machine</b> <b>Learning</b> Examples. <b>Machine</b> <b>learning</b> algorithms are often mistaken as objective analytics and decision-making solutions to human inefficiencies. Paradoxically, humans often make <b>machine</b> <b>learning</b> algorithms inefficient by way of biases. These biases include sample <b>bias</b>, reporting <b>bias</b>, prejudice <b>bias</b>, confirmation <b>bias</b> ...", "dateLastCrawled": "2022-01-28T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Accuracy comparison across face recognition algorithms: Where are we on ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7879975/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7879975", "snippet": "One of the first studies to demonstrate a race <b>bias</b> in algorithms examined early neural network models based on auto-associative <b>learning</b> and principal components analysis (PCA) . This study showed that experience-based computational models are influenced by race, but only when the basic features used to encode faces were derived from the statistical structure of the training data. The model was trained with either Asian faces, as the minority race, and Caucasian faces, as the majority race ...", "dateLastCrawled": "2022-01-29T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "linkedin-skill-assessments-quizzes/<b>machine</b>-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/.../blob/master/<b>machine</b>-<b>learning</b>/<b>machine</b>-<b>learning</b>-quiz.md", "snippet": "Higher K values lower the variance but increase the <b>bias</b>. Q33. Your <b>machine</b> <b>learning</b> system is attempting to describe a hidden structure from unlabeled data. How would you describe this <b>machine</b> <b>learning</b> method? supervised <b>learning</b>; unsupervised <b>learning</b>; reinforcement <b>learning</b>; semi-unsupervised <b>learning</b>; Q34. You work for a large credit card processing company that wants to create targeted promotions for its customers. The data science team created a <b>machine</b> <b>learning</b> system that groups ...", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bias</b>, awareness, and ignorance in deep-<b>learning</b>-based face recognition ...", "url": "https://link.springer.com/article/10.1007%2Fs43681-021-00108-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s43681-021-00108-6", "snippet": "FR has improved considerably and constantly over the last decade [1,2,3,4], giving rise to numerous applications ranging from services on mobile consumer devices to the use by law enforcement agencies [5,6,7].The increased deployment has triggered an intense debate on the dangers of the pervasive use of biometrics [8,9,10,11] up to the point where regulation [] and bans on the technology are discussed [] and partially enforced [14, 15].Several civil rights groups oppose facial recognition ...", "dateLastCrawled": "2022-02-03T10:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Using <b>Machine</b> <b>Learning</b> to Compare Provaccine and Antivaccine Discourse ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8277307/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8277307", "snippet": "Second, we developed a <b>machine</b> <b>learning</b> (ML)-based automatic classifier of pro- and antivaccine posts and unsupervised clustering for extracting discursive topics. This set of ML algorithms will aid future researchers in assessing the effectiveness of public health campaigns on social media and hence facilitate the successful development of future interventions. Lastly, we conducted a multistep content analysis that combines interpretive (inductive) with objective (deductive) coding to ...", "dateLastCrawled": "2021-09-03T12:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Lecture 10: Clustering</b>", "url": "https://shuaili8.github.io/Teaching/VE445/L10_clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://shuaili8.github.io/Teaching/VE445/L10_clustering.pdf", "snippet": "<b>Machine</b> <b>learning</b> categories \u2022Unsupervised <b>learning</b> \u2022No labeled data \u2022Supervised <b>learning</b> \u2022Use labeled data to predict on unseen points \u2022Semi-supervised <b>learning</b> \u2022Use labeled data and unlabeled data to predict on unlabeled/unseen points \u2022Reinforcement <b>learning</b> \u2022Sequential prediction and receiving feedbacks 4. Course outline \u2022Basics \u2022Supervised <b>learning</b> \u2022Linear Regression \u2022Logistic regression \u2022SVM and Kernel methods \u2022Decision Tree \u2022Deep <b>learning</b> \u2022Neural Networks ...", "dateLastCrawled": "2022-02-02T06:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Interventions | <b>Machine Learning Bias Mitigation</b>", "url": "https://cdeiuk.github.io/bias-mitigation/interventions/", "isFamilyFriendly": true, "displayUrl": "https://cdeiuk.github.io/<b>bias</b>-mitigation/interventions", "snippet": "The first component of the <b>algorithm</b> is an information withholding procedure. For a fixed proportion of randomly chosen points in each protected group in the dataset, we will predict the <b>in-group</b> class balance of the labels rather than return the output of the model. The observation Pleiss make is that that this procedure preserves calibration.", "dateLastCrawled": "2022-02-02T02:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Sharing learnings from the first algorithmic <b>bias</b> bounty challenge", "url": "https://blog.twitter.com/engineering/en_us/topics/insights/2021/learnings-from-the-first-algorithmic-bias-bounty-challenge", "isFamilyFriendly": true, "displayUrl": "https://blog.twitter.com/.../<b>learning</b>s-from-the-first-<b>algorithm</b>ic-<b>bias</b>-bounty-challenge", "snippet": "In August 2021, we held the first algorithmic <b>bias</b> bounty challenge and invited the ethical AI hacker community to take apart our <b>algorithm</b> to identify additional <b>bias</b> and other potential harms within it. The results of their findings confirmed our hypothesis: we can\u2019t solve these challenges alone, and our understanding of <b>bias</b> in AI can be improved when diverse voices are able to contribute to the conversation.", "dateLastCrawled": "2022-02-02T23:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Comparison of <b>machine</b> <b>learning</b> and logistic regression models in ...", "url": "https://www.sciencedirect.com/science/article/pii/S1386505621001106", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1386505621001106", "snippet": "<b>Machine</b> <b>learning</b> performance to predict acute kidney injury is variable and depends on the predictor variables included in the model as well as the type of <b>algorithm</b> deployed. While common biomarkers (creatinine, BUN) for acute kidney injury were important for model performance, there are a large number of predictor variables that have been identified and are currently being used in <b>machine</b> <b>learning</b> models.", "dateLastCrawled": "2022-01-27T13:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Racist in <b>the Machine: The Disturbing Implications of Algorithmic Bias</b>", "url": "https://www.researchgate.net/publication/312080801_Racist_in_the_Machine_The_Disturbing_Implications_of_Algorithmic_Bias", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/312080801_Racist_in_the_<b>Machine</b>_The...", "snippet": "Another example of <b>machine</b> <b>learning</b> <b>bias</b> relates to word embedding, as algorithms are trained using text, they may exhibit gender stereotyping (Bolukbasi, Chang, Zou, Saligrama, and Kalai, 2016 ...", "dateLastCrawled": "2022-01-21T19:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Algorithmic <b>Bias</b> in Education | SpringerLink", "url": "https://link.springer.com/article/10.1007/s40593-021-00285-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s40593-021-00285-9", "snippet": "While several attempts have been made at locating sources of <b>bias</b> within the <b>machine</b> <b>learning</b> pipeline (See Fig. 1), other researchers have argued for locating algorithmic <b>bias</b>, not only at a stage within this process, but also as the product of the social interactions surrounding the production and use of an <b>algorithm</b>. Drawing from sociocultural activity theory, Ferrero and Barujel (2019) describe an <b>algorithm</b> as the artifact of an activity system, locating <b>bias</b> within the connected parts ...", "dateLastCrawled": "2022-01-28T10:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias</b>, awareness, and ignorance in deep-<b>learning</b>-based face recognition ...", "url": "https://link.springer.com/article/10.1007%2Fs43681-021-00108-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s43681-021-00108-6", "snippet": "We investigate how well <b>machine</b> <b>learning</b> models <b>can</b> predict the sensitive features, such as ethnicity and gender, based on the face embedding. The intuition is that an FR model is \u201caware\u201d of a sensitive feature if it <b>can</b> be predicted from the embedding vectors produced by the FR model. This inference is a classification task and the performance depends on the classification model at hand. If simple models, more precisely models with a low number of parameters, <b>can</b> properly infer the ...", "dateLastCrawled": "2022-02-03T10:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Algorithmic <b>bias</b>: Senses, sources, solutions - Fazelpour - 2021 ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/phc3.12760?af=R", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/phc3.12760?af=R", "snippet": "We deliberately show some details than are not usually philosophically relevant, as popular presentations of <b>machine</b> <b>learning</b> and data science sometimes mistakenly suggest that <b>algorithm</b> development is a relatively simple pipeline. At the same time, given that complexity, our discussion of sources of <b>bias</b> across this pipeline cannot be exhaustive. The many, often inter-dependent choice points\u2014some seemingly innocuous\u2014require value judgments, and so imbue the model with values. A key ...", "dateLastCrawled": "2022-01-01T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Chapter 11 Bias and Fairness</b> | Big Data and Social Science", "url": "https://textbook.coleridgeinitiative.org/chap-bias.html", "isFamilyFriendly": true, "displayUrl": "https://textbook.coleridgeinitiative.org/chap-<b>bias</b>.html", "snippet": "Unfortunately, just as there is no single <b>machine</b> <b>learning</b> <b>algorithm</b> that is best suited to every application, no one fairness metric will fit every situation. However, we hope this chapter will provide you with a grounding in the available ways of measuring algorithmic fairness that will help you navigate the trade-offs involved putting these into practice in your own applications. 11.2 Sources of <b>Bias</b>. <b>Bias</b> may be introduced into a <b>machine</b> <b>learning</b> project at any step along the way and it ...", "dateLastCrawled": "2022-01-30T01:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bias</b> does not equal <b>bias</b>. A socio-technical typology of <b>bias</b> in data ...", "url": "https://policyreview.info/articles/analysis/bias-does-not-equal-bias-socio-technical-typology-bias-data-based-algorithmic", "isFamilyFriendly": true, "displayUrl": "https://policyreview.info/articles/analysis/<b>bias</b>-does-not-equal-<b>bias</b>-socio-technical...", "snippet": "Zooming into the technical details of a <b>machine</b> <b>learning</b> system\u2019s life cycle, Suresh and Guttag (2020) described various issues that <b>can</b> introduce <b>bias</b> into a system: historical <b>bias</b>, representation <b>bias</b>, measurement <b>bias</b>, aggregation <b>bias</b>, <b>learning</b> <b>bias</b>, evaluation <b>bias</b> and deployment <b>bias</b>. Some of these types of data <b>bias</b> <b>can</b> only be identified through extensive knowledge and close examination of the development process of a particular system including the underlying data used to build ...", "dateLastCrawled": "2022-01-22T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>In-Group</b> <b>Bias</b> in the Indian Judiciary: Evidence from 5 Million Criminal ...", "url": "https://casi.sas.upenn.edu/events/paulnovosad", "isFamilyFriendly": true, "displayUrl": "https://casi.sas.upenn.edu/events/paulnovosad", "snippet": "Today, Paul Novosad is going to present on judicial <b>bias</b>, <b>In-Group</b> <b>Bias</b> in Indian criminal courts, collecting data on over five million criminal case records from 2010 to 2018. The research explores quasi-random assignment of cases to judges, to examine whether defendant outcomes are affected by assignment to a judge with a similar identity. The paper is [inaudible 00:01:35] of evidence of <b>In-Group</b> <b>Bias</b> on gender and religious identity and finds limited <b>In-Group</b> <b>Bias</b> in some settings, where ...", "dateLastCrawled": "2022-01-26T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "linkedin-skill-assessments-quizzes/<b>machine</b>-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/.../blob/master/<b>machine</b>-<b>learning</b>/<b>machine</b>-<b>learning</b>-quiz.md", "snippet": "Higher K values lower the variance but increase the <b>bias</b>. Q33. Your <b>machine</b> <b>learning</b> system is attempting to describe a hidden structure from unlabeled data. How would you describe this <b>machine</b> <b>learning</b> method? supervised <b>learning</b>; unsupervised <b>learning</b>; reinforcement <b>learning</b>; semi-unsupervised <b>learning</b>; Q34. You work for a large credit card processing company that wants to create targeted promotions for its customers. The data science team created a <b>machine</b> <b>learning</b> system that groups ...", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Amazon SageMaker Clarify: <b>Machine</b> <b>Learning</b> <b>Bias</b> Detection and ...", "url": "https://deepai.org/publication/amazon-sagemaker-clarify-machine-learning-bias-detection-and-explainability-in-the-cloud", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/amazon-sagemaker-clarify-<b>machine</b>-<b>learning</b>-<b>bias</b>...", "snippet": "Understanding the predictions made by <b>machine</b> <b>learning</b> (ML) models and their potential biases remains a challenging and labor-intensive task that depends on the application, the dataset, and the specific model. We present Amazon SageMaker Clarify, an explainability feature for Amazon SageMaker that launched in December 2020, providing insights into data and ML models by identifying biases and explaining predictions.", "dateLastCrawled": "2022-01-25T08:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Development and Internal Validation of <b>Machine</b> <b>Learning</b> Algorithms for ...", "url": "https://www.researchgate.net/publication/357001931_Development_and_Internal_Validation_of_Machine_Learning_Algorithms_for_Predicting_Hyponatremia_After_TJA", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357001931_Development_and_Internal_Validation...", "snippet": "Results: The <b>machine</b> <b>learning</b> <b>algorithm</b> required age, race, gender, and comorbidity scores (&quot;risk of illness&quot; and &quot;risk of morbidity&quot;) to demonstrate excellent validity, reliability, and ...", "dateLastCrawled": "2022-01-01T10:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Where <b>can</b> I learn the basics of <b>machine</b> <b>learning</b> algorithms? - Quora", "url": "https://www.quora.com/Where-can-I-learn-the-basics-of-machine-learning-algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Where-<b>can</b>-I-learn-the-basics-of-<b>machine</b>-<b>learning</b>-<b>algorithms</b>", "snippet": "Answer (1 of 4): I will suggest the course \u201c introduction to <b>machine</b> <b>learning</b> \u201c by Andrew Ng on coursera ,although this course will use octave/matlab for coding purposes but it will teach you all the basics of <b>machine</b> <b>learning</b> ,working of different algorithms in the easiest way possible. One day ...", "dateLastCrawled": "2022-01-11T11:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Biases in <b>machine</b> <b>learning</b> models and big data analytics: The ...", "url": "https://www.cambridge.org/core/journals/international-review-of-the-red-cross/article/biases-in-machine-learning-models-and-big-data-analytics-the-international-criminal-and-humanitarian-law-implications/86BEAC9ADD165C90B2931AB2B665FFDF", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/international-review-of-the-red-cross/article/...", "snippet": "Common biases in <b>machine</b> <b>learning</b> and big data analytics. Data sets often contain biases which have the potential to unfairly disadvantage certain groups or to over-focus on certain activities to the detriment of others, and ML models or big data analytics trained on such data sets <b>can</b> inherit these biases.", "dateLastCrawled": "2021-12-21T11:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Comparing <b>Machine</b> <b>Learning</b> Algorithms on a single Dataset ...", "url": "https://medium.com/@vaibhavpaliwal/comparing-machine-learning-algorithms-on-a-single-dataset-classification-46ffc5d3f278", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@vaibhavpaliwal/comparing-<b>machine</b>-<b>learning</b>-<b>algorithms</b>-on-a-single...", "snippet": "It is a supervised <b>machine</b> <b>learning</b> <b>algorithm</b> that is mainly used to classify data into different classes. Unlike most algorithms, SVM makes use of a hyperplane which acts as a decision boundary ...", "dateLastCrawled": "2022-01-30T10:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Fairness and Bias in</b> <b>Machine</b> <b>Learning</b> Algorithms | District Data Labs", "url": "https://www.districtdatalabs.com/fairness-and-bias-in-algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.districtdatalabs.com/<b>fairness-and-bias-in-algorithms</b>", "snippet": "In this post, I want to explore whether we <b>can</b> use the tools in Yellowbrick to \u201caudit\u201d a black-box <b>algorithm</b> and assess claims about fairness and <b>bias</b>. At the same time, I prefer R for most visualization tasks. Fortunately, the new reticulate package has allowed Python part-timers, like me, to get something close to the best of both worlds.", "dateLastCrawled": "2022-01-23T03:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Comparison of <b>machine</b> <b>learning</b> and logistic regression models in ...", "url": "https://www.sciencedirect.com/science/article/pii/S1386505621001106", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1386505621001106", "snippet": "<b>Machine</b> <b>learning</b> performance to predict acute kidney injury is variable and depends on the predictor variables included in the model as well as the type of <b>algorithm</b> deployed. While common biomarkers (creatinine, BUN) for acute kidney injury were important for model performance, there are a large number of predictor variables that have been identified and are currently being used in <b>machine</b> <b>learning</b> models.", "dateLastCrawled": "2022-01-27T13:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Chapter 11 Bias and Fairness</b> | Big Data and Social Science", "url": "https://textbook.coleridgeinitiative.org/chap-bias.html", "isFamilyFriendly": true, "displayUrl": "https://textbook.coleridgeinitiative.org/chap-<b>bias</b>.html", "snippet": "Unfortunately, just as there is no single <b>machine</b> <b>learning</b> <b>algorithm</b> that is best suited to every application, no one fairness metric will fit every situation. However, we hope this chapter will provide you with a grounding in the available ways of measuring algorithmic fairness that will help you navigate the trade-offs involved putting these into practice in your own applications. 11.2 Sources of <b>Bias</b>. <b>Bias</b> may be introduced into a <b>machine</b> <b>learning</b> project at any step along the way and it ...", "dateLastCrawled": "2022-01-30T01:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Using <b>Machine</b> <b>Learning</b> to Compare Provaccine and Antivaccine Discourse ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8277307/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8277307", "snippet": "Second, we developed a <b>machine</b> <b>learning</b> (ML)-based automatic classifier of pro- and antivaccine posts and unsupervised clustering for extracting discursive topics. This set of ML algorithms will aid future researchers in assessing the effectiveness of public health campaigns on social media and hence facilitate the successful development of future interventions. Lastly, we conducted a multistep content analysis that combines interpretive (inductive) with objective (deductive) coding to ...", "dateLastCrawled": "2021-09-03T12:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Propensity score adjustment using <b>machine</b> <b>learning</b> classification ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0231500", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0231500", "snippet": "Propensity estimation with the Random Forest <b>algorithm</b> is only advantageous in terms of <b>bias</b> removal in the estimations for Party 3, in which case the Random Forests <b>algorithm</b> achieves the highest <b>bias</b> reduction of all the classifiers reviewed. This is an important finding, as this missing data mechanism is particularly troublesome and, moreover, is commonly encountered in real data. The results for the MSE estimators under PSA with Random Forests show that this value may be only half that ...", "dateLastCrawled": "2021-05-29T12:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "linkedin-skill-assessments-quizzes/<b>machine</b>-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/.../blob/master/<b>machine</b>-<b>learning</b>/<b>machine</b>-<b>learning</b>-quiz.md", "snippet": "Higher K values lower the variance but increase the <b>bias</b>. Q33. Your <b>machine</b> <b>learning</b> system is attempting to describe a hidden structure from unlabeled data. How would you describe this <b>machine</b> <b>learning</b> method? supervised <b>learning</b>; unsupervised <b>learning</b>; reinforcement <b>learning</b>; semi-unsupervised <b>learning</b>; Q34. You work for a large credit card processing company that wants to create targeted promotions for its customers. The data science team created a <b>machine</b> <b>learning</b> system that groups ...", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Interventions | <b>Machine Learning Bias Mitigation</b>", "url": "https://cdeiuk.github.io/bias-mitigation/interventions/", "isFamilyFriendly": true, "displayUrl": "https://cdeiuk.github.io/<b>bias</b>-mitigation/interventions", "snippet": "Furthermore, as noted above, the decision threshold modification <b>algorithm</b> of Hardt et al. is optimal among post-processing algorithms for equalised odds and equal opportunity, which means we <b>can</b>&#39;t expect better performance from this intervention. That said, since the intervention of Hardt et al. introduces some stochasticity to predictions, if that is unacceptable then this might be a viable alternative.", "dateLastCrawled": "2022-02-02T02:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Racist in <b>the Machine: The Disturbing Implications of Algorithmic Bias</b>", "url": "https://www.researchgate.net/publication/312080801_Racist_in_the_Machine_The_Disturbing_Implications_of_Algorithmic_Bias", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/312080801_Racist_in_the_<b>Machine</b>_The...", "snippet": "Another example of <b>machine</b> <b>learning</b> <b>bias</b> relates to word embedding, as algorithms are trained using text, they may exhibit gender stereotyping (Bolukbasi, Chang, Zou, Saligrama, and Kalai, 2016 ...", "dateLastCrawled": "2022-01-21T19:45:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning Techniques for Group Technology Applications</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0007850607627450", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0007850607627450", "snippet": "Based on the relative roles of teacher and learner, <b>learning</b> can be classified as 1131: <b>learning</b> by rote, <b>learning</b> by instruction, <b>learning</b> by <b>analogy</b>, <b>learning</b> from examples, <b>learning</b> from observation and discovery. The laat two kinds require inductive <b>learning</b> which is the process of acquiring new knowledge by making inductive inferences from facts provided by a teacher or environment. For a typical inductive <b>learning</b> problem, the givens are (1) a set of observational statements that ...", "dateLastCrawled": "2022-01-19T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) A Conceptual Framework for Investigating and Mitigating <b>Machine</b> ...", "url": "https://www.researchgate.net/publication/353587790_A_Conceptual_Framework_for_Investigating_and_Mitigating_Machine_Learning_Measurement_Bias_MLMB_in_Psychological_Assessment", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353587790_A_Conceptual_Framework_for...", "snippet": "Given significant concerns about fairness and <b>bias</b> in the use of artificial intelligence (AI) and <b>machine</b> <b>learning</b> (ML) for assessing psychological constructs, we provide a conceptual framework ...", "dateLastCrawled": "2021-12-15T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Gentle Introduction to <b>Machine Learning</b> Concepts | by Robbie Allen ...", "url": "https://medium.com/machine-learning-in-practice/a-gentle-introduction-to-machine-learning-concepts-cfe710910eb", "isFamilyFriendly": true, "displayUrl": "https://medium.com/<b>machine-learning</b>-in-practice/a-gentle-introduction-to-<b>machine</b>...", "snippet": "<b>Machine learning</b> doesn\u2019t just happen in the ether. All that computation has to take place somewhere. Whether you do your calculations on-site or in the cloud, <b>machine learning</b> is a physical ...", "dateLastCrawled": "2022-02-03T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Multi-Dimensional Gender <b>Bias</b> Classification | DeepAI", "url": "https://deepai.org/publication/multi-dimensional-gender-bias-classification", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/multi-dimensional-gender-<b>bias</b>-classification", "snippet": "Multi-Dimensional Gender <b>Bias</b> Classification. 05/01/2020 \u2219 by Emily Dinan, et al. \u2219 0 \u2219 share. <b>Machine</b> <b>learning</b> models are trained to find patterns in data. NLP models can inadvertently learn socially undesirable patterns when training on gender biased text. In this work, we propose a general framework that decomposes gender <b>bias</b> in text ...", "dateLastCrawled": "2021-12-15T17:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Bow-tie signaling in c-di-GMP: <b>Machine</b> <b>learning</b> in a simple biochemical ...", "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005677", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005677", "snippet": "The <b>analogy</b> between c-di-GMP signaling and a <b>machine</b> <b>learning</b> classifier explains that weak selection favors generalist bacteria; generalists integrate environmental stimuli and decide between biofilm and swarming according to the environmental fluctuations experienced in their evolutionary history. Evolution in strong selection, on the other hand, favors specialists. This is similar to how small data sets tend to produce biased classifiers.", "dateLastCrawled": "2019-11-12T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Recommendation System Series Part 7: The 3 Variants of Boltzmann ...", "url": "https://towardsdatascience.com/recsys-series-part-7-the-3-variants-of-boltzmann-machines-for-collaborative-filtering-4c002af258f9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/recsys-series-part-7-the-3-variants-of-boltzmann...", "snippet": "The <b>learning</b> algorithm is intuitive: They subtracted the sleep phase correlation from the wake <b>learning</b> phase and then adjusted the weights accordingly. With a big enough dataset, this algorithm can effectively learn arbitrary mappings between input and output. The Boltzmann <b>machine</b> <b>analogy</b> turns out to be a good insight into what\u2019s happing in the human brain during sleep. In cognitive science, there\u2019s a concept called replay, where the hippocampus plays back our memories and experiences ...", "dateLastCrawled": "2022-01-31T08:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The human factor: Working with machines to make big decisions", "url": "https://images.forbes.com/forbesinsights/StudyPDFs/PwC-The_Human_Factor-REPORT.pdf", "isFamilyFriendly": true, "displayUrl": "https://images.forbes.com/forbesinsights/StudyPDFs/PwC-The_Human_Factor-REPORT.pdf", "snippet": "role of <b>machine</b> <b>learning</b> in the business world. \u201cArtificial intelligence can help people make faster, better, and cheaper decisions. For that to happen, first and foremost, you need an openness of mind to collaborate with the <b>machine</b>, as opposed to treating the technology as either a servant or an overlord.\u201d This balance of mind and machines is just taking hold as companies experiment. Executives say their internal cultures could be more data-driven, with a greater emphasis on data ...", "dateLastCrawled": "2022-01-29T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "Simply put, the goal of classification is to determine a plausible value for an unknown variable Y given an observed variable X.For example, we might try to predict whether a loan applicant will pay back her loan by looking at various characteristics such as credit history, income, and net worth. Classification also applies in situations where the variable Y does not refer to an event that lies in the future. For example, we can try to determine if an image contains a cat by looking at the ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Understanding Unconscious Bias - A Deeper</b> Dive | Webfor", "url": "https://webfor.com/blog/understanding-unconscious-bias-a-deeper-dive/", "isFamilyFriendly": true, "displayUrl": "https://webfor.com/blog/<b>understanding-unconscious-bias-a-deeper</b>-dive", "snippet": "There\u2019s the \u201c<b>in\u201d group</b> and \u201cout\u201d group. So what happens with a team <b>bias</b>, I often call it as if I\u2019m in a game and I\u2019m watching the Blazers play. If the other team does a foul against my team in basketball, I\u2019m going to be screaming and yelling like, \u201cHey call the foul,\u201d right? But on the other side of the floor, when our team fouls their team and possibly gets away with it, I\u2019m probably not going to be yelling and screaming that out because I have this association, this ...", "dateLastCrawled": "2021-12-31T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What does the word &#39;fit&#39; mean in <b>machine</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-does-the-word-fit-mean-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-does-the-word-fit-mean-in-<b>machine</b>-<b>learning</b>", "snippet": "Answer (1 of 3): \u201cFit\u201d is a term that belongs to the process of back propagation, where the desired outcome is pre-set and the AI is rewarded based on how close it comes to that outcome. What you want the AI to learn is called \u201cfit\u201d. For example, if an AI is trying to learn to play guitar, \u201cfit\u201d ...", "dateLastCrawled": "2022-01-26T08:00:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(in-group bias)  is like +(machine learning algorithm)", "+(in-group bias) is similar to +(machine learning algorithm)", "+(in-group bias) can be thought of as +(machine learning algorithm)", "+(in-group bias) can be compared to +(machine learning algorithm)", "machine learning +(in-group bias AND analogy)", "machine learning +(\"in-group bias is like\")", "machine learning +(\"in-group bias is similar\")", "machine learning +(\"just as in-group bias\")", "machine learning +(\"in-group bias can be thought of as\")", "machine learning +(\"in-group bias can be compared to\")"]}