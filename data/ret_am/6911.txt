{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "<b>Learning</b> Curves in <b>Machine Learning</b>. Generally, a <b>learning</b> <b>curve</b> is a plot that shows time or experience on the x-axis and <b>learning</b> or improvement on the y-axis. <b>Learning</b> curves (LCs) are deemed effective tools for monitoring the performance of workers exposed to a new task. LCs provide a mathematical representation of the <b>learning</b> process that takes place as task repetition occurs. \u2014 <b>Learning</b> <b>curve</b> models and applications: Literature review and research directions, 2011. For example, if ...", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to interpret \u201c<b>loss</b>\u201d and \u201c<b>accuracy</b>\u201d for <b>a machine</b> <b>learning</b> model ...", "url": "https://intellipaat.com/community/368/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/community/368/how-to-interpret-<b>loss</b>-and-<b>accuracy</b>-for-<b>a-machine</b>...", "snippet": "A <b>loss</b> function is used to optimize <b>a machine</b> <b>learning</b> <b>algorithm</b>. The <b>loss</b> is calculated on training and validation and its interpretation is based on how <b>well</b> the model <b>is doing</b> in these two sets. It is the sum of errors made for each example in training or validation sets. <b>Loss</b> value implies how poorly or <b>well</b> a model behaves after each iteration of optimization. An <b>accuracy</b> metric is used to measure the <b>algorithm</b>\u2019s performance in an interpretable way. The <b>accuracy</b> of a model is usually ...", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Tutorial: <b>Learning Curves for Machine Learning</b> in Python", "url": "https://www.dataquest.io/blog/learning-curves-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.dataquest.io/blog/<b>learning</b>-<b>curves</b>-<b>machine</b>-<b>learning</b>", "snippet": "If you\u2019re new to <b>machine</b> <b>learning</b> and have never tried scikit, a good place to start is this blog post. We begin with a brief introduction to bias and variance. The bias-variance trade-off. In supervised <b>learning</b>, we assume there\u2019s a real relationship between feature(s) and target and estimate this unknown relationship with a model. Provided the assumption is true, there really is a model, which we\u2019ll call \\(f\\), which describes perfectly the relationship between features and target ...", "dateLastCrawled": "2022-02-02T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Introduction to <b>Loss</b> Functions - Algorithmia Blog", "url": "https://www.algorithmia.com/blog/introduction-to-loss-functions", "isFamilyFriendly": true, "displayUrl": "https://www.<b>algorithm</b>ia.com/blog/introduction-to-<b>loss</b>-functions", "snippet": "Introduction to <b>loss</b> functions. The <b>loss function</b> is the bread and butter of modern <b>machine</b> <b>learning</b>; it takes your <b>algorithm</b> from theoretical to practical and transforms neural networks from glorified matrix multiplication into deep <b>learning</b>.. This post will explain the role of <b>loss</b> functions and how they work, while surveying a few of the most popular from the past decade.", "dateLastCrawled": "2022-02-03T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to interpret <b>loss</b> and accuracy for <b>a machine</b> <b>learning</b> model", "url": "https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34518656", "snippet": "The <b>loss</b> is calculated on training and validation and its interperation is how <b>well</b> the model <b>is doing</b> for these two sets. Unlike accuracy, <b>loss</b> is not a percentage. It is a summation of the errors made for each example in training or validation sets. In the case of neural networks, the <b>loss</b> is usually negative log-likelihood and residual sum of squares for classification and regression respectively. Then naturally, the main objective in a <b>learning</b> model is to reduce (minimize) the <b>loss</b> ...", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Scikit-<b>Plot: Visualizing Machine Learning Algorithm Results</b> ...", "url": "https://coderzcolumn.com/tutorials/machine-learning/scikit-plot-visualizing-machine-learning-algorithm-results-and-performance", "isFamilyFriendly": true, "displayUrl": "https://coderzcolumn.com/tutorials/<b>machine</b>-<b>learning</b>/scikit-plot-visualizing-<b>machine</b>...", "snippet": "Once we are done with training <b>machine</b> <b>learning</b> algorithms, we need the right way to visualize results as <b>well</b> as the performance of the <b>algorithm</b>. We need to visualize various metrics to understand results better and hence performance of the <b>algorithm</b>. Matplotlib is a very commonly used data visualization library for plotting results of ML algorithms. But plotting with matplotlib requires a quite a <b>learning</b> <b>curve</b> to plot ML algorithms results. Also, one minor mistake when implementing ...", "dateLastCrawled": "2022-02-02T20:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Optimization in <b>Machine Learning</b> \u2014 Part 1 | by Abhishek Chatterjee ...", "url": "https://medium.com/swlh/optimization-in-machine-learning-part-1-e9da1aa1eedf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/optimization-in-<b>machine-learning</b>-part-1-e9da1aa1eedf", "snippet": "Optimization in <b>Machine Learning</b> is one of the most important steps and possibly the hardest to learn also. The optimizer is a function that optimizes <b>Machine Learning</b> models using training data\u2026", "dateLastCrawled": "2022-02-02T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Getting out of <b>Loss Plateaus by adjusting Learning Rates</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2020/02/26/getting-out-of-loss-plateaus-by-adjusting-learning-rates/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machinecurve</b>.com/.../getting-out-of-<b>loss-plateaus-by-adjusting-learning-rates</b>", "snippet": "Now, if they are the output of a function, it may be the case that we can compute the derivative of that function as <b>well</b>. And by consequence, we can compute the gradient for that particular \\((x, y)\\) position too, a.k.a. the direction and speed of change at that point.. Saddle points are points in your <b>loss</b> landscape where the gradient is zero, but which are no extremum (Wikipedia, 2004). That is, the gradient is zero but they don\u2019t represent minima or maxima.", "dateLastCrawled": "2022-02-02T04:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "ML | Underfitting and Overfitting - GeeksforGeeks", "url": "https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/<b>underfitting-and-overfitting-in-machine-learning</b>", "snippet": "Let us consider that we are designing <b>a machine</b> <b>learning</b> model. A model is said to be a good <b>machine</b> <b>learning</b> model if it generalizes any new input data from the problem domain in a proper way. This helps us to make predictions in the future data, that the data model has never seen. Now, suppose we want to check how <b>well</b> our <b>machine</b> <b>learning</b> model learns and generalizes to the new data. For that, we have overfitting and underfitting, which are majorly responsible for the poor performances of ...", "dateLastCrawled": "2022-02-02T09:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Understanding <b>PPO</b> Plots in TensorBoard | by AurelianTactics ... - Medium", "url": "https://medium.com/aureliantactics/understanding-ppo-plots-in-tensorboard-cbc3199b9ba2", "isFamilyFriendly": true, "displayUrl": "https://medium.com/aureliantactics/understanding-<b>ppo</b>-plots-in-tensorboard-cbc3199b9ba2", "snippet": "Value <b>Loss</b> \u2014 The mean <b>loss</b> of the value function update. Correlates to how <b>well</b> the model is able to predict the value of each state. This should increase while the agent is <b>learning</b>, and then ...", "dateLastCrawled": "2022-02-02T14:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to interpret \u201c<b>loss</b>\u201d and \u201c<b>accuracy</b>\u201d for <b>a machine</b> <b>learning</b> model ...", "url": "https://intellipaat.com/community/368/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/community/368/how-to-interpret-<b>loss</b>-and-<b>accuracy</b>-for-<b>a-machine</b>...", "snippet": "A <b>loss</b> function is used to optimize <b>a machine</b> <b>learning</b> <b>algorithm</b>. The <b>loss</b> is calculated on training and validation and its interpretation is based on how <b>well</b> the model <b>is doing</b> in these two sets. It is the sum of errors made for each example in training or validation sets. <b>Loss</b> value implies how poorly or <b>well</b> a model behaves after each iteration of optimization. An <b>accuracy</b> metric is used to measure the <b>algorithm</b>\u2019s performance in an interpretable way. The <b>accuracy</b> of a model is usually ...", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "<b>Learning</b> Curves in <b>Machine Learning</b>. Generally, a <b>learning</b> <b>curve</b> is a plot that shows time or experience on the x-axis and <b>learning</b> or improvement on the y-axis. <b>Learning</b> curves (LCs) are deemed effective tools for monitoring the performance of workers exposed to a new task. LCs provide a mathematical representation of the <b>learning</b> process that takes place as task repetition occurs. \u2014 <b>Learning</b> <b>curve</b> models and applications: Literature review and research directions, 2011. For example, if ...", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Introduction to <b>Loss</b> Functions - Algorithmia Blog", "url": "https://www.algorithmia.com/blog/introduction-to-loss-functions", "isFamilyFriendly": true, "displayUrl": "https://www.<b>algorithm</b>ia.com/blog/introduction-to-<b>loss</b>-functions", "snippet": "Introduction to <b>loss</b> functions. The <b>loss function</b> is the bread and butter of modern <b>machine</b> <b>learning</b>; it takes your <b>algorithm</b> from theoretical to practical and transforms neural networks from glorified matrix multiplication into deep <b>learning</b>.. This post will explain the role of <b>loss</b> functions and how they work, while surveying a few of the most popular from the past decade.", "dateLastCrawled": "2022-02-03T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Loss</b> and <b>Loss</b> <b>Functions for Training Deep Learning Neural Networks</b>", "url": "https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>loss</b>-and-<b>loss</b>-<b>functions-for-training-deep-learning</b>...", "snippet": "A good division to consider is to use the <b>loss</b> to evaluate and diagnose how <b>well</b> the model is <b>learning</b>. This includes all of the considerations of the optimization process, such as overfitting, underfitting, and convergence. An alternate metric can then be chosen that has meaning to the project stakeholders to both evaluate model performance and perform model selection.", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "5. <b>Model Metrics</b> \u2014 <b>Machine</b> <b>Learning</b> 101 documentation", "url": "https://machinelearning101.readthedocs.io/en/latest/_pages/05_model_metrics.html", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>101.readthedocs.io/en/latest/_pages/05_<b>model_metrics</b>.html", "snippet": "5. <b>Model Metrics</b>\u00b6. Evaluating your <b>machine</b> <b>learning</b> <b>algorithm</b> is an essential. Your model may give you satisfying results when evaluated using a metric say accuracy_score but may give poor results when evaluated against other metrics such as logarithmic_<b>loss</b> or any other such metric. Most of the times we use classification accuracy to measure the performance of our model, however it is not enough to truly judge our model.", "dateLastCrawled": "2022-01-29T19:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b> | by Aditya Mishra ...", "url": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metrics-to-evaluate-your-<b>machine</b>-<b>learning</b>-<b>algorithm</b>-f10...", "snippet": "Evaluating your <b>machine</b> <b>learning</b> <b>algorithm</b> is an essential part of any project. Your model may give you satisfying results when evaluated using a metric say <b>accuracy</b>_score but may give poor results when evaluated against other metrics such as logarithmic_<b>loss</b> or any other such metric. Most of the times we use classification <b>accuracy</b> to measure ...", "dateLastCrawled": "2022-02-02T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Overfitting and Underfitting With <b>Machine</b> <b>Learning</b> Algorithms", "url": "https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/overfitting-and-", "snippet": "There is a terminology used in <b>machine</b> <b>learning</b> when we talk about how <b>well</b> <b>a machine</b> <b>learning</b> model learns and generalizes to new data, namely overfitting and underfitting. Overfitting and underfitting are the two biggest causes for poor performance of <b>machine</b> <b>learning</b> algorithms. Statistical Fit. In statistics, a fit refers to how <b>well</b> you approximate a target function. This is good terminology to use in <b>machine</b> <b>learning</b>, because supervised <b>machine</b> <b>learning</b> algorithms seek to approximate ...", "dateLastCrawled": "2022-02-02T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Analyzing my <b>weight loss</b> with <b>machine</b> <b>learning</b> | by Khanh Nguyen ...", "url": "https://towardsdatascience.com/analyzing-my-weight-loss-journey-with-machine-learning-b74aa2e170f2", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/analyzing-my-<b>weight-loss</b>-journey-with-<b>machine</b>-<b>learning</b>...", "snippet": "Another example of this is I now learn some of the scikit-learn models do not behave like I would expect them to: SGDClassifier(<b>loss</b>=\u2019log\u2019, penalty=\u2019l2&#39;, <b>learning</b>_rate=\u2019constant\u2019) does not seem to shrink the \u03b8 of the intercept, and gave <b>similar</b> \u03b8\u2019s to my model, while LogisticRegression(penalty=\u2019l2&#39;) shrinks the \u03b8 of intercept at the default setting, unless one fiddles with the intercept_scaling parameter. As a result, I will be more careful when using third-party libraries ...", "dateLastCrawled": "2022-01-30T16:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Curve Fitting With Python</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/curve-fitting-with-python/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>curve-fitting-with-python</b>", "snippet": "Unlike supervised <b>learning</b>, <b>curve</b> fitting requires that you define the function that maps examples of inputs to outputs. The mapping function, also called the basis function can have any form you like, including a straight line (linear regression), a curved line (polynomial regression), and much more. This provides the flexibility and control to define the form of the <b>curve</b>, where an optimization process is used to find the specific optimal parameters of the function. In this tutorial, you ...", "dateLastCrawled": "2022-02-02T23:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>A machine</b> <b>learning</b> framework for rapid forecasting and history matching ...", "url": "https://www.nature.com/articles/s41598-021-01023-w", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-01023-w", "snippet": "There are <b>graph</b>-based reduced-order models based on mapping a DFN <b>to graph</b> 46, and reduced DFNs themselves obtained by use of <b>graph</b>-theory or <b>machine</b>-<b>learning</b> or a combination of both 47.", "dateLastCrawled": "2022-02-02T11:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a plot of model <b>learning</b> performance over experience or time. <b>Learning</b> curves are a widely used diagnostic tool in <b>machine learning</b> for algorithms that learn from a training dataset incrementally. The model <b>can</b> be evaluated on the training dataset and on a hold out validation dataset after each update during training and plots of the measured performance", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to interpret <b>loss</b> and accuracy for <b>a machine</b> <b>learning</b> model", "url": "https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34518656", "snippet": "The <b>loss</b> is calculated on training and validation and its interperation is how <b>well</b> the model <b>is doing</b> for these two sets. Unlike accuracy, <b>loss</b> is not a percentage. It is a summation of the errors made for each example in training or validation sets. In the case of neural networks, the <b>loss</b> is usually negative log-likelihood and residual sum of squares for classification and regression respectively. Then naturally, the main objective in a <b>learning</b> model is to reduce (minimize) the <b>loss</b> ...", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> <b>Curve</b> Theory: Meaning, Formulas, Graphs", "url": "https://www.valamis.com/hub/learning-curve", "isFamilyFriendly": true, "displayUrl": "https://www.valamis.com/hub/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a correlation between a learner&#39;s performance on a task and the number of attempts or time required to complete the task; this <b>can</b> be represented as a direct proportion on a <b>graph</b>. The <b>learning</b> <b>curve</b> theory proposes that a learner\u2019s efficiency in a task improves over time the more the learner performs the task. Graphical ...", "dateLastCrawled": "2022-02-03T03:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Getting out of <b>Loss Plateaus by adjusting Learning Rates</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2020/02/26/getting-out-of-loss-plateaus-by-adjusting-learning-rates/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machinecurve</b>.com/.../getting-out-of-<b>loss-plateaus-by-adjusting-learning-rates</b>", "snippet": "Now, if they are the output of a function, it may be the case that we <b>can</b> compute the derivative of that function as <b>well</b>. And by consequence, we <b>can</b> compute the gradient for that particular \\((x, y)\\) position too, a.k.a. the direction and speed of change at that point.. Saddle points are points in your <b>loss</b> landscape where the gradient is zero, but which are no extremum (Wikipedia, 2004). That is, the gradient is zero but they don\u2019t represent minima or maxima.", "dateLastCrawled": "2022-02-02T04:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Build your first <b>Machine</b> <b>Learning</b> Model using <b>TensorFlow</b> | by Shadab ...", "url": "https://towardsdatascience.com/build-your-first-machine-learning-model-using-tensorflow-d61b9b2b7d5e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/build-your-first-<b>machine</b>-<b>learning</b>-model-using-tensor...", "snippet": "In <b>machine</b> <b>learning</b>, instead of writing the <b>algorithm</b> to solve a problem, we use a class of <b>learning</b> methodology (linear regression in this case study) and pass historical data to generate the <b>algorithm</b>, that <b>can</b> be verified and used later to solve the problem. What is your definition of <b>machine</b> <b>learning</b>? Share it in comments.", "dateLastCrawled": "2022-02-03T15:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How Does <b>Linear Regression</b> Actually Work? | by Anas Al-Masri | Towards ...", "url": "https://towardsdatascience.com/how-does-linear-regression-actually-work-3297021970dd", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-does-<b>linear-regression</b>-actually-work-3297021970dd", "snippet": "<b>Linear Regression</b> <b>can</b> be considered <b>a Machine</b> <b>Learning</b> <b>algorithm</b> that allows us to map numeric inputs to numeric outputs, fitting a line into the data points. In other words, <b>Linear Regression</b> is a way o f modelling the relationship between one or more variables. From the <b>Machine</b> <b>Learning</b> perspective, this is done to ensure generalization ...", "dateLastCrawled": "2022-02-03T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning</b> (Stanford) Coursera (Week 1, Quiz 2) for the github ...", "url": "https://gist.github.com/mGalarnyk/cc964bea99b09e3c733b339ad3b7b019", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/mGalarnyk/cc964bea99b09e3c733b339ad3b7b019", "snippet": "<b>Machine Learning</b> Week 1 Quiz 2 (Linear Regression with One Variable) Stanford Coursera. Github repo for the Course: Stanford <b>Machine Learning</b> (Coursera) Question 1. Consider the problem of predicting how <b>well</b> a student does in her second year of college/university, given how <b>well</b> she did in her first year.", "dateLastCrawled": "2022-02-02T18:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to create <b>an MLP classifier with TensorFlow 2 and</b> Keras \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2019/07/27/how-to-create-a-basic-mlp-classifier-with-the-keras-sequential-api/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machinecurve</b>.com/index.php/2019/07/27/how-to-create-a-basic-mlp-classifier...", "snippet": "Two main streams of <b>thought</b> emerged in the 1950s for making the cybernetic dreams a reality (Olazaran, 1996). The ... together compose a purple elephant (a.k.a. distribution). We next train <b>a machine</b> <b>learning</b> model that attempts to be as accurate as the original data; hence attempting to classify data as that purple elephant. How <b>well</b> the model is capable of <b>doing</b> that is what is called a <b>loss</b>, and the <b>loss</b> function allows one to compare one distribution (elephant) with the other (hopefully ...", "dateLastCrawled": "2022-01-30T20:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning for BCI</b> - NeurotechEDU", "url": "http://learn.neurotechedu.com/machinelearning/", "isFamilyFriendly": true, "displayUrl": "learn.neurotechedu.com/<b>machinelearning</b>", "snippet": "In general terms, SVM algorithms, just like other <b>machine</b> <b>learning</b> techniques, aim to define a <b>curve</b> capable of differentiating two distinct classes of data. In a higher dimensional space, this <b>curve</b> is called a hyperplane. In order to find the correct hyperplane, the <b>algorithm</b> goes through an optimization process where the number of misclassified instances (players, in the above example) are minimized. This process is what we call \u201ctraining the <b>algorithm</b>\u201d and we\u2019ll go over how to do ...", "dateLastCrawled": "2022-02-03T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>to plot accuracy and loss with mxnet</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2017/12/25/plot-accuracy-loss-mxnet/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2017/12/25/plot-accuracy-<b>loss</b>-mxnet", "snippet": "How <b>to plot accuracy and loss with mxnet</b>. In today\u2019s tutorial, we\u2019ll be plotting accuracy and <b>loss</b> using the mxnet library. The log file format changed slightly between mxnet v.0.11 and v0.12 so we\u2019ll be covering both versions here. In particular, we\u2019ll be plotting: Validation rank-1 accuracy. Validation rank-5 accuracy.", "dateLastCrawled": "2022-01-27T02:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a plot of model <b>learning</b> performance over experience or time. <b>Learning</b> curves are a widely used diagnostic tool in <b>machine learning</b> for algorithms that learn from a training dataset incrementally. The model <b>can</b> be evaluated on the training dataset and on a hold out validation dataset after each update during training and plots of the measured performance", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to interpret \u201c<b>loss</b>\u201d and \u201c<b>accuracy</b>\u201d for <b>a machine</b> <b>learning</b> model ...", "url": "https://intellipaat.com/community/368/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/community/368/how-to-interpret-<b>loss</b>-and-<b>accuracy</b>-for-<b>a-machine</b>...", "snippet": "A <b>loss</b> function is used to optimize <b>a machine</b> <b>learning</b> <b>algorithm</b>. The <b>loss</b> is calculated on training and validation and its interpretation is based on how <b>well</b> the model <b>is doing</b> in these two sets. It is the sum of errors made for each example in training or validation sets. <b>Loss</b> value implies how poorly or <b>well</b> a model behaves after each iteration of optimization. An <b>accuracy</b> metric is used to measure the <b>algorithm</b>\u2019s performance in an interpretable way. The <b>accuracy</b> of a model is usually ...", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Tutorial: <b>Learning Curves for Machine Learning</b> in Python", "url": "https://www.dataquest.io/blog/learning-curves-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.dataquest.io/blog/<b>learning</b>-<b>curves</b>-<b>machine</b>-<b>learning</b>", "snippet": "If you\u2019re new to <b>machine</b> <b>learning</b> and have never tried scikit, a good place to start is this blog post. We begin with a brief introduction to bias and variance. The bias-variance trade-off. In supervised <b>learning</b>, we assume there\u2019s a real relationship between feature(s) and target and estimate this unknown relationship with a model. Provided the assumption is true, there really is a model, which we\u2019ll call \\(f\\), which describes perfectly the relationship between features and target ...", "dateLastCrawled": "2022-02-02T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to interpret <b>loss</b> and accuracy for <b>a machine</b> <b>learning</b> model", "url": "https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34518656", "snippet": "The <b>loss</b> is calculated on training and validation and its interperation is how <b>well</b> the model <b>is doing</b> for these two sets. Unlike accuracy, <b>loss</b> is not a percentage. It is a summation of the errors made for each example in training or validation sets. In the case of neural networks, the <b>loss</b> is usually negative log-likelihood and residual sum of squares for classification and regression respectively. Then naturally, the main objective in a <b>learning</b> model is to reduce (minimize) the <b>loss</b> ...", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b> | by Aditya Mishra ...", "url": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metrics-to-evaluate-your-<b>machine</b>-<b>learning</b>-<b>algorithm</b>-f10...", "snippet": "Evaluating your <b>machine</b> <b>learning</b> <b>algorithm</b> is an essential part of any project. Your model may give you satisfying results when evaluated using a metric say <b>accuracy</b>_score but may give poor results when evaluated against other metrics such as logarithmic_<b>loss</b> or any other such metric. Most of the times we use classification <b>accuracy</b> to measure ...", "dateLastCrawled": "2022-02-02T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Data Visualization using Python for <b>Machine Learning</b> and Data science ...", "url": "https://towardsdatascience.com/data-visualization-for-machine-learning-and-data-science-a45178970be7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/data-visualization-for-<b>machine-learning</b>-and-data...", "snippet": "Data Visualization using Python for <b>Machine Learning</b> and Data science : ... we <b>can</b> see which two features <b>can</b> <b>well</b> explain/separate the data and then we <b>can</b> use scatter plot between those 2 features to explore further. From the above plot we <b>can</b> conclude like, Petal length and petal width are the 2 features which <b>can</b> separate the data very <b>well</b>. Since we will be getting n x n plots for n features, pairplot may become complex when we have more number of feature say like 10 or so on. So in ...", "dateLastCrawled": "2022-02-02T20:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning</b> <b>Curve</b> Theory: Meaning, Formulas, Graphs", "url": "https://www.valamis.com/hub/learning-curve", "isFamilyFriendly": true, "displayUrl": "https://www.valamis.com/hub/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a correlation between a learner&#39;s performance on a task and the number of attempts or time required to complete the task; this <b>can</b> be represented as a direct proportion on a <b>graph</b>. The <b>learning</b> <b>curve</b> theory proposes that a learner\u2019s efficiency in a task improves over time the more the learner performs the task. Graphical ...", "dateLastCrawled": "2022-02-03T03:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Learning for BCI</b> - NeurotechEDU", "url": "http://learn.neurotechedu.com/machinelearning/", "isFamilyFriendly": true, "displayUrl": "learn.neurotechedu.com/<b>machinelearning</b>", "snippet": "In general terms, SVM algorithms, just like other <b>machine</b> <b>learning</b> techniques, aim to define a <b>curve</b> capable of differentiating two distinct classes of data. In a higher dimensional space, this <b>curve</b> is called a hyperplane. In order to find the correct hyperplane, the <b>algorithm</b> goes through an optimization process where the number of misclassified instances (players, in the above example) are minimized. This process is what we call \u201ctraining the <b>algorithm</b>\u201d and we\u2019ll go over how to do ...", "dateLastCrawled": "2022-02-03T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Loss function figure explanation</b> : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/15to9t/loss_function_figure_explanation/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/15to9t/<b>loss_function_figure_explanation</b>", "snippet": "Hinge <b>loss</b> is the classical <b>loss</b> function for Suppor Vector Machines. Hinge <b>loss</b> with a margin of 0 is the <b>loss</b> of the (single layer) Perceptron <b>algorithm</b>. Note: the Perceptron <b>loss</b> (Hinge <b>loss</b> without margin) will not cause an update of the model parameters w whenever the input sample is correctly classified. This <b>can</b> make the model parameters ...", "dateLastCrawled": "2022-01-15T19:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>How to Normalize or Standardize a Dataset in Python</b>? \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2020/11/19/how-to-normalize-or-standardize-a-dataset-in-python/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machinecurve</b>.com/index.php/2020/11/19/<b>how-to-normalize-or-standardize</b>-a...", "snippet": "Code language: JSON / JSON with Comments (json) Applying the MinMaxScaler from Scikit-learn. Scikit-learn, the popular <b>machine</b> <b>learning</b> library used frequently for training many traditional <b>Machine</b> <b>Learning</b> algorithms provides a module called MinMaxScaler, and it is part of the sklearn.preprocessing API.. It allows us to fit a scaler with a predefined range to our dataset, and subsequently perform a transformation for the data.", "dateLastCrawled": "2022-02-03T12:56:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding the 3 most common <b>loss</b> functions for <b>Machine</b> <b>Learning</b> ...", "url": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-the-3-most-common-<b>loss</b>-functions-for...", "snippet": "A <b>loss function</b> in <b>Machine</b> <b>Learning</b> is a measure of how accurately your ML model is able to predict the expected outcome i.e the ground truth. The <b>loss function</b> will take two items as input: the output value of our model and the ground truth expected value. The output of the <b>loss function</b> is called the <b>loss</b> which is a measure of how well our model did at predicting the outcome. A high value for the <b>loss</b> means our model performed very poorly. A low value for the <b>loss</b> means our model performed ...", "dateLastCrawled": "2022-02-02T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "Introduction Evaluating your <b>machine learning</b> model is a crucial part of any project. Your model may give satisfactory results when evaluated using metrics such as accuracy but may perform poorly when evaluated against other metrics such as <b>loss</b> or F1 score. In most cases, we use accuracy to measure the model performance, however, it is not enough to truly judge our model. Thus, let\u2019s take a look at different <b>evaluation metrics</b> available. Confusion Matrix Confusion Matrix is a performance ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Evaluating a <b>Machine</b> <b>Learning</b> Model: Regression and Classification ...", "url": "https://arnavbansal-8232.medium.com/evaluating-a-machine-learning-model-regression-and-classification-metrics-4f2316e180b4", "isFamilyFriendly": true, "displayUrl": "https://arnavbansal-8232.medium.com/evaluating-a-<b>machine</b>-<b>learning</b>-model-regression-and...", "snippet": "<b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> plays a vital role in all this. ... This <b>analogy</b> is true only when we have balanced data, meaning the number of rows for each class should be the same. Contradicting this <b>analogy</b> one can say that for a binary classification algorithm if we have 100 samples, where 90 denote one class, and the remaining 10 samples denote another class. In that case our <b>analogy</b> fails. (here, we can easily get 90% accuracy by just giving all samples to first class, which seems ...", "dateLastCrawled": "2022-01-05T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Learning to Teach with Dynamic Loss Functions</b>", "url": "https://proceedings.neurips.cc/paper/2018/file/8051a3c40561002834e59d566b7430cf-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2018/file/8051a3c40561002834e59d566b7430cf-Paper.pdf", "snippet": "<b>loss</b> function of a <b>machine</b> <b>learning</b> model (we call it student) is de\ufb01ned by another <b>machine</b> <b>learning</b> model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end, similar to human teaching, the teacher, a parametric model, dynamically outputs different <b>loss</b> functions that will be used and optimized by its student model at different training stages. We develop an ef\ufb01cient <b>learning</b> ...", "dateLastCrawled": "2022-01-26T01:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>learning</b> fundamentals (I): Cost functions and gradient descent ...", "url": "https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-fundamentals-via-linear-regression-41a...", "snippet": "In this post I\u2019ll use a simple linear regression model to explain two <b>machine</b> <b>learning</b> (ML) fundamentals; (1) cost functions and; (2) gradient descent. The linear regression isn\u2019t the most powerful model in the ML tool kit, but due to its familiarity and interpretability, it is still in widespread use in research and industry. Simply, linear regression is used to estimate linear relationships between continuous or/and categorical data and a continuous output variable \u2014 you can see an ...", "dateLastCrawled": "2022-01-30T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Measuring model loss</b> | <b>Machine</b> <b>Learning</b> for Finance", "url": "https://subscription.packtpub.com/book/data/9781789136364/1/ch01lvl1sec21/measuring-model-loss", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/.../9781789136364/1/ch01lvl1sec21/<b>measuring-model-loss</b>", "snippet": "In <b>machine</b> <b>learning</b>, a <b>loss</b> function measures how bad the model performs. A high <b>loss</b> function goes hand in hand with low accuracy, whereas if the function is low, then the model is doing well. In this case, our issue is a binary classification problem. Because of that, we will be using the binary cross-entropy <b>loss</b>, as we can see in the ...", "dateLastCrawled": "2021-12-21T06:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "PREDICTION OF RESEARCH TOPICS USING COMBINATION OF <b>MACHINE</b> <b>LEARNING</b> AND ...", "url": "http://www.jatit.org/volumes/Vol49No3/14Vol49No3.pdf", "isFamilyFriendly": true, "displayUrl": "www.jatit.org/volumes/Vol49No3/14Vol49No3.pdf", "snippet": "Extreme <b>Learning</b> <b>Machine</b> and Support Vector <b>Machine</b>. The prediction result is then finally refined by logistic <b>curve</b>. The dataset used in this study is a research report on Bioinformatics from Microsoft Research and NCBI (National Center for Biotechnology Information), over the past 30 years. Experimental result indicates that the combination of <b>machine</b> <b>learning</b> approaches and logistic-<b>curve</b> may improve the prediction accuracy. In addition, the emerging topic of the same dataset can be ...", "dateLastCrawled": "2021-11-21T16:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Has anyone experience val <b>loss</b> curves like this? : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/s2h03q/has_anyone_experience_val_loss_curves_like_this/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/s2h03q/has_anyone_experience...", "snippet": "\ud83c\udfc3 Although a relatively simple optimization algorithm, gradient descent (and its variants) has found an irreplaceable place in the heart of <b>machine</b> <b>learning</b>. This is majorly due to the fact that it has shown itself to be quite handy when optimizing deep neural networks and other models. The models behind the latest advances in ML and computer vision are majorly optimized using gradient descent and its variants like Adam and gradient descent with momentum.", "dateLastCrawled": "2022-01-13T05:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "B. <b>Analogy</b> C. Deduction D. Memorization Answer : A Explanation: Different <b>learning</b> methods does not include the introduction. 8. The model will be trained with data in one single batch is known as ? A. Batch <b>learning</b> B. Offline <b>learning</b> C. Both A and B D. None of the above Ans : C Explanation: we have end-to-end <b>Machine</b> <b>Learning</b> systems in which we need to train the model in one go by using whole available training data. Such kind of <b>learning</b> method or algorithm is called Batch or Offline ...", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "deep <b>learning</b> - How can both generator and discriminator losses ...", "url": "https://datascience.stackexchange.com/questions/32699/how-can-both-generator-and-discriminator-losses-decrease", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/32699", "snippet": "In the subsection of the figure, they compute the average <b>loss</b> across 100 iterations, which is why the <b>loss</b> is monotonically decreasing because on average the <b>loss</b> does decrease with the training. You are correct in inferring that if this was reported on an iteration to iteration basis, the <b>loss</b> would be a zig zag <b>curve</b>, which is less nice to look at than a smooth <b>curve</b>.", "dateLastCrawled": "2022-01-28T20:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "PINN deep <b>learning</b> method for the Chen\u2013Lee\u2013Liu equation: Rogue wave on ...", "url": "https://www.sciencedirect.com/science/article/pii/S1007570421003798", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1007570421003798", "snippet": "<b>Machine</b> <b>learning</b> with the neural network method ... Interestingly, from Fig. 5(d), we can observe that the <b>loss curve is like</b> \u201cstair\u201d, which does not exist in that one of periodic wave solution. 4.3. The data-driven soliton wave solution. As shown in Ref. , the expression (59) of Ref. will be the bright soliton solution with taking a = c = 1, \u03b2 = 0. 5, and be the dark soliton solution with taking a = c = 1, \u03b2 = \u2212 0. 5. Let [x 0, x 1] and [t 0, t 1] in Eq. as [\u2212 6. 0, 6. 0] and [\u2212 ...", "dateLastCrawled": "2022-01-17T00:12:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(loss curve)  is like +(graph of how well a machine learning algorithm is doing)", "+(loss curve) is similar to +(graph of how well a machine learning algorithm is doing)", "+(loss curve) can be thought of as +(graph of how well a machine learning algorithm is doing)", "+(loss curve) can be compared to +(graph of how well a machine learning algorithm is doing)", "machine learning +(loss curve AND analogy)", "machine learning +(\"loss curve is like\")", "machine learning +(\"loss curve is similar\")", "machine learning +(\"just as loss curve\")", "machine learning +(\"loss curve can be thought of as\")", "machine learning +(\"loss curve can be compared to\")"]}