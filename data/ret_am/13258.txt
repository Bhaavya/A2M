{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Overview of different Optimizers for neural networks</b> | by Renu ...", "url": "https://medium.datadriveninvestor.com/overview-of-different-optimizers-for-neural-networks-e0ed119440c3", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/<b>overview-of-different-optimizers-for-neural</b>...", "snippet": "Nesterov acceleration <b>optimization</b> <b>is like</b> a <b>ball</b> <b>rolling</b> down the hill but knows exactly when to slow down before the gradient of the hill increases again. We calculate the gradient not with respect to the current step but with respect to the future step. We evaluate the gradient of the looked ahead and based on the importance then update the ...", "dateLastCrawled": "2022-02-02T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Guide To Optimizers For Machine Learning</b>", "url": "https://analyticsindiamag.com/guide-to-optimizers-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/<b>guide-to-optimizers-for-machine-learning</b>", "snippet": "As gradient descent is comparable with finding a valley, momentum can be compared to a <b>ball</b> <b>rolling</b> <b>downhill</b>. Momentum helps us to accelerate Gradient Descent(GD) when we have surfaces that curve more steeply in one direction than in another direction. It also moistens the oscillation as shown below. For updating the weights it takes the gradient of the current step as well as the gradient of the previous time steps. Momentum speeds up gradient descent by converging faster.", "dateLastCrawled": "2022-01-31T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The art of VaR optimisation | The Actuary", "url": "https://www.theactuary.com/features/2013/06/2013/06/07/art-var-optimisation", "isFamilyFriendly": true, "displayUrl": "https://www.theactuary.com/features/2013/06/2013/06/07/art-var-optimisation", "snippet": "An intuitive way of thinking about a numerical optimisation algorithm <b>is like</b> a <b>ball</b> that is <b>rolling</b> slowly <b>downhill</b>. If the <b>ball</b> gets stuck in a local hollow it can stay there, and so not get to the bottom of the hill. That is what can happen with VaR optimisation too: the numerical optimisers can get stuck in local optima <b>like</b> the one above, and never actually find the global optimum. This will correspond to a suboptimal strategy. The sharp edges here can also confuse the algorithm, so ...", "dateLastCrawled": "2021-12-12T13:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Gradient Descent With Nesterov Momentum From Scratch</b>", "url": "https://machinelearningmastery.com/gradient-descent-with-nesterov-momentum-from-scratch/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>gradient-descent-with-nesterov-momentum-from-scratch</b>", "snippet": "We can think of momentum in terms of a <b>ball</b> <b>rolling</b> <b>downhill</b> that will accelerate and continue to go in the same direction even in the presence of small hills. Momentum can be interpreted as a <b>ball</b> <b>rolling</b> down a nearly horizontal incline. The <b>ball</b> naturally gathers momentum as gravity causes it to accelerate, just as the gradient causes momentum to accumulate in this descent method. \u2014 Page 75, Algorithms for <b>Optimization</b>, 2019. A problem with momentum is that acceleration can sometimes ...", "dateLastCrawled": "2022-01-29T04:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "An overview of gradient descent <b>optimization</b> algorithms", "url": "https://ruder.io/optimizing-gradient-descent/", "isFamilyFriendly": true, "displayUrl": "https://ruder.io/optimizing-gradient-descent", "snippet": "However, a <b>ball</b> that rolls down a hill, blindly following the slope, is highly unsatisfactory. We&#39;d <b>like</b> to have a smarter <b>ball</b>, a <b>ball</b> that has a notion of where it is going so that it knows to slow down before the hill slopes up again. Nesterov accelerated gradient (NAG) is a way to give our momentum term this kind of prescience. We know that we will use our momentum term \\(\\gamma v_{t-1}\\) to move the parameters \\(\\theta\\). Computing \\( \\theta - \\gamma v_{t-1} \\) thus gives us an ...", "dateLastCrawled": "2022-02-02T21:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Optimisation in Deep Learning - GitHub Pages", "url": "https://hansen7.github.io/notesDL/Optimiser_in_DL.pdf", "isFamilyFriendly": true, "displayUrl": "https://hansen7.github.io/notesDL/Optimiser_in_DL.pdf", "snippet": "\\Zigzag would not happen for a heavy <b>ball</b> <b>rolling</b> <b>downhill</b>&quot; !use previous gradients! Hanchen Wang (hw501@cam.ac.uk) Optimisation in DL Sep 2020 5/24. Momentum with a Zigzag Example Momentum: between consequent steps: @f=@y o sets, @f=@x accumulates Back to the zigzag example: Hanchen Wang (hw501@cam.ac.uk) Optimisation in DL Sep 2020 6/24. Momentum with a Zigzag Example Momentum + Nesterov Acceleration (use previous locations): Hanchen Wang (hw501@cam.ac.uk) Optimisation in DL Sep 2020 7/24 ...", "dateLastCrawled": "2021-12-04T21:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "ELI5: the significance of convexity in <b>optimization</b> : explainlikeimfive", "url": "https://www.reddit.com/r/explainlikeimfive/comments/920mqg/eli5_the_significance_of_convexity_in_optimization/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/explain<b>like</b>imfive/comments/920mqg/eli5_the_significance_of...", "snippet": "Searching tells me a lot about what <b>convex</b> <b>optimization</b> is, but not why convexity is important or significant. ... Now the easiest way of doing this is the so called &quot;gradient descent&quot;, which is just a fancy word for &quot;<b>rolling</b> <b>downhill</b>&quot;: We just take a random point somewhere on the bowl, calculate which direction is going <b>downhill</b>, and move a bit in that direction. This will eventually lead us to the center of the bowl. This works very well, until we get a bowl <b>like</b> this, which isn&#39;t entirely ...", "dateLastCrawled": "2021-11-19T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "An <b>overview of gradient descent optimization algorithms</b>", "url": "https://opendatascience.com/an-overview-of-gradient-descent-optimization-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://opendatascience.com/an-<b>overview-of-gradient-descent-optimization-algorithms</b>", "snippet": "The <b>ball</b> accumulates momentum as it rolls <b>downhill</b>, becoming faster and faster on the way (until it reaches its terminal velocity if there is air resistance, i.e. (gamma &lt; 1)). The same thing happens to our parameter updates: The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain faster convergence and reduced oscillation.", "dateLastCrawled": "2022-01-31T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "An <b>overview of gradient descent optimization algorithms</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1609.04747/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1609.04747", "snippet": "The <b>ball</b> accumulates momentum as it rolls <b>downhill</b>, becoming faster and faster on the way (until it reaches its terminal velocity, if there is air resistance, i.e. \u03b3 &lt; 1). The same thing happens to our parameter updates: The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain faster convergence and reduced oscillation.", "dateLastCrawled": "2022-01-26T04:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "17 Gradient Descent Interview Questions Every Data Analyst And ML ...", "url": "https://www.mlstack.cafe/blog/gradient-descent-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.mlstack.cafe/blog/gradient-descent-interview-questions", "snippet": "Gradient descent is an <b>optimization</b> algorithm that\u2019s used when training a machine learning model and is based on a <b>convex</b> function and tweaks its parameters iteratively to minimize a given function to its local minimum (that is, slope = 0). For a start, we have to select a random bias and weights, and then iterate over the slope function to get a slope of 0. The way we change update the value of the bias and weights is through a variable called the learning rate. We have to be wise on the ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Guide To Optimizers For Machine Learning</b>", "url": "https://analyticsindiamag.com/guide-to-optimizers-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/<b>guide-to-optimizers-for-machine-learning</b>", "snippet": "As gradient descent is comparable with finding a valley, momentum can be compared to a <b>ball</b> <b>rolling</b> <b>downhill</b>. Momentum helps us to accelerate Gradient Descent(GD) when we have surfaces that curve more steeply in one direction than in another direction. It also moistens the oscillation as shown below. For updating the weights it takes the gradient of the current step as well as the gradient of the previous time steps. Momentum speeds up gradient descent by converging faster.", "dateLastCrawled": "2022-01-31T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "An overview of gradient descent <b>optimization</b> algorithms", "url": "https://ruder.io/optimizing-gradient-descent/", "isFamilyFriendly": true, "displayUrl": "https://ruder.io/optimizing-gradient-descent", "snippet": "The <b>ball</b> accumulates momentum as it rolls <b>downhill</b>, becoming faster and faster on the way (until it reaches its terminal velocity if there is air resistance, i.e. \\(\\gamma &lt; 1\\)). The same thing happens to our parameter updates: The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain faster convergence and reduced oscillation.", "dateLastCrawled": "2022-02-02T21:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Optimisation in Deep Learning - GitHub Pages", "url": "https://hansen7.github.io/notesDL/Optimiser_in_DL.pdf", "isFamilyFriendly": true, "displayUrl": "https://hansen7.github.io/notesDL/Optimiser_in_DL.pdf", "snippet": "\\Zigzag would not happen for a heavy <b>ball</b> <b>rolling</b> <b>downhill</b>&quot; !use previous gradients! Hanchen Wang (hw501@cam.ac.uk) Optimisation in DL Sep 2020 5/24. Momentum with a Zigzag Example Momentum: between consequent steps: @f=@y o sets, @f=@x accumulates Back to the zigzag example: Hanchen Wang (hw501@cam.ac.uk) Optimisation in DL Sep 2020 6/24. Momentum with a Zigzag Example Momentum + Nesterov Acceleration (use previous locations): Hanchen Wang (hw501@cam.ac.uk) Optimisation in DL Sep 2020 7/24 ...", "dateLastCrawled": "2021-12-04T21:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>02_optimization-algorithms</b> | SnailDove&#39;s blog", "url": "https://snaildove.github.io/2018/03/02/02_optimization-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://snaildove.github.io/2018/03/02/<b>02_optimization-algorithms</b>", "snippet": "Now, your little <b>ball</b> can roll <b>downhill</b> and gain momentum, but it can accelerate down this bowl and therefore gain momentum. I find that this <b>ball</b> <b>rolling</b> down a bowl analogy, it seems to work for some people who enjoy physics intuitions. But it doesn\u2019t work for everyone, so if this analogy of a <b>ball</b> <b>rolling</b> down the bowl doesn\u2019t work for you, don\u2019t worry about it.", "dateLastCrawled": "2022-01-19T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The art of VaR optimisation | The Actuary", "url": "https://www.theactuary.com/features/2013/06/2013/06/07/art-var-optimisation", "isFamilyFriendly": true, "displayUrl": "https://www.theactuary.com/features/2013/06/2013/06/07/art-var-optimisation", "snippet": "An intuitive way of thinking about a numerical optimisation algorithm is like a <b>ball</b> that is <b>rolling</b> slowly <b>downhill</b>. If the <b>ball</b> gets stuck in a local hollow it can stay there, and so not get to the bottom of the hill. That is what can happen with VaR optimisation too: the numerical optimisers can get stuck in local optima like the one above, and never actually find the global optimum. This will correspond to a suboptimal strategy. The sharp edges here can also confuse the algorithm, so ...", "dateLastCrawled": "2021-12-12T13:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "An <b>overview of gradient descent optimization algorithms</b>", "url": "https://opendatascience.com/an-overview-of-gradient-descent-optimization-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://opendatascience.com/an-<b>overview-of-gradient-descent-optimization-algorithms</b>", "snippet": "The momentum term (gamma) is usually set to 0.9 or a <b>similar</b> value. Essentially, when using momentum, we push a <b>ball</b> down a hill. The <b>ball</b> accumulates momentum as it rolls <b>downhill</b>, becoming faster and faster on the way (until it reaches its terminal velocity if there is air resistance, i.e. (gamma &lt; 1)). The same thing happens to our parameter ...", "dateLastCrawled": "2022-01-31T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "An <b>overview of gradient descent optimization algorithms</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1609.04747/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1609.04747", "snippet": "The <b>ball</b> accumulates momentum as it rolls <b>downhill</b>, becoming faster and faster on the way (until it reaches its terminal velocity, if there is air resistance, i.e. \u03b3 &lt; 1). The same thing happens to our parameter updates: The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain faster convergence and reduced oscillation.", "dateLastCrawled": "2022-01-26T04:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "17 Gradient Descent Interview Questions Every Data Analyst And ML ...", "url": "https://www.mlstack.cafe/blog/gradient-descent-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.mlstack.cafe/blog/gradient-descent-interview-questions", "snippet": "Gradient descent is an <b>optimization</b> algorithm that\u2019s used when training a machine learning model and is based on a <b>convex</b> function and tweaks its parameters iteratively to minimize a given function to its local minimum (that is, slope = 0).. For a start, we have to select a random bias and weights, and then iterate over the slope function to get a slope of 0.", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "An overview of gradient descent <b>optimization</b> algorithms \u2013 L\u00e3o Trang", "url": "https://vantinhkhuc.wordpress.com/2017/05/15/an-overview-of-gradient-descent-optimization-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://vantinhkhuc.wordpress.com/2017/05/15/an-overview-of-gradient-descent...", "snippet": "By Sebastian Ruder | 04/27/2017 Note: If you are looking for a review paper, this blog post is also available as an article on arXiv. Table of contents: Gradient descent variants Batch gradient descent Stochastic gradient descent Mini-batch gradient descent Challenges Gradient descent <b>optimization</b> algorithms Momentum Nesterov accelerated gradient Adagrad Adadelta RMSprop Adam Visualization of\u2026", "dateLastCrawled": "2021-12-30T09:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why evolutionary algorithms can guarantee better performance than the ...", "url": "https://www.quora.com/Why-evolutionary-algorithms-can-guarantee-better-performance-than-the-traditional-deterministic-optimization-approaches-in-complicated-optimization-tasks", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-evolutionary-algorithms-can-guarantee-better-performance...", "snippet": "Answer (1 of 2): You\u2019re wrong. Evolutionary methods guarantee nothing! If you actually want to find an optimal solution mathematical optimisation tools are the ones that will give it to you. Why settle for an output that you do not know how good it is?? Modern branch-cut-and-bound methods utilis...", "dateLastCrawled": "2022-01-13T04:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Introduction to Stochastic Gradient Descent</b> - Great Learning", "url": "https://www.mygreatlearning.com/blog/introduction-to-stochastic-gradient-descent/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreatlearning.com/blog/<b>introduction-to-stochastic-gradient-descent</b>", "snippet": "Gradient Descent <b>can</b> be associated with the <b>ball</b> <b>rolling</b> down from a valley and the lowest point is the steepest descent, learning rate (\u03f5) consider it as the steps taken by the <b>ball</b> to reach the lowest point of the valley. For example, let\u2019s consider the below function as the cost function: Step by step approach: Start with an initial assumed parameter \ud83e\udc6a assumed value=(x); = learning rate; For the value (x), you calculate the output of the differentiated function which we denote as f ...", "dateLastCrawled": "2022-02-03T00:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Gradient Descent With Nesterov Momentum From Scratch</b>", "url": "https://machinelearningmastery.com/gradient-descent-with-nesterov-momentum-from-scratch/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>gradient-descent-with-nesterov-momentum-from-scratch</b>", "snippet": "We <b>can</b> think of momentum in terms of a <b>ball</b> <b>rolling</b> <b>downhill</b> that will accelerate and continue to go in the same direction even in the presence of small hills. Momentum <b>can</b> be interpreted as a <b>ball</b> <b>rolling</b> down a nearly horizontal incline. The <b>ball</b> naturally gathers momentum as gravity causes it to accelerate, just as the gradient causes momentum to accumulate in this descent method. \u2014 Page 75, Algorithms for <b>Optimization</b>, 2019. A problem with momentum is that acceleration <b>can</b> sometimes ...", "dateLastCrawled": "2022-01-29T04:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Introduction to Stochastic Gradient Descent \u2013 Thankful AI", "url": "https://thankfulai.com/introduction-to-stochastic-gradient-descent/", "isFamilyFriendly": true, "displayUrl": "https://thankfulai.com/introduction-to-stochastic-gradient-descent", "snippet": "Gradient Descent <b>can</b> be associated with the <b>ball</b> <b>rolling</b> down from a valley and the lowest point is the steepest descent, learning rate (\u03f5) consider it as the steps taken by the <b>ball</b> to reach the lowest point of the valley. For example, let\u2019s consider the below function as the cost function: Step by step approach: Start with an initial assumed parameter assumed value=(x); = learning rate; For the value (x), you calculate the output of the differentiated function which we denote as f\u2019(x ...", "dateLastCrawled": "2021-10-06T21:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>An Overview on Optimization Algorithms in Deep Learning</b> 1", "url": "https://prinsphield.github.io/posts/2016/02/overview_opt_alg_deep_learning1/", "isFamilyFriendly": true, "displayUrl": "https://prinsphield.github.io/posts/2016/02/overview_opt_alg_deep_learning1", "snippet": "<b>An Overview on Optimization Algorithms in Deep Learning</b> 1. 4 minute read. Published : February 04, 2016. Recently, I have been learning about <b>optimization algorithms in deep learning</b>. And it is necessary, I think, to sum them up, so I plan to write a series of articles about different kinds of these algorithms. This article will mainly talk about the basic <b>optimization</b> algorithms used in machine learning and deep learning. Gradient Descent. Gradient descent is the most basic gradient-based ...", "dateLastCrawled": "2021-12-29T03:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>The ground of optimization</b> - LessWrong 2.0 viewer", "url": "https://www.greaterwrong.com/posts/znfkdCoHMANwqc2WE/the-ground-of-optimization-1", "isFamilyFriendly": true, "displayUrl": "https://www.greaterwrong.com/posts/znfkdCoHMANwqc2WE/<b>the-ground-of-optimization</b>-1", "snippet": "For example, we could introduce a barrier that prevents the <b>ball</b> from <b>rolling</b> <b>downhill</b> past a certain point, and we <b>can</b> then expect a sufficiently intelligent robot to move the <b>ball</b> over the barrier. We <b>can</b> expect a sufficiently well-designed robot to be able to overcome a wide variety of hurdles that gravity would not overcome on its own. Therefore we say that this system is more robust than the system without the robot. There is a sequence of systems spanning the gap between a <b>ball</b> <b>rolling</b> ...", "dateLastCrawled": "2021-12-28T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>The ground of optimization</b> - AI Alignment Forum", "url": "https://www.alignmentforum.org/posts/znfkdCoHMANwqc2WE/the-ground-of-optimization-1", "isFamilyFriendly": true, "displayUrl": "https://www.alignmentforum.org/posts/znfkdCoHMANwqc2WE/<b>the-ground-of-optimization</b>-1", "snippet": "For example, we could introduce a barrier that prevents the <b>ball</b> from <b>rolling</b> <b>downhill</b> past a certain point, and we <b>can</b> then expect a sufficiently intelligent robot to move the <b>ball</b> over the barrier. We <b>can</b> expect a sufficiently well-designed robot to be able to overcome a wide variety of hurdles that gravity would not overcome on its own. Therefore we say that this system is more robust than the system without the robot. There is a sequence of systems spanning the gap between a <b>ball</b> <b>rolling</b> ...", "dateLastCrawled": "2022-02-02T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A novel meta-heuristic algorithm for solving numerical <b>optimization</b> ...", "url": "https://link.springer.com/article/10.1007/s00521-021-06392-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-021-06392-x", "snippet": "For <b>optimization</b> problems, the search space <b>can</b> be easily plotted in the Cartesian coordinate system and its shapes <b>can</b> then be observed. Having a large number of decision variables is the first challenge when addressing <b>optimization</b> problems. The limitation of the search space is the range of variables, which is diversified. These variables <b>can</b> be discrete or continuous. This means that they either create a discrete or a continuous search space. In the first case, there is a finite set of ...", "dateLastCrawled": "2022-01-30T01:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Diwekar - Introduction to Applied Optimization</b> | suparna gharpure ...", "url": "https://www.academia.edu/6907208/Diwekar_Introduction_to_Applied_Optimization", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/6907208/<b>Diwekar_Introduction_to_Applied_Optimization</b>", "snippet": "<b>Diwekar - Introduction to Applied Optimization</b>. Suparna Gharpure. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 32 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package ...", "dateLastCrawled": "2022-02-03T02:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Case Studies In Trajectory <b>Optimization</b>: Trains, Planes, And ...", "url": "https://www.researchgate.net/publication/2801869_Case_Studies_In_Trajectory_Optimization_Trains_Planes_And_Other_Pastimes", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/2801869_Case_Studies_In_Trajectory...", "snippet": "K e y wor ds and phrases. trajectory <b>optimization</b>, optimal control, constrained <b>optimization</b>. Research supported by NSF grant DMS-9870317, ONR grant N00014-98-1-0036. 1", "dateLastCrawled": "2022-01-27T02:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why evolutionary algorithms <b>can</b> guarantee better performance than the ...", "url": "https://www.quora.com/Why-evolutionary-algorithms-can-guarantee-better-performance-than-the-traditional-deterministic-optimization-approaches-in-complicated-optimization-tasks", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-evolutionary-algorithms-<b>can</b>-guarantee-better-performance...", "snippet": "Answer (1 of 2): You\u2019re wrong. Evolutionary methods guarantee nothing! If you actually want to find an optimal solution mathematical optimisation tools are the ones that will give it to you. Why settle for an output that you do not know how good it is?? Modern branch-cut-and-bound methods utilis...", "dateLastCrawled": "2022-01-13T04:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Guide To Optimizers For Machine Learning</b>", "url": "https://analyticsindiamag.com/guide-to-optimizers-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/<b>guide-to-optimizers-for-machine-learning</b>", "snippet": "As gradient descent is comparable with finding a valley, momentum <b>can</b> <b>be compared</b> to a <b>ball</b> <b>rolling</b> <b>downhill</b>. Momentum helps us to accelerate Gradient Descent(GD) when we have surfaces that curve more steeply in one direction than in another direction. It also moistens the oscillation as shown below. For updating the weights it takes the gradient of the current step as well as the gradient of the previous time steps. Momentum speeds up gradient descent by converging faster.", "dateLastCrawled": "2022-01-31T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "An overview of gradient descent <b>optimization</b> algorithms", "url": "https://ruder.io/optimizing-gradient-descent/", "isFamilyFriendly": true, "displayUrl": "https://ruder.io/optimizing-gradient-descent", "snippet": "The authors provide an example for a simple <b>convex</b> <b>optimization</b> problem where the same behaviour <b>can</b> be observed for Adam. To fix this behaviour, the authors propose a new algorithm, AMSGrad that uses the maximum of past squared gradients \\(v_t\\) rather than the exponential average to update the parameters. \\(v_t\\) is defined the same as in Adam above: \\(v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\) Instead of using \\(v_t\\) (or its bias-corrected version \\(\\hat{v}_t\\)) directly, we now ...", "dateLastCrawled": "2022-02-02T21:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Overview of different Optimizers for neural networks</b> | by Renu ...", "url": "https://medium.datadriveninvestor.com/overview-of-different-optimizers-for-neural-networks-e0ed119440c3", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/<b>overview-of-different-optimizers-for-neural</b>...", "snippet": "Nesterov acceleration <b>optimization</b> is like a <b>ball</b> <b>rolling</b> down the hill but knows exactly when to slow down before the gradient of the hill increases again. We calculate the gradient not with respect to the current step but with respect to the future step. We evaluate the gradient of the looked ahead and based on the importance then update the ...", "dateLastCrawled": "2022-02-02T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>02_optimization-algorithms</b> | SnailDove&#39;s blog", "url": "https://snaildove.github.io/2018/03/02/02_optimization-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://snaildove.github.io/2018/03/02/<b>02_optimization-algorithms</b>", "snippet": "Now, your little <b>ball</b> <b>can</b> roll <b>downhill</b> and gain momentum, but it <b>can</b> accelerate down this bowl and therefore gain momentum. I find that this <b>ball</b> <b>rolling</b> down a bowl analogy, it seems to work for some people who enjoy physics intuitions. But it doesn\u2019t work for everyone, so if this analogy of a <b>ball</b> <b>rolling</b> down the bowl doesn\u2019t work for you, don\u2019t worry about it.", "dateLastCrawled": "2022-01-19T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "17 Gradient Descent Interview Questions Every Data Analyst And ML ...", "url": "https://www.mlstack.cafe/blog/gradient-descent-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.mlstack.cafe/blog/gradient-descent-interview-questions", "snippet": "These two methods <b>can</b> be imagined as a <b>ball</b> in parameter space. This is how these balls behave: Instead of <b>rolling</b> like normal balls, they jump between points in parameter space. Let \u03b8 t \\theta_t \u03b8 t be a <b>ball</b>&#39;s t-th location in parameter space, and let v t v_t v t be the <b>ball</b>&#39;s t-th jump.", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Sebastian Ruder: An overview of gradient descent <b>optimization</b> ...", "url": "https://klmlinks.wordpress.com/2020/05/10/sebastian-ruder-an-overview-of-gradient-descent-optimization-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://klmlinks.wordpress.com/2020/05/10/sebastian-ruder-an-overview-of-gradient...", "snippet": "<b>optimization</b> An overview of gradient descent <b>optimization</b> algorithms. Gradient descent is the preferred way to optimize neural networks and many other machine learning algorithms but is often used as a black box. This post explores how many of the most popular gradient-based <b>optimization</b> algorithms such as Momentum, Adagrad, and Adam actually work.", "dateLastCrawled": "2021-10-06T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>The ground of optimization</b> - LessWrong 2.0 viewer", "url": "https://www.greaterwrong.com/posts/znfkdCoHMANwqc2WE/the-ground-of-optimization-1", "isFamilyFriendly": true, "displayUrl": "https://www.greaterwrong.com/posts/znfkdCoHMANwqc2WE/<b>the-ground-of-optimization</b>-1", "snippet": "For example, we could introduce a barrier that prevents the <b>ball</b> from <b>rolling</b> <b>downhill</b> past a certain point, and we <b>can</b> then expect a sufficiently intelligent robot to move the <b>ball</b> over the barrier. We <b>can</b> expect a sufficiently well-designed robot to be able to overcome a wide variety of hurdles that gravity would not overcome on its own. Therefore we say that this system is more robust than the system without the robot. There is a sequence of systems spanning the gap between a <b>ball</b> <b>rolling</b> ...", "dateLastCrawled": "2021-12-28T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "An overview of gradient descent <b>optimization</b> algorithms \u2013 L\u00e3o Trang", "url": "https://vantinhkhuc.wordpress.com/2017/05/15/an-overview-of-gradient-descent-optimization-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://vantinhkhuc.wordpress.com/2017/05/15/an-overview-of-gradient-descent...", "snippet": "By Sebastian Ruder | 04/27/2017 Note: If you are looking for a review paper, this blog post is also available as an article on arXiv. Table of contents: Gradient descent variants Batch gradient descent Stochastic gradient descent Mini-batch gradient descent Challenges Gradient descent <b>optimization</b> algorithms Momentum Nesterov accelerated gradient Adagrad Adadelta RMSprop Adam Visualization of\u2026", "dateLastCrawled": "2021-12-30T09:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is <b>gradient descent guaranteed to converge? - Quora</b>", "url": "https://www.quora.com/Is-gradient-descent-guaranteed-to-converge", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-<b>gradient-descent-guaranteed-to-converge</b>", "snippet": "Answer (1 of 2): In contrast to the claim by the previous answer by Obaidullah Rahman, theoretical results until now show that Backtracking Gradient Descent is the best theoretically guaranteed method among all known iterative methods (including Newton\u2019s method). For example, convergence for Bac...", "dateLastCrawled": "2022-01-25T09:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A novel meta-heuristic algorithm for solving numerical <b>optimization</b> ...", "url": "https://link.springer.com/article/10.1007/s00521-021-06392-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-021-06392-x", "snippet": "For <b>optimization</b> problems, the search space <b>can</b> be easily plotted in the Cartesian coordinate system and its shapes <b>can</b> then be observed. Having a large number of decision variables is the first challenge when addressing <b>optimization</b> problems. The limitation of the search space is the range of variables, which is diversified. These variables <b>can</b> be discrete or continuous. This means that they either create a discrete or a continuous search space. In the first case, there is a finite set of ...", "dateLastCrawled": "2022-01-30T01:29:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Optimization</b> for <b>Machine</b> <b>Learning</b>", "url": "http://optml.mit.edu/talks/pkuLectAlgo3.pdf", "isFamilyFriendly": true, "displayUrl": "optml.mit.edu/talks/pkuLectAlgo3.pdf", "snippet": "<b>Optimization</b> for <b>Machine</b> <b>Learning</b> \u2013 Sra, Nowozin, Wright Theory of <b>Convex</b> <b>Optimization</b> for <b>Machine</b> <b>Learning</b> \u2013 Bubeck NIPS 2016 <b>Optimization</b> Tutorial \u2013 Bach, Sra Some related courses: EE227A, Spring 2013, (Sra, UC Berkeley) 10-801, Spring 2014 (Sra, CMU) EE364a,b (Boyd, Stanford) EE236b,c (Vandenberghe, UCLA) Venues: NIPS, ICML, UAI, AISTATS, SIOPT, Math. Prog. Suvrit Sra(suvrit@mit.edu)<b>Optimization</b> for <b>Machine</b> <b>Learning</b> 2 / 29. Lecture Plan \u2013Introduction (3 lectures) \u2013Problems and ...", "dateLastCrawled": "2021-08-29T23:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "For example combinatorial <b>optimization</b>, <b>convex</b> <b>optimization</b>, constrained <b>optimization</b>. All <b>machine learning</b> algorithms are combinations of these three components. A framework for understanding all algorithms. Types of <b>Learning</b> . There are four types of <b>machine learning</b>: Supervised <b>learning</b>: (also called inductive <b>learning</b>) Training data includes desired outputs. This is spam this is not, <b>learning</b> is supervised. Unsupervised <b>learning</b>: Training data does not include desired outputs. Example is ...", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "<b>Optimization</b> methods are applied to minimize the loss function by changing the parameter values, which is the central theme of <b>machine</b> <b>learning</b>.Zero-one loss is L0-1 = 1 (m &lt;= 0); in zero-one loss, value of loss is 0 for m &gt;= 0 whereas 1 for m &lt; 0. The difficult part with this loss is it is not differentiable, non-<b>convex</b>, and also NP-hard. Hence, in order to make <b>optimization</b> feasible and solvable, these losses are replaced by different surrogate losses for different problems.", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "11.2. <b>Convexity</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_optimization/convexity.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_<b>optimization</b>/<b>convexity</b>.html", "snippet": "Furthermore, even though the <b>optimization</b> problems in deep <b>learning</b> are generally nonconvex, they often exhibit some properties of <b>convex</b> ones near local minima. This can lead to exciting new <b>optimization</b> variants such as [Izmailov et al., 2018].", "dateLastCrawled": "2022-01-30T21:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Optimization</b> for deep <b>learning</b>: an overview", "url": "https://www.ise.ncsu.edu/fuzzy-neural/wp-content/uploads/sites/9/2022/01/Optimization-for-deep-learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ise.ncsu.edu/.../uploads/sites/9/2022/01/<b>Optimization</b>-for-deep-<b>learning</b>.pdf", "snippet": "timization problems beyond <b>convex</b> problems. A somewhat related <b>analogy</b> is the development of conic <b>optimization</b>: in 1990\u2019s, researchers realized that many seemingly non-<b>convex</b> problems can actually be reformulated as conic <b>optimization</b> problems (e.g. semi-de nite programming) which are <b>convex</b> problems, thus the boundary of tractability has advanced signi cantly. Neural network problems are surely not the worst non-<b>convex</b> <b>optimization</b> problems and their global optima could be found ...", "dateLastCrawled": "2022-01-19T03:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Regularization : What? Why? and How? (Part -1) | by Siddhant Rai ...", "url": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "isFamilyFriendly": true, "displayUrl": "https://medium.com/m<b>learning</b>-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "snippet": "In general <b>machine</b> <b>learning</b> sense, it is solving an objective function to perform maximum or minimum evaluation. In reality, <b>optimization</b> is lot more profound in usage. Then we have two terms ...", "dateLastCrawled": "2022-01-28T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Gradient</b> Descent: A Quick, Simple Introduction | Built In", "url": "https://builtin.com/data-science/gradient-descent", "isFamilyFriendly": true, "displayUrl": "https://builtin.com/data-science/<b>gradient</b>-descent", "snippet": "<b>Gradient</b> descent is an <b>optimization</b> algorithm that&#39;s used when training a <b>machine</b> <b>learning</b> model. It&#39;s based on a <b>convex</b> function and tweaks its parameters iteratively to minimize a given function to its local minimum.", "dateLastCrawled": "2022-02-02T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Summary of Thesis: <b>Non-convex Optimization for Machine Learning</b>: Design ...", "url": "https://ai.stanford.edu/~tengyuma/slides/summary.pdf", "isFamilyFriendly": true, "displayUrl": "https://ai.stanford.edu/~tengyuma/slides/summary.pdf", "snippet": "Summary of Thesis: <b>Non-convex Optimization for Machine Learning</b>: Design, Analysis, and Understanding Tengyu Ma October 15, 2018 Non-<b>convex</b> <b>optimization</b> is ubiquitous in modern <b>machine</b> <b>learning</b>: re-cent breakthroughs in deep <b>learning</b> require optimizing non-<b>convex</b> training objective functions; problems that admit accurate <b>convex</b> relaxation can often be solved more e ciently with non-<b>convex</b> formulations. However, the theoretical understanding of non-<b>convex</b> <b>optimization</b> remained rather limited ...", "dateLastCrawled": "2021-09-02T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "7. <b>Optimization</b>, the central part of any <b>Machine</b> <b>Learning</b> algortithm ...", "url": "https://compphysics.github.io/MachineLearning/doc/LectureNotes/_build/html/chapteroptimization.html", "isFamilyFriendly": true, "displayUrl": "https://compphysics.github.io/<b>MachineLearning</b>/doc/LectureNotes/_build/html/chapter...", "snippet": "7. <b>Optimization</b>, the central part of any <b>Machine</b> <b>Learning</b> algortithm\u00b6. Almost every problem in <b>machine</b> <b>learning</b> and data science starts with a dataset \\(X\\), a model \\(g(\\beta)\\), which is a function of the parameters \\(\\beta\\) and a cost function \\(C(X, g(\\beta))\\) that allows us to judge how well the model \\(g(\\beta)\\) explains the observations \\(X\\).The model is fit by finding the values of \\(\\beta\\) that minimize the cost function. Ideally we would be able to solve for \\(\\beta ...", "dateLastCrawled": "2022-01-31T15:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[2005.14605] CoolMomentum: A Method for Stochastic <b>Optimization</b> by ...", "url": "https://arxiv.org/abs/2005.14605", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2005.14605", "snippet": "This <b>analogy</b> provides useful insights for non-<b>convex</b> stochastic <b>optimization</b> in <b>machine</b> <b>learning</b>. Here we find that integration of the discretized Langevin equation gives a coordinate updating rule equivalent to the famous Momentum <b>optimization</b> algorithm. As a main result, we show that a gradual decrease of the momentum coefficient from the initial value close to unity until zero is equivalent to application of Simulated Annealing or slow cooling, in physical terms. Making use of this novel ...", "dateLastCrawled": "2021-10-23T08:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Best <b>Artificial Intelligence</b> Course (AIML) by UT Austin", "url": "https://www.mygreatlearning.com/pg-program-artificial-intelligence-course", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/pg-program-<b>artificial-intelligence</b>-course", "snippet": "<b>Machine</b> <b>Learning</b>: <b>Machine</b> <b>learning</b> is a sub-branch of AI that teaches machines to learn any task without the help of explicit directions. It teaches machines to learn by drawing inferences from past experience. <b>Machine</b> <b>learning</b> primarily focuses on developing computer programs that can access and analyze data to identify patterns and understand data behaviour to reach possible conclusions without any kind of human intervention.", "dateLastCrawled": "2022-02-01T17:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Which <b>machine</b> <b>learning</b> algorithms for classification support online ...", "url": "https://www.quora.com/Which-machine-learning-algorithms-for-classification-support-online-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Which-<b>machine</b>-<b>learning</b>-algorithms-for-classification-support...", "snippet": "Answer (1 of 5): Most algorithms can be adapted to make them online, even though the standard implementations may not support it. E.g. both decision trees and support ...", "dateLastCrawled": "2022-01-09T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>the relationship between Online Machine Learning</b> and ...", "url": "https://www.quora.com/What-is-the-relationship-between-Online-Machine-Learning-and-Incremental-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-relationship-between-Online-Machine-Learning</b>-and...", "snippet": "Answer (1 of 4): Online <b>learning</b> usually refers to the case where each example is only used once (e.g. if you&#39;re updating an ad click prediction model online after each impression or click), while incremental methods usually pick one example at a time from a finite dataset and can process the sam...", "dateLastCrawled": "2022-01-14T06:00:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "SimplifiedMachineLearningWorkflows-book/Wolfram-Technology-Conference ...", "url": "https://github.com/antononcube/SimplifiedMachineLearningWorkflows-book/blob/master/Data/Wolfram-Technology-Conference-2016-to-2019-abstracts.csv", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/antononcube/Simplified<b>MachineLearning</b>Workflows-book/blob/master/...", "snippet": "Finally, I use <b>machine</b> <b>learning</b> algorithms to train a series of classifiers that can predict a text&#39;s authorship based on its MFW frequencies. Cross-validation indicates that Gallus and Monk are very likely one and the same author. The results also reveal the especially high and hitherto underexplored effectiveness of the Bray Curtis Distance measure and of logistic regression in shedding light on questions of authorship attribution. Data Analytics &amp; Information Science : 2016.Gunnar.Prei\u00df ...", "dateLastCrawled": "2021-12-28T12:42:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(convex optimization)  is like +(ball rolling downhill)", "+(convex optimization) is similar to +(ball rolling downhill)", "+(convex optimization) can be thought of as +(ball rolling downhill)", "+(convex optimization) can be compared to +(ball rolling downhill)", "machine learning +(convex optimization AND analogy)", "machine learning +(\"convex optimization is like\")", "machine learning +(\"convex optimization is similar\")", "machine learning +(\"just as convex optimization\")", "machine learning +(\"convex optimization can be thought of as\")", "machine learning +(\"convex optimization can be compared to\")"]}