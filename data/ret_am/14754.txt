{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Editing <b>Like</b> Humans: A Contextual, <b>Multimodal</b> Framework for Automated ...", "url": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Koorathota_Editing_Like_Humans_A_Contextual_Multimodal_Framework_for_Automated_Video_CVPRW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Koorathota_Editing_<b>Like</b>...", "snippet": "\u2022 evaluate our <b>model</b> through <b>human</b> judgements of CMVE- and <b>human</b> professionally-edited videos in participants recruited on Amazon MTurk. 2. Related Work 2.1. <b>Multimodal</b> Reasoning Whilepastworkusedthespatial-temporalrelationofob-jects in video for retrieval, allowing discrimination power about different video criteria [30], recent research related to <b>multimodal</b> video retrieval has focused on improving natu-ral language descriptors [23] or extracting key events from videos [31, 12 ...", "dateLastCrawled": "2022-01-29T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Premise-based Multimodal Reasoning: A Human</b>-<b>like</b> Cognitive Process | DeepAI", "url": "https://deepai.org/publication/premise-based-multimodal-reasoning-a-human-like-cognitive-process", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>premise-based-multimodal-reasoning-a-human</b>-<b>like</b>...", "snippet": "<b>Premise-based Multimodal Reasoning: A Human</b>-<b>like</b> Cognitive Process. 05/15/2021 \u2219 by Qingxiu Dong, et al. \u2219 0 \u2219 share . Reasoning is one of the major challenges of <b>Human</b>-<b>like</b> AI and has recently attracted intensive attention from natural language processing (NLP) researchers. However, cross-modal reasoning needs further research.", "dateLastCrawled": "2021-12-14T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Combating <b>Human</b> Trafcking with Deep <b>Multimodal</b> Models", "url": "https://aclanthology.org/P17-1142.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/P17-1142.pdf", "snippet": "deep <b>multimodal</b> <b>model</b> called the <b>Human</b> Trafcking Deep Network (HTDN). 1 Introduction <b>Human</b> trafcking a crime that shames us all (UNODC,2008),hasseenasteepriseintheUnited States since 2012. The number of cases reported rose from 3,279 in 2012 to 7,572 in 2016 more than doubling over the course of v e years (Hot-line ...", "dateLastCrawled": "2022-01-29T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is <b>multimodal</b> system of AI and its evolution", "url": "https://analyticsindiamag.com/what-is-the-multimodal-system-of-ai-and-its-evolution/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/what-is-the-<b>multimodal</b>-system-of-ai-and-its-evolution", "snippet": "What is <b>multimodal</b> interaction? As <b>human</b> beings, we experience the world as <b>multimodal</b>: we can feel texture, hear sounds, see objects, smell odours and taste flavours. However, standard AI systems are usually unimodal, meaning they are trained to do a specific task such as processing images or languages. The systems are fed a single sample of training data, from which they are able to identify corresponding images or words. While it is easier to work with a single source of information, it ...", "dateLastCrawled": "2022-01-30T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Multimodal</b> models are fast becoming a reality -- consequences be damned ...", "url": "https://venturebeat.com/2021/12/21/multimodal-models-are-fast-becoming-a-reality-consequences-be-damned/", "isFamilyFriendly": true, "displayUrl": "https://<b>venturebeat.com</b>/2021/12/21/<b>multimodal</b>-<b>models</b>-are-fast-becoming-a-reality...", "snippet": "Some hurdles have yet to be overcome, <b>like</b> <b>model</b> bias. But already, <b>multimodal</b> models have been applied to real-world applications including hate speech detection. Promising new directions. Humans ...", "dateLastCrawled": "2022-01-30T18:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Multimodal</b> AI Modeling is the Future, But It&#39;s Also Pandora&#39;s Box ...", "url": "https://www.extremetech.com/extreme/330247-multimodal-ai-modeling-is-the-futurebut-its-also-pandoras-box", "isFamilyFriendly": true, "displayUrl": "https://<b>www.extremetech.com</b>/extreme/330247-<b>multimodal</b>-ai-<b>model</b>ing-is-the-futurebut-its...", "snippet": "The discipline of building or teaching a neural net to have this kind of multifaced awareness is called <b>multimodal</b> modeling. Tools <b>like</b> DALL-E are designed to generate images based on text ...", "dateLastCrawled": "2022-02-03T14:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The Virtual <b>Human</b> as a <b>Multimodal</b> Interface", "url": "http://ivizlab.sfu.ca/arya/Papers/ACM/Virtual%20Human%20as%20a%20Multimodal%20Interface.pdf", "isFamilyFriendly": true, "displayUrl": "ivizlab.sfu.ca/arya/Papers/ACM/Virtual <b>Human</b> as a <b>Multimodal</b> Interface.pdf", "snippet": "the bones using primitives <b>like</b> ellipsoids or more generally kinds of implicit surfaces, called in the jargon of computer graphics, metaballs, blobs or soft objects. The skin or body shape is generated from the inner structure. One way of doing this is to cut the metaballs into cross sections and generate the skin from these sections. Figure 2 shows the principle. Figure 2. Modeling <b>human</b> body: skeleton, metaballs, metaballs with wireframe skin, rendered skin and clothes For creating face ...", "dateLastCrawled": "2021-10-20T16:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is <b>Multimodal</b>? \u2013 Center for Academic Success - University of ...", "url": "https://www.uis.edu/cas/thelearninghub/writing/handouts/rhetorical-concepts/what-is-multimodal/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.uis.edu</b>/.../writing/handouts/rhetorical-concepts/what-is-<b>multimodal</b>", "snippet": "<b>Like</b> a well-designed advertisement, all elements of your project should work together to create one cohesive message. Compositions can contain visual, motion, audio, and textual elements. Some traits under these elements will be emphasized to stress importance while others will be deemphasized. Your choices regarding how these elements and traits are used will be crucial\u2014there is a large difference between choosing a background color because it \u201clooks cool\u201d and picking a background ...", "dateLastCrawled": "2022-01-31T09:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Quantum-<b>Like</b> <b>multimodal</b> network framework for modeling interaction ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "snippet": "In this paper, we design a quantum-<b>like</b> <b>multimodal</b> network (QMN) framework, which leverages the mathematical formalism of quantum theory (QT) and a long short-term memory (LSTM) network, to <b>model</b> both intra- and inter-utterance interaction dynamics and recognize speakers\u2019 emotions. The main idea is to use a density matrix-based CNN, a quantum measurement-inspired strong-weak influence <b>model</b> and a quantum interference-inspired <b>multimodal</b> decision fusion approach. The experimental results on ...", "dateLastCrawled": "2022-01-24T13:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>multi-modal</b> parcellation of <b>human</b> cerebral cortex | <b>Nature</b>", "url": "https://www.nature.com/articles/nature18933", "isFamilyFriendly": true, "displayUrl": "https://www.<b>nature</b>.com/articles/<b>nature</b>18933", "snippet": "Understanding the amazingly complex <b>human</b> cerebral cortex requires a map (or parcellation) of its major subdivisions, known as cortical areas. Making an accurate areal map has been a century-old ...", "dateLastCrawled": "2022-01-27T17:31:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Multimodal</b> models are fast becoming a reality -- consequences be damned ...", "url": "https://venturebeat.com/2021/12/21/multimodal-models-are-fast-becoming-a-reality-consequences-be-damned/", "isFamilyFriendly": true, "displayUrl": "https://<b>venturebeat.com</b>/2021/12/21/<b>multimodal</b>-<b>models</b>-are-fast-becoming-a-reality...", "snippet": "In a paper published by Stanford\u2019s Institute for <b>Human</b>-Centered Artificial Intelligence (HAI), the coauthors argue that advances in <b>multimodal</b> models like DALL-E will result in higher-quality ...", "dateLastCrawled": "2022-01-30T18:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Multimodal Explanations: Justifying Decisions and Pointing</b> to the Evidence", "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Park_Multimodal_Explanations_Justifying_CVPR_2018_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Park_<b>Multimodal</b>_Explanations...", "snippet": "Explaining decisions is an integral part of <b>human</b> com-munication, understanding, and learning, and humans nat- urally provide both deictic (pointing) and textual modali-ties in a typical explanation. We aim to build deep learn-ing models that also are able to explain their decisions with <b>similar</b> \ufb02uency in both visual and textual modalities. Previ-ous machine learning methods for explanation were able to provide a text-only explanation conditioned on an image in context of a task, or were ...", "dateLastCrawled": "2022-01-25T21:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Combating <b>Human</b> Trafcking with Deep <b>Multimodal</b> Models", "url": "https://aclanthology.org/P17-1142.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/P17-1142.pdf", "snippet": "deep <b>multimodal</b> <b>model</b> called the <b>Human</b> Trafcking Deep Network (HTDN). 1 Introduction <b>Human</b> trafcking a crime that shames us all (UNODC,2008),hasseenasteepriseintheUnited States since 2012. The number of cases reported rose from 3,279 in 2012 to 7,572 in 2016 more than doubling over the course of v e years (Hot-line ...", "dateLastCrawled": "2022-01-29T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretable Multimodal Routing for Human Multimodal Language</b> | DeepAI", "url": "https://deepai.org/publication/interpretable-multimodal-routing-for-human-multimodal-language", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>interpretable-multimodal-routing-for-human-multimodal</b>...", "snippet": "The <b>human</b> <b>multimodal</b> language contains <b>multimodal</b> cues, including textual (e.g., spoken or written words), visual (e.g., body gestures), and acoustic (e.g., voice tones) modalities. It acts as a medium for <b>human</b> communication and has been advanced in areas spanning affect recognition Busso et al. (2008), media description Lin et al. (2014), event recognition Alam et al. (2018), and multimedia information retrieval Abu-El-Haija et al. (2016). Modeling <b>multimodal</b> sources takes into account the ...", "dateLastCrawled": "2021-12-29T00:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "MODEC: <b>Multimodal</b> Decomposable Models for <b>Human</b> Pose Estimation", "url": "https://openaccess.thecvf.com/content_cvpr_2013/papers/Sapp_MODEC_Multimodal_Decomposable_2013_CVPR_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_cvpr_2013/papers/Sapp_MODEC_<b>Multimodal</b>...", "snippet": "We propose a <b>multimodal</b>, decomposable <b>model</b> for ar-ticulated <b>human</b> pose estimation in monocular images. A typical approach to this problem is to use a linear struc- tured <b>model</b>, which struggles to capture the wide range of appearance present in realistic, unconstrained images. In this paper, we instead propose a <b>model</b> of <b>human</b> pose that explicitly captures a variety of pose modes. Unlike other <b>multimodal</b> models, our approach includes both global and local pose cues and uses a convex ...", "dateLastCrawled": "2022-01-30T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "MTAG: Modal-Temporal Attention Graph for Unaligned <b>Human</b> <b>Multimodal</b> ...", "url": "https://aclanthology.org/2021.naacl-main.79.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.naacl-main.79.pdf", "snippet": "follow <b>similar</b> sampling rate. MTAG can capture interactions of various types across any number of modalities all at once, comparing to previous methods that <b>model</b> bi-modal interactions at a time (Tsai et al.,2019a). At its core, MTAG utilizes an ef\ufb01cient trimodal-temporal graph fusion oper-ation. Coupled with our proposed dynamic prun-ing technique, MTAG learns a parameter-ef\ufb01cient and interpretable graph. In our experiments, we use two unaligned <b>multimodal</b> emotion recognition and ...", "dateLastCrawled": "2022-01-27T17:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Multimodal</b> Probabilistic <b>Model</b>-Based Planning for <b>Human</b>-Robot Interaction", "url": "https://stanfordasl.github.io/wp-content/papercite-data/pdf/Schmerling.Leung.Vollprecht.Pavone.ICRA18.pdf", "isFamilyFriendly": true, "displayUrl": "https://stanfordasl.github.io/wp-content/papercite-data/pdf/Schmerling.Leung...", "snippet": "<b>Multimodal</b> Probabilistic <b>Model</b>-Based Planning for <b>Human</b>-Robot Interaction Edward Schmerling1 Karen Leung 2Wolf Vollprecht3 Marco Pavone Abstract\u2014This paper presents a method for constructing <b>human</b>-robot interaction policies in settings where <b>multimodal</b>-ity, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traf\ufb01c weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars ...", "dateLastCrawled": "2022-01-16T09:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>MULTIMODAL</b> <b>HUMAN</b> ACTION RECOGNITION IN ASSISTIVE <b>HUMAN</b>-ROBOT ...", "url": "http://cvsp.cs.ntua.gr/publications/confr/RKPMKTM_MultimodalHumanActionRecogn-AssistHRI_ICASSP2016.pdf", "isFamilyFriendly": true, "displayUrl": "cvsp.cs.ntua.gr/publications/confr/RKPMKTM_<b>MultimodalHuman</b>ActionRecogn-AssistHRI...", "snippet": "<b>Multimodal</b> <b>human</b> action recognition poses challenges due to distant speech recognition and noise, pronunciation variability, scene noise by other subjects, camera motion and variation in ac- tion/gesture performance. Another source of difculties concerns the nature of our task, i.e. elderly subjects who often articulate or pronounce the <b>multimodal</b> gestures in a loose manner. Overcoming such problems for each modality separately is still open. Further, there are issues related to fusion ...", "dateLastCrawled": "2021-12-21T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "AttnSense: Multi-level Attention Mechanism For <b>Multimodal</b> <b>Human</b> ...", "url": "https://www.ijcai.org/Proceedings/2019/0431.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/Proceedings/2019/0431.pdf", "snippet": "ral network <b>model</b> called AttnSense for <b>multimodal</b> <b>human</b> activity recognition. 3 Problem Denition In this paper, we assume that there areK different sensors that are attached to the <b>human</b> body and are synchronized to emit data. For example, a smartwatch or an inertial measurement unit (IMU) is usually equipped with the accelerometer, gyro-scope and magnetometer, where each sensor could generate a signal vector at a time (e.g. accelerometer generates a signal along the x-axis, y-axis and z ...", "dateLastCrawled": "2022-01-30T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "An interdisciplinary agent-based <b>multimodal</b> wildfire evacuation <b>model</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1361920921004429", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1361920921004429", "snippet": "These results are <b>similar</b> to those from other disaster research that also found a strong predilection for private vehicles compared with other transportation modes (Lindell et al., 2019). In addition, modal split data provide information about evacuees\u2019 movement through the road network using transportation modes that differ in size and capacity. It is important to account for these behaviors in the wildfire studies since vehicles take more space on the roads than people evacuating by foot.", "dateLastCrawled": "2022-01-28T11:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "MODEC: <b>Multimodal</b> Decomposable Models for <b>Human</b> Pose Estimation", "url": "https://openaccess.thecvf.com/content_cvpr_2013/papers/Sapp_MODEC_Multimodal_Decomposable_2013_CVPR_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_cvpr_2013/papers/Sapp_MODEC_<b>Multimodal</b>...", "snippet": "<b>can</b> <b>be thought</b> of as a typical unimodal <b>model</b> over yc, one <b>model</b> for each value of zc. Hence, we refer to these terms as mode-speci\ufb01c submodels. The bene\ufb01ts of such a <b>model</b> over a non-<b>multimodal</b> one s(x,y) is that different modeling behaviors <b>can</b> be captured by the different mode submodels. This introduces bene\ufb01cial \ufb02exibility, especially", "dateLastCrawled": "2022-01-30T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Mind <b>Model</b> for <b>Multimodal</b> Communicative Creatures &amp; Humanoids", "url": "https://alumni.media.mit.edu/~kris/ftp/IJAAI.pdf", "isFamilyFriendly": true, "displayUrl": "https://alumni.media.mit.edu/~kris/ftp/IJAAI.pdf", "snippet": "This paper presents a computational <b>model</b> of real-time task-oriented dialogue skills. The architecture, termed Ymir, bridges between <b>multimodal</b> perception and <b>multimodal</b> action and supports the creation of autonomous computer characters that afford full-duplex, real-time face-to-face interaction with a <b>human</b>. Ymir has been prototyped in ...", "dateLastCrawled": "2022-01-29T13:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Multimodal</b> models are fast becoming a reality -- consequences be damned ...", "url": "https://venturebeat.com/2021/12/21/multimodal-models-are-fast-becoming-a-reality-consequences-be-damned/", "isFamilyFriendly": true, "displayUrl": "https://<b>venturebeat.com</b>/2021/12/21/<b>multimodal</b>-<b>models</b>-are-fast-becoming-a-reality...", "snippet": "It describes a <b>multimodal</b> <b>model</b> called Guided Language to Image Diffusion for Generation and Editing (GLIDE), which \u2014 like DALL-E \u2014 <b>can</b> create photos given a short text caption. But GLIDE <b>can</b> ...", "dateLastCrawled": "2022-01-30T18:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>Model</b> for <b>Multimodal</b> Reference Resolution", "url": "https://aclanthology.org/J00-2002.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/J00-2002.pdf", "snippet": "manuals) and from the point of view of <b>human</b>-computer interaction (HCI) where it <b>can</b> help in the design of computer interfaces in which the interpretation constraints of <b>multimodal</b> messages should be taken into account. Consider Figure 1 (adapted from Rist [1996]) in which a message is expressed through two different modalities, namely text and graphics. The figure illustrates a kind of reasoning required to understand <b>multimodal</b> presentations: in order to make sense of the message, the ...", "dateLastCrawled": "2022-01-30T09:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Challenges and opportunities of multimodal</b> data in <b>human</b> learning: The ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/jcal.12542", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/jcal.12542", "snippet": "Using these devices, researchers <b>can</b> collect data such as heart rate, gaze, electrophysiological activity of the brain, or facial expressions data, to study and <b>model</b> learning strategies (Mangaroska et al., 2018; Worsley &amp; Blikstein, 2015), to predict high-level constructs such as learner attention and engagement (Chan et al., 2020), to design <b>multimodal</b> learning interfaces (Echeverria et al., 2019), or to generate insights about teaching at a more fine-grained levels (Martinez-Maldonado ...", "dateLastCrawled": "2022-01-12T18:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The origin <b>of human multi-modal communication</b> | Philosophical ...", "url": "https://royalsocietypublishing.org/doi/10.1098/rstb.2013.0302", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rstb.2013.0302", "snippet": "The accumulations <b>can</b> <b>be thought</b> of as strata, and peeling away the strata successively <b>can</b> give us some insights into the probable evolution of the whole complex system. This holistic account of our communicational capacities also helps to bridge the gulf between the articulate species and our inarticulate cousins, allowing us to see precursor adaptations in, for example, the turn-taking widely if sparsely represented in current primates and the gestural skills of great apes.", "dateLastCrawled": "2022-01-29T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Editing Like Humans: A Contextual, <b>Multimodal</b> Framework for Automated ...", "url": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Koorathota_Editing_Like_Humans_A_Contextual_Multimodal_Framework_for_Automated_Video_CVPRW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Koorathota_Editing_Like...", "snippet": "\u2022 evaluate our <b>model</b> through <b>human</b> judgements of CMVE- and <b>human</b> professionally-edited videos in participants recruited on Amazon MTurk. 2. Related Work 2.1. <b>Multimodal</b> Reasoning Whilepastworkusedthespatial-temporalrelationofob-jects in video for retrieval, allowing discrimination power about different video criteria [30], recent research related to <b>multimodal</b> video retrieval has focused on improving natu-ral language descriptors [23] or extracting key events from videos [31, 12 ...", "dateLastCrawled": "2022-01-29T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>MODEC: Multimodal Decomposable Models for Human</b> Pose Estimation", "url": "https://www.researchgate.net/publication/261276858_MODEC_Multimodal_Decomposable_Models_for_Human_Pose_Estimation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/261276858_MODEC_<b>Multimodal</b>_Decomposable...", "snippet": "In this paper, we instead propose a <b>model</b> of <b>human</b> pose that explicitly captures a variety of pose modes. Unlike other <b>multimodal</b> models, our approach includes both global and local pose cues and ...", "dateLastCrawled": "2022-01-03T07:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Multimodal</b> mapping of the <b>face connectome</b> | Nature <b>Human</b> Behaviour", "url": "https://www.nature.com/articles/s41562-019-0811-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41562-019-0811-3", "snippet": "An analysis of absolute <b>model</b> fit suggests that the feedforward <b>model</b> <b>can</b> explain 16 \u00b1 8% (mean \u00b1 s.d.) of the observed variance in the left hemisphere and the recurrent <b>model</b> accounts for 18 \u00b1 ...", "dateLastCrawled": "2022-01-30T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>multimodal</b> stereovision framework to <b>model</b> wildfires", "url": "http://researchfeatures.com/multimodal-stereovision-framework-model-wildfires/", "isFamilyFriendly": true, "displayUrl": "researchfeatures.com/<b>multimodal</b>-stereovision-framework-<b>model</b>-wildfires", "snippet": "<b>Thought</b> Leaders. <b>Thought</b> Leaders . Uncategorized. Uncategorized . More results... A <b>multimodal</b> stereovision framework to <b>model</b> wildfires. October 20, 2021 Earth &amp; Environment; Article Detail Download PDF. Wildfires propagate in a chaotic way so finding patterns in their spread would help us understand how best to tackle them. Dr Lucile Rossi from the University of Corsica, France, is a lead scientist in the field of image processing. Dr Rossi proposes a system of <b>multimodal</b> vision, using ...", "dateLastCrawled": "2022-01-15T17:52:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Human</b> vs Machine: Establishing a <b>Human</b> Baseline for <b>Multimodal</b> Location ...", "url": "https://www.icsi.berkeley.edu/pubs/multimedia/humanmachine13.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.icsi.berkeley.edu/pubs/multimedia/<b>human</b>machine13.pdf", "snippet": "<b>Human</b> vs Machine: Establishing a <b>Human</b> Baseline for <b>Multimodal</b> Location Estimation Jaeyoung Choi1, Howard Lei1, Venkatesan Ekambaram2, Pascal Kelm3, Luke Gottlieb1, Thomas Sikora3, Kannan Ramchandran2 and Gerald Friedland1 1International Computer Science Institute, Berkeley, CA, USA 2Department of Electrical Engineering and Computer Sciences, UC Berkeley, Berkeley, CA, USA 3Communication Systems Group, Technische Universit\u00e4t Berlin, Germany 1{jaeyoung,hlei,luke,fractor}@icsi.berkeley.edu 2 ...", "dateLastCrawled": "2022-01-06T13:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Combating <b>Human</b> Trafcking with Deep <b>Multimodal</b> Models", "url": "https://aclanthology.org/P17-1142.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/P17-1142.pdf", "snippet": "deep <b>multimodal</b> <b>model</b> called the <b>Human</b> Trafcking Deep Network (HTDN). 1 Introduction <b>Human</b> trafcking a crime that shames us all (UNODC,2008),hasseenasteepriseintheUnited States since 2012. The number of cases reported rose from 3,279 in 2012 to 7,572 in 2016 more than doubling over the course of v e years (Hot-line ...", "dateLastCrawled": "2022-01-29T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Multimodal</b> models are fast becoming a reality -- consequences be damned ...", "url": "https://venturebeat.com/2021/12/21/multimodal-models-are-fast-becoming-a-reality-consequences-be-damned/", "isFamilyFriendly": true, "displayUrl": "https://<b>venturebeat.com</b>/2021/12/21/<b>multimodal</b>-<b>models</b>-are-fast-becoming-a-reality...", "snippet": "\u201cWe hope that Merlot <b>can</b> inspire future work for learning vision plus language representations in a more <b>human</b>-like fashion <b>compared</b> to ... It describes a <b>multimodal</b> <b>model</b> called Guided Language ...", "dateLastCrawled": "2022-01-30T18:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Multimodal</b> Integration of <b>Human</b>-Like Attention in Visual Question ...", "url": "https://deepai.org/publication/multimodal-integration-of-human-like-attention-in-visual-question-answering", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>multimodal</b>-integration-of-<b>human</b>-like-attention-in...", "snippet": "To <b>model</b> <b>human</b>-like attention on text we make use of the recently proposed Text Saliency <b>Model</b> (TSM) ... Specifically, we <b>compared</b> <b>multimodal</b> with text-only, image-only, and integration of <b>human</b>-like attention. Afterwards, we evaluated performance of the <b>multimodal</b> method when integrating <b>human</b>-like attention at different layers of the Transformer network. Finally, we evaluated more fine-grained performance values of the <b>multimodal</b>, unimodal, and no attention integration method for the ...", "dateLastCrawled": "2021-12-30T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is <b>multimodal</b> system of AI and its evolution", "url": "https://analyticsindiamag.com/what-is-the-multimodal-system-of-ai-and-its-evolution/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/what-is-the-<b>multimodal</b>-system-of-ai-and-its-evolution", "snippet": "What is <b>multimodal</b> interaction? As <b>human</b> beings, we experience the world as <b>multimodal</b>: we <b>can</b> feel texture, hear sounds, see objects, smell odours and taste flavours. However, standard AI systems are usually unimodal, meaning they are trained to do a specific task such as processing images or languages. The systems are fed a single sample of training data, from which they are able to identify corresponding images or words. While it is easier to work with a single source of information, it ...", "dateLastCrawled": "2022-01-30T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretable Multimodal Routing for Human Multimodal Language</b> | DeepAI", "url": "https://deepai.org/publication/interpretable-multimodal-routing-for-human-multimodal-language", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>interpretable-multimodal-routing-for-human-multimodal</b>...", "snippet": "In our experiments, we provide both global and local interpretation using <b>Multimodal</b> Routing on sentiment analysis and emotion prediction, without loss of performance <b>compared</b> to state-of-the-art methods. For example, we observe that our <b>model</b> relies mostly on the text modality for neutral sentiment predictions, the acoustic modality for extremely negative predictions, and the text-acoustic bimodal interaction for extremely positive predictions.", "dateLastCrawled": "2021-12-29T00:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>MODEC: Multimodal Decomposable Models for Human</b> Pose Estimation", "url": "https://www.researchgate.net/publication/261276858_MODEC_Multimodal_Decomposable_Models_for_Human_Pose_Estimation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/261276858_MODEC_<b>Multimodal</b>_Decomposable...", "snippet": "<b>Compared</b> with state-of-the-art <b>human</b> pose estimation methods, the proposed methods <b>can</b> accurately locate, classify, and connect the <b>human</b> body keypoints robustly. View Show abstract", "dateLastCrawled": "2022-01-03T07:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>EmotionMeter: A Multimodal Framework for Recognizing Human Emotions</b>", "url": "https://bcmi.sjtu.edu.cn/~lubaoliang/papers/2019/1.pdf", "isFamilyFriendly": true, "displayUrl": "https://bcmi.sjtu.edu.cn/~lubaoliang/papers/2019/1.pdf", "snippet": "a <b>multimodal</b> framework called EmotionMeter to recognize <b>human</b> emotions using six EEG electrodes and eye-tracking glasses. The framework of our proposed approach is shown in Fig. 1. The main contributions of this paper are as follows. 1) We developed a novel design of six symmetrical tempo-ral electrodes that <b>can</b> easily be embedded in a headset or", "dateLastCrawled": "2022-01-30T07:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Multimodal 3D Human Pose Estimation from a Single Image</b>", "url": "https://facstaff.elon.edu/sspurlock/papers/spurlock19_mdnpose.pdf", "isFamilyFriendly": true, "displayUrl": "https://facstaff.elon.edu/sspurlock/papers/spurlock19_mdnpose.pdf", "snippet": "We propose a <b>model</b> that predicts a <b>multimodal</b> prob-ability distribution over the possible output values by in-corporating Mixture Density Networks (MDNs) [2]. This approach allows for more accurate modeling of the ambi-guity in <b>human</b> pose <b>compared</b> with traditional averaging methods. Predicted distributions <b>can</b> also be naturally ag-gregated over a sequence of frames for video prediction or a set of cameras for multi-view prediction. 1.2. Modeling Joint Dependencies There have been a variety ...", "dateLastCrawled": "2022-01-25T04:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Multimodal</b> Conversation Modeling via Neural Perception, Structure ...", "url": "https://escholarship.org/uc/item/3fn5f194", "isFamilyFriendly": true, "displayUrl": "https://escholarship.org/uc/item/3fn5f194", "snippet": "<b>Multimodal</b> conversation modeling is an important and challenging problem when building conversational agents. Pioneer works mostly focus on end-to-end <b>multimodal</b> fusion techniques, which require large volumes of pairwise data and lacks interpretability.This dissertation aims at closing the loop of vision and language <b>multimodal</b> modeling from the perspectives of neural perception, structure learning, and communication.", "dateLastCrawled": "2022-02-02T07:13:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Towards <b>Multimodal</b> <b>Machine</b> <b>Learning</b> Prediction of Individual Cognitive ...", "url": "http://oliverychen.github.io/files/doc/Stijn_Denissen_et_al.pdf", "isFamilyFriendly": true, "displayUrl": "oliverychen.github.io/files/doc/Stijn_Denissen_et_al.pdf", "snippet": "used to learn the function is the <b>model</b> of choice. The concept can be clari\ufb01ed by means of an <b>analogy</b>; a student studying for a future exam. In the \ufb01rst phase, the student will gather knowledge on the domain by using available resources such as books and lecture notes (training). The student subsequently veri\ufb01es whether additional study is necessary by completing an exam from previous years to which the answers are available (validation). Together, this is called the training phase. As ...", "dateLastCrawled": "2022-01-04T13:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A <b>multilayer multimodal detection and prediction</b> <b>model</b> based on ...", "url": "https://www.nature.com/articles/s41598-021-82098-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-82098-3", "snippet": "An interpretable <b>machine</b> <b>learning</b> <b>model</b> for diagnosis of Alzheimer\u2019s disease. PeerJ 7 , e6543 (2019). PubMed PubMed Central Article Google Scholar", "dateLastCrawled": "2022-02-02T22:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Quantum-Like <b>multimodal</b> network framework for modeling interaction ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "snippet": "Our double-slit experiment <b>analogy</b> for <b>multimodal</b> sentiment analysis. We use the wave function \u03c6(x) ... <b>Multimodal</b> deep <b>learning</b> (MDL) <b>model</b>: this <b>model</b> can learn a joint representation of various features extracted in different modalities, which is similar to the method proposed in . In , the authors used a restricted Boltzmann <b>machine</b> (RBM) to learn the joint distribution over image and text inputs. We choose to replace the RBM with a convolutional neural network (CNN) to learn the joint ...", "dateLastCrawled": "2022-01-24T13:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) A <b>Machine</b> <b>learning</b> approach for rapid disaster response based on ...", "url": "https://www.researchgate.net/publication/353658800_A_Machine_learning_approach_for_rapid_disaster_response_based_on_multi-modal_data_The_case_of_housing_shelter_needs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353658800_A_<b>Machine</b>_<b>learning</b>_approach_for...", "snippet": "R esearch has shown that using <b>multimodal</b> data for <b>machine</b> <b>learning</b> leads to more robust inference than learn- ing f rom a single modality [5,6,7,8]. There are two approaches to <b>multimodal</b> data ...", "dateLastCrawled": "2022-01-29T05:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Structure-Mapping: A Computational Model of Analogy and</b> Similarity", "url": "https://www.qrg.northwestern.edu/ideas/smeidea.htm", "isFamilyFriendly": true, "displayUrl": "https://www.qrg.northwestern.edu/ideas/smeidea.htm", "snippet": "<b>Analogy</b> is also crucial in <b>learning</b> from instruction and in aligning experiential knowledge with knowledge gained via instruction. We have built a set of computational tools to facilitate detailed modeling of human analogical <b>learning</b> and reasoning. Our tools are accountable cognitive simulations. What we mean by this is that we use a theoretically-driven decomposition of the processes being simulated. Any choices that are not determined by the theory (i.e., are empirically open) are made ...", "dateLastCrawled": "2022-01-26T15:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Preliminary performance study of a brief review on <b>machine</b> <b>learning</b> ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "snippet": "<b>Analogy</b>-based effort estimation is the major task of software engineering which estimates the effort required for new software projects using existing histories for corresponding development and management. In general, the high accuracy of software effort estimation techniques can be a non-solvable problem we named as multi-objective problem. Recently, most of the authors have been used <b>machine</b> <b>learning</b> techniques for the same process however not possible to meet the higher performance ...", "dateLastCrawled": "2022-01-02T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - How to identify the modes in a (<b>multimodal</b> ...", "url": "https://stackoverflow.com/questions/51179095/how-to-identify-the-modes-in-a-multimodal-continuous-variable", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/51179095", "snippet": "<b>machine</b>-<b>learning</b> statistics probability probability-density kernel-density. Share. Follow asked Jul 4 &#39;18 at 18:12. Paulo Paulo. 73 3 3 ... I&#39;ll recommend a mixture density <b>model</b>, with varying numbers of components. E.g. mixture with 1 component, mixture with 2 components, 3, 4, 5, etc. Note that with k components, the maximum possible number of modes is k, although, depending on the locations and scales of the components, there might be fewer modes. There are probably many libraries which ...", "dateLastCrawled": "2022-01-03T12:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "<b>Analogy</b>: <b>Model</b>=organism, evolution=<b>learning</b>. Even with the improvements we typically consider to be evolvability (discussed in the previous section), evolution is a slow learner. Since it relies on mutations, it can only happen on relatively large populations over several generations.", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - What is the difference between multi-agent and multi ...", "url": "https://ai.stackexchange.com/questions/13794/what-is-the-difference-between-multi-agent-and-multi-modal-systems", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/13794/what-is-the-difference-between-multi...", "snippet": "<b>Multimodal</b> interaction (MI) refers to the interaction with a system (e.g. a computer) using multiple modalities (e.g. speech or gestures). For example, we usually can interact with a laptop using a keyboard and a touchpad (or mouse), so the keyboard and the touchpad are the two different modalities that are used to interact with the computer. MI could thus be considered a sub-field of", "dateLastCrawled": "2022-01-11T08:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Deep <b>Learning Models for Human Activity Recognition</b>", "url": "https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/deep-<b>learning-models-for-human-activity-recognition</b>", "snippet": "Human activity recognition, or HAR, is a challenging time series classification task. It involves predicting the movement of a person based on sensor data and traditionally involves deep domain expertise and methods from signal processing to correctly engineer features from the raw data in order to fit a <b>machine</b> <b>learning</b> <b>model</b>. Recently, deep <b>learning</b> methods such as convolutional neural networks and recurrent", "dateLastCrawled": "2022-02-02T16:15:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(multimodal model)  is like +(human)", "+(multimodal model) is similar to +(human)", "+(multimodal model) can be thought of as +(human)", "+(multimodal model) can be compared to +(human)", "machine learning +(multimodal model AND analogy)", "machine learning +(\"multimodal model is like\")", "machine learning +(\"multimodal model is similar\")", "machine learning +(\"just as multimodal model\")", "machine learning +(\"multimodal model can be thought of as\")", "machine learning +(\"multimodal model can be compared to\")"]}