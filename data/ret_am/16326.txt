{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A literature review of new methods in empirical asset pricing: omitted ...", "url": "https://link.springer.com/article/10.1007/s11408-020-00358-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11408-020-00358-0", "snippet": "Yet, rather than fixed <b>effects</b> for individual firms <b>like</b> Hoechle et al. , Kamstra ... Due to this <b>regularization</b>, the elastic net approach can take into account the information from a large number of factors without suffering from <b>overfitting</b>. Kozak et al. adjust the usual elastic net procedure by replacing the <b>ridge</b> penalty with an economically more sensible penalty that shrinks coefficients at different rates toward zero. In the application of their method to the pricing of test assets ...", "dateLastCrawled": "2021-10-31T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Empirical Asset Pricing via <b>Machine Learning</b> | The Review of Financial ...", "url": "https://academic.oup.com/rfs/article/33/5/2223/5758276", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/rfs/article/33/5/2223/5758276", "snippet": "The <b>regularization</b> procedures discussed below, which are <b>machine learning</b>\u2019s primary defense against <b>overfitting</b>, rely on a choice of hyperparameters (or, synonymously, \u201ctuning parameters\u201d). These are critical to the performance of <b>machine learning</b> methods as they control model complexity. Hyperparameters include, for example, the penalization parameters in lasso and elastic net, the number of iterated trees in boosting, the number of random trees in a forest, and the depth of the trees ...", "dateLastCrawled": "2022-02-02T19:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Dompteur: <b>Taming</b> Audio Adversarial Examples | Request PDF", "url": "https://www.researchgate.net/publication/349195476_Dompteur_Taming_Audio_Adversarial_Examples", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/349195476_Dompteur_<b>Taming</b>_Audio_Adversarial...", "snippet": "To reduce <b>overfitting</b> in the fully-connected layers we employed a recently-developed <b>regularization</b> method called &quot;dropout&quot; that proved to be very effective. We also entered a variant of this ...", "dateLastCrawled": "2022-01-30T17:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Simplifying the Assessment of Measurement Invariance over Multiple ...", "url": "https://europepmc.org/article/PMC/PMC7596881", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC7596881", "snippet": "Europe PMC is an archive of life sciences journal literature.", "dateLastCrawled": "2021-01-16T02:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Shrinking the <b>cross</b>-section - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0304405X19301655", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0304405X19301655", "snippet": "Fig. 1 presents results for our dual-penalty estimator in Eq. (28).The results using the raw FF25 portfolio returns are shown in the left-hand side in Fig. 1a; those using PCs of these returns are shown in the right-hand side plot Fig. 1b. Every point on the plane in these plots represents a particular combination of the two penalties \u03b3 1 and \u03b3 2 that control sparsity and L 2-shrinkage, respectively.We vary the degree of L 2-shrinkage on the horizontal axis, going from extreme shrinkage on ...", "dateLastCrawled": "2022-02-02T21:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Bond Risk Premiums with <b>Machine Learning</b> | The Review of Financial ...", "url": "https://academic.oup.com/rfs/article/34/2/1046/5843806", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/rfs/article/34/2/1046/5843806", "snippet": "However, our statistical measure of expected bond returns contrasts with recent survey-based measures <b>like</b> the one proposed by Buraschi, Piatti, and Whelan (2019). Their measure is mostly related to financial (specifically, bond) volatility. In the context of <b>machine learning</b> in asset pricing, we document three novel facts. 4 First, our result that extreme trees and NNs constitute the best-performing methods even in the case when only information in the term structure is used to forecast ...", "dateLastCrawled": "2022-01-30T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Machine Learning in Python</b> | ismail setiawan - Academia.edu", "url": "https://www.academia.edu/36391584/Machine_Learning_in_Python", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/36391584/<b>Machine_Learning_in_Python</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2021-11-29T23:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "GitHub - <b>namanUIUC/ICML-2019</b>: A summary of research work presented in ...", "url": "https://github.com/namanUIUC/ICML-2019", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>namanUIUC/ICML-2019</b>", "snippet": "A summary of research work presented in the thirty-sixth International Conference on Machine Learning (ICML) @ Long beach - 2019 - GitHub - <b>namanUIUC/ICML-2019</b>: A summary of research work presented in the thirty-sixth International Conference on Machine Learning (ICML) @ Long beach - 2019", "dateLastCrawled": "2022-01-29T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>ICML 2019 most cited papers</b> \u2013 Ludovic Arnold", "url": "https://ludovicarnold.com/icml-2019-most-cited-papers/", "isFamilyFriendly": true, "displayUrl": "https://ludovicarnold.com/<b>icml-2019-most-cited-papers</b>", "snippet": "Toward <b>Controlling</b> Discrimination in Online Ad Auctions: 243: 2: Learning to Infer Program Sketches: 244: 2: Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Value Approximation : 245: 2: Classification from Positive, Unlabeled and Biased Negative Data: 246: 2: Neural Network Attributions: A Causal Perspective: 247: 2: Learning Discrete Structures for Graph Neural Networks: 248: 2: Cheap Orthogonal Constraints in Neural Networks: A Simple Parametrization of the ...", "dateLastCrawled": "2021-12-25T15:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Accepted papers at ICML 2019</b> - Angelos Katharopoulos", "url": "https://www.idiap.ch/~katharas/pages/accepted-papers-at-icml-2019.html", "isFamilyFriendly": true, "displayUrl": "https://www.idiap.ch/~katharas/pages/<b>accepted-papers-at-icml-2019</b>.html", "snippet": "<b>Accepted papers at ICML 2019</b>. The data to produce the following list is a slightly processed version of these. In the following list you can filter the papers by writing a small piece of javascript code. You are creating a function that should return true or false to keep or discard a paper respectively. That function takes a single parameter ...", "dateLastCrawled": "2022-01-25T14:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Comparing the Lasso Predictor-Selection and Regression Method with ...", "url": "https://www.researchgate.net/publication/343874560_Comparing_the_Lasso_Predictor-Selection_and_Regression_Method_with_Classical_Approaches_of_Precipitation_Bias_Adjustment_in_Decadal_Climate_Predictions", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343874560_Comparing_the_Lasso_Predictor...", "snippet": "Request PDF | Comparing the Lasso Predictor-Selection and Regression Method with Classical Approaches of Precipitation Bias Adjustment in Decadal Climate Predictions | In this study, we ...", "dateLastCrawled": "2022-02-03T01:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Algorithm Supported Induction for Building Theory</b>: How Can We Use ...", "url": "https://pubsonline.informs.org/doi/10.1287/orsc.2020.1382", "isFamilyFriendly": true, "displayUrl": "https://pubsonline.informs.org/doi/10.1287/orsc.2020.1382", "snippet": "Unsupervised ML techniques use the same basic logic but provide more flexibility in terms of choosing different types of algorithms to perform the clustering, followed again by procedures such as <b>regularization</b> and cross-validation to prevent <b>overfitting</b>. The relevant algorithms include K-means, hierarchical, and spectral clustering, all of which largely share a <b>similar</b> intuition. LDA is a powerful suite of unsupervised learning algorithms that detect clusters of topics in a corpus of text ...", "dateLastCrawled": "2021-12-30T22:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Decomposing motion that changes over time into task-relevant and task ...", "url": "https://europepmc.org/article/MED/31076575", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/31076575", "snippet": "Furthermore, the <b>regularization</b> parameter \u03bb allows the appropriate w to be found even in the presence of observation noise because minimizing the cost function for <b>ridge</b> regression (equation ) is analytically equivalent to finding the appropriate w when nonzero observation noise exists (see the Materials and Methods section for the detailed mathematical calculations). The <b>ridge</b> regression procedure thus allows the relation between the motion data and performance data to be found while ...", "dateLastCrawled": "2022-01-23T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A literature review of new methods in empirical asset pricing: omitted ...", "url": "https://link.springer.com/article/10.1007/s11408-020-00358-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11408-020-00358-0", "snippet": "Due to this <b>regularization</b>, the elastic net approach can take into account the information from a large number of factors without suffering from <b>overfitting</b>. Kozak et al. adjust the usual elastic net procedure by replacing the <b>ridge</b> penalty with an economically more sensible penalty that shrinks coefficients at different rates toward zero. In the application of their method to the pricing of test assets, such as characteristics-sorted portfolios, they find that the estimated SDF needs to ...", "dateLastCrawled": "2021-10-31T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Decomposing motion that changes over time into task-relevant and task ...", "url": "https://www.nature.com/articles/s41598-019-43558-z", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-019-43558-z", "snippet": "Furthermore, the <b>regularization</b> parameter \u03bb allows the appropriate w to be found even in the presence of observation noise because minimizing the cost function for <b>ridge</b> regression (equation ) is ...", "dateLastCrawled": "2022-02-01T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Taming the Factor Zoo: A Test</b> of New Factors | Request PDF", "url": "https://www.researchgate.net/publication/338797077_Taming_the_Factor_Zoo_A_Test_of_New_Factors", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338797077_<b>Taming_the_Factor_Zoo_A_Test</b>_of_New...", "snippet": "These <b>effects</b> are amplified for investors with an increased sensitivity to risk-adjusted returns, during high volatility periods or when accounting for tail risk. View Show abstract", "dateLastCrawled": "2022-01-21T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Shrinking the <b>cross</b>-section - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0304405X19301655", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0304405X19301655", "snippet": "Fig. 1 presents results for our dual-penalty estimator in Eq. (28).The results using the raw FF25 portfolio returns are shown in the left-hand side in Fig. 1a; those using PCs of these returns are shown in the right-hand side plot Fig. 1b. Every point on the plane in these plots represents a particular combination of the two penalties \u03b3 1 and \u03b3 2 that control sparsity and L 2-shrinkage, respectively.We vary the degree of L 2-shrinkage on the horizontal axis, going from extreme shrinkage on ...", "dateLastCrawled": "2022-02-02T21:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Empirical Asset Pricing via <b>Machine Learning</b> | The Review of Financial ...", "url": "https://academic.oup.com/rfs/article/33/5/2223/5758276", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/rfs/article/33/5/2223/5758276", "snippet": "The <b>regularization</b> procedures discussed below, which are <b>machine learning</b>\u2019s primary defense against <b>overfitting</b>, rely on a choice of hyperparameters (or, synonymously, \u201ctuning parameters\u201d). These are critical to the performance of <b>machine learning</b> methods as they control model complexity. Hyperparameters include, for example, the penalization parameters in lasso and elastic net, the number of iterated trees in boosting, the number of random trees in a forest, and the depth of the trees ...", "dateLastCrawled": "2022-02-02T19:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Bond Risk Premiums with <b>Machine Learning</b> | The Review of Financial ...", "url": "https://academic.oup.com/rfs/article/34/2/1046/5843806", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/rfs/article/34/2/1046/5843806", "snippet": "The identity states that (after <b>controlling</b> for the slope ... ignored the potential capability of <b>machine learning</b> techniques to address the issue of nonlinearity and variable <b>regularization</b>. Arguably, this comes at the expense of not fully capturing the extent to which yields and macroeconomic variables are relevant for the measurement of expected excess bond returns. This is the focus of our paper. 2. Research Design. In this section, we outline the research design for the empirical ...", "dateLastCrawled": "2022-01-30T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>ICML 2019 most cited papers</b> \u2013 Ludovic Arnold", "url": "https://ludovicarnold.com/icml-2019-most-cited-papers/", "isFamilyFriendly": true, "displayUrl": "https://ludovicarnold.com/<b>icml-2019-most-cited-papers</b>", "snippet": "Toward <b>Controlling</b> Discrimination in Online Ad Auctions: 243: 2: Learning to Infer Program Sketches: 244: 2: Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Value Approximation : 245: 2: Classification from Positive, Unlabeled and Biased Negative Data: 246: 2: Neural Network Attributions: A Causal Perspective: 247: 2: Learning Discrete Structures for Graph Neural Networks: 248: 2: Cheap Orthogonal Constraints in Neural Networks: A Simple Parametrization of the ...", "dateLastCrawled": "2021-12-25T15:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Dompteur: <b>Taming</b> Audio Adversarial Examples | Request PDF", "url": "https://www.researchgate.net/publication/349195476_Dompteur_Taming_Audio_Adversarial_Examples", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/349195476_Dompteur_<b>Taming</b>_Audio_Adversarial...", "snippet": "To reduce <b>overfitting</b> in the fully-connected layers we employed a recently-developed <b>regularization</b> method called &quot;dropout&quot; that proved to be very effective. We also entered a variant of this ...", "dateLastCrawled": "2022-01-30T17:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bond Risk Premiums with Machine Learning</b> | The Review of Financial ...", "url": "https://academic.oup.com/rfs/article-abstract/34/2/1046/5843806", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/rfs/article-abstract/34/2/1046/5843806", "snippet": "Depending on the functional form of the penalty term, the regression coefficients <b>can</b> be regularized and shrunk towards zero (as in <b>ridge</b>), exactly set to zero (as in lasso), or a combination of the two (as in elastic net). In Appendix E.2, we describe each method in detail. Penalized regressions still do not account for nonlinear relations. To ...", "dateLastCrawled": "2022-01-05T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Empirical Asset Pricing via <b>Machine Learning</b> | The Review of Financial ...", "url": "https://academic.oup.com/rfs/article/33/5/2223/5758276", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/rfs/article/33/5/2223/5758276", "snippet": "The <b>regularization</b> procedures discussed below, which are <b>machine learning</b>\u2019s primary defense against <b>overfitting</b>, rely on a choice of hyperparameters (or, synonymously, \u201ctuning parameters\u201d). These are critical to the performance of <b>machine learning</b> methods as they control model complexity. Hyperparameters include, for example, the penalization parameters in lasso and elastic net, the number of iterated trees in boosting, the number of random trees in a forest, and the depth of the trees ...", "dateLastCrawled": "2022-02-02T19:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Algorithm Supported Induction for Building Theory: How <b>Can</b> We Use ...", "url": "https://pubsonline.informs.org/doi/full/10.1287/orsc.2020.1382", "isFamilyFriendly": true, "displayUrl": "https://pubsonline.informs.org/doi/full/10.1287/orsc.2020.1382", "snippet": "For example, if we were to build a well-fitting OLS model by selectively adding or dropping variables to find significant <b>effects</b>, we would run two related risks <b>of overfitting</b>: (a) excessive model complexity\u2014the realized R 2 may be high simply because we have too many parameters in the model, and the model must be penalized for this to enable comparison with other models; and (b) excessive sample dependence\u2014including cherry-picked variables <b>can</b> produce a model that may fit the ...", "dateLastCrawled": "2022-01-31T02:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Taming the Factor Zoo: A Test</b> of New Factors | Request PDF", "url": "https://www.researchgate.net/publication/338797077_Taming_the_Factor_Zoo_A_Test_of_New_Factors", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338797077_<b>Taming_the_Factor_Zoo_A_Test</b>_of_New...", "snippet": "By integrating over idiosyncratic market data we <b>can</b> learn general transferable dynamics, avoiding the problem <b>of overfitting</b> to produce strategies with superior returns. We evaluate QuantNet on ...", "dateLastCrawled": "2022-01-21T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Empirical Asset Pricing Via Machine Learning SSRN-id3159577 PDF ...", "url": "https://www.scribd.com/document/475090296/Empirical-Asset-Pricing-via-Machine-Learning-SSRN-id3159577-pdf", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/475090296/Empirical-Asset-Pricing-via-Machine-Learning...", "snippet": "because it achieves <b>regularization</b> at a much lower computational cost.24 Early stopping <b>can</b> be used alone, or together with l1 -<b>regularization</b> as we do in this paper. \u201cBatch normalization\u201d (Ioffe and Szegedy, 2015) is a simple technique for <b>controlling</b> the variabil- ity of predictors across different regions of the network and across different datasets.", "dateLastCrawled": "2021-08-25T15:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Machine Learning in Python</b> | ismail setiawan - Academia.edu", "url": "https://www.academia.edu/36391584/Machine_Learning_in_Python", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/36391584/<b>Machine_Learning_in_Python</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2021-11-29T23:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>CSAIL Publications</b>", "url": "http://publications.csail.mit.edu/ai/browse/completebrowse.shtml", "isFamilyFriendly": true, "displayUrl": "publications.csail.mit.edu/ai/browse/completebrowse.shtml", "snippet": "Our algorithm <b>can</b> <b>be thought</b> of as learning a manifold of images by taking into account the dynamics underlying the low-dimensional representation of these images. It also serves as a nonlinear system identification procedure that estimates the inverse of the observation function in nonlinear dynamic system. Our algorithm reduces to a generalized eigenvalue problem, so it does not suffer from the computational or local minimum issues traditionally associated with nonlinear system ...", "dateLastCrawled": "2021-09-27T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Glossary Of Data Analytics, Data Science, Big Data and ... - datasetsdb.com", "url": "https://datasetsdb.com/pages/glossary-of-data-analytics-data-science-big-data-and-digital-marketing-terminology-and-jargon", "isFamilyFriendly": true, "displayUrl": "https://datasetsdb.com/pages/glossary-of-data-analytics-data-science-big-data-and...", "snippet": "Over 1,250 Terms Every Data Analyst, Data Scientist and Marketer Should Know. Whether you\u2019re into data analytics, data science or digital marketing the complex world of data and analytics <b>can</b> be a mess of confusing terminology and jargon.", "dateLastCrawled": "2022-01-06T20:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Machine <b>Learning with SAS Viya 9781951685317, 1951685318</b> - DOKUMEN.PUB", "url": "https://dokumen.pub/machine-learning-with-sas-viya-9781951685317-1951685318.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/machine-<b>learning-with-sas-viya-9781951685317-1951685318</b>.html", "snippet": "<b>Controlling</b> hyperparameters of a learning algorithm is very important because proper control <b>can</b> increase accuracy and prevent <b>overfitting</b>. Table 5.1 presents some best practices for selecting SAS Visual Data Mining and Machine Learning supervised learning algorithms. Table 5.1: Selecting Supervised Learning Algorithms Target Type Usage", "dateLastCrawled": "2022-01-05T15:50:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Decomposing motion that changes over time into task-relevant and task ...", "url": "https://europepmc.org/article/MED/31076575", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/31076575", "snippet": "The current study relied on <b>ridge</b> regression 29, a linear regression technique that is robust in the presence of measurement noise, has a definite relation to PCA, and <b>can</b> be used to evaluate how the motion of each part of the body at each moment in time is relevant to task performance in a data-driven manner 30. Our technique thus enables the identification of task functions in a data-driven manner without requiring any explicit function, such as a parabola, or forward kinematics. First, we ...", "dateLastCrawled": "2022-01-23T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Sparse Recovery via Differential Inclusions</b> | Request PDF", "url": "https://www.researchgate.net/publication/290508012_Sparse_Recovery_via_Differential_Inclusions", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/290508012_Sparse_Recovery_via_Differential...", "snippet": "Simulation results show that <b>compared</b> with L1 <b>regularization</b>, nonconvex <b>regularization</b> <b>can</b> reduce the average relative bias from 10.88% to 0.25%, <b>compared</b> with the matched filtering method and L1 ...", "dateLastCrawled": "2022-01-25T19:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Shrinking the <b>cross</b>-section - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0304405X19301655", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0304405X19301655", "snippet": "As a consequence, biased beliefs <b>can</b> only have substantial pricing <b>effects</b> in the <b>cross</b>-section if these biased beliefs align with high-eigenvalue PCs; otherwise, arbitrageurs would find it too attractive to aggressively lean against the demand from biased investors, leaving very little price impact. To the extent it exists, mispricing then appears in the SDF mainly through the risk prices of high-eigenvalue PCs. Thus, within both classes of asset pricing models, we would expect Sharpe ...", "dateLastCrawled": "2022-02-02T21:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Taming the Factor Zoo: A Test</b> of New Factors | Request PDF", "url": "https://www.researchgate.net/publication/338797077_Taming_the_Factor_Zoo_A_Test_of_New_Factors", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338797077_<b>Taming_the_Factor_Zoo_A_Test</b>_of_New...", "snippet": "By integrating over idiosyncratic market data we <b>can</b> learn general transferable dynamics, avoiding the problem <b>of overfitting</b> to produce strategies with superior returns. We evaluate QuantNet on ...", "dateLastCrawled": "2022-01-21T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Empirical Asset Pricing via <b>Machine Learning</b> | The Review of Financial ...", "url": "https://academic.oup.com/rfs/article/33/5/2223/5758276", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/rfs/article/33/5/2223/5758276", "snippet": "The <b>regularization</b> procedures discussed below, which are <b>machine learning</b>\u2019s primary defense against <b>overfitting</b>, rely on a choice of hyperparameters (or, synonymously, \u201ctuning parameters\u201d). These are critical to the performance of <b>machine learning</b> methods as they control model complexity. Hyperparameters include, for example, the penalization parameters in lasso and elastic net, the number of iterated trees in boosting, the number of random trees in a forest, and the depth of the trees ...", "dateLastCrawled": "2022-02-02T19:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Algorithm Supported Induction for Building Theory: How <b>Can</b> We Use ...", "url": "https://pubsonline.informs.org/doi/full/10.1287/orsc.2020.1382", "isFamilyFriendly": true, "displayUrl": "https://pubsonline.informs.org/doi/full/10.1287/orsc.2020.1382", "snippet": "For example, if we were to build a well-fitting OLS model by selectively adding or dropping variables to find significant <b>effects</b>, we would run two related risks <b>of overfitting</b>: (a) excessive model complexity\u2014the realized R 2 may be high simply because we have too many parameters in the model, and the model must be penalized for this to enable comparison with other models; and (b) excessive sample dependence\u2014including cherry-picked variables <b>can</b> produce a model that may fit the ...", "dateLastCrawled": "2022-01-31T02:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Decomposing motion that changes over time into task-relevant and task ...", "url": "https://www.nature.com/articles/s41598-019-43558-z", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-019-43558-z", "snippet": "<b>Overfitting</b>, which <b>can</b> arise in the absence of any <b>regularization</b>, will lead to a model that is more complicated than the true model. Minimization of the cost function with respect to w leads to ...", "dateLastCrawled": "2022-02-01T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Bond Risk Premiums with Machine Learning</b> | The Review of Financial ...", "url": "https://academic.oup.com/rfs/article-abstract/34/2/1046/5843806", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/rfs/article-abstract/34/2/1046/5843806", "snippet": "The identity states that (after <b>controlling</b> for the slope ... ignored the potential capability of machine learning techniques to address the issue of nonlinearity and variable <b>regularization</b>. Arguably, this comes at the expense of not fully capturing the extent to which yields and macroeconomic variables are relevant for the measurement of expected excess bond returns. This is the focus of our paper. 2. Research Design. In this section, we outline the research design for the empirical ...", "dateLastCrawled": "2022-01-05T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Paper Digest: <b>ICML 2019 Highlights</b> \u2013 Paper Digest", "url": "https://www.paperdigest.org/2019/05/icml-2019-highlights/", "isFamilyFriendly": true, "displayUrl": "https://www.paperdigest.org/2019/05/<b>icml-2019-highlights</b>", "snippet": "Paper Digest: <b>ICML 2019 Highlights</b>. May 23, 2019. October 5, 2019. admin. Download ICML-2019-Paper-Digests.pdf \u2013 highlights of all ICML-2019 papers (.PDF file size is ~0.5M). The 2019 International Conference on Machine Learning (ICML) is one of the top machine learning conferences in the world. In 2019, it is to be held in Long Beach ...", "dateLastCrawled": "2022-01-22T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Machine <b>Learning with SAS Viya 9781951685317, 1951685318</b> - DOKUMEN.PUB", "url": "https://dokumen.pub/machine-learning-with-sas-viya-9781951685317-1951685318.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/machine-<b>learning-with-sas-viya-9781951685317-1951685318</b>.html", "snippet": "<b>Controlling</b> hyperparameters of a learning algorithm is very important because proper control <b>can</b> increase accuracy and prevent <b>overfitting</b>. Table 5.1 presents some best practices for selecting SAS Visual Data Mining and Machine Learning supervised learning algorithms. Table 5.1: Selecting Supervised Learning Algorithms Target Type Usage", "dateLastCrawled": "2022-01-05T15:50:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Regularization</b> \u2014 Understanding L1 and L2 <b>regularization</b> for Deep <b>Learning</b>", "url": "https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2-regularization-for-deep-learning-a7b9e4a409bf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>regularization</b>-understanding-l1-and-l2...", "snippet": "Understanding what <b>regularization</b> is and why it is required for <b>machine</b> <b>learning</b> and diving deep to clarify the importance of L1 and L2 <b>regularization</b> in Deep <b>learning</b>.", "dateLastCrawled": "2022-02-01T00:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Ridge Regression</b> Explained, Step by Step - <b>Machine</b> <b>Learning</b> Compass", "url": "https://machinelearningcompass.com/machine_learning_models/ridge_regression/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>compass.com/<b>machine</b>_<b>learning</b>_models/<b>ridge_regression</b>", "snippet": "<b>Ridge Regression</b> is an adaptation of the popular and widely used linear regression algorithm. It enhances regular linear regression by slightly changing its cost function, which results in less overfit models. In this article, you will learn everything you need to know about <b>Ridge Regression</b>, and how you can start using it in your own <b>machine</b> <b>learning</b> projects.", "dateLastCrawled": "2022-02-02T15:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Ridge Regression</b> - University of Washington", "url": "https://courses.cs.washington.edu/courses/cse446/17wi/slides/ridgeregression-annotated.pdf", "isFamilyFriendly": true, "displayUrl": "https://courses.cs.washington.edu/courses/cse446/17wi/slides/<b>ridgeregression</b>-annotated.pdf", "snippet": "<b>Ridge regression</b> (a.k.a L 2 <b>regularization</b>) tuning parameter = balance of fit and magnitude 2 20 CSE 446: <b>Machine</b> <b>Learning</b> Bias-variance tradeoff Large \u03bb: high bias, low variance (e.g., 1=0 for \u03bb=\u221e) Small \u03bb: low bias, high variance (e.g., standard least squares (RSS) fit of high-order polynomial for \u03bb=0) \u00a92017 Emily Fox In essence, \u03bb controls model complexity . 1/13/2017 11 21 CSE 446: <b>Machine</b> <b>Learning</b> Revisit polynomial fit demo What happens if we refit our high-order polynomial ...", "dateLastCrawled": "2022-01-30T17:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Regularization</b> with <b>Ridge</b>, Lasso, and <b>Elastic Net</b> Regressions | by ...", "url": "https://towardsdatascience.com/what-is-regularization-and-how-do-i-use-it-f7008b5a68c6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/what-is-<b>regularization</b>-and-how-do-i-use-it-f7008b5a68c6", "snippet": "<b>Ridge</b> regression is often referred to as L2 norm <b>regularization</b>. <b>Ridge</b> Cost Function \u2014 Notice the lambda (\u03bb) multiplied by the sum of squared predictors Keep in mind that the goal is to minimize the cost function, so the larger the penalty term (\u03bb * sum(m\u2c7c\u00b2)) the worse the model will perform.", "dateLastCrawled": "2022-01-27T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "ISL: Linear Model Selection and <b>Regularization</b> - Part 1 - Yao&#39;s blog", "url": "https://blog.listcomp.com/machine-learning/2014/09/28/isl-linear-model-selection-and-regularization-part-1", "isFamilyFriendly": true, "displayUrl": "https://blog.listcomp.com/<b>machine</b>-<b>learning</b>/2014/09/28/isl-linear-model-selection-and...", "snippet": "<b>Ridge</b> regression does have one obvious disadvantage that, unlike subset selection, <b>ridge</b> regression will include all $ p $ predictors in the final model because the shrinkage penalty does shrink all of the coefficients towards zero but it will not set any of them exactly to zero (unless $ \\lambda = \\infty $). This may not be a problem for prediction accuracy, but it can create a challenge in model interpretation when $ p $ is quite large", "dateLastCrawled": "2022-01-06T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Support Vector <b>Machine</b> (SVM) Algorithm. | by Nadeem | MLearning.ai | Medium", "url": "https://medium.com/mlearning-ai/support-vector-machine-svm-algorithm-a5acaa48fe3a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/m<b>learning</b>-ai/support-vector-<b>machine</b>-svm-algorithm-a5acaa48fe3a", "snippet": "I would like to bring an <b>analogy</b> with the <b>regularization</b> equation. The cost function is the sum of errors and the squared sum of coefficients (in terms of the <b>ridge</b>).", "dateLastCrawled": "2022-01-26T23:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Understanding Linear Regression \u2013 Part II \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/30/understanding-linear-regression-part-ii/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/30/understanding-linear-regression-part-ii", "snippet": "A similar <b>analogy</b> is applied for comparing statistical modeling and <b>machine</b> <b>learning</b> methodologies here. The two-point validation is performed on the statistical modeling methodology on training data using overall model accuracy and individual parameters significance test. Due to the fact that either linear or logistic regression has less variance by shape of the model itself, hence there would be very little chance of it working worse on unseen data. Hence, during deployment, these models ...", "dateLastCrawled": "2022-01-03T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "LASSO and <b>ridge</b> from the Bayesian perspective: what about the tuning ...", "url": "https://stats.stackexchange.com/questions/368002/lasso-and-ridge-from-the-bayesian-perspective-what-about-the-tuning-parameter", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/368002", "snippet": "This is not an exact <b>analogy</b>, but it is a close <b>analogy</b>, up to arbitrary accuracy. It is also important to note that the MAP <b>analogy</b> no longer shares the same likelihood function as the original problem, since the loss function depends on the data and is thus absorbed as part of the likelihood rather than the prior. In fact, the full <b>analogy</b> is as follows:", "dateLastCrawled": "2022-01-14T18:12:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Linear Model Regularization. An extension of Lasso and Ridge\u2026 | by Cary ...", "url": "https://medium.com/@carylmosley/elastic-net-regression-fb7461253cd7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@carylmosley/elastic-net-regression-fb7461253cd7", "snippet": "<b>Ridge regularization is similar</b> to Lasso in that it also adds an additional penalty term, scaled by lambda, to the OLS equation. Unlike Lasso, the Ridge equation uses the sum of the square of the ...", "dateLastCrawled": "2021-11-14T17:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Problem Statement - 5 - InternshipGitbook", "url": "https://shahyaseen71.gitbook.io/internshipgitbook/data-science-mini-project-task-5/problem-statement", "isFamilyFriendly": true, "displayUrl": "https://shahyaseen71.gitbook.io/internshipgitbook/data-science-mini-project-task-5/...", "snippet": "We begin our exploration of the foundational <b>machine</b> <b>learning</b> concepts of overfitting, underfitting, and the bias-variance trade-off by examining how the logistic regression model can be extended to address the overfitting problem. After reviewing the mathematical details of the regularization methods that are used to alleviate overfitting, you will learn a useful practice for tuning the hyperparameters of regularization: cross-validation. Through the methods of regularization and some ...", "dateLastCrawled": "2022-01-29T06:27:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Student Association for Applied Statistics", "url": "https://saas.berkeley.edu/rp/performance-of-cricket-batsmen", "isFamilyFriendly": true, "displayUrl": "https://saas.berkeley.edu/rp/performance-of-cricket-batsmen", "snippet": "One risk of implementing <b>machine</b> <b>learning</b> models is that the developed algorithm could assign coefficients that are reflective of the training set and not the general data. Hence, I used a technique called ridge regularization that prevents this from happening. <b>Ridge regularization can be thought of as</b> a penalty against complexity. Increasing ...", "dateLastCrawled": "2021-12-21T09:08:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(ridge regularization)  is like +(taming or controlling the effects of overfitting)", "+(ridge regularization) is similar to +(taming or controlling the effects of overfitting)", "+(ridge regularization) can be thought of as +(taming or controlling the effects of overfitting)", "+(ridge regularization) can be compared to +(taming or controlling the effects of overfitting)", "machine learning +(ridge regularization AND analogy)", "machine learning +(\"ridge regularization is like\")", "machine learning +(\"ridge regularization is similar\")", "machine learning +(\"just as ridge regularization\")", "machine learning +(\"ridge regularization can be thought of as\")", "machine learning +(\"ridge regularization can be compared to\")"]}