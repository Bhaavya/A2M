{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep</b> Learning 101 \u2014 What is a Neural Network? The Perceptron and the ...", "url": "https://medium.com/analytics-vidhya/deep-learning-101-what-is-a-neural-network-the-perceptron-and-the-multi-layer-perceptron-c50d9bc49e42", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>deep</b>-learning-101-what-is-a-neural-network-the...", "snippet": "The \u201c<b>Deep</b>\u201d term comes from the complexity of the Neural Network, as it is constructed as a <b>stack</b> of <b>layers</b> from which we extract <b>hierarchical</b> data representations from our inputs. The higher ...", "dateLastCrawled": "2021-08-06T08:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>What is Deep Learning? - PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2021/04/17/what-is-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/04/17/<b>what-is-deep-learning</b>", "snippet": "<b>Deep</b> learning algorithms learn in <b>a hierarchical</b> fashion and therefore <b>stack</b> multiple <b>layers</b> on top of each other to learn increasingly more abstract concepts. A network should have &gt; 2 <b>layers</b> to be considered \u201c<b>deep</b>\u201d (this is my anecdotal opinion based on decades of neural network research).", "dateLastCrawled": "2022-01-26T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Deep Learning Architecture</b> - Types of Neural Networks - Addepto", "url": "https://addepto.com/deep-learning-architecture/", "isFamilyFriendly": true, "displayUrl": "https://addepto.com/<b>deep-learning-architecture</b>", "snippet": "<b>Deep</b> RNN: Multiple <b>layers</b> are present. As a result, the DL <b>model</b> can extract more <b>hierarchical</b> information. You may also find it interesting \u2013 Business Intelligence Consulting Services. LSTM: Long Short-Term Memory. It\u2019s also a type of RNN. However, LSTM has feedback connections. This means that it can process not only single data points (such as images) but also entire sequences of data (such as audio or video files)[3]. LSTM derives from neural network architectures and is based on the ...", "dateLastCrawled": "2022-02-02T05:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What&#39;s the difference between &quot;<b>deep</b> learning&quot; and multilevel ...", "url": "https://stats.stackexchange.com/questions/60153/whats-the-difference-between-deep-learning-and-multilevel-hierarchical-modeli", "isFamilyFriendly": true, "displayUrl": "https://stats.<b>stack</b>exchange.com/questions/60153", "snippet": "It looks <b>like</b> the number of nodes in a typical &quot;<b>deep</b> learning&quot; application is larger and uses a generic <b>hierarchical</b> form, whereas applications of multilevel modeling typically uses <b>a hierarchical</b> relationships that mimic the generative process being modeled. Using a generic hierarchy in an applied statistics (<b>hierarchical</b> modeling) domain would be regarded as an &quot;incorrect&quot; <b>model</b> of the phenomena, whereas modeling a domain-specific hierarchy might be regarded as subverting the objective of ...", "dateLastCrawled": "2022-01-11T21:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>25 : Deep Learning and Graphical Models</b>", "url": "https://www.cs.cmu.edu/~epxing/Class/10708-15/notes/10708_scribe_lecture25.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~epxing/Class/10708-15/notes/10708_scribe_lecture25.pdf", "snippet": "mation <b>processing</b> stages in <b>hierarchical</b> architectures are exploited for pattern classi cation and for feature representation[1]. <b>Deep</b> Boltzman Machines(DBN), <b>Deep</b> Neural Networks(DNN) and <b>Deep</b> auto-encoder - all fall under this category of learning techniques. They di er from traditional machine learning approaches in the sense that there is a lot of feature engineering involved in the traditional techniques, <b>deep</b> learning techniques learn their own relevant features. Apart from classi ...", "dateLastCrawled": "2022-01-21T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "60 Advanced <b>Deep</b> Learning Interview Questions (ANSWERED) To Crush Your ...", "url": "https://www.mlstack.cafe/blog/deep-learning-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.ml<b>stack</b>.cafe/blog/<b>deep</b>-learning-interview-questions", "snippet": "<b>Deep</b> learning or Neural Network Architectures have been used to solve a multitude of problems in various different fields <b>like</b> vision, natural language <b>processing</b>. Architectures <b>like</b> the LeNet, VGG-16, Inception have become part of the day-to-day toolkits of almost every practitioner out there. Follow along and prepare yourself with 60 Advanced <b>Deep</b> Learning Interview Questions and Answers and pass your next Machine Learning and Data Science Interview.", "dateLastCrawled": "2022-02-03T17:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Hierarchical</b> Transformers Are More Efficient Language Models | DeepAI", "url": "https://deepai.org/publication/hierarchical-transformers-are-more-efficient-language-models", "isFamilyFriendly": true, "displayUrl": "https://<b>deep</b>ai.org/.../<b>hierarchical</b>-transformers-are-more-efficient-language-<b>models</b>", "snippet": "We use the best performing upsampling and downsampling <b>layers</b> to create Hourglass - <b>a hierarchical</b> Transformer language <b>model</b>. Hourglass improves upon the Transformer baseline given the same amount of computation and can yield the same results as Transformers more efficiently. In particular, Hourglass sets new state-of-the-art for Transformer models on the ImageNet32 generation task and improves language modeling efficiency on the widely studied enwik8 benchmark. READ FULL TEXT VIEW PDF ...", "dateLastCrawled": "2022-01-21T00:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "HDMapGen: <b>A Hierarchical</b> Graph Generative <b>Model</b> of High Definition Maps ...", "url": "https://deepai.org/publication/hdmapgen-a-hierarchical-graph-generative-model-of-high-definition-maps", "isFamilyFriendly": true, "displayUrl": "https://<b>deep</b>ai.org/publication/hdmapgen-<b>a-hierarchical</b>-graph-generative-<b>model</b>-of-high...", "snippet": "The results show that the proposed <b>hierarchical</b> graph generative <b>model</b> HDMapGen (both coordinate-first and topology-first) generate the highest quality maps and vastly outperform other methods. They capture the typical features of HD maps, including patterns <b>like</b> the overall layouts, the crossroads, parallel lanes, . Moreover, they are capable of generating maps with different city styles. For the maps generated from HDMapGen with the", "dateLastCrawled": "2022-01-21T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Top <b>Deep Learning Interview Questions</b> &amp; Answers for 2022 | Simplilearn", "url": "https://www.simplilearn.com/tutorials/deep-learning-tutorial/deep-learning-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/<b>deep</b>-learning-tutorial/<b>deep</b>-learning-interview...", "snippet": "Neural Networks are used in <b>deep</b> learning algorithms <b>like</b> CNN, RNN, GAN, etc. 3. What Is a Multi-layer Perceptron(MLP)? As in Neural Networks, MLPs have an input layer, a hidden layer, and an output layer. It has the same structure as a single layer perceptron with one or more hidden <b>layers</b>. A single layer perceptron can classify only linear separable classes with binary output (0,1), but MLP can classify nonlinear classes. Except for the input layer, each node in the other <b>layers</b> uses a ...", "dateLastCrawled": "2022-02-02T12:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What are the advantages of <b>stacking</b> multiple LSTMs? - Cross Validated", "url": "https://stats.stackexchange.com/questions/163304/what-are-the-advantages-of-stacking-multiple-lstms", "isFamilyFriendly": true, "displayUrl": "https://stats.<b>stack</b>exchange.com/questions/163304/what-are-the-advantages-of-<b>stacking</b>...", "snippet": "In that case the main reason for <b>stacking</b> <b>LSTM</b> is to allow for greater <b>model</b> complexity. In case of a simple feedforward net we <b>stack</b> <b>layers</b> to create <b>a hierarchical</b> feature representation of the input data to then use for some machine learning task. The same applies for stacked <b>LSTM</b>&#39;s. At every time step an <b>LSTM</b>, besides the recurrent input. If the input is already the result from an <b>LSTM</b> layer (or a feedforward layer) then the current <b>LSTM</b> can create a more complex feature representation ...", "dateLastCrawled": "2022-02-02T15:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Deep learning</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Deep_learning", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Deep_learning</b>", "snippet": "Definition. <b>Deep learning</b> is a class of machine learning algorithms that: 199\u2013200 uses multiple <b>layers</b> to progressively extract higher-level features from the raw input. For example, in image <b>processing</b>, lower <b>layers</b> may identify edges, while higher <b>layers</b> may identify the concepts relevant to a human such as digits or letters or faces.. Overview. Most modern <b>deep learning</b> models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can ...", "dateLastCrawled": "2022-02-02T23:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Deep</b> Learning in Medical Image Analysis", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5479722/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5479722", "snippet": "<b>Similar</b> to SAE, it is possible to <b>stack</b> multiple RBMs for <b>deep</b> architecture construction, which results in a single probabilistic <b>model</b>, called a <b>deep</b> belief network (DBN). A DBN has one visible layer v and a series of hidden <b>layers</b> h (1), \u00b7\u00b7\u00b7, h (L) as shown in Fig. 2(b). Note that once stacking multiple RBMs hierarchically, while the top two <b>layers</b> still form an undirected generative <b>model</b>, i.e., RBM, the lower <b>layers</b> form directed generative models. Hence, the joint distribution of the ...", "dateLastCrawled": "2022-01-25T21:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>What is Deep Learning? - PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2021/04/17/what-is-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/04/17/<b>what-is-deep-learning</b>", "snippet": "<b>Deep</b> learning algorithms learn in a <b>hierarchical</b> fashion and therefore <b>stack</b> multiple <b>layers</b> on top of each other to learn increasingly more abstract concepts. A network should have &gt; 2 <b>layers</b> to be considered \u201c<b>deep</b>\u201d (this is my anecdotal opinion based on decades of neural network research).", "dateLastCrawled": "2022-01-26T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Deep</b> Learning 101 \u2014 What is a Neural Network? The Perceptron and the ...", "url": "https://medium.com/analytics-vidhya/deep-learning-101-what-is-a-neural-network-the-perceptron-and-the-multi-layer-perceptron-c50d9bc49e42", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>deep</b>-learning-101-what-is-a-neural-network-the...", "snippet": "The \u201c<b>Deep</b>\u201d term comes from the complexity of the Neural Network, as it is constructed as a <b>stack</b> of <b>layers</b> from which we extract <b>hierarchical</b> data representations from our inputs. The higher ...", "dateLastCrawled": "2021-08-06T08:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What&#39;s the difference between &quot;<b>deep</b> learning&quot; and multilevel ...", "url": "https://stats.stackexchange.com/questions/60153/whats-the-difference-between-deep-learning-and-multilevel-hierarchical-modeli", "isFamilyFriendly": true, "displayUrl": "https://stats.<b>stack</b>exchange.com/questions/60153", "snippet": "It looks like the number of nodes in a typical &quot;<b>deep</b> learning&quot; application is larger and uses a generic <b>hierarchical</b> form, whereas applications of multilevel modeling typically uses a <b>hierarchical</b> relationships that mimic the generative process being modeled. Using a generic hierarchy in an applied statistics (<b>hierarchical</b> modeling) domain would be regarded as an &quot;incorrect&quot; <b>model</b> of the phenomena, whereas modeling a domain-specific hierarchy might be regarded as subverting the objective of ...", "dateLastCrawled": "2022-01-11T21:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>25 : Deep Learning and Graphical Models</b>", "url": "https://www.cs.cmu.edu/~epxing/Class/10708-15/notes/10708_scribe_lecture25.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~epxing/Class/10708-15/notes/10708_scribe_lecture25.pdf", "snippet": "mation <b>processing</b> stages in <b>hierarchical</b> architectures are exploited for pattern classi cation and for feature representation[1]. <b>Deep</b> Boltzman Machines(DBN), <b>Deep</b> Neural Networks(DNN) and <b>Deep</b> auto-encoder - all fall under this category of learning techniques. They di er from traditional machine learning approaches in the sense that there is a lot of feature engineering involved in the traditional techniques, <b>deep</b> learning techniques learn their own relevant features. Apart from classi ...", "dateLastCrawled": "2022-01-21T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Deep</b> reservoir computing: A critical experimental analysis - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0925231217307567", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231217307567", "snippet": "Another approach consists in learning all the weights in the <b>stack</b> of recurrent <b>layers</b>, ... Note that deepESN and deepESN-IA show a <b>similar</b> <b>hierarchical</b> organization of time-scales (<b>similar</b> values of KT and SF) and in both cases the higher <b>layers</b> of the architecture present longer time-scales than the corresponding standard ESN (as can be seen in the plots of Fig. 3(a) and (b)). However deepESN-IA shows a reduced separation of time-scales with respect to deepESN, as can be seen graphically ...", "dateLastCrawled": "2022-01-22T05:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Top <b>Deep Learning Interview Questions</b> &amp; Answers for 2022 | Simplilearn", "url": "https://www.simplilearn.com/tutorials/deep-learning-tutorial/deep-learning-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/<b>deep</b>-learning-tutorial/<b>deep</b>-learning-interview...", "snippet": "It\u2019s a pre-<b>processing</b> step to eliminate data redundancy. Often, data comes in, and you get the same information in different formats. In these cases, you should rescale values to fit into a particular range, achieving better convergence. 5. What is the Boltzmann Machine? One of the most basic <b>Deep</b> Learning models is a Boltzmann Machine, resembling a simplified version of the Multi-Layer Perceptron. This <b>model</b> features a visible input layer and a hidden layer -- just a two-layer neural net ...", "dateLastCrawled": "2022-02-02T12:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Task-<b>driven hierarchical deep neural networkmodels</b> of the ...", "url": "https://www.researchgate.net/publication/341259273_Task-driven_hierarchical_deep_neural_networkmodels_of_the_proprioceptive_pathway", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341259273_Task-driven_<b>hierarchical</b>_<b>deep</b>...", "snippet": "Each <b>model</b> is comprised of one or more <b>processing</b> <b>layers</b> as shown here. <b>Processing</b> of spatial and temporal information takes place through a series of 1-D or 2-D convolutional <b>layers</b>.", "dateLastCrawled": "2022-01-07T04:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Basic CNN Architecture: Explaining 5 <b>Layers</b> of Convolutional Neural ...", "url": "https://www.upgrad.com/blog/basic-cnn-architecture/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/basic-cnn-architecture", "snippet": "In Python Programming, the <b>model</b> type that is most commonly used is the Sequential type. It is the easiest way to build a CNN <b>model</b> in keras. It permits us to build a <b>model</b> layer by layer. The \u2018add()\u2019 function is used to add <b>layers</b> to the <b>model</b>. As explained above, for the LeNet-5 architecture, there are two Convolution and Pooling pairs ...", "dateLastCrawled": "2022-02-03T01:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Modeling language and cognition with <b>deep</b> unsupervised learning: a ...", "url": "https://www.researchgate.net/profile/Alberto-Testolin/publication/256083992_Modeling_Language_and_Cognition_with_Deep_Unsupervised_LearningA_Tutorial_Overview/links/02e7e52208024258ba000000/Modeling-Language-and-Cognition-with-Deep-Unsupervised-LearningA-Tutorial-Overview.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/profile/Alberto-Testolin/publication/256083992_<b>Model</b>ing...", "snippet": "data by \ufb01tting a <b>hierarchical</b> generative <b>model</b>. In this article we discuss the theoretical foundations of this approach and we review key issues related to training, testing and analysis of <b>deep</b> ...", "dateLastCrawled": "2021-11-07T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Hierarchical</b> Transformers Are More Efficient Language Models | DeepAI", "url": "https://deepai.org/publication/hierarchical-transformers-are-more-efficient-language-models", "isFamilyFriendly": true, "displayUrl": "https://<b>deep</b>ai.org/.../<b>hierarchical</b>-transformers-are-more-efficient-language-<b>models</b>", "snippet": "We use the best performing upsampling and downsampling <b>layers</b> to create Hourglass - a <b>hierarchical</b> Transformer language <b>model</b>. Hourglass improves upon the Transformer baseline given the same amount of computation and <b>can</b> yield the same results as Transformers more efficiently. In particular, Hourglass sets new state-of-the-art for Transformer models on the ImageNet32 generation task and improves language modeling efficiency on the widely studied enwik8 benchmark. READ FULL TEXT VIEW PDF ...", "dateLastCrawled": "2022-01-21T00:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>25 : Deep Learning and Graphical Models</b>", "url": "https://www.cs.cmu.edu/~epxing/Class/10708-15/notes/10708_scribe_lecture25.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~epxing/Class/10708-15/notes/10708_scribe_lecture25.pdf", "snippet": "mation <b>processing</b> stages in <b>hierarchical</b> architectures are exploited for pattern classi cation and for feature representation[1]. <b>Deep</b> Boltzman Machines(DBN), <b>Deep</b> Neural Networks(DNN) and <b>Deep</b> auto-encoder - all fall under this category of learning techniques. They di er from traditional machine learning approaches in the sense that there is a lot of feature engineering involved in the traditional techniques, <b>deep</b> learning techniques learn their own relevant features. Apart from classi ...", "dateLastCrawled": "2022-01-21T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>What is Deep Learning? - PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2021/04/17/what-is-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/04/17/<b>what-is-deep-learning</b>", "snippet": "We <b>can</b> view this process as <b>hierarchical</b> learning: each layer in the network uses the output of previous <b>layers</b> as \u201cbuilding blocks\u201d to construct increasingly more abstract concepts. These <b>layers</b> are learned automatically \u2014 there is no hand-crafted feature engineering taking place in our network. Figure 7 compares classic image classification algorithms using hand-crafted features to representation learning via <b>deep</b> learning and Convolutional Neural Networks. Figure 7: Left ...", "dateLastCrawled": "2022-01-26T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Numerosity discrimination in <b>deep</b> neural networks: Initial competence ...", "url": "http://ccnl.psy.unipd.it/publications/numerosity-discrimination-in-deep-neural-networks-initial-competence-developmental-refinement-and-experience-statistics/at_download/file", "isFamilyFriendly": true, "displayUrl": "ccnl.psy.unipd.it/publications/numerosity-discrimination-in-<b>deep</b>-neural-networks...", "snippet": "perceptual <b>processing</b> takes place in a <b>hierarchical</b> <b>processing</b> sys-tem, with neurons in the lower <b>layers</b> encoding simple visual prop - erties that are successively combined into more complex features (Fukushima, 1980; McClelland &amp; Rumelhart, 1981; Riesenhuber &amp; Poggio, 1999). Subsequently, it was demonstrated that \u2018<b>deep</b>\u2019 neu-ral networks composed of several <b>layers</b> of non-linear <b>processing</b> units <b>can</b> be effectively trained with the simple objective of re-constructing their own input ...", "dateLastCrawled": "2021-11-04T00:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "AI SERIES: <b>Deep</b> into <b>Deep</b> Learning - Experfy", "url": "https://resources.experfy.com/ai-ml/ai-series-deep-into-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://resources.experfy.com/ai-ml/ai-series-<b>deep</b>-into-<b>deep</b>-learning", "snippet": "<b>Deep</b> learning is a technique that, as many other AI related models, is inspired by our natural brain. In particular, Neural Networks, which are the underlying architecture of <b>Deep</b> Learning, are loosely analogous to biological neurons, albeit greatly simplified, and the connections between nodes <b>can</b> <b>be thought</b> of as in some way reflecting connections between neurons. Thanks to a growing availability of computing <b>processing</b> power, neural networks have increased the number of hidden <b>layers</b> they ...", "dateLastCrawled": "2022-01-14T03:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Deep Learning for Natural Language Processing</b>", "url": "https://www.eecis.udel.edu/~vijay/fall13/snlp/lit-survey/DeepLearning.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.eecis.udel.edu/~vijay/fall13/snlp/lit-survey/<b>Deep</b>Learning.pdf", "snippet": "of <b>layers</b> with learned weights could be stacked to initialize a <b>deep</b> supervised predictor, such as a neural network classifier, or a <b>deep</b> generative <b>model</b>, such as a <b>Deep</b> Boltzmann Machine (Salakhutdinov and Hinton 2009). 2.1 Stacked auto-encoder One good illustration of the idea of greedy", "dateLastCrawled": "2022-01-30T08:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The fall of RNN / <b>LSTM</b>. We fell for Recurrent neural networks\u2026 | by ...", "url": "https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-fall-of-rnn-<b>lstm</b>-2d1594c74ce0", "snippet": "Note 1: <b>Hierarchical</b> neural attention is similar to the ideas in WaveNet. But instead of a convolutional neural network we use <b>hierarchical</b> attention modules. Also: <b>Hierarchical</b> neural attention <b>can</b> be also bi-directional. Note 2: RNN and <b>LSTM</b> are memory-bandwidth limited problems (see this for details). The <b>processing</b> unit(s) need as much ...", "dateLastCrawled": "2022-02-01T10:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Unsupervised Deep Auditory Model Using</b> <b>Stack</b> of Convolutional RBMs for ...", "url": "https://www.researchgate.net/publication/307889389_Unsupervised_Deep_Auditory_Model_Using_Stack_of_Convolutional_RBMs_for_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/307889389_Unsupervised_<b>Deep</b>_Auditory_<b>Model</b>...", "snippet": "A <b>stack</b> of RBMs <b>can</b> also be used to initialize a <b>deep</b> Boltzmann machine that has many hidden <b>layers</b>. Combining this initialization method with a new method for fine-tuning the weights finally ...", "dateLastCrawled": "2022-01-03T14:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is time complexity of training and predicting with <b>deep</b> neural ...", "url": "https://www.quora.com/What-is-time-complexity-of-training-and-predicting-with-deep-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-time-complexity-of-training-and-predicting-with-<b>deep</b>...", "snippet": "Answer: Time complexity would be n, where n is the number of hidden <b>layers</b> including softmax. Predicting the output of a neural network after training is just a sum of products.", "dateLastCrawled": "2022-01-11T05:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep</b> Learning in Medical Image Analysis", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5479722/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5479722", "snippet": "Their <b>model</b> was a 3D-CNN, composed of two interconnected pathways, i.e., convolutional pathway that learned <b>hierarchical</b> feature representations as other CNNs did and deconvolutional pathway that consisted of deconvolutional and unpooling <b>layers</b> with shortcut connections to the corresponding convolutional <b>layers</b>. Specifically, the deconvolutional <b>layers</b> were designed to calculate abstract segmentation features from the features represented from the convolutional <b>layers</b> and the activations of ...", "dateLastCrawled": "2022-01-25T21:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Deep</b> Learning and Its Applications to Signal and Information <b>Processing</b> T", "url": "https://www.cse.fau.edu/~xqzhu/courses/cap5615/reading/deep.learning.signal.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cse.fau.edu/~xqzhu/courses/cap5615/reading/<b>deep</b>.learning.signal.pdf", "snippet": "widened its scope <b>compared</b> with just a few years ago [4], and machine learning has been an important technical area of the signal <b>processing</b> society. Since 2006, <b>deep</b> learning\u2014a new area of machine learning research\u2014has emerged [7], impacting a wide range of signal and information <b>processing</b> work within the traditional and the new, widened scopes. Various workshops, such as the 2009 ICML Workshop on Learning Feature Hierarchies; the 2008 NIPS <b>Deep</b> Learning Workshop: Foundations and ...", "dateLastCrawled": "2022-02-03T08:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>What is Deep Learning? - PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2021/04/17/what-is-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/04/17/<b>what-is-deep-learning</b>", "snippet": "We <b>can</b> view this process as <b>hierarchical</b> learning: each layer in the network uses the output of previous <b>layers</b> as \u201cbuilding blocks\u201d to construct increasingly more abstract concepts. These <b>layers</b> are learned automatically \u2014 there is no hand-crafted feature engineering taking place in our network. Figure 7 compares classic image classification algorithms using hand-crafted features to representation learning via <b>deep</b> learning and Convolutional Neural Networks. Figure 7: Left ...", "dateLastCrawled": "2022-01-26T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "60 Advanced <b>Deep</b> Learning Interview Questions (ANSWERED) To Crush Your ...", "url": "https://www.mlstack.cafe/blog/deep-learning-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.ml<b>stack</b>.cafe/blog/<b>deep</b>-learning-interview-questions", "snippet": "Machine Learning is less dependent on the amount of data as <b>compared</b> to <b>deep</b> learning. <b>Deep</b> Learning requires a lot of data to give high accuracy. It would take thousands or millions of data points which are trained for days or weeks to give an acceptable accurate <b>model</b>. Having Machine Learning, Data Science or Python Interview? Check \ud83d\udc49 51 <b>Deep</b> Learning Interview Questions. Source: ibm.com. Q4: How <b>can</b> Neural Networks be Unsupervised? Junior . Unsupervised Learning 27 . Answer. Neural ...", "dateLastCrawled": "2022-02-03T17:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Unsupervised Deep Auditory Model Using</b> <b>Stack</b> of Convolutional RBMs for ...", "url": "https://www.researchgate.net/publication/307889389_Unsupervised_Deep_Auditory_Model_Using_Stack_of_Convolutional_RBMs_for_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/307889389_Unsupervised_<b>Deep</b>_Auditory_<b>Model</b>...", "snippet": "A <b>stack</b> of RBMs <b>can</b> also be used to initialize a <b>deep</b> Boltzmann machine that has many hidden <b>layers</b>. Combining this initialization method with a new method for fine-tuning the weights finally ...", "dateLastCrawled": "2022-01-03T14:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Hierarchical</b> Transformers Are More Efficient Language Models | DeepAI", "url": "https://deepai.org/publication/hierarchical-transformers-are-more-efficient-language-models", "isFamilyFriendly": true, "displayUrl": "https://<b>deep</b>ai.org/.../<b>hierarchical</b>-transformers-are-more-efficient-language-<b>models</b>", "snippet": "We use the best performing upsampling and downsampling <b>layers</b> to create Hourglass - a <b>hierarchical</b> Transformer language <b>model</b>. Hourglass improves upon the Transformer baseline given the same amount of computation and <b>can</b> yield the same results as Transformers more efficiently. In particular, Hourglass sets new state-of-the-art for Transformer models on the ImageNet32 generation task and improves language modeling efficiency on the widely studied enwik8 benchmark. READ FULL TEXT VIEW PDF ...", "dateLastCrawled": "2022-01-21T00:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Top <b>Deep Learning Interview Questions</b> &amp; Answers for 2022 | Simplilearn", "url": "https://www.simplilearn.com/tutorials/deep-learning-tutorial/deep-learning-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/<b>deep</b>-learning-tutorial/<b>deep</b>-learning-interview...", "snippet": "Companies are now on the lookout for skilled professionals who <b>can</b> use <b>deep</b> learning and machine learning techniques to build models that <b>can</b> mimic human behavior. As per indeed.com, the average salary for a <b>deep</b> learning engineer in the United States is $133,580 per annum. In this tutorial, you will learn the top 45 <b>Deep Learning interview questions</b> that are frequently asked. Build <b>deep</b> learning models in TensorFlow and learn the TensorFlow open-source framework with the <b>Deep</b> Learning ...", "dateLastCrawled": "2022-02-02T12:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "HDMapGen: A <b>Hierarchical</b> Graph Generative <b>Model</b> of High Definition Maps ...", "url": "https://deepai.org/publication/hdmapgen-a-hierarchical-graph-generative-model-of-high-definition-maps", "isFamilyFriendly": true, "displayUrl": "https://<b>deep</b>ai.org/publication/hdmapgen-a-<b>hierarchical</b>-graph-generative-<b>model</b>-of-high...", "snippet": "For PlainGen, we find the <b>model</b> to completely fail for this task, as it is too challenging to generate a graph with a much large number of nodes and edges in this setting, <b>compared</b> to the <b>hierarchical</b> graph. For SketchRNN, we find the <b>model</b> <b>can</b> learn the overall geometric patterns. However, there are a large number of problematic cut-offs or dead-ends occurring in the generated lanes. This is because, during the sequential data generation, it is possible to stop generating a consecutive ...", "dateLastCrawled": "2022-01-21T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The OSI <b>Model</b> \u2013 The 7 <b>Layers</b> of Networking Explained in Plain English", "url": "https://www.freecodecamp.org/news/osi-model-networking-layers-explained-in-plain-english/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>freecodecamp</b>.org/news/osi-<b>model</b>-networking-<b>layers</b>-explained-in-plain-english", "snippet": "What the OSI <b>model</b> is; The purpose of each of the 7 <b>layers</b>; The problems that <b>can</b> happen at each of the 7 <b>layers</b>; The difference between TCP/IP <b>model</b> and the OSI <b>model</b>; Common Networking Terms. Here are some common networking terms that you should be familiar with to get the most out of this article. I\u2019ll use these terms when I talk about OSI ...", "dateLastCrawled": "2022-02-02T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Convolutional Neural Networks</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/engineering/convolutional-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/engineering/<b>convolutional-neural-networks</b>", "snippet": "Inception-v3 is a popular <b>deep</b> learning <b>model</b> and is 42 <b>layers</b> <b>deep</b> [108]. It is computationally efficient since it achieved similar performance as VGG but with fewer parameters. It is made of inception blocks that have towers-containing kernels of different sizes. The larger kernels are aimed to capture macro features, whereas smaller ones aim to detect minute details. A large number of retinal diagnostics papers both in OCT and fundus imaging have used Inception-v3 with a majority of them ...", "dateLastCrawled": "2022-01-30T22:53:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://<b>deep</b>ai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor <b>model</b> fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Deep learning vs. machine learning</b>: What\u2019s the difference?", "url": "https://www.zendesk.com/blog/machine-learning-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.zendesk.com/blog/<b>machine</b>-<b>learning</b>-and-<b>deep</b>-<b>learning</b>", "snippet": "A <b>deep</b> <b>learning</b> <b>model</b> is able to learn through its own method of computing\u2014a technique that makes it seem like it has its own brain. To recap, the key differences between <b>machine</b> <b>learning</b> and <b>deep</b> <b>learning</b> are: <b>Machine</b> <b>learning</b> uses algorithms to parse data, learn from that data, and make informed decisions based on what it has learned.", "dateLastCrawled": "2022-01-29T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor <b>model</b> fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "In addition to three invited talks, the meeting also included workshops on CBR and <b>Deep</b> <b>Learning</b>, Computer <b>Analogy</b>, and Process-Oriented CBR, as well as a Doctoral Consortium, the ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Analogies between Biology and <b>Deep</b> <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "There are a number of exciting connections between physics and <b>deep</b> <b>learning</b>. Perhaps the most discussed are scaling laws (e.g. ... Evolvability seems at least partially analogous to what we call &quot;meta-<b>learning</b>&quot; in <b>machine</b> <b>learning</b>, a broad category of ideas around <b>machine</b> <b>learning</b> systems <b>learning</b> to learn better (see discussion in Gajewski et al, 2019). At the same time, if one tries to apply some of the ideas we include in meta-<b>learning</b> to evolution, they often seem much broader than ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Using <b>Deep</b> <b>Learning</b> for Image Analogies | by Tomer Amit | Towards Data ...", "url": "https://towardsdatascience.com/using-deep-learning-for-image-analogies-aa2e7d7af337", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-<b>deep</b>-<b>learning</b>-for-image-analogies-aa2e7d7af337", "snippet": "Another concept, related to language processing and <b>deep</b> <b>learning</b>, is Word Embeddings. Given a large corpus of text, say with 100,000 words, we build an embedding, or a mapping, giving each word a vector in a smaller space of dimension n=500, say. This kind of dimesionality reduction gives us a compact representation of the words. And indeed, Word Embeddings are useful for many tasks, including sentiment analysis, <b>machine</b> translation, and also Word Analogies , i.e, solving an <b>analogy</b> of the ...", "dateLastCrawled": "2022-01-19T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Types of Machine Learning</b> | Different Methods and Kinds of <b>Model</b>", "url": "https://www.educba.com/types-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>types-of-machine-learning</b>", "snippet": "Introduction to <b>Types of Machine Learning</b>. <b>Machine</b> <b>learning</b> is the subfield of AI that focuses on the development of the computer programs which have access to data by providing a system with the ability to learn and improve automatically. For example, finding patterns in the database without any human interventions or actions is based upon the ...", "dateLastCrawled": "2022-02-02T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Difference Between Algorithm and Model</b> in <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/difference-between-algorithm-and-model-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>difference-between-algorithm-and-model</b>-", "snippet": "A <b>machine learning</b> <b>model</b> is more challenging for a beginner because there is not a clear <b>analogy</b> with other algorithms in computer science. For example, the sorted list output of a sorting algorithm is not really a <b>model</b>. The best <b>analogy</b> is to think of the <b>machine learning</b> <b>model</b> as a \u201cprogram.\u201d The <b>machine learning</b> <b>model</b> \u201cprogram\u201d is comprised of both data and a procedure for using the data to make a prediction. For example, consider the linear regression algorithm and resulting ...", "dateLastCrawled": "2022-01-31T01:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine</b> <b>Learning</b> with Spreadsheets! Part 1: <b>Gradient</b> Descent and ...", "url": "https://medium.com/excel-with-ml/machine-learning-with-spreadsheets-part-1-gradient-descent-f9316676db9b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/excel-with-ml/<b>machine</b>-<b>learning</b>-with-spreadsheets-part-1-<b>gradient</b>...", "snippet": "<b>Gradient</b> descent: Step-by-step spreadsheets show you how machines learn without the code. Go under the hood with backprop, partial derivatives, and <b>gradient</b> descent.", "dateLastCrawled": "2022-01-29T01:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Li Hongyi &quot;Deep <b>Learning</b>&quot; study notes-GNN - Programmer Sought", "url": "https://www.programmersought.com/article/25166341055/", "isFamilyFriendly": true, "displayUrl": "https://www.programmersought.com/article/25166341055", "snippet": "The flat model has a poorer <b>learning</b> effect than the deep model, because the <b>deep model is like</b> a modular, each layer only recognizes some features, and t... 2020 Li Hongyi study notes-64.Deep Reinforcement <b>Learning</b>. 1. Concept: The content in this section is just some introductory aspects of reinforcement <b>learning</b> (Scratching the surface). First, I will start with examples, and then take the bee on the red and wh... Li Hongyi &quot;Deep <b>Learning</b> Language Processing&quot; study notes. Deep <b>Learning</b>-Li ...", "dateLastCrawled": "2022-01-13T08:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Li Hongyi study in deep <b>learning</b> (seven) - Programmer Sought", "url": "https://www.programmersought.com/article/38149282673/", "isFamilyFriendly": true, "displayUrl": "https://www.programmersought.com/article/38149282673", "snippet": "Introduced the development of artificial intelligence, <b>machine</b> <b>learning</b>, deep <b>learning</b>, and the relationship between the three. This paper introduces the related technologies of <b>machine</b> <b>learning</b>: Scenario, problem (task), and methods or models that solve problems (Method). return Introduced the definition of the regression: Find a function function, output a value Y by entering the feature X. Model step: STEP1 model assumption (model), STEP2 model evaluation (policies, loss functions), STEP3 ...", "dateLastCrawled": "2022-01-27T12:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Deep Learning, Pachinko, and James Watt: Efficiency</b> is the Driver of ...", "url": "https://inverseprobability.com/2016/03/04/deep-learning-and-uncertainty", "isFamilyFriendly": true, "displayUrl": "https://inverseprobability.com/2016/03/04/deep-<b>learning</b>-and-uncertainty", "snippet": "In <b>machine</b> <b>learning</b> this is known as deep <b>learning</b>. For some authors it is related to the brain or a fundamental way of thinking about AI, but we can simply think of it as a sensible idea of applying a set of simple transformations to an image to built a complex transformation. The challenge of <b>machine</b> <b>learning</b> is how to determine what these transformations should be. Each of the simpler deterministic transformations can actually have very many parameters. In the case of DeepFace there are ...", "dateLastCrawled": "2021-12-08T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Deep <b>Learning, Pachinko, and James Watt: Efficiency</b> is the Driver of ...", "url": "https://www.kdnuggets.com/2016/06/deep-learning-pachinko-james-watt-efficiency-driver-uncertainty.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2016/06/deep-<b>learning</b>-pachinko-james-watt-efficiency-driver...", "snippet": "In <b>machine</b> <b>learning</b> this is known as deep <b>learning</b>. For some authors it is related to the brain or a fundamental way of thinking about AI, but we can simply think of it as a sensible idea of applying a set of simple transformations to an image to built a complex transformation. The challenge of <b>machine</b> <b>learning</b> is how to determine what these transformations should be. Each of the simpler deterministic transformations can actually have very many parameters. In the case of DeepFace there are ...", "dateLastCrawled": "2022-01-15T03:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Wide and deep <b>learning</b> for <b>peer-to-peer lending</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S095741741930377X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S095741741930377X", "snippet": "After training the model, it is crucial to evaluate the performance of the model on the test samples and compare its performance with the benchmarks, namely, deep <b>learning</b> (DP), wide <b>learning</b> (WL), random forest (RF), gradient boosting regression algorithm (GB), and support vector <b>machine</b> (SVM). 15 Precision and recall are used as performance metrics of the models. It is well-known that in the presence of imbalanced dataset, accuracy is not a proper performance metric, and precision and ...", "dateLastCrawled": "2021-12-28T02:33:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>Learning</b> Demystified. From Optimization to Deep <b>Learning</b> | by ...", "url": "https://medium.com/walmartglobaltech/deep-learning-demystified-693a2d7ec79e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/walmartglobaltech/deep-<b>learning</b>-demystified-693a2d7ec79e", "snippet": "What it says is that a <b>deep model can be thought of as</b> a function N, parameterized by \u03b8, that given the input data d, ... <b>Learning</b> <b>Machine</b> <b>Learning</b> \u2014 Part 4: Neural Network Theory. Ryan ...", "dateLastCrawled": "2022-01-04T10:16:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(deep model)  is like +(a hierarchical stack of processing layers)", "+(deep model) is similar to +(a hierarchical stack of processing layers)", "+(deep model) can be thought of as +(a hierarchical stack of processing layers)", "+(deep model) can be compared to +(a hierarchical stack of processing layers)", "machine learning +(deep model AND analogy)", "machine learning +(\"deep model is like\")", "machine learning +(\"deep model is similar\")", "machine learning +(\"just as deep model\")", "machine learning +(\"deep model can be thought of as\")", "machine learning +(\"deep model can be compared to\")"]}