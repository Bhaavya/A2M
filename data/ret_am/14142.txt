{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Decision</b> Tree for <b>Regression</b> \u2014 The <b>Recipe</b> | by Akshaya Sriram ...", "url": "https://medium.com/analytics-vidhya/decision-tree-for-regression-the-recipe-74f7628b8a0", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>decision</b>-tree-for-<b>regression</b>-the-<b>recipe</b>-74f7628b8a0", "snippet": "<b>Decision</b> Tree for <b>Regression</b> \u2014 The <b>Recipe</b>. Akshaya Sriram . Follow. Jun 3, 2020 \u00b7 7 min read. <b>Regression</b> refers to identifying the underlying relationship between the dependent and independent ...", "dateLastCrawled": "2022-01-29T15:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Chapter 8 <b>Regression</b> II: linear <b>regression</b> | Data Science: A First ...", "url": "https://ubc-dsci.github.io/introduction-to-datascience/regression2.html", "isFamilyFriendly": true, "displayUrl": "https://ubc-dsci.github.io/introduction-to-datascience/<b>regression</b>2.html", "snippet": "<b>Like</b> KNN <b>regression</b>, simple linear <b>regression</b> involves predicting a numerical response variable (<b>like</b> race time, house price, or height); but how it makes those predictions for a new observation is quite different from KNN <b>regression</b>. Instead of looking at the K nearest neighbors and averaging over their values for a prediction, in simple linear <b>regression</b>, we create a straight line of best fit through the training data and then \u201clook up\u201d the prediction using the line.", "dateLastCrawled": "2022-02-01T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Recipe: 002 Marvel Cinematic Universe Regression Model</b> \u2013 Pancake ...", "url": "https://pancakebreakfaststats.com/2018/10/07/recipe-002-marvel-cinematic-universe-regression-model/", "isFamilyFriendly": true, "displayUrl": "https://pancakebreakfaststats.com/2018/10/07/<b>recipe-002-marvel-cinematic-universe</b>...", "snippet": "<b>Regression</b> Modeling <b>Recipe: 002 Marvel Cinematic Universe Regression Model</b>. October 7, 2018 August 25, 2019 ferrt041. There\u2019s is no argument against the Marvel Cinematic Universe being a financial success. I\u2019ll try to identify variables which can equate to box office success. The goal is to fit a <b>regression</b> <b>model</b> to Box Office USD for Marvel Cinematic Movie releases. *At the time of cooking Ant-man and the Wasp did not have finalized Box Office USD data (This movie was excluded.) \u2013 TF ...", "dateLastCrawled": "2022-01-01T05:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>How to do regression using Dask</b>?", "url": "https://www.projectpro.io/recipes/do-regression-dask", "isFamilyFriendly": true, "displayUrl": "https://www.projectpro.io/<b>recipes</b>/do-<b>regression</b>-dask", "snippet": "<b>How to do regression using Dask</b>? This <b>recipe</b> helps you <b>do regression using Dask</b> Last Updated: 05 May 2021. ... Step 2- Making a <b>Regression</b> <b>Model</b>. Seperating the dataset into X, y by using predefined make_<b>regression</b>() function from Dask. We will initialize the Linear <b>Regression</b> and fit the dataset into the <b>model</b>, and calculate the score by the conventional method. X, y = make_<b>regression</b>() lr = LinearRegression() lr.fit(X, y) z=lr.predict(X) lr.score(X, y) Visualizing the predicted chunks of ...", "dateLastCrawled": "2022-01-24T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Data Science \u2014 Linear <b>Regression</b> <b>Model</b> \u2013 Thought Journey", "url": "https://thought-journey.com/data-science-linear-regression-model/", "isFamilyFriendly": true, "displayUrl": "https://thought-journey.com/data-science-linear-<b>regression</b>-<b>model</b>", "snippet": "<b>Recipe</b> \u2014 Google Sheets; <b>Recipe</b> \u2014 Kanye West Framework; <b>Recipe</b> \u2014 Nato Word Translation; <b>Recipe</b> -- \u201cprime number\u201d function; <b>Recipe</b> -- Password Generator ; Password Generator JSON; <b>Recipe</b> \u2014 Snake Game; <b>Recipe</b> \u2014 RainAlert; <b>Recipe</b> \u2014 Spirography; <b>Recipe</b> \u2014 States Game; <b>Recipe</b> \u2014 Turtle Race; Example of my Coding; Python Packages. Mid-Point Plotting; Numpy; Numpy Basic Operations 1; Numpy Creations 1; Pandas; Pandas \u2014 DataFrame Comparison to Mean; Seaborn Graphing Package ...", "dateLastCrawled": "2021-12-21T00:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Linear Regression with tidymodels</b>", "url": "https://www.gmudatamining.com/lesson-10-r-tutorial.html", "isFamilyFriendly": true, "displayUrl": "https://www.gmudatamining.com/lesson-10-r-tutorial.html", "snippet": "The parsnip package from tidymodels acts <b>like</b> an aggregator across the various modeling engines within R. This makes it easy to implement machine learning algorithms from different R packages with one unifying syntax. To specify a <b>model</b> object with parsnip, we must: Pick a <b>model</b> type; Set the engine; Set the mode (either <b>regression</b> or classification) Linear <b>regression</b> is implemented with the linear_reg() function in parsnip. To the set the engine and mode, we use set_engine() and set_mode ...", "dateLastCrawled": "2022-01-29T19:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Chapter 7 <b>Regression</b> I: <b>K-nearest</b> neighbors | Data Science: A First ...", "url": "https://ubc-dsci.github.io/introduction-to-datascience/regression1.html", "isFamilyFriendly": true, "displayUrl": "https://ubc-dsci.github.io/introduction-to-datascience/<b>regression</b>1.html", "snippet": "7.3 The <b>regression</b> problem. <b>Regression</b>, <b>like</b> classification, is a predictive problem setting where we want to use past information to predict future observations. But in the case of <b>regression</b>, the goal is to predict numerical values instead of categorical values. The variable that you want to predict is often called the response variable.For example, we could try to use the number of hours a person spends on exercise each week to predict their race time in the annual Boston marathon.", "dateLastCrawled": "2022-02-02T08:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Modelling with <b>Tidymodels</b> and Parsnip | by Diego Usai | Towards Data ...", "url": "https://towardsdatascience.com/modelling-with-tidymodels-and-parsnip-bae2c01c131c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>model</b>ling-with-<b>tidymodels</b>-and-parsnip-bae2c01c131c", "snippet": "To show the basic steps in the <b>tidymodels</b> framework I am fitting and evaluating a simple logistic <b>regression</b> <b>model</b>. Train and test split. rsample provides a streamlined way to create a randomised training and test split of the original data. set.seed (seed = 1972) train_test_split &lt;-rsample::initial_split(data = telco, prop = 0.80 ) train_test_split ## &lt;5626/1406/7032&gt; Of the 7,043 total customers, 5,626 have been assigned to the training set and 1,406 to the test set. I save them as train ...", "dateLastCrawled": "2022-02-02T22:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "r - running multiple <b>regression</b> models using <b>tidymodels</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/66117523/running-multiple-regression-models-using-tidymodels", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/66117523", "snippet": "library (<b>tidymodels</b>) library (tidyverse) #some <b>regression</b> <b>model</b> cars_<b>recipe</b> &lt;- <b>recipe</b> (mpg ~ disp + drat, data = mtcars) wf &lt;- workflow () %&gt;% add_<b>recipe</b> (cars_<b>recipe</b>) (roughly using syntax from this blog post for comparison; I&#39;m not doing various steps <b>like</b> splitting test/train just for clarity in this example) I can then run many models and ...", "dateLastCrawled": "2022-01-21T14:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>SHAP</b> Part 2: Kernel <b>SHAP</b>. Kernel <b>SHAP</b> is a <b>model</b> agnostic method\u2026 | by ...", "url": "https://medium.com/analytics-vidhya/shap-part-2-kernel-shap-3c11e7a971b1", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>shap</b>-part-2-kernel-<b>shap</b>-3c11e7a971b1", "snippet": "Train an interpretable <b>model</b> (<b>like</b> linear <b>regression</b>, lasso, decision tree etc.) on this new dataset. Explain the prediction of the black box <b>model</b> by interpreting the local <b>model</b> (also called the ...", "dateLastCrawled": "2022-01-30T02:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chapter 7 <b>Regression</b> I: <b>K-nearest</b> neighbors | Data Science: A First ...", "url": "https://ubc-dsci.github.io/introduction-to-datascience/regression1.html", "isFamilyFriendly": true, "displayUrl": "https://ubc-dsci.github.io/introduction-to-datascience/<b>regression</b>1.html", "snippet": "For example, a <b>regression</b> <b>model</b> predicts a new observation\u2019s response variable based on the response variables for <b>similar</b> observations in the data set of past observations. When building a <b>regression</b> <b>model</b>, we first split the data into training and test sets, in order to ensure that we assess the performance of our method on observations not seen during training. And finally, we can use cross-validation to evaluate different choices of <b>model</b> parameters (e.g., K in a <b>K-nearest</b> neighbors ...", "dateLastCrawled": "2022-02-02T08:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Perfect <b>Recipe</b> for Classification Using <b>Logistic Regression</b> | by Ashwin ...", "url": "https://towardsdatascience.com/the-perfect-recipe-for-classification-using-logistic-regression-f8648e267592", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-perfect-<b>recipe</b>-for-classification-using-logistic...", "snippet": "<b>Logistic regression</b> is a classification technique borrowed by machine learning from the field of statistics. <b>Logistic Regression</b> is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The intention behind using <b>logistic regression</b> is to find the best fitting <b>model</b> to describe the relationship between the dependent and the independent variable. In this article, we will first be taking a theoretical approach on what ...", "dateLastCrawled": "2022-02-03T03:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Chapter 8 <b>Regression</b> II: linear <b>regression</b> | Data Science: A First ...", "url": "https://ubc-dsci.github.io/introduction-to-datascience/regression2.html", "isFamilyFriendly": true, "displayUrl": "https://ubc-dsci.github.io/introduction-to-datascience/<b>regression</b>2.html", "snippet": "In logistic <b>regression</b>\u2014<b>similar</b> to linear <b>regression</b>\u2014you \u201cfit\u201d the <b>model</b> to the training data and then \u201clook up\u201d the prediction for each new observation. Logistic <b>regression</b> and KNN classification have an advantage/disadvantage comparison <b>similar</b> to that of linear <b>regression</b> and KNN <b>regression</b>. It is useful to have a good understanding of linear <b>regression</b> before learning about logistic <b>regression</b>. After reading this chapter, see the \u201cAdditional Resources\u201d section at the end ...", "dateLastCrawled": "2022-02-01T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Healthy <b>Recipe</b> Recommendation using Nutrition and Ratings Models", "url": "https://snap.stanford.edu/class/cs224w-2019/project/26410425.pdf", "isFamilyFriendly": true, "displayUrl": "https://snap.stanford.edu/class/cs224w-2019/project/26410425.pdf", "snippet": "tritional <b>model</b> using linear <b>regression</b> to understand the overall nutritional content of a <b>recipe</b> given its ingre-dients. The second part consists of modelling a user\u2019s rating scores using a graph neural network (GNN) on ingredient-<b>recipe</b> and <b>recipe</b>-user bipartite graphs. We combine these two models to enable us to evaluate the healthiness and tastiness of novel recipes according to users\u2019 preferences. We show that our GNN approach towards the ratings <b>model</b> achieves strong performance ...", "dateLastCrawled": "2022-02-01T07:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Introduction to <b>F-testing in linear regression models</b>", "url": "https://www.uio.no/studier/emner/sv/oekonomi/ECON4130/h15/lecture-note-on-f-test-2015.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.uio.no/studier/emner/sv/oekonomi/ECON4130/h15/lecture-note-on-f-test-2015.pdf", "snippet": "<b>Recipe</b> for the F-test of the reduced <b>model</b> against the full <b>model</b> Run two regressions, ... <b>similar</b> function in Stata). [Example: The F-test reported (in red) is test for all the <b>regression</b> coefficients in front of explanatory variables, i.e., H 0 1 2 3:0 against some j &#39;0s . This is a standard F-test in all OLS-outputs. Non-rejection of this test indicates that there is no evidence in the data that the explanatory variables have any explanatory power at all\u2013 thus indicating that further ...", "dateLastCrawled": "2022-01-30T12:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Chapter 3 Local <b>Regression</b> - GitHub Pages", "url": "http://rafalab.github.io/pages/754/section-03.pdf", "isFamilyFriendly": true, "displayUrl": "rafalab.github.io/pages/754/section-03.pdf", "snippet": "We will now de\ufb01ne the <b>recipe</b> to obtain a loess smooth for a target covariate 3. 18 CHAPTER3. LOCALREGRESSION The \ufb01rst step in loess is to de\ufb01ne a weight function (<b>similar</b> to the kernel C we de\ufb01ned for kernel smoothers). For computational and theoretical purposes we will de\ufb01ne this weight function so that only values within a smoothing window 3 7 3; 3 B # 3; will be considered in the estimate of 3; . Notice: In local <b>regression</b> # 3; is called the span or bandwidth. It is like the ...", "dateLastCrawled": "2022-02-03T03:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Machine learning overview \u2013 classification versus <b>regression</b> | scikit ...", "url": "https://subscription.packtpub.com/book/big-data-and-business-intelligence/9781787286382/1/ch01lvl1sec11/loading-the-iris-dataset", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/book/big-data-and-business-intelligence/...", "snippet": "In this <b>recipe</b> we will examine how <b>regression</b> can be viewed as being very <b>similar</b> to classification. This is done by reconsidering the categorical labels of <b>regression</b> as real numbers. In this section we will also look at at several aspects of machine learning from a very broad perspective including the purpose of scikit-learn. scikit-learn allows us to find models that work well incredibly quickly. We do not have to work out all the details of the <b>model</b>, or optimize, until we found one that ...", "dateLastCrawled": "2022-01-25T08:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Modelling with <b>Tidymodels</b> and Parsnip | by Diego Usai | Towards Data ...", "url": "https://towardsdatascience.com/modelling-with-tidymodels-and-parsnip-bae2c01c131c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>model</b>ling-with-<b>tidymodels</b>-and-parsnip-bae2c01c131c", "snippet": "My aim is to show how easy it is to fit a simple logistic <b>regression</b> in R\u2019s glm and quickly switch to a cross-validated random forest using the ranger engine by changing only a few lines of code. For this post in particular I\u2019m focusing on four different libraries from the <b>tidymodels</b> suite: rsample for data sampling and cross-validation, recipes for data preprocessing, parsnip for <b>model</b> set up and estimation, and yardstick for <b>model</b> assessment. Note that the focus is on modelling ...", "dateLastCrawled": "2022-02-02T22:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Regression</b> modeling without fully observable data", "url": "https://doordash.engineering/2020/10/14/solving-for-unobserved-data-in-a-regression-model/", "isFamilyFriendly": true, "displayUrl": "https://doordash.engineering/2020/10/14/<b>solving-for-unobserved-data-in-a-regression</b>-<b>model</b>", "snippet": "<b>Solving for Unobserved Data in a Regression Model Using a Simple</b> Data Adjustment 9 Minute Read. Supercharging DoorDash\u2019s Marketplace Decision-Making with Real-Time Knowledge 8 Minute Read. Santhosh Hari 4. Making accurate predictions when historical information isn\u2019t fully observable is a central problem in delivery logistics. At DoorDash, we face this problem in the matching between delivery drivers on our platform, who we call Dashers, and orders in real time. The core feature of our ...", "dateLastCrawled": "2022-01-23T05:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Tutorial on tidymodels for Machine Learning", "url": "https://hansjoerg.me/2020/02/09/tidymodels-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://hansjoerg.me/2020/02/09/tidy<b>models</b>-for-machine-learning", "snippet": "Defining and Fitting Models: parsnip The parsnip package has wrappers around many 1 popular machine learning algorithms, and you can fit them using a unified interface. This is extremely helpful, since you have to remember only one rather then dozens of interfaces. The models are separated into two modes/categories, namely, <b>regression</b> and classification (set_mode()).The <b>model</b> is defined using a function specific to each algorithm (e.g., linear_reg(), rand_forest()).Finally, the backend ...", "dateLastCrawled": "2021-11-20T19:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chapter <b>7 Moving Beyond Linearity</b> | ISLR tidymodels Labs", "url": "https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/moving-beyond-linearity.html", "isFamilyFriendly": true, "displayUrl": "https://emilhvitfeldt.github.io/ISLR-tidy<b>models</b>-labs/<b>moving-beyond-linearity</b>.html", "snippet": "Polynomial <b>regression</b> <b>can</b> <b>be thought</b> of as doing polynomial expansion on a variable and passing that expansion into a linear <b>regression</b> <b>model</b>. We will be very explicit in this formulation in this chapter. step_poly() allows us to do a polynomial expansion on one or more variables. The following step will take age and replace it with the variables age, age^2, age^3, and age^4 since we set degree = 4. rec_poly &lt;-<b>recipe</b> (wage ~ age, data = Wage) %&gt;% step_poly (age, degree = 4) This <b>recipe</b> is ...", "dateLastCrawled": "2022-02-03T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Linear <b>Regression</b>", "url": "https://uoepsy.github.io/usmr/labs/07_regression.html", "isFamilyFriendly": true, "displayUrl": "https://uoepsy.github.io/usmr/labs/07_<b>regression</b>.html", "snippet": "In <b>regression</b>, the null <b>model</b> <b>can</b> <b>be thought</b> of as the <b>model</b> in which all explanatory variables have zero <b>regression</b> coefficients. It is also referred to as the intercept-only <b>model</b> , because if all predictor variable coefficients are zero, then the only we are only estimating \\(y\\) via an intercept (which will be the mean: \\(\\bar y\\) ).", "dateLastCrawled": "2022-01-24T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Chapter 8 <b>Regression</b> II: linear <b>regression</b> | Data Science: A First ...", "url": "https://ubc-dsci.github.io/introduction-to-datascience/regression2.html", "isFamilyFriendly": true, "displayUrl": "https://ubc-dsci.github.io/introduction-to-datascience/<b>regression</b>2.html", "snippet": "8.4 Linear <b>regression</b> in R. We <b>can</b> perform simple linear <b>regression</b> in R using tidymodels in a very similar manner to how we performed KNN <b>regression</b>. To do this, instead of creating a nearest_neighbor <b>model</b> specification with the kknn engine, we use a linear_reg <b>model</b> specification with the lm engine. Another difference is that we do not need to choose \\(K\\) in the context of linear <b>regression</b>, and so we do not need to perform cross-validation. Below we illustrate how we <b>can</b> use the usual ...", "dateLastCrawled": "2022-02-01T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The Ultimate Guide to <b>Linear Regression for Machine Learning</b>", "url": "https://www.keboola.com/blog/linear-regression-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.keboola.com/blog/linear-<b>regression</b>-machine-learning", "snippet": "Algorithm: think of it as a <b>recipe</b>. The result of training the linear <b>regression</b> <b>model</b> on training data is an equation (<b>recipe</b>), which <b>can</b> be applied to new (previously unseen) data. It\u2019s a bit like applying a cooking <b>recipe</b> to a fresh batch of ingredients! Keep in mind that linear <b>regression</b> is just one of the many <b>regression</b> techniques that we have at our disposal. There are several types of these techniques in the field of predictive modeling: Simple and multiple linear <b>regression</b> ...", "dateLastCrawled": "2022-02-03T12:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Regression</b> modeling without fully observable data", "url": "https://doordash.engineering/2020/10/14/solving-for-unobserved-data-in-a-regression-model/", "isFamilyFriendly": true, "displayUrl": "https://doordash.engineering/2020/10/14/<b>solving-for-unobserved-data-in-a-regression</b>-<b>model</b>", "snippet": "<b>Solving for Unobserved Data in a Regression Model Using a Simple</b> Data Adjustment 9 Minute Read. Supercharging DoorDash\u2019s Marketplace Decision-Making with Real-Time Knowledge 8 Minute Read. Santhosh Hari 4. Making accurate predictions when historical information isn\u2019t fully observable is a central problem in delivery logistics. At DoorDash, we face this problem in the matching between delivery drivers on our platform, who we call Dashers, and orders in real time. The core feature of our ...", "dateLastCrawled": "2022-01-23T05:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Six quick tips to improve your <b>regression modeling</b> | Statistical ...", "url": "https://statmodeling.stat.columbia.edu/2015/01/29/six-quick-tips-improve-regression-modeling/", "isFamilyFriendly": true, "displayUrl": "https://stat<b>model</b>ing.stat.columbia.edu/2015/01/29/six-quick-tips-improve-<b>regression</b>...", "snippet": "Graphing the data is fine (see Appendix B) but it is also useful to graph the estimated <b>model</b> itself (see lots of examples of <b>regression</b> lines and curves throughout this book). A table of <b>regression</b> coefficients does not give you the same sense as graphs of the <b>model</b>. This point should seem obvious but <b>can</b> be obscured in statistical textbooks that focus so strongly on plots for raw data and for <b>regression</b> diagnostics, forgetting the simple plots that help us understand a <b>model</b>.", "dateLastCrawled": "2022-01-19T08:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "r - running multiple <b>regression</b> models using <b>tidymodels</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/66117523/running-multiple-regression-models-using-tidymodels", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/66117523", "snippet": "library (<b>tidymodels</b>) library (tidyverse) #some <b>regression</b> <b>model</b> cars_<b>recipe</b> &lt;- <b>recipe</b> (mpg ~ disp + drat, data = mtcars) wf &lt;- workflow () %&gt;% add_<b>recipe</b> (cars_<b>recipe</b>) (roughly using syntax from this blog post for comparison; I&#39;m not doing various steps like splitting test/train just for clarity in this example) I <b>can</b> then run many models and ...", "dateLastCrawled": "2022-01-21T14:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "11 <b>Linear Regression</b> and <b>ANOVA</b> | R Cookbook, 2nd Edition", "url": "https://rc2e.com/linearregressionandanova", "isFamilyFriendly": true, "displayUrl": "https://rc2e.com/<b>linearregression</b>and<b>anova</b>", "snippet": "If you <b>thought</b> the relationship was quadratic, you could use a square-root transformation: lm (sqrt (y) ~ month) You <b>can</b> apply transformations to variables on both sides of the formula, of course. This formula regresses y on the square root of x: lm (y ~ sqrt (x)) This <b>regression</b> is for a log-log relationship between x and y: lm (log (y) ~ log (x)) See Also. See <b>Recipe</b> @ref(<b>recipe</b>-id210,) \u201cFinding the Best Power Transformation (Box\u2013Cox Procedure)\u201d. 11.13 Finding the Best Power ...", "dateLastCrawled": "2022-02-03T02:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Topic 2: Logistic <b>Regression</b> - GitHub Pages", "url": "https://danielpimentel.github.io/teaching/CS4850/lectures/CS4850_2LogisticRegression.pdf", "isFamilyFriendly": true, "displayUrl": "https://danielpimentel.github.io/teaching/CS4850/lectures/CS4850_2Logistic<b>Regression</b>.pdf", "snippet": "Arguably, the simplest, most natural approach is to <b>model</b> the odds as a linear combination of the entries in x, i.e., P(y= 1jx) P(y= 0jx) = Tx; (2.2) where 2Rd contains the coe cients of the linear combination of x. Notice that T is just the compact (grown up) way to write 1x 1 + 2x 2 + + dx d. The problem with (2.2) is that P(y=1jx) P(y=0jx) 0, while Tx 2R. To avoid this discrepancy, rather than (2.2), logistic <b>regression</b> simply applies a log function on the odds, to obtain: log P(y= 1jx) P ...", "dateLastCrawled": "2021-06-23T18:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Save And <b>Finalize Your Machine Learning</b> <b>Model</b> in R", "url": "https://machinelearningmastery.com/finalize-machine-learning-models-in-r/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/finalize-<b>machine-learning</b>-<b>models</b>-in-r", "snippet": "In the <b>recipe</b> below, the dataset is split into a validation dataset and a training dataset. The validation dataset could just as easily be a new dataset stored in a separate file and loaded as a data frame. A good <b>model</b> of the data is found using LDA. We <b>can</b> see that caret provides access to the best <b>model</b> from a training run in the finalModel variable. We <b>can</b> use that <b>model</b> to make predictions by calling predict using the fit from train which will automatically use the final <b>model</b>. We must ...", "dateLastCrawled": "2022-02-02T06:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Get Started - <b>Preprocess your data with recipes</b>", "url": "https://www.tidymodels.org/start/recipes/", "isFamilyFriendly": true, "displayUrl": "https://www.tidy<b>models</b>.org/start/<b>recipes</b>", "snippet": "To get started, let\u2019s create a <b>recipe</b> for a simple logistic <b>regression</b> <b>model</b>. Before training the <b>model</b>, we <b>can</b> use a <b>recipe</b> to create a few new predictors and conduct some preprocessing required by the <b>model</b>. Let\u2019s initiate a new <b>recipe</b>: flights_rec &lt;-<b>recipe</b> (arr_delay ~., data = train_data) The <b>recipe</b>() function as we used it here has two arguments: A formula. Any variable on the left-hand side of the tilde (~) is considered the <b>model</b> outcome (here, arr_delay). On the right-hand side ...", "dateLastCrawled": "2022-01-31T23:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Chapter 8 <b>Regression</b> II: linear <b>regression</b> | Data Science: A First ...", "url": "https://ubc-dsci.github.io/introduction-to-datascience/regression2.html", "isFamilyFriendly": true, "displayUrl": "https://ubc-dsci.github.io/introduction-to-datascience/<b>regression</b>2.html", "snippet": "8.4 Linear <b>regression</b> in R. We <b>can</b> perform simple linear <b>regression</b> in R using tidymodels in a very similar manner to how we performed KNN <b>regression</b>. To do this, instead of creating a nearest_neighbor <b>model</b> specification with the kknn engine, we use a linear_reg <b>model</b> specification with the lm engine. Another difference is that we do not need to choose \\(K\\) in the context of linear <b>regression</b>, and so we do not need to perform cross-validation. Below we illustrate how we <b>can</b> use the usual ...", "dateLastCrawled": "2022-02-01T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Chapter 7 <b>Regression</b> I: <b>K-nearest</b> neighbors | Data Science: A First ...", "url": "https://ubc-dsci.github.io/introduction-to-datascience/regression1.html", "isFamilyFriendly": true, "displayUrl": "https://ubc-dsci.github.io/introduction-to-datascience/<b>regression</b>1.html", "snippet": "If we want to compare this multivariable KNN <b>regression</b> <b>model</b> to the <b>model</b> with only a single predictor as part of the <b>model</b> tuning process (e.g., if we are running forward selection as described in the chapter on evaluating and tuning classification models), then we must compare the accuracy estimated using only the training data via cross-validation. Looking back, the estimated cross-validation accuracy for the single-predictor <b>model</b> was 85,227. The estimated cross-validation accuracy for ...", "dateLastCrawled": "2022-02-02T08:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Step-by-Step <b>Regression Analysis</b>. What is <b>Regression Analysis</b>? | by ...", "url": "https://medium.com/@mygreatlearning/step-by-step-regression-analysis-f7e3e3ebf296", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@mygreatlearning/step-by-step-<b>regression-analysis</b>-f7e3e3ebf296", "snippet": "If the goal is prediction, linear <b>regression</b> <b>can</b> be used to fit a predictive <b>model</b> to an observed data set of values of the response and explanatory variables. After developing such a <b>model</b>, if ...", "dateLastCrawled": "2022-02-03T04:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>11 Comparing models with resampling</b> | Tidy Modeling with R", "url": "https://www.tmwr.org/compare.html", "isFamilyFriendly": true, "displayUrl": "https://www.tmwr.org/compare.html", "snippet": "<b>11 Comparing models with resampling</b>. Once we create two or more models, the next step is to compare them. In some cases, comparisons might be within-<b>model</b>, where the same <b>model</b> might be evaluated with different features or preprocessing methods.Alternatively, between-<b>model</b> comparisons, such as when we <b>compared</b> linear <b>regression</b> and random forest models in Chapter 10, are the more common scenario. In either case, the result is a collection of resampled summary statistics (e.g. RMSE, accuracy ...", "dateLastCrawled": "2022-01-30T05:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Classification with Tidymodels, Workflows and Recipes</b> | Jan Kirenz", "url": "https://www.kirenz.com/post/2021-02-17-r-classification-tidymodels/", "isFamilyFriendly": true, "displayUrl": "https://www.kirenz.com/post/2021-02-17-r-classification-tidy<b>models</b>", "snippet": "To simplify this process, we <b>can</b> use a <b>model</b> workflow, which pairs a <b>model</b> and <b>recipe</b> together. 3.1 Data preparation Before we create our recipes , we first select the variables which we will use in the <b>model</b>.", "dateLastCrawled": "2022-02-02T04:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning - Performance Metrics</b> - <b>Tutorialspoint</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_algorithms_performance_metrics.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/machine_learning_with_python/machine_learning...", "snippet": "We <b>can</b> use r2_score function of sklearn.metrics to compute R squared value. Example. The following is a simple <b>recipe</b> in Python which will give us an insight about how we <b>can</b> use the above explained performance metrics on <b>regression</b> <b>model</b> \u2212", "dateLastCrawled": "2022-02-02T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "5.1 <b>Linear Regression</b> | Interpretable Machine Learning", "url": "https://christophm.github.io/interpretable-ml-book/limo.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-book/limo.html", "snippet": "The weights of the <b>linear regression</b> <b>model</b> <b>can</b> be more meaningfully analyzed when they are multiplied by the actual feature values. The weights depend on the scale of the features and will be different if you have a feature that measures e.g. a person\u2019s height and you switch from meter to centimeter. The weight will change, but the actual effects in your data will not. It is also important to know the distribution of your feature in the data, because if you have a very low variance, it ...", "dateLastCrawled": "2022-02-03T04:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>10 Resampling for evaluating performance</b> | Tidy Modeling with R", "url": "https://www.tmwr.org/resampling.html", "isFamilyFriendly": true, "displayUrl": "https://www.tmwr.org/resampling.html", "snippet": "10.1 The resubstitution approach. Let\u2019s again use the Ames data to demonstrate the concepts in this chapter. Section 8.8 summarizes the current state of our Ames analysis. It includes a <b>recipe</b> object named ames_rec, a linear <b>model</b>, and a workflow using that <b>recipe</b> and <b>model</b> called lm_wflow.This workflow was fit on the training set, resulting in lm_fit.. For a comparison to this linear <b>model</b>, we <b>can</b> also fit a different type of <b>model</b>.", "dateLastCrawled": "2022-01-28T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Chapter 5 <b>Model</b> formulation | ml4ec - Machine Learning for Eddy ...", "url": "https://stineb.github.io/ml4ec_workshop/model-formulation.html", "isFamilyFriendly": true, "displayUrl": "https://stineb.github.io/ml4ec_workshop/<b>model</b>-formulation.html", "snippet": "Chapter 5 <b>Model</b> formulation. The aim of supervised ML is to find a <b>model</b> \\(\\hat{Y} = f(X)\\) so that \\(\\hat{Y}\\) agrees well with observations \\(Y\\).We typically start with a research question where \\(Y\\) is given - naturally - by the problem we are addressing and we have a data set at hand where one or multiple predictors (or features) \\(X\\) are recorded along with \\(Y\\).From our data, we have information about how GPP (ecosystem-level photosynthesis) depends on set of abiotic factors ...", "dateLastCrawled": "2021-12-28T21:20:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor <b>model</b> fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "A difficult <b>regression</b> parameter estimation problem is posed when the data sample is hypothesized to have been generated by more than a single <b>regression</b> <b>model</b>. To find the best-fitting number and ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Introduction to <b>Machine Learning</b> Algorithms: <b>Linear Regression</b> | by ...", "url": "https://towardsdatascience.com/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-<b>machine-learning</b>-algorithms-linear...", "snippet": "The impetus behind such ubiquitous use of AI is <b>machine learning</b> algorithms. For anyone who wants to learn ML algorithms but hasn\u2019t gotten their feet wet yet, you are at the right place. The rudimental algorithm that every <b>Machine Learning</b> enthusiast starts with is a <b>linear regression</b> algorithm. Therefore, we shall do the same as it provides a base for us to build on and learn other ML algorithms.", "dateLastCrawled": "2022-02-02T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A review and analysis of <b>regression</b> and <b>machine</b> <b>learning</b> models on ...", "url": "https://www.sciencedirect.com/science/article/pii/S1364032117302265", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1364032117302265", "snippet": "<b>Regression</b> trees were the best performing <b>model</b> over other <b>regression</b>, <b>machine</b> <b>learning</b>, and time series models . 3. Literature review on <b>regression</b> models . <b>Regression</b> models are statistical methods for estimating the relationship between the output and the variables which have influence on the output, also referred to as influence parameters. An example of a <b>regression</b> equation is given below: (1) y \u02c6 = a 1 \u00d7 x 1 + a 2 \u00d7 x 2 + \u2026 + a n \u00d7 x n (2) y = y \u02c6 + e where, y is the real ...", "dateLastCrawled": "2022-02-03T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor <b>model</b> fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Introduction to Machine Learning and</b> <b>Deep Dive into Linear Regression</b> ...", "url": "https://medium.com/analytics-vidhya/machine-learning-i-introduction-linear-regression-explained-bc5bfee25832", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>machine</b>-<b>learning</b>-i-introduction-linear-<b>regression</b>...", "snippet": "In <b>machine</b> <b>learning</b> terms, \u2018x\u2019 is the \u2018input data\u2019, y is the \u2018output\u2019 and W and b are the parameters that we want the linear <b>regression</b> algorithm to learn to give the \u2018rules\u2019 so ...", "dateLastCrawled": "2021-07-09T13:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Linear Regression</b> \u2014 Simple/Single \u2014 Multiple | by Shanthababu Pandian ...", "url": "https://medium.com/analytics-vidhya/linear-regression-simple-single-multiple-fb8a1a678168", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>linear-regression</b>-simple-single-multiple-fb8a1a678168", "snippet": "<b>Linear Regression</b> \u2014 Components Let\u2019s discuss <b>Linear Regression</b> \u2014 In Mathematical point of view. Before, how to use the <b>Machine</b> <b>Learning</b> <b>model</b>.", "dateLastCrawled": "2022-01-23T13:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Difference Between Algorithm and Model</b> in <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/difference-between-algorithm-and-model-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>difference-between-algorithm-and-model</b>-", "snippet": "A <b>machine learning</b> <b>model</b> is more challenging for a beginner because there is not a clear <b>analogy</b> with other algorithms in computer science. For example, the sorted list output of a sorting algorithm is not really a <b>model</b>. The best <b>analogy</b> is to think of the <b>machine learning</b> <b>model</b> as a \u201cprogram.\u201d The <b>machine learning</b> <b>model</b> \u201cprogram\u201d is comprised of both data and a procedure for using the data to make a prediction. For example, consider the linear <b>regression</b> algorithm and resulting ...", "dateLastCrawled": "2022-01-31T01:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Ridge Regression</b> Explained, Step by Step - <b>Machine</b> <b>Learning</b> Compass", "url": "https://machinelearningcompass.com/machine_learning_models/ridge_regression/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>compass.com/<b>machine</b>_<b>learning</b>_<b>models</b>/<b>ridge_regression</b>", "snippet": "<b>Ridge Regression</b> is an adaptation of the popular and widely used linear <b>regression</b> algorithm. It enhances regular linear <b>regression</b> by slightly changing its cost function, which results in less overfit models. In this article, you will learn everything you need to know about <b>Ridge Regression</b>, and how you can start using it in your own <b>machine</b> <b>learning</b> projects.", "dateLastCrawled": "2022-02-02T15:51:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Linear Regression in Machine Learning: Everything</b> You Need to Know ...", "url": "https://www.upgrad.com/blog/linear-regression-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/<b>linear-regression-in-machine-learning</b>", "snippet": "The process involved in training a linear <b>regression model is similar</b> in many ways to how other <b>machine</b> <b>learning</b> models are trained. We need to work on a training data set and model the relationship of its variables in a way that doesn\u2019t impact the ability of the model to predict new data samples. Model is trained to improve your prediction equation continuously. It is done by iteratively looping through the given dataset. Every time you repeat this action, you simultaneously update the ...", "dateLastCrawled": "2022-02-01T02:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>learning</b> for predicting risk of metabolic syndrome | RMHP", "url": "https://www.dovepress.com/machine-learning-based-prediction-for-4-year-risk-of-metabolic-syndrom-peer-reviewed-fulltext-article-RMHP", "isFamilyFriendly": true, "displayUrl": "https://www.dovepress.com/<b>machine</b>-<b>learning</b>-based-prediction-for-4-year-risk-of...", "snippet": "For clinical use, when the performance of the logistic <b>regression model is similar</b> to ML-based prediction models, the simplest and more interpretable model should be chosen. Keywords: prognosis model, metabolic syndrome, calibration, discrimination, <b>machine</b> <b>learning</b>. Introduction. Metabolic Syndrome (MetS) refers to a group of risk factors including hypertension, hyperglycemia, dyslipidemia, hypertension, and abdominal obesity. 1 It is well known that metabolic risk factors can increase the ...", "dateLastCrawled": "2022-01-22T10:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Predicting Tensile Properties of <b>AZ31 Magnesium Alloys</b> by <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s11837-020-04343-w", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11837-020-04343-w", "snippet": "An SVM <b>regression model is similar</b> to an SVM classification model while reversing the objective: instead of trying to fit the largest possible street between two classes, SVM regression tries to fit as many instances as possible on the street while limiting margin violations (i.e., instances off the street). The regression function can be linear or nonlinear. To tackle nonlinear regression tasks, the so-called \u201ckernel trick\u201d is adopted to project input data to a higher-dimensional space ...", "dateLastCrawled": "2022-02-02T08:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b>-Based Prediction for 4-Year Risk of Metabolic Syndrome ...", "url": "https://pubmed.ncbi.nlm.nih.gov/34707419/", "isFamilyFriendly": true, "displayUrl": "https://pubmed.ncbi.nlm.nih.gov/34707419", "snippet": "Purpose: <b>Machine</b> <b>learning</b> (ML) techniques have emerged as a promising tool to predict risk and make decisions in different medical domains. We aimed to compare the predictive performance of <b>machine</b> <b>learning</b>-based methods for 4-year risk of metabolic syndrome in adults with the previous model using logistic regression. Patients and methods: This was a retrospective cohort study that employed a temporal validation strategy. Three popular ML techniques were selected to build the prognostic ...", "dateLastCrawled": "2021-12-30T11:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Chapter 6 Regularized Regression</b> | Hands-On <b>Machine</b> <b>Learning</b> with R", "url": "https://bradleyboehmke.github.io/HOML/regularized-regression.html", "isFamilyFriendly": true, "displayUrl": "https://bradleyboehmke.github.io/HOML/regularized-regression.html", "snippet": "A <b>Machine</b> <b>Learning</b> Algorithmic Deep Dive Using R. Many real-life data sets, like those common to text mining and genomic studies are wide, meaning they contain a larger number of features (\\(p &gt; n\\)).As p increases, we\u2019re more likely to violate some of the OLS assumptions and alternative approaches should be considered. This was briefly illustrated in Chapter 4 where the presence of multicollinearity was diminishing the interpretability of our estimated coefficients due to inflated ...", "dateLastCrawled": "2022-02-02T07:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Predicting Tensile Properties of AZ31 Magnesium Alloys by <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/content/pdf/10.1007/s11837-020-04343-w.pdf", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/content/pdf/10.1007/s11837-020-04343-w.pdf", "snippet": "<b>Machine</b> <b>Learning</b> Algorithms and Model Training Arti\ufb01cial Neural Network (ANN) ANN is one of the most popular algorithms in modern <b>machine</b> <b>learning</b>.24 The algorithm combi-nes linear transformation and non-linear activation functions to simulate complex nonlinear systems. A basic ANN consists of three interconnected layers: an input layer, a hidden layer, and an output layer. The input layer is a vector of the attribute values of a data item. The hidden layer consists of certain number of ...", "dateLastCrawled": "2021-12-17T03:13:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>learning</b> methods (Chapter 7) - Mapping Species Distributions", "url": "https://www.cambridge.org/core/books/mapping-species-distributions/machine-learning-methods/DCB5ADE9F03693BB806C751912693B11", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/books/mapping-species-distributions/<b>machine</b>-<b>learning</b>...", "snippet": "Statistical or <b>machine</b> <b>learning</b> approaches can be used to solve a supervised <b>learning</b> problem. In Chapter 6 it was noted that the linear (<b>regression) model can be thought of as</b> a model-driven or parametric approach to statistical <b>learning</b>, in which certain assumptions are made about the form of the model, and also a \u201cglobal\u201d method, meaning that all of the data (observations) are used to estimate the parameters. In other words, the problem in supervised <b>learning</b> is to construct a ...", "dateLastCrawled": "2021-11-13T19:22:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(regression model)  is like +(recipe)", "+(regression model) is similar to +(recipe)", "+(regression model) can be thought of as +(recipe)", "+(regression model) can be compared to +(recipe)", "machine learning +(regression model AND analogy)", "machine learning +(\"regression model is like\")", "machine learning +(\"regression model is similar\")", "machine learning +(\"just as regression model\")", "machine learning +(\"regression model can be thought of as\")", "machine learning +(\"regression model can be compared to\")"]}