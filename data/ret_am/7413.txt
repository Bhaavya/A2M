{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Step-by-Step Introduction to <b>Bayesian</b> Hyperparameter <b>Optimization</b> ...", "url": "https://towardsdatascience.com/a-step-by-step-introduction-to-bayesian-hyperparameter-optimization-94a623062fc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-step-by-step-introduction-to-<b>bayesian</b>-hyperparameter...", "snippet": "Hyperparameters are parameters that are set before the actual training to control the <b>learning</b> process. The decision tree requires a limit for the maximum number of nodes of the tree; the polynomial\u2026", "dateLastCrawled": "2022-02-01T16:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Conceptual Explanation of <b>Bayesian</b> Hyperparameter <b>Optimization</b> for ...", "url": "https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-conceptual-explanation-of-<b>bayesian</b>-model-based-hyper...", "snippet": "The aim of hyperparameter <b>optimization</b> in machine <b>learning</b> is to find the hyperparameters of a given machine <b>learning</b> algorithm that return the best performance as measured on a validation set. (Hyperparameters, in contrast to model parameters, are set by the machine <b>learning</b> engineer before training. The number of trees in a random forest is a hyperparameter while the weights in a neural network are model parameters learned during training. I <b>like</b> to think of hyperparameters as the model ...", "dateLastCrawled": "2022-02-02T22:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian Optimization</b>: fine-tuning black-box processes", "url": "https://www.innovating-automation.blog/bayesian-optimization/", "isFamilyFriendly": true, "displayUrl": "https://www.innovating-automation.blog/<b>bayesian-optimization</b>", "snippet": "AutoML (automated machine <b>learning</b>) is one of the recent paradigm-breaking developments in machine <b>learning</b>. New libraries such as HyperOpt allow data scientists and machine <b>learning</b> practitioners to save time spent on selecting, tuning and evaluating different algorithms, tasks that are often very time consuming. Some of these libraries \u2013 HyperOpt, for example \u2013 use a technique called <b>Bayesian Optimization</b>. Instead of randomly or exhaustively iterating through combinations of algorithms ...", "dateLastCrawled": "2022-02-03T16:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bayesian Optimization with Unknown Constraints</b>", "url": "https://www.cs.princeton.edu/~rpa/pubs/gelbart2014constraints.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.princeton.edu/~rpa/pubs/gelbart2014constraints.pdf", "snippet": "<b>Bayesian Optimization with Unknown Constraints</b> Michael A. Gelbart Harvard University Cambridge, MA Jasper Snoek Harvard University Cambridge, MA Ryan P. Adams Harvard University Cambridge, MA Abstract Recent work on <b>Bayesian</b> <b>optimization</b> has shown its effectiveness in global <b>optimization</b> of dif\ufb01cult black-box objective functions. Many real-world <b>optimization</b> problems of interest also have constraints which are unknown a priori. In this paper, we study <b>Bayesian</b> <b>optimization</b> for constrained ...", "dateLastCrawled": "2022-01-29T02:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Towards an Interactive Drone, A <b>Bayesian</b> <b>Optimization</b> Approach", "url": "https://essay.utwente.nl/76246/1/Asem%20Thesis%20Final.pdf", "isFamilyFriendly": true, "displayUrl": "https://essay.utwente.nl/76246/1/Asem Thesis Final.pdf", "snippet": "5.3 <b>Bayesian</b> <b>Optimization</b> and Reinforcement <b>Learning</b>. . . . . . . . . . . . . . . . . . . . . . .68 Conclusion and Future Work70 A Impedance Control 73 B Simulation Software Implementation Details74 Bibliography 80 Asem Khattab University of Twente. 1 1 Introduction With their high mobility, drones can be employed in various industrial tasks signi\ufb01cantly de-creasing their cost. Examples include inspection of high structures <b>like</b> wind turbines, cell tow-ers and power lines. There is a ...", "dateLastCrawled": "2021-12-25T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bayesian</b> <b>Optimization</b> with Unknown Constraints", "url": "http://auai.org/uai2014/proceedings/individuals/107.pdf", "isFamilyFriendly": true, "displayUrl": "auai.org/uai2014/proceedings/individuals/107.pdf", "snippet": "<b>Bayesian</b> <b>Optimization</b> with Unknown Constraints Michael A. Gelbart Harvard University Cambridge, MA Jasper Snoek Harvard University Cambridge, MA Ryan P. Adams Harvard University Cambridge, MA Abstract Recent work on <b>Bayesian</b> <b>optimization</b> has shown its effectiveness in global <b>optimization</b> of dif\ufb01cult black-box objective functions. Many real-world <b>optimization</b> problems of interest also have constraints which are unknown a priori. In this paper, we study <b>Bayesian</b> <b>optimization</b> for constrained ...", "dateLastCrawled": "2022-02-03T16:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bayesian</b> <b>Optimization</b> for a Better Dessert", "url": "https://bayesopt.github.io/papers/2017/37.pdf", "isFamilyFriendly": true, "displayUrl": "https://bayesopt.github.io/papers/2017/37.pdf", "snippet": "<b>Bayesian</b> <b>Optimization</b> for a Better Dessert Greg Kochanski, Daniel Golovin, John Karro, Benjamin Solnik, Subhodeep Moitra, and D. Sculley {gpk, dgg, karro, bsolnik, smoitra, dsculley}@google.com ; Google Brain Team Abstract We present a case study on applying <b>Bayesian</b> <b>Optimization</b> to a complex real-world system; our challenge was to optimize chocolate chip cookies. The process was a mixed-initiative system where both <b>human</b> chefs, <b>human</b> raters, and a machine optimizer participated in 144 ...", "dateLastCrawled": "2022-02-01T02:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Why Optimization Is Important in Machine Learning</b>", "url": "https://machinelearningmastery.com/why-optimization-is-important-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/<b>why-optimization-is-important-in-machine-learning</b>", "snippet": "We can use an <b>optimization</b> algorithm, <b>like</b> a quasi-Newton local search algorithm, but it will almost always be less efficient than the analytical solution. Linear Regression: Function inputs are model coefficients, <b>optimization</b> problems that can be solved analytically. A logistic regression (for classification problems) is slightly less constrained and must be solved as an <b>optimization</b> problem, although something about the structure of the <b>optimization</b> function being solved is known given ...", "dateLastCrawled": "2022-02-02T08:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "On Compression Principle and <b>Bayesian Optimization</b> for Neural Networks ...", "url": "https://deepai.org/publication/on-compression-principle-and-bayesian-optimization-for-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/on-compression-principle-and-<b>bayesian-optimization</b>-for...", "snippet": "On Compression Principle and <b>Bayesian Optimization</b> for Neural Networks. 06/23/2020 \u2219 by Michael Tetelman, et al. \u2219 13 \u2219 share . Finding methods for making generalizable predictions is a fundamental problem of machine <b>learning</b>.By looking into similarities between the prediction problem for unknown data and the lossless compression we have found an approach that gives a solution.", "dateLastCrawled": "2021-12-11T12:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Causal Model Comparison Shows That <b>Human</b> Representation <b>Learning</b> Is Not ...", "url": "http://symposium.cshlp.org/content/79/161.full", "isFamilyFriendly": true, "displayUrl": "symposium.cshlp.org/content/79/161.full", "snippet": "The values of all features were initialized at zero at the beginning of each game; on each <b>trial</b>, values of the three features of the stimulus that was chosen were then updated according to (5) where \u03b7 represents the <b>learning</b> rate, and [R t \u2212 V t\u22121 (S chosen)] is a prediction <b>error</b>\u2014the discrepancy between the actual reward on the current <b>trial</b> and the reward that was expected based on choosing this stimulus.", "dateLastCrawled": "2021-12-18T03:11:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian</b> <b>optimization</b> for goal-oriented multi-objective inverse ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8273421/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8273421", "snippet": "Although the process resembles <b>human</b>-based <b>trial</b>-<b>and-error</b>, ... with the Matern52 kernel implemented in GPy and the normal distribution noise model were used for the machine <b>learning</b> model driving <b>Bayesian</b> <b>optimization</b>. Since the noise model assumed in the Gaussian process regression is the normal distribution, the probability distribution of the objective property with design parameter X, predicted by Gaussian process regression, also follows the normal distribution and acquisition ...", "dateLastCrawled": "2022-01-23T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Towards an Interactive Drone, A <b>Bayesian</b> <b>Optimization</b> Approach", "url": "https://essay.utwente.nl/76246/1/Asem%20Thesis%20Final.pdf", "isFamilyFriendly": true, "displayUrl": "https://essay.utwente.nl/76246/1/Asem Thesis Final.pdf", "snippet": "5.3 <b>Bayesian</b> <b>Optimization</b> and Reinforcement <b>Learning</b>. . . . . . . . . . . . . . . . . . . . . . .68 Conclusion and Future Work70 A Impedance Control 73 B Simulation Software Implementation Details74 Bibliography 80 Asem Khattab University of Twente. 1 1 Introduction With their high mobility, drones can be employed in various industrial tasks signi\ufb01cantly de-creasing their cost. Examples include inspection of high structures like wind turbines, cell tow-ers and power lines. There is a ...", "dateLastCrawled": "2021-12-25T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Hyperparameter <b>Optimization</b> with KerasTuner | by Renu Khandelwal | Geek ...", "url": "https://medium.com/geekculture/hyperparameter-optimization-with-kerastuner-cba8af446add", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/hyperparameter-<b>optimization</b>-with-kerastuner-cba8af446add", "snippet": "<b>Bayesian</b> <b>Optimization</b>. <b>Bayesian</b> <b>Optimization</b> uses Bayes theorem to find the combination of different hyperparameters to minimize or maximize an objective function. It is tailored for complex ...", "dateLastCrawled": "2022-01-20T22:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Automatic tuning of hyperparameters using Bayesian optimization</b> ...", "url": "https://link.springer.com/article/10.1007/s12530-020-09345-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12530-020-09345-2", "snippet": "Thereby tuning of hyperparameters can be formulated as an <b>optimization</b> problem, <b>similar</b> to fuzzy <b>optimization</b> (Angelov 1994; Angelov et al. 2011; Baruah and Angelov 2014) that is done in raw data. Hyperparameters of deep <b>learning</b> model remain fixed throughout the training procedure which helps to increase the accuracy of the model, also considering the memory cost and time for training the model eventually reducing the value of loss function.", "dateLastCrawled": "2022-01-23T02:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bayesian</b> Estimation of Potential Performance Improvement Elicited by ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8567031/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8567031", "snippet": "<b>Human</b>-in-the-loop <b>Bayesian</b> <b>optimization</b> of wearable device parameters. PLoS One 12:e0184054. 10.1371/journal.pone.0184054 [PMC free article] [Google Scholar] Liu J., Cramer S. C., Reinkensmeyer D. J. (2006). <b>Learning</b> to perform a new movement with robotic assistance: comparison of haptic guidance and visual demonstration. J. Neuroeng.", "dateLastCrawled": "2022-01-04T01:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A LRS: A <b>LEARNING-RATE SCHEDULE BY</b> B <b>OPTIMIZATION ON THE FLY</b>", "url": "https://homes.cs.washington.edu/~arvind/papers/autolrs.pdf", "isFamilyFriendly": true, "displayUrl": "https://homes.cs.washington.edu/~arvind/papers/autolrs.pdf", "snippet": "without <b>human</b> involvement? At the beginning of every \u02ddsteps (i.e., a \u201cstage\u201d in our method), we seek to identify an LR that optimizes the validation loss (i.e., an empirical estimate of the generalization <b>error</b>) at the end of the stage. To do so, we employ <b>Bayesian</b> <b>optimization</b> (BO) that treats the validation loss as a black-box function ...", "dateLastCrawled": "2022-01-02T05:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Spiderweb Nanomechanical Resonators via <b>Bayesian</b> <b>Optimization</b>: Inspired ...", "url": "https://onlinelibrary.wiley.com/doi/10.1002/adma.202106248", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1002/adma.202106248", "snippet": "Under these conditions, using data-scarce machine <b>learning</b> to guide the <b>optimization</b> process is particularly effective, as achieved by the <b>Bayesian</b> <b>optimization</b> method. [ 51 - 53 ] <b>Bayesian</b> <b>optimization</b> [ 54 ] constructs a machine-<b>learning</b> regression model usually from Gaussian processes, [ 55 ] by predicting model uncertainty and seeking the optimum solution in fewer iterations than competing algorithms.", "dateLastCrawled": "2022-02-02T11:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Causal Model Comparison Shows That <b>Human</b> Representation <b>Learning</b> Is Not ...", "url": "http://symposium.cshlp.org/content/79/161.full", "isFamilyFriendly": true, "displayUrl": "symposium.cshlp.org/content/79/161.full", "snippet": "The two models we compared represent two different ways of thinking about <b>human</b> representation <b>learning</b>. The first is a <b>Bayesian</b> model that assumes statistically optimal updating of the posterior probabilities of each feature being the target feature, and the second model uses reinforcement-<b>learning</b> principles to update values via <b>trial</b> and ...", "dateLastCrawled": "2021-12-18T03:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Human sensorimotor learning: adaptation, skill, and</b> beyond - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0959438811001218", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0959438811001218", "snippet": "A simple <b>error</b>-based <b>learning</b> rule selects those primitives best tuned to the perturbation. The authors go on to show that the model is able to predict those state-dependent force fields that subjects will find easier or more difficult to learn. The overall behavior ends up being identical to a <b>Bayesian</b> model having a prior that assumes that perturbations have correlated position and velocity components. Another recent study", "dateLastCrawled": "2022-01-15T14:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>AlphaGo vs Lee Sedol \u2013 The new AI Challenge</b> | Marc&#39;s Machine <b>Learning</b> Blog", "url": "https://gridworld.wordpress.com/2016/03/12/alphago-vs-lee-sedol-the-new-ai-challenge/", "isFamilyFriendly": true, "displayUrl": "https://gridworld.wordpress.com/2016/03/12/<b>alphago-vs-lee-sedol-the-new-ai-challenge</b>", "snippet": "AlphaGo\u2019s key insight is a clever strategy to reduce the complexity of the search tree using Deep <b>Learning</b> techniques: 1) The depth of the search tree is reduced by simulating possible games up to some point (say, ten moves ahead) and estimating the quality of the game play from here using a \u201cvalue network\u201d. 2) The width of the search ...", "dateLastCrawled": "2022-01-16T10:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian optimization explains human active search</b>", "url": "https://papers.nips.cc/paper/4952-bayesian-optimization-explains-human-active-search.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/4952-<b>bayesian-optimization-explains-human-active-search</b>.pdf", "snippet": "active <b>learning</b> [1], <b>Bayesian</b> <b>optimization</b> [2, 3], optimal search [4, 5, 6], optimal experimental design [7, 8], hyper-parameter <b>optimization</b>, and others. Optimal decision making algorithms show signi\ufb01cant promise in many applications, including <b>human</b>-machine interaction, intelligent tutoring systems, recommendation systems, sensor placement, robotics control, and many more. Here, inspired by the <b>optimization</b> literature, we design and conduct a series of experiments to understand <b>human</b> ...", "dateLastCrawled": "2021-09-15T11:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian</b> <b>optimization</b> for chemical products and functional materials ...", "url": "https://www.sciencedirect.com/science/article/pii/S2211339821000605", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2211339821000605", "snippet": "This review focuses on recent applications of <b>Bayesian</b> <b>optimization</b> (BO) to chemical products and materials including molecular design, drug discovery, molecular modeling, electrolyte design, and additive manufacturing. Numerous examples show how BO often requires an order of magnitude fewer experiments than Edisonian search. The essential equations for BO are introduced in a self-contained primer specifically written for chemical engineers and others new to the area. Finally, the review ...", "dateLastCrawled": "2022-01-06T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Guidance for the Use of <b>Bayesian Statistics in Medical Device Clinical</b> ...", "url": "https://www.fda.gov/regulatory-information/search-fda-guidance-documents/guidance-use-bayesian-statistics-medical-device-clinical-trials", "isFamilyFriendly": true, "displayUrl": "https://<b>www.fda.gov</b>/.../guidance-use-<b>bayesian</b>-statistics-medical-device-clinical-<b>trials</b>", "snippet": "A <b>Bayesian</b> <b>trial</b> <b>can</b> investigate this question by using previous studies comparing the active control to the inactive control. <b>Bayesian</b> methods for active control trials are discussed in Gould ...", "dateLastCrawled": "2022-01-15T05:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Application of <b>Bayesian</b> Active <b>Learning</b> to the Estimation of Auditory ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7580188/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7580188", "snippet": "To reduce the testing time, we applied <b>Bayesian</b> active <b>learning</b> (BAL) to the notched-noise test, picking the most informative stimulus parameters for each <b>trial</b> based on nine Gaussian Processes. A total of 11 hearing-impaired subjects were tested. In 20 to 30 min, the test provided estimates of signal threshold as a continuous function of frequency from 500 to 4000 Hz for nine notch widths and for notches placed both symmetrically and asymmetrically around the signal frequency. The ...", "dateLastCrawled": "2022-01-26T01:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Why Optimization Is Important in Machine Learning</b>", "url": "https://machinelearningmastery.com/why-optimization-is-important-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/<b>why-optimization-is-important-in-machine-learning</b>", "snippet": "Machine <b>learning</b> involves using an algorithm to learn and generalize from historical data in order to make predictions on new data. This problem <b>can</b> be described as approximating a function that maps examples of inputs to examples of outputs. Approximating a function <b>can</b> be solved by framing the problem as function <b>optimization</b>. This is where a machine <b>learning</b> algorithm defines a", "dateLastCrawled": "2022-02-02T08:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Mixture of Delta-Rules Approximation to <b>Bayesian</b> Inference in Change ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3723502/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3723502", "snippet": "One way around this problem is to dynamically update the <b>learning</b> rate on a <b>trial</b>-<b>by-trial</b> basis between zero, indicating that no weight is given to the last observed outcome, and one, indicating that the prediction is equal to the last outcome , . During periods of stability, a decreasing <b>learning</b> rate <b>can</b> match the current belief to the average outcome. After change-points, a high <b>learning</b> rate shifts beliefs away from historical data and towards more recent, and more relevant, outcomes.", "dateLastCrawled": "2021-11-21T22:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Deep <b>Learning</b> and <b>Bayesian</b> Methods", "url": "https://www.researchgate.net/publication/315540040_Deep_Learning_and_Bayesian_Methods", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/315540040_Deep_<b>Learning</b>_and_<b>Bayesian</b>_Methods", "snippet": "\u2022 <b>trial</b> <b>and error</b>, \u2022 <b>Bayesian</b> <b>optimization</b> [23], and \u2022 empirical Bayes [24]. In the next section, we sketch a possible way the choice of hyper-parameters might be optimized using. empirical ...", "dateLastCrawled": "2022-01-19T20:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Reversal Learning and Dopamine: A Bayesian Perspective</b> | Journal of ...", "url": "https://www.jneurosci.org/content/35/6/2407", "isFamilyFriendly": true, "displayUrl": "https://www.jneurosci.org/content/35/6/2407", "snippet": "<b>Trial</b> structure of a single block and the sequence of events in a single <b>trial</b> of the two-arm bandit reversal <b>learning</b> task. Each block contained 80 trials. The stimulus reward mapping was reversed on a randomly chosen <b>trial</b> between trials 30 and 50. Trials before the reversal are referred to as acquisition, and trials after the reversal are referred to as reversal. The reward schedule was always constant within a block (i.e., 80/20, 70/30, or 60/40%), but it usually changed across blocks ...", "dateLastCrawled": "2021-09-14T20:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Importance of <b>Optimization</b> in ML - BLOCKGENI", "url": "https://blockgeni.com/importance-of-optimization-in-ml/", "isFamilyFriendly": true, "displayUrl": "https://blockgeni.com/importance-of-<b>optimization</b>-in-ml", "snippet": "<b>Optimization</b> in a Machine <b>Learning</b> Project <b>Optimization</b> plays an important part in a machine <b>learning</b> project in addition to fitting the <b>learning</b> algorithm on the training dataset. The step of preparing the data prior to fitting the model and the step of tuning a chosen model also <b>can</b> be framed as an <b>optimization</b> problem. In fact, an entire predictive modeling project <b>can</b> <b>be thought</b> of as one large <b>optimization</b> problem. Let\u2019s take a closer look at each of these cases in turn. Data ...", "dateLastCrawled": "2022-01-07T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Learning</b> Reward <b>Functions by Integrating Human Demonstrations</b> and ...", "url": "https://iliad.stanford.edu/blog/2019/06/24/learning-reward-functions-by-integrating-human-demonstrations-and-preferences/", "isFamilyFriendly": true, "displayUrl": "https://iliad.stanford.edu/blog/2019/06/24/<b>learning</b>-reward-functions-by-integrating...", "snippet": "<b>Learning</b> Reward <b>Functions by Integrating Human Demonstrations and Preferences</b>. Many modern autonomous systems (such as autonomous cars or robots 1) rely on \u201creward functions\u201d, which encode the robot\u2019s desired behavior; in other words, reward functions effectively tell a robot, in any given situation, which action is good and which is bad ...", "dateLastCrawled": "2021-11-27T22:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian</b> <b>optimization</b> for goal-oriented multi-objective inverse ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8273421/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8273421", "snippet": "Although the process resembles <b>human</b>-based <b>trial</b>-<b>and-error</b>, design parameters in BO are determined based on a machine-<b>learning</b> model, which is updated after each experiment and gets smarter through repeated updates (Shahriari et al., 2015). Accordingly, BO <b>can</b> effectively accelerate difficult <b>optimization</b> problems and is useful, particularly for material-design problems involving time-consuming experiments. Currently, there are many computational material design studies that utilize BO", "dateLastCrawled": "2022-01-23T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian optimization explains human active search</b>", "url": "https://papers.nips.cc/paper/4952-bayesian-optimization-explains-human-active-search.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/4952-<b>bayesian-optimization-explains-human-active-search</b>.pdf", "snippet": "active <b>learning</b> [1], <b>Bayesian</b> <b>optimization</b> [2, 3], optimal search [4, 5, 6], optimal experimental design [7, 8], hyper-parameter <b>optimization</b>, and others. Optimal decision making algorithms show signi\ufb01cant promise in many applications, including <b>human</b>-machine interaction, intelligent tutoring systems, recommendation systems, sensor placement, robotics control, and many more. Here, inspired by the <b>optimization</b> literature, we design and conduct a series of experiments to understand <b>human</b> ...", "dateLastCrawled": "2021-09-15T11:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Conceptual Explanation of <b>Bayesian</b> Hyperparameter <b>Optimization</b> for ...", "url": "https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-conceptual-explanation-of-<b>bayesian</b>-model-based-hyper...", "snippet": "The aim of hyperparameter <b>optimization</b> in machine <b>learning</b> is to find the hyperparameters of a given machine <b>learning</b> algorithm that return the best performance as measured on a validation set. (Hyperparameters, in contrast to model parameters, are set by the machine <b>learning</b> engineer before training. The number of trees in a random forest is a hyperparameter while the weights in a neural network are model parameters learned during training. I like to think of hyperparameters as the model ...", "dateLastCrawled": "2022-02-02T22:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bayesian</b> <b>Optimization</b> for a Better Dessert", "url": "https://bayesopt.github.io/papers/2017/37.pdf", "isFamilyFriendly": true, "displayUrl": "https://bayesopt.github.io/papers/2017/37.pdf", "snippet": "<b>Bayesian</b> <b>Optimization</b> for a Better Dessert Greg Kochanski, Daniel Golovin, John Karro, Benjamin Solnik, Subhodeep Moitra, and D. Sculley {gpk, dgg, karro, bsolnik, smoitra, dsculley}@google.com ; Google Brain Team Abstract We present a case study on applying <b>Bayesian</b> <b>Optimization</b> to a complex real-world system; our challenge was to optimize chocolate chip cookies. The process was a mixed-initiative system where both <b>human</b> chefs, <b>human</b> raters, and a machine optimizer participated in 144 ...", "dateLastCrawled": "2022-02-01T02:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Frontiers | <b>Bayesian Optimization for Neuroimaging Pre-processing</b> in ...", "url": "https://www.frontiersin.org/articles/10.3389/fnagi.2018.00028/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fnagi.2018.00028", "snippet": "The classification task was included to allow evaluation of <b>Bayesian</b> <b>Optimization</b> hyper-parameters and to show the applicability of <b>Bayesian</b> <b>optimization</b> to different contexts. We hypothesized that by using <b>Bayesian</b> <b>optimization</b> we would improve model accuracy <b>compared</b> to previously used \u2018non-optimized\u2019 values. The study was designed to show proof-of-principle of the applicability of <b>Bayesian</b> <b>optimization</b> to help improve neuroimaging pre-processing in a principled and unbiased fashion.", "dateLastCrawled": "2022-01-31T13:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Automatic tuning of hyperparameters using Bayesian optimization</b> ...", "url": "https://link.springer.com/article/10.1007/s12530-020-09345-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12530-020-09345-2", "snippet": "<b>Bayesian</b> <b>optimization</b> is most useful while optimizing the hyperparameters of a deep neural network, where evaluating the accuracy of the model <b>can</b> take few days for training. The aim of optimizing the hyperparameters is to find an algorithm that returns best and accurate performance obtained on a validation set. The optimizer finds the best hyperparameters which yield the best score on the test set. <b>Bayesian</b> <b>optimization</b> is also widely used in diverse design problems in different fields ...", "dateLastCrawled": "2022-01-23T02:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A LRS: A <b>LEARNING-RATE SCHEDULE BY</b> B <b>OPTIMIZATION ON THE FLY</b>", "url": "https://homes.cs.washington.edu/~arvind/papers/autolrs.pdf", "isFamilyFriendly": true, "displayUrl": "https://homes.cs.washington.edu/~arvind/papers/autolrs.pdf", "snippet": "and BERT, respectively, <b>compared</b> to the LR schedules in their original papers, and an average speedup of 1:31 over state-of-the-art heavily-tuned LR schedules. 1 INTRODUCTION In the regime of deep <b>learning</b>, the success of training largely depends on the choice of the <b>learning</b> rate (LR) schedule, since most optimizers will have dif\ufb01culty traversing a non-smooth and non-convex loss landscape with multiple local minimums and possibly saddle points (Kawaguchi, 2016; Jin et al., 2017 ...", "dateLastCrawled": "2022-01-02T05:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Frontiers | Application of <b>Bayesian</b> Hyperparameter Optimized Random ...", "url": "https://www.frontiersin.org/articles/10.3389/feart.2021.712240/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/feart.2021.712240", "snippet": "However, the <b>Bayesian</b> <b>optimization</b> algorithm <b>can</b> quickly obtain the optimal value and is widely used to determine the optimal hyperparameter value of the model (Klein et al., 2016; Stuke et al., 2020). The <b>Bayesian</b> algorithm uses prior knowledge in the Gaussian process (GP) and has strong robustness. The algorithm only needs input and output data. It fits the posterior distribution of the objective function by increasing the number of samples, thereby realizing the hyperparameter ...", "dateLastCrawled": "2022-02-03T06:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Computational</b> <b>optimization</b> of associative <b>learning</b> experiments", "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371%2Fjournal.pcbi.1007593", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007593", "snippet": "Lastly, the <b>optimization</b> options depend on the specifics of the chosen <b>optimization</b> algorithm (for <b>Bayesian</b> <b>optimization</b>, details are provided in the S1 Appendix). A common <b>optimization</b> option is the termination criterion: we used a fixed maximum number of <b>optimization</b> iterations as the criterion, but the maximum elapsed time, or the number of iterations without substantial improvement <b>can</b> also be used.", "dateLastCrawled": "2021-11-06T09:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Meta-Learning Acquisition Functions for</b> <b>Bayesian</b> <b>Optimization</b> | DeepAI", "url": "https://deepai.org/publication/meta-learning-acquisition-functions-for-bayesian-optimization", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../<b>meta-learning-acquisition-functions-for</b>-<b>bayesian</b>-<b>optimization</b>", "snippet": "In an offline training phase on such a set of functions the algorithm <b>can</b> then be adjusted to a particular type of <b>optimization</b> problems with the goal of exhibiting superior performance <b>compared</b> with general-purpose <b>optimization</b> strategies in the subsequent application. For meta-<b>learning</b> global black-box <b>optimization</b>, such cheap training sets <b>can</b> be obtained in various ways. For example, in the context of hyperparameter <b>optimization</b> for NN training", "dateLastCrawled": "2022-01-04T09:57:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>machine</b> <b>learning</b> approach to <b>Bayesian</b> parameter estimation | npj ...", "url": "https://www.nature.com/articles/s41534-021-00497-w", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-021-00497-w", "snippet": "<b>Bayesian</b> estimation is a powerful theoretical paradigm for the operation of the approach to parameter estimation. However, the <b>Bayesian</b> method for statistical inference generally suffers from ...", "dateLastCrawled": "2022-02-03T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian Optimization</b>: fine-tuning black-box processes", "url": "https://www.innovating-automation.blog/bayesian-optimization/", "isFamilyFriendly": true, "displayUrl": "https://www.innovating-automation.blog/<b>bayesian-optimization</b>", "snippet": "AutoML (automated <b>machine</b> <b>learning</b>) is one of the recent paradigm-breaking developments in <b>machine</b> <b>learning</b>. New libraries such as HyperOpt allow data scientists and <b>machine</b> <b>learning</b> practitioners to save time spent on selecting, tuning and evaluating different algorithms, tasks that are often very time consuming. Some of these libraries \u2013 HyperOpt, for example \u2013 use a technique called <b>Bayesian Optimization</b>. Instead of randomly or exhaustively iterating through combinations of algorithms ...", "dateLastCrawled": "2022-02-03T16:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b>: A <b>Bayesian</b> and <b>Optimization</b> Perspective [2&amp;nbsp;ed ...", "url": "https://dokumen.pub/machine-learning-a-bayesian-and-optimization-perspective-2nbsped-0128188030-9780128188033.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>machine</b>-<b>learning</b>-a-<b>bayesian</b>-and-<b>optimization</b>-perspective-2nbsped...", "snippet": "<b>Machine</b> <b>Learning</b> A <b>Bayesian</b> and <b>Optimization</b> Perspective <b>Machine</b> <b>Learning</b> A <b>Bayesian</b> and <b>Optimization</b> Perspective 2nd Edition Sergios Theodoridis Department of Informatics and Telecommunications National and Kapodistrian University of Athens Athens, Greece Shenzhen Research Institute of Big Data The Chinese University of Hong Kong Shenzhen, China Academic Press is an imprint of Elsevier 125 London Wall, London EC2Y 5AS, United Kingdom 525 B Street, Suite 1650, San Diego, CA 92101, United ...", "dateLastCrawled": "2022-01-28T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The Hitchhiker\u2019s Guide to <b>Optimization</b> in <b>Machine Learning</b> | by Aman ...", "url": "https://towardsdatascience.com/the-hitchhikers-guide-to-optimization-in-machine-learning-edcf5a104210", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-hitchhikers-guide-to-<b>optimization</b>-in-<b>machine</b>...", "snippet": "Gradient descent is one of the easiest to implement (and arguably one of the worst) <b>optimization</b> algorithms in <b>machine learning</b>. It is a first-order (i.e., gradient-based) <b>optimization</b> algorithm where we iteratively update the parameters of a differentiable cost function until its minimum is attained. Before we understand how gradient descent works, first let us have a look at the generalized formula of GD: Gradient descent (Image by author) The basic idea here is to update the model ...", "dateLastCrawled": "2022-02-02T19:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Three things to help you <b>get started on Bayesian Optimisation</b> | Oxford ...", "url": "https://www.blopig.com/blog/2019/09/three-things-to-help-you-get-started-on-bayesian-optimisation/", "isFamilyFriendly": true, "displayUrl": "https://www.blopig.com/blog/2019/09/three-things-to-help-you-get-started-on-<b>bayesian</b>...", "snippet": "This entry was posted in Code, <b>Machine</b> <b>Learning</b>, <b>Optimization</b>, Python and tagged <b>Bayesian</b> <b>optimization</b> on September 3, 2019 by Susan Leung. Post navigation \u2190 OpenMM \u2013 easy to learn, highly flexible molecular dynamics in Python When OPIGlets leave the office \u2192", "dateLastCrawled": "2022-01-22T10:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b> <b>learning</b> for high-throughput experimental exploration of metal ...", "url": "https://www.sciencedirect.com/science/article/pii/S2542435121004451", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2542435121004451", "snippet": "The synthesis process is controlled by <b>Bayesian</b> <b>optimization</b> (BO) workflow that can simultaneously optimize the optoelectronic properties by composition selection and processing parameters for thin film materials. The alternative is the microfluidic systems as e.g., developed by Abolhasani et al. Figure 3B). 52, 53, 54 Here, using a modular microfluidic platform enables continuous manufacturing of inorganic MHP QDs guided by an ensemble neural network (ENN) exploration of the colloidal ...", "dateLastCrawled": "2022-01-23T17:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Preliminary performance study of a brief review on <b>machine</b> <b>learning</b> ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "snippet": "<b>Analogy</b>-based effort estimation is the major task of software engineering which estimates the effort required for new software projects using existing histories for corresponding development and management. In general, the high accuracy of software effort estimation techniques can be a non-solvable problem we named as multi-objective problem. Recently, most of the authors have been used <b>machine</b> <b>learning</b> techniques for the same process however not possible to meet the higher performance ...", "dateLastCrawled": "2022-01-02T12:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian Optimization</b> Concept Explained in Layman Terms | by Wei Wang ...", "url": "https://towardsdatascience.com/bayesian-optimization-concept-explained-in-layman-terms-1d2bcdeaf12f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bayesian-optimization</b>-concept-explained-in-layman-terms...", "snippet": "<b>Bayesian Optimization</b> has been widely used for the hyperparameter tuning purpose in the <b>Machine</b> <b>Learning</b> world. Despite the fact that there are many terms and math formulas involved, the concept behind turns out to be very simple. The goal of this article is to share what I learned about <b>Bayesian Optimization</b> with a straight forward interpretation of textbook terminologies, and hopefully, it will help you understand what <b>Bayesian Optimization</b> is in a short period of time. The Overview of ...", "dateLastCrawled": "2022-01-29T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian optimization</b> or <b>gradient descent</b>? - Cross Validated", "url": "https://stats.stackexchange.com/questions/161923/bayesian-optimization-or-gradient-descent", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/161923/<b>bayesian-optimization</b>-or-<b>gradient-descent</b>", "snippet": "The most immediate difference is that <b>Bayesian optimization</b> is applicable when you don&#39;t know the gradients. If you can cheaply compute gradients of your function, you&#39;ll want to use a method that can incorporate those, since they can be extremely helpful in understanding the function. If you can&#39;t easily compute gradients and need to resort to ...", "dateLastCrawled": "2022-02-02T21:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Study Neural Architecture Search", "url": "https://www.cse.cuhk.edu.hk/lyu/_media/students/lyu2002_1st_term_report.pdf?id=students%3Afyp&cache=cache", "isFamilyFriendly": true, "displayUrl": "https://www.cse.cuhk.edu.hk/lyu/_media/students/lyu2002_1st_term_report.pdf?id=students...", "snippet": "searching for the best hyperparameters of a <b>machine</b> <b>learning</b> model to attain the best performance. Common hyperparameters of a model are <b>learning</b> rate, batch size, number of training epoch etc. While it is not the focus of our project, it is worth to mention that hyperparameter optimization overlaps a lot with NAS. We can think of the architecture of a network as one of the hyperparameters of the network. Meta-<b>learning</b> suggests using meta-data to lead the <b>learning</b> of our model. Meta-data is ...", "dateLastCrawled": "2021-12-15T21:44:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What&#39;s <b>trending in machine learning (outside of deep learning</b>)? - Quora", "url": "https://www.quora.com/Whats-trending-in-machine-learning-outside-of-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Whats-<b>trending-in-machine-learning-outside-of-deep-learning</b>", "snippet": "Answer (1 of 11): I don\u2019t know about trending, but I know of a powerful method (outside of mainstream ML) which is demonstrated to have tremendous flexibility, interpretability, and the advantage of relative ease of implementation in VLSI/FPGA hardware. Volterra Kernels The easiest way to under...", "dateLastCrawled": "2022-01-22T10:52:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(bayesian optimization)  is like +(human learning by trial and error)", "+(bayesian optimization) is similar to +(human learning by trial and error)", "+(bayesian optimization) can be thought of as +(human learning by trial and error)", "+(bayesian optimization) can be compared to +(human learning by trial and error)", "machine learning +(bayesian optimization AND analogy)", "machine learning +(\"bayesian optimization is like\")", "machine learning +(\"bayesian optimization is similar\")", "machine learning +(\"just as bayesian optimization\")", "machine learning +(\"bayesian optimization can be thought of as\")", "machine learning +(\"bayesian optimization can be compared to\")"]}