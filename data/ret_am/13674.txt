{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Addressing issues of fairness and</b> bias in AI - <b>Thomson Reuters Institute</b>", "url": "https://www.thomsonreuters.com/en-us/posts/news-and-media/ai-fairness-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.thomsonreuters.com/en-us/posts/news-and-media/ai-<b>fairness</b>-bias", "snippet": "For data scientists, addressing the problem of unfairness in <b>machine</b> <b>learning</b> and artificial intelligence requires defining certain statistical qualities of \u201c<b>fairness</b>,\u201d then <b>tweaking</b> and testing the <b>algorithm</b> to ensure a fair (or at least fairer) result. Unfortunately, Nielsen explained, the road to <b>fairness</b> in <b>machine</b> <b>learning</b> is littered with obstacles, not all of which can be easily overcome.", "dateLastCrawled": "2022-02-03T21:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Ethics of AI: <b>Benefits and risks of artificial intelligence</b> | <b>ZDNet</b>", "url": "https://www.zdnet.com/article/ethics-of-ai-the-benefits-and-risks-of-artificial-intelligence/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.zdnet.com</b>/article/ethics-of-ai-the-<b>benefits-and-risks-of-artificial</b>...", "snippet": "On the first score, the scale of data sets, scholars have argued for going beyond merely <b>tweaking</b> <b>a machine</b> <b>learning</b> system in order to mitigate bias, and to instead investigate the data sets used ...", "dateLastCrawled": "2022-02-02T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "9.3 <b>Counterfactual</b> Explanations | Interpretable <b>Machine</b> <b>Learning</b>", "url": "https://christophm.github.io/interpretable-ml-book/counterfactual.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-book/<b>counterfactual</b>.html", "snippet": "In interpretable <b>machine</b> <b>learning</b>, <b>counterfactual</b> explanations can be used to explain predictions of <b>individual</b> instances. The \u201cevent\u201d is the predicted outcome of an instance, the \u201ccauses\u201d are the particular feature values of this instance that were input to the model and \u201ccaused\u201d a certain prediction. Displayed as a graph, the relationship between the inputs and the prediction is very simple: The feature values cause the prediction.", "dateLastCrawled": "2022-02-03T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "seai/I4_<b>fairness</b>.md at S2021 \u00b7 <b>ckaestne/seai</b> \u00b7 GitHub", "url": "https://github.com/ckaestne/seai/blob/S2021/assignments/I4_fairness.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>ckaestne/seai</b>/blob/S2021/assignments/I4_<b>fairness</b>.md", "snippet": "Measure the <b>fairness</b>\u2013accuracy tradeoff in <b>machine</b> <b>learning</b>; Suggest <b>fairness</b> practices throughout a system\u2019s life cycle ; Dataset. For the first tasks of this assignment, you will work with a dataset from a credit card scoring system used by Schufa, a German private credit bureau. Schufa scores are similar to FICO scores in the US; most German citizens have a Schufa score, and these scores are used to inform financial decisions in various contexts, from banking and insurance to real ...", "dateLastCrawled": "2021-08-17T14:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Ethics of AI: <b>A Data Scientist\u2019s Perspective</b> | by QuantumBlack, a ...", "url": "https://medium.com/quantumblack/ethics-of-ai-a-data-scientists-perspective-cb7cdb1c8392", "isFamilyFriendly": true, "displayUrl": "https://medium.com/quantumblack/ethics-of-ai-<b>a-data-scientists-perspective</b>-cb7cdb1c8392", "snippet": "<b>Individual</b> discrimination occurs when an <b>algorithm</b> treats an <b>individual</b> unequally to another, despite both possessing similar features \u2014 e.g., an ethnic minority candidate and a caucasian ...", "dateLastCrawled": "2021-01-22T01:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Myth: <b>AI can be objective/unbiased</b> | AI Myths", "url": "https://www.aimyths.org/ai-can-be-objective-or-unbiased/", "isFamilyFriendly": true, "displayUrl": "https://www.aimyths.org/ai-can-be-objective-or-unbiased", "snippet": "For a basic explanation of <b>machine</b> <b>learning</b>, see these helpful videos from the Royal Society on What is <b>machine</b> <b>learning</b>? or check out this article from MIT Technology Review: &quot;<b>Machine</b>-<b>learning</b> algorithms use statistics to find patterns in massive amounts of data. And data, here, encompasses a lot of things\u2014numbers, words, images, clicks, what have you. If it can be digitally stored, it can be fed into <b>a machine</b>-<b>learning</b> <b>algorithm</b>.&quot;", "dateLastCrawled": "2022-02-01T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How the <b>machine</b> \u2018thinks\u2019: Understanding <b>opacity</b> in <b>machine</b> <b>learning</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2053951715622512", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2053951715622512", "snippet": "A given <b>machine</b> <b>learning</b> <b>algorithm</b> generally includes two parallel operations, or two distinct algorithms: a \u2018classifier\u2019 and a \u2018learner\u2019 (see, for example, Figure 3). Classifiers take input (referred to as a set of \u2018features\u2019) and produce an output (a \u2018category\u2019). For example, a classifier that does spam filtering takes a set of features (such as email header information, words in the body of the email, etc.) and produces one of two output categories (\u2018spam\u2019 or \u2018not ...", "dateLastCrawled": "2022-01-29T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Idea Behind <b>LIME</b> and <b>SHAP</b>. Intuition behind ML interpretation\u2026 | by ...", "url": "https://towardsdatascience.com/idea-behind-lime-and-shap-b603d35d34eb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/idea-behind-<b>lime</b>-and-<b>shap</b>-b603d35d34eb", "snippet": "<b>LIME</b> and <b>SHAP</b> are surrogate models (Figure 1). It means they still use the black-box <b>machine</b> <b>learning</b> models. They tweak the input slightly (<b>like</b> we do in sensitivity tests) and test the changes in prediction. This tweak has to be small so that it is still close to the original data point (or in the local region). <b>LIME</b> and <b>SHAP</b> models are ...", "dateLastCrawled": "2022-02-03T15:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Interpretability vs Explainability: The Black</b> Box of <b>Machine</b> <b>Learning</b> ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/<b>machine</b>-<b>learning</b>-interpretability-vs-explainability", "snippet": "Explainability becomes significant in the field of <b>machine</b> <b>learning</b> because, often, it is not apparent. Explainability is often unnecessary. <b>A machine</b> <b>learning</b> engineer can build a model without ever having considered the model\u2019s explainability. It is an extra step in the building process\u2014<b>like</b> wearing a seat belt while driving a car. It is ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "He got Facebook hooked on AI. Now he can&#39;t fix its misinformation ...", "url": "https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.technologyreview.com</b>/2021/03/11/1020600/facebook-responsible-ai-misinformation", "snippet": "The trained <b>algorithm</b>, known as <b>a machine</b>-<b>learning</b> model, can then automate future decisions. An <b>algorithm</b> trained on ad click data, for example, might learn that women click on ads for yoga ...", "dateLastCrawled": "2022-02-02T23:34:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Addressing issues of fairness and</b> bias in AI - <b>Thomson Reuters Institute</b>", "url": "https://www.thomsonreuters.com/en-us/posts/news-and-media/ai-fairness-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.thomsonreuters.com/en-us/posts/news-and-media/ai-<b>fairness</b>-bias", "snippet": "For data scientists, addressing the problem of unfairness in <b>machine</b> <b>learning</b> and artificial intelligence requires defining certain statistical qualities of \u201c<b>fairness</b>,\u201d then <b>tweaking</b> and testing the <b>algorithm</b> to ensure a fair (or at least fairer) result. Unfortunately, Nielsen explained, the road to <b>fairness</b> in <b>machine</b> <b>learning</b> is littered with obstacles, not all of which can be easily overcome.", "dateLastCrawled": "2022-02-03T21:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The long road to fairer algorithms", "url": "https://www.nature.com/articles/d41586-020-00274-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/d41586-020-00274-3", "snippet": "<b>Individual</b> <b>fairness</b> 17. This concept states that <b>similar</b> individuals should get <b>similar</b> predictions. If two people are alike except for their sexual orientation, say, an <b>algorithm</b> that displays ...", "dateLastCrawled": "2022-01-26T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>TWEAKING</b> MORAL COMPLEXITY IN VIDEOGAMES? OPTIMISING PLAYER EXPERIENCES ...", "url": "https://www.ihci-conf.org/wp-content/uploads/2021/07/03_202105C028_Hanussek.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ihci-conf.org/wp-content/uploads/2021/07/03_202105C028_Hanussek.pdf", "snippet": "However, based on these data sets, a genetic <b>machine</b> <b>learning</b> <b>algorithm</b> was applied to create weights for the <b>individual</b> decisions within branching narrative. A new test group with <b>similar</b> age and gender participants like the original group were invited to do the test again (Pereira Santos 2019: 72). This time, the results", "dateLastCrawled": "2021-12-31T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Equity of Attention: Amortizing <b>Individual</b> <b>Fairness</b> in Rankings", "url": "https://www.researchgate.net/publication/324982483_Equity_of_Attention_Amortizing_Individual_Fairness_in_Rankings", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324982483_Equity_of_Attention_Amortizing...", "snippet": "<b>Algorithm</b> <b>fairness</b> is an established line of research in the <b>machine</b> <b>learning</b> domain with substantial work while the equivalent in the recommender system domain is relatively new. In this article ...", "dateLastCrawled": "2022-01-10T00:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "seai/I4_<b>fairness</b>.md at S2021 \u00b7 <b>ckaestne/seai</b> \u00b7 GitHub", "url": "https://github.com/ckaestne/seai/blob/S2021/assignments/I4_fairness.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>ckaestne/seai</b>/blob/S2021/assignments/I4_<b>fairness</b>.md", "snippet": "Measure the <b>fairness</b>\u2013accuracy tradeoff in <b>machine</b> <b>learning</b>; Suggest <b>fairness</b> practices throughout a system\u2019s life cycle; Dataset. For the first tasks of this assignment, you will work with a dataset from a credit card scoring system used by Schufa, a German private credit bureau. Schufa scores are <b>similar</b> to FICO scores in the US; most German citizens have a Schufa score, and these scores are used to inform financial decisions in various contexts, from banking and insurance to real ...", "dateLastCrawled": "2021-08-17T14:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "9.3 <b>Counterfactual</b> Explanations | Interpretable <b>Machine</b> <b>Learning</b>", "url": "https://christophm.github.io/interpretable-ml-book/counterfactual.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-book/<b>counterfactual</b>.html", "snippet": "In interpretable <b>machine</b> <b>learning</b>, <b>counterfactual</b> explanations can be used to explain predictions of <b>individual</b> instances. The \u201cevent\u201d is the predicted outcome of an instance, the \u201ccauses\u201d are the particular feature values of this instance that were input to the model and \u201ccaused\u201d a certain prediction. Displayed as a graph, the relationship between the inputs and the prediction is very simple: The feature values cause the prediction.", "dateLastCrawled": "2022-02-03T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Ethics of AI: <b>Benefits and risks of artificial intelligence</b> | <b>ZDNet</b>", "url": "https://www.zdnet.com/article/ethics-of-ai-the-benefits-and-risks-of-artificial-intelligence/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.zdnet.com</b>/article/ethics-of-ai-the-<b>benefits-and-risks-of-artificial</b>...", "snippet": "On the first score, the scale of data sets, scholars have argued for going beyond merely <b>tweaking</b> <b>a machine</b> <b>learning</b> system in order to mitigate bias, and to instead investigate the data sets used ...", "dateLastCrawled": "2022-02-02T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How the <b>machine</b> \u2018thinks\u2019: Understanding <b>opacity</b> in <b>machine</b> <b>learning</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2053951715622512", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2053951715622512", "snippet": "A given <b>machine</b> <b>learning</b> <b>algorithm</b> generally includes two parallel operations, or two distinct algorithms: a \u2018classifier\u2019 and a \u2018learner\u2019 (see, for example, Figure 3). Classifiers take input (referred to as a set of \u2018features\u2019) and produce an output (a \u2018category\u2019). For example, a classifier that does spam filtering takes a set of features (such as email header information, words in the body of the email, etc.) and produces one of two output categories (\u2018spam\u2019 or \u2018not ...", "dateLastCrawled": "2022-01-29T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Interpretability vs Explainability: The Black</b> Box of <b>Machine</b> <b>Learning</b> ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/<b>machine</b>-<b>learning</b>-interpretability-vs-explainability", "snippet": "Interpretability has to do with how accurate <b>a machine</b> <b>learning</b> model can associate a cause to an effect. Explainability has to do with the ability of the parameters, often hidden in Deep Nets, to justify the results. This is a long article. Hang in there and, by the end, you will understand: How interpretability is different from explainability.", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What do you think of &#39;<b>Machine</b> Teaching&#39;? Do you think this is just a ...", "url": "https://www.quora.com/What-do-you-think-of-Machine-Teaching-Do-you-think-this-is-just-a-new-concept-of-reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-do-you-think-of-<b>Machine</b>-Teaching-Do-you-think-this-is-just...", "snippet": "Answer: I think <b>machine</b> teaching is a fascinating research area! What is <b>Machine</b> Teaching? <b>Machine</b> teaching is the problem of choosing a set (or sequence) of training examples to teach a learner. In contrast, normal <b>machine</b> <b>learning</b> is about designing a <b>learning</b> <b>algorithm</b> to extract a model fro...", "dateLastCrawled": "2022-01-23T18:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "4. <b>Fairness</b> Pre-Processing - Practical <b>Fairness</b> [Book]", "url": "https://www.oreilly.com/library/view/practical-fairness/9781492075721/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/practical-<b>fairness</b>/9781492075721/ch04.html", "snippet": "Chapter 4. <b>Fairness</b> Pre-Processing. As discussed in the previous chapter, <b>fairness</b> <b>can</b> affect three stages of the data modeling pipeline. This chapter focuses on the earliest stage, adjusting the way that data is translated into inputs for <b>a machine</b> <b>learning</b> training process, also called pre-processing the data.. The advantages of pre-processing a data set are numerous.", "dateLastCrawled": "2022-01-13T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Principles and Practice of Explainable <b>Machine</b> <b>Learning</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8281957/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8281957", "snippet": "To this end, we first provide general perspectives on explainable <b>machine</b> <b>learning</b> that covers: notions of transparency, criteria for evaluating explainability, as well as the type of explanations one <b>can</b> expect in general. We then turn to some frameworks for summarizing developments on explainable <b>machine</b> <b>learning</b>. A taxonomic framework provides an overview of explainable ML, and the other two frameworks study certain aspects of the taxonomy. A detailed discussion on transparent vs. opaque ...", "dateLastCrawled": "2022-01-30T04:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Myth: <b>AI can be objective/unbiased</b> | AI Myths", "url": "https://www.aimyths.org/ai-can-be-objective-or-unbiased/", "isFamilyFriendly": true, "displayUrl": "https://www.aimyths.org/ai-<b>can</b>-be-objective-or-unbiased", "snippet": "For a basic explanation of <b>machine</b> <b>learning</b>, see these helpful videos from the Royal Society on What is <b>machine</b> <b>learning</b>? or check out this article from MIT Technology Review: &quot;<b>Machine</b>-<b>learning</b> algorithms use statistics to find patterns in massive amounts of data. And data, here, encompasses a lot of things\u2014numbers, words, images, clicks, what have you. If it <b>can</b> be digitally stored, it <b>can</b> be fed into <b>a machine</b>-<b>learning</b> <b>algorithm</b>.&quot;", "dateLastCrawled": "2022-02-01T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Idea Behind <b>LIME</b> and <b>SHAP</b>. Intuition behind ML interpretation\u2026 | by ...", "url": "https://towardsdatascience.com/idea-behind-lime-and-shap-b603d35d34eb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/idea-behind-<b>lime</b>-and-<b>shap</b>-b603d35d34eb", "snippet": "In <b>machine</b> <b>learning</b>, there has been a trade-off between model complexity and model performance. Complex <b>machine</b> <b>learning</b> models e.g. deep <b>learning</b> (that perform better than interpretable models e.g\u2026 Get started. Open in app. Sign in. Get started. Follow. 618K Followers \u00b7 Editors&#39; Picks Features Deep Dives Grow Contribute. About. Get started. Open in app. Idea Behind <b>LIME</b> and <b>SHAP</b>. The intuition behind ML interpretation models. ashutosh nayak. Dec 22, 2019 \u00b7 7 min read. In <b>machine</b> ...", "dateLastCrawled": "2022-02-03T15:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretability vs Explainability: The Black</b> Box of <b>Machine</b> <b>Learning</b> ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/<b>machine</b>-<b>learning</b>-interpretability-vs-explainability", "snippet": "Interpretability has to do with how accurate <b>a machine</b> <b>learning</b> model <b>can</b> associate a cause to an effect. Explainability has to do with the ability of the parameters, often hidden in Deep Nets, to justify the results. This is a long article. Hang in there and, by the end, you will understand: How interpretability is different from explainability.", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The ethics of <b>algorithms</b>: Mapping the debate - Brent Daniel Mittelstadt ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2053951716679679", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2053951716679679", "snippet": "<b>A machine</b> <b>learning</b> <b>algorithm</b> applied to classification tasks, for example, typically consists of two components, a learner which produces a classifier, with the intention to develop classes that <b>can</b> generalise beyond the training data (Domingos, 2012). The <b>algorithm&#39;s</b> work involves placing new inputs into a model or classification structure. Image recognition technologies, for example, <b>can</b> decide what types of objects appear in a picture. The <b>algorithm</b> \u2018learns\u2019 by defining rules to ...", "dateLastCrawled": "2022-02-03T00:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b>, Trust, and the Whole Transparency Thing", "url": "https://www.researchgate.net/publication/341285103_Machine_Learning_Trust_and_the_Whole_Transparency_Thing", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341285103_<b>Machine</b>_<b>Learning</b>_Trust_and_the...", "snippet": "underlying <b>machine</b> <b>learning</b> <b>algorithm</b>, while others are specific for an <b>algorithm</b> or type of input or o utput. T o test if a model gives sound and trustable output, experts <b>can</b> look at many parame ...", "dateLastCrawled": "2022-01-23T11:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>The Ethics of Algorithms: Mapping the Debate</b>", "url": "https://www.researchgate.net/publication/309322060_The_Ethics_of_Algorithms_Mapping_the_Debate", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/309322060", "snippet": "<b>A machine</b> <b>learning</b> <b>algorithm</b>. applied to classi\ufb01cation tasks, for example, typically . consists of two components, a learner which produces. a classi\ufb01er, with the intention to develop classes ...", "dateLastCrawled": "2022-02-03T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "He got Facebook hooked on AI. Now he <b>can</b>&#39;t fix its misinformation ...", "url": "https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.technologyreview.com</b>/2021/03/11/1020600/facebook-responsible-ai-misinformation", "snippet": "The trained <b>algorithm</b>, known as <b>a machine</b>-<b>learning</b> model, <b>can</b> then automate future decisions. An <b>algorithm</b> trained on ad click data, for example, might learn that women click on ads for yoga ...", "dateLastCrawled": "2022-02-02T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What do you think of &#39;<b>Machine</b> Teaching&#39;? Do you think this is just a ...", "url": "https://www.quora.com/What-do-you-think-of-Machine-Teaching-Do-you-think-this-is-just-a-new-concept-of-reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-do-you-think-of-<b>Machine</b>-Teaching-Do-you-think-this-is-just...", "snippet": "Answer: I think <b>machine</b> teaching is a fascinating research area! What is <b>Machine</b> Teaching? <b>Machine</b> teaching is the problem of choosing a set (or sequence) of training examples to teach a learner. In contrast, normal <b>machine</b> <b>learning</b> is about designing a <b>learning</b> <b>algorithm</b> to extract a model fro...", "dateLastCrawled": "2022-01-23T18:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Addressing issues of fairness and</b> bias in AI - <b>Thomson Reuters Institute</b>", "url": "https://www.thomsonreuters.com/en-us/posts/news-and-media/ai-fairness-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.thomsonreuters.com/en-us/posts/news-and-media/ai-<b>fairness</b>-bias", "snippet": "For data scientists, addressing the problem of unfairness in <b>machine</b> <b>learning</b> and artificial intelligence requires defining certain statistical qualities of \u201c<b>fairness</b>,\u201d then <b>tweaking</b> and testing the <b>algorithm</b> to ensure a fair (or at least fairer) result. Unfortunately, Nielsen explained, the road to <b>fairness</b> in <b>machine</b> <b>learning</b> is littered with obstacles, not all of which <b>can</b> be easily overcome.", "dateLastCrawled": "2022-02-03T21:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "FairEdit: Preserving <b>Fairness</b> in Graph Neural Networks through Greedy ...", "url": "https://deepai.org/publication/fairedit-preserving-fairness-in-graph-neural-networks-through-greedy-graph-editing", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/fairedit-preserving-<b>fairness</b>-in-graph-neural-networks...", "snippet": "A survey on <b>fairness</b> in <b>machine</b> <b>learning</b> [] identified two reasons for algorithmic unfairness: a) bias in the data and b) and an <b>algorithm</b>\u2019s susceptibility to biasThey evaluated the COMPAS software which measures the risk of an offender recommitting a crime [], finding heavy racial bias. They cite the unwillingness of the authors to open-source their proprietary data as one of the driving issues. Another example that has demonstrated unfairness is the recent adoption of facial recognition ...", "dateLastCrawled": "2022-01-24T11:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Equity of Attention: Amortizing <b>Individual</b> <b>Fairness</b> in Rankings", "url": "https://www.researchgate.net/publication/324982483_Equity_of_Attention_Amortizing_Individual_Fairness_in_Rankings", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324982483_Equity_of_Attention_Amortizing...", "snippet": "<b>Algorithm</b> <b>fairness</b> is an established line of research in the <b>machine</b> <b>learning</b> domain with substantial work while the equivalent in the recommender system domain is relatively new. In this article ...", "dateLastCrawled": "2022-01-10T00:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>TWEAKING</b> MORAL COMPLEXITY IN VIDEOGAMES? OPTIMISING PLAYER EXPERIENCES ...", "url": "https://www.ihci-conf.org/wp-content/uploads/2021/07/03_202105C028_Hanussek.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ihci-conf.org/wp-content/uploads/2021/07/03_202105C028_Hanussek.pdf", "snippet": "before they played the game, and the results were then <b>compared</b>. The outcomes showed no statistically significant correlation at first. (Pereira Santos 2019: 71-72). However, based on these data sets, a genetic <b>machine</b> <b>learning</b> <b>algorithm</b> was applied to create weights for the <b>individual</b> decisions within branching narrative. A new test group with ...", "dateLastCrawled": "2021-12-31T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "4. <b>Fairness</b> Pre-Processing - Practical <b>Fairness</b> [Book]", "url": "https://www.oreilly.com/library/view/practical-fairness/9781492075721/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/practical-<b>fairness</b>/9781492075721/ch04.html", "snippet": "Chapter 4. <b>Fairness</b> Pre-Processing. As discussed in the previous chapter, <b>fairness</b> <b>can</b> affect three stages of the data modeling pipeline. This chapter focuses on the earliest stage, adjusting the way that data is translated into inputs for <b>a machine</b> <b>learning</b> training process, also called pre-processing the data.. The advantages of pre-processing a data set are numerous.", "dateLastCrawled": "2022-01-13T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Principles and Practice of Explainable <b>Machine</b> <b>Learning</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8281957/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8281957", "snippet": "To this end, we first provide general perspectives on explainable <b>machine</b> <b>learning</b> that covers: notions of transparency, criteria for evaluating explainability, as well as the type of explanations one <b>can</b> expect in general. We then turn to some frameworks for summarizing developments on explainable <b>machine</b> <b>learning</b>. A taxonomic framework provides an overview of explainable ML, and the other two frameworks study certain aspects of the taxonomy. A detailed discussion on transparent vs. opaque ...", "dateLastCrawled": "2022-01-30T04:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Myth: <b>AI can be objective/unbiased</b> | AI Myths", "url": "https://www.aimyths.org/ai-can-be-objective-or-unbiased/", "isFamilyFriendly": true, "displayUrl": "https://www.aimyths.org/ai-<b>can</b>-be-objective-or-unbiased", "snippet": "For a basic explanation of <b>machine</b> <b>learning</b>, see these helpful videos from the Royal Society on What is <b>machine</b> <b>learning</b>? or check out this article from MIT Technology Review: &quot;<b>Machine</b>-<b>learning</b> algorithms use statistics to find patterns in massive amounts of data. And data, here, encompasses a lot of things\u2014numbers, words, images, clicks, what have you. If it <b>can</b> be digitally stored, it <b>can</b> be fed into <b>a machine</b>-<b>learning</b> <b>algorithm</b>.&quot;", "dateLastCrawled": "2022-02-01T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Interpretability vs Explainability: The Black</b> Box of <b>Machine</b> <b>Learning</b> ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/<b>machine</b>-<b>learning</b>-interpretability-vs-explainability", "snippet": "Interpretability has to do with how accurate <b>a machine</b> <b>learning</b> model <b>can</b> associate a cause to an effect. Explainability has to do with the ability of the parameters, often hidden in Deep Nets, to justify the results. This is a long article. Hang in there and, by the end, you will understand: How interpretability is different from explainability.", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Machine</b> <b>Learning</b> as a Service \u2013 Challenges in Research and ...", "url": "https://www.researchgate.net/publication/346471896_Machine_Learning_as_a_Service_-_Challenges_in_Research_and_Applications", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/346471896_<b>Machine</b>_<b>Learning</b>_as_a_Service...", "snippet": "<b>tweaking</b> options for advanced <b>machine</b> <b>learning</b> engineers. Through their platform, they achieve faster time- to -market, model- reusability, scalability, availability and security.", "dateLastCrawled": "2022-01-28T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Deterring Adversarial Behavior at Scale in Gitcoin Grants | by ...", "url": "https://medium.com/block-science/deterring-adversarial-behavior-at-scale-in-gitcoin-grants-a8a5cd7899ff", "isFamilyFriendly": true, "displayUrl": "https://medium.com/block-science/deterring-adversarial-behavior-at-scale-in-gitcoin...", "snippet": "Many lessons in AI ethics and algorithmic <b>fairness</b> <b>can</b> be gained from Aaron Roth\u2019s The Ethical <b>Algorithm</b> and ongoing work on algorithms in society by some of our research contributors. The goal ...", "dateLastCrawled": "2022-01-20T06:48:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Practical <b>Individual</b> <b>Fairness</b> Algorithms \u2013 Toronto <b>Machine</b> <b>Learning</b>", "url": "https://www.torontomachinelearning.com/events/practical-individual-fairness-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.toronto<b>machinelearning</b>.com/events/practical-<b>individual</b>-<b>fairness</b>-algorithms", "snippet": "<b>Individual</b> <b>Fairness</b> (IF) is a very intuitive and desirable notion of <b>fairness</b>: we want ML models to treat similar individuals similarly, that is, to be fair for every person. For example, two resumes of individuals that only differ in their name and gender pronouns should be treated similarly by the model. Despite the intuition, training ML/AI models that abide by this rule in theory and in practice poses several challenges. In this talk, I will introduce a notion of Distributional ...", "dateLastCrawled": "2021-12-31T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Finding the <b>fairness</b> in ethical <b>machine</b> <b>learning</b> - Taylor Fry", "url": "https://taylorfry.nz/articles/finding-the-fairness-in-ethical-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://taylorfry.nz/articles/finding-the-<b>fairness</b>-in-ethical-<b>machine</b>-<b>learning</b>", "snippet": "Likewise, <b>machine</b> <b>learning</b> infrastructure is also missing, specifically, regulating the use of <b>machine</b> <b>learning</b> to ensure it\u2019s used in an ethical and beneficial way, rather than used by a small number for their advantage at the significant disadvantage of the majority. It\u2019s important we all continue to have this conversation together, and take action at <b>individual</b>, organisational, governmental and global levels to bring about a future where AI is used to help not hinder.", "dateLastCrawled": "2022-01-07T11:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fairness in Machine Learning: Lessons from Political Philosophy</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-lessons-from-political-philosophy", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-lessons-from-political</b>...", "snippet": "This discussion suggests that \u2018<b>fairness</b>\u2019 as used in the fair <b>machine</b> <b>learning</b> community is best understood as a placeholder term for a variety of normative egalitarian considerations. Notably, while egalitarianism is a widely held principle, exactly what it requires is the subject of much debate. I provide an overview of some of this debate and finish with implications for the incorporation of \u2018<b>fairness</b>\u2019 into algorithmic decision-making systems.", "dateLastCrawled": "2021-12-26T22:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "RStudio AI Blog: Starting to think about AI <b>Fairness</b>", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-<b>fairness</b>", "snippet": "Papers on <b>fairness</b> in <b>machine</b> <b>learning</b>, as is common in fields like computer science, abound with formulae. Even the papers referenced here, though selected not for their theorems and proofs but for the ideas they harbor, are no exception. But to start thinking about <b>fairness</b> as it might apply to an ML process at hand, common language \u2013 and common sense \u2013 will do just fine. If, after analyzing your use case, you judge that the more technical results are relevant to the process in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Residual Unfairness in Fair <b>Machine</b> <b>Learning</b> from Prejudiced Data", "url": "http://proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "snippet": "Recent work on <b>fairness</b> in <b>machine</b> <b>learning</b> proposes and analyzes competing criteria for assessing the <b>fairness</b> of <b>ma-chine</b> <b>learning</b> algorithms, where some adjustments attempt to equalize accuracy metrics across groups (Corbett-Davies etal.,2017;Kleinbergetal.,2017;Hardtetal.,2016). Other work studies how historical prejudices may be re\ufb02ected in training data such that algorithmic systems might replicate historical biases (Angwin et al., 2016; Lum &amp; Isaac, 2016; Kilbertus et al., 2017). We ...", "dateLastCrawled": "2022-01-31T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The <b>measure and mismeasure of fairness: a critical review</b> of fair ...", "url": "https://blog.acolyer.org/2020/02/03/measure-mismeasure-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blog.acolyer.org/2020/02/03/measure-mismeasure-<b>fairness</b>", "snippet": "In case you\u2019re wondering where on earth I\u2019m going with this\u2026 it\u2019s a very stretched <b>analogy</b> I\u2019ve been playing with in my mind. One premise of many models of <b>fairness</b> in <b>machine</b> <b>learning</b> is that you can measure (\u2018prove\u2019) <b>fairness</b> of a <b>machine</b> <b>learning</b> model from within the system \u2013 i.e. from properties of the model itself and perhaps the data it is trained on. Beyond the questions of whether any one model of <b>fairness</b> is better or worse than another, I\u2019m coming to the ...", "dateLastCrawled": "2022-01-30T11:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to <b>Create Unbiased ML Models | Deepchecks</b>", "url": "https://deepchecks.com/how-to-create-unbiased-ml-models/", "isFamilyFriendly": true, "displayUrl": "https://deepchecks.com/how-to-create-unbiased-ml-models", "snippet": "\u201cIn <b>machine</b> <b>learning</b>, a given algorithm is said to be fair, or to have <b>fairness</b>, if its results are independent of given variables, especially those considered sensitive, such as the traits of individuals which should not correlate with the outcome (i.e. gender, ethnicity, sexual orientation, disability, etc.).\u201d \u201c<b>Fairness</b>\u201d, Wikipedia", "dateLastCrawled": "2022-01-13T06:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Fairness</b> Through Awareness", "url": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "snippet": "this <b>individual</b>-based <b>fairness</b>, we assume a distance metric that de\ufb01nes the similarity between the individuals. This is the source of \u201cawareness\u201d in the title of this paper. We formalize this guiding principle as a Lipschitz condition on the classi\ufb01er. In our approach a classi\ufb01er is a randomized mapping from individuals to outcomes, or equivalently, a mapping from individuals to distributions over outcomes. The Lipschitz condition requires that any two individuals x;ythat are at ...", "dateLastCrawled": "2022-01-29T03:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine</b> <b>Learning</b> and Theological Traditions of <b>Analogy</b> - Davison - 2021 ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "snippet": "12 <b>Machine</b> <b>Learning</b>, <b>Analogy</b>, and God. The texts considered in this article come from theological sources. They have offered ways to think analogically about features of the world, in this case the similarities we are beginning to see between capacities in <b>machine</b> <b>learning</b> and those in human beings and other animals. Much of the mediaeval ...", "dateLastCrawled": "2021-04-16T10:41:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Making Fair ML Software using Trustworthy Explanation", "url": "https://www.researchgate.net/profile/Kewen-Peng-4/publication/342733939_Making_Fair_ML_Software_using_Trustworthy_Explanation/links/5fe0ddcea6fdccdcb8ef5a11/Making-Fair-ML-Software-using-Trustworthy-Explanation.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/profile/Kewen-Peng-4/publication/342733939_Making_Fair_ML...", "snippet": "<b>Machine</b> <b>learning</b> software is being used in many applications (fi-nance, hiring, admissions, criminal justice) having huge social im-pact. But sometimes the behavior of this software is biased and ...", "dateLastCrawled": "2021-09-29T17:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Making Fair <b>ML Software using Trustworthy Explanation</b> | DeepAI", "url": "https://deepai.org/publication/making-fair-ml-software-using-trustworthy-explanation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/making-fair-<b>ml-software-using-trustworthy-explanation</b>", "snippet": "<b>Machine</b> <b>learning</b> software is being used in many applications (finance, hiring, admissions, criminal justice) having a huge social impact. But sometimes the behavior of this software is biased and it shows discrimination based on some sensitive attributes such as sex, race, etc. Prior works concentrated on finding and mitigating bias in ML models.", "dateLastCrawled": "2022-01-24T00:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Making fair ML software using trustworthy explanation", "url": "https://www.researchgate.net/publication/348827111_Making_fair_ML_software_using_trustworthy_explanation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/348827111_Making_fair_ML_software_using...", "snippet": "PDF | On Dec 21, 2020, Joymallya Chakraborty and others published Making fair ML software using trustworthy explanation | Find, read and cite all the research you need on ResearchGate", "dateLastCrawled": "2021-11-13T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Service-Oriented Computing: 18th International Conference, ICSOC 2020 ...", "url": "https://dokumen.pub/service-oriented-computing-18th-international-conference-icsoc-2020-dubai-united-arab-emirates-december-1417-2020-proceedings-1st-ed-9783030653095-9783030653101.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/service-oriented-computing-18th-international-conference-icsoc...", "snippet": "In a Fog environment, a Kubernetes Node is a worker <b>machine</b>, and it may be a virtual <b>machine</b> or a physical <b>machine</b> that corresponds to a node, a.k.a., Fog node. A set of Kubernetes Nodes makes up a Kubernetes cluster. A Kubernetes cluster corresponds to a set of fog nodes. Each microservice can be containerized and, therefore, it belongs to a single Docker container. A Kubernetes Pod is a group of containers with shared network and storage, that are always coscheduled and co-located. Finally ...", "dateLastCrawled": "2021-12-24T17:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Counterfactual Fairness: Unidentification, Bound and Algorithm ...", "url": "https://www.researchgate.net/publication/334843895_Counterfactual_Fairness_Unidentification_Bound_and_Algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334843895_Counterfactual_Fairness_Un...", "snippet": "Fairness in <b>machine</b> <b>learning</b> has been a research subject with rapid growth recently. Many different definitions of fairness have been designed to fit different settings, e.g., equality of ...", "dateLastCrawled": "2021-12-23T12:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Putting <b>Fairness Principles into Practice: Challenges, Metrics</b>, and ...", "url": "https://deepai.org/publication/putting-fairness-principles-into-practice-challenges-metrics-and-improvements", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/putting-<b>fairness-principles-into-practice-challenges</b>...", "snippet": "By almost every measure, there has been an explosion in attention and research on <b>machine</b> <b>learning</b> fairness: there is a quickly growing amount of research on how to define, measure, and address <b>machine</b> <b>learning</b> fairness, and products are evaluated with these concerns in mind. Despite this significant attention, there has been much less published work detailing how fairness concerns are measured and addressed by product teams in industry. In this paper, we hope to shed light on the challenges ...", "dateLastCrawled": "2022-01-23T04:12:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(individual fairness)  is like +(tweaking a machine learning algorithm)", "+(individual fairness) is similar to +(tweaking a machine learning algorithm)", "+(individual fairness) can be thought of as +(tweaking a machine learning algorithm)", "+(individual fairness) can be compared to +(tweaking a machine learning algorithm)", "machine learning +(individual fairness AND analogy)", "machine learning +(\"individual fairness is like\")", "machine learning +(\"individual fairness is similar\")", "machine learning +(\"just as individual fairness\")", "machine learning +(\"individual fairness can be thought of as\")", "machine learning +(\"individual fairness can be compared to\")"]}