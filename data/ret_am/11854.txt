{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "3D <b>keypoints</b> definition for <b>car</b> models. 66 <b>keypoints</b> are defined for ...", "url": "https://www.researchgate.net/figure/3D-keypoints-definition-for-car-models-66-keypoints-are-defined-for-each-model_fig2_338509493", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/3D-<b>keypoints</b>-definition-for-<b>car</b>-models-66...", "snippet": "While only a handful of <b>keypoints</b> can be sufficient solve the EPnP problem, we define 66 semantic <b>keypoints</b> in our dataset, as shown in Fig. 3, which has much higher density than most previous <b>car</b> ...", "dateLastCrawled": "2022-01-13T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Viewpoints and Keypoints</b> | DeepAI", "url": "https://deepai.org/publication/viewpoints-and-keypoints", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>viewpoints-and-keypoints</b>", "snippet": "There are two ways in which one can describe the pose of the <b>car</b> in Figure 1 - either via its viewpoint or via specifying the locations of a fixed set of <b>keypoints</b>. The former characterization provides a global perspective about the object whereas the latter provides a more local one. In this work, we aim to reliably predict both these representations of pose for objects. Our overall approach is motivated by the theory of global precedence - that humans perceive the global structure before ...", "dateLastCrawled": "2022-01-25T15:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Viewpoints and Keypoints</b> - cv-foundation.org", "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Tulsiani_Viewpoints_and_Keypoints_2015_CVPR_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cv-foundation.org/.../Tulsiani_<b>Viewpoints_and_Keypoints</b>_2015_CVPR_paper.pdf", "snippet": "of the <b>car</b> in Figure1- either via its viewpoint or via spec-ifying the locations of a \ufb01xed set of <b>keypoints</b>. The former characterization provides a global perspective about the ob-ject whereas the latter provides a more local one. In this work, we aim to reliably predict both these representations of pose for objects. Our overall approach is motivated by the theory of global precedence - that humans perceive the global structure be-fore the \ufb01ne level local details [27]. It was also noted ...", "dateLastCrawled": "2022-01-13T19:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Real-time 3D <b>car</b> <b>pose estimation</b> trained on synthetic data", "url": "https://labs.laan.com/blog/real-time-3d-car-pose-estimation-trained-on-synthetic-data.html", "isFamilyFriendly": true, "displayUrl": "https://labs.laan.com/blog/real-time-3d-<b>car</b>-<b>pose-estimation</b>-trained-on-synthetic-data.html", "snippet": "Since the body pose network had 14 <b>keypoints</b>, that seemed <b>like</b> a reasonable starting point since it would reduce any modifications to the existing training pipeline. This step required creating 14 empty game objects and positioning them for each <b>car</b> model: 14 <b>Car</b> <b>Keypoints</b> Creating Variations in the Dataset A big concern when training on synthetic data is whether the model will generalize to real world images. This is an active and evolving research area with many interesting approaches ...", "dateLastCrawled": "2022-02-03T07:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How a Self-Driving <b>Car</b> Works With the Help of Machine Learning - <b>Intellias</b>", "url": "https://intellias.com/how-machine-learning-algorithms-make-self-driving-cars-a-reality/", "isFamilyFriendly": true, "displayUrl": "https://<b>intellias</b>.com/how-machine-learning-algorithms-make-self-driving-<b>car</b>s-a-reality", "snippet": "The algorithm uses an image database to extract salient points (i.e. <b>keypoints</b>) of an object. Those points are <b>features</b> of the object that don\u2019t change with scaling, rotation, clutter, or noise. In a self-driving <b>car</b>, machine learning algorithms compare every new image with the SIFT <b>features</b> that it has already extracted from the database. It detects correspondence between them to identify objects. For instance, when an autonomous <b>car</b> sees a triangular road sign, it takes its three corners ...", "dateLastCrawled": "2022-02-01T00:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Next-Generation Stereo Vision Autocalibration Software for</b> Advanced ...", "url": "https://medium.com/nodar-blog/next-generation-stereo-vision-autocalibration-software-for-adas-and-av-8e86327ace1f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/nodar-blog/<b>next-generation-stereo-vision-autocalibration-software</b>...", "snippet": "ORB picks out good <b>features</b>, <b>like</b> the <b>car</b> on the main road and the cars on the side road. However, all the matching <b>keypoints</b> returned are heavily clustered around the key objects with few ...", "dateLastCrawled": "2022-01-09T19:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Vehicle Detection using Support Vector Machine</b>(SVM) | by Avinash Singh ...", "url": "https://towardsdatascience.com/vehicle-detection-using-support-vector-machine-svm-19e073b61d16", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>vehicle-detection-using-support-vector-machine</b>-svm-19e...", "snippet": "Extracting spatial <b>features</b> of the image: After resizing the image, we still have all the <b>features</b> preserved of the image. Hence we resize the image, as with the help of this, our code will run a bit more fast with no loss of information. This can be done with the help of open cv function cv2.resize(). 2. Image Colorspace Conversion:", "dateLastCrawled": "2022-01-29T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "python - OpenCV Combining SURF with <b>Neural Network</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/14383034/opencv-combining-surf-with-neural-network", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/14383034", "snippet": "The <b>keypoints</b> have angles and each keypoint corresponds to a 64 or 128 long Vector as the Descriptor. What I don&#39;t know is what exactly these <b>keypoints</b> are and how they could be used as an input to the <b>Neural Network</b>. I am using OpenCV with Python. I am new to using SURF and other Feature Extraction methods. Any help pertaining to this will be very good. python image-processing opencv <b>neural-network</b> surf. Share. Follow asked Jan 17 &#39;13 at 15:59. Colenso Castellino Colenso Castellino. 880 2 2 ...", "dateLastCrawled": "2022-01-16T16:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Understanding Autonomous Technology and ADAS</b> - Team-BHP", "url": "https://www.team-bhp.com/forum/indian-car-scene/231085-understanding-autonomous-technology-adas.html", "isFamilyFriendly": true, "displayUrl": "https://www.team-bhp.com/forum/indian-<b>car</b>-scene/231085-understanding-autonomous...", "snippet": "Below are some videos from my YouTube channel demonstrating Adas <b>features</b> <b>like</b> ACC and Lane Keep Assist on the newly launched MG Astor. I tend to use ACC more on the highways and sometimes in the city when there is stop go traffic. However detection of motorbikes is sometimes an issue and other times even though the motorbike is detected, the system is not good enough to judge that it can drive through (as the motorbike is in the left edge of the driving corridor mostly).", "dateLastCrawled": "2022-02-02T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "10 <b>Qualities Of A Good Driver</b>. How Many Do You Have? - <b>Traffic Counsel</b>", "url": "https://www.trafficcounsel.com/10-qualities-of-a-good-driver-how-many-do-you-have/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>trafficcounsel</b>.com/10-<b>qualities-of-a-good-driver</b>-how-many-do-you-have", "snippet": "Not everyone is a good driver <b>like</b> you, there are many people on the road who are not <b>like</b> you. Hence, being a good driver, you must be absolutely alert all the time on the road for the safety of your self and people <b>like</b> you. Mechanical Skills. Well, not <b>like</b> a professional mechanic but a good driver should know the basic mechanical skills so that when the need arises, he or she can troubleshoot the basic issues of his or her vehicle. Responsible . One of the most important qualities of a ...", "dateLastCrawled": "2022-02-03T02:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "3D <b>keypoints</b> definition for <b>car</b> models. 66 <b>keypoints</b> are defined for ...", "url": "https://www.researchgate.net/figure/3D-keypoints-definition-for-car-models-66-keypoints-are-defined-for-each-model_fig2_338509493", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/3D-<b>keypoints</b>-definition-for-<b>car</b>-models-66...", "snippet": "While only a handful of <b>keypoints</b> can be sufficient solve the EPnP problem, we define 66 semantic <b>keypoints</b> in our dataset, as shown in Fig. 3, which has much higher density than most previous <b>car</b> ...", "dateLastCrawled": "2022-01-13T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Viewpoints and Keypoints</b> | DeepAI", "url": "https://deepai.org/publication/viewpoints-and-keypoints", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>viewpoints-and-keypoints</b>", "snippet": "There are two ways in which one can describe the pose of the <b>car</b> in Figure 1 - either via its viewpoint or via specifying the locations of a fixed set of <b>keypoints</b>. The former characterization provides a global perspective about the object whereas the latter provides a more local one. In this work, we aim to reliably predict both these representations of pose for objects. Our overall approach is motivated by the theory of global precedence - that humans perceive the global structure before ...", "dateLastCrawled": "2022-01-25T15:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Viewpoints and Keypoints</b> - cv-foundation.org", "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Tulsiani_Viewpoints_and_Keypoints_2015_CVPR_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cv-foundation.org/.../Tulsiani_<b>Viewpoints_and_Keypoints</b>_2015_CVPR_paper.pdf", "snippet": "of the <b>car</b> in Figure1- either via its viewpoint or via spec-ifying the locations of a \ufb01xed set of <b>keypoints</b>. The former characterization provides a global perspective about the ob-ject whereas the latter provides a more local one. In this work, we aim to reliably predict both these representations of pose for objects. Our overall approach is motivated by the theory of global precedence - that humans perceive the global structure be-fore the \ufb01ne level local details [27]. It was also noted ...", "dateLastCrawled": "2022-01-13T19:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Real-time 3D <b>car</b> <b>pose estimation</b> trained on synthetic data", "url": "https://labs.laan.com/blog/real-time-3d-car-pose-estimation-trained-on-synthetic-data.html", "isFamilyFriendly": true, "displayUrl": "https://labs.laan.com/blog/real-time-3d-<b>car</b>-<b>pose-estimation</b>-trained-on-synthetic-data.html", "snippet": "Even though these don\u2019t look like real street scenes, the many variations of the background and lighting should force the network to pick up on <b>car</b> <b>features</b> that remain constant throughout all the photos. If we only used a street scene, our detector would probably incorporate aspects of the street scene into its <b>features</b>; expecting certain shadow and lighting characteristics to always accompany the <b>car</b> itself.", "dateLastCrawled": "2022-02-03T07:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Feature detection (SIFT, SURF</b>, ORB) \u2013 OpenCV 3.4 with python 3 Tutorial ...", "url": "https://pysource.com/2018/03/21/feature-detection-sift-surf-obr-opencv-3-4-with-python-3-tutorial-25/", "isFamilyFriendly": true, "displayUrl": "https://pysource.com/2018/03/21/<b>feature-detection-sift-surf</b>-obr-opencv-3-4-with-python...", "snippet": "We find the <b>keypoints</b> and descriptors of each spefic algorythm. A keypoint is the position where the feature has been detected, while the descriptor is an array containing numbers to describe that feature. When the descriptors are <b>similar</b>, it means that also the feature <b>is similar</b>. You can see this tutorial to understand more about feature ...", "dateLastCrawled": "2022-01-31T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "python - why is FAST/ORB bad at finding <b>keypoints</b> near the edge of an ...", "url": "https://stackoverflow.com/questions/63651619/why-is-fast-orb-bad-at-finding-keypoints-near-the-edge-of-an-image", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/63651619", "snippet": "Usually, <b>keypoints</b> at the edge of the image are not useful for most applications. Consider e.g. a moving <b>car</b> or a plane for aerial images. Points at the image border are often not visible in the following frame. When calculating 3D reconstructions of objects most of the time the object of interest lies in the center of the image. Also the fact you mentioned, that most feature detectors work with areas of interest around pixels is important since these regions could give unwanted effects at ...", "dateLastCrawled": "2022-01-15T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 6, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Advanced driver-assistance systems</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Advanced_driver-assistance_systems", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Advanced_driver-assistance_systems</b>", "snippet": "Modern cars have ADAS integrated into their electronics; manufacturers can add these new <b>features</b>. ... Level 1 and 2 are very <b>similar</b> in that they both have the driver do most of the decision making. The difference is level 1 can take control over one functionality and level 2 can take control over multiple to aid the driver. ADAS that are considered level 1 are: adaptive cruise control, emergency brake assist, automatic emergency brake assist, lane-keeping, and lane centering. ADAS that are ...", "dateLastCrawled": "2022-02-03T00:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>OpenCV</b>: Features2D + <b>Homography</b> to find a known object", "url": "https://docs.opencv.org/3.4/d7/dff/tutorial_feature_homography.html", "isFamilyFriendly": true, "displayUrl": "https://docs.<b>opencv</b>.org/3.4/d7/dff/tutorial_feature_<b>homography</b>.html", "snippet": "Prev Tutorial: Feature Matching with FLANN Next Tutorial: Detection of planar objects Goal . In this tutorial you will learn how to: Use the function cv::<b>findHomography</b> to find the transform between matched <b>keypoints</b>.; Use the function cv::perspectiveTransform to map the points.; Warning You need the <b>OpenCV</b> contrib modules to be able to use the SURF <b>features</b> (alternatives are ORB, KAZE, ... <b>features</b>). Theory Code", "dateLastCrawled": "2022-02-02T14:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Understanding Autonomous Technology and ADAS</b> - Team-BHP", "url": "https://www.team-bhp.com/forum/indian-car-scene/231085-understanding-autonomous-technology-adas.html", "isFamilyFriendly": true, "displayUrl": "https://www.team-bhp.com/forum/indian-<b>car</b>-scene/231085-understanding-autonomous...", "snippet": "But the words, driver assistance, automated, autonomous, self-driving which we discuss a lot look <b>similar</b> but are quite different. There is a widespread misunderstanding of the <b>features</b> and with the OEMs now starting to launch these advanced systems into the Indian market (MG Gloster and upcoming Mahindra XUV5OO), we must be aware of the technicalities a bit to not get mislead by their marketing and ads.", "dateLastCrawled": "2022-02-02T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to match <b>2 HOG for object detection</b>? - OpenCV Q&amp;A Forum", "url": "https://answers.opencv.org/question/877/how-to-match-2-hog-for-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://answers.opencv.org/question/877/how-to-match-<b>2-hog-for-object-detection</b>", "snippet": "Those parameters are usually very <b>similar</b>, if not identical, for each patch of the input area. they are usually low-quality by themselves, and only their high numbers makes them useful for a classification task. However, no human would be able to correlate all the data to extract anything useful, or to build a distance function, or a threshold on what <b>is &quot;similar</b>&quot; or &quot;not <b>similar</b>&quot;. One would have to manually select and set thousands/tens of thousands of thresholds. This is why texture ...", "dateLastCrawled": "2022-02-01T08:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Viewpoints and Keypoints</b> - cv-foundation.org", "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Tulsiani_Viewpoints_and_Keypoints_2015_CVPR_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cv-foundation.org/.../Tulsiani_<b>Viewpoints_and_Keypoints</b>_2015_CVPR_paper.pdf", "snippet": "There are two ways in which one <b>can</b> describe the pose of the <b>car</b> in Figure1- either via its viewpoint or via spec-ifying the locations of a \ufb01xed set of <b>keypoints</b>. The former characterization provides a global perspective about the ob-ject whereas the latter provides a more local one. In this work, we aim to reliably predict both these representations of pose for objects. Our overall approach is motivated by the theory of global precedence - that humans perceive the global structure be-fore ...", "dateLastCrawled": "2022-01-13T19:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Viewpoints and <b>Keypoints</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1411.6067/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1411.6067", "snippet": "We characterize the problem of pose estimation for rigid objects in terms of determining viewpoint to explain coarse pose and keypoint prediction to capture the finer details. We address both these tasks in two different settings - the constrained setting with known bounding boxes and the more challenging detection setting where the aim is to simultaneously detect and correctly estimate pose of objects. We present Convolutional Neural Network based architectures for these and demonstrate ...", "dateLastCrawled": "2021-08-18T10:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Detecting facial keypoints with TensorFlow</b> - Alex Staravoitau\u2019s Blog", "url": "https://navoshta.com/facial-with-tensorflow/", "isFamilyFriendly": true, "displayUrl": "https://navoshta.com/facial-with-tensorflow", "snippet": "<b>Detecting facial keypoints with TensorFlow</b> 15 minute read This is a TensorFlow follow-along for an amazing Deep Learning tutorial by Daniel Nouri. Daniel describes ways of approaching a computer vision problem of detecting facial <b>keypoints</b> in an image using various deep learning techniques, while these techniques gradually build upon each other, demonstrating advantages and limitations of each.", "dateLastCrawled": "2022-02-03T11:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>StarMap for Category-Agnostic Keypoint and Viewpoint Estimation</b> | DeepAI", "url": "https://deepai.org/publication/starmap-for-category-agnostic-keypoint-and-viewpoint-estimation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>starmap-for-category-agnostic-keypoint-and-viewpoint</b>...", "snippet": "To combat scarcity of training data and generic <b>features</b>, ... chairs with legged bases and swivel bases cannot be learned together due to varying number of <b>keypoints</b>. As a result, they <b>can</b> not be considered as the same category based on their different keypoint configurations. To generalize heatmaps to multiple categories, a popular approach is to stack all heatmaps from all categories [37, 26] (resulting in \u2211 N c output channels, where N c is the number of <b>keypoints</b> of category c). In ...", "dateLastCrawled": "2021-12-22T20:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "computer vision - Purpose of <b>image feature detection and matching</b> ...", "url": "https://dsp.stackexchange.com/questions/11024/purpose-of-image-feature-detection-and-matching", "isFamilyFriendly": true, "displayUrl": "https://dsp.stackexchange.com/questions/11024/purpose-of-image-feature-detection-and...", "snippet": "Image <b>keypoints</b> are a key feature in many Image and Video processing softwares, both industrial and academic. The principle behind is always the same: detect some meaningful points in some images; [optional] compute a stable description of the image part surrounding each keypoint; match <b>keypoints</b> from an image (the template) to another (the query).", "dateLastCrawled": "2022-01-16T22:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Survey on Feature Description Techniques", "url": "https://www.ijsr.net/archive/v4i5/27041503.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijsr.net/archive/v4i5/27041503.pdf", "snippet": "described the <b>car</b>\u201fs <b>features</b>. In similar manner the <b>features</b> in image b should also be described so that they could be matched. This process is known as . Feature Description. Once after finding <b>features</b> . and describing them you <b>can</b> match them from other images and align them together or stitch them. A wide variety of applications such as object reorganization, pattern matching etc are of this technique [3]. Figure 1: Description and Matching between two Images [4]. Paper ID: 27041503 38 ...", "dateLastCrawled": "2022-01-06T12:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Why some FeatureDetector finds features only in</b> the middle of the image ...", "url": "https://answers.opencv.org/question/38327/why-some-featuredetector-finds-features-only-in-the-middle-of-the-image/", "isFamilyFriendly": true, "displayUrl": "https://answers.opencv.org/question/38327/<b>why-some-featuredetector-finds-features-only</b>...", "snippet": "Ok my istake. I <b>thought</b> that the border was an initial detection of a cascade <b>car</b> classifier. Again I think the same conclusion <b>can</b> be stated. Probably the <b>features</b> at the borders cannot be calculated due to the fact how the feature is calculated. I do not have an exact solution for this, should investigate STAR code further.", "dateLastCrawled": "2021-11-28T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "PVN3D: A <b>Deep Point-wise 3D Keypoints Voting</b> Network for 6DoF Pose ...", "url": "https://www.allaboutrobotix.com/pvn3d-a-deep-point-wise-3d-keypoints-voting-network-for-6dof-pose-estimation/", "isFamilyFriendly": true, "displayUrl": "https://www.allaboutrobotix.com/pvn3d-a-<b>deep-point-wise-3d-keypoints-voting</b>-network...", "snippet": "The learned <b>features</b> are then fed into a 3D <b>keypoints</b> detector, which predicts the per-point offsets w.r.t. <b>key points</b>. There is also an instance segmentation module for detecting poses of multiple objects. This is done with a semantic segmentation module that predicts the labels of various objects, and a center voting module that predicts the per-point offsets to the center point (Fig 1b). The center voting module is extrapolated to 3D, taking inspiration from CenterNet. Finally, a least ...", "dateLastCrawled": "2022-01-16T15:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Secondary Sheet Metal Features: Louvers and Gussets</b> | Solid Edge", "url": "https://blogs.sw.siemens.com/solidedge/Secondary-Sheet-Metal-Features-Louvers-and-Gussets/", "isFamilyFriendly": true, "displayUrl": "https://blogs.sw.siemens.com/solidedge/<b>Secondary-Sheet-Metal-Features-Louvers-and-Gussets</b>", "snippet": "Solid Edge has a wealth of built-in secondary sheet metal <b>features</b> that are sure to make your life easier if you use them. There\u2019s a lot to show here, so let\u2019s just get started. All of these tools are found under the Dimple drop down on the Sheet Metal group. You have to have a sheet metal part open in order to see these <b>features</b>. For those of you more familiar with other CAD packages, Solid Edge has a separate part type for regular parts and sheet metal parts.", "dateLastCrawled": "2022-01-22T02:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "3D <b>Sketching: The future of sketching</b> in CAD | <b>Solid Edge</b>", "url": "https://blogs.sw.siemens.com/solidedge/3D-Sketching-The-future-of-sketching-in-CAD/", "isFamilyFriendly": true, "displayUrl": "https://blogs.sw.siemens.com/<b>solidedge</b>/3D-<b>Sketching-The-future-of-sketching</b>-in-CAD", "snippet": "But for complex models, there is no alternative to <b>features</b> based on sketching profiles. While 2D sketching <b>can</b> be used to create extrusions, holes, paths and other <b>features</b>, its restriction of drawing on a single plane is cumbersome, when creating some complex shapes. We always see and create things in 3D then why restrict us to sketching in 2D? The 3D pen from 3Doodler. is a result of this fascination of creating things in 3D. 3D Sketching in <b>Solid Edge</b> is similar to drawing using the 3D ...", "dateLastCrawled": "2022-02-03T02:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Adaboost with &quot;Keypoint Presence Features&quot; for Real</b>-Time Vehicle ...", "url": "https://www.academia.edu/4787316/Adaboost_with_Keypoint_Presence_Features_for_Real_Time_Vehicle_Visual_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/4787316/<b>Adaboost_with_Keypoint_Presence_Features_for_Real</b>...", "snippet": "Specificity <b>Keypoints</b> concentrated on the rectangular side of the <b>car</b> hal-00422581, version 1 - 7 Oct 2009 <b>Keypoints</b> concentrated under the <b>car</b> between the two wheels <b>Keypoints</b> concentrated on wheels Figure 6 - Position of adaBoost positively responding <b>keypoints</b>, cumulated on all positive example images: each selected keypoint seem to correspond to a specific part of the <b>car</b>. Another motivation for these new kind of adaBoost <b>features</b> is that, by nature of the <b>features</b>, it is possible to ...", "dateLastCrawled": "2021-06-05T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Detection of copy-move forgery using AKAZE and SIFT keypoint extraction</b> ...", "url": "https://link.springer.com/article/10.1007/s11042-019-7629-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11042-019-7629-x", "snippet": "<b>Compared</b> to other methods, the keypoint-based methods give promising robustness against most of the post-processing operations. However, these methods are weak in locating the forgery when the copy-move is done in smooth regions because the significant <b>keypoints</b> cannot be extracted through the SIFT and speeded up robust <b>features</b> (SURF) algorithms.", "dateLastCrawled": "2021-11-21T22:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "ADABOOST WITH \u201cKEYPOINT PRESENCE <b>FEATURES</b>\u201d FOR REAL-TIME VEHICLE VISUAL ...", "url": "https://people.minesparis.psl.eu/fabien.moutarde/Publis/kpBoostDetect_ITSwc2009.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.minesparis.psl.eu/fabien.moutarde/Publis/kpBoostDetect_ITSwc2009.pdf", "snippet": "adaBoost using new original \u201c<b>keypoints</b> presence <b>features</b>\u201d. These weak-classifiers produce a boolean response based on presence or absence in the tested image of a \u201ckeypoint\u201d (~ a SURF interest point) with a descriptor sufficiently similar (i.e. within a given distance) to a reference descriptor characterizing the feature. A first experiment was conducted on a public image dataset containing lateral-viewed cars, yielding 95% recall with 95% precision on test set. Moreover, analysis of ...", "dateLastCrawled": "2022-01-14T17:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "3D <b>keypoints</b> definition for <b>car</b> models. 66 <b>keypoints</b> are defined for ...", "url": "https://www.researchgate.net/figure/3D-keypoints-definition-for-car-models-66-keypoints-are-defined-for-each-model_fig2_338509493", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/3D-<b>keypoints</b>-definition-for-<b>car</b>-models-66...", "snippet": "While only a handful of <b>keypoints</b> <b>can</b> be sufficient solve the EPnP problem, we define 66 semantic <b>keypoints</b> in our dataset, as shown in Fig. 3, which has much higher density than most previous <b>car</b> ...", "dateLastCrawled": "2022-01-13T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Self-supervised Keypoint <b>Learning</b> \u2014 A Review | by Patrick Langechuan ...", "url": "https://towardsdatascience.com/self-supervised-keypoint-learning-aade18081fc3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/self-supervised-keypoint-<b>learning</b>-aade18081fc3", "snippet": "The method proposed by KP3D is that we <b>can</b> roughly use transformed 3d position (with initial guess) of <b>keypoints</b> to get 3D location of points in new camera coordinate. Then essentially the problem is reduced to estimate the relative camera pose change based on two sets of matched 3D points. This problem is known as the Orthogonal Procrustes problem with well established solution such as ICP (iterative closes point, commonly used in lidar point cloud registration). Under the assumption that ...", "dateLastCrawled": "2022-02-02T14:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Visual Categorization with Bags of Keypoints</b>", "url": "https://people.eecs.berkeley.edu/~efros/courses/AP06/Papers/csurka-eccv-04.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.eecs.berkeley.edu/~efros/courses/AP06/Papers/csurka-eccv-04.pdf", "snippet": "basis of low-level image <b>features</b>, given a query image or manually constructed de-scription of these low-level <b>features</b>. Such descriptions frequently have little rela- tion to the semantic content of the image. Detection: This refers to deciding whether or not a member of one visual category is present in a given image. Most previous work on detection has centered on ma-chine learning approaches to detecting faces, cars or pedestrians [1]-[6] While it would be possible to perform generic ...", "dateLastCrawled": "2022-02-02T15:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Convolutional Neural Networks</b> in Object Detection - Azoft", "url": "https://www.azoft.com/blog/convolutional-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.azoft.com/blog/<b>convolutional-neural-networks</b>", "snippet": "You <b>can</b> see the example of <b>keypoints</b> detection in the image below. ... Image 1 \u2013 The unedited <b>car</b> picture. Image 2 \u2013 The feature map after applying first convolutional layer. Image 3 \u2013 The feature map after second convolutional layer . Finally, we designated the received coordinates of the <b>key points</b> and succesfully got the desired image: The convolutional neural network was very effective in this recognition task detecting <b>keypoints</b> of license plates. In the majority of cases, the key ...", "dateLastCrawled": "2022-01-30T06:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Viewpoints and Keypoints</b> | DeepAI", "url": "https://deepai.org/publication/viewpoints-and-keypoints", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>viewpoints-and-keypoints</b>", "snippet": "There are two ways in which one <b>can</b> describe the pose of the <b>car</b> in Figure 1 - either via its viewpoint or via specifying the locations of a fixed set of <b>keypoints</b>. The former characterization provides a global perspective about the object whereas the latter provides a more local one. In this work, we aim to reliably predict both these representations of pose for objects. Our overall approach is motivated by the theory of global precedence - that humans perceive the global structure before ...", "dateLastCrawled": "2022-01-25T15:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Introduction to <b>SIFT</b>( Scale Invariant Feature Transform) | by ... - Medium", "url": "https://medium.com/data-breach/introduction-to-sift-scale-invariant-feature-transform-65d7f3a72d40", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-breach/introduction-to-<b>sift</b>-scale-invariant-feature-transform...", "snippet": "<b>SIFT</b> stands for Scale-Invariant Feature Transform and was first presented in 2004, by D.Lowe, University of British Columbia. <b>SIFT</b> is invariance to image scale and rotation. This algorithm is\u2026", "dateLastCrawled": "2022-01-30T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Keypoint-Aligned Embeddings for Image Retrieval</b> and Re ... - arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2008.11368/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2008.11368", "snippet": "We fine-tuned a pose estimation network HRNet [28, 38] from a provided checkpoint to detect 20 <b>car</b> <b>keypoints</b> on annotated VeRi-776 [32]. We <b>can</b> observe that 94.5% <b>keypoints</b> <b>can</b> be correctly predicted within 10 pixels (4% of the image size) to the ground truth. The domain shift between VeRi776 and Cars196 makes the predictions on the latter less accurate. We visually inspect the predicted <b>keypoints</b> on Cars196 and conclude that many <b>keypoints</b> are detected correctly. We use the predicted ...", "dateLastCrawled": "2021-12-25T03:14:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Experience is key. A Basic Guide to AI: | by Venkat Yarlagadda ...", "url": "https://studentsxstudents.com/experience-is-key-a-basic-guide-to-ai-4da3111b218e", "isFamilyFriendly": true, "displayUrl": "https://studentsxstudents.com/experience-is-key-a-basic-guide-to-ai-4da3111b218e", "snippet": "<b>Machine</b> <b>learning</b> (ML) is one of the most commonly known forms of AI. As per the name, <b>machine</b> <b>learning</b> means machines that learn. <b>Machine</b> <b>learning</b> is basically a <b>machine</b> that will learn through experience, when it\u2019s put through a certain test, it will do terribly, but slowly it will grasp concepts and slowly perform better and better. <b>KeyPoints</b>. Data flow points. The main key point that makes ML, ML is data. You really need to have diverse forms of data when you want to do a <b>machine</b> ...", "dateLastCrawled": "2022-01-09T12:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "All you need to know for starting basic <b>Machine</b> <b>Learning</b>. | by Shehzen ...", "url": "https://medium.com/analytics-vidhya/the-world-yet-to-come-and-the-world-currently-is-in-favor-of-machines-that-learn-by-themselves-as-cf11de1d5146", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/the-world-yet-to-come-and-the-world-currently-is...", "snippet": "Hands-On <b>Machine</b> <b>Learning</b> with Scikit-Learn, Keras, and TensorFlow Concepts, Tools, and Techniques to Build Intelligent Systems by Aur\u00e9lien G\u00e9ron \u2014 start with this book and complete all the ...", "dateLastCrawled": "2021-08-20T06:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "What are the <b>basic concepts in machine learning</b>? I found that the best way to discover and get a handle on the <b>basic concepts in machine learning</b> is to review the introduction chapters to <b>machine learning</b> textbooks and to watch the videos from the first model in online courses. Pedro Domingos is a lecturer and professor on <b>machine learning</b> at the University of Washing and", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Visual Categorization with Bags of <b>Keypoints</b>", "url": "https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/csurka-eccv-04.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/csurka-eccv-04.pdf", "snippet": "based <b>machine</b> <b>learning</b> approach. This paper presents a bag of <b>keypoints</b> approach to visual categorization. A bag of <b>keypoints</b> corresponds to a histogram of the number of occurrences of particular image patterns in a given image. The main advantages of the . method are its simplicity, its computational efficiency and its invariance to affine transformations, as well as occlusion, lighting and intra-class variations. It is important to understand the distinction of visual categorization from ...", "dateLastCrawled": "2022-01-28T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> and Category Representation", "url": "https://lear.inrialpes.fr/~verbeek/mlcr.slides.11.12/lecture1verbeek.pdf", "isFamilyFriendly": true, "displayUrl": "https://lear.inrialpes.fr/~verbeek/mlcr.slides.11.12/lecture1verbeek.pdf", "snippet": "\u2013 Student presentation 2: Visual categorization with bags of <b>keypoints</b> Csurka, Dance, Fan, Willamowski, Bray, ECCV 2004. Plan for the course \u2022 Class 4, December 16 2011 \u2013 Jakob Verbeek: Non-linear kernels + Fisher vector image representation \u2013 Cordelia Schmid: Category level localization \u2013 Student presentation 3: Beyond bags of features: spatial pyramid matching for recognizing natural scene categories. \u2013 Student presentation 4: Video Google: A Text Retrieval Approach to Object ...", "dateLastCrawled": "2022-01-04T15:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>Learning</b> Models for Cultural Heritage Image Classification ...", "url": "https://pdfs.semanticscholar.org/6a10/3c66f0e252812acad7367b49c6af052d4eb8.pdf", "isFamilyFriendly": true, "displayUrl": "https://pdfs.semanticscholar.org/6a10/3c66f0e252812acad7367b49c6af052d4eb8.pdf", "snippet": "information rough sets and <b>analogy</b> based reasoning, and compares these with the results obtained from the Article <b>Machine</b> <b>Learning</b> Models for Cultural Heritage Image Classi\ufb01cation: Comparison Based on Attribute Selection Radmila Jankovic\u00b4 Mathematical Institute of the Serbian Academy of Sciences and Arts, 11000 Belgrade, Serbia; rjankovic@mi.sanu.ac.rs Received: 19 November 2019; Accepted: 21 December 2019; Published: 24 December 2019 Abstract: Image classi\ufb01cation is one of the most ...", "dateLastCrawled": "2021-12-30T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep Generative Models for Facial <b>Keypoints</b> Detection", "url": "https://core.ac.uk/download/pdf/39969093.pdf", "isFamilyFriendly": true, "displayUrl": "https://core.ac.uk/download/pdf/39969093.pdf", "snippet": "Keywords: deep <b>learning</b>, generative models, facial <b>keypoints</b> A new area of <b>machine</b> <b>learning</b> research called deep <b>learning</b>, has moved <b>machine</b> <b>learn-ing</b> closer to one of its original goals: arti\ufb01cial intelligence and general <b>learning</b> algo-rithm. The key idea is to pretrain models in completely unsupervised way and \ufb01nally they", "dateLastCrawled": "2018-08-01T15:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is <b>Artificial</b> Intelligence? How Does AI Work? | Built In", "url": "https://builtin.com/artificial-intelligence", "isFamilyFriendly": true, "displayUrl": "https://builtin.com/<b>artificial</b>-intelligence", "snippet": "Deep <b>learning</b> is a type of <b>machine</b> <b>learning</b> that runs inputs through a biologically-inspired neural network architecture. The neural networks contain a number of hidden layers through which the data is processed, allowing the <b>machine</b> to go &quot;deep&quot; in its <b>learning</b>, making connections and weighting input for the best results. <b>Artificial</b> General Intelligence. The creation of a <b>machine</b> with human-level intelligence that can be applied to any task is the Holy Grail for many AI researchers, but the ...", "dateLastCrawled": "2022-02-03T00:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "LifelongGlue: Keypoint matching for 3D reconstruction with continual ...", "url": "https://www.sciencedirect.com/science/article/pii/S095741742200104X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S095741742200104X", "snippet": "In our methodology a pair of multiplex graph neural networks are used to generate distinctive feature descriptors through <b>learning</b> a function f, that accumulates the matched <b>keypoints</b> near each other in feature space or increases the effective similarity among them by: (3) f = argmax f 2 M \u2211 x = 1 M \u2211 y = 1 N P x y S x y In , S x, y denotes the pairwise score, and P x, y is the assignment.", "dateLastCrawled": "2022-02-05T15:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Computer Vision: How is object detection using SIFT <b>keypoints</b> scale ...", "url": "https://www.quora.com/Computer-Vision-How-is-object-detection-using-SIFT-keypoints-scale-rotationally-invariant", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Computer-Vision-How-is-object-detection-using-SIFT-<b>keypoints</b>...", "snippet": "Answer (1 of 2): SIFT descriptors rotationally invariant since while calculating those, a step involves orienting all local gradients with respect to the overall dominant gradient in that spatial locality. So, if object is rotated, so will the dominant gradients of each locality, and the gradient...", "dateLastCrawled": "2022-01-20T20:12:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "GitHub - AlexTheBad/AP-10K: NeurIPS 2021 Datasets and Benchmarks Track", "url": "https://github.com/AlexTheBad/AP-10K", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/AlexTheBad/AP-10K", "snippet": "For plantigrade animals, the annotation is the same as the biology definition. Thus, the visual distribution of <b>keypoints is similar</b> across the dataset, as the &#39;knee&#39; is around the middle of the limbs for all animals. 5. What tasks could the dataset be used for? AP-10K can be used for the research of animal pose estimation. Besides, it can also be used for specific <b>machine</b> <b>learning</b> topics such as few-shot <b>learning</b>, domain generalization, self-supervised <b>learning</b>. Please see the Discussion ...", "dateLastCrawled": "2022-01-10T20:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Learned local descriptors for recognition and matching", "url": "https://www.researchgate.net/publication/228987759_Learned_local_descriptors_for_recognition_and_matching", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228987759_Learned_local_descriptors_for...", "snippet": "The <b>machine</b> <b>learning</b> models, the training loss and the respective training data of <b>learning</b>-based algorithms are looked at in more detail; subsequently the various advantages and challenges of the ...", "dateLastCrawled": "2021-12-10T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Dynamic Pore <b>Filtering for Keypoint Detection Applied</b> to Newborn ...", "url": "https://www.researchgate.net/publication/262566359_Dynamic_Pore_Filtering_for_Keypoint_Detection_Applied_to_Newborn_Authentication", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/262566359_Dynamic_Pore_Filtering_for_Keypoint...", "snippet": "between <b>keypoints is similar</b> in images from the same subject (colored lines in Figures 6(a) and 6(b)) and different in images. from other subjects (see Figure 6(c)). (a) (b) (c) Fig. 6. Example of ...", "dateLastCrawled": "2022-01-19T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Multilevel similarity model for high-resolution remote sensing image ...", "url": "https://www.sciencedirect.com/science/article/pii/S0020025519306292", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0020025519306292", "snippet": "In addition, our future works mainly consist of two aspects: (1) explore robust keypoint descriptors to enhance the performance of the registration combining with <b>machine</b> <b>learning</b> methods, e.g., generative adversarial network (GAN) and siamese network and (2) improve the adaptability of the proposed method while deal with low texture remote sensing images such as Synthetic Aperture Radar (SAR) images and infrared images .", "dateLastCrawled": "2022-02-03T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "AP-10K: NeurIPS 2021 Datasets and Benchmarks Track", "url": "https://gitee.com/giteebob/AP-10K", "isFamilyFriendly": true, "displayUrl": "https://gitee.com/giteebob/AP-10K", "snippet": "NeurIPS 2021 Datasets and Benchmarks Track", "dateLastCrawled": "2022-01-26T14:42:00.0000000Z", "language": "zh_chs", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "PAPER Special Issue on <b>Machine</b> Vision and its Applications Recognition ...", "url": "http://www.am.sanken.osaka-u.ac.jp/~mansur/files/IEICE_special.pdf", "isFamilyFriendly": true, "displayUrl": "www.am.sanken.osaka-u.ac.jp/~mansur/files/IEICE_special.pdf", "snippet": "PAPER Special Issue on <b>Machine</b> Vision and its Applications Recognition of Plain Objects Using Local Region Matching Al MANSUR , Katsutoshi SAKATA , Dipankar DAS , Nonmembers, and Yoshinori KUNO , Member SUMMARY Conventional interest point based matching re-quires computationally expensive patch preprocessing and is not appropriate for plain objects with negligible detail. This paper presents a method for extracting distinctive interest regions from images that can be used to perform reliable ...", "dateLastCrawled": "2021-12-18T16:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Advances in Visual Information Systems, 9 conf., VISUAL</b> 2007 - PDF Free ...", "url": "https://epdf.pub/advances-in-visual-information-systems-9-conf-visual-2007.html", "isFamilyFriendly": true, "displayUrl": "https://epdf.pub/<b>advances-in-visual-information-systems-9-conf-visual</b>-2007.html", "snippet": "An iterative algorithm is used to find the maximum sub-graphs of both shape graphs for which all corresponding pairs of edges have approximately proportional labels (i.e. the geometric distribution of <b>keypoints is similar</b>). This algorithm converges very fast and in most cases only a few iterations are needed. The generated sub-graphs (if they contain enough nodes) specify the final set of query and database keypoints confirming the validity of the hypothesis. Fig. 9 shows a b/w example (from ...", "dateLastCrawled": "2022-01-26T01:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Putting the pieces together: Connected Poselets for Human Pose Estimation", "url": "http://personal.ee.surrey.ac.uk/Personal/R.Bowden/publications/2011/ICCV/WS/Holt2011Putting.pdf", "isFamilyFriendly": true, "displayUrl": "personal.ee.surrey.ac.uk/Personal/R.Bowden/publications/2011/ICCV/WS/Holt2011Putting.pdf", "snippet": "texts [2] andHOG[8] within a Support Vector <b>Machine</b> (SVM) classi\ufb01er [11,15]. Approaches to part assembly have typically used graphical models, of which Pictorial Structures [13,10,2] are an elegant method of relating body parts within a tree structure that supports direct in-ference of the marginals. Loopy belief propagation models [25,29,27] and fully connected models [28] require ap-proximations to infer the marginals. Model parameters can be trained iteratively [2], discriminatively [21 ...", "dateLastCrawled": "2021-08-07T21:27:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fast adaptive optics scanning light ophthalmoscope retinal montaging", "url": "https://opg.optica.org/boe/viewmedia.cfm?uri=boe-9-9-4317&html=true", "isFamilyFriendly": true, "displayUrl": "https://opg.optica.org/boe/viewmedia.cfm?uri=boe-9-9-4317&amp;html=true", "snippet": "The field of view of high-resolution ophthalmoscopes that require the use of adaptive optics (AO) wavefront correction is limited by the isoplanatic patch of the eye, which varies across individual eyes and with the portion of the pupil used for illumination and/or imaging. Therefore all current AO ophthalmoscopes have small fields of view comparable to, or smaller than, the isoplanatic patch, and the resulting images have to be stitched off-line to create larger montages. These montages are ...", "dateLastCrawled": "2022-01-28T06:10:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(keypoints)  is like +(features of a car)", "+(keypoints) is similar to +(features of a car)", "+(keypoints) can be thought of as +(features of a car)", "+(keypoints) can be compared to +(features of a car)", "machine learning +(keypoints AND analogy)", "machine learning +(\"keypoints is like\")", "machine learning +(\"keypoints is similar\")", "machine learning +(\"just as keypoints\")", "machine learning +(\"keypoints can be thought of as\")", "machine learning +(\"keypoints can be compared to\")"]}