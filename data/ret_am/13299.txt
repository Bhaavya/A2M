{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Counterfactual</b> <b>Fairness</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1703.06856/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1703.06856", "snippet": "We propose a definition called <b>counterfactual</b> <b>fairness</b> that captures the intuition that a decision <b>is fair</b> towards an individual if it gives the same predictions in (a) the observed world and (b) a world where the individual had always belonged to a different demographic group, other background causes of the outcome being equal. We demonstrate our framework on two real-world problems: <b>fair</b> prediction of law school success, and <b>fair</b> modeling of an individual\u2019s criminality in policing data ...", "dateLastCrawled": "2021-12-15T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Fairness judgments and counterfactual thinking:Pricing</b> goods ...", "url": "https://www.researchgate.net/publication/276443166_Fairness_judgments_and_counterfactual_thinkingPricing_goods_versus_services", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/276443166_<b>Fairness</b>_judgments_and...", "snippet": "What makes people feel <b>like</b> they paid a \u201c<b>fair</b>\u201d price for a product? <b>Fairness</b>, after all, is. not an absolute objective criteria \u2013 rather, it is a perception that can be shaped by many ...", "dateLastCrawled": "2022-01-19T12:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Expertise, Counterfactual Thinking, and Fairness Perceptions</b>: A Test of ...", "url": "https://www.researchgate.net/publication/255895217_Expertise_Counterfactual_Thinking_and_Fairness_Perceptions_A_Test_of_Fairness_Theory", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/255895217_Expertise_<b>Counterfactual</b>_Thinking...", "snippet": "While <b>fairness</b> theory (Folger &amp; Cropanzano, 1998, 2001) suggests perceptions of injustice are due to accountability judgments and <b>counterfactual</b> thinking, few studies have examined the influence ...", "dateLastCrawled": "2022-02-02T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Legal perspective on possible <b>fairness</b> measures \u2013 A legal discussion ...", "url": "https://www.sciencedirect.com/science/article/pii/S026736492100056X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S026736492100056X", "snippet": "It should be noted that <b>Counterfactual</b> <b>Fairness</b> of the <b>fairness</b> measures analyzed in this paper would in practice give decision-makers the greatest room of freedom to determine the decision conditions themselves while state bodies, such as courts and supervisory authorities, would remain monitoring bodies. What <b>fairness</b> measure should be applied to what decision situation, should be decided by a democratically legitimized organ, ideally the parliament. The respective organ could work out ...", "dateLastCrawled": "2021-10-26T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Chandan Singh | <b>fairness</b>, sts", "url": "https://csinva.io/notes/ai/fairness_sts.html", "isFamilyFriendly": true, "displayUrl": "https://csinva.io/notes/ai/<b>fairness</b>_sts.html", "snippet": "<b>counterfactual</b> <b>fairness</b> - replace attributes w/ flipped values; <b>fair</b> algorithms preprocessing - remove sensitive information; optimization at training time - add regularization; postprocessing - change thresholds to impose <b>fairness</b>; <b>fairness</b> in computer vision (tutorial) harms of CV. timnit gebru - <b>fairness</b> team at google also emily denton; startups faceception startup - profile people based on their image; hirevue startup videos - facial recognition for judging interviews; clearview ai ...", "dateLastCrawled": "2022-02-03T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Counterfactual</b> explanations: Can you get to the \u201cground truth\u201d of black ...", "url": "https://www.centre4innovation.org/stories/counterfactual-explanations-ground-truth-black-box-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.centre4innovation.org/stories/<b>counterfactual</b>-explanations-ground-truth...", "snippet": "The <b>court</b> agreed with your demand and the company has provided you with a <b>counterfactual</b> explanation. The model came up with the following suggestion: your chances of getting the job would increase if you had more years of experience. However, you are still not satisfied. It might be true that you are relatively inexperienced, but the referral from your previous employer is very positive. It seems reasonable to you that the quality of your experience as well as the quantity should be taken ...", "dateLastCrawled": "2021-12-15T09:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "On the <b>Fairness</b> of &#39;Fake&#39; Data in Legal AI | DeepAI", "url": "https://deepai.org/publication/on-the-fairness-of-fake-data-in-legal-ai", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/on-the-<b>fairness</b>-of-fake-data-in-legal-ai", "snippet": "On the <b>Fairness</b> of &#39;Fake&#39; Data in Legal AI. 09/10/2020 . \u2219. by Lauren Boswell, et al. \u2219. The University of Sydney \u2219. 0 \u2219. share The economics of smaller budgets and larger case numbers necessitates the use of AI in legal proceedings. We examine the concept of disparate impact and how biases in the training data lead to the search for fairer AI. This paper seeks to begin the discourse on what such an implementation would actually look <b>like</b> with a criticism of pre-processing methods in ...", "dateLastCrawled": "2022-01-30T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is John Rawls&#39; main idea in his <b>theory of justice as fairness</b>? - Quora", "url": "https://www.quora.com/What-is-John-Rawls-main-idea-in-his-theory-of-justice-as-fairness", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-John-Rawls-main-idea-in-his-<b>theory-of-justice-as-fairness</b>", "snippet": "Answer (1 of 5): A society is just if its basic structure (main political, social and economic institutions) are organised that <b>is fair</b> to the citizens. There are three principles of justice: 1. Greatest equal liberty: each is entitled to a scheme of the greatest possible liberties which is comp...", "dateLastCrawled": "2022-01-26T05:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[D] Is it possible to create machine learning system that <b>is fair</b> ...", "url": "https://www.reddit.com/r/MachineLearning/comments/gqugku/d_is_it_possible_to_create_machine_learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/MachineLearning/comments/gqugku/d_is_it_possible_to_create...", "snippet": "Started thinking about <b>fairness</b> of machine learning models recently. Wiki page for <b>Fairness</b>_(machine_learning) defines <b>fairness</b> as: In machine learning, a given algorithm is said to be <b>fair</b>, or to have <b>fairness</b> if its results are independent of some variables we consider to be sensitive and not related with it (f.e.: gender, ethnicity, sexual orientation, etc.). UC Berkley CS 294 in turn defines <b>fairness</b> as:. understanding and mitigating discrimination based on sensitive characteristics ...", "dateLastCrawled": "2022-01-01T13:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Google Book Settlement And The <b>Fair</b> Use <b>Counterfactual</b>", "url": "https://works.bepress.com/matthew_sag/7/download/", "isFamilyFriendly": true, "displayUrl": "https://works.bepress.com/matthew_sag/7/download", "snippet": "essentially mirror the <b>fair</b> use <b>counterfactual</b>. The initial digitization of books, the processing and analysis of metadata, and the basic reporting functions of the book search engine were likely to constitute <b>fair</b> use, and these are also allowed under the terms of the Amended Settlement. It is not surprising that, as soon the Settlement was announced, the Google Book debate shifted from the merits of digitization to issues of commoditization and control. These are the points of contention ...", "dateLastCrawled": "2022-01-07T18:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Counterfactual</b> <b>Fairness</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1703.06856/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1703.06856", "snippet": "We propose a definition called <b>counterfactual</b> <b>fairness</b> that captures the intuition that a decision <b>is fair</b> towards an individual if it gives the same predictions in (a) the observed world and (b) a world where the individual had always belonged to a different demographic group, other background causes of the outcome being equal. We demonstrate our framework on two real-world problems: <b>fair</b> prediction of law school success, and <b>fair</b> modeling of an individual\u2019s criminality in policing data ...", "dateLastCrawled": "2021-12-15T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Counterfactual fairness: removing direct effects through regularization</b> ...", "url": "https://deepai.org/publication/counterfactual-fairness-removing-direct-effects-through-regularization", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>counterfactual-fairness-removing-direct-effects-through</b>...", "snippet": "<b>Counterfactual fairness: removing direct effects through regularization</b>. 02/25/2020 \u2219 by Pietro G. Di Stefano, et al. \u2219 Experian Information Solutions, Inc \u2219 0 \u2219 share . Building machine learning models that are <b>fair</b> with respect to an unprivileged group is a topical problem. Modern <b>fairness</b>-aware algorithms often ignore causal effects and enforce <b>fairness</b> through modifications applicable to only a subset of machine learning models.", "dateLastCrawled": "2021-12-01T08:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Counterfactual</b> explanations: Can you get to the \u201cground truth\u201d of black ...", "url": "https://www.centre4innovation.org/stories/counterfactual-explanations-ground-truth-black-box-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.centre4innovation.org/stories/<b>counterfactual</b>-explanations-ground-truth...", "snippet": "<b>Fairness</b> is a term used to describe machine learning algorithms. An algorithm <b>is fair</b> if it does not base its outcomes on certain \u201cprotected variables\u201d. These variables usually concern age, gender, nationality or sexuality. So these variables should never be the ground truth reason for an algorithm to give a certain output. Incorporating causal relationships between variables can be realised using causal inference techniques. The <b>court</b> agreed with your demand and the company has provided ...", "dateLastCrawled": "2021-12-15T09:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Supplementary Material for \u201cDECAF: Generating <b>Fair</b> Synthetic Data Using ...", "url": "https://proceedings.neurips.cc/paper/2021/file/ba9fab001f67381e56e410575874d967-Supplemental.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2021/file/ba9fab001f67381e56e410575874d967...", "snippet": "<b>similar</b> de\ufb01nition, coined <b>counterfactual</b> <b>fairness</b>, is proposed by [10]. Kilbertus et al. [11] introduce unresolved discrimination (UD) as the path-equivalent version of conditional <b>fairness</b>. They de\ufb01ne proxy discrimination as well, which can be considered the dual of UD [11].", "dateLastCrawled": "2022-01-28T03:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The Google Book Settlement and the <b>Fair</b> Use <b>Counterfactual</b>.", "url": "https://lawecommons.luc.edu/cgi/viewcontent.cgi?article=1057&context=facpubs", "isFamilyFriendly": true, "displayUrl": "https://lawecommons.luc.edu/cgi/viewcontent.cgi?article=1057&amp;context=facpubs", "snippet": "Sag, Matthew. The Google Book Settlement and the <b>Fair</b> Use <b>Counterfactual</b>, 55 N.Y. L. R. 19 (2010) MATTHEW SAG The Google Book Settlement and the <b>Fair</b> Use <b>Counterfactual</b> ABOUT THE AUTHOR: Associate Professor, DePaul University College of Law. Thanks to Jackson Cooper, Joshua McIntyre, and Brian Murray for their dedicated research assistance, and to Peter DiCola, James Grimmelmann, Peter Hirtle, Pamela Samuelson, Michael Schiffer, and Spencer Waller for their many insightful comments and ...", "dateLastCrawled": "2021-09-20T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Google Book Settlement And The <b>Fair</b> Use <b>Counterfactual</b>", "url": "https://works.bepress.com/matthew_sag/6/download/", "isFamilyFriendly": true, "displayUrl": "https://works.bepress.com/matthew_sag/6/download", "snippet": "This <b>counterfactual</b> provides a useful benchmark by which to assess the effects, and thus the merits, of the Google Book Search settlement. As well as providing a guide to understanding the settlement, this article identifies how the agreement mirrors the <b>court</b>\u2019s most likely <b>fair</b> use ruling and how it deviates form it. Because the opt-out that", "dateLastCrawled": "2022-01-08T13:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Causation, Fault, and Fairness in</b> the Criminal Law - <b>McGill Law Journal</b>", "url": "https://lawjournal.mcgill.ca/article/causation-fault-and-fairness-in-the-criminal-law/", "isFamilyFriendly": true, "displayUrl": "https://lawjournal.mcgill.ca/article/<b>causation-fault-and-fairness-in</b>-the-criminal-law", "snippet": "Four out of the nine Supreme <b>Court</b> Justices in Nette shared a <b>similar</b> view. They explained: \u201cTo claim that something not unimportant is important would be a sophism. Likewise, to consider things that are not dissimilar to be <b>similar</b> would amount to an erroneous interpretation.\u201d Hugues Parent also rejects the equivalency between both standards. In his view, the significant contributing cause standard in Nette is more demanding than the beyond the de minimis range standard in Smithers. In ...", "dateLastCrawled": "2022-01-30T09:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Machine Learning Analysis on the <b>Fairness</b> of the Boston Police ...", "url": "https://groups.csail.mit.edu/mac/classes/6.805/student-papers/fall18-papers/Stop%20and%20Frisk.pdf", "isFamilyFriendly": true, "displayUrl": "https://groups.csail.mit.edu/mac/classes/6.805/student-papers/fall18-papers/Stop and...", "snippet": "4.2.4.2 Show nearest <b>counterfactual</b> 16 ... Deciding what it means to be <b>fair</b> has always been a difficult task, and it is particularly difficult in situations related to the police and stop and frisk. In this paper, we discuss 5 different definitions of <b>fairness</b>: Group Unaware, Group Aware, Demographic Parity, Equal opportunity, and Equal Access. To determine which definitions of <b>fairness</b> to use in our machine learning analysis, we examine past legal cases regarding stop and frisk encounters ...", "dateLastCrawled": "2021-12-11T03:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Google Book Settlement And The <b>Fair</b> Use <b>Counterfactual</b>", "url": "https://works.bepress.com/matthew_sag/7/download/", "isFamilyFriendly": true, "displayUrl": "https://works.bepress.com/matthew_sag/7/download", "snippet": "11 The district <b>court</b> has considerable discretion in determining whether settlement <b>is fair</b> and reasonable. Bryan v Pittsburgh Plate Glass Co. (PPG Industries, Inc.), 494 F2d 799 (3d Cir. 1974). Nonetheless, the DOJ has recommended the <b>court</b> undertake \u201ca particularly searching analysis\u201d of the requirements of Rule 23 have been met in this ...", "dateLastCrawled": "2022-01-07T18:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is John Rawls&#39; main idea in his <b>theory of justice as fairness</b>? - Quora", "url": "https://www.quora.com/What-is-John-Rawls-main-idea-in-his-theory-of-justice-as-fairness", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-John-Rawls-main-idea-in-his-<b>theory-of-justice-as-fairness</b>", "snippet": "Answer (1 of 5): A society is just if its basic structure (main political, social and economic institutions) are organised that <b>is fair</b> to the citizens. There are three principles of justice: 1. Greatest equal liberty: each is entitled to a scheme of the greatest possible liberties which is comp...", "dateLastCrawled": "2022-01-26T05:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Counterfactual</b> <b>Fairness</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1703.06856/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1703.06856", "snippet": "We propose a definition called <b>counterfactual</b> <b>fairness</b> that captures the intuition that a decision <b>is fair</b> towards an individual if it gives the same predictions in (a) the observed world and (b) a world where the individual had always belonged to a different demographic group, other background causes of the outcome being equal. We demonstrate our framework on two real-world problems: <b>fair</b> prediction of law school success, and <b>fair</b> modeling of an individual\u2019s criminality in policing data ...", "dateLastCrawled": "2021-12-15T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Fairness judgments and counterfactual thinking:Pricing</b> goods ...", "url": "https://www.researchgate.net/publication/276443166_Fairness_judgments_and_counterfactual_thinkingPricing_goods_versus_services", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/276443166_<b>Fairness</b>_judgments_and...", "snippet": "<b>Counterfactual</b> thoughts <b>can</b> also aid judgments of <b>fairness</b>, for example, if an employee deems that a supervisor could and should have acted differently to lead to a fairer outcome ( Folger and ...", "dateLastCrawled": "2022-01-19T12:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Expertise, Counterfactual Thinking, and Fairness Perceptions</b>: A Test of ...", "url": "https://www.researchgate.net/publication/255895217_Expertise_Counterfactual_Thinking_and_Fairness_Perceptions_A_Test_of_Fairness_Theory", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/255895217_Expertise_<b>Counterfactual</b>_Thinking...", "snippet": "While <b>fairness</b> theory (Folger &amp; Cropanzano, 1998, 2001) suggests perceptions of injustice are due to accountability judgments and <b>counterfactual</b> thinking, few studies have examined the influence ...", "dateLastCrawled": "2022-02-02T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Mirror Mirror", "url": "https://shiraamitchell.github.io/fairness/", "isFamilyFriendly": true, "displayUrl": "https://shiraamitchell.github.io/<b>fairness</b>", "snippet": "Perhaps one of my notions is completely wrong in certain situations where I never <b>thought</b> to apply it. Unexpected Consequences: ... individual <b>counterfactual</b> <b>fairness</b> <b>can</b> be regarded as a negative answer to each individual\u2019s question \u201cwould the decision have been different if I were not black?\u201d <b>Counterfactual</b> parity provides a negative answer to the question \u201cwould the rates of diring be different if everyone were black?\u201d Finally, conditional <b>counterfactual</b> parity answers the same ...", "dateLastCrawled": "2022-01-06T19:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Can AI Be Fair</b>? | www.caltech.edu", "url": "https://www.caltech.edu/about/news/can-ai-be-fair", "isFamilyFriendly": true, "displayUrl": "https://www.caltech.edu/about/news/<b>can-ai-be-fair</b>", "snippet": "This approach asks a &quot;<b>counterfactual</b>&quot; question\u2014basically a &quot;what if&quot; question\u2014about the decisions one would have made if the world had been <b>fair</b>. In other words, once unfair causal effects are identified\u2014such as one&#39;s race leading to different bail decisions in a <b>court</b>\u2014the goal is to selectively remove those effects from an algorithm that makes automated decisions.", "dateLastCrawled": "2021-12-28T05:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Causality</b> - <b>Fairness</b> and machine learning", "url": "https://fairmlbook.org/causal.html", "isFamilyFriendly": true, "displayUrl": "https://<b>fair</b>mlbook.org/causal.html", "snippet": "Kusner et al. Kusner et al., \u201c<b>Counterfactual</b> <b>Fairness</b>.\u201d introduced a notion of <b>counterfactual</b> <b>fairness</b>. The authors extend this line of <b>thought</b> in another work. Russell et al., \u201cWhen Worlds Collide: Integrating Different <b>Counterfactual</b> Assumptions in <b>Fairness</b>,\u201d in Proc. 30 Th NIPS, 2017, 6417\u201326.", "dateLastCrawled": "2022-01-25T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Rethinking admission policy: Is Affirmative Action compatible</b> with ...", "url": "https://files.eric.ed.gov/fulltext/ED490346.pdf", "isFamilyFriendly": true, "displayUrl": "https://files.eric.ed.gov/fulltext/ED490346.pdf", "snippet": "<b>fair</b> if the so-called overall <b>fairness</b> in terms of total welfare of a wider community could not be achieved. The River Study made a <b>counterfactual</b> but unconvincing calculation of the damage to Whites and Asians under the affirmative action program. Bowen and Bok pointed out that even if race-sensitive", "dateLastCrawled": "2021-10-30T05:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Can AI Be Fair</b>? | Division of the Humanities and Social Sciences", "url": "https://www.hss.caltech.edu/news-and-events/news/can-ai-be-fair", "isFamilyFriendly": true, "displayUrl": "https://www.hss.caltech.edu/news-and-events/news/<b>can-ai-be-fair</b>", "snippet": "This approach asks a &quot;<b>counterfactual</b>&quot; question\u2014basically a &quot;what if&quot; question\u2014about the decisions one would have made if the world had been <b>fair</b>. In other words, once unfair causal effects are identified\u2014such as one&#39;s race leading to different bail decisions in a <b>court</b>\u2014the goal is to selectively remove those effects from an algorithm that makes automated decisions.", "dateLastCrawled": "2022-01-15T16:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Google Book Settlement And The <b>Fair</b> Use <b>Counterfactual</b>", "url": "https://works.bepress.com/matthew_sag/7/download/", "isFamilyFriendly": true, "displayUrl": "https://works.bepress.com/matthew_sag/7/download", "snippet": "the <b>court</b> will have to decide in the upcoming <b>class-action</b> <b>fairness</b> hearing. The Amended Settlement Agreement does nothing to diminish Google\u2019s unique position in relation to the exploitation of orphan works. However, it does change the institutional framework in ways that may become", "dateLastCrawled": "2022-01-07T18:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is John Rawls&#39; main idea in his <b>theory of justice as fairness</b>? - Quora", "url": "https://www.quora.com/What-is-John-Rawls-main-idea-in-his-theory-of-justice-as-fairness", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-John-Rawls-main-idea-in-his-<b>theory-of-justice-as-fairness</b>", "snippet": "Answer (1 of 5): A society is just if its basic structure (main political, social and economic institutions) are organised that <b>is fair</b> to the citizens. There are three principles of justice: 1. Greatest equal liberty: each is entitled to a scheme of the greatest possible liberties which is comp...", "dateLastCrawled": "2022-01-26T05:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Counterfactual</b> <b>Fairness</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1703.06856/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1703.06856", "snippet": "We propose a definition called <b>counterfactual</b> <b>fairness</b> that captures the intuition that a decision <b>is fair</b> towards an individual if it gives the same predictions in (a) the observed world and (b) a world where the individual had always belonged to a different demographic group, other background causes of the outcome being equal. We demonstrate our framework on two real-world problems: <b>fair</b> prediction of law school success, and <b>fair</b> modeling of an individual\u2019s criminality in policing data ...", "dateLastCrawled": "2021-12-15T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Counterfactual fairness: removing direct effects through regularization</b> ...", "url": "https://deepai.org/publication/counterfactual-fairness-removing-direct-effects-through-regularization", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>counterfactual-fairness-removing-direct-effects-through</b>...", "snippet": "<b>Counterfactual fairness: removing direct effects through regularization</b>. 02/25/2020 \u2219 by Pietro G. Di Stefano, et al. \u2219 Experian Information Solutions, Inc \u2219 0 \u2219 share . Building machine learning models that are <b>fair</b> with respect to an unprivileged group is a topical problem. Modern <b>fairness</b>-aware algorithms often ignore causal effects and enforce <b>fairness</b> through modifications applicable to only a subset of machine learning models.", "dateLastCrawled": "2021-12-01T08:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Fairness judgments and counterfactual thinking:Pricing</b> goods ...", "url": "https://www.researchgate.net/publication/276443166_Fairness_judgments_and_counterfactual_thinkingPricing_goods_versus_services", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/276443166_<b>Fairness</b>_judgments_and...", "snippet": "<b>Counterfactual</b> thoughts <b>can</b> also aid judgments of <b>fairness</b>, for example, if an employee deems that a supervisor could and should have acted differently to lead to a fairer outcome ( Folger and ...", "dateLastCrawled": "2022-01-19T12:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Expertise, Counterfactual Thinking, and Fairness Perceptions</b>: A Test of ...", "url": "https://www.researchgate.net/publication/255895217_Expertise_Counterfactual_Thinking_and_Fairness_Perceptions_A_Test_of_Fairness_Theory", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/255895217_Expertise_<b>Counterfactual</b>_Thinking...", "snippet": "While <b>fairness</b> theory (Folger &amp; Cropanzano, 1998, 2001) suggests perceptions of injustice are due to accountability judgments and <b>counterfactual</b> thinking, few studies have examined the influence ...", "dateLastCrawled": "2022-02-02T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Unfair offers, unfair offenders? <b>Fairness</b> considerations in ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3724121/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3724121", "snippet": "Pitting an unfair offer (8:2) against a <b>fair</b> alternative (5:5) <b>can</b> be seen as an explicit version of the classic UG in which decision-making is generally based on comparing any offer to a potential equal split. The resulting 8 conditions were presented 16 times each (counterbalanced for proposers&#39; gender and position of the unfair offer). As the no-alternative condition entails an 8:2 offer for either alternative, an unfair offer (8:2) was presented in 5 of the 8 conditions, equivalent to 80 ...", "dateLastCrawled": "2022-02-03T02:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Causality</b> - <b>Fairness</b> and machine learning", "url": "https://fairmlbook.org/causal.html", "isFamilyFriendly": true, "displayUrl": "https://<b>fair</b>mlbook.org/causal.html", "snippet": "It\u2019s important to realize that this procedure defines what a <b>counterfactual</b> is in a structural causal model. The notation Y_{X:=x}(E) denotes the outcome of the procedure and is part of the definition. We haven\u2019t encountered this notation before. Put in words, we interpret the formal <b>counterfactual</b> Y_{X:=x}(E) as the value Y would\u2019ve taken had the variable X been set to value x in the circumstances described by the event E.. In general, the <b>counterfactual</b> Y_{X:=x}(E) is a random ...", "dateLastCrawled": "2022-01-25T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Legal perspective on possible <b>fairness</b> measures \u2013 A legal discussion ...", "url": "https://www.sciencedirect.com/science/article/pii/S026736492100056X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S026736492100056X", "snippet": "It should be noted that <b>Counterfactual</b> <b>Fairness</b> of the <b>fairness</b> measures analyzed in this paper would in practice give decision-makers the greatest room of freedom to determine the decision conditions themselves while state bodies, such as courts and supervisory authorities, would remain monitoring bodies. What <b>fairness</b> measure should be applied to what decision situation, should be decided by a democratically legitimized organ, ideally the parliament. The respective organ could work out ...", "dateLastCrawled": "2021-10-26T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Machine Learning Analysis on the <b>Fairness</b> of the Boston Police ...", "url": "https://groups.csail.mit.edu/mac/classes/6.805/student-papers/fall18-papers/Stop%20and%20Frisk.pdf", "isFamilyFriendly": true, "displayUrl": "https://groups.csail.mit.edu/mac/classes/6.805/student-papers/fall18-papers/Stop and...", "snippet": "4.2.4.2 Show nearest <b>counterfactual</b> 16 ... Deciding what it means to be <b>fair</b> has always been a difficult task, and it is particularly difficult in situations related to the police and stop and frisk. In this paper, we discuss 5 different definitions of <b>fairness</b>: Group Unaware, Group Aware, Demographic Parity, Equal opportunity, and Equal Access. To determine which definitions of <b>fairness</b> to use in our machine learning analysis, we examine past legal cases regarding stop and frisk encounters ...", "dateLastCrawled": "2021-12-11T03:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[D] Is it possible to create machine learning system that <b>is fair</b> ...", "url": "https://www.reddit.com/r/MachineLearning/comments/gqugku/d_is_it_possible_to_create_machine_learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/MachineLearning/comments/gqugku/d_is_it_possible_to_create...", "snippet": "Many in the ML <b>fairness</b> community are promoting a concept called <b>counterfactual</b> <b>fairness</b>. It is known that there are various statistical correlations between various seemingly innocuous pieces of information and protected characteristics. For example, if someone puts on their resume that they compete in Dressage, there is a very good chance that they are white. Through sets of correlated attributes, an ML model <b>can</b> infer race and gender somewhat accurately, and may be able to exploit it as a ...", "dateLastCrawled": "2022-01-01T13:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Google Book Settlement And The <b>Fair</b> Use <b>Counterfactual</b>", "url": "https://works.bepress.com/matthew_sag/7/download/", "isFamilyFriendly": true, "displayUrl": "https://works.bepress.com/matthew_sag/7/download", "snippet": "the <b>court</b> will have to decide in the upcoming <b>class-action</b> <b>fairness</b> hearing. The Amended Settlement Agreement does nothing to diminish Google\u2019s unique position in relation to the exploitation of orphan works. However, it does change the institutional framework in ways that may become", "dateLastCrawled": "2022-01-07T18:15:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Counterfactual Fairness</b> - ResearchGate", "url": "https://www.researchgate.net/publication/315454664_Counterfactual_Fairness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/315454664_<b>Counterfactual_Fairness</b>", "snippet": "way of assessing an existing decision making process, it is not as natural as <b>counterfactual fairness</b> in. the context of <b>machine</b> <b>learning</b>. Approximate <b>fairness</b> and model validation. The notion of ...", "dateLastCrawled": "2022-01-26T14:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Counterfactual Generation and Fairness Evaluation</b> Using Adversarially ...", "url": "https://www.researchgate.net/publication/344294835_Counterfactual_Generation_and_Fairness_Evaluation_Using_Adversarially_Learned_Inference", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344294835_<b>Counterfactual</b>_Generation_and...", "snippet": "<b>Counterfactual</b> examples for an input---perturbations that change specific features but not others---have been shown to be useful for evaluating explainability and <b>fairness</b> of <b>machine</b> <b>learning</b> ...", "dateLastCrawled": "2022-01-04T04:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "A case-study on the application of <b>fairness</b> in <b>machine</b> <b>learning</b> research to a production classification system, and new insights in how to measure and address algorithmic <b>fairness</b> issues. Research paper <b>Counterfactual</b> <b>fairness</b> in text classification through robustness Provides and compares multiple approaches for addressing <b>counterfactual</b> <b>fairness</b> issues in text models. Research paper Model Cards for Model Reporting Proposes a framework to encourage transparent model reporting. Research ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Fairness in Machine Learning: Lessons from Political Philosophy</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-lessons-from-political-philosophy", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-lessons-from-political</b>...", "snippet": "This discussion suggests that \u2018<b>fairness</b>\u2019 as used in the fair <b>machine</b> <b>learning</b> community is best understood as a placeholder term for a variety of normative egalitarian considerations. Notably, while egalitarianism is a widely held principle, exactly what it requires is the subject of much debate. I provide an overview of some of this debate and finish with implications for the incorporation of \u2018<b>fairness</b>\u2019 into algorithmic decision-making systems.", "dateLastCrawled": "2021-12-26T22:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "[PDF] A Survey on Bias and <b>Fairness</b> in <b>Machine</b> <b>Learning</b> | Semantic Scholar", "url": "https://www.semanticscholar.org/paper/A-Survey-on-Bias-and-Fairness-in-Machine-Learning-Mehrabi-Morstatter/0090023afc66cd2741568599057f4e82b566137c", "isFamilyFriendly": true, "displayUrl": "https://www.semanticscholar.org/paper/A-Survey-on-Bias-and-<b>Fairness</b>-in-<b>Machine</b>...", "snippet": "This survey investigated different real-world applications that have shown biases in various ways, and created a taxonomy for <b>fairness</b> definitions that <b>machine</b> <b>learning</b> researchers have defined to avoid the existing bias in AI systems. With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for <b>fairness</b> has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive ...", "dateLastCrawled": "2022-01-29T11:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Counterfactual</b> Explanation of <b>Machine</b> <b>Learning</b> Survival Models - IOS Press", "url": "https://content.iospress.com/articles/informatica/infor468", "isFamilyFriendly": true, "displayUrl": "https://content.iospress.com/articles/informatica/infor468", "snippet": "A method for <b>counterfactual</b> explanation of <b>machine</b> <b>learning</b> survival models is proposed. One of the difficulties of solving the <b>counterfactual</b> explanation problem is that the classes of examples are implicitly defined through outcomes of a <b>machine</b> <b>learning</b> survival model in the form of survival functions. A condition that establishes the difference between survival functions of the original example and the <b>counterfactual</b> is introduced. This condition is based on using a distance between mean ...", "dateLastCrawled": "2022-01-15T22:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Human-centric Approach to <b>Fairness</b> in AI", "url": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "isFamilyFriendly": true, "displayUrl": "https://www.timlrx.com/blog/a-human-centric-approach-to-<b>fairness</b>-in-ai", "snippet": "A lot of what is discussed in the <b>machine</b> <b>learning</b> literature touches on <b>fairness</b> (or rather equivalence in certain outcomes) between groups, yet this narrowly constricts <b>fairness</b> to the notion of equality. Of course, we should think about <b>fairness</b> in the context of prejudiced groups, but we should also ask whether it is fair to an individual. Adding constraints in models might lead to worse outcomes for other individuals. If the decision making processs has serious consequences e.g. a fraud ...", "dateLastCrawled": "2022-02-03T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "dimensions of <b>machine</b> Causality and the normative", "url": "https://maxkasy.github.io/home/files/other/ML_inequality_conference/slides_loftus.pdf", "isFamilyFriendly": true, "displayUrl": "https://maxkasy.github.io/home/files/other/ML_inequality_conference/slides_loftus.pdf", "snippet": "dimensions of <b>machine</b> <b>learning</b> Joshua Loftus (LSE Statistics) High level intro Causality, what is it good for? Causal <b>fairness</b> In prediction and ranking tasks, and with intersectionality Designing interventions Optimal fair policies, causal interference Concluding thoughts 2 / 27. Tech solutionism, using ML/AI in every situation 3 / 27. Imagination Albert Einstein: Imagination is more important than knowledge. For knowledge is limited, whereas imagination [...] stimulat[es] progress, giving ...", "dateLastCrawled": "2022-01-11T12:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Stable <b>Learning</b> and its Causal Implication", "url": "http://pengcui.thumedialab.com/papers/Stable%20Learning-tutorial-valse2021.pdf", "isFamilyFriendly": true, "displayUrl": "pengcui.thumedialab.com/papers/Stable <b>Learning</b>-tutorial-valse2021.pdf", "snippet": "Application --- <b>counterfactual</b> visual explanations ... Goyal, Yash, et al. &quot;<b>Counterfactual</b> visual explanations.&quot; International Conference on <b>Machine</b> <b>Learning</b>. PMLR, 2019. Explainability with Causality Application --- causal recommendation 17 He et al. \u201dCollaborative Causal Filtering for Out-of-Distribution Recommendation.&quot; Under review. Caual structure among user features and item features Example . Explainability and OOD \u2022Explainability would be a side product when pursuing OOD with ...", "dateLastCrawled": "2022-01-28T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Counterfactual Fairness</b> - ResearchGate", "url": "https://www.researchgate.net/publication/315454664_Counterfactual_Fairness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/315454664_<b>Counterfactual_Fairness</b>", "snippet": "<b>Machine</b> <b>learning</b> has matured to the point to where it is now being considered to automate decisions in loan lending, employee hiring, and predictive policing. In many of these scenarios however ...", "dateLastCrawled": "2022-01-26T14:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Counterfactual Fairness \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1703.06856/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1703.06856", "snippet": "<b>Machine</b> <b>learning</b> has matured to the point to where it is now being considered to automate decisions in loan lending, employee hiring, and predictive policing. In many of these scenarios however, previous decisions have been made that are unfairly biased against certain subpopulations (e.g., those of a particular race, gender, or sexual orientation). Because this past data is often biased, <b>machine</b> <b>learning</b> predictors must account for this to avoid perpetuating discriminatory practices (or ...", "dateLastCrawled": "2021-12-15T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Abstract - arXiv", "url": "https://arxiv.org/pdf/1703.06856v3.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/1703.06856v3.pdf", "snippet": "<b>machine</b> <b>learning</b> predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our de\ufb01nition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it is the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real ...", "dateLastCrawled": "2020-08-09T05:32:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(counterfactual fairness)  is like +(a court is fair)", "+(counterfactual fairness) is similar to +(a court is fair)", "+(counterfactual fairness) can be thought of as +(a court is fair)", "+(counterfactual fairness) can be compared to +(a court is fair)", "machine learning +(counterfactual fairness AND analogy)", "machine learning +(\"counterfactual fairness is like\")", "machine learning +(\"counterfactual fairness is similar\")", "machine learning +(\"just as counterfactual fairness\")", "machine learning +(\"counterfactual fairness can be thought of as\")", "machine learning +(\"counterfactual fairness can be compared to\")"]}