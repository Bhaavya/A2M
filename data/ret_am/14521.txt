{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Word</b> Embeddings for the Analysis of Ideological Placement in ...", "url": "https://www.cambridge.org/core/journals/political-analysis/article/abs/word-embeddings-for-the-analysis-of-ideological-placement-in-parliamentary-corpora/017F0CEA9B3DB6E1B94AC36A509A8A7B", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/political-analysis/article/abs/<b>word</b>-<b>embeddings</b>...", "snippet": "Third, the methodology allows us to <b>map</b> political actors and language in a common vector space. This means that we can situate actors of interest based on their proximity to political concepts. Using a single model of embeddings, researchers can rank political actors relative to these concepts using a variety of metrics for vector arithmetic. We demonstrate such implementations in our empirical section. Our results suggest that <b>word</b> embeddings are a promising tool for expanding the ...", "dateLastCrawled": "2022-01-30T17:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Text Similarities : Estimate the degree of <b>similarity</b> between two texts ...", "url": "https://medium.com/@adriensieg/text-similarities-da019229c894", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@adriensieg/text-similarities-da019229c894", "snippet": "Every <b>word</b> <b>embedding</b> is weighted by a/(a + p(w)), where a is a parameter that is typically set to 0.001 and p(w) is the estimated frequency of the <b>word</b> in a reference corpus.", "dateLastCrawled": "2022-02-02T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Cities <b>Around the World by Latitude and Longitude</b> \u2013 BatchGeo Blog", "url": "https://blog.batchgeo.com/cities-by-latitude-and-longitude/", "isFamilyFriendly": true, "displayUrl": "https://blog.batchgeo.com/cities-<b>by-latitude-and-longitude</b>", "snippet": "These <b>coordinates</b>, called latitude and longitude, are used to create maps <b>like</b> the one below. In addition to the cities\u2019 exact <b>locations</b>, we found their nearest latitude and longitude (within 5 degrees), and you can filter the <b>map</b> by these ranges.", "dateLastCrawled": "2022-02-03T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Embedding</b> Geographic <b>Locations</b> for Modelling the Natural Environment ...", "url": "https://orca.cardiff.ac.uk/119323/1/ECIR2019.pdf", "isFamilyFriendly": true, "displayUrl": "https://orca.cardiff.ac.uk/119323/1/ECIR2019.pdf", "snippet": "natural way. To this end, we rely on an adaptation of the GloVe <b>word</b> <b>embedding</b> model [34], but rather than learning <b>word</b> vectors, we learn vectors representing <b>locations</b>. Similar to how the representation of a <b>word</b> in GloVe is determined by the context words surrounding it, the representation of a location in our model", "dateLastCrawled": "2022-01-02T10:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Enter Latitude and Longitude into Google Maps \u2013 BatchGeo Blog", "url": "https://blog.batchgeo.com/how-to-enter-latitude-and-longitude-into-google-maps/", "isFamilyFriendly": true, "displayUrl": "https://blog.batchgeo.com/how-to-enter-latitude-and-longitude-into-google-<b>map</b>s", "snippet": "Create a Google <b>Map</b> Listing Many <b>Locations</b>. It\u2019s one thing to plot a single point <b>on a map</b> or to discover the <b>coordinates</b> for all your favorite places. Next you need to get them all <b>on a map</b>. For programmers, Google includes a Google Maps API. As we discuss in our tutorial, that\u2019s definitely the hard way to <b>map</b> multiple <b>locations</b>.", "dateLastCrawled": "2022-02-02T21:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Geolocation: Displaying User or Device Position on Maps | Maps ...", "url": "https://developers.google.com/maps/documentation/javascript/geolocation", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>map</b>s/documentation/javascript/geo<b>location</b>", "snippet": "This tutorial shows you how to display the geographic <b>location</b> of a user or device on a Google <b>map</b>, using your browser&#39;s HTML5 Geolocation feature along with the Maps JavaScript API. (Note that the geographic <b>location</b> of a user will only display if he or she has allowed <b>location</b> sharing.) Below is a <b>map</b> that can identify your present <b>location</b>.", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>What is an embedding dimension</b>? - Quora", "url": "https://www.quora.com/What-is-an-embedding-dimension", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-an-embedding-dimension</b>", "snippet": "Answer: Let\u2019s talk about Spatial <b>Embedding</b>. Consider a Basket Ball: and be yourself my friendly Amoeba Scientist Amoeba Joe: You live your full life on the surface of that Ball, which I will call Wilson Universe: You can only move on the surface - so you rightfully concludes that the Universe...", "dateLastCrawled": "2022-02-02T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Visualizing Similarity Data with a Mixture of Maps", "url": "http://proceedings.mlr.press/v2/cook07a/cook07a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v2/cook07a/cook07a.pdf", "snippet": "<b>word</b> association data we <b>describe</b> later, subjects are asked to pick an associated <b>word</b>, so pjji is simply the fraction of the subjects who pick <b>word</b> j when given <b>word</b> i. If the data consists of the <b>coordinates</b> of objects in a high-dimensional Euclidean space, it can be converted into a set of conditional probabilities of the form pjji for each ...", "dateLastCrawled": "2021-12-06T08:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Google API Tutorial - <b>W3Schools</b>", "url": "https://www.w3schools.com/graphics/google_maps_intro.asp", "isFamilyFriendly": true, "displayUrl": "https://<b>www.w3schools.com</b>/graphics/<b>google_maps</b>_intro.asp", "snippet": "Canvas Intro Canvas Drawing Canvas <b>Coordinates</b> Canvas Gradients Canvas Text Canvas Images Canvas Reference Canvas Clock Clock Intro Clock Face Clock Numbers Clock Hands Clock Start HTML Game Game Intro Game Canvas Game Components Game Controllers Game Obstacles Game Score Game Images Game Sound Game Gravity Game Bouncing Game Rotation Game Movement. <b>Google Maps</b> Tutorial Previous Next <b>Google Maps</b> API. This tutorial is about the <b>Google Maps</b> API (Application Programming Interface). An API is a ...", "dateLastCrawled": "2022-02-02T23:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to See Exactly Where a Photo Was Taken (and Keep Your Location Private)", "url": "https://www.howtogeek.com/211427/how-to-see-exactly-where-a-photo-was-taken-and-keep-your-location-private/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.howtogeek.com</b>/211427/how-to-see-exactly-where-a-photo-was-taken-and-keep...", "snippet": "Match the <b>Coordinates</b> to a Location <b>on a Map</b>. These are standard GPS <b>coordinates</b>, so you just need to match them to a location <b>on a map</b> to find where the photo was actually taken. Many mapping services offer this feature\u2014you can plug the <b>coordinates</b> straight into Google Maps, for example. Google offers instructions for properly formatting the <b>coordinates</b> for Google Maps. Bear in mind that this is just metadata and could be faked, but it\u2019s pretty rare that someone would bother to fake ...", "dateLastCrawled": "2022-02-02T19:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A deep learning framework combined with <b>word</b> <b>embedding</b> to identify DNA ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7804333/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7804333", "snippet": "<b>Word</b> <b>embedding</b> technology is a general term for language models and representation learning technologies in the field of natural language processing. Conceptually, it refers to allowing machines to learn distributed representations of words by <b>embedding</b> a high-dimensional space with the number of all words in a low-dimensional continuous vector space. Before the advent of <b>word</b> <b>embedding</b> technology, one-hot representation is a traditional method, but one-hot is too sparse to reflect the ...", "dateLastCrawled": "2022-01-18T14:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Word</b> Embeddings for the Analysis of Ideological Placement in ...", "url": "https://www.cambridge.org/core/journals/political-analysis/article/abs/word-embeddings-for-the-analysis-of-ideological-placement-in-parliamentary-corpora/017F0CEA9B3DB6E1B94AC36A509A8A7B", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/political-analysis/article/abs/<b>word</b>-<b>embeddings</b>...", "snippet": "Third, the methodology allows us to <b>map</b> political actors and language in a common vector space. This means that we can situate actors of interest based on their proximity to political concepts. Using a single model of embeddings, researchers can rank political actors relative to these concepts using a variety of metrics for vector arithmetic. We demonstrate such implementations in our empirical section. Our results suggest that <b>word</b> embeddings are a promising tool for expanding the ...", "dateLastCrawled": "2022-01-30T17:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Unsupervised Text Classification and Search</b> using <b>Word</b> Embeddings ...", "url": "https://www.researchgate.net/publication/311688809_Unsupervised_Text_Classification_and_Search_using_Word_Embeddings_on_a_Self-Organizing_Map", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/311688809_Unsupervised_Text_Classification...", "snippet": "The encoded documents are organized on another self-organizing <b>map</b>, a document <b>map</b>, on which nearby <b>locations</b> contain <b>similar</b> documents. Special consideration is given to the computation of very ...", "dateLastCrawled": "2022-02-02T14:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Text Similarities : Estimate the degree of <b>similarity</b> between two texts ...", "url": "https://medium.com/@adriensieg/text-similarities-da019229c894", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@adriensieg/text-<b>similar</b>ities-da019229c894", "snippet": "BERT <b>embedding</b> for the <b>word</b> in the middle is more <b>similar</b> to the same <b>word</b> on the right than the one on the left. When classification is the larger objective, there is no need to build a BoW ...", "dateLastCrawled": "2022-02-02T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Cities <b>Around the World by Latitude and Longitude</b> \u2013 BatchGeo Blog", "url": "https://blog.batchgeo.com/cities-by-latitude-and-longitude/", "isFamilyFriendly": true, "displayUrl": "https://blog.batchgeo.com/cities-<b>by-latitude-and-longitude</b>", "snippet": "These <b>coordinates</b>, called latitude and longitude, are used to create maps like the one below. In addition to the cities\u2019 exact <b>locations</b>, we found their nearest latitude and longitude (within 5 degrees), and you can filter the <b>map</b> by these ranges.", "dateLastCrawled": "2022-02-03T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Embedding</b> Geographic <b>Locations</b> for Modelling the Natural Environment ...", "url": "https://orca.cardiff.ac.uk/119323/1/ECIR2019.pdf", "isFamilyFriendly": true, "displayUrl": "https://orca.cardiff.ac.uk/119323/1/ECIR2019.pdf", "snippet": "<b>describe</b> the location where these photos were taken, and Flickr can thus be re-garded as a source of environmental information. The use of Flickr for modelling urban environments has already received considerable attention. For instance, various approaches have been proposed for modelling urban regions [5], and for identifying points-of-interest [45] and itineraries [7,36]. However, the usefulness of Flickr for characterizing the natural environment, which is the focus of this paper, is less ...", "dateLastCrawled": "2022-01-02T10:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Visualizing Similarity Data with a Mixture of Maps", "url": "http://proceedings.mlr.press/v2/cook07a/cook07a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v2/cook07a/cook07a.pdf", "snippet": "in any <b>map</b> means that two objects really are <b>similar</b> in the mixture model. 2 Stochastic Neighbor <b>Embedding</b> SNE starts byconvertinghigh-dimensionaldistance orsim- ilarity data intoa set ofconditionalprobabilitiesof the form pjji, each of which is the probability that one object, i, would stochastically pick another object j as its neighbor if it was only allowed to pick one neighbor. These condi-tional probabilities can be produced in many ways. In the <b>word</b> association data we <b>describe</b> later ...", "dateLastCrawled": "2021-12-06T08:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>What is an embedding dimension</b>? - Quora", "url": "https://www.quora.com/What-is-an-embedding-dimension", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-an-embedding-dimension</b>", "snippet": "Answer: Let\u2019s talk about Spatial <b>Embedding</b>. Consider a Basket Ball: and be yourself my friendly Amoeba Scientist Amoeba Joe: You live your full life on the surface of that Ball, which I will call Wilson Universe: You can only move on the surface - so you rightfully concludes that the Universe...", "dateLastCrawled": "2022-02-02T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Introduction to <b>export</b> a <b>map</b> or layout\u2014ArcGIS Pro | Documentation", "url": "https://pro.arcgis.com/en/pro-app/latest/help/sharing/overview/export-a-map-or-layout.htm", "isFamilyFriendly": true, "displayUrl": "https://pro.arcgis.com/en/pro-app/latest/help/sharing/overview/<b>export</b>-a-<b>map</b>-or-layout.htm", "snippet": "After you&#39;ve created a <b>map</b> or layout, you can <b>export</b> it as a file to share with others. To <b>export</b>, make sure a <b>map</b> or layout view is active. On the Share tab, click <b>Export</b> <b>Map</b> or <b>Export</b> Layout, depending on the active view, to open the <b>Export</b> pane. Set a name and location for the file, and any other properties, and click <b>Export</b>.Once the <b>Export</b> pane is open, you can switch between <b>map</b> and layout views to <b>export</b> them without having to reset properties.. <b>Export</b> file types", "dateLastCrawled": "2022-02-03T05:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to See Exactly Where a Photo Was Taken (and Keep Your Location Private)", "url": "https://www.howtogeek.com/211427/how-to-see-exactly-where-a-photo-was-taken-and-keep-your-location-private/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.howtogeek.com</b>/211427/how-to-see-exactly-where-a-photo-was-taken-and-keep...", "snippet": "Match the <b>Coordinates</b> to a Location <b>on a Map</b>. These are standard GPS <b>coordinates</b>, so you just need to match them to a location <b>on a map</b> to find where the photo was actually taken. Many mapping services offer this feature\u2014you can plug the <b>coordinates</b> straight into Google Maps, for example. Google offers instructions for properly formatting the <b>coordinates</b> for Google Maps. Bear in mind that this is just metadata and could be faked, but it\u2019s pretty rare that someone would bother to fake ...", "dateLastCrawled": "2022-02-02T19:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>The Geometry of Culture: Analyzing the Meanings</b> of Class through <b>Word</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/0003122419877135", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/0003122419877135", "snippet": "We <b>describe</b> how dimensions of <b>word</b> <b>embedding</b> models correspond closely to \u201ccultural dimensions\u201d such as rich-poor, good-evil, and masculine-feminine, and how the positions of words arrayed on salient cultural dimensions of a <b>word</b> <b>embedding</b> reflect patterns of association and classification within a given cultural system. Furthermore, by calculating angles between cultural dimensions, we are able to investigate relationships between the axes of classification themselves.", "dateLastCrawled": "2022-02-02T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Correspondence analysis, spectral clustering and</b> graph <b>embedding</b> ...", "url": "https://www.nature.com/articles/s41598-021-87971-9", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-87971-9", "snippet": "In fact, it <b>can</b> be shown that CA is mathematically equivalent to network methods such as clustering and graph <b>embedding</b> techniques 17,18 (note that \u201cgraph\u201d is another <b>word</b> for network). The ...", "dateLastCrawled": "2022-02-01T09:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Deep Learning in a <b>Nutshell: Sequence Learning</b> | NVIDIA Developer Blog", "url": "https://developer.nvidia.com/blog/deep-learning-nutshell-sequence-learning/", "isFamilyFriendly": true, "displayUrl": "https://developer.nvidia.com/blog/deep-learning-<b>nutshell-sequence-learning</b>", "snippet": "The words mentioned above that are more similar to the <b>word</b> \u201ccat\u201d <b>map</b> to <b>locations</b> closer to the location of \u201ccat\u201d in the space; for example, \u201ckitty\u201d and \u201cfeline\u201d are close; \u201ctiger\u201d and \u201clion\u201d are a bit further away; \u201cdog\u201d further still; and \u201ccar\u201d is very, very far away. See Figure 3 for an example of words in cooking recipes and their <b>word</b> <b>embedding</b> space in two dimensions. If we use vectors that point to each <b>word</b> in this space, then each vector will ...", "dateLastCrawled": "2022-02-01T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Local conformal autoencoder for standardized data coordinates</b> | <b>PNAS</b>", "url": "https://www.pnas.org/content/117/49/30918", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/117/49/30918", "snippet": "We develop a method for extracting standardized, nonlinear, intrinsic <b>coordinates</b> from measured data, leading to a generalized isometric <b>embedding</b> of the observations. This is achieved through a local burst data acquisition strategy that allows us to capture the local z-scored structure. We implement this method using a local conformal autoencoder architecture and illustrate it computationally. The proposed <b>embedding</b> is fast, parallelizable, easy to implement using existing open-source ...", "dateLastCrawled": "2021-07-12T10:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Four dimensions characterize attributions from faces using a ...", "url": "https://www.nature.com/articles/s41467-021-25500-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-021-25500-y", "snippet": "Finally, the <b>word</b> <b>embedding</b> we applied to quantify and select the trait stimuli also depends on the criteria used by the neural networks (e.g., the corpus of English words used for training, as ...", "dateLastCrawled": "2022-01-25T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>What is an embedding dimension</b>? - Quora", "url": "https://www.quora.com/What-is-an-embedding-dimension", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-an-embedding-dimension</b>", "snippet": "Answer: Let\u2019s talk about Spatial <b>Embedding</b>. Consider a Basket Ball: and be yourself my friendly Amoeba Scientist Amoeba Joe: You live your full life on the surface of that Ball, which I will call Wilson Universe: You <b>can</b> only move on the surface - so you rightfully concludes that the Universe...", "dateLastCrawled": "2022-02-02T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>In-Depth: Manifold Learning</b> | Python Data Science Handbook", "url": "https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html", "isFamilyFriendly": true, "displayUrl": "https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html", "snippet": "To address this deficiency, we <b>can</b> turn to a class of methods known as manifold learning\u2014a class of unsupervised estimators that seeks <b>to describe</b> datasets as low-dimensional manifolds embedded in high-dimensional spaces. When you think of a manifold, I&#39;d suggest imagining a sheet of paper: this is a two-dimensional object that lives in our familiar three-dimensional world, and <b>can</b> be bent or rolled in that two dimensions. In the parlance of manifold learning, we <b>can</b> think of this sheet as ...", "dateLastCrawled": "2022-02-02T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "STRATEGIC PLANNING Guide for Managers", "url": "https://hr.un.org/sites/hr.un.org/files/4.5.1.6_Strategic%20Planning%20Guide_0.pdf", "isFamilyFriendly": true, "displayUrl": "https://hr.un.org/sites/hr.un.org/files/4.5.1.6_Strategic Planning Guide_0.pdf", "snippet": "You <b>can</b> see the overview Strategic Framework document for all departments here (within the UN network). The key steps for and timing of the biennial budgeting process are found in the Managers\u2019 Toolkit. Other strategic plans may need to be developed outside the timeframes and parameters of the biennial budget process. For example, if an office is suddenly faced with a new challenge or mandate, a change in its operating environment, or other strategic change, it may be valuable to undertake ...", "dateLastCrawled": "2022-02-03T00:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Advanced VLOOKUP in Excel with formula examples - <b>Ablebits.com</b>", "url": "https://www.ablebits.com/office-addins-blog/2014/07/29/vlookup-formula-examples/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ablebits.com</b>/office-addins-blog/2014/07/29/vlookup-formula-examples", "snippet": "For me to be able to help you, please <b>describe</b> your problem in more detail. What values are there in the cells you are applying your formula to? Are your 4 values typed in the same cell or in 4 different ones? What formula are you using to look for values? Please let me know. I think I <b>can</b> suggest a solution but some additional information is needed. Reply. HAIDAR RAZA says: February 13, 2020 at 11:37 am . Hi i want use vlookup formula but i have issue to find out result with two lookup ...", "dateLastCrawled": "2022-02-02T23:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Strategic Planning Resume Samples</b> | Velvet Jobs", "url": "https://www.velvetjobs.com/resume/strategic-planning-resume-sample", "isFamilyFriendly": true, "displayUrl": "https://www.velvetjobs.com/resume/strategic-planning-resume-sample", "snippet": "Drives and <b>coordinates</b> the efforts related to long term planning. Gathers analytics; reviews/analyzes metrics; identifies future trends and supports the Division with overall Strategy Liaises effectively with all the key stakeholders of BOW Compliance as needed Assists the Chief Compliance Officer and the SVP, Compliance Strategy &amp; Administration Manager by coordinating activities supporting the development of the Compliance Function team Oversees the Business Continuity Plan activities for ...", "dateLastCrawled": "2022-02-03T07:25:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A deep learning framework combined with <b>word</b> <b>embedding</b> to identify DNA ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7804333/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7804333", "snippet": "In addition, the principal component analysis (PCA) 49 and the T-distributed neighborhood <b>embedding</b> algorithm (T-SNE) 50 <b>can</b> be adopted to further reduce the dimension of the distributed representation in the <b>word</b> <b>embedding</b> space, thereby realizing the visualization of <b>word</b> <b>embedding</b> and <b>word</b> meaning induction. In view of this, <b>word</b> <b>embedding</b> technology is utilized in this paper to realize the distribution representation.", "dateLastCrawled": "2022-01-18T14:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A deep learning <b>framework combined with word embedding</b> to identify DNA ...", "url": "https://www.nature.com/articles/s41598-020-80670-x", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-020-80670-x", "snippet": "As shown in Fig. 2, a 2-dimensional feature space in the dataset \\(S_{1}\\) <b>can</b> be obtained by applying the t-distributed stochastic neighbor <b>embedding</b> (t-SNE) algorithm to the original feature ...", "dateLastCrawled": "2022-02-03T14:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Word</b> Embeddings for the Analysis of Ideological Placement in ...", "url": "https://www.cambridge.org/core/journals/political-analysis/article/abs/word-embeddings-for-the-analysis-of-ideological-placement-in-parliamentary-corpora/017F0CEA9B3DB6E1B94AC36A509A8A7B", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/political-analysis/article/abs/<b>word</b>-<b>embeddings</b>...", "snippet": "By accounting for the fact that different words <b>can</b> express the same meaning, a model based on <b>word</b> embeddings <b>can</b> account for continuity in a party\u2019s position even when <b>word</b> usage changes over time. For example, an expression related to an insurrection in the late 19th and early 20th century, the term \u201cMoros\u201d (referring to the Moro Rebellion in the Philippines) has a <b>word</b> <b>embedding</b> similar to the term \u201cISIL\u201d (the Islamic State of Iraq and the Levant).", "dateLastCrawled": "2022-01-30T17:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Text Similarities : Estimate the degree of <b>similarity</b> between two texts ...", "url": "https://medium.com/@adriensieg/text-similarities-da019229c894", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@adriensieg/text-similarities-da019229c894", "snippet": "Every <b>word</b> <b>embedding</b> is weighted by a/(a + p(w)), where a is a parameter that is typically set to 0.001 and p(w) is the estimated frequency of the <b>word</b> in a reference corpus.", "dateLastCrawled": "2022-02-02T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>The Geometry of Culture: Analyzing the Meanings</b> of Class through <b>Word</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/0003122419877135", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/0003122419877135", "snippet": "We <b>describe</b> how dimensions of <b>word</b> <b>embedding</b> models correspond closely to \u201ccultural dimensions\u201d such as rich-poor, good-evil, ... including scientific disciplines, political elites, and contributors to online forums, <b>can</b> be analyzed and <b>compared</b> by training <b>word</b> <b>embedding</b> models on the text they produce. Furthermore, while this article focused on insights produced by identifying, extracting, or comparing \u201ccultural dimensions\u201d from the vector space, we do not maintain this is the only ...", "dateLastCrawled": "2022-02-02T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Cities <b>Around the World by Latitude and Longitude</b> - BatchGeo", "url": "https://blog.batchgeo.com/cities-by-latitude-and-longitude/", "isFamilyFriendly": true, "displayUrl": "https://blog.batchgeo.com/cities-<b>by-latitude-and-longitude</b>", "snippet": "While no cities <b>can</b> share both sets of <b>coordinates</b> (since it\u2019s the exact location of the city), many share one of the numbers that make up their coordinate pair. These <b>coordinates</b>, called latitude and longitude, are used to create maps like the one below. In addition to the cities\u2019 exact <b>locations</b>, we found their nearest latitude and ...", "dateLastCrawled": "2022-02-03T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to Embed a <b>Google Map with WordPress Form Submissions</b>", "url": "https://formidableforms.com/embed-google-map-wordpress-form/", "isFamilyFriendly": true, "displayUrl": "https://formidableforms.com/embed-google-<b>map</b>-<b>word</b>press-form", "snippet": "How to <b>map</b> multiple <b>locations</b> and display form submissions as pins in an embedded Google <b>map</b> is a subject that comes up in our helpdesk regularly. The use of interactive maps is an essential part of realtor sites, classified ads sites and many other applications. These embedded Google maps <b>can</b> help make some really cool websites, and they are easy to setup.", "dateLastCrawled": "2022-02-02T19:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Gated Object-Attribute Matching Network for Detailed</b> Image ... - Hindawi", "url": "https://www.hindawi.com/journals/mpe/2020/9562587/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/mpe/2020/9562587", "snippet": "Computers <b>can</b> <b>describe</b> what objects are in the image but cannot give more details about these objects. In this study, we present a novel image caption approach to give more details when describing objects. In detail, a visual attention-based LSTM is used to find the objects, as well as a semantic attention-based LSTM is used for giving semantic attributes. At last, a <b>gated object-attribute matching network</b> is used to match the objects to their semantic attributes. The experiments on the ...", "dateLastCrawled": "2022-02-02T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "20 <b>Deep Learning Applications</b> in 2022 Across Industries", "url": "https://www.mygreatlearning.com/blog/deep-learning-applications/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreatlearning.com/blog/<b>deep-learning-applications</b>", "snippet": "In comes, Deep Learning and now images <b>can</b> be sorted based on <b>locations</b> detected in photographs, faces, a combination of people, or according to events, dates, etc. Searching for a particular photo from a library (let\u2019s say a dataset as large as Google\u2019s picture library) requires state-of-the-art visual recognition systems consisting of several layers from basic to advanced to recognize elements.", "dateLastCrawled": "2022-02-02T22:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Off on a Tangent \u2013 Left Adjoint to Forgetful Thinking", "url": "https://leftadjoint.wordpress.com/2021/09/23/off-on-a-tangent/", "isFamilyFriendly": true, "displayUrl": "https://leftadjoint.<b>word</b>press.com/2021/09/23/off-on-a-tangent", "snippet": "This is the idea underlying why you <b>can</b> use a flat, two-dimensional <b>map</b> of a city and reliably eyeball how distances, angles, and sizes compare between different <b>locations</b>, despite the general spherical shape of the Earth: a city is so small <b>compared</b> to the whole Earth that a <b>map</b>\u2014which is exactly a (scaled-down) linear approximation of the true city\u2014barely differs in geometry from the city itself.", "dateLastCrawled": "2022-01-20T01:15:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond king - man ...", "url": "https://aclanthology.org/C16-1332.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/C16-1332.pdf", "snippet": "<b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond King - Man + Woman = Queen Aleksandr Drozd y, Anna Gladkova z, Satoshi Matsuoka y yTokyo Institute of Technology, Meguro-ku, Tokyo 152-8550, Japan alex@smg.is.titech.ac.jp, matsu@is.titech.ac.jp z The University of Tokyo, Meguro-ku, Tokyo 153-8902 Japan gladkova@phiz.c.u-tokyo.ac.jp Abstract Solving <b>word</b> analogies became one of the most popular benchmarks for <b>word</b> embeddings on the assumption that linear relations between <b>word</b> pairs ...", "dateLastCrawled": "2022-01-20T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond king - man ...", "url": "https://aclanthology.org/C16-1332/", "isFamilyFriendly": true, "displayUrl": "https://acl<b>anthology</b>.org/C16-1332", "snippet": "\ufeff%0 Conference Proceedings %T <b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond king - man + woman = queen %A Drozd, Aleksandr %A Gladkova, Anna %A Matsuoka, Satoshi %S Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers %D 2016 %8 dec %I The COLING 2016 Organizing Committee %C Osaka, Japan %F drozd-etal-2016-<b>word</b> %X Solving <b>word</b> analogies became one of the most popular benchmarks for <b>word</b> embeddings on the assumption that ...", "dateLastCrawled": "2022-01-17T09:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond King ...", "url": "https://www.researchgate.net/publication/311843169_Word_Embeddings_Analogies_and_Machine_Learning_Beyond_King_-_Man_Woman_Queen", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/311843169_<b>Word</b>_<b>Embeddings</b>_Analogies_and...", "snippet": "<b>Word</b> Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond King - Man+ Woman= Queen December 2016 Conference: Proceedings of COLING 2016, the 26th International Conference on Computational ...", "dateLastCrawled": "2021-11-25T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Finding the <b>Word</b> <b>Analogy</b> from given words using Word2Vec embeddings ...", "url": "https://www.geeksforgeeks.org/finding-the-word-analogy-from-given-words-using-word2vec-embeddings/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/finding-the-<b>word</b>-<b>analogy</b>-from-given-<b>words</b>-using-<b>word</b>2vec...", "snippet": "What if we can use a <b>Machine</b> <b>Learning</b> algorithm to automate this task of finding the <b>word</b> <b>analogy</b>. In ... Overview of <b>Word</b> <b>Embedding</b> using Embeddings from Language Models (ELMo) 16, Mar 21. <b>Word</b> Embeddings in NLP. 11, Oct 20. Implement your own word2vec(skip-gram) model in Python. 18, Jan 19. Scraping And Finding Ordered Words In A Dictionary using Python. 23, Jul 17 . Python - Replace all words except the given <b>word</b>. 25, Sep 20. Python | Finding &#39;n&#39; Character Words in a Text File. 15, Oct ...", "dateLastCrawled": "2022-01-26T14:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Word Embeddings in NLP - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/word-embeddings-in-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>word</b>-<b>embeddings</b>-in-nlp", "snippet": "<b>Word</b> Embeddings are a method of extracting features out of text so that we can input those features into a <b>machine</b> <b>learning</b> model to work with text data. They try to preserve syntactical and semantic information. The methods such as Bag of Words(BOW), CountVectorizer and TFIDF rely on the <b>word</b> count in a sentence but do not save any syntactical or semantic information. In these algorithms, the size of the vector is the number of elements in the vocabulary. We can get a sparse matrix if most ...", "dateLastCrawled": "2022-01-30T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "GitHub - jungsoh/<b>word</b>-embeddings-<b>word</b>-<b>analogy</b>-by-document-similarity ...", "url": "https://github.com/jungsoh/word-embeddings-word-analogy-by-document-similarity", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/jungsoh/<b>word</b>-<b>embeddings</b>-<b>word</b>-<b>analogy</b>-by-document-similarity", "snippet": "An example of a <b>word</b> <b>analogy</b> problem is to fill in the blank: Man is to Woman as King is to _____`. Because <b>word</b> embeddings are very computationally expensive to train, most <b>machine</b> <b>learning</b> practitioners will load a pre-trained set of embeddings. We will load a collection of pre-trained embeddings and measure similarity between <b>word</b> embeddings ...", "dateLastCrawled": "2022-01-25T02:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to Solve <b>Analogies</b> with Word2Vec | by Khuyen Tran | Towards Data ...", "url": "https://towardsdatascience.com/how-to-solve-analogies-with-word2vec-6ebaf2354009", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-solve-<b>analogies</b>-with-<b>word</b>2vec-6ebaf2354009", "snippet": "To make words understood by <b>machine</b> <b>learning</b> algorithms, <b>word</b> <b>embedding</b> is used to map words into vectors of real numbers. There are various <b>word</b> <b>embedding</b> models and word2vec is one of them. In simple words, word2vec is a group of related models that are used to produce <b>word</b> embeddings. These models are trained to construct the linguistic contexts of words. Word2vec takes a large corpus of text and produces a vector space, with each unique <b>word</b> in the corpus being assigned to a ...", "dateLastCrawled": "2022-01-30T16:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Word2Vec in Gensim Explained for Creating <b>Word</b> <b>Embedding</b> Models ...", "url": "https://machinelearningknowledge.ai/word2vec-in-gensim-explained-for-creating-word-embedding-models-pretrained-and-custom/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>knowledge.ai/<b>word</b>2vec-in-gensim-explained-for-creating-<b>word</b>...", "snippet": "What is <b>Word</b> Embeddings? <b>Machine</b> <b>learning</b> and ... This is another way putting that word2vec can draw the <b>analogy</b> that if Man is to Woman then Kind is to Queen! The publicly released model of word2vec by Google consists of 300 features and the model is trained in the Google news dataset. The vocabulary size of the model is around 1.6 billion words. However, this might have taken a huge time for the model to be trained on but they have applied a method of simple subsampling approach to ...", "dateLastCrawled": "2022-02-02T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "DeepLearning <b>series: Natural Language Processing and Word Embeddings</b> ...", "url": "https://medium.com/machine-learning-bites/deeplearning-series-natural-language-processing-and-word-embeddings-70599080efc9", "isFamilyFriendly": true, "displayUrl": "https://medium.com/<b>machine</b>-<b>learning</b>-bites/deep<b>learning</b>-series-natural-language...", "snippet": "<b>Learning</b> <b>word</b> embeddings: When we implement an algorithm to learn <b>word</b> embeddings, what we end up <b>learning</b> is an <b>embedding</b> matrix. For a 300-feature <b>embedding</b> and a 10,000-<b>word</b> vocabulary, the ...", "dateLastCrawled": "2021-10-27T13:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Introduction to <b>Word Embeddings</b>. What is a <b>word</b> <b>embedding</b>? | by Hunter ...", "url": "https://towardsdatascience.com/introduction-to-word-embeddings-4cf857b12edc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/introduction-to-<b>word-embeddings</b>-4cf857b12edc", "snippet": "A very basic definition of a <b>word</b> <b>embedding</b> is a real number, vector representation of a <b>word</b>. Typically, these days, words with similar meaning will have vector representations that are close together in the <b>embedding</b> space (though this hasn\u2019t always been the case). When constructing a <b>word</b> <b>embedding</b> space, typically the goal is to capture some sort of relationship in that space, be it meaning, morphology, context, or some other kind of relationship. By encoding <b>word embeddings</b> in a ...", "dateLastCrawled": "2022-01-30T04:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Word Embeddings Explained. What is <b>Word Embedding</b> ? | by Ashwin Prasad ...", "url": "https://medium.com/analytics-vidhya/word-embeddings-explained-62c046f7c79e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/word-<b>embedding</b>s-explained-62c046f7c79e", "snippet": "<b>Word Embedding</b> is a technique in Natural Language Processing which is used to represent words in a Deep <b>Learning</b> environment. The main advantage of using <b>word embedding</b> is that it allows words of\u2026", "dateLastCrawled": "2022-01-24T11:15:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Survey and challenges of story generation models - A multimodal ...", "url": "https://www.sciencedirect.com/science/article/pii/S156625352030378X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S156625352030378X", "snippet": "Pang et al. used the deep Bolzmann <b>machine</b> (DBM), which is a joint density model for the visual, auditory, and textual modalities, for <b>learning</b> highly non-linear relations between low-level features across different modalities for emotional prediction. It is trained using joint representation over multimodal inputs; thus, it can handle training samples, which is absent from certain modality. It can be used for emotional prediction and retrieval on any combination of modalities.", "dateLastCrawled": "2022-01-24T04:42:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(word embedding)  is like +(coordinates to describe locations on a map)", "+(word embedding) is similar to +(coordinates to describe locations on a map)", "+(word embedding) can be thought of as +(coordinates to describe locations on a map)", "+(word embedding) can be compared to +(coordinates to describe locations on a map)", "machine learning +(word embedding AND analogy)", "machine learning +(\"word embedding is like\")", "machine learning +(\"word embedding is similar\")", "machine learning +(\"just as word embedding\")", "machine learning +(\"word embedding can be thought of as\")", "machine learning +(\"word embedding can be compared to\")"]}