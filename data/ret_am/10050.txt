{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Escaping the Impossibility <b>of Fairness</b>: From Formal to Substantive ...", "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3883649", "isFamilyFriendly": true, "displayUrl": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3883649", "snippet": "The most fundamental issue is the mathematical result known as the \u201cimpossibility <b>of fairness</b>\u201d (an <b>incompatibility</b> between mathematical definitions <b>of fairness</b>). Furthermore, many <b>algorithms</b> that satisfy standards <b>of fairness</b> actually exacerbate oppression. These <b>two</b> issues call into question whether algorithmic <b>fairness</b> can play a productive role in the pursuit of equality. In this paper, I diagnose these issues as the product of algorithmic <b>fairness</b> methodology and propose an ...", "dateLastCrawled": "2021-12-27T01:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "CONFAIR: Configurable and Interpretable Algorithmic <b>Fairness</b> | DeepAI", "url": "https://deepai.org/publication/confair-configurable-and-interpretable-algorithmic-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/confair-configurable-and-interpretable-algorithmic-<b>fairness</b>", "snippet": "The different definitions of statistical <b>fairness</b> lead to the evaluation of an algorithm\u2019s performance in fundamentally different ways. For instance, the disparate impact measures the ratio of true positive rates across groups while equal opportunity measures the difference between the true positive rates and false positive rates across groups with the restriction that they are less than a specified threshold. It has been shown that the different <b>fairness</b> <b>metrics</b> are often incompatible ...", "dateLastCrawled": "2022-01-22T16:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) The zoo <b>of Fairness</b> <b>metrics</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/352054128_The_zoo_of_Fairness_metrics_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../352054128_The_zoo_<b>of_Fairness</b>_<b>metrics</b>_in_<b>Machine</b>_<b>Learning</b>", "snippet": "PDF | In the recent years, the problem of addressing <b>fairness</b> in <b>Machine</b> <b>Learning</b> (ML) and automatic decision-making has attracted a lot of attention in... | Find, read and cite all the research ...", "dateLastCrawled": "2021-12-28T22:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fairness in Machine Learning: A Survey</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-a-survey</b>", "snippet": "As <b>Machine</b> <b>Learning</b> technologies become increasingly used in contexts that affect citizens, companies as well as researchers need to be confident that their application of these methods will not have unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote <b>fairness</b>, yet the area is complex and hard to penetrate for newcomers to the domain.", "dateLastCrawled": "2022-01-18T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Escaping the \u201cImpossibility <b>of Fairness</b>\u201d: From Formal to Substantive ...", "url": "https://www.benzevgreen.com/wp-content/uploads/2021/08/Escaping-Impossiblity.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.benzevgreen.com/wp-content/uploads/2021/08/Escaping-Impossiblity.pdf", "snippet": "each approach\u2019s responses to the \u201cimpossibility <b>of fairness</b>\u201d (an <b>incompatibility</b> between mathematical definitions of algorithmic <b>fairness</b>). While the formal approach requires us to accept the \u201cimpossibility <b>of fairness</b>\u201d as a harsh limit on efforts to enhance equality, the substantive approach allows us to escape the \u201cimpossibility <b>of fairness</b>\u201d by suggesting reforms that are not subject to this false dilemma and that are better equipped to ameliorate conditions of social ...", "dateLastCrawled": "2021-08-25T04:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) How do the Existing <b>Fairness</b> <b>Metrics</b> and Unfairness Mitigation ...", "url": "https://www.researchgate.net/publication/356914252_How_do_the_Existing_Fairness_Metrics_and_Unfairness_Mitigation_Algorithms_contribute_to_Ethical_Learning_Analytics", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/356914252_How_do_the_Existing_<b>Fairness</b>...", "snippet": "<b>of fairness</b> <b>metrics</b> Narayanan (2018) and <b>algorithms</b> satisfying such <b>metrics</b> M ehrabi, Morstatter, Sax ena, Lerman, and Galstyan (2019) have been developed in the broader ML community over the last ...", "dateLastCrawled": "2021-12-20T23:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine learning fairness notions: Bridging the</b> gap with real-world ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "snippet": "<b>Fairness</b> in <b>machine</b> <b>learning</b> can be categorized according to <b>two</b> dimensions, namely, the task and the type of <b>learning</b>. For the first dimension, there are <b>two</b> tasks in <b>fairness</b>-aware <b>machine</b> <b>learning</b>: discrimination discovery (or assessment) and discrimination removal (or prevention). Discrimination discovery task focuses on assessing and measuring bias in datasets or in predictions made by the MLDM. Discrimination removal focuses on preventing discrimination by manipulating datasets (pre ...", "dateLastCrawled": "2022-02-03T07:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Introduction to The Special Section on Bias and <b>Fairness</b> in AI", "url": "https://kdd.org/exploration_files/1_specialsectionBIAS_1.pdf", "isFamilyFriendly": true, "displayUrl": "https://kdd.org/exploration_files/1_specialsectionBIAS_1.pdf", "snippet": "of the frontiers <b>of fairness</b> in <b>machine</b> <b>learning</b> research can be found in [4]. Much of the research on <b>fairness</b> in <b>machine</b> <b>learning</b> can be framed in an optimization context [5], where the goal is to maintain good predictive performance while satisfying a number of group-level or individual <b>fairness</b> constraints. This combination can be achieved via modeling and remov-ing representation bias and/or labeling bias in the train-ing data, via <b>fairness</b>-aware representation <b>learning</b> [6; 7], model ...", "dateLastCrawled": "2022-01-17T12:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Survey on Bias and <b>Fairness</b> in <b>Machine</b> <b>Learning</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1908.09635/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1908.09635", "snippet": "With the widespread use of AI systems and applications in our everyday lives, it is important to take <b>fairness</b> issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in <b>machine</b> <b>learning</b>, natural language ...", "dateLastCrawled": "2021-11-15T17:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "When <b>machine learning</b> meets congestion control: A survey and comparison ...", "url": "https://www.sciencedirect.com/science/article/pii/S1389128621001407", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1389128621001407", "snippet": "Current challenges of <b>learning</b>-based CC <b>algorithms</b> are mainly focused on engineering-related issues such as parameter selection, high computational complexity, high memory consumption, low training efficiency, hard convergence, <b>incompatibility</b> and <b>fairness</b>. Based on the understanding and analysis of the current <b>learning</b>-based CC solutions, we identify trends in <b>learning</b>-based CC. Firstly, because of their capability for dealing with network congestion with dynamic and sophisticated state ...", "dateLastCrawled": "2021-11-10T05:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Fairness Metrics: A Comparative Analysis</b>", "url": "https://www.researchgate.net/publication/338762666_Fairness_Metrics_A_Comparative_Analysis", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338762666_<b>Fairness_Metrics_A_Comparative_Analysis</b>", "snippet": "A key goal of the fair-ML community is to develop <b>machine</b>-<b>learning</b> based systems that, once introduced into a social context, can achieve social and legal outcomes such as <b>fairness</b>, justice, and ...", "dateLastCrawled": "2021-11-10T12:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Etiq.ai Debiasing Solutions - How <b>fairness</b> <b>metrics</b> can be misleading", "url": "https://etiq.ai/research/how-fairness-metrics-can-be-misleading/", "isFamilyFriendly": true, "displayUrl": "https://etiq.ai/research/how-<b>fairness</b>-<b>metrics</b>-can-be-misleading", "snippet": "<b>Fairness</b> <b>metrics</b>. <b>Machine</b> <b>learning</b> <b>algorithms</b> are widely used to construct prediction models that inform decision-making processes. For example, a bank may use a model to predict the likelihood of someone paying back a loan based upon certain individual characteristics. This likelihood estimate can then help the bank to decide who to approve for a loan. However, it is well-known that <b>machine</b> <b>learning</b> models can exhibit prejudice towards specific types of people due to, for instance, their ...", "dateLastCrawled": "2022-01-04T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) The zoo <b>of Fairness</b> <b>metrics</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/352054128_The_zoo_of_Fairness_metrics_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../352054128_The_zoo_<b>of_Fairness</b>_<b>metrics</b>_in_<b>Machine</b>_<b>Learning</b>", "snippet": "PDF | In the recent years, the problem of addressing <b>fairness</b> in <b>Machine</b> <b>Learning</b> (ML) and automatic decision-making has attracted a lot of attention in... | Find, read and cite all the research ...", "dateLastCrawled": "2021-12-28T22:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Disparate Interactions: An Algorithm-in</b>-the-Loop Analysis <b>of Fairness</b> ...", "url": "https://econcs.seas.harvard.edu/files/green_fat19.pdf", "isFamilyFriendly": true, "displayUrl": "https://econcs.seas.harvard.edu/files/green_fat19.pdf", "snippet": "<b>incompatibility</b> of di\ufffferent <b>fairness</b> <b>metrics</b> [6, 44] and developing new <b>algorithms</b> to reduce bias [24, 33]. Despitethesee\ufffforts, current research intofairmachine <b>learning</b> fails to capture an essential aspect of how risk assessments impact the criminal justice system: their in\uffffuence on judges. After all, risk assessments do not make de\uffffnitive decisions about pretrial release and sentencing\u2014they merely aid judges, who must decide whom to release before trial and how to sentence ...", "dateLastCrawled": "2022-01-23T14:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Measuring <b>Fairness</b> in <b>Machine</b> <b>Learning</b> Models | by Alexandre Landeau ...", "url": "https://medium.com/data-from-the-trenches/measuring-fairness-in-machine-learning-models-2be070fab712", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-from-the-trenches/measuring-<b>fairness</b>-in-<b>machine</b>-<b>learning</b>...", "snippet": "The next step in our <b>fairness</b> journey is to dig into how to detect biased <b>machine</b> <b>learning</b> models. However, before detecting (un)<b>fairness</b> in <b>machine</b> <b>learning</b>, we first need to be able to define it ...", "dateLastCrawled": "2021-11-30T18:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Fairness in Machine Learning: A Survey</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-a-survey</b>", "snippet": "As <b>Machine</b> <b>Learning</b> technologies become increasingly used in contexts that affect citizens, companies as well as researchers need to be confident that their application of these methods will not have unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote <b>fairness</b>, yet the area is complex and hard to penetrate for newcomers to the domain.", "dateLastCrawled": "2022-01-18T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The Myth in the Methodology: Towards a Recontextualization <b>of Fairness</b> ...", "url": "https://scholar.harvard.edu/files/bgreen/files/18-icmldebates.pdf", "isFamilyFriendly": true, "displayUrl": "https://scholar.harvard.edu/files/bgreen/files/18-icmldebates.pdf", "snippet": "<b>of fairness</b> in terms of statistical <b>metrics</b> and rely heavily on historical data as accurate and neutral representations of the world. So long as the \ufb01eld conforms to these methods and believes it can op-timize systems according to universal notions <b>of fairness</b>, <b>machine</b> <b>learning</b> will be ill-suited to ad-dress the fundamentally political and ethical con-siderations at stake when deploying <b>algorithms</b> in the public sphere. The design and adoption of <b>machine</b> <b>learning</b> tools in high-stakes social ...", "dateLastCrawled": "2022-01-24T14:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine learning fairness notions: Bridging the</b> gap with real-world ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "snippet": "<b>Fairness</b> in <b>machine</b> <b>learning</b> can be categorized according <b>to two</b> dimensions, namely, the task and the type of <b>learning</b>. For the first dimension, there are <b>two</b> tasks in <b>fairness</b>-aware <b>machine</b> <b>learning</b>: discrimination discovery (or assessment) and discrimination removal (or prevention). Discrimination discovery task focuses on assessing and measuring bias in datasets or in predictions made by the MLDM. Discrimination removal focuses on preventing discrimination by manipulating datasets (pre ...", "dateLastCrawled": "2022-02-03T07:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "AI <b>auditing and impact assessment: according</b> to the UK information ...", "url": "https://link.springer.com/article/10.1007/s43681-021-00039-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s43681-021-00039-2", "snippet": "For instance, the <b>incompatibility</b> problem <b>of fairness</b> definitions is a well-documented issue, ... Not only supervised <b>learning</b> present risks, other <b>machine</b> <b>learning</b> systems bring <b>similar</b> and different problems, so there is a need for additional guidance to the deployment of such tools. And regression and forecasting techniques need to be better assessed in terms of <b>metrics</b> and methods used to analyse potential problems. And target audience need to have a better specification (Data Scientists ...", "dateLastCrawled": "2022-01-31T15:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "When <b>machine learning</b> meets congestion control: A survey and comparison ...", "url": "https://www.sciencedirect.com/science/article/pii/S1389128621001407", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1389128621001407", "snippet": "Current challenges of <b>learning</b>-based CC <b>algorithms</b> are mainly focused on engineering-related issues such as parameter selection, high computational complexity, high memory consumption, low training efficiency, hard convergence, <b>incompatibility</b> and <b>fairness</b>. Based on the understanding and analysis of the current <b>learning</b>-based CC solutions, we identify trends in <b>learning</b>-based CC. Firstly, because of their capability for dealing with network congestion with dynamic and sophisticated state ...", "dateLastCrawled": "2021-11-10T05:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Fairness Metrics: A Comparative Analysis</b>", "url": "https://www.researchgate.net/publication/338762666_Fairness_Metrics_A_Comparative_Analysis", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338762666_<b>Fairness_Metrics_A_Comparative_Analysis</b>", "snippet": "A key goal of the fair-ML community is to develop <b>machine</b>-<b>learning</b> based systems that, once introduced into a social context, <b>can</b> achieve social and legal outcomes such as <b>fairness</b>, justice, and ...", "dateLastCrawled": "2021-11-10T12:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Fairness in Machine Learning: A Survey</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-a-survey</b>", "snippet": "This article seeks to provide an overview of the different schools of <b>thought</b> and approaches to mitigating (social) biases and increase <b>fairness</b> in the <b>Machine</b> <b>Learning</b> literature. It organises approaches into the widely accepted framework of pre-processing, in-processing, and post-processing methods, subcategorizing into a further 11 method areas. Although much of the literature emphasizes binary classification, a discussion <b>of fairness</b> in regression, recommender systems,", "dateLastCrawled": "2022-01-18T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) A Survey on <b>Bias and Fairness in Machine Learning</b>", "url": "https://www.researchgate.net/publication/335420210_A_Survey_on_Bias_and_Fairness_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335420210_A_Survey_on_Bias_and_<b>Fairness</b>_in...", "snippet": "In this survey we identify <b>two</b> potential sources of unfairness in <b>machine</b> <b>learning</b> outcomes\u2014those arising from biases in the data and those arising from the <b>algorithms</b>. W e review research ...", "dateLastCrawled": "2022-01-27T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Survey on Bias and <b>Fairness</b> in <b>Machine</b> <b>Learning</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1908.09635/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1908.09635", "snippet": "With the widespread use of AI systems and applications in our everyday lives, it is important to take <b>fairness</b> issues into consideration while designing and engineering these types of systems. Such systems <b>can</b> be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in <b>machine</b> <b>learning</b>, natural language ...", "dateLastCrawled": "2021-11-15T17:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Democratizing Algorithmic Fairness</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s13347-019-00355-w", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00355-w", "snippet": "<b>Machine</b> <b>learning</b> <b>algorithms</b> <b>can</b> now identify patterns and correlations in (big) datasets and predict outcomes based on the identified patterns and correlations. They <b>can</b> then generate decisions in accordance with the outcomes predicted, and decision-making processes <b>can</b> thereby be automated. <b>Algorithms</b> <b>can</b> inherit questionable values from datasets and acquire biases in the course of (<b>machine</b>) <b>learning</b>. While researchers and developers have taken the problem of algorithmic bias seriously, the ...", "dateLastCrawled": "2022-02-03T18:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Mirror Mirror", "url": "https://shiraamitchell.github.io/fairness/", "isFamilyFriendly": true, "displayUrl": "https://shiraamitchell.github.io/<b>fairness</b>", "snippet": "In <b>machine</b> <b>learning</b> and statistics, a ... Pointedly, the existence of many plausible <b>metrics</b> <b>of fairness</b> allows us to pose explicitly the question of whether organizations are deliberately only publishing those <b>metrics</b> which reflect favorably on them, or whether they are suppressing any inquiry whatsoever to avoid a paper trail. In this article we have not taken a particularly adversarial analysis of the <b>fairness</b> landscape, but we encourage the reader to think through the way each definition ...", "dateLastCrawled": "2022-01-06T19:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Training a <b>Machine</b> <b>Learning</b> Model <b>in English Improves Its Performance</b> ...", "url": "https://www.amazon.science/blog/training-a-machine-learning-model-in-english-improves-its-performance-in-japanese", "isFamilyFriendly": true, "displayUrl": "https://www.amazon.science/blog/training-a-<b>machine</b>-<b>learning</b>-model-in-english-improves...", "snippet": "You will be expected to be a <b>thought</b> leader as we develop new products within Last Mile Safety and Evaluation space.Key job responsibilitiesIn this role you will:\u00b7 Use predictive analytics and <b>machine</b> <b>learning</b> techniques to solve complex problems and drive business decisions\u00b7 Develop new <b>algorithms</b> to discover patterns of risks, abuse and help reduce overall levels of safety incidents in our driver pool\u00b7 Work closely with internal stakeholders such as business teams, engineering teams ...", "dateLastCrawled": "2022-01-08T12:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "AI <b>auditing and impact assessment: according</b> to the UK information ...", "url": "https://link.springer.com/article/10.1007/s43681-021-00039-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s43681-021-00039-2", "snippet": "The <b>two</b> principal audiences are: (i) those with a compliance focus like Data Protection Officers (DPOs), general counsel, risk managers and the ICO&#39;s own auditors; and (ii) technology specialists, such as <b>machine</b> <b>learning</b> developers and data scientists, software developers/engineers, and cybersecurity and IT risk managers. Risks are stated in terms of impact on rights and freedoms and measures are thereby offered to mitigate risks that AI systems may present within this value framework. Non ...", "dateLastCrawled": "2022-01-31T15:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Artificial Intelligence and <b>Machine</b> <b>Learning</b> in Business Management ...", "url": "https://ebin.pub/artificial-intelligence-and-machine-learning-in-business-management-concepts-challenges-and-case-studies-1nbsped-0367645556-9780367645557.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/artificial-intelligence-and-<b>machine</b>-<b>learning</b>-in-business-management...", "snippet": "<b>Machine</b> <b>Learning</b> has its roots in numerous fields, of which Statistics and <b>Machine</b> <b>Learning</b> are the <b>two</b> most important. Statistics had its origins in Mathematics, so, focus was laid upon Mathematical rigour, a need to show that something makes sense on theoretical grounds, before bringing it into practice. The <b>Machine</b> <b>Learning</b> culture, on the other hand, is very much rooted in computer experience. This has resulted in a mindset that is practical, a desire to try something without asking for ...", "dateLastCrawled": "2022-01-29T11:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Quizzes Flashcards | <b>Quizlet</b> - <b>Learning</b> tools &amp; flashcards, for free", "url": "https://quizlet.com/423155597/quizzes-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/423155597/quizzes-flash-cards", "snippet": "Innovation and <b>learning</b> Internal business process improvement Financials. Financials All four measurement categories on the balanced scorecard (financial, customer, business process, and innovation and <b>learning</b>) should be taken into account and balanced against one another, but all measures must ultimately contribute to the bottom line. For a product or service, six sigma means that: the average opportunity for a defect is a target plus/minus three sigmas. the average opportunity for a ...", "dateLastCrawled": "2022-01-14T08:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Etiq.ai Debiasing Solutions - How <b>fairness</b> <b>metrics</b> <b>can</b> be misleading", "url": "https://etiq.ai/research/how-fairness-metrics-can-be-misleading/", "isFamilyFriendly": true, "displayUrl": "https://etiq.ai/research/how-<b>fairness</b>-<b>metrics</b>-<b>can</b>-be-misleading", "snippet": "<b>Fairness</b> <b>metrics</b>. <b>Machine</b> <b>learning</b> <b>algorithms</b> are widely used to construct prediction models that inform decision-making processes. For example, a bank may use a model to predict the likelihood of someone paying back a loan based upon certain individual characteristics. This likelihood estimate <b>can</b> then help the bank to decide who to approve for a loan. However, it is well-known that <b>machine</b> <b>learning</b> models <b>can</b> exhibit prejudice towards specific types of people due to, for instance, their ...", "dateLastCrawled": "2022-01-04T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) How do the Existing <b>Fairness</b> <b>Metrics</b> and Unfairness Mitigation ...", "url": "https://www.researchgate.net/publication/356914252_How_do_the_Existing_Fairness_Metrics_and_Unfairness_Mitigation_Algorithms_contribute_to_Ethical_Learning_Analytics", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/356914252_How_do_the_Existing_<b>Fairness</b>...", "snippet": "some unfairness mitigation <b>algorithms</b> had relatively less fairer r esults w.rt. to some <b>fairness</b> <b>metrics</b> <b>compared</b> to the baseline. Hu and R angwala (2020) also made similar \ufb01ndings.", "dateLastCrawled": "2021-12-20T23:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "CONFAIR: Configurable and Interpretable Algorithmic <b>Fairness</b> | DeepAI", "url": "https://deepai.org/publication/confair-configurable-and-interpretable-algorithmic-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/confair-configurable-and-interpretable-algorithmic-<b>fairness</b>", "snippet": "The different definitions of statistical <b>fairness</b> lead to the evaluation of an algorithm\u2019s performance in fundamentally different ways. For instance, the disparate impact measures the ratio of true positive rates across groups while equal opportunity measures the difference between the true positive rates and false positive rates across groups with the restriction that they are less than a specified threshold. It has been shown that the different <b>fairness</b> <b>metrics</b> are often incompatible ...", "dateLastCrawled": "2022-01-22T16:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fairness in Machine Learning: A Survey</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-a-survey</b>", "snippet": "As <b>Machine</b> <b>Learning</b> technologies become increasingly used in contexts that affect citizens, companies as well as researchers need to be confident that their application of these methods will not have unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote <b>fairness</b>, yet the area is complex and hard to penetrate for newcomers to the domain.", "dateLastCrawled": "2022-01-18T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine learning fairness notions: Bridging the</b> gap with real-world ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "snippet": "<b>Fairness</b> in <b>machine</b> <b>learning</b> <b>can</b> be categorized according <b>to two</b> dimensions, namely, the task and the type of <b>learning</b>. For the first dimension, there are <b>two</b> tasks in <b>fairness</b>-aware <b>machine</b> <b>learning</b>: discrimination discovery (or assessment) and discrimination removal (or prevention). Discrimination discovery task focuses on assessing and measuring bias in datasets or in predictions made by the MLDM. Discrimination removal focuses on preventing discrimination by manipulating datasets (pre ...", "dateLastCrawled": "2022-02-03T07:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Introduction to The Special Section on Bias and <b>Fairness</b> in AI", "url": "https://kdd.org/exploration_files/1_specialsectionBIAS_1.pdf", "isFamilyFriendly": true, "displayUrl": "https://kdd.org/exploration_files/1_specialsectionBIAS_1.pdf", "snippet": "of the frontiers <b>of fairness</b> in <b>machine</b> <b>learning</b> research <b>can</b> be found in [4]. Much of the research on <b>fairness</b> in <b>machine</b> <b>learning</b> <b>can</b> be framed in an optimization context [5], where the goal is to maintain good predictive performance while satisfying a number of group-level or individual <b>fairness</b> constraints. This combination <b>can</b> be achieved via modeling and remov-ing representation bias and/or labeling bias in the train-ing data, via <b>fairness</b>-aware representation <b>learning</b> [6; 7], model ...", "dateLastCrawled": "2022-01-17T12:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Survey on Bias and <b>Fairness</b> in <b>Machine</b> <b>Learning</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1908.09635/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1908.09635", "snippet": "With the widespread use of AI systems and applications in our everyday lives, it is important to take <b>fairness</b> issues into consideration while designing and engineering these types of systems. Such systems <b>can</b> be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in <b>machine</b> <b>learning</b>, natural language ...", "dateLastCrawled": "2021-11-15T17:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "When <b>machine learning</b> meets congestion control: A survey and comparison ...", "url": "https://www.sciencedirect.com/science/article/pii/S1389128621001407", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1389128621001407", "snippet": "<b>Compared</b> to supervised <b>learning</b> and unsupervised <b>learning</b> techniques, RL <b>algorithms</b> are more responsive to environmental changes. Instead of predicting congestion loss and delay as with supervised and unsupervised <b>learning</b>-based CC <b>algorithms</b>, RL-based CC <b>algorithms</b> learn the CC rules directly based on different environment information. Since RL <b>algorithms</b> <b>can</b> incorporate real-time network conditions and define actions accordingly, real-time control is possible in RL <b>algorithms</b>.", "dateLastCrawled": "2021-11-10T05:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Mirror Mirror", "url": "https://shiraamitchell.github.io/fairness/", "isFamilyFriendly": true, "displayUrl": "https://shiraamitchell.github.io/<b>fairness</b>", "snippet": "In <b>machine</b> <b>learning</b> and statistics, a ... Pointedly, the existence of many plausible <b>metrics</b> <b>of fairness</b> allows us to pose explicitly the question of whether organizations are deliberately only publishing those <b>metrics</b> which reflect favorably on them, or whether they are suppressing any inquiry whatsoever to avoid a paper trail. In this article we have not taken a particularly adversarial analysis of the <b>fairness</b> landscape, but we encourage the reader to think through the way each definition ...", "dateLastCrawled": "2022-01-06T19:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Tuning EU equality law <b>to algorithmic discrimination: Three pathways to</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/1023263X20982173", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/1023263X20982173", "snippet": "A further <b>incompatibility</b> pertains to the causal nature of the link between discrimination and given protected categories <b>compared</b> to the reliance of <b>machine</b> <b>learning</b> <b>algorithms</b> on statistical inferences and correlations. Finally, the exhaustive list of protected grounds featured in EU non-discrimination law poses a further compatibility issue in light of the dynamic nature of algorithmic classifications and the risk that new patterns of discrimination emerge. The grammar of EU non ...", "dateLastCrawled": "2022-01-29T21:37:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) How do the Existing <b>Fairness</b> <b>Metrics</b> and Unfairness Mitigation ...", "url": "https://www.researchgate.net/publication/356914252_How_do_the_Existing_Fairness_Metrics_and_Unfairness_Mitigation_Algorithms_contribute_to_Ethical_Learning_Analytics", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/356914252_How_do_the_Existing_<b>Fairness</b>...", "snippet": "<b>of fairness</b> <b>metrics</b> Narayanan ... Kearns, and R oth (2018) demonstrated the <b>incompatibility</b> between six. <b>fairness</b> measures and the impossibility to simultaneously maximize accuracy and <b>fairness</b> ...", "dateLastCrawled": "2021-12-20T23:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Fairness in Machine Learning: Lessons from Political Philosophy</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-lessons-from-political-philosophy", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-lessons-from-political</b>...", "snippet": "This discussion suggests that \u2018<b>fairness</b>\u2019 as used in the fair <b>machine</b> <b>learning</b> community is best understood as a placeholder term for a variety of normative egalitarian considerations. Notably, while egalitarianism is a widely held principle, exactly what it requires is the subject of much debate. I provide an overview of some of this debate and finish with implications for the incorporation <b>of \u2018fairness</b>\u2019 into algorithmic decision-making systems.", "dateLastCrawled": "2021-12-26T22:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Survey on Bias and <b>Fairness</b> in <b>Machine</b> <b>Learning</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1908.09635/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1908.09635", "snippet": "With the widespread use of AI systems and applications in our everyday lives, it is important to take <b>fairness</b> issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in <b>machine</b> <b>learning</b>, natural language ...", "dateLastCrawled": "2021-11-15T17:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "50 Years of Test (Un)<b>fairness</b>: Lessons for <b>Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/329207000_50_Years_of_Test_Unfairness_Lessons_for_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/329207000_50_Years_of_Test_Un<b>fairness</b>_Lessons...", "snippet": "Though bias, <b>fairness</b>, and ethics have recently become hot topics in affective computing and multimodal <b>machine</b> <b>learning</b>, there is a long history of research on enhancing the <b>fairness</b> and reducing ...", "dateLastCrawled": "2022-01-11T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Measurement and <b>Fairness</b> | DeepAI", "url": "https://deepai.org/publication/measurement-and-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/measurement-and-<b>fairness</b>", "snippet": "Measurement and <b>Fairness</b>. We introduce the language of measurement modeling from the quantitative social sciences as a framework for understanding <b>fairness</b> in computational systems. Computational systems often involve unobservable theoretical constructs, such as &quot;creditworthiness,&quot; &quot;teacher quality,&quot; or &quot;risk to society,&quot; that cannot be ...", "dateLastCrawled": "2021-11-29T01:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Democratizing Algorithmic Fairness</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s13347-019-00355-w", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00355-w", "snippet": "<b>Metrics</b> details. Abstract. <b>Machine</b> <b>learning</b> algorithms can now identify patterns and correlations in (big) datasets and predict outcomes based on the identified patterns and correlations. They can then generate decisions in accordance with the outcomes predicted, and decision-making processes can thereby be automated. Algorithms can inherit questionable values from datasets and acquire biases in the course of (<b>machine</b>) <b>learning</b>. While researchers and developers have taken the problem of ...", "dateLastCrawled": "2022-02-03T18:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Poster session 5</b> \u2013 Aies Conference", "url": "https://www.aies-conference.com/2021/schedule/poster-session-5/", "isFamilyFriendly": true, "displayUrl": "https://www.aies-conference.com/2021/schedule/<b>poster-session-5</b>", "snippet": "Much of the previous work on unfairness in <b>machine</b> <b>learning</b> has focused on the <b>fairness</b> of outcomes rather than process. We propose a feature selection method inspired by fair process (procedural <b>fairness</b>) in addition to fair outcome. Specifically, we introduce the notion of unfairness weight, which indicates how heavily to weight unfairness versus accuracy when measuring the marginal benefit of adding a new feature to a model. Our goal is to maintain accuracy while reducing unfairness, as ...", "dateLastCrawled": "2021-12-07T20:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Practical <b>Fairness</b>: Achieving Fair and Secure Data Models [1&amp;nbsp;ed ...", "url": "https://ebin.pub/practical-fairness-achieving-fair-and-secure-data-models-1nbsped-1492075736-9781492075738.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/practical-<b>fairness</b>-achieving-fair-and-secure-data-models-1nbsped...", "snippet": "<b>Fairness</b> in <b>machine</b> <b>learning</b> and in the technology sector remains an active struggle, an ongoing social concern, and an interesting engineering problem. We need legal, economic, and social solutions as well as technical ones. Toward that end, 50% of the royalties earned on this book will be donated to the American Civil Liberties Union, an organization that has relentlessly pursued <b>fairness</b> for a hundred years. The ACLU is actively working to secure fundamental rights to privacy and <b>fairness</b> ...", "dateLastCrawled": "2021-12-11T12:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Tuning EU equality law <b>to algorithmic discrimination: Three pathways to</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/1023263X20982173", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/1023263X20982173", "snippet": "A further <b>incompatibility</b> pertains to the causal nature of the link between discrimination and given protected categories compared to the reliance of <b>machine</b> <b>learning</b> algorithms on statistical inferences and correlations. Finally, the exhaustive list of protected grounds featured in EU non-discrimination law poses a further compatibility issue in light of the dynamic nature of algorithmic classifications and the risk that new patterns of discrimination emerge. The grammar of EU non ...", "dateLastCrawled": "2022-01-29T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Nuit Blanche: CS: Low-<b>Dimensional Models for Dimensionality Reduction</b> ...", "url": "https://nuit-blanche.blogspot.com/2009/11/cs-low-dimensional-models-for.html", "isFamilyFriendly": true, "displayUrl": "https://nuit-blanche.blogspot.com/2009/11/cs-low-dimensional-models-for.html", "snippet": "We address the denoising of images contaminated with multiplicative noise, e.g. speckle noise. Classical ways to solve such problems are filtering, statistical (Bayesian) methods, variational methods, and methods that convert the multiplicative noise into additive noise (using a logarithmic function), apply a variational method on the log data or shrink their coefficients in a frame (e.g. a wavelet basis), and transform back the result using an exponential function.", "dateLastCrawled": "2022-01-24T11:15:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(incompatibility of fairness metrics)  is like +(two machine learning algorithms)", "+(incompatibility of fairness metrics) is similar to +(two machine learning algorithms)", "+(incompatibility of fairness metrics) can be thought of as +(two machine learning algorithms)", "+(incompatibility of fairness metrics) can be compared to +(two machine learning algorithms)", "machine learning +(incompatibility of fairness metrics AND analogy)", "machine learning +(\"incompatibility of fairness metrics is like\")", "machine learning +(\"incompatibility of fairness metrics is similar\")", "machine learning +(\"just as incompatibility of fairness metrics\")", "machine learning +(\"incompatibility of fairness metrics can be thought of as\")", "machine learning +(\"incompatibility of fairness metrics can be compared to\")"]}