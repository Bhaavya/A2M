{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Cooperative Swarm based Evolutionary Approach to find optimal cluster ...", "url": "http://ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "isFamilyFriendly": true, "displayUrl": "ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "snippet": "<b>Centroid-based</b> <b>clustering</b> is a NP-hard optimization problem, and thus the common approach is to search for cluster centers only for approximate solutions. Well-known <b>centroid-based</b> <b>clustering</b> methods are k-means, k-medoids and fuzzy c-means. In this paper we proposed swarm intelligence based nature-inspired center-based <b>clustering</b> method using PSO optimization. PSO searches the optimized solution from available solutions in multidimensional search space. So PSO is capable to search best ...", "dateLastCrawled": "2021-09-15T23:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning Automata Clustering</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "snippet": "<b>Centroid-based</b> <b>clustering</b> where each cluster is represented using a cluster center which may not belong to the data points. K-means, K ... Artificial <b>fish</b> swarm algorithm is another evolutionary algorithm derived from the movement of herd <b>of fish</b>. In , the initial solutions for the artificial <b>fish</b> swarm algorithm are initialized using K-means algorithm and then the algorithm carries out the <b>clustering</b> task. In order to achieve the <b>clustering</b> goal, a new fitness function is used which ...", "dateLastCrawled": "2021-12-04T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) A Hybrid Sequential Approach for Data <b>Clustering</b> Using K-Means ...", "url": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_Clustering_Using_K_Means_and_Particle_Swarm_Optimization_Algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_<b>Clustering</b>...", "snippet": "However, if good initial <b>clustering</b> centroids can be obtained using any of the other techniques, the K-Means would work well in refining the <b>clustering</b> centroids to find the optimal <b>clustering</b> centers. The same idea is proposed in this paper to determine initial points for K-Means algorithm by some other global optimization search algorithms. Evolutionary and bio-inspired algorithms eradicate some of the above mentioned difficulties and are quickly replacing the classical methods in solving ...", "dateLastCrawled": "2022-01-18T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Kao and Cheng (2006) designed a <b>centroid-based</b> ACO <b>clustering</b> algorithm, where ants assign each data instance to one of the available clusters and cluster centroids are adjusted based on this ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A New Soft Computing Method for <b>K-Harmonic Means Clustering</b>", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "snippet": "The <b>K-harmonic means clustering</b> algorithm (KHM) is a new <b>clustering</b> method used to group data such that the sum of the harmonic averages of the distances between each entity and all cluster centroids is minimized. Because it is less sensitive to initialization than K-means (KM), many researchers have recently been attracted to studying KHM. In this study, the proposed iSSO-KHM is based on an improved simplified swarm optimization (iSSO) and integrates a variable neighborhood search (VNS) for ...", "dateLastCrawled": "2021-02-15T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>lec27 - Lecture 27 The Story of the Ne2lix Prize Lester</b> ... - Course Hero", "url": "https://www.coursehero.com/file/14936346/lec27/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/14936346/lec27", "snippet": "<b>Clustering</b> with Missing Data \u2022 <b>Centroid-based</b> <b>clustering</b> \u2013 Represent user by incomplete raJngs vector, \u2013 Represent cluster by centroid vector, \u2022 Typically, is average of user vectors in cluster \u2013 Minimize (esJmated) distance between users and their cluster centers \u2022 Result: r u = (1, 5,?,?, 3,?, 4) c k c k r u k-0.3% improvement over Cinematch. Matching Cinematch \u2022 Incorporate prior informaJon \u2013 PosiJve raJngs {3,4,5} vs. negaJve raJngs {1,2} \u2022 EsJmate and combine ...", "dateLastCrawled": "2021-12-08T17:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Differences Between Classification and Clustering</b> | Baeldung on ...", "url": "https://www.baeldung.com/cs/ml-classification-vs-clustering", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/cs/ml-classification-vs-<b>clustering</b>", "snippet": "Ironically, it\u2019s frequently used for features <b>like</b> texts that certainly have a strong linear dependence. ... Another <b>centroid-based</b> algorithm is the mean shift, which works by iteratively attempting to identify cluster centroids that are placed as close as possible to the ideal mean of the points in a region. This takes place by first placing the centroids randomly, and then updating their position so that they shift towards the mean: The algorithm identifies as clusters all observations ...", "dateLastCrawled": "2022-01-21T10:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "K Means <b>Clustering</b> Tutorial - Effective Learning Is Here", "url": "https://onlinecoursesfee.com/k-means-clustering-tutorial", "isFamilyFriendly": true, "displayUrl": "https://onlinecoursesfee.com/k-means-<b>clustering</b>-tutorial", "snippet": "Big Data Analytics - K-Means <b>Clustering</b> (Verified 18 hours ago) k-means <b>clustering</b> aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells. Given a set of observations (x1, x2, \u2026, xn), where each observation is a d-dimensional real ...", "dateLastCrawled": "2022-01-03T11:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "testing k means <b>clustering</b>", "url": "https://sukin.com/ulsyn/testing-k-means-clustering.html", "isFamilyFriendly": true, "displayUrl": "https://sukin.com/ulsyn/testing-k-means-<b>clustering</b>.html", "snippet": "K Means algorithm is a <b>centroid-based</b> <b>clustering</b> (unsupervised) technique. K-Means is a very popular <b>clustering</b> technique. The number of centroids represents the number of output classes. The most common <b>clustering</b> covered in machine learning for beginners is K-Means. Two points are assigned as centroids. <b>Clustering</b> outliers. We repeat the process for a given number of iterations and at the end, we have our clusters. Objective The objective of this hands on is to let you reason about the ...", "dateLastCrawled": "2022-01-27T09:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Centroid-Based</b> Particle Swarm Optimization Variant for Data ...", "url": "https://www.researchgate.net/publication/330937798_Centroid-Based_Particle_Swarm_Optimization_Variant_for_Data_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330937798_<b>Centroid-Based</b>_Particle_Swarm...", "snippet": "Request PDF | <b>Centroid-Based</b> Particle Swarm Optimization Variant for Data Classification | Recently, data mining has become more attractive for researchers as a technique to analyze and transform ...", "dateLastCrawled": "2022-02-03T08:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Cooperative Swarm based Evolutionary Approach to find optimal cluster ...", "url": "http://ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "isFamilyFriendly": true, "displayUrl": "ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "snippet": "<b>Centroid-based</b> <b>clustering</b> is a NP-hard optimization problem, and thus the common approach is to search for cluster centers only for approximate solutions. Well-known <b>centroid-based</b> <b>clustering</b> methods are k-means, k-medoids and fuzzy c-means. In this paper we proposed swarm intelligence based nature-inspired center-based <b>clustering</b> method using PSO optimization. PSO searches the optimized solution from available solutions in multidimensional search space. So PSO is capable to search best ...", "dateLastCrawled": "2021-09-15T23:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Meal Pattern Analysis</b> in Nutritional Science: Recent Methods and ...", "url": "https://academic.oup.com/advances/article-abstract/12/4/1365/6103933", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/advances/article-abstract/12/4/1365/6103933", "snippet": "Finally, K-means <b>clustering</b> is a <b>similar</b> approach to PAM, with the <b>centroid (based</b> on the mean of the variables in the cluster) being used in place of the medoid to minimize variation within clusters. Both approaches are limited to identifying clusters that can be separated by a straight line. One of the decisions required when <b>clustering</b> is choosing the number of clusters to represent the data. Different approaches were taken in the studies reviewed here. Chau et al. selected 5 clusters to ...", "dateLastCrawled": "2022-01-21T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Kao and Cheng (2006) designed a <b>centroid-based</b> ACO <b>clustering</b> algorithm, where ants assign each data instance to one of the available clusters and cluster centroids are adjusted based on this ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Differences Between Classification and Clustering</b> | Baeldung on ...", "url": "https://www.baeldung.com/cs/ml-classification-vs-clustering", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/cs/ml-classification-vs-<b>clustering</b>", "snippet": "Another <b>centroid-based</b> algorithm is the mean shift, which works by iteratively attempting to identify cluster centroids that are placed as close as possible to the ideal mean of the points in a region. This takes place by first placing the centroids randomly, and then updating their position so that they shift towards the mean: The algorithm identifies as clusters all observations that comprise a region of smooth density around the centroids. Those observations that lie outside of all ...", "dateLastCrawled": "2022-01-21T10:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A New Soft Computing Method for <b>K-Harmonic Means Clustering</b>", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "snippet": "The former builds a hierarchy tree of data that successively merges <b>similar</b> clusters, ... The most popular class of partition <b>clustering</b> is the <b>centroid-based</b> <b>clustering</b> algorithm. Among all <b>clustering</b> methods, with an extensive history dating back to 1972, K-means (KM) is one of the most well-known center-based partition <b>clustering</b> techniques [4\u201317]. KM is implemented by first randomly selecting K initial centroids and then trying to minimize heuristically the sum of the squares of ...", "dateLastCrawled": "2021-02-15T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning Automata Clustering</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "snippet": "Comparing the proposed algorithm with four <b>centroid based</b> <b>clustering</b> algorithms, the proposed algorithm achieves a decent accuracy and comparable Silhouette coefficient on 14 real world datasets. Abstract . <b>Clustering</b> of data points has been a profound research avenue in the history of machine learning algorithms. Using learning automata which are autonomous decision making entities, in this paper, the <b>learning automata clustering</b> algorithm is proposed. In <b>learning automata clustering</b>, each ...", "dateLastCrawled": "2021-12-04T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>lec27 - Lecture 27 The Story of the Ne2lix Prize Lester</b> ... - Course Hero", "url": "https://www.coursehero.com/file/14936346/lec27/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/14936346/lec27", "snippet": "<b>Clustering</b> with Missing Data \u2022 <b>Centroid-based</b> <b>clustering</b> \u2013 Represent user by incomplete raJngs vector, \u2013 Represent cluster by centroid vector, \u2022 Typically, is average of user vectors in cluster \u2013 Minimize (esJmated) distance between users and their cluster centers \u2022 Result: r u = (1, 5,?,?, 3,?, 4) c k c k r u k-0.3% improvement over Cinematch. Matching Cinematch \u2022 Incorporate prior informaJon \u2013 PosiJve raJngs {3,4,5} vs. negaJve raJngs {1,2} \u2022 EsJmate and combine ...", "dateLastCrawled": "2021-12-08T17:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Lecture-09-<b>clustering</b>-Nov5.pptx - Machine Learning a Unsupervised ...", "url": "https://www.coursehero.com/file/121899136/Lecture-09-clustering-Nov5pptx/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/121899136/Lecture-09-<b>clustering</b>-Nov5pptx", "snippet": "<b>Clustering</b>: the process of grouping a set of objects into classes of <b>similar</b> objects, ... Recursive application of a standard <b>clustering</b> algorithm can produce a hierarchical <b>clustering</b>. animal vertebrate <b>fish</b> reptile amphib. mammal worm insect crustacean invertebrate. 7 Agglomerative vs. Divisive <b>Clustering</b> Agglomerative (bottom-up) methods start with each example in its own cluster and iteratively combine them to form larger and larger clusters. Divisive (partitional, top-down) separate all ...", "dateLastCrawled": "2021-12-27T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Data <b>Clustering</b> A Review", "url": "https://mail.goldenspikeharley.com/data-clustering-a-review-pdf", "isFamilyFriendly": true, "displayUrl": "https://mail.goldenspikeharley.com/data-<b>clustering</b>-a-review-pdf", "snippet": "<b>Clustering</b> is the task of partitioning the dataset into groups called clusters. The goal is to split up the data in such a way that points within single cluster are very <b>similar</b> and points in different clusters are different. k-Shape: Ef?cient and Accurate <b>Clustering</b> of Time Series Examples of unsupervised learning include <b>clustering</b> and data reduction strategies such as PCA. <b>Clustering</b> methods discover structures in data using a given measure of similarity amongst data instances in order to ...", "dateLastCrawled": "2021-12-18T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "testing k means <b>clustering</b>", "url": "https://sukin.com/ulsyn/testing-k-means-clustering.html", "isFamilyFriendly": true, "displayUrl": "https://sukin.com/ulsyn/testing-k-means-<b>clustering</b>.html", "snippet": "K Means algorithm is a <b>centroid-based</b> <b>clustering</b> (unsupervised) technique. K-Means is a very popular <b>clustering</b> technique. The number of centroids represents the number of output classes. The most common <b>clustering</b> covered in machine learning for beginners is K-Means. Two points are assigned as centroids. <b>Clustering</b> outliers. We repeat the process for a given number of iterations and at the end, we have our clusters. Objective The objective of this hands on is to let you reason about the ...", "dateLastCrawled": "2022-01-27T09:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Kao and Cheng (2006) designed a <b>centroid-based</b> ACO <b>clustering</b> algorithm, where ants assign each data instance to one of the available clusters and cluster centroids are adjusted based on this ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Using cluster edge counting to aggregate iterations of centroid-linkage ...", "url": "https://europepmc.org/article/MED/31453226", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/31453226", "snippet": "<b>School</b> of Earth and Space Exploration, Arizona State University, Tempe, AZ 85287-6004 USA. ... capacity beyond what is typically <b>thought</b> of for a standard computer. By eliminating the need for a distance matrix, the number of sequences that the centroid-linkage algorithm is able to process is only limited by the size of the file that <b>can</b> be read into memory (&gt; 1000000 for our 120 GB RAM computer). Importantly, these results do become input-order dependent. By avoiding distance matrices and ...", "dateLastCrawled": "2021-12-18T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) A Hybrid Sequential Approach for Data <b>Clustering</b> Using K-Means ...", "url": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_Clustering_Using_K_Means_and_Particle_Swarm_Optimization_Algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_<b>Clustering</b>...", "snippet": "However, if good initial <b>clustering</b> centroids <b>can</b> be obtained using any of the other techniques, the K-Means would work well in refining the <b>clustering</b> centroids to find the optimal <b>clustering</b> centers. The same idea is proposed in this paper to determine initial points for K-Means algorithm by some other global optimization search algorithms. Evolutionary and bio-inspired algorithms eradicate some of the above mentioned difficulties and are quickly replacing the classical methods in solving ...", "dateLastCrawled": "2022-01-18T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Efficient <b>Clustering</b> of Emails Into Spam and Ham: The ...", "url": "https://www.researchgate.net/publication/343709430_Efficient_Clustering_of_Emails_Into_Spam_and_Ham_The_Foundational_Study_of_a_Comprehensive_Unsupervised_Framework", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343709430_Efficient_<b>Clustering</b>_of_Emails_Into...", "snippet": "ferred over <b>centroid-based</b> <b>clustering</b> as in K-means. Density. based <b>clustering</b> is an unsupervised learning technique that . recognises distinctive clusters in the data, on the assumption. that a ...", "dateLastCrawled": "2022-01-28T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Differential Threshold of Breakfast, Caffeine and Food Groups May Be ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8288514/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8288514", "snippet": "Using chi-square analysis, the significant variables in Cluster 1 for men included breakfast, <b>fish</b> and supplements use pattern (vitamins and <b>fish</b> oil), which represent a healthy dietary practice. Cluster 2 encompassed a spectrum of nutrient-dense food groups, which represents a healthy dietary pattern. Cluster 3 consists of fast-food, which represents an unhealthy dietary pattern. As for women, Cluster 1 comprised fast-food and meat, which represent an unhealthy dietary pattern. Cluster 2 ...", "dateLastCrawled": "2021-11-16T19:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "3D mapping and accelerated super-resolution imaging of the human genome ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7537785/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7537785", "snippet": "DBSCAN <b>clustering</b> algorithm was used to identify the clusters from the raw image. 50 particles within a 0.1 \u03bcm distance was used for <b>clustering</b>. The mean axial precision was 50 +/\u2212 10 nm in Z and mean radial precision was 17+\\- 5 nm in XY. The resolution of the super-resolved structures were calculated by Fourier ring correlation analysis (a built-up feature in SRX software). Resolution in XY was 40 +/\u22125 nm and resolution in Z was 60 +/\u22125 nm.", "dateLastCrawled": "2021-12-15T10:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Using Dendritic Heat Maps to Simultaneously Display Genotype Divergence ...", "url": "https://europepmc.org/article/PMC/PMC4990276", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC4990276", "snippet": "Since the USEARCH command \u201c-cluster_fast\u201d performs <b>centroid-based</b> <b>clustering</b> in the order of the input FASTA file, input sequences were first multiple aligned using Clustal Omega (described later) and arranged to ensure that the most distantly related and potentially cluster splitting \u201ccentroid\u201d sequences were listed first in a staggered order (conceptualized in Fig 1). This ordering process was performed by a script that reads from opposite ends of the multiple alignment and is ...", "dateLastCrawled": "2021-09-12T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "MS153 - jbmethods.org", "url": "https://jbmethods.org/jbm/article/download/153/160?inline=1", "isFamilyFriendly": true, "displayUrl": "https://jbmethods.org/jbm/article/download/153/160?inline=1", "snippet": "<b>School</b> of Earth and Space Exploration, Arizona State University, Tempe, AZ 85287-6004 USA *Corresponding author: Matthew Kellom, Email: matthewkellom@gmail.com. Competing interests: The authors have declared that no competing interests exist. Abbreviations used: GB: gigabyte; KS, Kolmogorov-Smirnov; RAM, random-access memory. Received August 19, 2016; Revision received January 20, 2017; Accepted January 22, 2017; Published March 16, 2017. Abstract. Sequence <b>clustering</b> is a fundamental tool ...", "dateLastCrawled": "2021-11-20T03:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "JPM | Free Full-Text | Customization of Diet May Promote Exercise and ...", "url": "https://www.mdpi.com/2075-4426/11/5/435/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2075-4426/11/5/435/htm", "snippet": "The K-means <b>clustering</b> algorithm used iteration to partition the dataset into a pre-specified number of k distinct clusters. Each training instance was allocated to the closest <b>centroid based</b> on the Euclidean distance applied to the instance and cluster center. All centroids were then recalculated as the mean attribute value vectors of the ...", "dateLastCrawled": "2022-02-03T03:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>Machine Learning</b> Tutorial with Examples | Toptal", "url": "https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer", "isFamilyFriendly": true, "displayUrl": "https://www.toptal.com/<b>machine-learning</b>/<b>machine-learning</b>-theory-an-introductory-primer", "snippet": "We <b>can</b> then tweak h(x) ... However, for something to chew on in the meantime, take a look at <b>clustering</b> algorithms such as k-means, and also look into dimensionality reduction systems such as principle component analysis. Our prior post on big data discusses a number of these topics in more detail as well. Conclusion. We\u2019ve covered much of the basic theory underlying the field of <b>Machine Learning</b> here, but of course, we have only barely scratched the surface. Keep in mind that to really ...", "dateLastCrawled": "2022-02-02T23:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Medoid-based <b>clustering</b> methods are helpful\u2014<b>compared</b> to classical <b>centroid-based</b> techniques\u2014when centroids cannot be easily defined. This paper proposes two medoid-based ACO <b>clustering</b> ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Centroid-Based</b> Particle Swarm Optimization Variant for Data ...", "url": "https://www.researchgate.net/publication/330937798_Centroid-Based_Particle_Swarm_Optimization_Variant_for_Data_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330937798_<b>Centroid-Based</b>_Particle_Swarm...", "snippet": "Request PDF | <b>Centroid-Based</b> Particle Swarm Optimization Variant for Data Classification | Recently, data mining has become more attractive for researchers as a technique to analyze and transform ...", "dateLastCrawled": "2022-02-03T08:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Fuzzy C-Means <b>Clustering</b> and Particle Swarm Optimization based scheme ...", "url": "https://link.springer.com/article/10.1007/s10489-017-0917-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10489-017-0917-0", "snippet": "The cluster center is different for random allocation, <b>centroid-based</b> FCM and PSO-based FCM schemes. ... However, when the intra-cluster distances are <b>compared</b> with each other, it <b>can</b> be observed from Table 8 that the FCM-PSO scheme has got more cumulative distance than other schemes. In case distance was the only criteria, this would have been a not so good result to be analyzed. But when demand from villages is considered, the ability of PSO to adjust the CSC location at appropriate ...", "dateLastCrawled": "2021-11-20T22:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) A Hybrid Sequential Approach for Data <b>Clustering</b> Using K-Means ...", "url": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_Clustering_Using_K_Means_and_Particle_Swarm_Optimization_Algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_<b>Clustering</b>...", "snippet": "However, if good initial <b>clustering</b> centroids <b>can</b> be obtained using any of the other techniques, the K-Means would work well in refining the <b>clustering</b> centroids to find the optimal <b>clustering</b> centers. The same idea is proposed in this paper to determine initial points for K-Means algorithm by some other global optimization search algorithms. Evolutionary and bio-inspired algorithms eradicate some of the above mentioned difficulties and are quickly replacing the classical methods in solving ...", "dateLastCrawled": "2022-01-18T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A New Soft Computing Method for <b>K-Harmonic Means Clustering</b>", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "snippet": "The <b>K-harmonic means clustering</b> algorithm (KHM) is a new <b>clustering</b> method used to group data such that the sum of the harmonic averages of the distances between each entity and all cluster centroids is minimized. Because it is less sensitive to initialization than K-means (KM), many researchers have recently been attracted to studying KHM. In this study, the proposed iSSO-KHM is based on an improved simplified swarm optimization (iSSO) and integrates a variable neighborhood search (VNS) for ...", "dateLastCrawled": "2021-02-15T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Density-based particle swarm optimization algorithm for data clustering</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417417305912", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417417305912", "snippet": "<b>Clustering</b> algorithms <b>can</b> be classified broadly into different categories, namely, partitional, hierarchical, and density-based algorithms. Each category has its own working mechanism, capability to deal with certain types of data, advantages, and drawbacks Saraswathi &amp; Sheela, 2014). One of the most widely used partitional <b>clustering</b> algorithms is the K-means (Hartigan &amp; Wong, 1979), a <b>centroid-based</b> <b>clustering</b> technique, where objects in a cluster are centered around its nearest ...", "dateLastCrawled": "2021-12-14T01:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning Automata Clustering</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "snippet": "It <b>can</b> be divided into two approaches: Agglomerative <b>clustering</b> which puts each data point in a cluster and merges the clusters on the way up to the tip of hierarchy, and divisive <b>clustering</b> which starts with one cluster for the entire dataset and splits it recursively in the way down the hierarchy. Generally, the result of a hierarchical <b>clustering</b> algorithm is a dendogram showing the configuration of clusters.", "dateLastCrawled": "2021-12-04T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Meal Pattern Analysis</b> in Nutritional Science: Recent Methods and ...", "url": "https://academic.oup.com/advances/article-abstract/12/4/1365/6103933", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/advances/article-abstract/12/4/1365/6103933", "snippet": "<b>Clustering</b> <b>can</b> identify groups of individuals who eat meals at similar times over the course of a day and in a similar context Chau et al. ; Khanna et al. ; Riou et al. Latent class analysis Groups of observations are identified that have similar probabilities of belonging to the same categories in the variables of interest Study participants <b>can</b> be grouped based on having high probabilities for eating during the same time periods of the day or consuming the same combinations of meals over a ...", "dateLastCrawled": "2022-01-21T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Image quantization using improved artificial <b>fish</b> swarm algorithm ...", "url": "https://link.springer.com/article/10.1007/s00500-014-1436-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00500-014-1436-0", "snippet": "Fuzzy C-means algorithm. Fast and robust <b>clustering</b> algorithms play an important role in extracting useful information in large databases. The aim of cluster analysis is to partition a set of N object into C clusters such that objects within cluster should be similar to each other and objects in different clusters should be dissimilar with each other (Yang 1993).One of the most widely used algorithms is fuzzy <b>clustering</b> algorithms which depend on Fuzzy set theory (Zadeh 1973, 2005).Fuzzy ...", "dateLastCrawled": "2021-12-10T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>regional structure of</b> spawning phenology and the potential consequences ...", "url": "https://academic.oup.com/icesjms/article/74/3/613/2734755", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/icesjms/article/74/3/613/2734755", "snippet": "Although coral larvae have low swimming capabilities in comparison to <b>fish</b> larvae (Leichter et al., 2013), ... and polyp <b>clustering</b> (Mizrahi et al., 2014) <b>can</b> increase the dispersal potential of corals. In the ETP, little is known about coral dispersal due to the difficulty in collecting empirical information in the field. For the major reef builders as Pocilloporids or P. lobata, there are no records of direct spawning observations either in the field or in controlled settings. Therefore ...", "dateLastCrawled": "2022-01-19T09:20:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~bgibson/cs540/handouts/learning_intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~bgibson/cs540/handouts/<b>learning</b>_intro.pdf", "snippet": "human <b>learning</b> (e.g., Computer-Aided Instruction (CAI)) \u2022Discover new things or structures that are unknown to humans (\u201cdata mining\u201d) \u2022Fill in skeletal or incomplete specifications about a domain Major Paradigms of <b>Machine</b> <b>Learning</b> \u2022Rote <b>Learning</b> \u2022Induction \u2022<b>Clustering</b> \u2022<b>Analogy</b> \u2022Discovery \u2022Genetic Algorithms \u2022Reinforcement", "dateLastCrawled": "2021-08-25T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Unsupervised Learning</b> and Data <b>Clustering</b> | by Sanatan Mishra | Towards ...", "url": "https://towardsdatascience.com/unsupervised-learning-and-data-clustering-eeecb78b422a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>unsupervised-learning</b>-and-data-<b>clustering</b>-eeecb78b422a", "snippet": "<b>Unsupervised Learning</b> and Data <b>Clustering</b>. Sanatan Mishra. May 19, 2017 \u00b7 15 min read. A task involving <b>machine</b> <b>learning</b> may not be linear, but it has a number of well known steps: Problem definition. Preparation of Data. Learn an underlying model. Improve the underlying model by quantitative and qualitative evaluations. Present the model. One good way to come to terms with a new problem is to work through identifying and defining the problem in the best possible way and learn a model that ...", "dateLastCrawled": "2022-02-02T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Density-Based <b>Clustering</b>", "url": "https://blog.dominodatalab.com/topology-and-density-based-clustering", "isFamilyFriendly": true, "displayUrl": "https://blog.dominodatalab.com/topology-and-density-based-<b>clustering</b>", "snippet": "Compared to <b>centroid-based</b> <b>clustering</b> like k-means, density-based <b>clustering</b> works by identifying \u201cdense\u201d clusters of points, allowing it to learn clusters of arbitrary shape and identify outliers in the data. In particular, I will: Discuss the highly popular DBSCAN algorithm. Use the denpro R package.", "dateLastCrawled": "2022-02-02T08:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Artificial Neural Networks - unit 3", "url": "https://www.slideshare.net/PVidyasri/artificial-neural-networks-unit-3", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/PVidyasri/artificial-neural-networks-unit-3", "snippet": "<b>Clustering</b>: \u2022 <b>Clustering</b> is a method of grouping the objects into clusters such that objects with most similarities remains into a group and has less or no similarities with the objects of another group. \u2022 Cluster analysis finds the commonalities between the data objects and categorizes them as per the presence and absence of those commonalities. \u2022 Below are some popular <b>Clustering</b> algorithms which come under unsupervised <b>learning</b>: \u2022 <b>Centroid-based</b> <b>Clustering</b> \u2022 Density-based ...", "dateLastCrawled": "2022-01-29T21:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "MaxMin <b>clustering</b> for <b>historical analogy</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s42452-020-03202-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42452-020-03202-2", "snippet": "In natural language processing and <b>machine</b> <b>learning</b> studies, <b>clustering</b> algorithms are widely used; therefore, several types of <b>clustering</b> algorithms have been developed. The key purpose of a <b>clustering</b> algorithm is to identify similarities between data and to cluster them into groups 1, 19]. As several surveys presenting a broad overview of <b>clustering</b> have been published, e.g., [17, 59, 60], this study compares previously proposed partitioning-, hierarchy-, distribution- and graph-based ...", "dateLastCrawled": "2021-12-27T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Deep <b>Clustering</b> with a Dynamic Autoencoder - deepai.org", "url": "https://deepai.org/publication/deep-clustering-with-a-dynamic-autoencoder", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/deep-<b>clustering</b>-with-a-dynamic-autoencoder", "snippet": "4 Experiments. 4.1 Datasets. We compare DynAE with five of the state-of-the-art autoencoder-based deep <b>clustering</b> algorithms on four image datasets: MNIST-full ( 30), MNIST-test, USPS ( 41) and Fashion-MNIST ( 42). MNIST-full ( 30): a dataset that consists of 70000, 28\u00d728 grayscale images of handwritten digits.", "dateLastCrawled": "2021-12-29T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Tour of the <b>Most Popular Machine Learning Algorithms</b> | by Athreya ...", "url": "https://towardsdatascience.com/a-tour-of-the-most-popular-machine-learning-algorithms-b57d50c2eb51", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tour-of-the-<b>most-popular-machine-learning-algorithms</b>...", "snippet": "In <b>machine</b> <b>learning</b>, it is tradition to categorize algorithms by their <b>learning</b> style. In general, <b>learning</b> style is just a fancy way of saying what data you have readily available to train your algorithm. Let\u2019s look at some! 1. Supervised <b>Learning</b>. In supervised <b>learning</b>, input data is called training data and has a known label/result. An example of an input could be a picture of an animal and a label could be the name of it (i.e. elephant, cat, etc.). Another example can be emails as ...", "dateLastCrawled": "2022-01-29T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Determination of miscible CO2 flooding analogue projects with <b>machine</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0920410521014455", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0920410521014455", "snippet": "We use <b>machine</b> <b>learning</b> <b>clustering</b> methods to group successfully executed miscible CO 2 flooding projects into clusters of projects with similar fluid/reservoir characteristics and to identify analogues for new target projects. Porosity, permeability, oil gravity and viscosity, reservoir pressure and temperature, minimum miscibility pressure (MMP), and depth were all input parameters. Data from nearly 200 miscible CO 2 EOR projects around the world were clustered using the Agglomerative ...", "dateLastCrawled": "2022-01-24T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How <b>Machine Learning</b> enhances <b>Personalization</b> at scale? | Opensense Labs", "url": "https://opensenselabs.com/blog/articles/machine-learning-enhances-personalization", "isFamilyFriendly": true, "displayUrl": "https://opensenselabs.com/blog/articles/<b>machine-learning</b>-enhances-<b>personalization</b>", "snippet": "If you want to learn about the miracles of the technological marvel of the 21st century, then this article is no less than a treat for you. In today\u2019s era, digital marketing may sound like a messy environment filled with constant change and complex systems. With the buzzword like <b>Machine Learning</b> (ML) that has penetrated into various aspects of our everyday life, human inputs are reduced to minimal. In other words, more freedom falls in the lap of a <b>machine</b> wherein the <b>machine</b> acts on its ...", "dateLastCrawled": "2022-01-17T11:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What are some use <b>cases of clustering in machine learning? - Quora</b>", "url": "https://www.quora.com/What-are-some-use-cases-of-clustering-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-some-use-<b>cases-of-clustering-in-machine-learning</b>", "snippet": "Answer (1 of 2): You are given the following types of objects (in four separate images) and you are asked to group them. What would you do? The most obvious way is to group all fruits together, and all the cars in another group (or cluster) based on the criteria that objects in one group are edi...", "dateLastCrawled": "2022-01-04T22:08:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(centroid-based clustering)  is like +(a school of fish)", "+(centroid-based clustering) is similar to +(a school of fish)", "+(centroid-based clustering) can be thought of as +(a school of fish)", "+(centroid-based clustering) can be compared to +(a school of fish)", "machine learning +(centroid-based clustering AND analogy)", "machine learning +(\"centroid-based clustering is like\")", "machine learning +(\"centroid-based clustering is similar\")", "machine learning +(\"just as centroid-based clustering\")", "machine learning +(\"centroid-based clustering can be thought of as\")", "machine learning +(\"centroid-based clustering can be compared to\")"]}