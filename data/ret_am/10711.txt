{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse</b> Matrix and its representations | Set 1 (Using Arrays and Linked ...", "url": "https://www.geeksforgeeks.org/sparse-matrix-representation/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>sparse</b>-matrix-<b>representation</b>", "snippet": "A matrix is a two-dimensional <b>data</b> object made of m rows and n columns, therefore having total m x ... So, instead of <b>storing</b> zeroes with non-zero elements, we only store non-zero elements. This means <b>storing</b> non-zero elements with triples- (Row, Column, value). <b>Sparse</b> Matrix Representations can be done in many ways following are two common representations: Array <b>representation</b>; Linked list <b>representation</b>. Method 1: Using Arrays: 2D array is used to represent a <b>sparse</b> matrix in which there ...", "dateLastCrawled": "2022-01-31T00:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Sparse Matrix Storage Formats</b> - GormAnalysis", "url": "https://www.gormanalysis.com/blog/sparse-matrix-storage-formats/", "isFamilyFriendly": true, "displayUrl": "https://www.gormanalysis.com/blog/<b>sparse-matrix-storage-formats</b>", "snippet": "In practice, such a matrix can have millions of rows and columns, and <b>storing</b> every single element of that matrix is expensive.<b>Compressed</b> matrix formats take advantage of the fact that <b>sparse</b> matrices are comprised mostly of 0s, and so they only store the non-zero entries. In this post, we\u2019ll look at common techniques for <b>storing</b> <b>sparse</b> matrices <b>in a compressed</b> <b>format</b>.", "dateLastCrawled": "2022-02-01T18:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Sparse</b> <b>data</b> structures \u2014 pandas 1.4.0 documentation", "url": "https://pandas.pydata.org/docs/user_guide/sparse.html", "isFamilyFriendly": true, "displayUrl": "https://pandas.py<b>data</b>.org/docs/user_guide/<b>sparse</b>.html", "snippet": "<b>Sparse</b> <b>data</b> structures. \u00b6. pandas provides <b>data</b> structures for efficiently <b>storing</b> <b>sparse</b> <b>data</b>. These are not necessarily <b>sparse</b> in the typical \u201cmostly 0\u201d. Rather, you can view these objects as being \u201c<b>compressed</b>\u201d where any <b>data</b> matching a specific value ( NaN / missing value, though any value can be chosen, including 0) is omitted.", "dateLastCrawled": "2022-02-03T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Sparse Matrix Representations | Set 3 ( CSR ) - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/sparse-matrix-representations-set-3-csr/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>sparse-matrix-representations-set-3</b>-csr", "snippet": "Stack <b>Data</b> Structure (Introduction and Program) Given an array A[] and a number x, check for pair in A[] with sum as x (aka Two Sum) ... we will discuss another <b>representation</b> of the <b>Sparse</b> Matrix which is commonly referred as the Yale <b>Format</b>. The CSR (<b>Compressed</b> <b>Sparse</b> Row) or the Yale <b>Format</b> is similar to the Array <b>Representation</b> (discussed in Set 1) of <b>Sparse</b> Matrix. We represent a matrix M (m * n), by three 1-D arrays or vectors called as A, IA, JA. Let NNZ denote the number of non-zero ...", "dateLastCrawled": "2022-02-03T07:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Understanding compressed matrices for sparse</b> <b>data</b> \u2013 Datastronomy", "url": "https://datastronomy.com/understanding-sparse-matrices-for-recommender-systems/", "isFamilyFriendly": true, "displayUrl": "https://<b>data</b>stronomy.com/understanding-<b>sparse</b>-matrices-for-recommender-systems", "snippet": "The distinct terms \u201c<b>compressed</b>\u201d and \u201c<b>sparse</b>\u201d are often used interchangeably. \u201c<b>Sparse</b>\u201d refers to the nature of inputs and indicates that only an arbitrarily-sized minority of the <b>data</b> is known. \u201c<b>Compressed</b>\u201d matrices are stored in a <b>format</b> that requires preprocessing to be usable, and that ideally uses less memory than an ...", "dateLastCrawled": "2022-01-21T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>An Alternative Compressed Storage Format for</b> <b>Sparse</b> Matrices | Request PDF", "url": "https://www.researchgate.net/publication/221579407_An_Alternative_Compressed_Storage_Format_for_Sparse_Matrices", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221579407_An_Alternative_<b>Compressed</b>_Storage...", "snippet": "<b>Sparse</b> matrix storage formats such as <b>Compressed</b> <b>Sparse</b> Row (CSR) and Diagonal <b>format</b> (DIA) are not the most effective for such matrices. In this work, we present a new <b>sparse</b> matrix storage ...", "dateLastCrawled": "2022-01-18T10:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is a <b>CSR (compressed sparse rows) matrix? - Quora</b>", "url": "https://www.quora.com/What-is-a-CSR-compressed-sparse-rows-matrix", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-a-<b>CSR-compressed-sparse-rows-matrix</b>", "snippet": "Answer (1 of 2): If most of the elements in the matrix are zero then the matrix is called a <b>sparse</b> matrix. It is wasteful to store the zero elements in the matrix since they do not affect the results of our computation. This is why we implement these matrices in more efficient representations tha...", "dateLastCrawled": "2022-01-25T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "In-memory <b>Data</b> Compression for <b>Sparse</b> Matrices", "url": "https://www.cs.uaf.edu/~olawlor/papers/2013/compression/lawlor_compression_2013.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.uaf.edu/~olawlor/papers/2013/compression/lawlor_compression_2013.pdf", "snippet": "32-bit column indices per row is the common <b>Compressed</b> <b>Sparse</b> Row (CSR) <b>format</b>. In this paper, we propose further shrinking these to a variable bit per column <b>format</b> called <b>Compressed</b> Col-umn Indices (CCI). 1.1 <b>Sparse</b> Matrix Dense Vector Multiply A typical desktop-scale scienti\ufb01c problem today might have on the order of n = 106 unknowns, and involve the solution of a linear algebra problem <b>like</b> AX = B, where X and B are vectors and A is a matrix. The vectors are of dimension n and hence ...", "dateLastCrawled": "2022-01-31T16:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Compressed</b> <b>Sparse</b> Row <b>Format</b> Answer | Solution Guide", "url": "https://www.edusolutionguide.com/compressed-sparse-row-format-answer/", "isFamilyFriendly": true, "displayUrl": "https://www.edusolutionguide.com/<b>compressed</b>-<b>sparse</b>-row-<b>format</b>-answer", "snippet": "The inputs are three Python lists corresponding to a <b>sparse</b> matrix in COO <b>format</b>, <b>like</b> the example illustrated above. Your function should return a triple, (csr_ptrs, csr_inds, csr_vals), corresponding to the same matrix but stored in CSR <b>format</b>, again, <b>like</b> what is shown above, where csr_ptrs would be the row pointers (rowptr), csr_inds would be the column indices (colind), and csr_vals would be the values (values). To help you out, we show how to calculate csr_inds and csr_vals. You need ...", "dateLastCrawled": "2022-01-31T05:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What to Do When Your <b>Data</b> Is Too Big for Your Memory? | by Sara A ...", "url": "https://towardsdatascience.com/what-to-do-when-your-data-is-too-big-for-your-memory-65c84c600585", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/what-to-do-when-your-<b>data</b>-is-too-big-for-your-memory-65...", "snippet": "Compression here doesn\u2019t mean putting the <b>data</b> in a ZIP file; it instead means <b>storing</b> the <b>data</b> in the memory <b>in a compressed</b> <b>format</b>. In other words, compressing the <b>data</b> is finding a way to represent the <b>data</b> in a different way that will use less memory. There are two types of <b>data</b> compression: lossless compression and lossy one. Both these types only affect the loading of your <b>data</b> and won\u2019t cause any changes in the processing section of your code. Lossless compression. Lossless ...", "dateLastCrawled": "2022-02-02T13:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse</b> <b>data</b> structures \u2014 pandas 1.4.0 documentation", "url": "https://pandas.pydata.org/docs/user_guide/sparse.html", "isFamilyFriendly": true, "displayUrl": "https://pandas.py<b>data</b>.org/docs/user_guide/<b>sparse</b>.html", "snippet": "<b>Sparse</b> <b>data</b> structures. \u00b6. pandas provides <b>data</b> structures for efficiently <b>storing</b> <b>sparse</b> <b>data</b>. These are not necessarily <b>sparse</b> in the typical \u201cmostly 0\u201d. Rather, you can view these objects as being \u201c<b>compressed</b>\u201d where any <b>data</b> matching a specific value ( NaN / missing value, though any value can be chosen, including 0) is omitted.", "dateLastCrawled": "2022-02-03T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Sparse Matrix Representations | Set 3 ( CSR ) - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/sparse-matrix-representations-set-3-csr/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>sparse-matrix-representations-set-3</b>-csr", "snippet": "Stack <b>Data</b> Structure (Introduction and Program) Given an array A[] and a number x, check for pair in A[] with sum as x (aka Two Sum) ... we will discuss another <b>representation</b> of the <b>Sparse</b> Matrix which is commonly referred as the Yale <b>Format</b>. The CSR (<b>Compressed</b> <b>Sparse</b> Row) or the Yale <b>Format</b> <b>is similar</b> to the Array <b>Representation</b> (discussed in Set 1) of <b>Sparse</b> Matrix. We represent a matrix M (m * n), by three 1-D arrays or vectors called as A, IA, JA. Let NNZ denote the number of non-zero ...", "dateLastCrawled": "2022-02-03T07:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Packed Compressed Sparse Row: A Dynamic Graph Representation</b>", "url": "http://supertech.csail.mit.edu/papers/WheatmanXu18.pdf", "isFamilyFriendly": true, "displayUrl": "supertech.csail.mit.edu/papers/WheatmanXu18.pdf", "snippet": "<b>format</b> is <b>Compressed</b> <b>Sparse</b> Row (CSR). CSR excels at <b>storing</b> graphs compactly with minimal overhead, allowing for fast traver- sals, lookups, and basic graph computations such as PageRank. Since elements in CSR <b>format</b> are packed together, additions and deletions often require time linear in the size of the graph. We introduce a new dynamic <b>sparse</b> graph <b>representation</b> called Packed <b>Compressed</b> <b>Sparse</b> Row (PCSR), based on an array-based dynamic <b>data</b> structure called the Packed Memory Array ...", "dateLastCrawled": "2022-01-16T13:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Packed <b>Compressed Sparse Row</b>: A Dynamic Graph <b>Representation</b> | IEEE ...", "url": "https://ieeexplore.ieee.org/document/8547566", "isFamilyFriendly": true, "displayUrl": "https://ieeexplore.ieee.org/document/8547566", "snippet": "Perhaps the most popular <b>sparse</b> graph storage <b>format</b> is <b>Compressed Sparse Row</b> (CSR). CSR excels at <b>storing</b> graphs compactly with minimal overhead, allowing for fast traversals, lookups, and basic graph computations such as PageRank. Since elements in CSR <b>format</b> are packed together, additions and deletions often require time linear in the size of the graph. We introduce a new dynamic <b>sparse</b> graph <b>representation</b> called Packed <b>Compressed Sparse Row</b> (PCSR), based on an array-based dynamic <b>data</b> ...", "dateLastCrawled": "2022-01-30T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Compressed</b> <b>Sparse</b> Row (CSR) <b>representation</b>. Every graph can be ...", "url": "https://www.researchgate.net/figure/Compressed-Sparse-Row-CSR-representation-Every-graph-can-be-represented-as-an_fig3_324640550", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/<b>Compressed</b>-<b>Sparse</b>-Row-CSR-<b>representation</b>-Every...", "snippet": "<b>Compressed</b> <b>Sparse</b> Row (CSR) <b>representation</b>. Every graph can be represented as an adjacency matrix, which can be encoded using the CSR <b>representation</b>.", "dateLastCrawled": "2022-01-30T22:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Packed Compressed Sparse Row: A Dynamic Graph Representation</b> - IEEE ...", "url": "https://ieeexplore.ieee.org/abstract/document/8547566", "isFamilyFriendly": true, "displayUrl": "https://ieeexplore.ieee.org/abstract/document/8547566", "snippet": "CSR excels at <b>storing</b> graphs compactly with minimal overhead, allowing for fast traversals, lookups, and basic graph computations such as PageRank. Since elements in CSR <b>format</b> are packed together, additions and deletions often require time linear in the size of the graph. We introduce a new dynamic <b>sparse</b> graph <b>representation</b> called Packed <b>Compressed</b> <b>Sparse</b> Row (PCSR), based on an array-based dynamic <b>data</b> structure called the Packed Memory Array. PCSR <b>is similar</b> to CSR, but leaves spaces ...", "dateLastCrawled": "2020-11-20T23:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A competitive scheme for <b>storing</b> <b>sparse</b> <b>representation</b> of X-Ray medical ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201455", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201455", "snippet": "A competitive scheme for economic storage of the informational content of an X-Ray image, as it can be used for further processing, is presented. It is demonstrated that <b>sparse</b> <b>representation</b> of that type of <b>data</b> can be encapsulated in a small file without affecting the quality of the recovered image. The proposed <b>representation</b>, which is inscribed within the context of <b>data</b> reduction, provides a <b>format</b> for saving the image information in a way that could assist methodologies for analysis ...", "dateLastCrawled": "2021-09-15T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "In-memory <b>Data</b> Compression for <b>Sparse</b> Matrices", "url": "https://www.cs.uaf.edu/~olawlor/papers/2013/compression/lawlor_compression_2013.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.uaf.edu/~olawlor/papers/2013/compression/lawlor_compression_2013.pdf", "snippet": "32-bit column indices per row is the common <b>Compressed</b> <b>Sparse</b> Row (CSR) <b>format</b>. In this paper, we propose further shrinking these to a variable bit per column <b>format</b> called <b>Compressed</b> Col-umn Indices (CCI). 1.1 <b>Sparse</b> Matrix Dense Vector Multiply A typical desktop-scale scienti\ufb01c problem today might have on the order of n = 106 unknowns, and involve the solution of a linear algebra problem like AX = B, where X and B are vectors and A is a matrix. The vectors are of dimension n and hence ...", "dateLastCrawled": "2022-01-31T16:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is a <b>CSR (compressed sparse rows) matrix? - Quora</b>", "url": "https://www.quora.com/What-is-a-CSR-compressed-sparse-rows-matrix", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-a-<b>CSR-compressed-sparse-rows-matrix</b>", "snippet": "Answer (1 of 2): If most of the elements in the matrix are zero then the matrix is called a <b>sparse</b> matrix. It is wasteful to store the zero elements in the matrix since they do not affect the results of our computation. This is why we implement these matrices in more efficient representations tha...", "dateLastCrawled": "2022-01-25T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "c++ - Efficient (time and space complexity) <b>data</b> structure for dense ...", "url": "https://stackoverflow.com/questions/34591861/efficient-time-and-space-complexity-data-structure-for-dense-and-sparse-matrix", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34591861", "snippet": "In case of very <b>sparse</b> <b>data</b>, you could scan through the <b>data</b> once and keep a list of the empty regions/blocks in memory (only need to store startpos and size), which you could then skip (and adjust where needed) in further runs. With memory mapping, only frequently accessed pages are kept in memory. This means that once you have scanned for the empty regions, memory will only be allocated for the frequently accessed non-empty regions (all this will be done automagically by the kernel - no ...", "dateLastCrawled": "2022-01-10T07:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse</b> Matrix and its representations | Set 1 (Using Arrays and Linked ...", "url": "https://www.geeksforgeeks.org/sparse-matrix-representation/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>sparse</b>-matrix-<b>representation</b>", "snippet": "A matrix is a two-dimensional <b>data</b> object made of m rows and n columns, therefore having total m x n values. If most of the elements of the matrix have 0 value, then it is called a <b>sparse</b> matrix.. Why to use <b>Sparse</b> Matrix instead of simple matrix ? Storage: There are lesser non-zero elements than zeros and thus lesser memory <b>can</b> be used to store only those elements. Computing time: Computing time <b>can</b> be saved by logically designing a <b>data</b> structure traversing only non-zero elements.. Example ...", "dateLastCrawled": "2022-01-31T00:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Understanding compressed matrices for sparse</b> <b>data</b> \u2013 Datastronomy", "url": "https://datastronomy.com/understanding-sparse-matrices-for-recommender-systems/", "isFamilyFriendly": true, "displayUrl": "https://<b>data</b>stronomy.com/understanding-<b>sparse</b>-matrices-for-recommender-systems", "snippet": "Another key difference is that lossily <b>compressed</b> <b>data</b> <b>can</b> often be used directly without any preprocessing, while losslessly <b>compressed</b> <b>data</b> must be unpacked before it <b>can</b> be used. The former should be apparent if you are familiar with dimensionality reduction techniques, while the latter will become clear as you read the remainder of this article. Formats. There are many ways to compress matrices, but you only need to know a handful of them. The main formats are COOrdinate (COO) <b>format</b> ...", "dateLastCrawled": "2022-01-21T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Three storage formats for <b>sparse</b> matrices on GPGPUs | Salvatore ...", "url": "https://www.academia.edu/67723552/Three_storage_formats_for_sparse_matrices_on_GPGPUs", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/67723552/Three_storage_<b>formats</b>_for_<b>sparse</b>_matrices_on_GPGPUs", "snippet": "2.2 <b>Compressed</b> <b>Sparse</b> Rows The CSR <b>format</b> is perhaps the most popular <b>sparse</b> matrix <b>representation</b>. It explicitly stores column indices and nonzero values in two arrays JA and AS and uses a third array of row pointers IRP, to mark the boundaries of each row. The name is based on the fact that the row index information is <b>compressed</b> with respect to the COO <b>format</b>, after having sorted the coefficients in row-major order. Figure 3 illustrates the CSR <b>representation</b> of the example matrix shown ...", "dateLastCrawled": "2022-01-27T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) An Efficient Storage <b>Format</b> for <b>Storing</b> Configuration Interaction ...", "url": "https://www.researchgate.net/publication/321210185_An_Efficient_Storage_Format_for_Storing_Configuration_Interaction_Sparse_Matrices_on_CPUGPU", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321210185_An_Efficient_Storage_<b>Format</b>_for...", "snippet": "An Efficient Storage <b>Format</b> for <b>Storing</b> Configuration Interaction <b>Sparse</b> Matrices on CPU/GPU. December 2017. DOI: 10.1109/CSCI.2017.340. Conference: 2017 International Conference on Computational ...", "dateLastCrawled": "2021-08-17T20:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Assignment 4: Sorting in Linear Time solved - codeshive.com", "url": "https://codeshive.com/product/assignment-4-sorting-in-linear-time-solved/", "isFamilyFriendly": true, "displayUrl": "https://codeshive.com/product/assignment-4-sorting-in-linear-time-solved", "snippet": "using a special <b>data</b> structure, instead of <b>storing</b> it as a 2-dimensional array. One common <b>data</b> structure is known as the <b>compressed</b> <b>sparse</b>-row (CSR) <b>representation</b>. In CSR <b>representation</b>, matrix A is stored using three arrays: R, C, and V . These arrays are respectively of length m + 1, k, and k. The array C stores the column indices of the non-zeros, such that for each 0 \u2264 i \u2264 m \u2212 1, the subarray C[R[i]..R[i + 1] \u2212 1] stores the column indices of the ith row of A, in increasing ...", "dateLastCrawled": "2022-01-23T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Sparse Matrix</b> Program in C - C Programming Notes", "url": "http://www.cprogrammingnotes.com/question/sparse-matrix.html", "isFamilyFriendly": true, "displayUrl": "www.cprogrammingnotes.com/question/<b>sparse-matrix</b>.html", "snippet": "A <b>sparse matrix</b> has many zero elements. For example, the following 4x4 matrix is a <b>sparse Matrix</b>. Conventional method of <b>representation</b> of such a matrix is not space efficient. It will be prudent to store non-zero elements only. If this is done, then the matrix may <b>be thought</b> of as an ordered list of non-zero elements. Information about non ...", "dateLastCrawled": "2022-01-31T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Sparse Matrix Computation</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/sparse-matrix-computation", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>sparse-matrix-computation</b>", "snippet": "<b>Compressed</b> <b>Sparse</b> Row (CSR) <b>format</b> is probably the most widely used <b>format</b> for <b>storing</b> general <b>sparse</b> matrices [3, 4]. In this <b>format</b>, the input matrix is represented by the following components: CsrVal , which contains nonzero values; ColIdx , which holds the column index of nonzero elements; CsrPtr , which shows the first nonzero element in each row.", "dateLastCrawled": "2022-01-24T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "US8484023B2 - <b>Sparse representation features</b> for speech recognition ...", "url": "https://patents.google.com/patent/US8484023B2/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US8484023B2/en", "snippet": "Techniques are disclosed for generating and using <b>sparse representation features</b> to improve speech recognition performance. In particular, principles of the invention provide <b>sparse</b> <b>representation</b> exemplar-based recognition techniques. For example, a method comprises the following steps. A test vector and a training <b>data</b> set associated with a speech recognition system are obtained. A subset of the training <b>data</b> set is selected. The test vector is mapped with the selected subset of the ...", "dateLastCrawled": "2021-12-19T02:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "When and why do we use <b>sparse</b> coding? - <b>Cross Validated</b>", "url": "https://stats.stackexchange.com/questions/300199/when-and-why-do-we-use-sparse-coding", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/300199/when-and-why-do-we-use-<b>sparse</b>-coding", "snippet": "It <b>can</b> be seen that the first instance, where most of the attributes are nonzero, becomes longer in the <b>sparse</b> <b>representation</b>. The second instance, however, has mostly zeros as attributes and is represented more efficiently. If most of your dataset is like the second instance - if the dataset is a <b>sparse</b> matrix - then a <b>sparse</b> file <b>format</b> might ...", "dateLastCrawled": "2022-01-21T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "c++ - Efficient (time and space complexity) <b>data</b> structure for dense ...", "url": "https://stackoverflow.com/questions/34591861/efficient-time-and-space-complexity-data-structure-for-dense-and-sparse-matrix", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34591861", "snippet": "This way you don&#39;t need to allocate extra memory and read in all the <b>data</b>, and the <b>data</b> <b>can</b> simply and efficiently be accessed with M[i][j]. Going over the rows would be L1-cache friendly. In case of very <b>sparse</b> <b>data</b>, you could scan through the <b>data</b> once and keep a list of the empty regions/blocks in memory (only need to store startpos and size), which you could then skip (and adjust where needed) in further runs.", "dateLastCrawled": "2022-01-10T07:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse</b> Matrix and its representations | Set 1 (Using Arrays and Linked ...", "url": "https://www.geeksforgeeks.org/sparse-matrix-representation/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>sparse</b>-matrix-<b>representation</b>", "snippet": "A matrix is a two-dimensional <b>data</b> object made of m rows and n columns, therefore having total m x n values. If most of the elements of the matrix have 0 value, then it is called a <b>sparse</b> matrix.. Why to use <b>Sparse</b> Matrix instead of simple matrix ? Storage: There are lesser non-zero elements than zeros and thus lesser memory <b>can</b> be used to store only those elements. Computing time: Computing time <b>can</b> be saved by logically designing a <b>data</b> structure traversing only non-zero elements.. Example ...", "dateLastCrawled": "2022-01-31T00:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Comparative Study of <b>Sparse</b> Matrix Storage <b>Format</b> in the Finite Element ...", "url": "https://www.sci-en-tech.com/ICCM2014/PDFs/501-790-1-PB.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.sci-en-tech.com/ICCM2014/PDFs/501-790-1-PB.pdf", "snippet": "variety of <b>compressed</b> <b>sparse</b> row (CSR) <b>format</b> is used to store and manipulate the <b>sparse</b> matrix for the thermal problem [Mukaddes (2014)]. The matrix in the structural problems has inherent block shape. In order to reduce the memory requirement, exploiting the block shape of the matrix could be a beneficial choice. In this research, a diagonal block <b>compressed</b> <b>sparse</b> row (DBCSR) <b>format</b> for the structural problem are proposed and <b>compared</b> with other formats. Here instead of entire rows or ...", "dateLastCrawled": "2021-11-19T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A competitive scheme for <b>storing</b> <b>sparse</b> <b>representation</b> of X-Ray medical ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201455", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201455", "snippet": "A competitive scheme for economic storage of the informational content of an X-Ray image, as it <b>can</b> be used for further processing, is presented. It is demonstrated that <b>sparse</b> <b>representation</b> of that type of <b>data</b> <b>can</b> be encapsulated in a small file without affecting the quality of the recovered image. The proposed <b>representation</b>, which is inscribed within the context of <b>data</b> reduction, provides a <b>format</b> for saving the image information in a way that could assist methodologies for analysis ...", "dateLastCrawled": "2021-09-15T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "An Efficient Mixed-Mode <b>Representation</b> of <b>Sparse</b> Tensors", "url": "https://dl.acm.org/doi/epdf/10.1145/3295500.3356216", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/epdf/10.1145/3295500.3356216", "snippet": "The <b>Compressed</b> <b>Sparse</b> Fiber (CSF) <b>representation</b> for <b>sparse</b> ten-sors is a generalization of the <b>Compressed</b> <b>Sparse</b> Row (CSR) <b>format</b> for <b>sparse</b> matrices. For a tensor with d modes, typical tensor meth-ods such as CANDECOMP/PARAFAC decomposition (CPD) require a sequence of d tensor computations, where efficient memory ac-cess with respect to different modes is required for each of them. The straightforward solution is to use d distinct representations of the tensor, with each one being ...", "dateLastCrawled": "2022-01-15T09:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "python - Construct <b>Sparse</b> Matrix in Matlab from <b>Compressed</b> <b>Sparse</b> ...", "url": "https://stackoverflow.com/questions/43021896/construct-sparse-matrix-in-matlab-from-compressed-sparse-column-csc-format", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/43021896", "snippet": "Construct <b>Sparse</b> Matrix in Matlab from <b>Compressed</b> <b>Sparse</b> Column (CSC) <b>format</b>. Ask Question Asked 4 years, 9 months ago. Active 1 year, 5 months ago. Viewed 194 times 0 I have a large <b>sparse</b> matrix (~5 billion non-zero values) in Python, stored in the csc_matrix <b>format</b>. I need to open it as a <b>sparse</b> matrix in Matlab. savemat apparently cannot save <b>data</b> of this size (seems to be capped at ~5GB), so I am resorting to saving it as an hdf5 file, as detailed here. However, I am having trouble ...", "dateLastCrawled": "2022-01-12T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>An Alternative Compressed Storage Format for</b> <b>Sparse</b> Matrices | Request PDF", "url": "https://www.researchgate.net/publication/221579407_An_Alternative_Compressed_Storage_Format_for_Sparse_Matrices", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221579407_An_Alternative_<b>Compressed</b>_Storage...", "snippet": "However, as is the case for text documents, the matrix is likely to be <b>sparse</b>. Therefore, we <b>can</b> eliminate the words that never occur in the <b>data</b>, and/or store the matrix <b>in a compressed</b> <b>format</b> ...", "dateLastCrawled": "2022-01-18T10:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "In-memory <b>Data</b> Compression for <b>Sparse</b> Matrices", "url": "https://www.cs.uaf.edu/~olawlor/papers/2013/compression/lawlor_compression_2013.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.uaf.edu/~olawlor/papers/2013/compression/lawlor_compression_2013.pdf", "snippet": "32-bit column indices per row is the common <b>Compressed</b> <b>Sparse</b> Row (CSR) <b>format</b>. In this paper, we propose further shrinking these to a variable bit per column <b>format</b> called <b>Compressed</b> Col-umn Indices (CCI). 1.1 <b>Sparse</b> Matrix Dense Vector Multiply A typical desktop-scale scienti\ufb01c problem today might have on the order of n = 106 unknowns, and involve the solution of a linear algebra problem like AX = B, where X and B are vectors and A is a matrix. The vectors are of dimension n and hence ...", "dateLastCrawled": "2022-01-31T16:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[Solved] <b>Compressed</b> <b>Sparse</b> Row <b>Format</b> This <b>format</b> tries to compress the ...", "url": "https://www.coursehero.com/tutors-problems/Python-Programming/34431145-Compressed-Sparse-Row-Format-This-format-tries-to-compress-the/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/tutors-problems/Python-Programming/34431145-<b>Compressed</b>...", "snippet": "<b>Compressed</b> <b>Sparse</b> Row <b>Format</b> . This <b>format</b> tries to compress the <b>sparse</b> matrix further <b>compared</b> to COO <b>format</b>. Suppose you have the following coordinate <b>representation</b> of a <b>sparse</b> matrix where you sort by row index:", "dateLastCrawled": "2022-01-15T14:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Compressed</b> <b>Sparse</b> Row <b>Format</b> Answer | Solution Guide", "url": "https://www.edusolutionguide.com/compressed-sparse-row-format-answer/", "isFamilyFriendly": true, "displayUrl": "https://www.edusolutionguide.com/<b>compressed</b>-<b>sparse</b>-row-<b>format</b>-answer", "snippet": "You <b>can</b> also purchase as below at a lower price. Please click on the \u201cPURCHASE\u201d link below to get \u201c<b>Compressed</b> <b>Sparse</b> Row <b>Format</b> Answer\u201d. The below link is for the purchase of \u2018ePowerX Genesis Pass\u2019 which will help you to get the tutorial for the above educational material.", "dateLastCrawled": "2022-01-31T05:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Sparse</b> Non-Linear Least Squares in C/C++", "url": "https://users.ics.forth.gr/~lourakis/sparseLM/", "isFamilyFriendly": true, "displayUrl": "https://users.ics.forth.gr/~lourakis/<b>sparse</b>LM", "snippet": "It accepts <b>sparse</b> Jacobians encoded in either <b>compressed</b> row storage or <b>compressed</b> column storage (a.k.a. Harwell-Boeing) <b>format</b>, allowing user applications to choose the <b>representation</b> that is most natural to them. It also offers the possibility of numerically approximating the Jacobian using forward finite differences on <b>data</b> provided by successive invocations of the function to be minimized. In this case, only the sparsity pattern of the Jacobian should be specified by the user and not ...", "dateLastCrawled": "2022-01-29T18:58:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Neural Networks: Analogies. When our brains form analogies, they\u2026 | by ...", "url": "https://towardsdatascience.com/neural-networks-analogies-7ebeb3ac5d5e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-networks-analogies-7ebeb3ac5d5e", "snippet": "I\u2019ll outline a potential route to artificial neural networks which exhibit transfer <b>learning</b>: First, <b>Sparse</b> Distributed Representations. Numenta\u2019s Hierarchical Te m poral Memory, along with other techniques, relies upon a <b>sparse</b> distributed <b>representation</b>. An example of this is a very long string of ones and zeroes, where almost all the values are zero \u2014 there is a <b>sparse</b> distribution of the ones. If each digit represented a different thing, like \u2018pointy ears\u2019, \u2018tail ...", "dateLastCrawled": "2022-01-28T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Conceptualization as a Basis for Cognition \u2014 Human and <b>Machine</b> | by ...", "url": "https://towardsdatascience.com/conceptualization-as-a-basis-for-cognition-human-and-machine-345d9e687e3c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/conceptualization-as-a-basis-for-cognition-human-and...", "snippet": "Abstraction and <b>analogy</b> allow concepts to be re-applied in new domains. There are many, often conflicting, ... <b>Machine</b>-<b>learning</b> systems must learn to conceptualize to reach the goal of creating machines with higher intelligence. To substantiate this claim, let\u2019s first examine what generalization in artificial intelligence means specifically in the context of artificial intelligence/<b>machine</b> <b>learning</b> (as opposed to the layman\u2019s use of the term), and then explore how that differs from ...", "dateLastCrawled": "2022-01-20T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Compressed Sensing Meets <b>Machine</b> <b>Learning</b>: Classification via <b>Sparse</b> ...", "url": "https://nuit-blanche.blogspot.com/2008/05/cs-mini-course-classification-via.html", "isFamilyFriendly": true, "displayUrl": "https://nuit-blanche.blogspot.com/2008/05/cs-mini-course-classification-via.html", "snippet": "Compressed Sensing Meets <b>Machine</b> <b>Learning</b>: Classification via <b>Sparse</b> <b>Representation</b> and Distributed Pattern Recognition This Spring, Allen Yang has given a mini course at Berkeley entitled Compressed Sensing Meets <b>Machine</b> <b>Learning</b>. The three lectures are listed here (it includes accompanying code): lecture 1: Classification via <b>Sparse</b> <b>Representation</b>; lecture 2: Classification of Mixture Subspace Models via <b>Sparse</b> <b>Representation</b>, lecture 3: Distributed Pattern Recognition; The third lecture ...", "dateLastCrawled": "2022-01-25T10:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Word Embedding: Syntactics or Semantics</b> \u00b7 Shengbin&#39;s Studio", "url": "https://wushbin.github.io/2017/10/09/Word-Embedding-Syntactics-or-Semantics/", "isFamilyFriendly": true, "displayUrl": "https://wushbin.github.io/2017/10/09/<b>Word-Embedding-Syntactics-or-Semantics</b>", "snippet": "<b>Sparse</b> Vector <b>Representation</b>. The co-occurrence matrix in represented each cell by the raw frequency of the co-occurrence of two words. The raw frequency in a matrix may be skewed. Pointwise mutual information PPMI is a good measure for association between words which can tell us how much often the two words occur. The pointwise mutual information is a measure of how often two events x and y occur, compared with what we would expect if they were independent: PMI between two words is ...", "dateLastCrawled": "2022-01-09T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What Are Word Embeddings</b> for Text? - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/what-are-word-embeddings/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>what-are-word-embeddings</b>", "snippet": "Word embeddings are a type of word <b>representation</b> that allows words with similar meaning to have a similar <b>representation</b>. They are a distributed <b>representation</b> for text that is perhaps one of the key breakthroughs for the impressive performance of deep <b>learning</b> methods on challenging natural language processing problems. In this post, you will discover the word embedding approach for representing text data. After", "dateLastCrawled": "2022-01-30T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Word Embeddings in NLP - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/word-embeddings-in-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/word-embeddings-in-nlp", "snippet": "Word Embeddings are a method of extracting features out of text so that we can input those features into a <b>machine</b> <b>learning</b> model to work with text data. They try to preserve syntactical and semantic information. The methods such as Bag of Words(BOW), CountVectorizer and TFIDF rely on the word count in a sentence but do not save any syntactical or semantic information. In these algorithms, the size of the vector is the number of elements in the vocabulary. We can get a <b>sparse</b> matrix if most ...", "dateLastCrawled": "2022-01-30T08:38:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse Adaptive Local Machine Learning</b> Algorithms for Sensing and Analytics", "url": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1000&context=mcecs_mentoring", "isFamilyFriendly": true, "displayUrl": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1000&amp;context=mcecs...", "snippet": "Fig. 2: A <b>sparse representation can be thought of as</b> the dot product of a dictionary vector and a sparse code vector. Given a . dictionary . of general components, we can use a . sparse code. to select as few of them as possible to reconstruct an image of interest (Fig. 2). This reconstruction is called a . sparse representation. Sparse Coding. Image processing is expensive. Instead of working with the original image, we can identify its most relevant components and discard the rest. This ...", "dateLastCrawled": "2021-08-31T12:20:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(sparse representation)  is like +(storing data in a compressed format)", "+(sparse representation) is similar to +(storing data in a compressed format)", "+(sparse representation) can be thought of as +(storing data in a compressed format)", "+(sparse representation) can be compared to +(storing data in a compressed format)", "machine learning +(sparse representation AND analogy)", "machine learning +(\"sparse representation is like\")", "machine learning +(\"sparse representation is similar\")", "machine learning +(\"just as sparse representation\")", "machine learning +(\"sparse representation can be thought of as\")", "machine learning +(\"sparse representation can be compared to\")"]}