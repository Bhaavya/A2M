{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The <b>Area Under</b> an <b>ROC</b> <b>Curve</b>", "url": "http://gim.unmc.edu/dxtests/RoC3.htm", "isFamilyFriendly": true, "displayUrl": "gim.unmc.edu/dxtests/<b>RoC</b>3.htm", "snippet": "The <b>accuracy</b> of the test depends on how well the test separates the group being tested into those with and without the disease in question. <b>Accuracy</b> is measured by the <b>area under</b> <b>the ROC</b> <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the <b>accuracy</b> of a diagnostic test is the traditional academic point system: .90-1 = excellent (A) .80-.90 = good (B) .70-.80 = fair (C) .60-.70 = poor (D) .50-.60 = fail (F) Recall the T4 ...", "dateLastCrawled": "2022-01-28T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-<b>the-roc</b>-<b>curve</b>-assessing-discrimination...", "snippet": "Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a model with no discrimination ability. The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is also sometimes referred to as the c-statistic (c for concordance). The <b>area</b> <b>under</b> the estimated <b>ROC</b> <b>curve</b> (AUC) is reported when we plot <b>the ROC</b> <b>curve</b> in R&#39;s Console.", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Receiver Operating Characteristic</b> (<b>ROC</b>) <b>Curve</b> Analysis for Medical ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3755824/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3755824", "snippet": "Derived indexes of <b>accuracy</b>, in particular <b>area</b> <b>under</b> the <b>curve</b> (AUC) has a meaningful interpretation for disease classification from healthy subjects. The methods of estimate of AUC and its testing in single diagnostic test and also comparative studies, the advantage of <b>ROC</b> <b>curve</b> to determine the optimal cut off values and the issues of bias and confounding have been discussed. Key Words: Sensitivity, Specificity, <b>ROC</b> <b>curve</b>, <b>Area</b> <b>under</b> the <b>curve</b> (AUC), Parametric, Nonparametric, Bias ...", "dateLastCrawled": "2022-02-02T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>The ROC Curve</b>: Unveiled. The complete guide to <b>the ROC curve</b> | by z_ai ...", "url": "https://towardsdatascience.com/the-roc-curve-unveiled-81296e1577b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>the-roc-curve</b>-unveiled-81296e1577b", "snippet": "This is where <b>the ROC</b> or <b>Receiver Operating Characteristic</b> <b>Curve</b> comes into play. It is a graphical representation of how two of these metrics (the Sensitivity or Recall and the Specificity) vary as we change this probability threshold. Intuitively, it is a summarization of all the confusion matrices that we would obtain as this threshold varies from 0 to 1, in a single, concise source of information.", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Diagnostic <b>accuracy</b> \u2013 Part 1 Basic concepts: sensitivity and ...", "url": "https://acutecaretesting.org/en/articles/diagnostic-accuracy--part-1brbasic-concepts-sensitivity-and-specificity-roc-analysis-stard-statement", "isFamilyFriendly": true, "displayUrl": "https://acutecaretesting.org/en/articles/diagnostic-<b>accuracy</b>--part-1brbasic-concepts...", "snippet": "AUC is a global measure of diagnostic <b>accuracy</b>. The <b>area</b> <b>under</b> the <b>curve</b> may be any value between 0 and 1 and it is a good indicator of the overall quality of the test. By comparing the areas <b>under</b> the two <b>ROC</b> curves we can estimate which test is better at diagnosing a disease. A perfect diagnostic test has an AUC of 1.0, whereas a useless test ...", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "AUC (<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>) ... The proportion of actual <b>positive</b> <b>examples</b> for which the <b>negative</b> class is predicted. False <b>negative</b> rate is calculated as follows: $$\\text{False <b>Negative</b> Rate} = \\frac{\\text{False Negatives}}{\\text{False Negatives} + \\text{True Positives}}$$ false <b>positive</b> (FP) An example in which the model mistakenly predicted the <b>positive</b> class. For example, the model inferred that a particular email message was spam (the <b>positive</b> class), but that email message was ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>ROC</b> Machine Learning Explained \u2013 How to Learn Machine Learning", "url": "https://howtolearnmachinelearning.com/articles/roc-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://howtolearnmachinelearning.com/articles/<b>roc</b>-machine-learning", "snippet": "Another thing to mention is that if <b>the ROC</b> <b>curve</b> is too good (<b>like</b> the <b>examples</b> from the figure directly above to illustrate different scenarios) it probably means that the model is over-fitting the training data. Cool huh? Finally, the following figure shows some other graphs of <b>ROC</b> curves that have been taken from different sources. Group of 4 different <b>ROC</b> curves taken from different sources. You have probably noticed that some of these graphs also give a value for the <b>area</b> <b>under</b> <b>the ROC</b> ...", "dateLastCrawled": "2022-02-03T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "One <b>ROC</b> <b>Curve</b> and Cutoff Analysis - NCSS", "url": "https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/One_ROC_Curve_and_Cutoff_Analysis.pdf", "isFamilyFriendly": true, "displayUrl": "https://ncss-wpengine.netdna-ssl.com/.../NCSS/One_<b>ROC</b>_<b>Curve</b>_and_Cutoff_Analysis.pdf", "snippet": "This procedure generates empirical (nonparametric) and Binormal <b>ROC</b> curves. It also gives the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (AUC), the corresponding confidence interval of AUC, and a statistical test to determine if AUC is greater than a specified value. Summary measures for a desired (user -specified) list of cutoff values are also available. Some of these measures include sensitivity, specificity, proportion correctly specified, table counts, <b>positive</b> predictive value, cost analysis, likelihood ...", "dateLastCrawled": "2022-02-02T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Prodding <b>the ROC</b> <b>Curve</b>: Constrained Optimization of Classifier Performance", "url": "https://proceedings.neurips.cc/paper/2001/file/2cd4e8a2ce081c3d7c32c3cde4312ef7-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://p<b>roc</b>eedings.neurips.cc/paper/2001/file/2cd4e8a2ce081c3d7c32c3cde4312ef7-Paper.pdf", "snippet": "obtained from the classi\ufb01er: the <b>accuracy</b> of correctly <b>identifying</b> an input as a member of the class (acorrect acceptance orCA), and the <b>accuracy</b> of correctly <b>identifying</b> an input as a nonmember of the class (a correct rejection or CR). To evaluate the CA and CR rates, it is necessary to pick a threshold above which the classi\ufb01er\u2019s probability estimate is inter-preted as an \u201caccept,\u201d and below which is interpreted as a \u201creject\u201d\u2014call this thecriterion. <b>The ROC</b> <b>curve</b> plots CA ...", "dateLastCrawled": "2021-08-24T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "model evaluation - AUC and <b>class imbalance in training/test dataset</b> ...", "url": "https://stats.stackexchange.com/questions/260164/auc-and-class-imbalance-in-training-test-dataset", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/260164", "snippet": "I just start to learn the <b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (AUC). I am told that AUC is not reflected by data imbalance. I think it means that AUC is insensitive to imbalance in test data, rather than imbalance in training data. In other words, only changing the distribution of <b>positive</b> and <b>negative</b> classes in the test data, the AUC value may not change much. But if we change the distribution in the training data, the AUC value may largely change. The reason is that the classifier cannot be learned ...", "dateLastCrawled": "2022-01-28T15:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Receiver Operating Characteristic</b> (<b>ROC</b>) <b>Curve</b> Analysis for Medical ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3755824/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3755824", "snippet": "Derived indexes of <b>accuracy</b>, in particular <b>area</b> <b>under</b> the <b>curve</b> (AUC) has a meaningful interpretation for disease classification from healthy subjects. The methods of estimate of AUC and its testing in single diagnostic test and also comparative studies, the advantage of <b>ROC</b> <b>curve</b> to determine the optimal cut off values and the issues of bias and confounding have been discussed. Key Words: Sensitivity, Specificity, <b>ROC</b> <b>curve</b>, <b>Area</b> <b>under</b> the <b>curve</b> (AUC), Parametric, Nonparametric, Bias ...", "dateLastCrawled": "2022-02-02T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-<b>the-roc</b>-<b>curve</b>-assessing-discrimination...", "snippet": "Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a model with no discrimination ability. The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is also sometimes referred to as the c-statistic (c for concordance). The <b>area</b> <b>under</b> the estimated <b>ROC</b> <b>curve</b> (AUC) is reported when we plot <b>the ROC</b> <b>curve</b> in R&#39;s Console.", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Understanding AUC (of ROC), sensitivity and specificity values</b>", "url": "https://www.researchgate.net/post/Understanding-AUC-of-ROC-sensitivity-and-specificity-values", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/<b>Understanding-AUC-of-ROC-sensitivity</b>-and-specificity...", "snippet": "The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (AUC) is a summary measure of performance, that indicates whether on average a true <b>positive</b> is ranked higher than a false positives. If model A has higher AUC than ...", "dateLastCrawled": "2022-02-02T19:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How can I <b>interpret the ROC curve result</b>? - ResearchGate", "url": "https://www.researchgate.net/post/how_can_I_interpret_the_ROC_curve_result", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/how_can_I_<b>interpret_the_ROC_curve_result</b>", "snippet": "<b>Accuracy</b> is measured by the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the <b>accuracy</b> of a diagnostic ...", "dateLastCrawled": "2022-01-30T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Measures of Diagnostic <b>Accuracy</b>: Basic Definitions", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4975285/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4975285", "snippet": "The closer the <b>curve</b> is located to upper-left hand corner and the larger the <b>area</b> <b>under</b> the <b>curve</b>, the better the test is at discriminating between diseased and non-diseased. The <b>area</b> <b>under</b> the <b>curve</b> can have any value between 0 and 1 and it is a good indicator of the goodness of the test. A perfect diagnostic test has an AUC 1.0. whereas a nondiscriminating test has an <b>area</b> 0.5. Generally we can say that the relation between AUC and diagnostic <b>accuracy</b> applies as described in", "dateLastCrawled": "2022-02-03T07:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "AUC (<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>) ... The proportion of actual <b>positive</b> <b>examples</b> for which the <b>negative</b> class is predicted. False <b>negative</b> rate is calculated as follows: $$\\text{False <b>Negative</b> Rate} = \\frac{\\text{False Negatives}}{\\text{False Negatives} + \\text{True Positives}}$$ false <b>positive</b> (FP) An example in which the model mistakenly predicted the <b>positive</b> class. For example, the model inferred that a particular email message was spam (the <b>positive</b> class), but that email message was ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Concept: Sensitivity and Specificity - Using the ROC</b> <b>Curve</b> to Measure", "url": "http://mchp-appserv.cpe.umanitoba.ca/viewConcept.php?printer=Y&conceptID=1047", "isFamilyFriendly": true, "displayUrl": "mchp-appserv.cpe.umanitoba.ca/viewConcept.php?printer=Y&amp;conceptID=1047", "snippet": "The <b>accuracy</b> of a test (i.e. the ability of the test to correctly classify cases with a certain condition and cases without the condition) is measured by the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>. An <b>area</b> of 1 represents a perfect test, while an <b>area</b> of .5 represents a worthless test. The closer the <b>curve</b> follows the left-hand border and then the top border of <b>the ROC</b> space, the more accurate the test; the true <b>positive</b> rate is high and the false <b>positive</b> rate is low. Statistically, more <b>area</b> <b>under</b> the ...", "dateLastCrawled": "2022-02-03T18:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Evaluating a <b>Classification Model</b> | Machine Learning, Deep Learning ...", "url": "https://www.ritchieng.com/machine-learning-evaluate-classification-model/", "isFamilyFriendly": true, "displayUrl": "https://www.ritchieng.com/machine-learning-evaluate-<b>classification-model</b>", "snippet": "<b>Receiver Operating Characteristic</b> (<b>ROC</b>) Curves; <b>Area</b> <b>Under</b> the <b>Curve</b> (AUC) Confusion Matrix Resources; <b>ROC</b> and AUC Resources ; Other Resources; This tutorial is derived from Data School&#39;s Machine Learning with scikit-learn tutorial. I added my own notes so anyone, including myself, can refer to this tutorial without watching the videos. 1. Review of model evaluation\u00b6 Need a way to choose between models: different model types, tuning parameters, and features; Use a model evaluation procedure ...", "dateLastCrawled": "2022-02-03T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "model evaluation - AUC and <b>class imbalance in training/test dataset</b> ...", "url": "https://stats.stackexchange.com/questions/260164/auc-and-class-imbalance-in-training-test-dataset", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/260164", "snippet": "I just start to learn the <b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (AUC). I am told that AUC is not reflected by data imbalance. I think it means that AUC is insensitive to imbalance in test data, rather than imbalance in training data. In other words, only changing the distribution of <b>positive</b> and <b>negative</b> classes in the test data, the AUC value may not change much. But if we change the distribution in the training data, the AUC value may largely change. The reason is that the classifier cannot be learned ...", "dateLastCrawled": "2022-01-28T15:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Evaluating Machine Learning Classification Problems in <b>Python</b>: 6+1 ...", "url": "https://towardsdatascience.com/evaluating-machine-learning-classification-problems-in-python-5-1-metrics-that-matter-792c6faddf5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/evaluating-machine-learning-classification-problems-in...", "snippet": "A <b>receiver operating characteristic</b> <b>curve</b>, or <b>ROC</b> <b>curve</b>, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. <b>The ROC</b> <b>curve</b> is created by plotting the true <b>positive</b> rate (TPR) against the false <b>positive</b> rate (FPR) at various threshold settings. The true-<b>positive</b> rate is also known as sensitivity, recall or probability of detection[4] in machine learning.", "dateLastCrawled": "2022-02-03T04:11:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-<b>the-roc</b>-<b>curve</b>-assessing-discrimination...", "snippet": "Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a model with no discrimination ability. The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is also sometimes referred to as the c-statistic (c for concordance). The <b>area</b> <b>under</b> the estimated <b>ROC</b> <b>curve</b> (AUC) is reported when we plot <b>the ROC</b> <b>curve</b> in R&#39;s Console.", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The <b>Area Under</b> an <b>ROC</b> <b>Curve</b>", "url": "http://gim.unmc.edu/dxtests/RoC3.htm", "isFamilyFriendly": true, "displayUrl": "gim.unmc.edu/dxtests/<b>RoC</b>3.htm", "snippet": "The <b>accuracy</b> of the test depends on how well the test separates the group being tested into those with and without the disease in question. <b>Accuracy</b> is measured by the <b>area under</b> <b>the ROC</b> <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the <b>accuracy</b> of a diagnostic test is the traditional academic point system: .90-1 = excellent (A) .80-.90 = good (B) .70-.80 = fair (C) .60-.70 = poor (D) .50-.60 = fail (F) Recall the T4 ...", "dateLastCrawled": "2022-01-28T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Prodding <b>the ROC</b> <b>Curve</b>: Constrained Optimization of Classifier Performance", "url": "https://proceedings.neurips.cc/paper/2001/file/2cd4e8a2ce081c3d7c32c3cde4312ef7-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://p<b>roc</b>eedings.neurips.cc/paper/2001/file/2cd4e8a2ce081c3d7c32c3cde4312ef7-Paper.pdf", "snippet": "<b>ROC</b> <b>curve</b>, a classi\ufb01er <b>can</b> <b>be thought</b> of as making a <b>positive</b>/<b>negative</b> judgement as to whether an input is a member of some class. Two different <b>accuracy</b> measures <b>can</b> be obtained from the classi\ufb01er: the <b>accuracy</b> of correctly <b>identifying</b> an input as a member of the class (acorrect acceptance orCA), and the <b>accuracy</b> of correctly <b>identifying</b> an input as a nonmember of the class (a correct rejection or CR). To evaluate the CA and CR rates, it is necessary to pick a threshold above which the ...", "dateLastCrawled": "2021-08-24T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A machine learning model to identify early stage symptoms of SARS-Cov-2 ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7305929/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7305929", "snippet": "\u2022 <b>Area</b> <b>Under</b> the <b>Curve</b> (AUC): AUC is the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> and demonstrates, how well the probabilities from the <b>positive</b> classes are isolated from the <b>negative</b> classes. Where True <b>positive</b> rate or TPR is only the range of trues we are utilizing our calculation (Agarwal, 2019).", "dateLastCrawled": "2022-02-02T13:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Diagnostic <b>accuracy</b> \u2013 Part 1 Basic concepts: sensitivity and ...", "url": "https://acutecaretesting.org/en/articles/diagnostic-accuracy--part-1brbasic-concepts-sensitivity-and-specificity-roc-analysis-stard-statement", "isFamilyFriendly": true, "displayUrl": "https://acutecaretesting.org/en/articles/diagnostic-<b>accuracy</b>--part-1brbasic-concepts...", "snippet": "AUC is a global measure of diagnostic <b>accuracy</b>. The <b>area</b> <b>under</b> the <b>curve</b> may be any value between 0 and 1 and it is a good indicator of the overall quality of the test. By comparing the areas <b>under</b> the two <b>ROC</b> curves we <b>can</b> estimate which test is better at diagnosing a disease. A perfect diagnostic test has an AUC of 1.0, whereas a useless test ...", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Evaluating screening questionnaires using receiver Operating ...", "url": "https://www.academia.edu/69402960/Evaluating_screening_questionnaires_using_receiver_Operating_Characteristic_ROC_curves_from_two_phase_double_samples", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69402960/Evaluating_screening_questionnaires_using_receiver...", "snippet": "The <b>area</b> <b>under</b> an <b>ROC</b> <b>curve</b> (AUC) the relative merits of an approach originating from provides a measure of the performance of the screening work by Delong et al. (1988) and computer-intensive test, beyond sensitivity and specificity at a single methods such as the jackknife (McNeil and Hanley, threshold, considering the full range of scores that 1984; Efron and Tibshirani, 1993). need to be taken into account in making a decision In this paper we illustrate the use of bootstrap about a ...", "dateLastCrawled": "2022-02-07T15:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Introduction to ROC analysis</b> - ResearchGate", "url": "https://www.researchgate.net/publication/222511520_Introduction_to_ROC_analysis", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/222511520", "snippet": "number of <b>positive</b> and <b>negative</b> <b>examples</b>. Outputs: ... late the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, abbreviated AUC (Bradley, 1997; Hanley and McNeil, 1982). Since the. AUC is a portion of the <b>area</b> of the ...", "dateLastCrawled": "2022-02-01T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 7, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Receiver operating characteristic</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Receiver_operating_characteristic", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Receiver_operating_characteristic</b>", "snippet": "The contingency table <b>can</b> derive several evaluation &quot;metrics&quot; (see infobox). To draw a <b>ROC</b> <b>curve</b>, only the true <b>positive</b> rate (TPR) and false <b>positive</b> rate (FPR) are needed (as functions of some classifier parameter). The TPR defines how many correct <b>positive</b> results occur among all <b>positive</b> samples available during the test. FPR, on the other hand, defines how many incorrect <b>positive</b> results occur among all <b>negative</b> samples available during the test. A <b>ROC</b> space is defined by FPR and TPR as ...", "dateLastCrawled": "2022-02-02T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>xG Model - Accuracy and Goodness-Of-Fit</b>", "url": "https://www.thesignificantgame.com/portfolio/xg-model-accuracy-and-goodness-of-fit/", "isFamilyFriendly": true, "displayUrl": "https://www.thesignifi<b>can</b>tgame.com/portfolio/<b>xg-model-accuracy-and-goodness-of-fit</b>", "snippet": "Another way to assess the goodness-of-fit of our model is a <b>ROC</b> <b>curve</b> (<b>receiver operating characteristic</b> <b>curve</b>). It highlights the trade-off between the true <b>positive</b>-rate (y-axis) and the false <b>positive</b>-rate for many different threshold values. For an ideal model we would see the <b>curve</b> stretch all the way to the top left of the quadrant, but any <b>curve</b> left of the dashed line is better than a random model. The <b>area</b> <b>under</b> the <b>curve</b> <b>can</b> be interpreted as the probability that the model ranks a ...", "dateLastCrawled": "2022-01-29T16:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Jaccard Coefficient</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/jaccard-coefficient", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>jaccard-coefficient</b>", "snippet": "The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (AUC) is a measure of <b>accuracy</b>, in the sense of the ability of an algorithm to distinguish between two classes or groups. 3.2.2 <b>Accuracy</b> and related measures. In the context of segmentation, for example, comparing the output of a computer algorithm to the ground truth generated by an expert human grader, <b>accuracy</b> (Acc) is often assessed by summing the number of correctly identified image pixels\u2014those belonging to a region (i.e., TP) and those external to the ...", "dateLastCrawled": "2022-01-29T00:31:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-<b>the-roc</b>-<b>curve</b>-assessing-discrimination...", "snippet": "Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a model with no discrimination ability. The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is also sometimes referred to as the c-statistic (c for concordance). The <b>area</b> <b>under</b> the estimated <b>ROC</b> <b>curve</b> (AUC) is reported when we plot <b>the ROC</b> <b>curve</b> in R&#39;s Console.", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification: <b>ROC</b> <b>Curve</b> and AUC | Machine Learning Crash Course ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/crash-course/classification/<b>roc</b>-and-auc", "snippet": "Fortunately, there&#39;s an efficient, sorting-based algorithm that <b>can</b> provide this information for us, called AUC. AUC: <b>Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>. AUC stands for &quot;<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>.&quot; That is, AUC measures the entire two-dimensional <b>area</b> underneath the entire <b>ROC</b> <b>curve</b> (think integral calculus) from (0,0) to (1,1). Figure 5. AUC (<b>Area</b> <b>under</b> ...", "dateLastCrawled": "2022-02-02T09:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The <b>Area Under</b> an <b>ROC</b> <b>Curve</b>", "url": "http://gim.unmc.edu/dxtests/RoC3.htm", "isFamilyFriendly": true, "displayUrl": "gim.unmc.edu/dxtests/<b>RoC</b>3.htm", "snippet": "The <b>accuracy</b> of the test depends on how well the test separates the group being tested into those with and without the disease in question. <b>Accuracy</b> is measured by the <b>area under</b> <b>the ROC</b> <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the <b>accuracy</b> of a diagnostic test is the traditional academic point system: .90-1 = excellent (A) .80-.90 = good (B) .70-.80 = fair (C) .60-.70 = poor (D) .50-.60 = fail (F) Recall the T4 ...", "dateLastCrawled": "2022-01-28T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Receiver Operating Characteristic</b> (<b>ROC</b>) <b>Curve</b> Analysis for Medical ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3755824/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3755824", "snippet": "Derived indexes of <b>accuracy</b>, in particular <b>area</b> <b>under</b> the <b>curve</b> (AUC) has a meaningful interpretation for disease classification from healthy subjects. The methods of estimate of AUC and its testing in single diagnostic test and also comparative studies, the advantage of <b>ROC</b> <b>curve</b> to determine the optimal cut off values and the issues of bias and confounding have been discussed. Key Words: Sensitivity, Specificity, <b>ROC</b> <b>curve</b>, <b>Area</b> <b>under</b> the <b>curve</b> (AUC), Parametric, Nonparametric, Bias ...", "dateLastCrawled": "2022-02-02T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "AUC-<b>ROC</b> <b>Curve</b> in Machine Learning Clearly Explained - Analytics Vidhya", "url": "https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2020/06/auc-<b>roc</b>-<b>curve</b>-machine-learning", "snippet": "The <b>Area</b> <b>Under</b> the <b>Curve</b> (AUC) ... then the classifier is not able to distinguish between <b>Positive</b> and <b>Negative</b> class points. Meaning either the classifier is predicting random class or constant class for all the data points. So, the higher the AUC value for a classifier, the better its ability to distinguish between <b>positive</b> and <b>negative</b> classes. How Does the AUC-<b>ROC</b> <b>Curve</b> Work? In a <b>ROC</b> <b>curve</b>, a higher X-axis value indicates a higher number of False positives than True negatives. While a ...", "dateLastCrawled": "2022-02-02T11:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Diagnostic <b>accuracy</b> \u2013 Part 1 Basic concepts: sensitivity and ...", "url": "https://acutecaretesting.org/en/articles/diagnostic-accuracy--part-1brbasic-concepts-sensitivity-and-specificity-roc-analysis-stard-statement", "isFamilyFriendly": true, "displayUrl": "https://acutecaretesting.org/en/articles/diagnostic-<b>accuracy</b>--part-1brbasic-concepts...", "snippet": "AUC is a global measure of diagnostic <b>accuracy</b>. The <b>area</b> <b>under</b> the <b>curve</b> may be any value between 0 and 1 and it is a good indicator of the overall quality of the test. By comparing the areas <b>under</b> the two <b>ROC</b> curves we <b>can</b> estimate which test is better at diagnosing a disease. A perfect diagnostic test has an AUC of 1.0, whereas a useless test ...", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>ROC Curve</b> | Real Statistics Using Excel", "url": "https://www.real-statistics.com/descriptive-statistics/roc-curve-classification-table/roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.real-statistics.com/descriptive-statistics/<b>roc-curve</b>-classification-table/...", "snippet": "The result is shown on the right side of Figure 1. The actual <b>ROC curve</b> is a step function with the points shown in the figure. Observation: The higher <b>the ROC curve</b> (i.e. the closer to the line y = 1) the better the fit. In fact, the <b>area</b> <b>under</b> the <b>curve</b> (AUC) <b>can</b> be used for this purpose. The closer AUC is to 1 (the maximum value) the better ...", "dateLastCrawled": "2022-01-29T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Measures of Diagnostic <b>Accuracy</b>: Basic Definitions", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4975285/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4975285", "snippet": "The closer the <b>curve</b> is located to upper-left hand corner and the larger the <b>area</b> <b>under</b> the <b>curve</b>, the better the test is at discriminating between diseased and non-diseased. The <b>area</b> <b>under</b> the <b>curve</b> <b>can</b> have any value between 0 and 1 and it is a good indicator of the goodness of the test. A perfect diagnostic test has an AUC 1.0. whereas a nondiscriminating test has an <b>area</b> 0.5. Generally we <b>can</b> say that the relation between AUC and diagnostic <b>accuracy</b> applies as described in", "dateLastCrawled": "2022-02-03T07:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The 5 <b>Classification</b> Evaluation metrics every Data Scientist must know ...", "url": "https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-5-<b>classification</b>-evaluation-metrics-you-must-know...", "snippet": "AUC is the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>. AUC <b>ROC</b> indicates how well the probabilities from the <b>positive</b> classes are separated from the <b>negative</b> classes. What is <b>the ROC</b> <b>curve</b>? We have got the probabilities from our classifier. We <b>can</b> use various threshold values to plot our sensitivity(TPR) and (1-specificity)(FPR) on the cure and we will have a <b>ROC</b> <b>curve</b>. Where True <b>positive</b> rate or TPR is just the proportion of trues we are capturing using our algorithm. Sensitivty = TPR(True <b>Positive</b> Rate ...", "dateLastCrawled": "2022-02-02T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Evaluating Machine Learning Classification Problems in <b>Python</b>: 6+1 ...", "url": "https://towardsdatascience.com/evaluating-machine-learning-classification-problems-in-python-5-1-metrics-that-matter-792c6faddf5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/evaluating-machine-learning-classification-problems-in...", "snippet": "The Plus One Metric: <b>ROC</b> AUC [or <b>Area</b> <b>Under</b> <b>Curve</b> for <b>The Receiver Operating Characteristic</b> (<b>ROC</b>)] ... We <b>can</b> utilize <b>the ROC</b> <b>curve</b> to visualize the overlap between the <b>positive</b> and <b>negative</b> classes. To do this, we <b>can</b> follow these steps: 1) Set the classification threshold at 0, which means all predictions are classified as Class 1 (<b>Positive</b>). 2) Calculate sensitivity and 1 \u2014 <b>specificity</b> for this threshold. 3) Plot the values (x = 1 \u2014 <b>specificity</b>, y = sensitivity). 4) Increase the ...", "dateLastCrawled": "2022-02-03T04:11:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The Receiver Operating <b>Curve</b> (<b>ROC</b>) and The Scale \u2014 Understanding <b>ROC</b> ...", "url": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the-scale-understanding-roc-through-an-analogy-8b8f9d954f84", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-everyday/the-receiver-operating-<b>curve</b>-<b>roc</b>-and-the...", "snippet": "The Receiver Operating <b>Curve</b> (<b>ROC</b>) is used to evaluate and improve classification <b>Machine</b> <b>Learning</b> models. Who does not want an accurate classifier, that place observations where they actually\u2026", "dateLastCrawled": "2021-02-13T00:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding <b>AUC</b> - <b>ROC</b> <b>Curve</b> | by Sarang Narkhede | Towards Data Science", "url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>auc</b>-<b>roc</b>-<b>curve</b>-68b2303cc9c5", "snippet": "In <b>Machine</b> <b>Learning</b>, performance measurement is an essential task. So when it comes to a classification problem, we can count on an <b>AUC</b> - <b>ROC</b> <b>Curve</b>. When we need to check or visualize the performance of the multi-class classification problem, we use the <b>AUC</b> <b>Area</b> <b>Under</b> The <b>Curve</b>) <b>ROC</b> (Receiver Operating Characteristics) <b>curve</b>. It is one of the most important evaluation metrics for checking any classification model\u2019s performance. It is also written as AUROC (<b>Area</b> <b>Under</b> the Receiver Operating ...", "dateLastCrawled": "2022-01-30T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>What is</b> AUC - <b>ROC</b> in <b>Machine</b> <b>Learning</b> | Overview of <b>ROC</b>", "url": "https://www.mygreatlearning.com/blog/roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>roc</b>-<b>curve</b>", "snippet": "By <b>analogy</b>, Higher the AUC, better the model is at distinguishing between patients with the disease and no disease. <b>The ROC</b> <b>curve</b> is plotted with TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis. Defining terms used in AUC and <b>ROC</b> <b>Curve</b>. Consider a two-class prediction problem, in which the outcomes are labeled either as positive (p) or negative (n). There are four possible outcomes from a binary classifier. If the outcome from a prediction is p and the actual value is ...", "dateLastCrawled": "2022-01-30T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "AUC calculates the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, and therefore it is between 0 and 1. One way of interpreting AUC is the probability that the model ranks a random positive example more highly than a random negative example. Youden\u2019s index Youden\u2019s J statistic (also called Youden\u2019s index) is a single statistic that captures the performance of a dichotomous (A partition of a whole into two) diagnostic tests. Youden\u2019s J statistic is J = sensitivity + specificity - 1 The right-hand two ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding AUC - <b>RO C</b> <b>Cur ve</b>", "url": "https://48hours.ai/files/AUC.pdf", "isFamilyFriendly": true, "displayUrl": "https://48hours.ai/files/AUC.pdf", "snippet": "In <b>Machine</b> <b>Learning</b>, performance measurement is an essential task. So when it comes to a classification problem, we can count on an AUC - <b>ROC</b> <b>Curve</b>. When we need to check or visualize the performance of the multi - class classification problem, we use AUC (<b>Area</b> <b>Under</b> The <b>Cur ve</b>) <b>ROC</b> (Receiver Operating Character istics) <b>curve</b>. It is one of the most important evaluation metrics for checking any classification model\u2019s performance. It is also written as AUROC (<b>Area</b> <b>Under</b> t he Receiver ...", "dateLastCrawled": "2022-02-01T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "C. <b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b> D. All of the above Answer : D. 24. Which of the following is a good test dataset characteristic? A. Large enough to yield meaningful results B. Is representative of the dataset as a whole C. Both A and B D. None of the above Answer : C. 25. Which of the following is a disadvantage of decision trees? A. Factor analysis", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is the AUC \u2014 <b>ROC</b> <b>Curve</b>?. AUC-<b>ROC</b> <b>CURVE</b> | CONFUSION MATRIX |\u2026 | by ...", "url": "https://medium.com/computer-architecture-club/what-is-the-auc-roc-curve-47fbdcbf7a4a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/computer-architecture-club/what-is-the-auc-<b>roc</b>-<b>curve</b>-47fbdcbf7a4a", "snippet": "The <b>Area</b> <b>Under</b> the <b>Curve</b> (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of <b>the ROC</b> <b>curve</b>. AUC-<b>ROC</b> <b>curve</b> is a performance measurement ...", "dateLastCrawled": "2022-01-26T00:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "<b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>. See AUC (<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b>). artificial general intelligence . A non-human mechanism that demonstrates a broad range of problem solving, creativity, and adaptability. For example, a program demonstrating artificial general intelligence could translate text, compose symphonies, and excel at games that have not yet been invented. artificial intelligence. A non-human program or model that can solve sophisticated tasks. For example, a program or model that ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "In <b>machine</b> <b>learning</b>, how model accuracy and <b>ROC</b> AUC (<b>area</b> <b>under</b> the TP ...", "url": "https://www.quora.com/In-machine-learning-how-model-accuracy-and-ROC-AUC-area-under-the-TP-vs-FP-rates-curve-are-related", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-<b>machine</b>-<b>learning</b>-how-model-accuracy-and-<b>ROC</b>-AUC-<b>area</b>-<b>under</b>...", "snippet": "Answer (1 of 2): High accuracy and higher AUC are both good things generally. Before understanding AUROC, first the concept of confusion matrix must be understood ...", "dateLastCrawled": "2022-01-07T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine learning predicts mortality based on analysis</b> of ventilation ...", "url": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01506-w", "isFamilyFriendly": true, "displayUrl": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01506-w", "snippet": "Predictive performance of RNN-based model was higher with <b>Area</b> <b>Under</b> <b>the Receiver Operating Characteristic</b> (<b>ROC</b>) <b>Curve</b> (AUC) of 0.72 (\u00b1 0.01) and Average Precision (AP) of 0.57 (\u00b1 0.01) in comparison to RF and LR for the overall patient dataset. Higher predictive performance was recorded in the subgroup of patients admitted with respiratory disorders with AUC of 0.75 (\u00b1 0.02) and AP of 0.65 (\u00b1 0.03). Inclusion of function of other organs further improved the performance to AUC of 0.79 ...", "dateLastCrawled": "2022-01-31T04:05:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Newest &#39;auc&#39; Questions</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/tagged/auc", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/tagged/auc", "snippet": "The <b>area under the ROC curve can be thought of as</b> a single scalar representation of the ROC curve itself. The AUC of a classifier has the property of being equivalent to the probability that the classifier will rank a randomly chosen positive data point higher than a randomly chosen negative data point.", "dateLastCrawled": "2022-01-19T11:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Reliability and Validity of the Ocular Surface Disease Index | External ...", "url": "https://jamanetwork.com/journals/jamaophthalmology/fullarticle/413145", "isFamilyFriendly": true, "displayUrl": "https://jamanetwork.com/journals/jamaophthalmology/fullarticle/413145", "snippet": "The <b>area under the ROC curve can be thought of as</b> a summary measure for these curves, with 0.5 indicating that the test is no better than chance at predicting dry eye disease and 1.0 indicating a perfect test for dry eye. The areas under the ROC curve for the <b>OSDI</b> demonstrate good to excellent discrimination with the instrument .", "dateLastCrawled": "2022-02-01T22:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Mastering <b>Machine</b> <b>Learning</b> with Spark 2.x [PDF] | Online Book Share", "url": "https://docero.net/doc/mastering-machine-learning-with-spark-2x-k9ezgwpn4w", "isFamilyFriendly": true, "displayUrl": "https://docero.net/doc/mastering-<b>machine</b>-<b>learning</b>-with-spark-2x-k9ezgwpn4w", "snippet": "Therefore, the <b>area under the ROC curve can be thought of as</b> an average model accuracy whereby a value of 1.0 would represent perfect classification, 0.5 would be a coin-flip (meaning our model is doing a 50-50 job at guessing 1 or 0), and anything less than 0.5 would mean flipping a coin is more accurate than our model! This is an incredibly useful metric which we will see can be used to compare against different hyperparameter tweaks and different models altogether! Let&#39;s go ahead and ...", "dateLastCrawled": "2022-01-27T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "US20160278736A1 - Monitoring structural features of cerebral blood flow ...", "url": "https://patents.google.com/patent/US20160278736A1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US20160278736A1/en", "snippet": "US20160278736A1 US15/036,776 US201415036776A US2016278736A1 US 20160278736 A1 US20160278736 A1 US 20160278736A1 US 201415036776 A US201415036776 A US 201415036776A US 2016278736 A", "dateLastCrawled": "2021-12-29T18:22:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(area under the roc curve)  is like +(accuracy of identifying positive examples from negative examples)", "+(area under the roc curve) is similar to +(accuracy of identifying positive examples from negative examples)", "+(area under the roc curve) can be thought of as +(accuracy of identifying positive examples from negative examples)", "+(area under the roc curve) can be compared to +(accuracy of identifying positive examples from negative examples)", "machine learning +(area under the roc curve AND analogy)", "machine learning +(\"area under the roc curve is like\")", "machine learning +(\"area under the roc curve is similar\")", "machine learning +(\"just as area under the roc curve\")", "machine learning +(\"area under the roc curve can be thought of as\")", "machine learning +(\"area under the roc curve can be compared to\")"]}