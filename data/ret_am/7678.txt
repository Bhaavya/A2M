{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Disparate Impact</b> - Definition, Examples, Cases, Processes", "url": "https://legaldictionary.net/disparate-impact/", "isFamilyFriendly": true, "displayUrl": "https://legaldictionary.net/<b>disparate-impact</b>", "snippet": "<b>Disparate impact</b> concerns policies and procedures \u2013 in employment, housing, education, and other issues \u2013 which are not necessarily meant to be discriminatory, but which end up ultimately having an \u201cadverse effect\u201d on a particular class of <b>people</b>, based on such traits as their race, color, or religion. For example, <b>disparate impact</b> can be applied to employment requirements concerning height, weight, and education, as well as written tests or even interviews.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Employment Tests and Selection Procedures</b> | U.S. Equal Employment ...", "url": "https://www.eeoc.gov/laws/guidance/employment-tests-and-selection-procedures", "isFamilyFriendly": true, "displayUrl": "https://<b>www.eeoc.gov</b>/laws/guidance/<b>employment-tests-and-selection-procedures</b>", "snippet": "This is called \u201c<b>disparate</b> <b>impact</b> ... Ford agreed to replace the ATSS with a selection procedure, to be designed by a jointly-<b>selected</b> industrial psychologist, that would predict job success and reduce adverse <b>impact</b>. Additionally, Ford paid $8.55 million in monetary relief. Title VII and Physical Strength Tests: Strength Test Must Be Job-Related and Consistent with Business Necessity If It Disproportionately Excludes Women. In EEOC v. Dial Corp., women were disproportionately rejected for ...", "dateLastCrawled": "2022-02-03T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Certifying and removing disparate impact</b> | DeepAI", "url": "https://deepai.org/publication/certifying-and-removing-disparate-impact", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>certifying-and-removing-disparate-impact</b>", "snippet": "The <b>disparate</b> <b>impact</b> removal problem is to take some data set D and return a data set \u00af D = (X, \u00af Y, C) that can be certified as not having <b>disparate</b> <b>impact</b>. The goal is to change <b>only</b> the remaining attributes Y, leaving C. as in the original data set so that the ability to classify can be preserved as much as possible.", "dateLastCrawled": "2022-01-22T13:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Tutorial on <b>Fairness</b> in <b>Machine</b> Learning | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-<b>machine</b>-learning-3ff8ba1040cb", "snippet": "A decision making process suffers from <b>disparate</b> treatment if its decisions are (partly) based on the subject\u2019s sensitive attribute, and it has <b>disparate</b> <b>impact</b> if its outcomes disproportionately hurt (or benefit) <b>people</b> with certain sensitive attribute values (e.g., females, blacks). These two definitions, however, are too abstract for the purpose of computation. As a result, there is no consensus on the mathematical formulations of <b>fairness</b>.", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Fair prediction with <b>disparate</b> <b>impact</b>: A study of bias in recidivism ...", "url": "https://www.researchgate.net/publication/314153531_Fair_prediction_with_disparate_impact_A_study_of_bias_in_recidivism_prediction_instruments", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/314153531_Fair_prediction_with_<b>disparate</b>...", "snippet": "Disparity and <b>machine</b> learning. The work on disparity in <b>machine</b> learning is centered on understanding and mitigating <b>disparate</b> <b>impact</b> of algorithmic decisions on subpopulations [2, 10, 28 ...", "dateLastCrawled": "2022-01-21T06:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Disparities</b> | Healthy <b>People</b> 2020", "url": "https://www.healthypeople.gov/2020/about/foundation-health-measures/Disparities", "isFamilyFriendly": true, "displayUrl": "https://<b>www.healthypeople.gov</b>/2020/about/foundation-health-measures/<b>Disparities</b>", "snippet": "It is important to recognize the <b>impact</b> that social determinants have on health outcomes of specific populations. Healthy <b>People</b> strives to improve the health of all groups. To better understand the context of <b>disparities</b>, it is important to understand more about the U.S. population. In 2008, the U.S. population was estimated at 304 million <b>people</b>. 1. In 2008, approximately 33%, or more than 100 million <b>people</b>, identified themselves as belonging to a racial or ethnic minority population. 1 ...", "dateLastCrawled": "2022-02-03T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Model Fairness &amp; Transparency</b>. A Project on Detecting, Understanding ...", "url": "https://medium.com/sfu-cspmp/model-transparency-fairness-552a747b444", "isFamilyFriendly": true, "displayUrl": "https://<b>medium</b>.com/sfu-cspmp/model-transparency-fairness-552a747b444", "snippet": "The metric lied between 0.8\u20131.2 in all other combinations but for African-American race as the unprivileged and Caucasian as the privileged group, the <b>Disparate</b> <b>Impact</b> was found to be 0.7 ( less ...", "dateLastCrawled": "2022-01-19T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "HR Management Ch. 3 Quiz Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/121080404/hr-management-ch-3-quiz-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/121080404/hr-management-ch-3-quiz-flash-cards", "snippet": "A. <b>disparate</b> <b>impact</b> B. <b>disparate</b> treatment C. reverse discrimination D. reasonable accommodation E. undue hardship. B. Which of the following legal measure requires all federal contractors and subcontractors to engage in affirmative-action programs designed to hire and promote women and minorities? A. Twenty-Second Amendment to the Constitution B. Executive Order 11246 C. Occupational Safety and Health Act D. Thirteenth Amendment to the Constitution E. Rehabilitation Act of 1973. E. Which of ...", "dateLastCrawled": "2021-11-02T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Algorithmic bias detection and mitigation: Best practices and policies ...", "url": "https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.brookings.edu</b>/research/algorithmic-bias-detection-and-mitigation-best-", "snippet": "If left unchecked, biased algorithms can lead to decisions which can have a collective, <b>disparate</b> <b>impact</b> on certain groups of <b>people</b> even without the programmer\u2019s intention to discriminate. The ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Cognitive collaboration: Why humans and computers think better together ...", "url": "https://www2.deloitte.com/us/en/insights/deloitte-review/issue-20/augmented-intelligence-human-computer-collaboration.html", "isFamilyFriendly": true, "displayUrl": "https://www2.deloitte.com/us/en/insights/deloitte-review/issue-20/augmented...", "snippet": "For example, there has long been legal doctrine around the socially undesirable <b>disparate</b> <b>impact</b> that hiring and credit scoring algorithms can potentially have on various classes of individuals. 31 More recent examples of algorithmic bias include online advertising systems that have been found to target career-coaching service ads for high-paying jobs more frequently to men than women, and ads suggestive of arrests more often to <b>people</b> with names commonly used by black <b>people</b>. 32", "dateLastCrawled": "2022-02-01T06:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is an example of a <b>disparate</b> <b>impact</b>?", "url": "https://treehozz.com/what-is-an-example-of-a-disparate-impact", "isFamilyFriendly": true, "displayUrl": "https://treehozz.com/what-is-an-example-of-a-<b>disparate</b>-<b>impact</b>", "snippet": "<b>Disparate</b> <b>impact</b> is often referred to as unintentional discrimination, whereas <b>disparate</b> treatment is intentional. For example, testing all applicants and using results from that test that will unintentionally eliminate certain minority applicants disproportionately is <b>disparate</b> <b>impact</b>. Read, more elaboration about it is given here.", "dateLastCrawled": "2021-12-30T21:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Certifying and removing disparate impact</b> | DeepAI", "url": "https://deepai.org/publication/certifying-and-removing-disparate-impact", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>certifying-and-removing-disparate-impact</b>", "snippet": "The <b>disparate</b> <b>impact</b> removal problem is to take some data set D and return a data set \u00af D = (X, \u00af Y, C) that can be certified as not having <b>disparate</b> <b>impact</b>. The goal is to change <b>only</b> the remaining attributes Y, leaving C. as in the original data set so that the ability to classify can be preserved as much as possible.", "dateLastCrawled": "2022-01-22T13:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Big Data and <b>Discrimination</b> | The University of Chicago Law Review", "url": "https://lawreview.uchicago.edu/publication/big-data-and-discrimination", "isFamilyFriendly": true, "displayUrl": "https://lawreview.uchicago.edu/publication/big-data-and-<b>discrimination</b>", "snippet": "On the other hand, most formal articulations are clear that <b>disparate</b> <b>impact</b> can apply even when there is no discriminatory intent, not <b>only</b> when discriminatory intent is not established.38 This understanding of the <b>disparate</b> <b>impact</b> doctrine also seems more in line with perceptions of regulators and agencies that enforce antidiscrimination law in the context of credit.39 To the extent that <b>disparate</b> <b>impact</b> plays a social role beyond acting as a proxy for <b>disparate</b> treatment,40 we may not ...", "dateLastCrawled": "2022-02-01T11:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Disparities</b> | Healthy <b>People</b> 2020", "url": "https://www.healthypeople.gov/2020/about/foundation-health-measures/Disparities", "isFamilyFriendly": true, "displayUrl": "https://<b>www.healthypeople.gov</b>/2020/about/foundation-health-measures/<b>Disparities</b>", "snippet": "It is important to recognize the <b>impact</b> that social determinants have on health outcomes of specific populations. Healthy <b>People</b> strives to improve the health of all groups. To better understand the context of <b>disparities</b>, it is important to understand more about the U.S. population. In 2008, the U.S. population was estimated at 304 million <b>people</b>. 1. In 2008, approximately 33%, or more than 100 million <b>people</b>, identified themselves as belonging to a racial or ethnic minority population. 1 ...", "dateLastCrawled": "2022-02-03T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Tutorial on <b>Fairness</b> in <b>Machine</b> Learning | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-<b>machine</b>-learning-3ff8ba1040cb", "snippet": "A decision making process suffers from <b>disparate</b> treatment if its decisions are (partly) based on the subject\u2019s sensitive attribute, and it has <b>disparate</b> <b>impact</b> if its outcomes disproportionately hurt (or benefit) <b>people</b> with certain sensitive attribute values (e.g., females, blacks). These two definitions, however, are too abstract for the purpose of computation. As a result, there is no consensus on the mathematical formulations of <b>fairness</b>.", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Fair Prediction with Disparate Impact</b>: A Study of Bias in Recidivism ...", "url": "https://www.researchgate.net/publication/309402975_Fair_Prediction_with_Disparate_Impact_A_Study_of_Bias_in_Recidivism_Prediction_Instruments", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/309402975_Fair_Prediction_with_<b>Disparate</b>...", "snippet": "In other words, both members of and have the same chance of receiving a positive rating (whether it is correct or not).Certainly, these are not the <b>only</b> existing definitions of algorithmic ...", "dateLastCrawled": "2021-12-22T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Model Fairness &amp; Transparency</b>. A Project on Detecting, Understanding ...", "url": "https://medium.com/sfu-cspmp/model-transparency-fairness-552a747b444", "isFamilyFriendly": true, "displayUrl": "https://<b>medium</b>.com/sfu-cspmp/model-transparency-fairness-552a747b444", "snippet": "The metric lied between 0.8\u20131.2 in all other combinations but for African-American race as the unprivileged and Caucasian as the privileged group, the <b>Disparate</b> <b>Impact</b> was found to be 0.7 ( less ...", "dateLastCrawled": "2022-01-19T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Algorithms as discrimination detectors | <b>PNAS</b>", "url": "https://www.pnas.org/content/117/48/30096", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/117/48/30096", "snippet": "Consider that to hire <b>people</b>, a company needs <b>only</b> its screening algorithm. Once the screening algorithm has been produced, the company, in principle, no longer needs the training algorithm or training data, so a discriminating firm could potentially choose not to store them for strategic reasons (which would not be prohibited currently in the legal systems of most countries). In this sense, algorithms create new risks for discrimination absent any changes to existing laws and regulations.", "dateLastCrawled": "2022-01-28T23:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "HR Management Ch. 3 Quiz Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/121080404/hr-management-ch-3-quiz-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/121080404/hr-management-ch-3-quiz-flash-cards", "snippet": "A. <b>disparate</b> <b>impact</b> B. <b>disparate</b> treatment C. reverse discrimination D. reasonable accommodation E. undue hardship. B. Which of the following legal measure requires all federal contractors and subcontractors to engage in affirmative-action programs designed to hire and promote women and minorities? A. Twenty-Second Amendment to the Constitution B. Executive Order 11246 C. Occupational Safety and Health Act D. Thirteenth Amendment to the Constitution E. Rehabilitation Act of 1973. E. Which of ...", "dateLastCrawled": "2021-11-02T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Beware Of Unintentional Discrimination", "url": "https://www.natlawreview.com/article/unintentional-discrimination-what-every-employer-needs-to-know-about-disparate", "isFamilyFriendly": true, "displayUrl": "https://<b>www.natlawreview.com</b>/article/unintentional-discrimination-what-every-employer...", "snippet": "Applying that test to the high school diploma requirement in Griggs, a <b>disparate</b> <b>impact</b> is shown by dividing the percentage of African American males who held high school diplomas (12 percent) by ...", "dateLastCrawled": "2022-01-19T01:52:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Employment Tests and Selection Procedures</b> | U.S. Equal Employment ...", "url": "https://www.eeoc.gov/laws/guidance/employment-tests-and-selection-procedures", "isFamilyFriendly": true, "displayUrl": "https://<b>www.eeoc.gov</b>/laws/guidance/<b>employment-tests-and-selection-procedures</b>", "snippet": "If the selection procedure has a <b>disparate</b> <b>impact</b> based on race, color, religion, sex, or national origin, <b>can</b> the employer show that the selection procedure is job-related and consistent with business necessity? An employer <b>can</b> meet this standard by showing that it is necessary to the safe and efficient performance of the job. The challenged policy or practice should therefore be associated with the skills needed to perform the job successfully. In contrast to a general measurement of ...", "dateLastCrawled": "2022-02-03T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Five steps <b>that will change reconciliation forever - FinTech Futures</b>", "url": "https://www.fintechfutures.com/2020/06/five-steps-that-will-change-reconciliation-forever/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>fintechfutures</b>.com/2020/06/five-steps-<b>that-will-change-reconciliation-forever</b>", "snippet": "With business continuity front of mind, many organisations are looking for more efficient ways to manage huge swathes of data from multiple, <b>disparate</b> sources quickly and accurately. Ensuring ongoing data integrity is a key concern, and many are asking how they <b>can</b> automate their most critical processes \u2013 and the potential for <b>machine</b> learning technology to revolutionise how these processes are carried out.", "dateLastCrawled": "2022-01-31T00:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Zest AI V2", "url": "https://www.zest.ai/insights/how-to-get-fair-lending-right-with-ai-driven-lending", "isFamilyFriendly": true, "displayUrl": "https://www.zest.ai/insights/how-to-get-fair-lending-right-with-ai-driven-lending", "snippet": "While some in the industry may question whether <b>disparate</b> <b>impact</b> is a viable theory of liability under the current Supreme Court, Zest AI and many others stand by it. Plus, managing <b>disparate</b> <b>impact</b> is just the right thing to do. Even if the court seems to be leaning a certain way, it is a long way from knocking down <b>disparate</b>-<b>impact</b> liability. When techniques exist to make your lending both fairer and more profitable, it&#39;s in your interest to use them.", "dateLastCrawled": "2022-02-03T13:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Beware Of Unintentional Discrimination", "url": "https://www.natlawreview.com/article/unintentional-discrimination-what-every-employer-needs-to-know-about-disparate", "isFamilyFriendly": true, "displayUrl": "https://<b>www.natlawreview.com</b>/article/unintentional-discrimination-what-every-employer...", "snippet": "Under a court\u2019s \u201c<b>disparate</b> <b>impact</b>\u201d or \u201cadverse <b>impact</b>\u201d analysis, a plaintiff <b>can</b> prevail in a lawsuit by establishing an employer\u2019s policy or practice affects members of the protected ...", "dateLastCrawled": "2022-01-19T01:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Reductions in Workforce-- 10 Questions You Must</b> Ask First | HR Exchange ...", "url": "https://www.hrexchangenetwork.com/employment-law/articles/reductions-in-workforce-10-questions-you-must-ask", "isFamilyFriendly": true, "displayUrl": "https://www.hrexchangenetwork.com/employment-law/articles/reductions-in-workforce-10...", "snippet": "A formal statistical test of <b>disparate</b> <b>impact</b> is preferred to other ad-hoc methods, such as the Four Fifths Rule (also known as the 80% Rule), a means test, or other non-statistical tests. If <b>disparate</b> <b>impact</b> is found, the selections should be examined to determine whether they <b>can</b> be justified by business necessity or reasonable factors other than protected group status.", "dateLastCrawled": "2022-01-30T04:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Review on Fairness in <b>Machine</b> Learning | ACM Computing Surveys", "url": "https://dl.acm.org/doi/10.1145/3494672", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/10.1145/3494672", "snippet": "<b>Disparate</b> <b>impact</b> : This measure was designed to mathematically represent the legal notion of <b>disparate</b> <b>impact</b>. It requires a high ratio between the positive prediction rates of both groups. This ensures that the proportion of the positive predictions is similar across groups. For example, if a positive prediction represents acceptance for a job, the condition requires the proportion of accepted applicants to be similar across groups. Formally, this measure is computed as follows:", "dateLastCrawled": "2022-02-07T09:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Race, Race-Based Discrimination, and Health Outcomes Among African ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4181672/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4181672", "snippet": "The issue gains even greater relevance when one considers that the Black-<b>White</b> differential exists not <b>only</b> in smoking prevalence, but also in smoking-related morbidity, mortality (MMWR 1996, Rivo et al. 1989), and death from respiratory cancers (CDC 1994, USDHHS 1998). Similar findings in research on alcohol consumption among African Americans indicate that internalized racism (i.e., a belief that African Americans are inferior) is positively associated with alcohol use as well as ...", "dateLastCrawled": "2022-01-29T02:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fair prediction with <b>disparate</b> <b>impact</b>: A study of bias in recidivism ...", "url": "https://www.researchgate.net/publication/314153531_Fair_prediction_with_disparate_impact_A_study_of_bias_in_recidivism_prediction_instruments", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/314153531_Fair_prediction_with_<b>disparate</b>...", "snippet": "Bagdasaryan et al. [1] and Pujol et al. [35] study disparity in accuracy under differential privacy (DP), and show that training with DP <b>can</b> increase <b>disparate</b> <b>impact</b>. In this work, we develop a ...", "dateLastCrawled": "2022-01-21T06:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is Twitter Biased Against BIPOC? Maybe It\u2019s Not What You Think It Is ...", "url": "https://medium.com/code4thought/is-twitter-biased-against-bipoc-9baa18cabf9d?source=post_internal_links---------2----------------------------", "isFamilyFriendly": true, "displayUrl": "https://medium.com/code4<b>thought</b>/is-twitter-biased-against-bipoc-9baa18cabf9d?source=...", "snippet": "More specifically, Twitter\u2019s <b>machine</b> learning algorithm that selects which part of an image to show in a photo preview favors showing the faces of <b>white</b> <b>people</b> over black <b>people</b>. For example the ...", "dateLastCrawled": "2021-01-18T14:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Machine Bias Artificial Intelligence and Discrimination</b>", "url": "https://www.researchgate.net/publication/334721591_Machine_Bias_Artificial_Intelligence_and_Discrimination", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334721591_<b>Machine</b>_Bias_Artificial...", "snippet": "<b>people</b> of the same mind. It is <b>thought</b> that filter bubble ... intelligence <b>can</b> in principle be so precisely described that a <b>machine</b> <b>can</b> be made to simulate it. An attempt will . be made to find ...", "dateLastCrawled": "2022-01-29T13:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Disparate Impact</b> - Definition, Examples, Cases, Processes", "url": "https://legaldictionary.net/disparate-impact/", "isFamilyFriendly": true, "displayUrl": "https://legaldictionary.net/<b>disparate-impact</b>", "snippet": "<b>Disparate impact</b> concerns policies and procedures \u2013 in employment, housing, education, and other issues \u2013 which are not necessarily meant to be discriminatory, but which end up ultimately having an \u201cadverse effect\u201d on a particular class of <b>people</b>, based on such traits as their race, color, or religion. For example, <b>disparate impact</b> <b>can</b> be applied to employment requirements concerning height, weight, and education, as well as written tests or even interviews.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Bias and Discrimination in AI: A Cross-Disciplinary Perspective - IEEE ...", "url": "https://technologyandsociety.org/bias-and-discrimination-in-ai-a-cross-disciplinary-perspective/", "isFamilyFriendly": true, "displayUrl": "https://technologyandsociety.org/bias-and-discrimination-in-ai-a-cross-disciplinary...", "snippet": "Automated decisions <b>can</b> <b>impact</b> a range of phenomena, from credit scores to insurance payouts to health evaluations. These forms of automation <b>can</b> become problematic when they place certain groups or <b>people</b> at a systematic disadvantage. These are cases of discrimination\u2014which is legally defined as the unfair or unequal treatment of an individual (or group) based on certain protected characteristics (also known as protected attributes) such as income, education, gender, or ethnicity. When ...", "dateLastCrawled": "2022-01-30T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Race, Race-Based Discrimination, and Health Outcomes Among African ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4181672/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4181672", "snippet": "The issue gains even greater relevance when one considers that the Black-<b>White</b> differential exists not <b>only</b> in smoking prevalence, but also in smoking-related morbidity, mortality (MMWR 1996, Rivo et al. 1989), and death from respiratory cancers (CDC 1994, USDHHS 1998). Similar findings in research on alcohol consumption among African Americans indicate that internalized racism (i.e., a belief that African Americans are inferior) is positively associated with alcohol use as well as ...", "dateLastCrawled": "2022-01-29T02:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fair Prediction with Disparate Impact</b>: A Study of Bias in Recidivism ...", "url": "https://www.researchgate.net/publication/309402975_Fair_Prediction_with_Disparate_Impact_A_Study_of_Bias_in_Recidivism_Prediction_Instruments", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/309402975_Fair_Prediction_with_<b>Disparate</b>...", "snippet": "Furthermore, the scientific evidence suggests they <b>can</b> be an effective strategy to help achieve pretrial system change, including reducing pretrial detention for <b>people</b> of color and <b>white</b> <b>people</b> ...", "dateLastCrawled": "2021-12-22T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Certifying and Removing Disparate Impact</b> | Request PDF", "url": "https://www.researchgate.net/publication/269416801_Certifying_and_Removing_Disparate_Impact", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../269416801_<b>Certifying_and_Removing_Disparate_Impact</b>", "snippet": "While AI offers various benefits, it <b>can</b> also be subject to systematic errors, whereby <b>people</b> from certain groups (defined by gender, age, or other sensitive attributes) experience <b>disparate</b> ...", "dateLastCrawled": "2021-11-13T21:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Questions and Answers to Clarify and Provide a Common Interpretation of ...", "url": "https://www.eeoc.gov/laws/guidance/questions-and-answers-clarify-and-provide-common-interpretation-uniform-guidelines", "isFamilyFriendly": true, "displayUrl": "https://<b>www.eeoc.gov</b>/laws/guidance/questions-and-answers-clarify-and-provide-common...", "snippet": "Stressing the view that the real <b>impact</b> of the Guidelines <b>can</b> <b>only</b> be fully assessed after agency instructions have been issued and applied, and after court rulings, however the Committee raised areas of possible inconsistency between the Uniform Guidelines, as applied, and the A.P.A. Standards. In particular, the letter raises (among others) three specific concerns: (1) that the Guidelines might call for &quot;a more rigid demand for a search for alternatives than we would deem consistent with ...", "dateLastCrawled": "2022-02-03T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Omitted and Included Variable Bias in Tests for <b>Disparate</b> <b>Impact</b> - DeepAI", "url": "https://deepai.org/publication/omitted-and-included-variable-bias-in-tests-for-disparate-impact", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../omitted-and-included-variable-bias-in-tests-for-<b>disparate</b>-<b>impact</b>", "snippet": "09/15/18 - Policymakers often seek to gauge discrimination against groups defined by race, gender, and other protected attributes. One popula...", "dateLastCrawled": "2021-11-26T02:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Model Fairness &amp; Transparency</b>. A Project on Detecting, Understanding ...", "url": "https://medium.com/sfu-cspmp/model-transparency-fairness-552a747b444", "isFamilyFriendly": true, "displayUrl": "https://<b>medium</b>.com/sfu-cspmp/model-transparency-fairness-552a747b444", "snippet": "1. Introduction. B ias is a prejudice in favor or against a person, group, or a thing that is considered to be unfair. At present times, <b>Machine</b> Learning and Artificial Intelligence play a major ...", "dateLastCrawled": "2022-01-19T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "HR Management Ch. 3 Quiz Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/121080404/hr-management-ch-3-quiz-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/121080404/hr-management-ch-3-quiz-flash-cards", "snippet": "A. <b>disparate</b> <b>impact</b> B. <b>disparate</b> treatment C. reverse discrimination D. reasonable accommodation E. undue hardship. B. Which of the following legal measure requires all federal contractors and subcontractors to engage in affirmative-action programs designed to hire and promote women and minorities? A. Twenty-Second Amendment to the Constitution B. Executive Order 11246 C. Occupational Safety and Health Act D. Thirteenth Amendment to the Constitution E. Rehabilitation Act of 1973. E. Which of ...", "dateLastCrawled": "2021-11-02T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Mind the gap: COVID-19 is widening racial disparities in learning, so ...", "url": "https://www.mckinsey.com/industries/public-and-social-sector/our-insights/covid-19-and-learning-loss-disparities-grow-and-students-need-help", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mckinsey.com</b>/industries/public-and-social-sector/our-insights/covid-19-and...", "snippet": "It\u2019s unclear whether remote tutoring <b>can</b> have the same <b>impact</b> as in-person sessions, but several school systems are running experiments. For example, the Broward County Public Schools district is implementing and assessing several remote tutoring programs, including targeted high-intensity algebra tutoring for high schoolers through an external partnership with Saga Education, as well as \u201cAsk BRIA\u201d (Broward Remote Instructional Assistance)\u2014a locally developed, broad-based interactive ...", "dateLastCrawled": "2022-02-03T02:10:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A New Metric for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare", "url": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "Often, the approach to fairness draws upon the legal standard of <b>disparate</b> <b>impact</b>[2][3]. <b>Disparate</b> <b>impact</b> occurs when the predicted outcomes are different for different groups. Some examples of when this metric is used are recidivism[4], hiring[5][6], and loan applications[2]. This standard metric accounts for only one factor: the rate at which the algorithm predicts a person should benefit from a particular classification.", "dateLastCrawled": "2022-02-01T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A New Metric for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare ...", "url": "https://towardsdatascience.com/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare-closedloop-ai-fc07b9c83487", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-new-metric-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "<b>Disparate</b> <b>impact</b> occurs when the predicted outcomes are different for different groups. Some examples of when this metric is used are recidivism[4], hiring[5][6], and loan applications[2]. This standard metric accounts for only one factor: the rate at which the algorithm predicts a person should benefit from a particular classification. In the context of healthcare, the standard of <b>disparate</b> <b>impact</b> is entirely inappropriate. The above examples have a common characteristic; every individual ...", "dateLastCrawled": "2022-01-17T14:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "A <b>machine learning</b> technique that iteratively combines a set of simple and not very accurate classifiers ... <b>disparate</b> <b>impact</b>. #fairness. Making decisions about people that <b>impact</b> different population subgroups disproportionately. This usually refers to situations where an algorithmic decision-making process harms or benefits some subgroups more than others. For example, suppose an algorithm that determines a Lilliputian&#39;s eligibility for a miniature-home loan is more likely to classify them ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Assessing <b>Disparate</b> <b>Impact</b> of Personalized Interventions ...", "url": "https://proceedings.neurips.cc/paper/8603-assessing-disparate-impact-of-personalized-interventions-identifiability-and-bounds.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/8603-assessing-<b>disparate</b>-<b>impact</b>-of-personalized...", "snippet": "result in <b>disparate</b> <b>impact</b> (with regards to social welfare) for the same reasons that these disparities occur in <b>machine</b> <b>learning</b> classi\ufb01cation models [21]. (See Appendix C for an expanded discussion on our use of the term \u201c<b>disparate</b> <b>impact</b>.\u201d) However, in the problem of personalized interventions, the \u201cfundamental problem of causal inference,\u201d that outcomes are not observed for interventions not administered, poses a fundamental challenge for evaluating the fairness of any ...", "dateLastCrawled": "2021-09-17T16:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Feature Engineering for Machine Learning</b>: Why and How | by ...", "url": "https://medium.com/analytics-vidhya/feature-engineering-for-machine-learning-stem-to-shtem-submission-76903112e437", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>feature-engineering-for-machine-learning</b>-stem-to...", "snippet": "Here\u2019s a simple <b>analogy</b>: a student named Timmy, analogous to a supervised <b>machine</b> <b>learning</b> model, has spent the last few weeks studying for a math test so that he can answer questions correctly ...", "dateLastCrawled": "2021-09-13T20:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) On the <b>Impact</b> of <b>Machine Learning Architecture without Architects</b>?", "url": "https://www.researchgate.net/publication/335175592_On_the_Impact_of_Machine_Learning_Architecture_without_Architects", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335175592_On_the_<b>Impact</b>_of_<b>Machine</b>_<b>Learning</b>...", "snippet": "3 The <b>Impact</b> of <b>Machine</b> <b>Learning</b> in Architectural Design . Current research [8-13] already illustrates some ML applications in architecture. We . complement t hose studies by hypothesizi ng on ...", "dateLastCrawled": "2021-11-05T03:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Algorithmic injustice: a relational ethics approach", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7892355/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7892355", "snippet": "<b>Machine</b> classification and prediction are practices that act directly upon the world and result in tangible <b>impact</b>.64 Various companies, institutes, and governments use <b>machine</b>-<b>learning</b> systems across a variety of areas. These systems process people&#39;s behaviors, actions, and the social world at large. The <b>machine</b>-detected patterns often provide \u201canswers\u201d to fuzzy, contingent, and open-ended questions. These \u201canswers\u201d neither reveal any causal relations nor provide explanation on why ...", "dateLastCrawled": "2022-01-26T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "Papers on fairness in <b>machine</b> <b>learning</b>, as is common in fields like computer science, abound with formulae. Even the papers referenced here, though selected not for their theorems and proofs but for the ideas they harbor, are no exception. But to start thinking about fairness as it might apply to an ML process at hand, common language \u2013 and common sense \u2013 will do just fine. If, after analyzing your use case, you judge that the more technical results are relevant to the process in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning is Popular</b> Right Now", "url": "https://machinelearningmastery.com/machine-learning-is-popular/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>machine-learning-is-popular</b>", "snippet": "Abundant and cheap computation has driven the abundance of data we are collecting and the increase in capability of <b>machine learning</b> methods. In this post you learned that <b>machine learning is popular</b> now for three reasons: The field has matured both in terms of identity and in terms of methods and tools. There is an abundance of data to learn from.", "dateLastCrawled": "2022-02-03T09:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Structural disconnects between algorithmic decision-making</b> and the law ...", "url": "https://blogs.icrc.org/law-and-policy/2019/04/25/structural-disconnects-algorithmic-decision-making-law/", "isFamilyFriendly": true, "displayUrl": "https://blogs.icrc.org/law-and-policy/2019/04/25/structural-disconnects-algorithmic...", "snippet": "And the definition of \u2018works\u2019 is based on (in the case of <b>machine</b> <b>learning</b>) compliance with some prespecified examples of scenarios that \u2018work\u2019 and scenarios that \u2018don\u2019t\u2019. To use a legal <b>analogy</b>, this would be analogous to defining a fair decision by coming up with a rule based on past decisions that someone decided were \u2018right\u2019 or \u2018wrong\u2019 based on past outcomes. In one sense this is entirely circular: we are deciding what is \u2018right\u2019 based on someone deciding what ...", "dateLastCrawled": "2022-01-25T19:25:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(disparate impact)  is like +(a machine that only selected white people)", "+(disparate impact) is similar to +(a machine that only selected white people)", "+(disparate impact) can be thought of as +(a machine that only selected white people)", "+(disparate impact) can be compared to +(a machine that only selected white people)", "machine learning +(disparate impact AND analogy)", "machine learning +(\"disparate impact is like\")", "machine learning +(\"disparate impact is similar\")", "machine learning +(\"just as disparate impact\")", "machine learning +(\"disparate impact can be thought of as\")", "machine learning +(\"disparate impact can be compared to\")"]}