{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "OpenAI&#39;s new DALL-E AI program generates images of anything with ...", "url": "https://www.dpreview.com/news/9173310557/openai-s-new-dall-e-ai-program-generates-images-of-anything-with-fascinating-success", "isFamilyFriendly": true, "displayUrl": "https://<b>www.dpreview.com</b>/news/9173310557/openai-s-new-dall-e-ai-program-generates...", "snippet": "The attention mask at each of its 64 <b>self-attention</b> layers allows each image token to attend to all text tokens. DALL\u00b7E uses the standard causal mask for the text tokens, and sparse attention for the image tokens with either a row, column, or convolutional attention pattern, depending on the <b>layer</b>.&#39; Further details about DALL-E&#39;s architecture and how OpenAI trained the program will be available in an upcoming paper. An armchair in the shape of an avocado might not be the most practical of ...", "dateLastCrawled": "2021-12-26T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Of Looking Glasses, <b>Mirror</b> Neurons, Culture, and Meaning", "url": "https://www.researchgate.net/publication/274819454_Of_Looking_Glasses_Mirror_Neurons_Culture_and_Meaning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/274819454_Of_Looking_Glasses_<b>Mirror</b>_Neurons...", "snippet": "Many reasons can be assigned for believing that originally <b>self-attention</b> directed . to personal appearance, in relation to the opinion of others, was the exciting cause; the same effect being ...", "dateLastCrawled": "2022-01-28T17:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "MM &#39;20: Proceedings of the 28th ACM International Conference on ...", "url": "http://sigmm.org/opentoc/MM2020-TOC-2", "isFamilyFriendly": true, "displayUrl": "sigmm.org/opentoc/MM2020-TOC-2", "snippet": "Simultaneously, <b>Self-Attention</b> module is introduced to match or outperform their convolutional counterparts, which allows the feature aggregation to adapt to each channel. Furthermore, to improve the basic convolutional feature transformation process of Convolutional Neural Networks (CNNs), Self-Calibrated convolution is applied to build long-range spatial and inter-channel dependencies around each spatial location that explicitly expand fields-of-view of each convolutional <b>layer</b> through ...", "dateLastCrawled": "2022-01-29T07:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Python Machine Learning: Machine Learning and Deep Learning with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with...", "snippet": "<b>While</b> we will cover classification algorithms quite extensively throughout the book, we will <b>also</b> explore different techniques for regression analysis and clustering. We have an exciting journey ahead, covering many powerful techniques in the vast field of machine learning. However, we will approach machine learning one step at a time, building upon our knowledge gradually throughout the chapters of this book. In the following chapter, we will start this journey by implementing one of the ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>The self as phenotype</b> | Request PDF - ResearchGate", "url": "https://www.researchgate.net/publication/49671223_The_self_as_phenotype", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/49671223_<b>The_self_as_phenotype</b>", "snippet": "<b>While</b> <b>watching</b> the stimuli, the infant\u2019s own face was touched either insynchrony or out of synchrony and their preferential looking behaviour was measured.Subsequently, the infants underwent the ...", "dateLastCrawled": "2021-11-11T20:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "ESPnet2 pretrained model, kamo-naoyuki/librispeech_asr_train_asr ...", "url": "https://zenodo.org/record/4604066/", "isFamilyFriendly": true, "displayUrl": "https://zenodo.org/record/4604066", "snippet": "This model was trained by kamo-naoyuki using librispeech recipe in espnet. Python APISee https://github.com/espnet/espnet_model_zoo Evaluate in the recipegit clone ...", "dateLastCrawled": "2021-12-17T00:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>New submissions for Fri, 2 Apr</b> 21 \u00b7 Issue #67 \u00b7 dajinstory/daily-arxiv ...", "url": "https://github.com/dajinstory/daily-arxiv-noti/issues/67", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/dajinstory/daily-arxiv-noti/issues/67", "snippet": "We <b>also</b> provide a method to estimate the surface normal of <b>the mirror</b> from vanishing points in the single image. To validate the proposed approach, we collect a large-scale dataset named Mirrored-Human, which covers a large variety of human subjects, poses and backgrounds. The experiments demonstrate that, when trained on Mirrored-Human with our reconstructed 3D poses as pseudo ground-truth, the accuracy and generalizability of existing single-view 3D pose estimators can be largely improved.", "dateLastCrawled": "2021-08-26T20:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Discontinuity Theory: Cognitive and Social Searches for Rationality and ...", "url": "https://www.sciencedirect.com/science/article/pii/S0065260108602762", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0065260108602762", "snippet": "The chapter <b>also</b> presents experimental investigations that are designed to test predictions about the operation of several kinds of discontinuities and associated search biases. In specific, a theoretical framework is presented to understand the fundamental process of adapting to experiential discontinuities that are of personal significance to one&#39;s self-concept. The central dynamic of this approach is the motivation triggered by perception of a discontinuity, which is defined as a ...", "dateLastCrawled": "2022-01-07T17:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Curse of the <b>Self: Self-Awareness, Egotism, and the Quality</b> of ...", "url": "https://silo.pub/the-curse-of-the-self-self-awareness-egotism-and-the-quality-of-human-life.html", "isFamilyFriendly": true, "displayUrl": "https://silo.pub/the-curse-of-the-<b>self-self-awareness-egotism-and-the-quality</b>-of-human...", "snippet": "Normally, we do not need conscious <b>self-attention</b> in order to walk down the street, but we might <b>like</b> the self to kick in when we must choose our steps carefully to avoid slipping on a patch of ice. Unfortunately, because people\u2019s selves are active even when they are not needed, self-related thought can override automatic reactions that might actually be more effective. One example involves what many people call intuition. Intuition is sometimes viewed as some kind of magical or spiritual ...", "dateLastCrawled": "2022-02-02T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The prospects for a scientific understanding of ... - SelfAwarePatterns", "url": "https://selfawarepatterns.com/2018/07/02/the-prospects-for-a-scientific-understanding-of-consciousness/", "isFamilyFriendly": true, "displayUrl": "https://selfawarepatterns.com/2018/07/02/the-prospects-for-a-scientific-understanding...", "snippet": "It <b>also</b> ties in with all the new neuroscience stuff about predictive processing (which really should be <b>called</b> expectation processing, but ah well). The brain has expectations of what it will see/experience depending on where it looks or what it (the body) does. I think these expectations are just inductive in that the \u201cprediction\u201d is that you will see whatever was there last time you looked, but taking into account things <b>like</b> velocity and time and other context.", "dateLastCrawled": "2022-01-08T19:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "MM &#39;20: Proceedings of the 28th ACM International Conference on ...", "url": "http://sigmm.org/opentoc/MM2020-TOC-2", "isFamilyFriendly": true, "displayUrl": "sigmm.org/opentoc/MM2020-TOC-2", "snippet": "Simultaneously, <b>Self-Attention</b> module is introduced to match or outperform their convolutional counterparts, which allows the feature aggregation to adapt to each channel. Furthermore, to improve the basic convolutional feature transformation process of Convolutional Neural Networks (CNNs), Self-Calibrated convolution is applied to build long-range spatial and inter-channel dependencies around each spatial location that explicitly expand fields-of-view of each convolutional <b>layer</b> through ...", "dateLastCrawled": "2022-01-29T07:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Style Example-Guided Text Generation using Generative Adversarial ...", "url": "https://deepai.org/publication/style-example-guided-text-generation-using-generative-adversarial-transformers", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/style-example-guided-text-generation-using-generative...", "snippet": "Model C: style-aware <b>self-attention</b>. In this model, we input z into each <b>self-attention</b> <b>layer</b> in F g to influence its computation given by S o f t m a x ( q m k T m \u2212 1 \u221a B ) v m \u2212 1 where q m = \u03b7 m ( z ) which \u03b7 m denotes an affine transformation, k m \u2212 1 and v m \u2212 1 denotes the key and value embeddings from the ( m \u2212 1 ) th hidden <b>layer</b>, and B denotes the hidden dimension.", "dateLastCrawled": "2022-01-01T08:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "DALL\u00b7E: Creating Images from Text", "url": "https://openai.com/blog/dall-e/", "isFamilyFriendly": true, "displayUrl": "https://openai.com/blog/dall-e", "snippet": "<b>Similar</b> to what was done before, we prompt DALL\u00b7E to complete the bottom-right corners of a sequence of frames, each of which contains a <b>mirror</b> and reflective floor. <b>While</b> the reflection in <b>the mirror</b> usually resembles the object outside of it, it often does not render the reflection in a physically correct way. By contrast, the reflection of an object drawn on a reflective floor is typically more plausible. navigateupwide. Visualizing Internal and External Structure. The samples from the ...", "dateLastCrawled": "2022-02-03T01:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Recent Advances in Deep Reinforcement Learning Applications for ...", "url": "https://www.academia.edu/68416043/Recent_Advances_in_Deep_Reinforcement_Learning_Applications_for_Solving_Partially_Observable_Markov_Decision_Processes_POMDP_Problems_Part_1_Fundamentals_and_Applications_in_Games_Robotics_and_Natural_Language_Processing", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/68416043/Recent_Advances_in_Deep_Reinforcement_Learning...", "snippet": "The first part of a two-part series of papers provides a survey on recent advances in Deep Reinforcement Learning (DRL) applications for solving partially observable Markov decision processes (POMDP) problems. Reinforcement Learning (RL) is an", "dateLastCrawled": "2022-01-26T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Python Machine Learning: Machine Learning and Deep Learning with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with...", "snippet": "<b>While</b> we will cover classification algorithms quite extensively throughout the book, we will <b>also</b> explore different techniques for regression analysis and clustering. We have an exciting journey ahead, covering many powerful techniques in the vast field of machine learning. However, we will approach machine learning one step at a time, building upon our knowledge gradually throughout the chapters of this book. In the following chapter, we will start this journey by implementing one of the ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "GitHub - <b>rvsrnvsn/ICML2019</b>: Notes from ICML 2019 (Jun 10-15, Long Beach ...", "url": "https://github.com/rvsrnvsn/ICML2019", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/rvsrnvsn/ICML2019", "snippet": "Add <b>self-attention</b> blocks to generator and discriminator; Spectral normalization; Different learning rate for generator and discriminator ; Convolutions excel at synthesizing image classes with few structural constrains, but fail to capture geometric or structural patterns For example, images of dogs should generally have four legs; <b>Self-attention</b> can capture long-range dependencies more efficiently Here, use softmax for attention weights over locations; This allows generator to allocate ...", "dateLastCrawled": "2021-12-12T14:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Crucial considerations in the understanding and</b> ... - Academia.edu", "url": "https://www.academia.edu/37206534/Crucial_considerations_in_the_understanding_and_treatment_of_intimate_partner_violence_in_African_American_couples", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/37206534/<b>Crucial_considerations_in_the_understanding_and</b>...", "snippet": "The purpose of this chapter is to provide a brief overview of prevalence rates of intimate partner violence among African Americans, describe an ecological model, which is a more comprehensive theoretical approach to understanding the risk factors", "dateLastCrawled": "2022-01-26T09:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Curse of the <b>Self: Self-Awareness, Egotism, and the Quality</b> of ...", "url": "https://silo.pub/the-curse-of-the-self-self-awareness-egotism-and-the-quality-of-human-life.html", "isFamilyFriendly": true, "displayUrl": "https://silo.pub/the-curse-of-the-<b>self-self-awareness-egotism-and-the-quality</b>-of-human...", "snippet": "In such cases, the self not only fails to help performance but dramatically hinders it.12 Many complex behaviors initially require a great deal of effort and attention to learn successfully, but once mastered, they can be executed skillfully without <b>self-attention</b>. After people have learned to play the piano, shoot a free throw in basketball, or recite the Gettysburg Address, for example, they do not need a self to execute the behavior. They may need the self to decide to initiate the action ...", "dateLastCrawled": "2022-02-02T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "MetaVD: A Meta Video Dataset for enhancing human action recognition ...", "url": "https://www.sciencedirect.com/science/article/pii/S107731422100120X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S107731422100120X", "snippet": "As assigning annotation by <b>watching</b> the videos is time-consuming, we simplified the task and asked annotators to give relation labels based on the linguistic meaning of the action labels. Consequently, 986 out of 1,309 unique action labels defined by the six datasets are annotated with either equal, <b>similar</b>, or is-a. The annotation work was performed by seven annotators in parallel. Subsequently, another annotator verified the assigned annotations and rectified any mistakes. The boundaries ...", "dateLastCrawled": "2022-02-02T18:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "IDW &#39;21 Final Program", "url": "https://www.idw.or.jp/finalprogram.html", "isFamilyFriendly": true, "displayUrl": "https://www.idw.or.jp/finalprogram.html", "snippet": "By combining our 8K technology with the newly developed Dual-Cell technology, we have developed a display that achieves high resolution and high contrast ratio of over 1,000,000 : 1. In addition, a 3-<b>layer</b> <b>driving</b> technology that combines this 8K Dual-Cell with a local dimming backlight has realized ultra-high contrast ratio of over 2,000,000: 1.", "dateLastCrawled": "2022-02-03T13:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "MM &#39;20: Proceedings of the 28th ACM International Conference on ...", "url": "http://sigmm.org/opentoc/MM2020-TOC-2", "isFamilyFriendly": true, "displayUrl": "sigmm.org/opentoc/MM2020-TOC-2", "snippet": "Simultaneously, <b>Self-Attention</b> module is introduced to match or outperform their convolutional counterparts, which allows the feature aggregation to adapt to each channel. Furthermore, to improve the basic convolutional feature transformation process of Convolutional Neural Networks (CNNs), Self-Calibrated convolution is applied to build long-range spatial and inter-channel dependencies around each spatial location that explicitly expand fields-of-view of each convolutional <b>layer</b> through ...", "dateLastCrawled": "2022-01-29T07:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "OpenAI&#39;s new DALL-E AI program generates images of anything with ...", "url": "https://www.dpreview.com/news/9173310557/openai-s-new-dall-e-ai-program-generates-images-of-anything-with-fascinating-success", "isFamilyFriendly": true, "displayUrl": "https://<b>www.dpreview.com</b>/news/9173310557/openai-s-new-dall-e-ai-program-generates...", "snippet": "The attention mask at each of its 64 <b>self-attention</b> layers allows each image token to attend to all text tokens. DALL\u00b7E uses the standard causal mask for the text tokens, and sparse attention for the image tokens with either a row, column, or convolutional attention pattern, depending on the <b>layer</b>.&#39; Further details about DALL-E&#39;s architecture and how OpenAI trained the program will be available in an upcoming paper. An armchair in the shape of an avocado might not be the most practical of ...", "dateLastCrawled": "2021-12-26T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Style Example-Guided Text Generation using Generative Adversarial ...", "url": "https://deepai.org/publication/style-example-guided-text-generation-using-generative-adversarial-transformers", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/style-example-guided-text-generation-using-generative...", "snippet": "Model C: style-aware <b>self-attention</b>. In this model, we input z into each <b>self-attention</b> <b>layer</b> in F g to influence its computation given by S o f t m a x (q m k T m \u2212 1 \u221a B) v m \u2212 1 where q m = \u03b7 m (z) which \u03b7 m denotes an affine transformation, k m \u2212 1 and v m \u2212 1 denotes the key and value embeddings from the (m \u2212 1) th hidden ...", "dateLastCrawled": "2022-01-01T08:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "MM &#39;19- Proceedings of <b>the 27th ACM International Conference</b> on ...", "url": "http://www.sigmm.org/opentoc/MM2019-TOC", "isFamilyFriendly": true, "displayUrl": "www.sigmm.org/opentoc/MM2019-TOC", "snippet": "In TPPA, we apply the <b>self-attention</b> mechanism between local regions at the same position across temporal frames to capture the interaction impacts. Meanwhile, to deal with video redundancy and capture long-range context, the TPPA is extended to the Random Frames based Bootstrapping Attention (RFBA) framework. <b>While</b> the bootstrapping sampling frames have the same distribution of the whole video sequence, the RFBA not only captures longer temporal context with only a few sampling frames but ...", "dateLastCrawled": "2022-01-11T13:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>The self as phenotype</b> | Request PDF - ResearchGate", "url": "https://www.researchgate.net/publication/49671223_The_self_as_phenotype", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/49671223_<b>The_self_as_phenotype</b>", "snippet": "It <b>can</b> <b>also</b> feel and integrate multiple sensory modalities. It <b>can</b> remember vowels as well as the language rhythms and jingles it has heard before birth. However, it cannot speak, remember ...", "dateLastCrawled": "2021-11-11T20:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "NeurIPS 2021 papers", "url": "https://tanelp.github.io/neurips2021/", "isFamilyFriendly": true, "displayUrl": "https://tanelp.github.io/neurips2021", "snippet": "Our approach uses <b>self-attention</b> to reason about relationships between datapoints explicitly, which <b>can</b> be seen as realizing non-parametric models using parametric attention mechanisms. However, unlike conventional non-parametric models, we let the model learn end-to-end from the data how to make use of other datapoints for prediction. Empirically, our models solve cross-datapoint lookup and complex reasoning tasks unsolvable by traditional deep learning models. We show highly competitive ...", "dateLastCrawled": "2022-02-03T00:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Python Machine Learning: Machine Learning and Deep Learning with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with...", "snippet": "Unsupervised dimensionality reduction is a commonly used approach in feature preprocessing to remove noise from data, which <b>can</b> <b>also</b> degrade the predictive performance of certain algorithms, and compress the data onto a smaller dimensional subspace <b>while</b> retaining most of the relevant information. Sometimes, dimensionality reduction <b>can</b> <b>also</b> be useful for visualizing data; for example, a high-dimensional feature set <b>can</b> be projected onto one-, two-, or three-dimensional feature spaces in ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Crucial considerations in the understanding and</b> ... - Academia.edu", "url": "https://www.academia.edu/37206534/Crucial_considerations_in_the_understanding_and_treatment_of_intimate_partner_violence_in_African_American_couples", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/37206534/<b>Crucial_considerations_in_the_understanding_and</b>...", "snippet": "The purpose of this chapter is to provide a brief overview of prevalence rates of intimate partner violence among African Americans, describe an ecological model, which is a more comprehensive theoretical approach to understanding the risk factors", "dateLastCrawled": "2022-01-26T09:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The prospects for a scientific understanding of ... - SelfAwarePatterns", "url": "https://selfawarepatterns.com/2018/07/02/the-prospects-for-a-scientific-understanding-of-consciousness/", "isFamilyFriendly": true, "displayUrl": "https://selfawarepatterns.com/2018/07/02/the-prospects-for-a-scientific-understanding...", "snippet": "It <b>also</b> ties in with all the new neuroscience stuff about predictive processing (which really should be <b>called</b> expectation processing, but ah well). The brain has expectations of what it will see/experience depending on where it looks or what it (the body) does. I think these expectations are just inductive in that the \u201cprediction\u201d is that you will see whatever was there last time you looked, but taking into account things like velocity and time and other context.", "dateLastCrawled": "2022-01-08T19:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Women In Real Life | A WordPress Site | Page 5", "url": "https://blog.womenexplode.com/category/women-in-real-life/page/5/", "isFamilyFriendly": true, "displayUrl": "https://blog.womenexplode.com/category/women-in-real-life/page/5", "snippet": "We went <b>driving</b> around the hills of our neighborhood in the dark when there was a bit of ice and snow on the streets. We drove around for a <b>while</b> just fine and it was fun. Then, in an instant we hit an ice patch and the car slid a bit off the road. I\u2019m scared but everyone else <b>thought</b> it was fun and were squealing with excitement and laughter. One of the car\u2019s tires got stuck in some mud. I gunned the car and it didn\u2019t move. I am freaking out inside, but try not to show it. Now ...", "dateLastCrawled": "2021-12-11T06:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "MM &#39;20: Proceedings of the 28th ACM International Conference on ...", "url": "http://sigmm.org/opentoc/MM2020-TOC-2", "isFamilyFriendly": true, "displayUrl": "sigmm.org/opentoc/MM2020-TOC-2", "snippet": "Simultaneously, <b>Self-Attention</b> module is introduced to match or outperform their convolutional counterparts, which allows the feature aggregation to adapt to each channel. Furthermore, to improve the basic convolutional feature transformation process of Convolutional Neural Networks (CNNs), Self-Calibrated convolution is applied to build long-range spatial and inter-channel dependencies around each spatial location that explicitly expand fields-of-view of each convolutional <b>layer</b> through ...", "dateLastCrawled": "2022-01-29T07:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "OpenAI&#39;s new DALL-E AI program generates images of anything with ...", "url": "https://www.dpreview.com/news/9173310557/openai-s-new-dall-e-ai-program-generates-images-of-anything-with-fascinating-success", "isFamilyFriendly": true, "displayUrl": "https://<b>www.dpreview.com</b>/news/9173310557/openai-s-new-dall-e-ai-program-generates...", "snippet": "The attention mask at each of its 64 <b>self-attention</b> layers allows each image token to attend to all text tokens. DALL\u00b7E uses the standard causal mask for the text tokens, and sparse attention for the image tokens with either a row, column, or convolutional attention pattern, depending on the <b>layer</b>.&#39; Further details about DALL-E&#39;s architecture and how OpenAI trained the program will be available in an upcoming paper. An armchair in the shape of an avocado might not be the most practical of ...", "dateLastCrawled": "2021-12-26T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Style Example-Guided Text Generation using Generative Adversarial ...", "url": "https://deepai.org/publication/style-example-guided-text-generation-using-generative-adversarial-transformers", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/style-example-guided-text-generation-using-generative...", "snippet": "Model C: style-aware <b>self-attention</b>. In this model, we input z into each <b>self-attention</b> <b>layer</b> in F g to influence its computation given by S o f t m a x (q m k T m \u2212 1 \u221a B) v m \u2212 1 where q m = \u03b7 m (z) which \u03b7 m denotes an affine transformation, k m \u2212 1 and v m \u2212 1 denotes the key and value embeddings from the (m \u2212 1) th hidden ...", "dateLastCrawled": "2022-01-01T08:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Recent Advances in Deep Reinforcement Learning Applications for ...", "url": "https://www.academia.edu/68416043/Recent_Advances_in_Deep_Reinforcement_Learning_Applications_for_Solving_Partially_Observable_Markov_Decision_Processes_POMDP_Problems_Part_1_Fundamentals_and_Applications_in_Games_Robotics_and_Natural_Language_Processing", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/68416043/Recent_Advances_in_Deep_Reinforcement_Learning...", "snippet": "The first part of a two-part series of papers provides a survey on recent advances in Deep Reinforcement Learning (DRL) applications for solving partially observable Markov decision processes (POMDP) problems. Reinforcement Learning (RL) is an", "dateLastCrawled": "2022-01-26T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "ESPnet2 pretrained model, Shinji Watanabe/gigaspeech_asr_train_asr_raw ...", "url": "https://zenodo.org/record/4630406", "isFamilyFriendly": true, "displayUrl": "https://zenodo.org/record/4630406", "snippet": "This model was trained by Shinji Watanabe using gigaspeech recipe in espnet. Python API See https://github.com/espnet/espnet_model_zoo Evaluate in the recipe git ...", "dateLastCrawled": "2022-01-31T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Python Machine Learning: Machine Learning and Deep Learning with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with...", "snippet": "The class labels are predicted by the predict method, which is <b>called</b> in the fit method during training to get the class label for the weight update; but predict <b>can</b> <b>also</b> be used to predict the class labels of new data after we have fitted our model. Furthermore, we <b>also</b> collect the number of misclassifications during each epoch in the self.errors_ list so that we <b>can</b> later analyze how well our perceptron performed during the training. The np.dot function that is used in the net_input method ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "NeurIPS 2021 papers", "url": "https://tanelp.github.io/neurips2021/?s=09", "isFamilyFriendly": true, "displayUrl": "https://tanelp.github.io/neurips2021/?s=09", "snippet": "Our approach uses <b>self-attention</b> to reason about relationships between datapoints explicitly, which <b>can</b> be seen as realizing non-parametric models using parametric attention mechanisms. However, unlike conventional non-parametric models, we let the model learn end-to-end from the data how to make use of other datapoints for prediction. Empirically, our models solve cross-datapoint lookup and complex reasoning tasks unsolvable by traditional deep learning models. We show highly competitive ...", "dateLastCrawled": "2022-02-03T07:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>The self as phenotype</b> | Request PDF - ResearchGate", "url": "https://www.researchgate.net/publication/49671223_The_self_as_phenotype", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/49671223_<b>The_self_as_phenotype</b>", "snippet": "It <b>can</b> <b>also</b> feel and integrate multiple sensory modalities. It <b>can</b> remember vowels as well as the language rhythms and jingles it has heard before birth. However, it cannot speak, remember ...", "dateLastCrawled": "2021-11-11T20:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>New submissions for Fri, 2 Apr</b> 21 \u00b7 Issue #67 \u00b7 dajinstory/daily-arxiv ...", "url": "https://github.com/dajinstory/daily-arxiv-noti/issues/67", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/dajinstory/daily-arxiv-noti/issues/67", "snippet": "<b>Compared</b> to general scenarios of 3D pose estimation from a single view, <b>the mirror</b> reflection provides an additional view for resolving the depth ambiguity. We develop an optimization-based approach that exploits <b>mirror</b> symmetry constraints for accurate 3D pose reconstruction. We <b>also</b> provide a method to estimate the surface normal of <b>the mirror</b> from vanishing points in the single image. To validate the proposed approach, we collect a large-scale dataset named Mirrored-Human, which covers a ...", "dateLastCrawled": "2021-08-26T20:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Crucial considerations in the understanding and</b> ... - Academia.edu", "url": "https://www.academia.edu/37206534/Crucial_considerations_in_the_understanding_and_treatment_of_intimate_partner_violence_in_African_American_couples", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/37206534/<b>Crucial_considerations_in_the_understanding_and</b>...", "snippet": "The purpose of this chapter is to provide a brief overview of prevalence rates of intimate partner violence among African Americans, describe an ecological model, which is a more comprehensive theoretical approach to understanding the risk factors", "dateLastCrawled": "2022-01-26T09:04:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>learning</b> glossary - DataTime", "url": "https://www.dtalg.com/article-1/", "isFamilyFriendly": true, "displayUrl": "https://www.dtalg.com/article-1", "snippet": "<b>self-attention</b> (<b>also</b> <b>called</b> <b>self-attention</b> <b>layer</b>) #language. A neural network <b>layer</b> that transforms a sequence of embeddings (for instance, token embeddings) into another sequence of embeddings. Each embedding in the output sequence is constructed by integrating information from the elements of the input sequence through an attention mechanism.", "dateLastCrawled": "2022-01-25T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Attention in Psychology, Neuroscience, and <b>Machine</b> <b>Learning</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7177153/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7177153", "snippet": "These weightings scale the word encodings themselves to create the next <b>layer</b> in the model, a process known as \u201c<b>self-attention</b>.\u201d This process repeats, and eventually interacts with the autoregressive decoder which <b>also</b> has attention mechanisms that allow it to flexibly focus on the encoded input (as in the standard form of attention) and on the previously generated output. The Transformer\u2014the name given to this new attention architecture\u2014outperformed many previous models and quickly ...", "dateLastCrawled": "2021-12-27T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "10.6. <b>Self-Attention</b> and <b>Positional Encoding</b> \u2014 Dive into Deep <b>Learning</b> ...", "url": "http://d2l.ai/chapter_attention-mechanisms/self-attention-and-positional-encoding.html", "isFamilyFriendly": true, "displayUrl": "d2l.ai/chapter_attention-mechanisms/<b>self-attention</b>-and-<b>positional-encoding</b>.html", "snippet": "In deep <b>learning</b>, we often use CNNs or RNNs to encode a sequence. Now with attention mechanisms, imagine that we feed a sequence of tokens into attention pooling so that the same set of tokens act as queries, keys, and values. Specifically, each query attends to all the key-value pairs and generates one attention output. Since the queries, keys, and values come from the same place, this performs <b>self-attention</b> [Lin et al., 2017b] [Vaswani et al., 2017], which is <b>also</b> <b>called</b> intra-attention ...", "dateLastCrawled": "2022-02-02T23:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Enhancing LSTM Models with <b>Self-attention</b> and Stateful Training ...", "url": "https://www.academia.edu/69040947/Enhancing_LSTM_Models_with_Self_attention_and_Stateful_Training", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69040947/Enhancing_LSTM_Models_with_<b>Self_attention</b>_and_Statef...", "snippet": "<b>Self-attention</b>, <b>also</b> known as intra-attention, is an attention mechanism relat- ing di\ufb00erent positions of a sequence in order to model dependencies between dif- ferent parts of the sequence. This di\ufb00ers from general attention in that instead of seeking to discover the \u201cimportant\u201d parts of the sequence relating to the net- work output, <b>self-attention</b> seeks to \ufb01nd the \u201cimportant\u201d portions of the sequence that relate to each other. This is done in order to leverage those intra ...", "dateLastCrawled": "2022-02-03T12:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Lecture 7: Transformers</b> - Deep <b>Learning</b>", "url": "https://chinmayhegde.github.io/dl-notes/notes/lecture07/", "isFamilyFriendly": true, "displayUrl": "https://chinmayhegde.github.io/dl-notes/notes/lecture07", "snippet": "<b>Self-Attention</b>. This is the point where papers-blogs-tweets-slides etc start talking about keys/values and attention mechanisms and everything goes a bit haywire. Let\u2019s just ignore all that for now, and instead talk about something <b>called</b> <b>self-attention</b>. The use of the \u201cself-\u201c prefix will become clear later on. Here is how it is defined.", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning Papers: Molecules</b> - <b>Machine Learning</b> Applied", "url": "https://machinelearningapplied.com/machine-learning-papers-molecules/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>applied.com/<b>machine-learning-papers-molecules</b>", "snippet": "A <b>self-attention</b> based message passing neural network for predicting molecular lipophilicity and aqueous solubility - Tang et al 2020 . Efficient and accurate prediction of molecular properties, such as lipophilicity and solubility, is highly desirable for rational compound design in chemical and pharmaceutical industries. To this end, we build and apply a graph-neural-network framework <b>called</b> <b>self-attention</b>-based message-passing neural network (SAMPN) to study the relationship between ...", "dateLastCrawled": "2021-12-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Transformers in NLP: A beginner friendly explanation | Towards Data Science", "url": "https://towardsdatascience.com/transformers-89034557de14", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>transformer</b>s-89034557de14", "snippet": "<b>Self attention</b>, sometimes <b>called</b> intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. In simpler terms, <b>self attention</b> helps us create similar connections but within the same sentence. Look at the following example: \u201cI poured water from the bottle into the cup until it was full.\u201d it =&gt; cup \u201cI poured water from the bottle into the cup until it was empty.\u201d it=&gt; bottle. By changing one word ...", "dateLastCrawled": "2022-02-02T13:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Attending to Attention. A summary of a revolutionary paper\u2026 | by Akash ...", "url": "https://towardsdatascience.com/attending-to-attention-eba798f0e940", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/attending-to-attention-eba798f0e940", "snippet": "The encoder is composed of a stack of N = 6 identical layers. Each <b>layer</b> has two sub-layers. The first is a multi-head <b>self-attention</b> mechanism, and the second is a simple, position-wise fully connected feed-forward network. We employ a residual connection around each of the two sub-layers, followed by <b>layer</b> normalization. That is, the output ...", "dateLastCrawled": "2022-01-25T10:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Enhancing LSTM Models with <b>Self-attention</b> and Stateful Training", "url": "https://www.researchgate.net/publication/353690477_Enhancing_LSTM_Models_with_Self-attention_and_Stateful_Training", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353690477_Enhancing_LSTM_Models_with_Self...", "snippet": "<b>Self-attention</b>, <b>also</b> known as in tra-attention, is an attention mec hanism re- lating di\ufb00erent positions of a sequence in order to model dependencies b etween di\ufb00erent parts of the sequence.", "dateLastCrawled": "2022-01-13T05:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Journal of Physics: Conference Series PAPER OPEN ACCESS You may <b>also</b> ...", "url": "https://iopscience.iop.org/article/10.1088/1742-6596/1651/1/012019/pdf", "isFamilyFriendly": true, "displayUrl": "https://iopscience.iop.org/article/10.1088/1742-6596/1651/1/012019/pdf", "snippet": "Different <b>machine</b> <b>learning</b> techniques have been used in this field for many years. But recently, deep <b>learning</b> has caused more and more attention in the field of education. Deep <b>learning</b> is a <b>machine</b> <b>learning</b> method based on neural network structure of multi-<b>layer</b> processing units, and it has been successfully applied to a series of problems in the field of image recognition and natural language processing[2]. With the diversified cultivation of traditional universities and the development ...", "dateLastCrawled": "2021-12-29T04:07:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(self-attention (also called self-attention layer))  is like +(watching the mirror while driving)", "+(self-attention (also called self-attention layer)) is similar to +(watching the mirror while driving)", "+(self-attention (also called self-attention layer)) can be thought of as +(watching the mirror while driving)", "+(self-attention (also called self-attention layer)) can be compared to +(watching the mirror while driving)", "machine learning +(self-attention (also called self-attention layer) AND analogy)", "machine learning +(\"self-attention (also called self-attention layer) is like\")", "machine learning +(\"self-attention (also called self-attention layer) is similar\")", "machine learning +(\"just as self-attention (also called self-attention layer)\")", "machine learning +(\"self-attention (also called self-attention layer) can be thought of as\")", "machine learning +(\"self-attention (also called self-attention layer) can be compared to\")"]}