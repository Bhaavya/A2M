{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High model <b>interpretability</b> wins arguments. Risk and responsibility. A model with high <b>interpretability</b> is desirable on a high-risk stakes game. High interpretable models equate to <b>being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Teaching Machines <b>to Read</b> <b>Movie Reviews: Thinking About Interpretability</b>", "url": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about-interpretability-63c12248b8e5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/teaching-machines-<b>to-read</b>-movie-reviews-thinking-about...", "snippet": "Model Accuracy vs <b>Interpretability</b>. Using stance categories (the lexicogramatical level of language) as features doesn\u2019t improve performance over a word-based model: Random Forest using stance vectors (image by author) Again reading diagonally from left to right, the stance-based model is about 80% accurate predicting positive reviews, and around 73% accurate with negative reviews. So from a pure performance perspective, using stance hurts performance. But insight is a very different story ...", "dateLastCrawled": "2022-01-19T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability, Explainability, and Machine Learning</b> | Insights ...", "url": "https://www.insightsassociation.org/article/interpretability-explainability-and-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.insightsassociation.org/article/<b>interpretability</b>-explainability-and...", "snippet": "Let\u2019s take a closer look at <b>interpretability</b> and explainability with regard to machine learning models. Imagine I were to create a highly accurate model for predicting a disease diagnosis based on symptoms, family history and so forth. If I created a logistic regression model for this purpose, you would be <b>able</b> to see exactly what weights ...", "dateLastCrawled": "2022-01-17T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretability</b> Models with Hermione | by Gustavo Resende | A3data ...", "url": "https://medium.com/a3data/interpretability-models-with-hermione-6f02e1bb4e43", "isFamilyFriendly": true, "displayUrl": "https://medium.com/a3data/<b>interpretability</b>-models-with-hermione-6f02e1bb4e43", "snippet": "<b>Interpretability</b> Models with Hermione. Hermione is an open-source library released in 2020 that helps Data Scientists on setting up more organized codes, quickly and simply. Besides, there are ...", "dateLastCrawled": "2021-12-30T16:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding the difference between <b>interpretability</b> and ...", "url": "https://subscription.packtpub.com/book/data/9781800203907/2/ch02lvl1sec05/understanding-the-difference-between-interpretability-and-explainability", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/<b>book</b>/data/9781800203907/2/ch02lvl1sec05/...", "snippet": "Design transparency: <b>Being</b> <b>able</b> to explain choices made, such as model architecture and hyperparameters. For instance, we could justify these choices based on the size or nature of the training data. If we were performing a sales forecast and we knew that our sales had a seasonality of 12 months, this could be a sound parameter choice. If we had doubts, we could always use some well-established statistical method to find the right seasonality.", "dateLastCrawled": "2021-12-29T16:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretability</b>, Explainability, and Machine Lear... - Alteryx Community", "url": "https://community.alteryx.com/t5/Data-Science/Interpretability-Explainability-and-Machine-Learning/ba-p/630765", "isFamilyFriendly": true, "displayUrl": "https://community.alteryx.com/t5/<b>Data-Science</b>/<b>Interpretability</b>-Explainability-and...", "snippet": "Whichever method is used to gain insight into a model\u2019s operation, <b>being</b> <b>able</b> to discuss how it makes predictions with stakeholders is important for improving the model with their informed input, ensuring the model\u2019s fairness, and increasing trust in its output. This need for insight into the model might make you wonder if black boxes are worth the challenges they pose.", "dateLastCrawled": "2022-01-17T20:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretability</b>, Explainability, and Machine Learning \u2013 What Data ...", "url": "https://www.kdnuggets.com/2020/11/interpretability-explainability-machine-learning.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/11/<b>interpretability</b>-explainability-machine-learning.html", "snippet": "Whichever method is used to gain insight into a model\u2019s operation, <b>being</b> <b>able</b> to discuss how it makes predictions with stakeholders is important for improving the model with their informed input, ensuring the model\u2019s fairness, and increasing trust in its output. This need for insight into the model might make you wonder if black boxes are worth the challenges they pose.", "dateLastCrawled": "2022-01-25T14:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What everyone <b>needs to know about interpretability in machine learning</b> ...", "url": "https://dallascard.medium.com/what-everyone-needs-to-know-about-interpretability-in-machine-learning-d5ce16730407", "isFamilyFriendly": true, "displayUrl": "https://dallascard.medium.com/what-everyone-<b>needs-to-know-about-interpretability</b>-in...", "snippet": "In addition to the supposedly delightful videos of children trying to fight their instincts, this experiment produced the finding that those who are <b>able</b> to delay their gratification will have better life outcomes in various ways (on average). Although one interpretation is that eating the marshmallow somehow made things worse for those who could not resist doing so, a much more reasonable interpretation is that there is some latent property which is <b>being</b> measured, such as self-control, and ...", "dateLastCrawled": "2022-01-12T04:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Model <b>Interpretability</b>. With the advancement in Machine\u2026 | by Sumedh ...", "url": "https://smdhtelang2.medium.com/model-interpretability-da57f807c42a", "isFamilyFriendly": true, "displayUrl": "https://smdhtelang2.medium.com/model-<b>interpretability</b>-da57f807c42a", "snippet": "Model <b>Interpretability</b>. With the advancement in Machine Learning where machine learning is <b>able</b> to solve the most complex problems in the world highly accurately, the need to understand the complexity of the black-box model working is increasing every day. In this article, I will be shedding light on some of the model agnostic methods <b>like</b> SHAP ...", "dateLastCrawled": "2022-01-21T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Model interpretation and data valuation for machine learning (<b>Book</b> ...", "url": "https://www.worldcat.org/title/model-interpretation-and-data-valuation-for-machine-learning/oclc/1255184724", "isFamilyFriendly": true, "displayUrl": "https://www.worldcat.org/title/model-interpretation-and-data-valuation-for-machine...", "snippet": "Machine learning is <b>being</b> applied in various critical applications <b>like</b> healthcare. In order to be <b>able</b> to trust a machine learning model and to repair it once it malfunctions, it is important to be <b>able</b> to interpret its decision-making. For example, if a model&#39;s performance is poor on a specific subgroup (gender, race, etc), it is important to find out why and fix it. In this thesis, we examine the drawbacks of existing <b>interpretability</b> methods and introduce new ML <b>interpretability</b> ...", "dateLastCrawled": "2021-10-17T14:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "A model that provided <b>similar</b> explanations would be more useful than one that just provided predictions. ... we\u2019ll explain in more detail what is meant by <b>interpretability</b>. We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High model <b>interpretability</b> wins arguments. Risk and responsibility. A model with high <b>interpretability</b> is desirable on a high-risk stakes game. High interpretable models equate <b>to being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "As such, we believe that the true benefit of an <b>interpretability</b> framework is <b>being</b> <b>able</b> to formalize these different aspects of <b>interpretability</b>, then pick the most relevant method. The claim \u201cyou should use SHAP because it makes your model more interpretable\u201d is largely useless. However, the claim \u201cyou should use SHAP because the decomposability it offers is worth the risk of using a post-hoc explanation\u201d makes clear both the benefits and risks of SHAP.", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Model <b>Interpretability</b>. With the advancement in Machine\u2026 | by Sumedh ...", "url": "https://smdhtelang2.medium.com/model-interpretability-da57f807c42a", "isFamilyFriendly": true, "displayUrl": "https://smdhtelang2.medium.com/model-<b>interpretability</b>-da57f807c42a", "snippet": "Model <b>Interpretability</b>. Sumedh Telang. Dec 20, 2020 \u00b7 6 min <b>read</b>. Source: Majemo/GettyImages. With the advancement in Machine Learning where machine learning is <b>able</b> to solve the most complex problems in the world highly accurately, the need to understand the complexity of the black-box model working is increasing every day. In this article, I will be shedding light on some of the model agnostic methods like SHAP, LIME, Anchor, etc on the tabular dataset. In this article, I used Adult ...", "dateLastCrawled": "2022-01-21T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Best Machine Learning Books</b> (Updated for 2020)", "url": "https://blog.floydhub.com/best-machine-learning-books/", "isFamilyFriendly": true, "displayUrl": "https://blog.floydhub.com/<b>best-machine-learning-books</b>", "snippet": "Why you should <b>read</b> it: <b>Interpretability</b> is rapidly becoming a hot topic to solve in Deep Learning. Unboxing the black box is still an active research area for Deep Learning, but luckily for Machine Learning models, we actually have more tools available \u2014 this <b>being</b> one of the best ones. Where you can get it: Buy on LeanPub or Lulu (paperback version). You can also <b>read</b> it for free, but if you like it, please support the author. 2 years, 250 pages, 1,219 commits, and 78,480 words: I am ...", "dateLastCrawled": "2022-02-02T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Chapter 16 Interpretable Machine Learning</b> | Hands-On Machine Learning ...", "url": "https://bradleyboehmke.github.io/HOML/iml.html", "isFamilyFriendly": true, "displayUrl": "https://bradleyboehmke.github.io/HOML/iml.html", "snippet": "<b>Being</b> <b>able</b> to answer such questions and provide both levels of explanation is key to any ML project becoming accepted, adopted, embedded, and properly utilized. 16.2.1 Global interpretation Global <b>interpretability</b> is about understanding how the model makes predictions, based on a holistic view of its features and how they influence the underlying model structure.", "dateLastCrawled": "2022-02-01T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>How important is interpretability for a</b> model in Machine Learning? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-model-in-Machine-Learning", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Against <b>Interpretability</b>: a Critical Examination of the ...", "url": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "snippet": "The first section argued that the concepts of <b>interpretability</b> and cognates lack the kind of definition that would render them adequate to the kind of work that their proponents want them to do, and also suggested that <b>interpretability</b> may end up <b>being</b> of more limited use than is often thought. The second section argued that since <b>interpretability</b> is most often proposed as a means to further ends rather than an end in itself, it would be more perspicuous to organize discussion around the ...", "dateLastCrawled": "2021-12-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What makes <b>interpretability</b> in neural networks difficult? - Quora", "url": "https://www.quora.com/What-makes-interpretability-in-neural-networks-difficult", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-makes-<b>interpretability</b>-in-neural-networks-difficult", "snippet": "Answer (1 of 2): The ultimate goal of machine learning (or statistics), many would argue, is to build insight into some phenomenon. Thus far, the ML community has largely been obsessed with predictive accuracy. If you <b>read</b> the many papers in different subfields of ML at leading conferences, like ...", "dateLastCrawled": "2022-01-13T06:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Interpretability</b> 2020", "url": "https://ff06-2020.fastforwardlabs.com/", "isFamilyFriendly": true, "displayUrl": "https://ff06-2020.fastforwardlabs.com", "snippet": "<b>Read</b> our full report on <b>interpretability</b> below or download the PDF. For this report we built an <b>interpretability</b> prototype: Refractor. Introduction . Our society is increasingly dependent on intelligent machines. Algorithms govern everything from which e-mails reach our inboxes to whether we are approved for credit to whom we get the opportunity to date \u2013 and their impact on our experience of the world is growing. FIGURE 1.1 As algorithmic systems become more prevalent, the need to ...", "dateLastCrawled": "2022-01-16T21:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of model <b>interpretability</b> and how it relates to interpretable and explainable machine learning. To summarise, <b>interpretability</b> is the degree to which a model <b>can</b> be understood ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High interpretable models equate to <b>being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was made. Highly interpretable models, and maintaining high <b>interpretability</b> as a design standard, <b>can</b> help build trust between engineers and users. It\u2019s bad enough when the chain of command prevents a person from <b>being</b> <b>able</b> to speak to the party responsible for making the decision. It is much worse ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "These explanations help us and others determine whether a decision or <b>thought</b> was fair, logical, or well-<b>thought</b>-out. This form of post-hoc explanation applies to model <b>interpretability</b> as well. Post-hoc explanations are methods by which what models have learned <b>can</b> be visualized. Common examples are: Text explanations: Similar to how humans justify decisions verbally. An explanation- or text-generating model is trained in tandem with the prediction model. Visualization: Qualitative ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to measure <b>interpretability</b>?. Today almost everyone uses ...", "url": "https://towardsdatascience.com/how-to-measure-interpretability-d93237b23cd3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-measure-<b>interpretability</b>-d93237b23cd3", "snippet": "Then the question of <b>interpretability</b> arises. ... Finally, considering a set of tree-based algorithms and rule-based algorithm, I am <b>able</b> to point out the most interpretable one by using a convex combination of the predictivity, the stability and the simplicity. The coefficients of the combination <b>can</b> be chosen according to your desiderata. For instance, if you try to describe a phenomenon the simplicity and the stability are more important than the predictivity (provided it remains ...", "dateLastCrawled": "2022-02-01T06:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Against <b>Interpretability</b>: a Critical Examination of the ...", "url": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "snippet": "<b>Interpretability</b> is often <b>thought</b> to play an important role in justification in an ML context. It <b>can</b> seem outright irresponsible to believe algorithmic outputs regarding unseen real-world data in the absence of detailed knowledge of the algorithm\u2019s inner workings. However, in some contexts, there are ways of achieving the desired assurance in the absence of knowledge about inner workings of tools. People were both responsible and justified in relying on the deliverances of their eyes ...", "dateLastCrawled": "2021-12-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How important is <b>interpretability</b> for a model in Machine Learning ...", "url": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-<b>interpretability</b>-for...", "snippet": "It <b>can</b> be even used by systems without operating system, example <b>being</b> compiled and fabricated as a neuromorphic chip (Qualc Continue Reading After the long training on a powerful computer, you <b>can</b> export the model (set of already trained weights for all neurons + description of the topology network) to a lightweights executable eg. using our library TensorRT.", "dateLastCrawled": "2022-01-10T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Model interpretation and data valuation for machine learning (<b>Book</b> ...", "url": "https://www.worldcat.org/title/model-interpretation-and-data-valuation-for-machine-learning/oclc/1255184724", "isFamilyFriendly": true, "displayUrl": "https://www.worldcat.org/title/model-interpretation-and-data-valuation-for-machine...", "snippet": "In order to be <b>able</b> to trust a machine learning model and to repair it once it malfunctions, it is important to be <b>able</b> to interpret its decision-making. For example, if a model&#39;s performance is poor on a specific subgroup (gender, race, etc), it is important to find out why and fix it. In this thesis, we examine the drawbacks of existing <b>interpretability</b> methods and introduce new ML <b>interpretability</b> algorithms that are designed to tackle some of the shortcomings. Data is the labor that ...", "dateLastCrawled": "2021-10-17T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>How important is interpretability for a</b> model in Machine Learning? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-model-in-Machine-Learning", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What makes <b>interpretability</b> in neural networks difficult? - Quora", "url": "https://www.quora.com/What-makes-interpretability-in-neural-networks-difficult", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-makes-<b>interpretability</b>-in-neural-networks-difficult", "snippet": "Answer (1 of 2): The ultimate goal of machine learning (or statistics), many would argue, is to build insight into some phenomenon. Thus far, the ML community has largely been obsessed with predictive accuracy. If you <b>read</b> the many papers in different subfields of ML at leading conferences, like ...", "dateLastCrawled": "2022-01-13T06:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Chapter 2 Statistical Learning</b> | A Tidy Introduction To ... - GitHub Pages", "url": "https://beaulucas.github.io/tidy_islr/statistical-learning.html", "isFamilyFriendly": true, "displayUrl": "https://beaulucas.github.io/tidy_islr/<b>statistical-learning</b>.html", "snippet": "2.2.3 The Trade-Off Between Prediction Accuracy and Model <b>Interpretability</b>. Restrictive models are much more intepretable than flexible ones. Flexible approaches <b>can</b> be so complicated that it is hard to understand how predictors affect the response. If inference is the goal, simple and inflexible methods are easier to interpret. For prediction, accuracy is the biggest concern. However, flexible models are more prone to overfitting. 2.2.4 Supervised Versus Unsupervised Learning. Most machine ...", "dateLastCrawled": "2022-01-28T07:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High interpretable models equate <b>to being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was made. Highly interpretable models, and maintaining high <b>interpretability</b> as a design standard, <b>can</b> help build trust between engineers and users. It\u2019s bad enough when the chain of command prevents a person from <b>being</b> <b>able</b> to speak to the party responsible for making the decision. It is much worse ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "<b>Interpretability</b> takes many forms and <b>can</b> be difficult to define; we first explore general frameworks and sets of definitions in which model <b>interpretability</b> <b>can</b> be evaluated and <b>compared</b> (Lipton 2016, Doshi-Velez &amp; Kim 2017). Next, we analyze several well-known examples of <b>interpretability</b> methods\u2013LIME (Ribeiro et al. 2016), SHAP (Lundberg &amp; Lee 2017), and convolutional neural network visualization (Olah et al. 2018)\u2013in the context of this framework. Model <b>interpretability</b> has no ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Teaching Machines <b>to Read</b> <b>Movie Reviews: Thinking About Interpretability</b>", "url": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about-interpretability-63c12248b8e5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/teaching-machines-<b>to-read</b>-movie-reviews-thinking-about...", "snippet": "Model Accuracy vs <b>Interpretability</b>. Using stance categories (the lexicogramatical level of language) as features doesn\u2019t improve performance over a word-based model: Random Forest using stance vectors (image by author) Again reading diagonally from left to right, the stance-based model is about 80% accurate predicting positive reviews, and around 73% accurate with negative reviews. So from a pure performance perspective, using stance hurts performance. But insight is a very different story ...", "dateLastCrawled": "2022-01-19T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretability</b> in the medical field: A systematic mapping and review ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "snippet": "FR (seven articles with 20 evaluations) was <b>compared</b> against white-box models or other <b>interpretability</b> techniques by comparing the shifts in attribute ranks (a mean rank shift of 1.24), and expert knowledge was discussed qualitatively and was generally in favor of the <b>interpretability</b> technique in question. Moreover, 11 articles with 104 evaluations <b>compared</b> tree explanations to other techniques, and interpretable models using accuracy, the mean accuracy improvement over these articles was ...", "dateLastCrawled": "2022-01-23T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Comparison and improvement of the predictability and <b>interpretability</b> ...", "url": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0417-9", "isFamilyFriendly": true, "displayUrl": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0417-9", "snippet": "Ensemble learning helps improve machine learning results by combining several models and allows the production of better predictive performance <b>compared</b> to a single model. It also benefits and accelerates the researches in quantitative structure\u2013activity relationship (QSAR) and quantitative structure\u2013property relationship (QSPR). With the growing number of ensemble learning models such as random forest, the effectiveness of QSAR/QSPR will be limited by the machine\u2019s inability to ...", "dateLastCrawled": "2022-02-01T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Prediction or <b>interpretability</b>? | Emerging Themes in Epidemiology ...", "url": "https://ete-online.biomedcentral.com/articles/10.1186/s12982-019-0086-1", "isFamilyFriendly": true, "displayUrl": "https://ete-online.biomedcentral.com/articles/10.1186/s12982-019-0086-1", "snippet": "The journal published a review of the literature on recursive partition in epidemiological research comparing two decision tree methods: classification and regression trees (CARTs) and conditional inference trees (CITs). There are two sources of potential confusion in the paper for readers: one lies in the definition and the comparison of CITs and CARTs, while the other is more general and it refers to the use of hyper-parameters and their tuning through resampling techniques.", "dateLastCrawled": "2022-01-26T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Chapter 16 Interpretable Machine Learning</b> | Hands-On Machine Learning ...", "url": "https://bradleyboehmke.github.io/HOML/iml.html", "isFamilyFriendly": true, "displayUrl": "https://bradleyboehmke.github.io/HOML/iml.html", "snippet": "Approaches to model <b>interpretability</b> to answer the exemplar questions above <b>can</b> be broadly categorized as providing global or local explanations. It is important to understand the entire model that you\u2019ve trained on a global scale, and also to zoom in on local regions of your data or your predictions and derive explanations. <b>Being</b> <b>able</b> to answer such questions and provide both levels of explanation is key to any ML project becoming accepted, adopted, embedded, and properly utilized.", "dateLastCrawled": "2022-02-01T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How important is <b>interpretability</b> for a model in Machine Learning ...", "url": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-<b>interpretability</b>-for...", "snippet": "It <b>can</b> be even used by systems without operating system, example <b>being</b> compiled and fabricated as a neuromorphic chip (Qualc Continue Reading After the long training on a powerful computer, you <b>can</b> export the model (set of already trained weights for all neurons + description of the topology network) to a lightweights executable eg. using our library TensorRT.", "dateLastCrawled": "2022-01-10T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Which, if any, machine learning algorithms are accepted as <b>being</b> a good ...", "url": "https://datascience.stackexchange.com/questions/11880/which-if-any-machine-learning-algorithms-are-accepted-as-being-a-good-tradeoff", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/11880", "snippet": "The tradeoff between <b>interpretability</b> and <b>being</b> <b>able</b> to predict those nonlinearities depends on the data and question asked. There really is no free lunch in data science and no single algorithm <b>can</b> be considered to be the best for any set of data (and the same applies for <b>interpretability</b>). The general rule should be that the more algorithms you know the better it is for you as you <b>can</b> adopt to your specific needs more easily. If I had to pick my favorite for classification task that I ...", "dateLastCrawled": "2022-01-16T10:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What makes <b>interpretability</b> in neural networks difficult? - Quora", "url": "https://www.quora.com/What-makes-interpretability-in-neural-networks-difficult", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-makes-<b>interpretability</b>-in-neural-networks-difficult", "snippet": "Answer (1 of 2): The ultimate goal of machine learning (or statistics), many would argue, is to build insight into some phenomenon. Thus far, the ML community has largely been obsessed with predictive accuracy. If you <b>read</b> the many papers in different subfields of ML at leading conferences, like ...", "dateLastCrawled": "2022-01-13T06:28:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/<b>interpretability</b>-in-ml-a-broad-overview", "snippet": "First, <b>interpretability</b> in <b>machine</b> <b>learning</b> is useful because it can aid in trust. As humans, we may be reluctant to rely on <b>machine</b> <b>learning</b> models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in something opaque, which we see when people confront new technology, and this can slow down adoption. Approaches to <b>interpretability</b> that focus on transparency could help mitigate some of these fears.", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "snippet": "This provides a novel <b>analogy</b> between data compression and regularization. Qualitative and quantitative state-of-the-art results on three datasets. 20 / 33. Interpretable Lens Variable Model (ILVM) 21 / 33. Interactive <b>Interpretability</b> via Active <b>Learning</b> Interactive \u2018human-in-the-loop\u2019 <b>interpretability</b> Choose the point with index j that maximizes : ^j = argmax jI(s ; ) = H(s ) E q \u02da(z js)[H(s jz j)] = Z p(s j)log p(s j)ds + E q \u02da(z js) Z p (s jjz)log p (s jjz)ds : (5) Choose the point ...", "dateLastCrawled": "2022-01-19T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-16T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://arxiv.org/abs/2005.12800", "isFamilyFriendly": true, "displayUrl": "https://<b>arxiv</b>.org/abs/2005.12800", "snippet": "Principles of analogical reasoning have recently been applied in the context of <b>machine</b> <b>learning</b>, for example to develop new methods for classification and preference <b>learning</b>. In this paper, we argue that, while analogical reasoning is certainly useful for constructing new <b>learning</b> algorithms with high predictive accuracy, is is arguably not less interesting from an <b>interpretability</b> and explainability point of view. More specifically, we take the view that an <b>analogy</b>-based approach is a ...", "dateLastCrawled": "2021-10-24T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Economic Methodology Meets Interpretable <b>Machine</b> <b>Learning</b> ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. But first ...", "dateLastCrawled": "2022-01-05T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Figure 1: <b>Interpretability</b> for <b>machine</b> <b>learning</b> models bridges the concrete objectives models optimize for and the real-world (and less easy to define) desiderata that ML applications aim to achieve. Introduction . The objectives <b>machine</b> <b>learning</b> models optimize for do not always reflect the actual desiderata of the task at hand. <b>Interpretability</b> in models allows us to evaluate their decisions and obtain information that the objective alone cannot confer. <b>Interpretability</b> takes many forms ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Economic Methodology Meets Interpretable Machine Learning</b> - Part I ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. Intro - Part ...", "dateLastCrawled": "2022-01-22T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Confusion Matrices</b> &amp; <b>Interpretable ML</b> | by andrea b | high stakes ...", "url": "https://medium.com/high-stakes-design/interpretability-techniques-explained-in-simple-terms-f5e1573674f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/high-stakes-design/<b>interpretability</b>-techniques-explained-in-simple...", "snippet": "The best [<b>analogy</b>] I can think of is an indicator light in your car \u2014 [and the] <b>machine</b> that you plug in to tell you more about the readout. ANDREA: Do you see <b>interpretability</b>, primarily, as ...", "dateLastCrawled": "2021-03-22T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "Neuroscience \u2194 <b>Interpretability</b>. <b>Analogy</b>: model=brain. Artificial neural networks are historically inspired by neuroscience, but I used to be pretty skeptical that the connection was anything more than superficial. I&#39;ve since come around: I now think this is a very deep connection. The thing that personally persuaded me was that, in my own investigations of what goes on inside neural networks, we kept finding things that were previously discovered by neuroscientists. The most recent ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chris Olah on what the hell is going on inside neural networks - 80,000 ...", "url": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/", "isFamilyFriendly": true, "displayUrl": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research", "snippet": "Chris is a <b>machine</b> <b>learning</b> researcher currently focused on neural network interpretability. Until last December he led OpenAI\u2019s interpretability team but along with some colleagues he recently moved on to help start a new AI lab focussed on large models and safety called Anthropic. Rob Wiblin: Before OpenAI he spent 4 years at Google Brain developing tools to visualize what\u2019s going on in neural networks. Chris was hugely impactful at Google Brain. He was second author on the launch of ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Marketing AI: Interpretability and Explainability</b> - Christopher S. Penn ...", "url": "https://www.christopherspenn.com/2021/03/marketing-ai-interpretability-and-explainability/", "isFamilyFriendly": true, "displayUrl": "https://www.christopherspenn.com/2021/03/<b>marketing-ai-interpretability-and-explainability</b>", "snippet": "<b>Interpretability is like</b> inspecting the baker\u2019s recipe for the cake. We look at the list of ingredients and the steps taken to bake the cake, and we verify that the recipe makes sense and the ingredients were good. This is a much more rigorous way of validating our results, but it\u2019s the most complete \u2013 and if we\u2019re in a high-stakes situation where we need to remove all doubt, this is the approach we take. Interpretability in AI is like that \u2013 we step through the code itself that ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Causal <b>Learning</b> From Predictive Modeling for Observational Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931928/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7931928", "snippet": "Given the recent success of <b>machine</b> <b>learning</b>, specifically deep <b>learning</b>, in several applications (Goodfellow et al., ... This statistical <b>interpretability is similar</b> in spirit to traditional interpretability. This allows to answer questions, such as \u201cdoes BMI influence susceptibility to Covid?\u201d Moreover, it has been argued that developing an effective CBN for practical applications requires expert knowledge when data collection is cumbersome (Fenton and Neil, 2012). This applies to ...", "dateLastCrawled": "2021-12-09T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimal <b>Predictive Clustering</b> - Dimitris Bertsimas", "url": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-predictive-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-<b>predictive-clustering</b>.pdf", "snippet": "Table 1 Comparison of major <b>machine</b> <b>learning</b> methods relative to each other across the metrics of performance (out-of-sample R2), scalability and interpretability. 1 is the best, while 5 is the worst. Optimal <b>Predictive Clustering</b> 3 From Table 1, we observe all existing methods have weakness in at least one category. We therefore seek to design a method that has strong performance in all three categories at the same time. Optimal <b>Predictive Clustering</b> (OPC) is an algorithm that uses mixed ...", "dateLastCrawled": "2021-11-24T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reviewing Challenges of Predicting Protein Melting Temperature Change ...", "url": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "snippet": "Predicting the effects of mutations on protein stability is a key problem in fundamental and applied biology, still unsolved even for the relatively simple case of small, soluble, globular, monomeric, two-state-folder proteins. Many articles discuss the limitations of prediction methods and of the datasets used to train them, which result in low reliability for actual applications despite globally capturing trends. Here, we review these and other issues by analyzing one of the most detailed ...", "dateLastCrawled": "2022-02-03T02:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "In my view, a shor t coming of interpretable <b>machine</b> <b>learning</b> is that it assumes to a degree that the data being fed into the model is always going to be suitable for human interpretation. This is not necessarily the case. For instance, let\u2019s say that a company is trying to implement interpretable <b>machine</b> <b>learning</b> to devise a credit scoring model, whereby prospective credit card applications are classified as approved or rejected based on numerous features. It is often the case that such ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Breaking the interpretability barrier - a</b> method for interpreting deep ...", "url": "http://www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "isFamilyFriendly": true, "displayUrl": "www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o between performance and inter-pretability. Graph classi cation is normally a domain which requires the ap-plication of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to in-terpret complex models post-hoc (brie y reviewed in section2). However, most ...", "dateLastCrawled": "2021-09-22T17:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Discovering Discriminative Nodes for Classi\ufb01cation with Deep Graph ...", "url": "http://muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "isFamilyFriendly": true, "displayUrl": "muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o\ufb00 between performance and inter-pretability. Graph classi\ufb01cation is normally a domain which requires the appli-cation of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to interpret complex models post-hoc (brie\ufb02y reviewed in Sect.2). However ...", "dateLastCrawled": "2021-09-02T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Confronting Abusive Language Online: A Survey from the Ethical and ...", "url": "https://www.arxiv-vanity.com/papers/2012.12305/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2012.12305", "snippet": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this ...", "dateLastCrawled": "2021-10-13T19:21:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(interpretability)  is like +(being able to read a book)", "+(interpretability) is similar to +(being able to read a book)", "+(interpretability) can be thought of as +(being able to read a book)", "+(interpretability) can be compared to +(being able to read a book)", "machine learning +(interpretability AND analogy)", "machine learning +(\"interpretability is like\")", "machine learning +(\"interpretability is similar\")", "machine learning +(\"just as interpretability\")", "machine learning +(\"interpretability can be thought of as\")", "machine learning +(\"interpretability can be compared to\")"]}