{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is a <b>Convolutional Neural Network</b>? - MATLAB &amp; Simulink", "url": "https://www.mathworks.com/discovery/convolutional-neural-network-matlab.html", "isFamilyFriendly": true, "displayUrl": "https://www.mathworks.com/discovery/<b>convolutional-neural-network</b>-matlab.html", "snippet": "<b>Like</b> other neural networks, a CNN is composed of an input layer, an output layer, and many hidden layers in between. These layers perform operations that alter the data with the intent of learning features specific to the data. Three of the most common layers are: convolution, activation or ReLU, and pooling. Convolution puts the input images through a <b>set</b> of <b>convolutional</b> <b>filters</b>, each of which activates certain features from the images. Rectified linear unit (ReLU) allows for faster and ...", "dateLastCrawled": "2022-02-03T14:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Novel <b>convolutional</b> neural networks for efficient classification of ...", "url": "https://link.springer.com/article/10.1007/s00521-021-06645-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-021-06645-9", "snippet": "The branches can be experimented with in order to either store independent <b>convolutional</b> <b>filters</b> or share some of the <b>filter</b> matrices. The proposed solution, however, has a remarkably different application. Siamese Networks usually work on the pairs of patches, yielding the binary answer that determines the similarity of inputs in terms of the desired relation. In the proposed solution, however, the inputs of the branches are generated from the same patch, and the network output represents ...", "dateLastCrawled": "2022-01-30T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Convolutional Neural Networks Tutorial in TensorFlow</b> \u2013 Adventures in ...", "url": "http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/", "isFamilyFriendly": true, "displayUrl": "adventuresinmachinelearning.com/<b>convolutional-neural-networks-tutorial</b>-tensorflow", "snippet": "The format that the conv2d() function receives for the <b>filter</b> is: [<b>filter</b>_height, <b>filter</b>_width, in_channels, out_channels]. The height and width of the <b>filter</b> are provided in the <b>filter</b>_shape variables (in this case [5, 5]). The number of input channels, for the first <b>convolutional</b> layer is simply 1, which corresponds to the single channel greyscale MNIST image. However, for the second <b>convolutional</b> layer it takes the output of the first <b>convolutional</b> layer, which has a 32 channel output ...", "dateLastCrawled": "2022-02-02T05:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "State\u2010of\u2010art analysis of <b>image denoising methods using convolutional</b> ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2019.0157", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2019.0157", "snippet": "The rank-order <b>filter</b> is formed by a median <b>filter</b>, adaptive median <b>filter</b>, centre weighted median <b>filter</b>, adaptive centre weighted median <b>filter</b> or Cai&#39;s method . After rank-order filtering, the up-sampling operation is done using bicubic interpolation. The frequency response of interpolation is low pass in nature. Therefore, some high-frequency components that arise from the rank-order filtering on the Gaussian noise are suppressed. Convolution stage consists of convolution layer, ReLU ...", "dateLastCrawled": "2022-02-03T14:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Filter learning for image categorization and pixel classification</b> ...", "url": "https://www.epfl.ch/labs/cvlab/research/descriptors-and-keypoints/research-filter_learning/", "isFamilyFriendly": true, "displayUrl": "https://www.epfl.ch/labs/cvlab/research/descriptors-and-keypoints/research-<b>filter</b>_learning", "snippet": "Learning a <b>convolutional</b> <b>filter</b> bank on the CIFAR-10 dataset Sparse representations are at the heart of many modern Machine Learning algorithms. Particularly relevant to the Computer Vision community is the possibility to learn <b>filter</b> banks (also called dictionaries) tuned to the statistics of the data.. We have investigated a <b>convolutional</b> approach to learn, under sparsity constraints, a <b>set</b> <b>of filters</b> for <b>image categorization and pixel classification</b> purposes.", "dateLastCrawled": "2022-01-14T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Review: <b>DnCNN</b> \u2014 Residual Learning of Deep CNN for Image Denoising ...", "url": "https://sh-tsang.medium.com/review-dncnn-residual-learning-of-deep-cnn-image-denoising-super-resolution-jpeg-deblocking-cbf464b03130", "isFamilyFriendly": true, "displayUrl": "https://sh-tsang.medium.com/review-<b>dncnn</b>-residual-learning-of-deep-cnn-image-denoising...", "snippet": "The size of <b>convolutional</b> <b>filters</b> are <b>set</b> to be 3\u00d73 and all pooling layers are removed. Therefore, the receptive field of <b>DnCNN</b> with ... (D-1), 64 <b>filters</b> of size 3\u00d73\u00d764 are <b>used</b>, and batch normalization is added between convolution and ReLU. (iii) Conv: for the last layer, c <b>filters</b> of size 3\u00d73\u00d764 are <b>used</b> to reconstruct the output. Simple zero padding strategy is <b>used</b> before convolution which does not result in any boundary artifacts. By incorporating convolution with ReLU, <b>DnCNN</b> can ...", "dateLastCrawled": "2022-02-03T04:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Copra Meat Classification using <b>Convolutional</b> Neural Network", "url": "https://www.researchgate.net/publication/339602184_Copra_Meat_Classification_using_Convolutional_Neural_Network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339602184_Copra_Meat_Classification_using...", "snippet": "<b>convolutional</b> layer <b>filters</b>, <b>filter</b> ... The first <b>set</b> is f or train ing the model, which co nsists of . accepting the input images, pr e-processing, data s plitt ing, and tr aining the CNN m odel ...", "dateLastCrawled": "2022-01-27T13:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Building Correlations Between Filters in Convolutional Neural Networks</b> ...", "url": "https://www.researchgate.net/publication/311682537_Building_Correlations_Between_Filters_in_Convolutional_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/311682537_Building_Correlations_Between...", "snippet": "A <b>convolutional</b> <b>filter</b> is a powerful tool for modeling spatial relations and organizing grouped signals, so the proposed methods map the channel signals onto a pseudoimage, <b>like</b> putting a lens ...", "dateLastCrawled": "2021-11-08T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to Develop a CNN From Scratch for CIFAR-10 Photo Classification", "url": "https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-", "snippet": "The architecture involves stacking <b>convolutional</b> layers with small 3\u00d73 <b>filters</b> followed by a max pooling layer. Together, these layers form a block, and these blocks can be repeated where the number <b>of filters</b> in each block is increased with the depth of the network such as 32, 64, 128, 256 for the first four blocks of the model. Padding is <b>used</b> on the <b>convolutional</b> layers to ensure the height and width of the output feature maps matches the inputs.", "dateLastCrawled": "2022-02-02T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Towards subject-level cerebral infarction classification of CT scans ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235765", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235765", "snippet": "While <b>convolutional</b> layers of standard CNNs only input data from the previous layer, dense <b>convolutional</b> blocks contain multiple <b>convolutional</b> layers, whereby each layer input data from multiple previous <b>convolutional</b> layers in a respective block. Layers within a block have a rising number <b>of filters</b>, defined by the growth rate. Transition blocks limit the number <b>of filters</b> and apply a max-pooling operation. A detailed description can be found in", "dateLastCrawled": "2022-01-08T03:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Novel <b>convolutional</b> neural networks for efficient classification of ...", "url": "https://link.springer.com/article/10.1007/s00521-021-06645-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-021-06645-9", "snippet": "This means that all the <b>convolutional</b> <b>filters</b> present in the model are trained with a specific purpose of being useful in the image classification task on a defined data <b>set</b>. It is worth mentioning that the CNN0, CNN1 \\(_i\\) and CNN2 blocks can be implemented as sequences of multiple <b>convolutional</b> layers and maximum-pooling layers, as it is typical for the <b>convolutional</b> neural network models. The sequence of applied <b>filter</b> groups and pooling sizes should be <b>similar</b> in each of the CNN1 \\(_i ...", "dateLastCrawled": "2022-01-30T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Building Correlations Between Filters in Convolutional Neural Networks</b> ...", "url": "https://www.researchgate.net/publication/311682537_Building_Correlations_Between_Filters_in_Convolutional_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/311682537_Building_Correlations_Between...", "snippet": "A <b>similar</b> property of correlation is identified in [3, 29, 2], where authors suggest to generate such features based on a separate <b>set</b> of correlation <b>filters</b> rather than learning all the redundant ...", "dateLastCrawled": "2021-11-08T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Towards subject-level cerebral infarction classification of CT scans ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235765", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235765", "snippet": "The second architecture <b>is similar</b> to Arbabshirani and consists of 5 <b>convolutional</b> layers (256, 64, 96, 128 and 128 <b>filters</b>), each followed by a max-pooling layer (two times 2 \u00d7 2 \u00d7 4 and three times 2 \u00d7 2 \u00d7 2 pooling). All <b>convolutional</b> layers use a 3 \u00d7 3 \u00d7 3 <b>filter</b> size. After the second layer we added a batch normalization layer, which is different from the original paper\u2019s local response normalization layer. Last, 2 dense layers with 1000 units each are <b>used</b> and afterwards one ...", "dateLastCrawled": "2022-01-08T03:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "PReLU and edge\u2010aware <b>filter</b>\u2010based image denoiser using <b>convolutional</b> ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2020.0717", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2020.0717", "snippet": "The bilateral <b>filter</b> is widely <b>used</b> for edge-preserving image smoothening in computer vision and image processing applications [, ]. The bilateral <b>filter</b> uses both range kernel and spatial kernel, whereas linear convolution uses only the spatial kernel. The input of the range kernel is the intensity difference between the centre pixel and neighbouring pixels. If this intensity difference is significant, then the minimum weight is assigned to neighbouring pixels, and it is excluded from ...", "dateLastCrawled": "2022-01-15T19:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is a <b>Convolutional Neural Network</b>? - MATLAB &amp; Simulink", "url": "https://www.mathworks.com/discovery/convolutional-neural-network-matlab.html", "isFamilyFriendly": true, "displayUrl": "https://www.mathworks.com/discovery/<b>convolutional-neural-network</b>-matlab.html", "snippet": "A <b>convolutional neural network</b> can have tens or hundreds of layers that each learn to detect different features of an image. <b>Filters</b> are applied to each training image at different resolutions, and the output of each convolved image is <b>used</b> as the input to the next layer. The <b>filters</b> can start as very simple features, such as brightness and ...", "dateLastCrawled": "2022-02-03T14:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Review: <b>DnCNN</b> \u2014 Residual Learning of Deep CNN for Image Denoising ...", "url": "https://sh-tsang.medium.com/review-dncnn-residual-learning-of-deep-cnn-image-denoising-super-resolution-jpeg-deblocking-cbf464b03130", "isFamilyFriendly": true, "displayUrl": "https://sh-tsang.medium.com/review-<b>dncnn</b>-residual-learning-of-deep-cnn-image-denoising...", "snippet": "The size of <b>convolutional</b> <b>filters</b> are <b>set</b> to be 3\u00d73 and all pooling layers are removed. Therefore, the receptive field of <b>DnCNN</b> with ... (D-1), 64 <b>filters</b> of size 3\u00d73\u00d764 are <b>used</b>, and batch normalization is added between convolution and ReLU. (iii) Conv: for the last layer, c <b>filters</b> of size 3\u00d73\u00d764 are <b>used</b> to reconstruct the output. Simple zero padding strategy is <b>used</b> before convolution which does not result in any boundary artifacts. By incorporating convolution with ReLU, <b>DnCNN</b> can ...", "dateLastCrawled": "2022-02-03T04:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Classification of <b>crystallization</b> outcomes using deep <b>convolutional</b> ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198883", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198883", "snippet": "The additional <b>convolutional</b> layer has a depth (number <b>of filters</b>) of 16, a 3 \u00d7 3 receptive field (it operates on a 3 \u00d7 3 square patch convolved over the image) and a stride of 2 (it skips over every other location in the image to reduce the dimensionality of the feature map). This modification improved classification absolute accuracy by approximately 0.3%. A few other <b>convolutional</b> layers were shrunk compared to the standard Inception-v3 by capping their depth as described in", "dateLastCrawled": "2022-01-23T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Neural Tangent Link Between CNN Denoisers and Non-Local <b>Filters</b>", "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tachella_The_Neural_Tangent_Link_Between_CNN_Denoisers_and_Non-Local_Filters_CVPR_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tachella_The_Neural_Tangent_Link...", "snippet": "patches centered at pixels i and j. b) <b>Filter</b> weights for different pixels in the <b>house</b> image, where red/white indicates a higher weight, and blue indicates a zero weight. CNNs as non-local \ufb01lters: Recently, Mohan et al. [21] showed that a fully-trained denoising CNN without biases can be interpreted as a non-local \ufb01lter by examining the", "dateLastCrawled": "2022-01-31T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>How Convolutional Neural Networks Accomplish Image Recognition</b>? - KDnuggets", "url": "https://www.kdnuggets.com/2017/08/convolutional-neural-networks-image-recognition.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2017/08/<b>convolutional</b>-neural-networks-image-recognition.html", "snippet": "Here we explain concepts, applications and techniques of image recognition using <b>Convolutional</b> Neural Networks. ... The <b>filter</b> that passes over it is the light rectangle. The Activation maps are arranged in a stack on the top of one another, one for each <b>filter</b> you use. The larger rectangle is 1 patch to be downsampled. The activation maps condensed via downsampling. A new group of activation maps generated by passing the <b>filters</b> over the stack that is downsampled first. The second ...", "dateLastCrawled": "2022-01-20T21:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Develop a CNN From Scratch for CIFAR-10 Photo Classification", "url": "https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-", "snippet": "The architecture involves stacking <b>convolutional</b> layers with small 3\u00d73 <b>filters</b> followed by a max pooling layer. Together, these layers form a block, and these blocks can be repeated where the number <b>of filters</b> in each block is increased with the depth of the network such as 32, 64, 128, 256 for the first four blocks of the model. Padding is <b>used</b> on the <b>convolutional</b> layers to ensure the height and width of the output feature maps matches the inputs.", "dateLastCrawled": "2022-02-02T04:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification of <b>crystallization</b> outcomes using deep <b>convolutional</b> ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198883", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198883", "snippet": "The additional <b>convolutional</b> layer has a depth (number <b>of filters</b>) of 16, a 3 \u00d7 3 receptive field (it operates on a 3 \u00d7 3 square patch convolved over the image) and a stride of 2 (it skips over every other location in the image to reduce the dimensionality of the feature map). This modification improved classification absolute accuracy by approximately 0.3%. A few other <b>convolutional</b> layers were shrunk compared to the standard Inception-v3 by capping their depth as described in", "dateLastCrawled": "2022-01-23T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Base-resolution models of transcription factor binding reveal soft ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8812996/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8812996", "snippet": "The first <b>convolutional</b> layer uses 64 <b>filters</b> of width 25 bp, followed by 9 dilated <b>convolutional</b> layers (64 <b>filters</b> of width 3 in each layer) where the dilation rate (number of skipped positions in the <b>convolutional</b> <b>filter</b>) doubles at every layer. This results in a receptive field of +/\u22121034 bp for any position in the genome. The output of the final <b>convolutional</b> layer within the BPNet body (also referred to as the bottleneck activation map) serves as input for two output heads per TF: i ...", "dateLastCrawled": "2022-02-05T05:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Brain-Computer Interface: Advancement and Challenges", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8433803/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8433803", "snippet": "It is a spatial <b>filter</b> that <b>can</b> <b>be thought</b> of as the subtraction of shared EEG activity, retaining only the idle action of each EEG particular electrode . 6.3. Adaptive <b>Filters</b> . The adaptive <b>filter</b> is a computational device for mathematical processes. It connects the adaptive <b>filter</b>\u2019s input/output signals iteratively. There are <b>filter</b> coefficients that are self-adjusted utilizing an adaptive algorithm. It works by altering signal properties depending on the characteristics of the signals ...", "dateLastCrawled": "2022-02-03T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "We <b>can</b> break down a <b>convolutional</b> layer with a larger <b>filter</b> size into a stack of <b>convolutional</b> layers with smaller <b>filter</b> size and this is known as factorized convolution. Suppose, we have a <b>convolutional</b> layer with a 5 x 5 <b>filter</b> then it <b>can</b> be broken down into two <b>convolutional</b> layers with 3 x 3 <b>filters</b>.", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Kalman <b>Filter</b> For Beginners With Matlab Examples", "url": "https://web1.sbnonline.com/m/images/Z9Q9K0/kalman-filter-for-beginners-with-matlab-examples_pdf", "isFamilyFriendly": true, "displayUrl": "https://web1.sbnonline.com/m/images/Z9Q9K0/kalman-<b>filter</b>-for-beginners-with-matlab...", "snippet": "second example demonstrates another common use of kalman <b>filters</b>, in which you <b>can</b> optimally estimate the state of a system (e.g., . For example, if the state models the motion of a train, the train operator might push on the throttle, causing the train to accelerate. Written for students and engineers, this book provides comprehensive coverage of the kalman <b>filter</b> and its applications. The book starts with recursive . For example, noisy data <b>can</b> generate unit impulses when <b>used</b> as input to ...", "dateLastCrawled": "2022-01-18T18:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Deep <b>Neural Networks as a Computational Model for Human Shape</b> ... - PLOS", "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004896", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004896", "snippet": "Whereas humans are <b>thought</b> to be able to perform many object and scene recognition tasks in a feedforward manner [44 ... This model computes a convolution of an image with a <b>set</b> of Gabor <b>filters</b> of five spatial frequencies and eight orientations, placed on a regular 10x10 grid. In our tests, we <b>used</b> a Python implementation of GaborJet, available in the psychopy_ext package . Histogram of Oriented Gradient (HOG) model that produces a histogram of normalized gradients (i.e., orientations) in ...", "dateLastCrawled": "2022-01-27T01:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Generative Deep Learning for Targeted Compound Design | Journal of ...", "url": "https://pubs.acs.org/doi/10.1021/acs.jcim.0c01496", "isFamilyFriendly": true, "displayUrl": "https://pubs.acs.org/doi/10.1021/acs.jcim.0c01496", "snippet": "To assess whether the models <b>can</b> generate new molecules, it measures the validity, uniqueness and novelty rates along with the internal diversity and the fraction of generated molecules that pass a <b>set</b> of structural <b>filters</b> for molecular quality. The framework also provides a <b>set</b> of metrics meant to evaluate how well the model learned features of the training data <b>set</b>. For this purpose, it presents the FCD, the distance between the distribution of various physicochemical properties, the ...", "dateLastCrawled": "2022-01-10T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Building Autoencoders in Keras", "url": "https://blog.keras.io/building-autoencoders-in-keras.html", "isFamilyFriendly": true, "displayUrl": "https://blog.keras.io/building-<b>autoencoder</b>s-in-keras.html", "snippet": "Additionally, in almost all contexts where the term &quot;<b>autoencoder</b>&quot; is <b>used</b>, the compression and decompression functions are implemented with neural networks. 1) Autoencoders are data-specific, which means that they will only be able to compress data similar to what they have been trained on. This is different from, say, the MPEG-2 Audio Layer III (MP3) compression algorithm, which only holds assumptions about &quot;sound&quot; in general, but not about specific types of sounds. An <b>autoencoder</b> trained ...", "dateLastCrawled": "2022-01-30T22:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Face recognition with OpenCV, Python, and deep learning</b>", "url": "https://www.pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2018/06/18/<b>face-recognition-with-opencv-python-and</b>-deep...", "snippet": "However, it <b>can</b> be <b>used</b> as a base model for object detection and other tasks. Typically we\u2019ll remove layers from the Inception network and use the rich <b>set</b> <b>of filters</b> it has learned to accomplish whatever tasks the practitioner is using it for. We call this \u201ctransfer learning\u201d as we\u2019ll utilizing what the model learned from one task and applying it to another.", "dateLastCrawled": "2022-02-03T09:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Get Started with Deep <b>Learning for Time Series Forecasting</b> (7 ...", "url": "https://machinelearningmastery.com/how-to-get-started-with-deep-learning-for-time-series-forecasting-7-day-mini-course/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/how-to-get-started-with-deep-learning-for-time...", "snippet": "Deep <b>Learning for Time Series Forecasting</b> Crash Course. Bring Deep Learning methods to Your Time Series project in 7 Days. Time series forecasting is challenging, especially when working with long sequences, noisy data, multi-step forecasts and multiple input and output variables. Deep learning methods offer a lot of promise for time series forecasting, such as the automatic learning of temporal dependence and the", "dateLastCrawled": "2022-01-31T12:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification of <b>crystallization</b> outcomes using deep <b>convolutional</b> ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198883", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198883", "snippet": "The additional <b>convolutional</b> layer has a depth (number <b>of filters</b>) of 16, a 3 \u00d7 3 receptive field (it operates on a 3 \u00d7 3 square patch convolved over the image) and a stride of 2 (it skips over every other location in the image to reduce the dimensionality of the feature map). This modification improved classification absolute accuracy by approximately 0.3%. A few other <b>convolutional</b> layers were shrunk <b>compared</b> to the standard Inception-v3 by capping their depth as described in", "dateLastCrawled": "2022-01-23T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Novel <b>convolutional</b> neural networks for efficient classification of ...", "url": "https://link.springer.com/article/10.1007/s00521-021-06645-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-021-06645-9", "snippet": "The branches <b>can</b> be experimented with in order to either store independent <b>convolutional</b> <b>filters</b> or share some of the <b>filter</b> matrices. The proposed solution, however, has a remarkably different application. Siamese Networks usually work on the pairs of patches, yielding the binary answer that determines the similarity of inputs in terms of the desired relation. In the proposed solution, however, the inputs of the branches are generated from the same patch, and the network output represents ...", "dateLastCrawled": "2022-01-30T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Convolutional Neural Networks Tutorial in TensorFlow</b> \u2013 Adventures in ...", "url": "http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/", "isFamilyFriendly": true, "displayUrl": "adventuresinmachinelearning.com/<b>convolutional-neural-networks-tutorial</b>-tensorflow", "snippet": "During training we have a few <b>convolutional</b> <b>filters</b> that have learnt to activate when they \u201csee\u201d a \u201c9\u201d shape in the image, but they activate most strongly depending on what orientation that \u201c9\u201d is. We want the <b>convolutional</b> neural network to recognise a \u201c9\u201d regardless of what orientation it is in. So the pooling \u201clooks\u201d over the output of these three <b>filters</b> and will give a high output so long as any one of these <b>filters</b> has a high activation. Pooling acts as a ...", "dateLastCrawled": "2022-02-02T05:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 3, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Convolutional neural network</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Convolutional_neural_network", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Convolutional_neural_network</b>", "snippet": "The weight vector (the <b>set</b> of adaptive parameters) of such a unit is often called a <b>filter</b>. Units <b>can</b> share <b>filters</b>. Downsampling layers contain units whose receptive fields cover patches of previous <b>convolutional</b> layers. Such a unit typically computes the average of the activations of the units in its patch. This downsampling helps to correctly classify objects in visual scenes even when the objects are shifted. In a variant of the neocognitron called the cresceptron, instead of using ...", "dateLastCrawled": "2022-02-07T07:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Develop a CNN From Scratch for CIFAR-10 Photo Classification", "url": "https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-", "snippet": "The architecture involves stacking <b>convolutional</b> layers with small 3\u00d73 <b>filters</b> followed by a max pooling layer. Together, these layers form a block, and these blocks <b>can</b> be repeated where the number <b>of filters</b> in each block is increased with the depth of the network such as 32, 64, 128, 256 for the first four blocks of the model. Padding is <b>used</b> on the <b>convolutional</b> layers to ensure the height and width of the output feature maps matches the inputs.", "dateLastCrawled": "2022-02-02T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards subject-level cerebral infarction classification of CT scans ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235765", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235765", "snippet": "While <b>convolutional</b> layers of standard CNNs only input data from the previous layer, dense <b>convolutional</b> blocks contain multiple <b>convolutional</b> layers, whereby each layer input data from multiple previous <b>convolutional</b> layers in a respective block. Layers within a block have a rising number <b>of filters</b>, defined by the growth rate. Transition blocks limit the number <b>of filters</b> and apply a max-pooling operation. A detailed description <b>can</b> be found in", "dateLastCrawled": "2022-01-08T03:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "An Advanced Noise Reduction and Edge Enhancement Algorithm", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8400271/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8400271", "snippet": "The denoised results of our method and <b>compared</b> methods on a \u201cjellyfish\u201d image, \u201c<b>house</b>\u201d image, and \u201cstatue\u201d image with 60 %, 70 %, and 80 % noise corruption are depicted in Figure 6, Figure 7 and Figure 8, respectively. As <b>can</b> be observed, the denoised results of the competitive methods still contain visible noises, resulting in blurred edges, darkening effects, and visual artifacts. By simultaneously optimizing denoising and contrast enhancement, and applying an edge enhancement ...", "dateLastCrawled": "2022-01-06T01:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Frontiers | Helix Matrix Transformation Combined With <b>Convolutional</b> ...", "url": "https://www.frontiersin.org/articles/10.3389/fmicb.2020.565434/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fmicb.2020.565434", "snippet": "Through the parameter optimization, the threshold for binarization was <b>set</b> as 16 and the final size of a matrix-type data was <b>set</b> as 25 \u00d7 25 to obtain a <b>clean</b> dataset with a small size. A CNN model with three <b>convolutional</b> layers was well trained using the dataset to predict bacterial species. The <b>filter</b> sizes for the three <b>convolutional</b> layers were 4, 8, and 16. The kernel size was three and the activation function was the rectified linear unit (ReLU). A back propagation neural network ...", "dateLastCrawled": "2022-01-22T06:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Frontiers | Comparative Analysis of Machine Learning Algorithms on ...", "url": "https://www.frontiersin.org/articles/10.3389/fmicb.2021.696921/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fmicb.2021.696921", "snippet": "In this study, we <b>used</b> the classic deep learning model LeNet-5, with six <b>convolutional</b> layers, three pooling layers, and two fully connected layers, while the size of the convolution kernel is <b>set</b> to 3*1. Then, each Raman spectrum was input into the CNN in the form of one-dimensional data. The Raman shift ranged from 519.56 to 1,800.81cm", "dateLastCrawled": "2022-02-02T16:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Generative Deep Learning for Targeted Compound Design | Journal of ...", "url": "https://pubs.acs.org/doi/10.1021/acs.jcim.0c01496", "isFamilyFriendly": true, "displayUrl": "https://pubs.acs.org/doi/10.1021/acs.jcim.0c01496", "snippet": "According to the team, this <b>can</b> be accomplished by training the model on a fraction of a large enumerated data <b>set</b>, such as GDB-13, and then tracking the percentage of the total data <b>set</b> the model <b>can</b> recover, how uniform the coverage is, and also whether it generates molecules outside the data <b>set</b>. These results <b>can</b> then <b>be compared</b> to an ideal model, directly sampling the data <b>set</b>, that serves as an upper bound for performance. Furthermore, the team introduced a method for evaluating the ...", "dateLastCrawled": "2022-01-10T07:41:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Visualizing How <b>Filters Work in Convolutional Neural Networks (CNNs</b> ...", "url": "https://towardsdatascience.com/visualizing-how-filters-work-in-convolutional-neural-networks-cnns-7383bd84ad2c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/visualizing-how-<b>filters-work-in-convolutional-neural</b>...", "snippet": "In Deep <b>Learning</b>, a <b>Convolutional</b> Neural Network (CNN) is a special type of neural network that is designed to process data through multiple layers of arrays. A CNN is well suited for applications like image recognition, and in particular is often used in face recognition software. In CNN, <b>convolutional</b> layers are the fundamental building blocks which make all the magic happens. In a typical image recognition application, a <b>convolutional</b> layer is made up of several filters to detect the ...", "dateLastCrawled": "2022-02-03T02:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Convolutional Neural Networks and their components for computer vision</b> ...", "url": "https://www.machinecurve.com/index.php/2018/12/07/convolutional-neural-networks-and-their-components-for-computer-vision/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2018/12/07/<b>convolutional</b>-neural-networks-and...", "snippet": "<b>Machine</b> <b>learning</b> (and consequently deep <b>learning</b>) can be used to train computers to see things. We know that <b>machine</b> <b>learning</b> is about feeding examples to machines, after which they derive the patterns in these examples themselves. Consequently, we can see that using <b>machine</b> <b>learning</b> for computer vision equals showing machines enough examples so that they can learn to recognize them on their own, for new data. In deep <b>learning</b>, we use deep neural networks to learn machines to recognize ...", "dateLastCrawled": "2022-01-30T13:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Visualizing Filters and Feature Maps in Convolutional Neural Networks</b> ...", "url": "https://debuggercafe.com/visualizing-filters-and-feature-maps-in-convolutional-neural-networks-using-pytorch/", "isFamilyFriendly": true, "displayUrl": "https://debuggercafe.com/<b>visualizing-filters-and-feature-maps</b>-in-<b>convolutional</b>-neural...", "snippet": "When dealing with <b>machine</b> <b>learning</b> models like random forests, or decision trees, we can explain many of its decision making procedure. Data scientists and business managers also need to know why a model took a particular decision as it can radically affect a big organization. In regard to deep neural networks, explainability is still a widely researched field. Many businesses avoid the use of neural network models due to a lack of such explainability. But we can answer some of the questions ...", "dateLastCrawled": "2022-02-02T23:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> (ML) and Neural Networks (NN)\u2026 An Intuitive ...", "url": "https://medium.com/visionary-hub/machine-learning-ml-and-neural-networks-nn-an-intuitive-walkthrough-76bdaba8b0e3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/visionary-hub/<b>machine</b>-<b>learning</b>-ml-and-neural-networks-nn-an...", "snippet": "A better <b>analogy</b> for unsupervised <b>learning</b>, and one that\u2019s more commonly used, is separating a group of blocks by colour. Suppose we have 10 blocks, each with different coloured faces. In the ...", "dateLastCrawled": "2022-01-30T17:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Convolutional</b> Neural Networks \u2014 Part 3: Convolutions Over <b>Volume</b> and ...", "url": "https://medium.com/swlh/convolutional-neural-networks-part-3-convolutions-over-volume-and-the-convnet-layer-91fb7c08e28b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>convolutional</b>-neural-networks-part-3-convolutions-over-<b>volume</b>...", "snippet": "<b>Convolutional</b> Neural Networks \u2014 Part 3: Convolutions Over <b>Volume</b> and the <b>Convolutional</b> Layer . Brighton Nkomo. Follow. Oct 5, 2020 \u00b7 7 min read. This is the third part of my blog post series on ...", "dateLastCrawled": "2022-01-29T19:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Notes on <b>Convolutional</b> Neural Network", "url": "https://blog.sparsh.dev/notes-on-convolutional-neural-network/", "isFamilyFriendly": true, "displayUrl": "https://blog.sparsh.dev/notes-on-<b>convolutional</b>-neural-network", "snippet": "We start with a simple <b>analogy</b> about what is an artificial neuron. It is a math function but a digital one. And it tries to function similar to our brain&#39;s . verbose tethics Home; About; Author; Artificial <b>Learning</b>; Algorithm; Architecture; Open Source; Opinion; Tutorial; Subscribe By Sparsh in artificial <b>learning</b> \u2014 Dec 31, 2021 Notes on <b>Convolutional</b> Neural Network. Preliminary knowledge of computer vision is good for readers. You may also like articles on Image Manipulation and Object ...", "dateLastCrawled": "2022-01-25T16:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is the best <b>analogy</b> <b>for a Convolutional Neural Network that you</b> ...", "url": "https://www.quora.com/What-is-the-best-analogy-for-a-Convolutional-Neural-Network-that-you-ever-read", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-<b>analogy</b>-<b>for-a-Convolutional-Neural-Network-that</b>...", "snippet": "Answer: The following intuition was given by Prof. Yann LeCun in one of his lectures: (He explained it at a very high level, I\u2019ve filled in the details for better exposition.) Suppose you have a set of hand-coded rules for a classification task. Then, you can rewrite them in terms of AND and OR...", "dateLastCrawled": "2022-01-14T13:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - Calculate the <b>Output</b> size in Convolution layer ...", "url": "https://stackoverflow.com/questions/53580088/calculate-the-output-size-in-convolution-layer", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/53580088", "snippet": "Now apply that <b>analogy</b> to convolution layers. Your <b>output</b> size will be: input size - <b>filter</b> size + 1. Because your <b>filter</b> can only have n-1 steps as fences I mentioned. Let&#39;s calculate your <b>output</b> with that idea. 128 - 5 + 1 = 124 Same for other dimension too. So now you have a 124 x 124 image. That is for one <b>filter</b>.", "dateLastCrawled": "2022-01-28T22:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Do convolutional neural networks work the</b> same way as the networks in ...", "url": "https://www.quora.com/Do-convolutional-neural-networks-work-the-same-way-as-the-networks-in-our-brain", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Do-convolutional-neural-networks-work-the</b>-same-way-as-the...", "snippet": "Answer: NO. For starters, we don\u2019t completely know how the human brain works and therefore, we cannot possibly argue that <b>Convolutional</b> Networks (ConvNets) work the same way as the network of neurons in the human brain does. <b>Convolutional</b> Nets and other related architectures under the deep lear...", "dateLastCrawled": "2022-01-24T14:25:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(convolutional filter)  is like +(set of filters used to clean a house)", "+(convolutional filter) is similar to +(set of filters used to clean a house)", "+(convolutional filter) can be thought of as +(set of filters used to clean a house)", "+(convolutional filter) can be compared to +(set of filters used to clean a house)", "machine learning +(convolutional filter AND analogy)", "machine learning +(\"convolutional filter is like\")", "machine learning +(\"convolutional filter is similar\")", "machine learning +(\"just as convolutional filter\")", "machine learning +(\"convolutional filter can be thought of as\")", "machine learning +(\"convolutional filter can be compared to\")"]}