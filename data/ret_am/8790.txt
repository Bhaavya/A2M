{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning Accuracy</b>: <b>True</b> vs. False <b>Positive</b>/Negative", "url": "https://research.aimultiple.com/machine-learning-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://research.aimultiple.com/<b>machine-learning-accuracy</b>", "snippet": "There are various theoretical approaches to measuring <b>accuracy</b>* of competing <b>machine</b> <b>learning</b> models however, in most commercial applications, you simply need to assign a business value to 4 types of results: <b>true</b> positives, <b>true</b> negatives, false positives and false negatives.By multiplying number of results in each bucket with the associated business values, you will ensure that you use the best model available.", "dateLastCrawled": "2022-02-03T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>True Positive Rate</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/true-positive-rate", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>true-positive-rate</b>", "snippet": "Of the 266 images that contained NLs, 83 were classified as complete <b>true</b> positives and 27 were classified as partial <b>true</b> positives, which gives a total <b>true positive rate</b> of 42% and a false negative <b>rate</b> of 58%. All test images with no NLs were classified as <b>true</b> negatives. The remainder of our analysis was done via precision, recall, and specificity, and <b>accuracy</b>. Precision is the percentage of complete <b>true</b> <b>positive</b> matches out of all <b>true</b> <b>positive</b> matches. Recall is the percentage of ...", "dateLastCrawled": "2022-02-02T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | <b>Machine</b> ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/crash-course/classification/<b>true</b>-false...", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model correctly predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model correctly predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Classification: <b>Accuracy</b> | <b>Machine</b> <b>Learning</b> Crash Course | Google ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/accuracy", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/crash-course/classification/<b>accuracy</b>", "snippet": "<b>Accuracy</b> alone doesn&#39;t tell the full story when you&#39;re working with a class-imbalanced data set, <b>like</b> this one, where there is a significant disparity between the number of <b>positive</b> and negative labels. In the next section, we&#39;ll look at two better metrics for evaluating class-imbalanced problems: precision and recall. Key Terms", "dateLastCrawled": "2022-02-02T21:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b> | by Aditya Mishra ...", "url": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metrics-to-evaluate-your-<b>machine</b>-<b>learning</b>-<b>algorithm</b>-f10...", "snippet": "False <b>Positive</b> <b>Rate</b> and <b>True</b> <b>Positive</b> <b>Rate</b> both have values in the range [0, 1]. FPR and TPR both are computed at varying threshold values such as (0.00, 0.02, 0.04, \u2026., 1.00) and a graph is drawn. AUC is the area under the curve of plot False <b>Positive</b> <b>Rate</b> vs <b>True</b> <b>Positive</b> <b>Rate</b> at different points in [0, 1].", "dateLastCrawled": "2022-02-02T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning - Performance Metrics</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_algorithms_performance_metrics.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/.../<b>machine</b>_<b>learning</b>_<b>algorithms</b>_performance_metrics.htm", "snippet": "Mathematically, it can be created by plotting TPR (<b>True</b> <b>Positive</b> <b>Rate</b>) i.e. Sensitivity or recall vs FPR (False <b>Positive</b> <b>Rate</b>) i.e. 1-Specificity, at various threshold values. Following is the graph showing ROC, AUC having TPR at y-axis and FPR at x-axis \u2212. We can use roc_auc_score function of sklearn.metrics to compute AUC-ROC.", "dateLastCrawled": "2022-02-02T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Confusion Matrix</b>, <b>Accuracy</b>, Precision, Recall, F1 Score | by ...", "url": "https://medium.com/analytics-vidhya/confusion-matrix-accuracy-precision-recall-f1-score-ade299cf63cd", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>confusion-matrix</b>-<b>accuracy</b>-precision-recall-f1...", "snippet": "Now we will introduce the <b>confusion matrix</b> which is required to compute the <b>accuracy</b> of the <b>machine</b> <b>learning</b> <b>algorithm</b> in ... Recall is also known as sensitivity or <b>true</b> <b>positive</b> <b>rate</b> and is ...", "dateLastCrawled": "2022-02-02T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How good is your <b>Machine</b> <b>Learning</b> <b>Algorithm</b>? | MyDataModels", "url": "https://www.mydatamodels.com/learn/how-good-is-your-machine-learning-algorithm/", "isFamilyFriendly": true, "displayUrl": "https://www.mydatamodels.com/learn/how-good-is-your-<b>machine</b>-<b>learning</b>-<b>algorithm</b>", "snippet": "<b>Accuracy</b> is the metric that counts the proportion of correct predictions. On the one hand, the pessimist made 65 correct predictions over 100 hence a 65% <b>accuracy</b>. On the other hand, the optimist\u2019s <b>accuracy</b> is 35% because of 35 accurate predictions over 100. The pessimist is a better <b>Machine</b> <b>Learning</b> <b>Algorithm</b>. The two classes (infected and not-infected) are balanced (65 and 35). There are cases where the classes are unbalanced, i.e., one class represents 5% and the other 95%. The \u2018small ...", "dateLastCrawled": "2022-01-30T17:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Accuracy, Precision, and Recall</b> in Deep <b>Learning</b> | Paperspace Blog", "url": "https://blog.paperspace.com/deep-learning-metrics-precision-recall-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://blog.paperspace.com/deep-<b>learning</b>-metrics-precision-recall-<b>accuracy</b>", "snippet": "The model correctly classified two <b>Positive</b> samples, but incorrectly classified one Negative sample as <b>Positive</b>. Thus, the <b>True</b> <b>Positive</b> <b>rate</b> is 2 and the False <b>Positive</b> <b>rate</b> is 1, and the precision is 2/(2+1)=0.667. In other words, the trustiness percentage of the model when it says that a sample is <b>Positive</b> is 66.7%.", "dateLastCrawled": "2022-02-02T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Comparing the performance of different machine learning algorithms</b> ...", "url": "https://dibyendudeb.com/comparing-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://dibyendudeb.com/comparing-<b>machine</b>-<b>learning</b>-<b>algorithms</b>", "snippet": "Comparing <b>Machine</b> <b>Learning</b> Algorithms (MLAs) are important to come out with the best-suited <b>algorithm</b> for a particular problem. This post discusses comparing different <b>machine</b> <b>learning</b> algorithms and how we can do this using scikit-learn package of python. You will learn how to compare multiple MLAs at a time using more than one fit statistics provided by scikit-learn and also creating plots to visualize the differences.", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>True Positive Rate</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/true-positive-rate", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>true-positive-rate</b>", "snippet": "The hit <b>rate</b> (<b>true positive rate</b>, TPR i) ... , ThresholdSelector, optimizes one of a number of different evaluation metrics, including F-measure, precision, recall, <b>accuracy</b>, and <b>true positive rate</b> (see Section 5.7, page 163), by selecting a probability threshold on the classifier&#39;s output. Performance can measured on the training data, on a holdout set, or by cross-validation. The probabilities returned by the base learner can be rescaled into the full range [0,1], which is useful if the ...", "dateLastCrawled": "2022-02-02T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b> | by Aditya Mishra ...", "url": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metrics-to-evaluate-your-<b>machine</b>-<b>learning</b>-<b>algorithm</b>-f10...", "snippet": "False <b>Positive</b> <b>Rate</b> and <b>True</b> <b>Positive</b> <b>Rate</b> both have values in the range [0, 1]. FPR and TPR both are computed at varying threshold values such as (0.00, 0.02, 0.04, \u2026., 1.00) and a graph is drawn. AUC is the area under the curve of plot False <b>Positive</b> <b>Rate</b> vs <b>True</b> <b>Positive</b> <b>Rate</b> at different points in [0, 1].", "dateLastCrawled": "2022-02-02T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | <b>Machine</b> ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/crash-course/classification/<b>true</b>-false...", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model correctly predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model correctly predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Confusion Matrix</b>, <b>Accuracy</b>, Precision, Recall, F1 Score | by ...", "url": "https://medium.com/analytics-vidhya/confusion-matrix-accuracy-precision-recall-f1-score-ade299cf63cd", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>confusion-matrix</b>-<b>accuracy</b>-precision-recall-f1...", "snippet": "Now we will introduce the <b>confusion matrix</b> which is required to compute the <b>accuracy</b> of the <b>machine</b> <b>learning</b> <b>algorithm</b> in ... Recall is also known as sensitivity or <b>true</b> <b>positive</b> <b>rate</b> and is ...", "dateLastCrawled": "2022-02-02T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Accuracy, Precision, and Recall</b> in Deep <b>Learning</b> | Paperspace Blog", "url": "https://blog.paperspace.com/deep-learning-metrics-precision-recall-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://blog.paperspace.com/deep-<b>learning</b>-metrics-precision-recall-<b>accuracy</b>", "snippet": "The model correctly classified two <b>Positive</b> samples, but incorrectly classified one Negative sample as <b>Positive</b>. Thus, the <b>True</b> <b>Positive</b> <b>rate</b> is 2 and the False <b>Positive</b> <b>rate</b> is 1, and the precision is 2/(2+1)=0.667. In other words, the trustiness percentage of the model when it says that a sample is <b>Positive</b> is 66.7%.", "dateLastCrawled": "2022-02-02T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "8 popular Evaluation Metrics for <b>Machine</b> <b>Learning</b> Models - Just into Data", "url": "https://www.justintodata.com/machine-learning-model-evaluation-metrics/", "isFamilyFriendly": true, "displayUrl": "https://www.justintodata.com/<b>machine</b>-<b>learning</b>-model-evaluation-metrics", "snippet": "Classification <b>Accuracy</b>. This is the most intuitive model evaluation metric. When we make predictions by classifying the observations, the result is either correct (<b>True</b>) or incorrect (False). The classification <b>accuracy</b> measures the percentage of the correct classifications with the formula below: <b>Accuracy</b> = # of correct predictions / # of total predictions. The higher the <b>accuracy</b>, the more accurate the model. Yet, <b>accuracy</b> doesn\u2019t tell the full story, especially for imbalanced datasets ...", "dateLastCrawled": "2022-02-03T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Test <b>Your Machine Learning Model through Model Accuracy</b>", "url": "https://www.analyticsinsight.net/test-your-machine-learning-model-through-model-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsinsight.net/test-<b>your-machine-learning-model-through-model-accuracy</b>", "snippet": "A <b>machine</b> <b>learning</b> model bags the highest <b>accuracy</b> when it has realized and learned about the data correctly and desirably. Henceforth, the predictions made by it are close to the actual values. On the other hand, receiver operating characteristic (ROC) curve is created by plotting the <b>true</b> <b>positive</b> <b>rate</b> of the classifier against the false <b>positive</b> <b>rate</b> at various threshold settings. The", "dateLastCrawled": "2022-01-26T09:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Comparing the performance of different machine learning algorithms</b> ...", "url": "https://dibyendudeb.com/comparing-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://dibyendudeb.com/comparing-<b>machine</b>-<b>learning</b>-<b>algorithms</b>", "snippet": "Comparing <b>Machine</b> <b>Learning</b> Algorithms (MLAs) are important to come out with the best-suited <b>algorithm</b> for a particular problem. This post discusses comparing different <b>machine</b> <b>learning</b> algorithms and how we can do this using scikit-learn package of python. You will learn how to compare multiple MLAs at a time using more than one fit statistics provided by scikit-learn and also creating plots to visualize the differences.", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to Compare <b>Machine</b> <b>Learning</b> Models and Algorithms - neptune.ai", "url": "https://neptune.ai/blog/how-to-compare-machine-learning-models-and-algorithms", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/how-to-compare-<b>machine</b>-<b>learning</b>-models-and-<b>algorithms</b>", "snippet": "Each model or any <b>machine</b> <b>learning</b> <b>algorithm</b> has several features that process the data in different ways. Often the data that is fed to these algorithms is also different depending on previous experiment stages. But, since <b>machine</b> <b>learning</b> teams and developers usually record their experiments, there\u2019s ample data available for comparison. The challenge is to understand which parameters, data, and metadata must be considered to arrive at the final choice. It\u2019s the classic paradox of ...", "dateLastCrawled": "2022-02-03T07:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "python - Scikit-learn: How to obtain <b>True Positive</b>, <b>True</b> Negative ...", "url": "https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/31324218", "snippet": "python <b>machine</b>-<b>learning</b> scikit-learn classification supervised-<b>learning</b>. Share. Follow edited Mar 17 &#39;19 at 21:49. Taysky. 4,271 2 2 gold badges 17 17 silver badges 27 27 bronze badges. asked Jul 9 &#39;15 at 17:19. Euskalduna Euskalduna. 1,189 1 1 gold badge 10 10 silver badges 11 11 bronze badges. Add a comment | 19 Answers Active Oldest Votes. 156 For the multi-class case, everything you need can be found from the confusion matrix. For example, if your confusion matrix looks like this: Then ...", "dateLastCrawled": "2022-01-26T12:03:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Confusion matrix, accuracy, recall, precision, false positive</b> <b>rate</b> and ...", "url": "https://blog.nillsf.com/index.php/2020/05/23/confusion-matrix-accuracy-recall-precision-false-positive-rate-and-f-scores-explained/", "isFamilyFriendly": true, "displayUrl": "https://blog.nillsf.com/index.php/2020/05/23/confusion-matrix-<b>accuracy</b>-recall...", "snippet": "When building a <b>machine</b> <b>learning</b> model, it\u2019s important to measure the results of your model. Typically, you split a dataset into a training dataset and a test dataset. The training dataset is used to train your model, while the test dataset is used to measure the performance of your model. A commonly used method to measure the performance of a classification <b>algorithm</b> is a confusion matrix. A confusion matrix plots the amount of amount of correct predictions against the amount of incorrect ...", "dateLastCrawled": "2022-02-02T16:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification <b>Accuracy</b> is Not Enough: More Performance Measures You ...", "url": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/classification-<b>accuracy</b>-is-not-enough-", "snippet": "It is also called Sensitivity or the <b>True</b> <b>Positive</b> <b>Rate</b>. Recall <b>can</b> <b>be thought</b> of as a measure of a classifiers completeness. A low recall indicates many False Negatives. The recall of the All No Recurrence model is 0/(0+85) or 0. The recall of the All Recurrence model is 85/(85+0) or 1. The recall of CART is 10/(10+75) or 0.12. As you would expect, the All Recurrence model has a perfect recall because it predicts \u201crecurrence\u201d for all instances. The recall for CART is lower than that of ...", "dateLastCrawled": "2022-02-03T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "3 Section 2 - <b>Machine</b> <b>Learning</b> Basics Overview | Data Science <b>Machine</b> ...", "url": "https://1965eric.github.io/Machine_Learning/section-2-machine-learning-basics-overview.html", "isFamilyFriendly": true, "displayUrl": "https://1965eric.github.io/<b>Machine</b>_<b>Learning</b>/section-2-<b>machine</b>-<b>learning</b>-basics-overview...", "snippet": "Overall <b>accuracy</b> <b>can</b> sometimes be a deceptive measure because of unbalanced classes. A general improvement to using overall <b>accuracy</b> is to study sensitivity and specificity separately. Sensitivity, also known as the <b>true</b> <b>positive</b> <b>rate</b> or recall, is the proportion of actual <b>positive</b> outcomes correctly identified as such. Specificity, also known as the <b>true</b> negative <b>rate</b>, is the proportion of actual negative outcomes that are correctly identified as such. A confusion matrix tabulates each ...", "dateLastCrawled": "2022-01-31T13:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Accuracy</b>, Recall, <b>Precision</b>, F-Score &amp; Specificity, which to optimize ...", "url": "https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>accuracy</b>-recall-<b>precision</b>-f-score-specificity-which-to...", "snippet": "A school is running a <b>machine</b> <b>learning</b> primary diabetes scan on all of its students. The output is either diabetic (+ve) or healthy (-ve). There are only 4 cases any st u dent X could end up with. We\u2019ll be using the following as a reference later, So don\u2019t hesitate to re-read it if you get confused. <b>True</b> <b>positive</b> (TP): Prediction is +ve and X is diabetic, we want that; <b>True</b> negative (TN): Prediction is -ve and X is healthy, we want that too; False <b>positive</b> (FP): Prediction is +ve and X ...", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>machine</b> <b>learning</b> - Advantages of AUC vs standard <b>accuracy</b> - Data ...", "url": "https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/806", "snippet": "AUC measures how <b>true</b> <b>positive</b> <b>rate</b> (recall) and false <b>positive</b> <b>rate</b> trade off, so in that sense it is already measuring something else. More importantly, AUC is not a function of threshold. It is an evaluation of the classifier as threshold varies over all possible values. It is in a sense a broader metric, testing the quality of the internal value that the classifier generates and then compares to a threshold. It is not testing the quality of a particular choice of threshold.", "dateLastCrawled": "2022-01-27T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evaluation Metrics for <b>Machine Learning</b> - <b>Accuracy</b>, Precision, Recall ...", "url": "https://wiki.pathmind.com/accuracy-precision-recall-f1", "isFamilyFriendly": true, "displayUrl": "https://wiki.pathmind.com/<b>accuracy</b>-precision-recall-f1", "snippet": "<b>Thought</b> Vectors; Unsupervised <b>Learning</b>; Deep <b>Learning</b> Use Cases; Variational Autoencoder (VAE) Word2Vec, Doc2Vec and Neural Word Embeddings; Evaluation Metrics for <b>Machine Learning</b> - <b>Accuracy</b>, Precision, Recall, and F1 Defined. After a data scientist has chosen a target variable - e.g. the \u201ccolumn\u201d in a spreadsheet they wish to predict - and completed the prerequisites of transforming data and building a model, one of the final steps is evaluating the model\u2019s performance. Confusion ...", "dateLastCrawled": "2022-02-02T10:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "51 Essential <b>Machine Learning Interview Questions</b> and Answers ...", "url": "https://www.springboard.com/blog/ai-machine-learning/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.springboard.com/blog/ai-<b>machine</b>-<b>learning</b>/<b>machine-learning-interview-questions</b>", "snippet": "Mathematically, it\u2019s expressed as the <b>true</b> <b>positive</b> <b>rate</b> of a condition sample divided by the sum of the false <b>positive</b> <b>rate</b> of the population and the <b>true</b> <b>positive</b> <b>rate</b> of a condition. Say you had a 60% chance of actually having the flu after a flu test, but out of people who had the flu, the test will be false 50% of the time, and the overall population only has a 5% chance of having the flu. Would you actually have a 60% chance of having the flu after having a <b>positive</b> test?", "dateLastCrawled": "2022-02-03T02:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "python - Scikit-learn: How to obtain <b>True Positive</b>, <b>True</b> Negative ...", "url": "https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/31324218", "snippet": "python <b>machine</b>-<b>learning</b> scikit-learn classification supervised-<b>learning</b>. Share. Follow edited Mar 17 &#39;19 at 21:49. Taysky. 4,271 2 2 gold badges 17 17 silver badges 27 27 bronze badges. asked Jul 9 &#39;15 at 17:19. Euskalduna Euskalduna. 1,189 1 1 gold badge 10 10 silver badges 11 11 bronze badges. Add a comment | 19 Answers Active Oldest Votes. 156 For the multi-class case, everything you need <b>can</b> be found from the confusion matrix. For example, if your confusion matrix looks like this: Then ...", "dateLastCrawled": "2022-01-26T12:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> <b>Learning</b> 99+ Most Important MCQ Part-2 | <b>Machine</b> <b>Learning</b> MCQ ...", "url": "https://www.jobsaarnee.com/2021/06/machine-learning-100-most-important-mcq-part2.html", "isFamilyFriendly": true, "displayUrl": "https://www.jobsaarnee.com/2021/06/<b>machine</b>-<b>learning</b>-100-most-important-mcq-part2.html", "snippet": "Q74 Which of the following <b>machine</b> <b>learning</b> <b>algorithm</b> <b>can</b> be used for imputing missing values of both categorical and continuous variables? (a) K-NN (b) Linear Regression (c) Logistic Regression (d) None of the Above. Sol. (a) K-NN. Q75 Typically, value of k in k-nearest neighbors lie between-(a) 0 to1 (b) 1 to 20 (c) 20 to 50 (d) -1 to 1. Sol ...", "dateLastCrawled": "2022-02-03T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Exam 2 Class Questions</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/460364182/exam-2-class-questions-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/460364182/<b>exam-2-class-questions</b>-flash-cards", "snippet": "Which of the following is NOT <b>true</b> about <b>Machine</b> <b>Learning</b>? A. <b>Machine</b> <b>Learning</b> is a form of supervised <b>learning</b>. B. <b>Machine</b> <b>Learning</b> requires training, testing, and evaluation. C. <b>Machine</b> <b>Learning</b> is a subset of Deep <b>Learning</b> D. <b>Machine</b> <b>Learning</b> has a goal to get closer to automatic solutions. <b>Machine</b> <b>Learning</b> is a subset of Deep <b>Learning</b>. What is the most common approach for generating association rules? A. Apriori <b>Algorithm</b> B. Decision tree C. Clustering D. Regression. Apriori <b>Algorithm</b> ...", "dateLastCrawled": "2021-12-02T12:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>True Positive Rate</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/true-positive-rate", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>true-positive-rate</b>", "snippet": "Of the 266 images that contained NLs, 83 were classified as complete <b>true</b> positives and 27 were classified as partial <b>true</b> positives, which gives a total <b>true positive rate</b> of 42% and a false negative <b>rate</b> of 58%. All test images with no NLs were classified as <b>true</b> negatives. The remainder of our analysis was done via precision, recall, and specificity, and <b>accuracy</b>. Precision is the percentage of complete <b>true</b> <b>positive</b> matches out of all <b>true</b> <b>positive</b> matches. Recall is the percentage of ...", "dateLastCrawled": "2022-02-02T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is False <b>Positive</b> <b>Rate</b> - Deepchecks", "url": "https://deepchecks.com/glossary/false-positive-rate/", "isFamilyFriendly": true, "displayUrl": "https://deepchecks.com/glossary/false-<b>positive</b>-<b>rate</b>", "snippet": "A False <b>Positive</b> <b>Rate</b> is a metric that <b>can</b> be used to assess <b>machine</b> <b>learning</b> <b>accuracy</b>. A model must have some notion of \u201cground reality,\u201d or the <b>true</b> state of things, in order to get a reading on its <b>true</b> <b>accuracy</b>. The <b>accuracy</b> of models <b>can</b> then be directly evaluated by comparing their outputs to the ground reality.", "dateLastCrawled": "2022-01-13T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | <b>Machine</b> ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/crash-course/classification/<b>true</b>-false...", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model correctly predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model correctly predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Understanding the AUC-ROC Curve in <b>Machine</b> <b>Learning</b> Classification", "url": "https://analyticsindiamag.com/understanding-the-auc-roc-curve-in-machine-learning-classification/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/understanding-the-auc-roc-curve-in-<b>machine</b>-<b>learning</b>...", "snippet": "ROC Curves help determine the exact trade-off between the <b>true</b> <b>positive</b> <b>rate</b> and false-<b>positive</b> <b>rate</b> for a model using different measures of probability thresholds. ROC curves are more appropriate to be used when the observations present are balanced between each class. This method was first used in signal detection but is now also being used in many other areas such as medicine, radiology, natural hazards other than <b>machine</b> <b>learning</b>. A discrete classifier returns only the predicted class ...", "dateLastCrawled": "2022-02-03T00:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "34 <b>Crucial Interview Questions for Machine Learning</b>", "url": "https://www.naukri.com/blog/34-crucial-interview-questions-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.naukri.com/blog/34-<b>crucial-interview-questions-for-machine-learning</b>", "snippet": "Recall <b>can</b> also be called as the <b>true</b> <b>positive</b> <b>rate</b>, which means that the number of positives a model claims <b>compared</b> to the number of actual positives a data possesses. Precision is similar to recall and is known as a <b>positive</b> predictive value which is a measure of the number of accurate positives a model claims <b>compared</b> to the number of positives it claims. 19. Explain what is the function of \u2018Unsupervised <b>Learning</b>\u2019? The functions of unsupervised <b>learning</b> are: Discover interesting ...", "dateLastCrawled": "2022-01-31T16:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "assessment id-130", "url": "https://www.nptel.ac.in/content/storage2/courses/downloads/106106139/Week_07_Assignment_07.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.nptel.ac.in/content/storage2/courses/downloads/106106139/Week_07...", "snippet": "1) For the ROC curve of <b>True</b> <b>positive</b> <b>rate</b> vs False <b>positive</b> <b>rate</b>, which of the fo lowing are <b>true</b>? The cun.&#39;e is always concave (negative convex) The cun.&#39;e is never concave The cun.&#39;e may or may not be concave No, the answer is incorrect. Score: 0 Accepted Answers: The curve may or may not be concave Due on 2019-09-18, 23:59 IST. 1 point 1 point", "dateLastCrawled": "2022-02-01T18:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Classification: <b>Accuracy</b> | <b>Machine</b> <b>Learning</b> Crash Course | Google ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/accuracy", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/crash-course/classification/<b>accuracy</b>", "snippet": "Formally, <b>accuracy</b> has the following definition: <b>Accuracy</b> = Number of correct predictions Total number of predictions. For binary classification, <b>accuracy</b> <b>can</b> also be calculated in terms of positives and negatives as follows: <b>Accuracy</b> = T P + T N T P + T N + F P + F N. Where TP = <b>True</b> Positives, TN = <b>True</b> Negatives, FP = False Positives, and FN ...", "dateLastCrawled": "2022-02-02T21:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine learning: Evaluation metrics</b> | ML Cheat Sheet", "url": "https://medium.com/ml-cheat-sheet/machine-learning-evaluation-metrics-b89b8832e275", "isFamilyFriendly": true, "displayUrl": "https://medium.com/ml-cheat-sheet/<b>machine-learning-evaluation-metrics</b>-b89b8832e275", "snippet": "As we <b>can</b> see, from 1003 samples, we have 1002 samples correctly classified. The <b>accuracy</b> here is equal to 0,999.hallelujah, you have done a great job! (Now we <b>can</b> celebrate it with some champagne ...", "dateLastCrawled": "2022-02-02T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Comparing the performance of different machine learning algorithms</b> ...", "url": "https://dibyendudeb.com/comparing-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://dibyendudeb.com/comparing-<b>machine</b>-<b>learning</b>-<b>algorithms</b>", "snippet": "Comparing <b>Machine</b> <b>Learning</b> Algorithms (MLAs) are important to come out with the best-suited <b>algorithm</b> for a particular problem. This post discusses comparing different <b>machine</b> <b>learning</b> algorithms and how we <b>can</b> do this using scikit-learn package of python. You will learn how to compare multiple MLAs at a time using more than one fit statistics provided by scikit-learn and also creating plots to visualize the differences.", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "51 Essential <b>Machine Learning Interview Questions</b> and Answers ...", "url": "https://www.springboard.com/blog/ai-machine-learning/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.springboard.com/blog/ai-<b>machine</b>-<b>learning</b>/<b>machine-learning-interview-questions</b>", "snippet": "Mathematically, it\u2019s expressed as the <b>true</b> <b>positive</b> <b>rate</b> of a condition sample divided by the sum of the false <b>positive</b> <b>rate</b> of the population and the <b>true</b> <b>positive</b> <b>rate</b> of a condition. Say you had a 60% chance of actually having the flu after a flu test, but out of people who had the flu, the test will be false 50% of the time, and the overall population only has a 5% chance of having the flu. Would you actually have a 60% chance of having the flu after having a <b>positive</b> test?", "dateLastCrawled": "2022-02-03T02:34:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning Accuracy</b>: <b>True</b> vs. False <b>Positive</b>/Negative", "url": "https://research.aimultiple.com/machine-learning-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://research.aimultiple.com/<b>machine-learning-accuracy</b>", "snippet": "There are various theoretical approaches to measuring accuracy* of competing <b>machine</b> <b>learning</b> models however, in most commercial applications, you simply need to assign a business value to 4 types of results: <b>true</b> positives, <b>true</b> negatives, false positives and false negatives.By multiplying number of results in each bucket with the associated business values, you will ensure that you use the best model available.", "dateLastCrawled": "2022-02-03T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "It essentially shows the <b>True</b> <b>Positive</b> <b>Rate</b> (TPR) against the False <b>Positive</b> <b>Rate</b> (FPR) for various threshold values. AUC The Area Under the Curve (AUC), is an aggregated measure of performance of a binary classifier on all possible threshold values (and therefore it is threshold invariant). AUC calculates the area under the ROC curve, and therefore it is between 0 and 1. One way of interpreting AUC is the probability that the model ranks a random <b>positive</b> example more highly than a random ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning from positive</b> and unlabeled data: a survey - <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "The SCAR assumption was introduced in <b>analogy</b> with the Missing Completely A Random assumption (MCAR) that is common when ... the <b>true</b> <b>positive</b> <b>rate</b>, the false <b>positive</b> <b>rate</b>, and precision. Hence, it is possible in this circumstance to report estimates of these metrics. PU <b>learning</b> methods. This section provides an overview of the methods that address PU <b>learning</b>. Most methods can be divided into the following three categories: Two-step techniques, biased <b>learning</b> and class prior ...", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) A Comparison of Various <b>Machine</b> <b>Learning</b> Algorithms in a ...", "url": "https://www.academia.edu/68902781/A_Comparison_of_Various_Machine_Learning_Algorithms_in_a_Distributed_Denial_of_Service_Intrusion", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/68902781/A_Comparison_of_Various_<b>Machine</b>_<b>Learning</b>_Algorithms...", "snippet": "2) <b>True</b> <b>Positive</b> <b>Rate</b> (TPR) 4) Decision Tree (DT) This metric calculates how often the model is able to predict a This algorithm uses a tree structure <b>analogy</b> to represent a <b>positive</b> result correctly. Similar to Accuracy, but difference is series of rules that lead to a class or value [16]. It starts with a it only takes <b>positive</b> observation. root node, which is the best predictor. Then, it progresses TPR:: \ud835\udc47\ud835\udc43 through branch nodes to other predictors. Ultimately it reaches \ud835\udc47\ud835\udc43 ...", "dateLastCrawled": "2022-02-05T20:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The Receiver Operating Curve (ROC) and The Scale \u2014 Understanding ROC ...", "url": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the-scale-understanding-roc-through-an-analogy-8b8f9d954f84", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the...", "snippet": "The <b>rate</b> of <b>True</b> Positives is also called Sensitivity. Similarly, the <b>rate</b> of False Positives means counting the False Positives as part of the actual Negatives. In other words, represents the ...", "dateLastCrawled": "2021-02-13T00:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evaluation metric for Supervised <b>Learning</b>: | by Anuganti Suresh | Medium", "url": "https://anugantisuresh.medium.com/evaluation-metric-for-supervised-learning-ba063f1bb1af", "isFamilyFriendly": true, "displayUrl": "https://anugantisuresh.medium.com/evaluation-metric-for-supervised-<b>learning</b>-ba063f1bb1af", "snippet": "In <b>machine</b> <b>learning</b>, ... By <b>analogy</b>, Higher the AUC, better the model is at distinguishing between patients with disease and no disease. a. AUC : Area Under Curve. One of the widely used metrics for binary classification is the Area Under Curve(AUC) AUC represents the probability that the classifier will rank a randomly chosen <b>positive</b> example higher than a randomly chosen negative example. The AUC is based on a plot of the false <b>positive</b> <b>rate</b> vs the <b>true</b> <b>positive</b> <b>rate</b> which are defined as ...", "dateLastCrawled": "2022-01-06T20:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is <b>True</b> Negative, and a pregnant woman whose test results say \u201cPregnant\u201d is <b>True</b> <b>Positive</b>. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Evaluation Metric Special ROC-AUC Candra\u2019s blog", "url": "https://saltfarmer.github.io/blog/machine%20learning/Evaluation-Metrics-Special-ROCAUC/", "isFamilyFriendly": true, "displayUrl": "https://saltfarmer.github.io/blog/<b>machine</b> <b>learning</b>/Evaluation-Metrics-Special-ROCAUC", "snippet": "The ROC curve is created by plotting the <b>true</b> <b>positive</b> <b>rate</b> (TPR) against the false <b>positive</b> <b>rate</b> (FPR) at various threshold settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s ...", "dateLastCrawled": "2022-02-03T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "ROC (Receiver Operating Characteristic curve): A curve of <b>true</b> <b>positive</b> <b>rate</b> vs. false <b>positive</b> <b>rate</b> at different classification thresholds. The x-axis is False <b>Positive</b> <b>rate</b>, and the y-axis is <b>True</b> <b>Positive</b> <b>rate</b>. [3] . Close to the up left point (TPR=1.0, FPR=0.0) indicates the model is better.", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Chi-squared tests to <b>compare two machine learning models and determine</b> ...", "url": "https://towardsdatascience.com/chi-squared-tests-to-compare-two-machine-learning-models-and-determine-whether-they-are-random-2a405fc55181", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/chi-squared-tests-to-compare-two-<b>machine</b>-<b>learning</b>...", "snippet": "Take T as the random variable describing the number of <b>true</b> <b>positive</b> instances (Heads by the coin <b>analogy</b>). Doesn\u2019t T follow a binomial distribution with p=0.65 (probability of <b>positive</b>) and n=69 (total data instances)? Sure it does. I assume you know that binomial distribution can be approximated from a normal distribution, provided both np and n(1-p) exceed 10. Accordingly, we get a normal variable z~N(0,1)", "dateLastCrawled": "2022-01-29T04:24:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "On <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> - Online courses and text books ...", "url": "https://www.linkedin.com/pulse/machine-learning-deep-online-courses-text-books-point-ajay-taneja-1f", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/<b>machine</b>-<b>learning</b>-deep-online-courses-text-books-point...", "snippet": "On <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> - Online courses and text books - A point of view \u2013 Evaluation Metrics (Part 2) Published on October 4, 2020 October 4, 2020 \u2022 8 Likes \u2022 0 Comments", "dateLastCrawled": "2021-08-15T14:28:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(true positive rate)  is like +(accuracy of a machine learning algorithm)", "+(true positive rate) is similar to +(accuracy of a machine learning algorithm)", "+(true positive rate) can be thought of as +(accuracy of a machine learning algorithm)", "+(true positive rate) can be compared to +(accuracy of a machine learning algorithm)", "machine learning +(true positive rate AND analogy)", "machine learning +(\"true positive rate is like\")", "machine learning +(\"true positive rate is similar\")", "machine learning +(\"just as true positive rate\")", "machine learning +(\"true positive rate can be thought of as\")", "machine learning +(\"true positive rate can be compared to\")"]}