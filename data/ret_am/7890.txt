{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Rationality Quotes February 2013</b> - LessWrong", "url": "https://www.lesswrong.com/posts/YeS5yESwcFcK57LQk/rationality-quotes-february-2013", "isFamilyFriendly": true, "displayUrl": "https://www.lesswrong.com/posts/YeS5yESwcFcK57LQk/<b>rationality-quotes-february-2013</b>", "snippet": "But sampled on a long timescale <b>you</b> just get a sequence of <b>i.i.d</b>. independent pairs. For cyclic graphs, I&#39;m not sure how &quot;path cancellation&quot; is defined, if it is at all. The generic causal graph of the archetypal control system has arrows D --&gt; P --&gt; O and R --&gt; O --&gt; P, there being a cycle between P and O. The four variables are the Disturbance, the Perception, the Output, and the Reference. If P = O+D, O is proportional to the integral of R-P, R = zero, and D is a signal varying generally ...", "dateLastCrawled": "2022-01-24T03:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Coherence arguments do not entail goal-directed behavior - LessWrong", "url": "https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail-goal-directed-behavior", "isFamilyFriendly": true, "displayUrl": "https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail...", "snippet": "If <b>you</b> believe that, then <b>you</b> should believe that the argument for AI risk should also work in a deterministic universe in which the AI can <b>perfectly</b> predict exactly what the universe does. However, in such a universe, the VNM theorem is nearly contentless -- the AI has no need of probability, and most of the VNM axioms are irrelevant. All <b>you</b> get with the VNM theorem in such a universe is that the AI&#39;s ordering over outcomes is transitive: If it chooses A over B and B over C, then it also ...", "dateLastCrawled": "2021-12-17T01:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Coherence arguments do not entail goal-directed behavior - LessWrong 2 ...", "url": "https://www.greaterwrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-imply-goal-directed-behavior", "isFamilyFriendly": true, "displayUrl": "https://www.greaterwrong.com/posts/NxF5G6CJiof6cemTw/<b>coherence-arguments-do-not-imply</b>...", "snippet": "If <b>you</b> believe that, then <b>you</b> should believe that the argument for AI risk should also work in a deterministic universe in which the AI can <b>perfectly</b> predict exactly what the universe does. However, in such a universe, the VNM theorem is nearly contentless\u2014the AI has no need of probability, and most of the VNM axioms are irrelevant. All <b>you</b> get with the VNM theorem in such a universe is that the AI\u2019s ordering over outcomes is transitive: If it chooses A over B and B over C, then it also ...", "dateLastCrawled": "2021-12-25T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Reinforcement Learning</b> in Economics and Finance | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10614-021-10119-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10614-021-10119-4", "snippet": "<b>Reinforcement learning</b> algorithms describe how an agent can <b>learn</b> an optimal action policy in a sequential decision process, through repeated experience. In a given environment, the agent policy provides him some running and terminal rewards. As in online learning, the agent learns sequentially. As in multi-armed bandit problems, when an agent picks an action, he can not infer ex-post the rewards induced by other action choices. In <b>reinforcement learning</b>, his actions have consequences: they ...", "dateLastCrawled": "2022-02-01T15:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) RESOURCE BOOKLET FOR TEACHERS OF ENGLISH AS A FOREIGN LANGUAGE IN ...", "url": "https://www.academia.edu/7520861/RESOURCE_BOOKLET_FOR_TEACHERS_OF_ENGLISH_AS_A_FOREIGN_LANGUAGE_IN_CENTRAL_ASIA_BY_ERCILIA_DELANCER_ENGLISH_LANGUAGE_FELLOW_PEACE_CORPS_VOLUNTEER", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/7520861/RESOURCE_BOOKLET_FOR_TEACHERS_OF_ENGLISH_AS_A_FOREIGN...", "snippet": "RESOURCE BOOKLET FOR TEACHERS OF ENGLISH AS A FOREIGN LANGUAGE IN CENTRAL ASIA BY <b>ERCILIA DELANCER ENGLISH LANGUAGE FELLOW PEACE CORPS VOLUNTEER</b>", "dateLastCrawled": "2022-01-27T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Applications of Discrete Mathematics, Rosen</b> | PDF | Randomness | Markov ...", "url": "https://www.scribd.com/document/373493074/Applications-of-Discrete-Mathematics-Rosen", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/373493074/<b>Applications-of-Discrete-Mathematics-Rosen</b>", "snippet": "Write a computer <b>program</b> to apportion the House by the method of major fractions using the lambda method. 2. Write a computer <b>program</b> to apportion the House by the method of major fractions using the sequential (ri ) method. 3. Write <b>a program</b> which will check all apportionments consistent with rank order of size (no state which is smaller than another state will receive more seats, but equality of seats is allowed). 2. Finite Markov Chains. Author: Eric Rieders, Department of the ...", "dateLastCrawled": "2021-12-25T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Reinforcement learning for cyber-physical systems with cybersecurity ...", "url": "https://dokumen.pub/reinforcement-learning-for-cyber-physical-systems-with-cybersecurity-case-studies-9781351006590-1351006592-9781351006606-1351006606-9781351006613-1351006614-9781351006620-1351006622-9781138543539.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/reinforcement-<b>learn</b>ing-for-cyber-physical-systems-with-cyber...", "snippet": "Years later, Donald Michie and Roger A. Chambers in [105] described another <b>tic-tac-toe</b> agent called GLEE (Game Learning Expectimaxing Engine) and a reinforcement learning controller called BOXES. They applied BOXES to the task of learning to balance a pole hinged to a movable cart. Michie and Chambers\u2019 version of pole-balancing is one of the best early examples of a reinforcement learning task under conditions of incomplete knowledge. It influenced much later work in reinforcement ...", "dateLastCrawled": "2022-01-23T02:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "February | 2019 | Freakonometrics", "url": "https://freakonometrics.hypotheses.org/date/2019/02", "isFamilyFriendly": true, "displayUrl": "https://freakonometrics.hypotheses.org/date/2019/02", "snippet": "A first application was to teach a machine to <b>play</b> a game (<b>tic-tac-toe</b>, chess, go, etc.). An essential step is to explain the objective it must achieve to win. One historical approach has been to teach the machine the rules of the game. If it allows <b>you</b> to <b>play</b>, it will not help the machine to <b>play</b> well. Assuming that the machine knows the rules of the game, and that it has a choice between several dozen possible moves, which one should it choose? The classical approach in artificial ...", "dateLastCrawled": "2022-01-29T07:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Computer Vision</b> | sandipanweb", "url": "https://sandipanweb.wordpress.com/category/computer-vision/", "isFamilyFriendly": true, "displayUrl": "https://sandipanweb.wordpress.com/category/<b>computer-vision</b>", "snippet": "Since <b>Tic-Tac-Toe</b> is a tie given optimal <b>play</b> by both sides, <b>you</b> should never be able to beat the AI (though if <b>you</b> don\u2019t <b>play</b> optimally as well, it may beat <b>you</b>!) The following figure demonstrates the basic concepts of adversarial search and Game and defines the different functions for <b>tic-tac-toe</b>. Here we shall use Minimax with alpha-beta pruning to speedup the game when it is computer\u2019s turn. The following python code fragment shows how to implement the minimax algorithm with alpha ...", "dateLastCrawled": "2022-02-03T09:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Let the Sun Shine In - Orrymain - Stargate SG-1 [SquidgeWorld Archive]", "url": "https://squidgeworld.org/collections/pejas_wwomb/works/15396", "isFamilyFriendly": true, "displayUrl": "https://squidgeworld.org/collections/pejas_wwomb/works/15396", "snippet": "I hope <b>you</b> understand the worry <b>you</b> cause when <b>you</b> get lost <b>like</b> this. I want <b>you</b> both to tell your fathers about what <b>you</b> did today because I think they need to know, but I&#39;m sorry for snapping at <b>you</b> and for letting my own past affect my judgment. I&#39;m just so glad <b>you</b>&#39;re safe,&quot; Alex expressed, surprising everyone when he drew the boys in for a long hug.", "dateLastCrawled": "2021-12-08T07:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Rationality Quotes February 2013</b> - LessWrong", "url": "https://www.lesswrong.com/posts/YeS5yESwcFcK57LQk/rationality-quotes-february-2013", "isFamilyFriendly": true, "displayUrl": "https://www.lesswrong.com/posts/YeS5yESwcFcK57LQk/<b>rationality-quotes-february-2013</b>", "snippet": "But sampled on a long timescale <b>you</b> just get a sequence of <b>i.i.d</b>. independent pairs. For cyclic graphs, I&#39;m not sure how &quot;path cancellation&quot; is defined, if it is at all. The generic causal graph of the archetypal control system has arrows D --&gt; P --&gt; O and R --&gt; O --&gt; P, there being a cycle between P and O. The four variables are the Disturbance, the Perception, the Output, and the Reference. If P = O+D, O is proportional to the integral of R-P, R = zero, and D is a signal varying generally ...", "dateLastCrawled": "2022-01-24T03:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Coherence arguments do not entail goal-directed behavior - LessWrong 2 ...", "url": "https://www.greaterwrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-imply-goal-directed-behavior", "isFamilyFriendly": true, "displayUrl": "https://www.greaterwrong.com/posts/NxF5G6CJiof6cemTw/<b>coherence-arguments-do-not-imply</b>...", "snippet": "If <b>you</b> believe that, then <b>you</b> should believe that the argument for AI risk should also work in a deterministic universe in which the AI can <b>perfectly</b> predict exactly what the universe does. However, in such a universe, the VNM theorem is nearly contentless\u2014the AI has no need of probability, and most of the VNM axioms are irrelevant. All <b>you</b> get with the VNM theorem in such a universe is that the AI\u2019s ordering over outcomes is transitive: If it chooses A over B and B over C, then it also ...", "dateLastCrawled": "2021-12-25T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Reinforcement Learning</b> in Economics and Finance | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10614-021-10119-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10614-021-10119-4", "snippet": "<b>Reinforcement learning</b> algorithms describe how an agent can <b>learn</b> an optimal action policy in a sequential decision process, through repeated experience. In a given environment, the agent policy provides him some running and terminal rewards. As in online learning, the agent learns sequentially. As in multi-armed bandit problems, when an agent picks an action, he can not infer ex-post the rewards induced by other action choices. In <b>reinforcement learning</b>, his actions have consequences: they ...", "dateLastCrawled": "2022-02-01T15:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) RESOURCE BOOKLET FOR TEACHERS OF ENGLISH AS A FOREIGN LANGUAGE IN ...", "url": "https://www.academia.edu/7520861/RESOURCE_BOOKLET_FOR_TEACHERS_OF_ENGLISH_AS_A_FOREIGN_LANGUAGE_IN_CENTRAL_ASIA_BY_ERCILIA_DELANCER_ENGLISH_LANGUAGE_FELLOW_PEACE_CORPS_VOLUNTEER", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/7520861/RESOURCE_BOOKLET_FOR_TEACHERS_OF_ENGLISH_AS_A_FOREIGN...", "snippet": "RESOURCE BOOKLET FOR TEACHERS OF ENGLISH AS A FOREIGN LANGUAGE IN CENTRAL ASIA BY <b>ERCILIA DELANCER ENGLISH LANGUAGE FELLOW PEACE CORPS VOLUNTEER</b>", "dateLastCrawled": "2022-01-27T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Computer Vision</b> | sandipanweb", "url": "https://sandipanweb.wordpress.com/category/computer-vision/", "isFamilyFriendly": true, "displayUrl": "https://sandipanweb.wordpress.com/category/<b>computer-vision</b>", "snippet": "Since <b>Tic-Tac-Toe</b> is a tie given optimal <b>play</b> by both sides, <b>you</b> should never be able to beat the AI (though if <b>you</b> don\u2019t <b>play</b> optimally as well, it may beat <b>you</b>!) The following figure demonstrates the basic concepts of adversarial search and Game and defines the different functions for <b>tic-tac-toe</b>. Here we shall use Minimax with alpha-beta pruning to speedup the game when it is computer\u2019s turn. The following python code fragment shows how to implement the minimax algorithm with alpha ...", "dateLastCrawled": "2022-02-03T09:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Applications of Discrete Mathematics, Rosen</b> | PDF | Randomness | Markov ...", "url": "https://www.scribd.com/document/373493074/Applications-of-Discrete-Mathematics-Rosen", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/373493074/<b>Applications-of-Discrete-Mathematics-Rosen</b>", "snippet": "Instead of being given an answer to a problem, the reader will <b>learn</b> how to ask questions which can be answered, and make use of the answers. This process includes deciding upon objectives, building algorithms to obtain those objec- tives, determining whether the algorithms will work within reasonable time constraints, and determining when two algorithms achieve the same \ufb01nal out- put.", "dateLastCrawled": "2021-12-25T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Java Collections</b> | PDF - Scribd", "url": "https://www.scribd.com/doc/88854047/84736540-Java-Collections-pdf", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/doc/88854047/84736540-<b>Java-Collections</b>-pdf", "snippet": "Of course, when <b>you</b> wish to write a Java <b>program</b> that manipulates character strings, <b>you</b> neither know nor care how strings are represented. <b>You</b> simply declare variables of type String, and manipulate them by calling methods provided by the Java. lang. String class. String is a simple example of what we call an abstract data type. <b>You</b> are told the name of the abstract data type, and the general properties of objects of that type, and the names of methods for manipulating these objects. But ...", "dateLastCrawled": "2021-12-14T12:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "February | 2019 | Freakonometrics", "url": "https://freakonometrics.hypotheses.org/date/2019/02", "isFamilyFriendly": true, "displayUrl": "https://freakonometrics.hypotheses.org/date/2019/02", "snippet": "A first application was to teach a machine to <b>play</b> a game (<b>tic-tac-toe</b>, chess, go, etc.). An essential step is to explain the objective it must achieve to win. One historical approach has been to teach the machine the rules of the game. If it allows <b>you</b> to <b>play</b>, it will not help the machine to <b>play</b> well. Assuming that the machine knows the rules of the game, and that it has a choice between several dozen possible moves, which one should it choose? The classical approach in artificial ...", "dateLastCrawled": "2022-01-29T07:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Creature-Crossing <b>DeviantArt</b> Gallery", "url": "https://www.deviantart.com/creature-crossing/gallery/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.deviantart.com</b>/creature-crossing/gallery", "snippet": "Greg stuttered, \u201cI-<b>I-I d</b>-didn\u2019t do a-anything-!\u201d Root bapped Greg on the face, their paws a bit too small to properly slap him. Greg continued, \u201cW-We just found him! I-I thought maybe <b>you</b> would k-know where he\u2019s b-been today\u2026\u201d The white fae scowled and hopped off the sloth. They walked over to the statue, looking at the frozen gerbil. They sighed, \u201cHe was going to have breakfast at Gramp\u2019s place, and then planned on coming over to see <b>you</b>. Kept texting on his phone.\u201d Greg ...", "dateLastCrawled": "2022-01-30T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>sandipanweb</b> | Simply Data Science | Page 2", "url": "https://sandipanweb.wordpress.com/page/2/", "isFamilyFriendly": true, "displayUrl": "https://<b>sandipanweb</b>.wordpress.com/page/2", "snippet": "Since <b>Tic-Tac-Toe</b> is a tie given optimal <b>play</b> by both sides, <b>you</b> should never be able to beat the AI (though if <b>you</b> don\u2019t <b>play</b> optimally as well, it may beat <b>you</b>!) The following figure demonstrates the basic concepts of adversarial search and Game and defines the different functions for <b>tic-tac-toe</b>. Here we shall use Minimax with alpha-beta pruning to speedup the game when it is computer\u2019s turn. The following python code fragment shows how to implement the minimax algorithm with alpha ...", "dateLastCrawled": "2022-01-22T22:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Coherence arguments do not entail goal-directed behavior - AI Alignment ...", "url": "https://www.alignmentforum.org/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail-goal-directed-behavior", "isFamilyFriendly": true, "displayUrl": "https://www.alignmentforum.org/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not...", "snippet": "If <b>you</b> believe that, then <b>you</b> should believe that the argument for AI risk should also work in a deterministic universe in which the AI <b>can</b> <b>perfectly</b> predict exactly what the universe does. However, in such a universe, the VNM theorem is nearly contentless -- the AI has no need of probability, and most of the VNM axioms are irrelevant. All <b>you</b> get with the VNM theorem in such a universe is that the AI&#39;s ordering over outcomes is transitive: If it chooses A over B and B over C, then it also ...", "dateLastCrawled": "2022-01-30T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Reinforcement Learning</b> in Economics and Finance | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10614-021-10119-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10614-021-10119-4", "snippet": "<b>Reinforcement learning</b> algorithms describe how an agent <b>can</b> <b>learn</b> an optimal action policy in a sequential decision process, through repeated experience. In a given environment, the agent policy provides him some running and terminal rewards. As in online learning, the agent learns sequentially. As in multi-armed bandit problems, when an agent picks an action, he <b>can</b> not infer ex-post the rewards induced by other action choices. In <b>reinforcement learning</b>, his actions have consequences: they ...", "dateLastCrawled": "2022-02-01T15:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Coherence arguments do not entail goal-directed behavior - LessWrong 2 ...", "url": "https://www.greaterwrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-imply-goal-directed-behavior", "isFamilyFriendly": true, "displayUrl": "https://www.greaterwrong.com/posts/NxF5G6CJiof6cemTw/<b>coherence-arguments-do-not-imply</b>...", "snippet": "If <b>you</b> believe that, then <b>you</b> should believe that the argument for AI risk should also work in a deterministic universe in which the AI <b>can</b> <b>perfectly</b> predict exactly what the universe does. However, in such a universe, the VNM theorem is nearly contentless\u2014the AI has no need of probability, and most of the VNM axioms are irrelevant. All <b>you</b> get with the VNM theorem in such a universe is that the AI\u2019s ordering over outcomes is transitive: If it chooses A over B and B over C, then it also ...", "dateLastCrawled": "2021-12-25T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Coherence arguments do not entail goal-directed behavior - LessWrong", "url": "https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail-goal-directed-behavior", "isFamilyFriendly": true, "displayUrl": "https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail...", "snippet": "If <b>you</b> believe that, then <b>you</b> should believe that the argument for AI risk should also work in a deterministic universe in which the AI <b>can</b> <b>perfectly</b> predict exactly what the universe does. However, in such a universe, the VNM theorem is nearly contentless -- the AI has no need of probability, and most of the VNM axioms are irrelevant. All <b>you</b> get with the VNM theorem in such a universe is that the AI&#39;s ordering over outcomes is transitive: If it chooses A over B and B over C, then it also ...", "dateLastCrawled": "2021-12-17T01:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Applications of Discrete Mathematics, Rosen</b> | PDF | Randomness | Markov ...", "url": "https://www.scribd.com/document/373493074/Applications-of-Discrete-Mathematics-Rosen", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/373493074/<b>Applications-of-Discrete-Mathematics-Rosen</b>", "snippet": "Instead of being given an answer to a problem, the reader will <b>learn</b> how to ask questions which <b>can</b> be answered, and make use of the answers. This process includes deciding upon objectives, building algorithms to obtain those objec- tives, determining whether the algorithms will work within reasonable time constraints, and determining when two algorithms achieve the same \ufb01nal out- put.", "dateLastCrawled": "2021-12-25T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "RESOURCE BOOKLET FOR TEACHERS OF ENGLISH AS A FOREIGN ... - Academia.edu", "url": "https://www.academia.edu/7520861/RESOURCE_BOOKLET_FOR_TEACHERS_OF_ENGLISH_AS_A_FOREIGN_LANGUAGE_IN_CENTRAL_ASIA_BY_ERCILIA_DELANCER_ENGLISH_LANGUAGE_FELLOW_PEACE_CORPS_VOLUNTEER", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/7520861/RESOURCE_BOOKLET_FOR_TEACHERS_OF_ENGLISH_AS_A_FOREIGN...", "snippet": "RESOURCE BOOKLET FOR TEACHERS OF ENGLISH AS A FOREIGN LANGUAGE IN CENTRAL ASIA BY <b>ERCILIA DELANCER ENGLISH LANGUAGE FELLOW PEACE CORPS VOLUNTEER</b>", "dateLastCrawled": "2022-01-27T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) M AC H I N E LEARNING | moch chamadani - Academia.edu", "url": "https://www.academia.edu/31654807/M_AC_H_I_N_E_LEARNING", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/31654807/M_AC_H_I_N_E_<b>LEARN</b>ING", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-02T07:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Let the Sun Shine In - Orrymain - Stargate SG-1 [SquidgeWorld Archive]", "url": "https://squidgeworld.org/collections/pejas_wwomb/works/15396", "isFamilyFriendly": true, "displayUrl": "https://squidgeworld.org/collections/pejas_wwomb/works/15396", "snippet": "&quot;<b>You</b>&#39;ve put some <b>thought</b> into this, I <b>can</b> tell,&quot; the designer praised. &quot;I have a lot <b>to learn</b>,&quot; Jennifer replied. &quot;And a lot of time <b>to learn</b> in,&quot; the designer responded supportively. ~Let&#39;s give her a challenge, and see how she does with that,~ he <b>thought</b>. &quot;Now, stop and think some more, Jen. Are <b>you</b> the only person who has ever encountered this design challenge?&quot; &quot;I suppose not.&quot; Alex queried, &quot;What would the solution <b>you</b> are seeking look like?&quot; &quot;Well, I guess it would fold up like a ...", "dateLastCrawled": "2021-12-08T07:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "February | 2019 | Freakonometrics", "url": "https://freakonometrics.hypotheses.org/date/2019/02", "isFamilyFriendly": true, "displayUrl": "https://freakonometrics.hypotheses.org/date/2019/02", "snippet": "A first application was to teach a machine to <b>play</b> a game (<b>tic-tac-toe</b>, chess, go, etc.). An essential step is to explain the objective it must achieve to win. One historical approach has been to teach the machine the rules of the game. If it allows <b>you</b> to <b>play</b>, it will not help the machine to <b>play</b> well. Assuming that the machine knows the rules of the game, and that it has a choice between several dozen possible moves, which one should it choose? The classical approach in artificial ...", "dateLastCrawled": "2022-01-29T07:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Rationality Quotes February 2013</b> - LessWrong", "url": "https://www.lesswrong.com/posts/YeS5yESwcFcK57LQk/rationality-quotes-february-2013", "isFamilyFriendly": true, "displayUrl": "https://www.lesswrong.com/posts/YeS5yESwcFcK57LQk/<b>rationality-quotes-february-2013</b>", "snippet": "<b>You</b> should do it when <b>you</b> spot regularities <b>you</b> <b>can</b> eke efficiency out of. But <b>you</b> should do this only if it does not make the code unwieldy or unnatural, and only if it does not make the code fragile. Beliefs should be the same thing. When your rules of thumb seem to respect some regularity in reality, I&#39;m <b>perfectly</b> happy to call that &quot;truth&quot;. So long as that does not break my tools.", "dateLastCrawled": "2022-01-24T03:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Coherence arguments do not entail goal-directed behavior - AI Alignment ...", "url": "https://www.alignmentforum.org/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail-goal-directed-behavior", "isFamilyFriendly": true, "displayUrl": "https://www.alignmentforum.org/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not...", "snippet": "If <b>you</b> believe that, then <b>you</b> should believe that the argument for AI risk should also work in a deterministic universe in which the AI <b>can</b> <b>perfectly</b> predict exactly what the universe does. However, in such a universe, the VNM theorem is nearly contentless -- the AI has no need of probability, and most of the VNM axioms are irrelevant. All <b>you</b> get with the VNM theorem in such a universe is that the AI&#39;s ordering over outcomes is transitive: If it chooses A over B and B over C, then it also ...", "dateLastCrawled": "2022-01-30T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Coherence arguments do not entail goal-directed behavior - LessWrong 2 ...", "url": "https://www.greaterwrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-imply-goal-directed-behavior", "isFamilyFriendly": true, "displayUrl": "https://www.greaterwrong.com/posts/NxF5G6CJiof6cemTw/<b>coherence-arguments-do-not-imply</b>...", "snippet": "If <b>you</b> believe that, then <b>you</b> should believe that the argument for AI risk should also work in a deterministic universe in which the AI <b>can</b> <b>perfectly</b> predict exactly what the universe does. However, in such a universe, the VNM theorem is nearly contentless\u2014the AI has no need of probability, and most of the VNM axioms are irrelevant. All <b>you</b> get with the VNM theorem in such a universe is that the AI\u2019s ordering over outcomes is transitive: If it chooses A over B and B over C, then it also ...", "dateLastCrawled": "2021-12-25T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Coherence arguments do not entail goal-directed behavior - LessWrong", "url": "https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail-goal-directed-behavior", "isFamilyFriendly": true, "displayUrl": "https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail...", "snippet": "If <b>you</b> believe that, then <b>you</b> should believe that the argument for AI risk should also work in a deterministic universe in which the AI <b>can</b> <b>perfectly</b> predict exactly what the universe does. However, in such a universe, the VNM theorem is nearly contentless -- the AI has no need of probability, and most of the VNM axioms are irrelevant. All <b>you</b> get with the VNM theorem in such a universe is that the AI&#39;s ordering over outcomes is transitive: If it chooses A over B and B over C, then it also ...", "dateLastCrawled": "2021-12-17T01:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) RESOURCE BOOKLET FOR TEACHERS OF ENGLISH AS A FOREIGN LANGUAGE IN ...", "url": "https://www.academia.edu/7520861/RESOURCE_BOOKLET_FOR_TEACHERS_OF_ENGLISH_AS_A_FOREIGN_LANGUAGE_IN_CENTRAL_ASIA_BY_ERCILIA_DELANCER_ENGLISH_LANGUAGE_FELLOW_PEACE_CORPS_VOLUNTEER", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/7520861/RESOURCE_BOOKLET_FOR_TEACHERS_OF_ENGLISH_AS_A_FOREIGN...", "snippet": "resource booklet for teachers of english as a foreign language in central asia by <b>ercilia delancer english language fellow peace corps volunteer</b>", "dateLastCrawled": "2022-01-27T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Computer Vision</b> | sandipanweb", "url": "https://sandipanweb.wordpress.com/category/computer-vision/", "isFamilyFriendly": true, "displayUrl": "https://sandipanweb.wordpress.com/category/<b>computer-vision</b>", "snippet": "Since <b>Tic-Tac-Toe</b> is a tie given optimal <b>play</b> by both sides, <b>you</b> should never be able to beat the AI (though if <b>you</b> don\u2019t <b>play</b> optimally as well, it may beat <b>you</b>!) The following figure demonstrates the basic concepts of adversarial search and Game and defines the different functions for <b>tic-tac-toe</b>. Here we shall use Minimax with alpha-beta pruning to speedup the game when it is computer\u2019s turn. The following python code fragment shows how to implement the minimax algorithm with alpha ...", "dateLastCrawled": "2022-02-03T09:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Java Collections</b> | PDF - Scribd", "url": "https://www.scribd.com/doc/88854047/84736540-Java-Collections-pdf", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/doc/88854047/84736540-<b>Java-Collections</b>-pdf", "snippet": "For some case studies, there is an application <b>program</b> that <b>can</b> be downloaded and run. For others, there is an applet that <b>can</b> be run immediately using a Java-enabled Web browser. Where appropriate, each case study comes in two versions, one using the classes developed in this book and the other using the Java collection classes. Exercises Each chapter is followed by a set of exercises. Some of these exercises are drill, or simple modifications to designs, algorithms, or implementations ...", "dateLastCrawled": "2021-12-14T12:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>sandipanweb</b> | Simply Data Science | Page 2", "url": "https://sandipanweb.wordpress.com/page/2/", "isFamilyFriendly": true, "displayUrl": "https://<b>sandipanweb</b>.wordpress.com/page/2", "snippet": "Later we shall see how an Integer Linear <b>Program</b> (ILP) <b>can</b> be formulated to solve the bipartite matching problem and then solved with a MIP solver. With Max-flow . The following animations show how the algorithm finds the maximum matching for a few bipartite graphs (the blue and green nodes represent the self-edge-disjoint sets for the graph): Image by Author Image by Author Image by Author With Integer Linear <b>Program</b>. Using the mip package to solve the integer <b>program</b> and using a binary ...", "dateLastCrawled": "2022-01-22T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Rationality Quotes February 2013</b> - LessWrong", "url": "https://www.lesswrong.com/posts/YeS5yESwcFcK57LQk/rationality-quotes-february-2013", "isFamilyFriendly": true, "displayUrl": "https://www.lesswrong.com/posts/YeS5yESwcFcK57LQk/<b>rationality-quotes-february-2013</b>", "snippet": "<b>You</b> should do it when <b>you</b> spot regularities <b>you</b> <b>can</b> eke efficiency out of. But <b>you</b> should do this only if it does not make the code unwieldy or unnatural, and only if it does not make the code fragile. Beliefs should be the same thing. When your rules of thumb seem to respect some regularity in reality, I&#39;m <b>perfectly</b> happy to call that &quot;truth&quot;. So long as that does not break my tools.", "dateLastCrawled": "2022-01-24T03:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "February | 2019 | Freakonometrics", "url": "https://freakonometrics.hypotheses.org/date/2019/02", "isFamilyFriendly": true, "displayUrl": "https://freakonometrics.hypotheses.org/date/2019/02", "snippet": "A first application was to teach a machine to <b>play</b> a game (<b>tic-tac-toe</b>, chess, go, etc.). An essential step is to explain the objective it must achieve to win. One historical approach has been to teach the machine the rules of the game. If it allows <b>you</b> to <b>play</b>, it will not help the machine to <b>play</b> well. Assuming that the machine knows the rules of the game, and that it has a choice between several dozen possible moves, which one should it choose? The classical approach in artificial ...", "dateLastCrawled": "2022-01-29T07:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Statistical Notes \u00b7 Gwern.net", "url": "https://www.gwern.net/Statistical-notes", "isFamilyFriendly": true, "displayUrl": "https://www.gwern.net/Statistical", "snippet": "If <b>you</b> visit centenarian A on day 1, and <b>you</b> want to visit centenarian B on day 2, then <b>you</b> <b>can</b> count on a 99.9% chance B is still alive. So far so good. And if <b>you</b> wanted to visit 566 centenarians (let\u2019s <b>imagine</b> <b>you</b> have a regularly-updated master list of centenarians from the Finnish population registry), then <b>you</b> only have to beat the odds 566 times in a row, which is not", "dateLastCrawled": "2022-01-29T10:58:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~bgibson/cs540/handouts/learning_intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~bgibson/cs540/handouts/<b>learning</b>_intro.pdf", "snippet": "<b>learning</b> process \u2022x i = (x i1, . . . , x iD) \u2022Assume these instances are sampled independently from an unknown (population) distribution, P(x) \u2022We denote this by x i \u223c P(x), where <b>i.i.d</b>. stands for independent and identically distributed <b>i.i.d</b>. Training Sample \u2022A training sample is the \u201cexperience\u201d given to a <b>learning</b> algorithm", "dateLastCrawled": "2021-08-25T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Learning</b>? <b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "<b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b> Chapter 18.1, 18.2, 18.8.1 and \u201cIntroduction to Statistical <b>Machine</b> <b>Learning</b>\u201d 1 What is <b>Learning</b>? \u2022\u201c<b>Learning</b> is making useful changes in our minds\u201d \u2013Marvin Minsky \u2022\u201c<b>Learning</b> is constructing or modifying representations of what is being experienced\u201c \u2013RyszardMichalski \u2022\u201c<b>Learning</b> denotes changes in a system that ... enable a system to do the same task more efficiently the next time\u201d \u2013Herbert Simon 3 Why do Mach", "dateLastCrawled": "2022-02-03T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> for Drug <b>Discovery</b> in a Nutshell \u2014 Part I | by Stefan ...", "url": "https://medium.com/atomwise/machine-learning-for-drug-discovery-in-a-nutshell-part-i-24ae3f65c135", "isFamilyFriendly": true, "displayUrl": "https://medium.com/atomwise/<b>machine</b>-<b>learning</b>-for-drug-<b>discovery</b>-in-a-nutshell-part-i...", "snippet": "Classical <b>machine</b> <b>learning</b> literature spends little attention to this aspect. Most often, the underlying assumption is that training and test examples are drawn <b>i.i.d</b>. from the same distribution ...", "dateLastCrawled": "2022-01-26T14:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "11._Intro_to_<b>Machine</b>_<b>Learning</b>.pdf - CMPSC 442 Artificial Intelligence ...", "url": "https://www.coursehero.com/file/121916721/11-Intro-to-Machine-Learningpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/121916721/11-Intro-to-<b>Machine</b>-<b>Learning</b>pdf", "snippet": "Outline Data-Driven Problem Solving Types of <b>Machine</b> <b>Learning</b> <b>I.I.D</b> Assumption and Generalization The Fundamental Tradeoff between Bias and Variance Bias and Variance Overfitting and Underfitting Regularization Hyperparameters, Three-fold split, Cross-Validation Example of Polynomial Regression 2. Minimum Spanning Tree A classical problem in algorithm design: Minimum Spanning Tree Input: A graph with cost for edges Output: A spanning tree with minimum cost Prim&#39;s algorithm, Kruskal&#39;s ...", "dateLastCrawled": "2022-01-15T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Lecture 16: Reinforcement <b>Learning</b>, Part 1 | Lecture Videos | <b>Machine</b> ...", "url": "https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s897-machine-learning-for-healthcare-spring-2019/lecture-videos/lecture-16-reinforcement-learning-part-1/", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/courses/electrical-engineering-and-computer-science/6-s897-<b>machine</b>...", "snippet": "So that S0, 1, et cetera, up to St are all <b>i.i.d</b>. draws of the same distribution. Then we have, essentially, a model for t different patients with a single time step or single action, instead of them being dependent in some way. So we can see that by going backwards through my slides, this is essentially what we had last week.", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Shortcut <b>learning</b> in deep neural networks | Nature <b>Machine</b> Intelligence", "url": "https://www.nature.com/articles/s42256-020-00257-z", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42256-020-00257-z", "snippet": "In <b>analogy</b> to <b>machine</b> <b>learning</b>, we have a striking discrepancy between intended and actual <b>learning</b> outcome. Shortcut <b>learning</b> in education (surface <b>learning</b>) Alice loves history\u2014but at this ...", "dateLastCrawled": "2022-02-03T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning from positive</b> and unlabeled data: a survey - <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "<b>Learning from positive</b> and unlabeled data or PU <b>learning</b> is the setting where a learner only has access to positive examples and unlabeled data. The assumption is that the unlabeled data can contain both positive and negative examples. This setting has attracted increasing interest within the <b>machine</b> <b>learning</b> literature as this type of data naturally arises in applications such as medical diagnosis and knowledge base completion. This article provides a survey of the current state of the art ...", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Time Series Forecasting as Supervised Learning</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/time-series-forecasting-supervised-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/time-series-forecasting-su", "snippet": "Time series forecasting can be framed as a supervised <b>learning</b> problem. This re-framing of your time series data allows you access to the suite of standard linear and nonlinear <b>machine</b> <b>learning</b> algorithms on your problem. In this post, you will discover how you can re-frame your time series problem as a supervised <b>learning</b> problem for <b>machine</b> <b>learning</b>. After reading this post, you", "dateLastCrawled": "2022-02-02T19:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[1910.07796] Overcoming Forgetting in <b>Federated Learning</b> on Non-<b>IID</b> Data", "url": "https://arxiv.org/abs/1910.07796", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1910.07796", "snippet": "We tackle the problem of <b>Federated Learning</b> in the non <b>i.i.d</b>. case, in which local models drift apart, inhibiting <b>learning</b>. Building on an <b>analogy</b> with Lifelong <b>Learning</b>, we adapt a solution for catastrophic forgetting to <b>Federated Learning</b>. We add a penalty term to the loss function, compelling all local models to converge to a shared optimum. We show that this can be done efficiently for communication (adding no further privacy risks), scaling with the number of nodes in the distributed ...", "dateLastCrawled": "2022-01-28T12:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "econometrics - Principle of <b>Analogy</b> and Method of Moments - Cross Validated", "url": "https://stats.stackexchange.com/questions/272803/principle-of-analogy-and-method-of-moments", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/272803/principle-of-<b>analogy</b>-and-method-of...", "snippet": "The basic principle of MoM is to choose the parameter estimate so that the corresponding sample moments are also zero. This is the &quot;matching&quot; part of the population moments with those of sample. The impetus for the evolution of MoM is that Hansen thought if there are more orthogonality conditions than parameters, then the system may not have a ...", "dateLastCrawled": "2022-01-25T20:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Pearson\u2019s Correlation, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black-swans-in-your-market-neutral-portfolios-part-1-e17fc18a42a7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum ...", "dateLastCrawled": "2021-05-27T10:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Pearson\u2019s <b>Correlation</b>, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part-i-7521683a7317", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum-entropy problem , which aims at finding among all probability distributions that are consistent with observed empirical evidence, the one the is the most ignorant about everything else.", "dateLastCrawled": "2022-02-02T09:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(i.i.d.)  is like +(imagine that you are creating a program to learn how to play tic-tac-toe perfectly)", "+(i.i.d.) is similar to +(imagine that you are creating a program to learn how to play tic-tac-toe perfectly)", "+(i.i.d.) can be thought of as +(imagine that you are creating a program to learn how to play tic-tac-toe perfectly)", "+(i.i.d.) can be compared to +(imagine that you are creating a program to learn how to play tic-tac-toe perfectly)", "machine learning +(i.i.d. AND analogy)", "machine learning +(\"i.i.d. is like\")", "machine learning +(\"i.i.d. is similar\")", "machine learning +(\"just as i.i.d.\")", "machine learning +(\"i.i.d. can be thought of as\")", "machine learning +(\"i.i.d. can be compared to\")"]}