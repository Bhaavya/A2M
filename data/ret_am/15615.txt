{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Effectiveness of <b>Equalized</b> <b>Odds</b> for <b>Fair</b> Classification under Imperfect ...", "url": "https://deepai.org/publication/effectiveness-of-equalized-odds-for-fair-classification-under-imperfect-group-information", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/effectiveness-of-<b>equalized</b>-<b>odds</b>-for-<b>fair</b>-classification...", "snippet": "The appropriate formalization of <b>fair</b> or high-quality predictions necessarily varies based upon the domain, ... We then describe our noise model for perturbing the protected attribute and present our analysis of <b>equalized</b> <b>odds</b> under this noise model. <b>Like</b> Hardt et al. and as it is common in the literature on <b>fair</b> machine learning (e.g., Pleiss et al., 2017; Hashimoto et al., 2018), we deal with the distributional setting and ignore the effect of estimating probabilities from finite training ...", "dateLastCrawled": "2022-01-18T17:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "On Fairness and Calibration - NeurIPS", "url": "https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf", "snippet": "growing line of work on what it means for a classication procedure to be <b>fair</b>. ... of <b>coin</b> tosses especially in sensitive settings such as health care or criminal justice. The optimality of this algorithm thus has troubling implications and shows that calibration and error-rate fairness are inherently at <b>odds</b> (even beyond the initial results by [8] and [26]). Finally, we evaluate these theoretical ndings empirically, comparing calibrated notions of non-discrimination against the ...", "dateLastCrawled": "2022-01-30T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is <b>Fair</b>? <b>Exploring Pareto-Efficiency for Fairness Constrained</b> ...", "url": "https://deepai.org/publication/what-is-fair-exploring-pareto-efficiency-for-fairness-constrained-classifiers", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/what-is-<b>fair</b>-<b>exploring-pareto-efficiency-for-fairness</b>...", "snippet": "The potential for learned models to amplify existing societal biases has been broadly recognized. Fairness-aware classifier constraints, which apply equality metrics of performance across subgroups defined on sensitive attributes such as race and gender, seek to rectify inequity but can yield non-uniform degradation in performance for skewed datasets. In certain domains, imbalanced degradation of performance can yield another form of unintentional bias.", "dateLastCrawled": "2021-12-16T19:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "do not consider points below the main diagonal line from 0 0 to 1 1 ...", "url": "https://www.coursehero.com/file/p669tidb/do-not-consider-points-below-the-main-diagonal-line-from-0-0-to-1-1-which-are/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p669tidb/do-not-consider-points-below-the-main...", "snippet": "We will first show that a Bayes optimal <b>equalized</b> <b>odds</b> predictor can be obtained as an derived threshold ... and black. FICO scores are complicated proprietary classifiers based on features, <b>like</b> number of bank accounts kept, that could interact with culture and race. 300 400 500 600 700 800 FICO score 0 20 40 60 80 100 Non-default rate Non-default rate by FICO score Asian White Hispanic Black 300 400 500 600 700 800 900 FICO score 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 Fraction of group below CDF of ...", "dateLastCrawled": "2021-12-27T13:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Paradoxes in <b>Fair</b> Computer-Aided Decision Making", "url": "https://www.aies-conference.com/2019/wp-content/papers/main/AIES-19_paper_216.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aies-conference.com/2019/wp-content/papers/main/AIES-19_paper_216.pdf", "snippet": "ing these future <b>coin</b>-tosses needed to determine it into \u02d9, and simply making sure they are not part of the observable features O(\u02d9). Additionally, an individual \u02d9 is part of some group g(\u02d9) 2G\u2014for instance, in the COMPAS setting, the group is the race of the individual. We will refer to the tuple P= (D;f;g;O) as a classi\ufb01cation context. Given such a classi\ufb01cation context P, we let Pdenote the range of f, and G Pdenote the range of g. Whenever the classi\ufb01cation context Pis clear ...", "dateLastCrawled": "2021-08-28T06:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The limits <b>of fair equality of opportunity</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007%2Fs11098-011-9721-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11098-011-9721-6", "snippet": "So, for instance, if I get 1:1 <b>odds</b> on the toss of a <b>coin</b>, wager US $100 on heads and the toss comes up heads, my resource holding is to be calculated at US $100 (the expected value of the gamble), rather than US $200, which is what I now have. In this way, people who had the same alternatives open to them can be said to have the same set of resources even when, after a series of gambles, they no longer have equal wealth.", "dateLastCrawled": "2021-12-14T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How <b>to Choose a Mining Pool</b>. The purpose of a bitcoin mining pool is ...", "url": "https://thecryptowriter.co/how-to-choose-the-best-mining-pool-d63ca16ffc14", "isFamilyFriendly": true, "displayUrl": "https://thecryptowriter.co/how-to-choose-the-best-mining-pool-d63ca16ffc14", "snippet": "Dec 17, 2019 \u00b7 5 min read. The purpose of a bitcoin mining pool is for a group of miners to join together and form a pool. By combining resources from all clients in that pool, they increase the <b>odds</b> of discovering the solution to a given block. When a solution is found to the block, it rewards the newly issued <b>coin</b> to the pool owner.", "dateLastCrawled": "2022-01-06T14:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Debunking Common Pro-Current Overtime Arguments : nfl", "url": "https://www.reddit.com/r/nfl/comments/sh463p/debunking_common_procurrent_overtime_arguments/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/nfl/comments/sh463p/debunking_common_procurrent_overtime...", "snippet": "&quot;The <b>coin</b> toss is <b>fair</b> since each team has an equal chance of winning it.&quot; This one is technically true. So in a literal sense, the game is <b>fair</b>; each team goes into the game with an equal chance of winning the original toss, and the second toss should the game go to overtime. The issue is, I don&#39;t believe that a <b>coin</b> should decide anything significant. I think of <b>fair</b> as not just equal, but as teams being able to control whether they win. And again, yes, they still can control if they win ...", "dateLastCrawled": "2022-02-01T11:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is the <b>expected number of moves required</b> to finish a snakes and ...", "url": "https://www.quora.com/What-is-the-expected-number-of-moves-required-to-finish-a-snakes-and-ladders-game", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-<b>expected-number-of-moves-required</b>-to-finish-a-snakes...", "snippet": "Answer (1 of 4): Good question! Prompted me to run a quick Monte Carlo simulation program in C. The results are as follows: [1] One of your snakehead is ambiguously placed. I have assumed a snake head at position 89. [2] The average number of turns required is 23.244 and average number of die r...", "dateLastCrawled": "2022-01-17T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Choose a Mining Pool : PhanesTechnology", "url": "https://www.reddit.com/r/PhanesTechnology/comments/ot2adc/how_to_choose_a_mining_pool/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/PhanesTechnology/comments/ot2adc/how_to_choose_a_mining_pool", "snippet": "By combining resources from all clients in that pool, they increase the <b>odds</b> of discovering the solution to a given block. When a solution is found to the block, it rewards the newly issued <b>coin</b> to the pool owner. The pool owner then divides the coins between the miners based on their contribution. \u2022 Pooled mining produces a constant revenue of smaller values, whereas solo mining tends to be more erratic and could take years to mine one block. \u2022 Pooled mining can generate a 1\u20132% higher ...", "dateLastCrawled": "2021-08-14T18:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Effectiveness of <b>Equalized</b> <b>Odds</b> for <b>Fair</b> Classification under Imperfect ...", "url": "https://deepai.org/publication/effectiveness-of-equalized-odds-for-fair-classification-under-imperfect-group-information", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/effectiveness-of-<b>equalized</b>-<b>odds</b>-for-<b>fair</b>-classification...", "snippet": "Effectiveness of <b>Equalized</b> <b>Odds</b> for <b>Fair Classification under Imperfect Group Information</b>. 06/07/2019 . \u2219. by Pranjal Awasthi, et al. \u2219. Rutgers University \u2219. 0 \u2219. share Most approaches for ensuring or improving a model&#39;s fairness with respect to a protected attribute (such as race or gender) assume access to the true value of the protected attribute for every data point. In many scenarios, however, perfect knowledge of the protected attribute is unrealistic. In this paper, we ask to ...", "dateLastCrawled": "2022-01-18T17:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Pareto-Efficient <b>Fairness for Skewed Subgroup Data</b>", "url": "https://aiforsocialgood.github.io/icml2019/accepted/track1/pdfs/24_aisg_icml2019.pdf", "isFamilyFriendly": true, "displayUrl": "https://aiforsocialgood.github.io/icml2019/accepted/track1/pdfs/24_aisg_icml2019.pdf", "snippet": "satis\ufb01es <b>equalized</b> <b>odds</b> with respect to protected attribute A and outcome Y, if Y\u02c6 and A are independent conditional on Y. P(Y\u02c6 =\u02c6y|Y = y,A= m)=P(Y\u02c6 =\u02c6y|Y = y,A= n) 8Y,8m,n 2 A (Pleiss et al., 2017) and (Raghavan et al., 2018) prove that equality of <b>odds</b> can\u2019t be achieved by two models on sep-arate groups which are calibrated , unless both the models achieve perfect accuracy. The main intuition behind this pa-per is the hypothesis that <b>similar</b> impossibility regimes exist in real ...", "dateLastCrawled": "2022-02-02T12:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>FAIR MIXUP: FAIRNESS VIA INTERPOLATION</b>", "url": "https://openreview.net/pdf?id=DNl5s5BXeBn", "isFamilyFriendly": true, "displayUrl": "https://openreview.net/pdf?id=DNl5s5BXeBn", "snippet": "as demographic parity (DP) and <b>equalized</b> <b>odds</b> (EO) (Barocas et al.,2019). Given two sensitive groups such as male and female, instead of directly restricting the disparity, we propose to regularize the model on interpolated distributions between them. Those augmented distributions form a path connecting the two sensitive groups. Figure1provides an illustrative example of the idea. The path simulates how the distribution transitions from one group to another via interpolation. Ideally, if the ...", "dateLastCrawled": "2022-02-03T00:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fairwashing: the risk of rationalization</b>", "url": "http://proceedings.mlr.press/v97/aivodji19a/aivodji19a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v97/aivodji19a/aivodji19a.pdf", "snippet": "attribute. <b>Equalized</b> <b>odds</b> (Hardt et al.,2016) is another com-mon criterion requiring the false positive and false negative rates be equal across the majority and minority groups. In a nutshell, demographic parity quanti\ufb01es biases in both train-ing data and learning, while <b>equalized</b> <b>odds</b> focus on the learning process. In this paper, we adopt ...", "dateLastCrawled": "2022-01-24T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "do not consider points below the main diagonal line from 0 0 to 1 1 ...", "url": "https://www.coursehero.com/file/p669tidb/do-not-consider-points-below-the-main-diagonal-line-from-0-0-to-1-1-which-are/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p669tidb/do-not-consider-points-below-the-main...", "snippet": "For an optimal equation opportunity derived predictor the construction <b>is similar</b>, except its sufficient to find points in D a that are on the same horizontal line. Assuming continuity of the conditional ROC curves, we can always take points on the ROC curve C a itself and no randomization is necessary. 4 Bayes optimal predictors In this section, we develop the theory a theory for non-discriminating Bayes optimal classification. We will first show that a Bayes optimal <b>equalized</b> <b>odds</b> ...", "dateLastCrawled": "2021-12-27T13:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Paradoxes in <b>Fair</b> Computer-Aided Decision Making", "url": "https://www.aies-conference.com/2019/wp-content/papers/main/AIES-19_paper_216.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aies-conference.com/2019/wp-content/papers/main/AIES-19_paper_216.pdf", "snippet": "ing these future <b>coin</b>-tosses needed to determine it into \u02d9, and simply making sure they are not part of the observable features O(\u02d9). Additionally, an individual \u02d9 is part of some group g(\u02d9) 2G\u2014for instance, in the COMPAS setting, the group is the race of the individual. We will refer to the tuple P= (D;f;g;O) as a classi\ufb01cation context. Given such a classi\ufb01cation context P, we let Pdenote the range of f, and G Pdenote the range of g. Whenever the classi\ufb01cation context Pis clear ...", "dateLastCrawled": "2021-08-28T06:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "PS2 (3).pdf - IEOR 172 PS 2 Read Chapter 3 Do Chapter 3 problems 5(add ...", "url": "https://www.coursehero.com/file/105777945/PS2-3pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/105777945/PS2-3pdf", "snippet": "IEOR 172 PS 2 Read Chapter 3. Do Chapter 3 problems 5 (add b: What is the probability that the first two are black? and c: What is the probability the last two are black?), 7 (optional), 8 (optional), 10, 25 (optional), 66, Chapter 3 theoretical exercise 9. Also do the problems below. Note: Optional problems (or variants) are for extra practice and may appear on exams. 1. (optional) Suppose we have 4 six-sided die, labeled A, B, C, and D.", "dateLastCrawled": "2021-12-29T12:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The limits <b>of fair equality of opportunity</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007%2Fs11098-011-9721-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11098-011-9721-6", "snippet": "So, for instance, if I get 1:1 <b>odds</b> on the toss of a <b>coin</b>, wager US $100 on heads and the toss comes up heads, my resource holding is to be calculated at US $100 (the expected value of the gamble), rather than US $200, which is what I now have. In this way, people who had the same alternatives open to them can be said to have the same set of resources even when, after a series of gambles, they no longer have equal wealth.", "dateLastCrawled": "2021-12-14T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What is another word for &quot;fair shake</b>&quot;?", "url": "https://www.wordhippo.com/what-is/another-word-for/fair_shake.html", "isFamilyFriendly": true, "displayUrl": "https://www.wordhippo.com/<b>what-is/another-word-for/fair_shake</b>.html", "snippet": "Synonyms for <b>fair</b> shake include justice, equity, right, square deal, fifty-fifty, <b>fair</b> treatment, even break, even chance, even <b>odds</b> and square <b>odds</b>. Find more <b>similar</b> words at wordhippo.com!", "dateLastCrawled": "2022-01-12T22:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Choose a Mining Pool : PhanesTechnology", "url": "https://www.reddit.com/r/PhanesTechnology/comments/ot2adc/how_to_choose_a_mining_pool/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/PhanesTechnology/comments/ot2adc/how_to_choose_a_mining_pool", "snippet": "By combining resources from all clients in that pool, they increase the <b>odds</b> of discovering the solution to a given block. When a solution is found to the block, it rewards the newly issued <b>coin</b> to the pool owner. The pool owner then divides the coins between the miners based on their contribution. \u2022 Pooled mining produces a constant revenue of smaller values, whereas solo mining tends to be more erratic and could take years to mine one block. \u2022 Pooled mining can generate a 1\u20132% higher ...", "dateLastCrawled": "2021-08-14T18:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "EqGNN: <b>Equalized</b> Node Opportunity in Graphs | DeepAI", "url": "https://deepai.org/publication/eqgnn-equalized-node-opportunity-in-graphs", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/eqgnn-<b>equalized</b>-node-opportunity-in-graphs", "snippet": "<b>Equalized</b>-<b>Odds</b> <b>Fair</b> Graph Neural Network Figure 1. The full EqGNN architecture. The blue box represents the sampler model that given a label, samples a dummy sensitive attribute (Section 3.1.1 for details). This model is pretrained independently. The green box represents the classifier, which given a graph and node features, tries to predict its label. The red box represents the discriminator, which minimizes a permutation loss (Section 3.3). Purple arrows represent loss functions while the ...", "dateLastCrawled": "2021-12-12T16:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Fair</b>? <b>Exploring Pareto-Efficiency for Fairness Constrained</b> ...", "url": "https://deepai.org/publication/what-is-fair-exploring-pareto-efficiency-for-fairness-constrained-classifiers", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/what-is-<b>fair</b>-<b>exploring-pareto-efficiency-for-fairness</b>...", "snippet": "The potential for learned models to amplify existing societal biases has been broadly recognized. Fairness-aware classifier constraints, which apply equality metrics of performance across subgroups defined on sensitive attributes such as race and gender, seek to rectify inequity but <b>can</b> yield non-uniform degradation in performance for skewed datasets. In certain domains, imbalanced degradation of performance <b>can</b> yield another form of unintentional bias.", "dateLastCrawled": "2021-12-16T19:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Fairness Under Feature Exemptions: Counterfactual</b> and ...", "url": "https://www.researchgate.net/publication/342198049_Fairness_Under_Feature_Exemptions_Counterfactual_and_Observational_Measures", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342198049_<b>Fair</b>ness_Under_Feature_Exemptions...", "snippet": "On the other hand, <b>equalized</b> <b>odds</b> suffers from label bias [36], [37], [41], [48], [ 49 ] because it is based on agreement with the true labels. In fact, we will demonstrate through an example ...", "dateLastCrawled": "2021-11-09T21:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Equality</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/equality/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/<b>equality</b>", "snippet": "The opportunities to be <b>equalized</b> between people <b>can</b> be opportunities for well-being (i.e. objective welfare), or for preference satisfaction (i.e., subjective welfare), or for resources. It is not <b>equality</b> of objective or subjective well-being or resources themselves that should be <b>equalized</b>, but an equal opportunity to gain the well-being or resources one aspires to. Such <b>equality</b> depends on their being a realm of options for each individual equal to the options enjoyed by all other ...", "dateLastCrawled": "2022-02-02T13:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) EqGNN: <b>Equalized</b> Node Opportunity in Graphs", "url": "https://www.researchgate.net/publication/354020699_EqGNN_Equalized_Node_Opportunity_in_Graphs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/354020699_EqGNN_<b>Equalized</b>_Node_Opportunity_in...", "snippet": "PDF | Graph neural networks (GNNs), has been widely used for supervised learning tasks in graphs reaching state-of-the-art results. However, little work... | Find, read and cite all the research ...", "dateLastCrawled": "2021-12-10T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The limits <b>of fair equality of opportunity</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007%2Fs11098-011-9721-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11098-011-9721-6", "snippet": "So, for instance, if I get 1:1 <b>odds</b> on the toss of a <b>coin</b>, wager US $100 on heads and the toss comes up heads, my resource holding is to be calculated at US $100 (the expected value of the gamble), rather than US $200, which is what I now have. In this way, people who had the same alternatives open to them <b>can</b> be said to have the same set of resources even when, after a series of gambles, they no longer have equal wealth.", "dateLastCrawled": "2021-12-14T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Probability interpretations</b> - Infogalactic: the planetary knowledge core", "url": "https://infogalactic.com/info/Probability_interpretations", "isFamilyFriendly": true, "displayUrl": "https://infogalactic.com/info/<b>Probability_interpretations</b>", "snippet": "In the case of tossing a <b>fair</b> <b>coin</b>, frequentists say that the probability of getting a heads is 1/2, not because there are two equally likely outcomes but because repeated series of large numbers of trials demonstrate that the empirical frequency converges to the limit 1/2 as the number of trials goes to infinity. If we denote by the number of occurrences of an event in trials, then if we say that . The frequentist view has its own problems. It is of course impossible to actually perform an ...", "dateLastCrawled": "2020-10-16T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Research Methods and Statistical Terms Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/3176831/research-methods-and-statistical-terms-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/3176831/research-methods-and-statistical-terms-flash-cards", "snippet": "The governmental system a country has in terms of free and <b>fair</b> elections and levels of participation. Ethology. The comparison of animal and human behavior. Foreign policy process . A concept that includes the influences and activities within a country that cause its government to decide to adopt one or another foreign policy. Formal powers. Authority to act or to exert influence that is granted by statutory law or by the constitution to a political executive or to another element of ...", "dateLastCrawled": "2020-10-23T22:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Draws Method</b> - Betting Systems &amp; Strategy - Punters Lounge Forum", "url": "https://forum.punterslounge.com/topic/122923-draws-method/", "isFamilyFriendly": true, "displayUrl": "https://forum.punterslounge.com/topic/122923-<b>draws-method</b>", "snippet": "Secondly, the true <b>odds</b> for any event are one less than the number of outcomes, if you toss a <b>coin</b> there <b>can</b> be two results, heads or tails so the true <b>odds</b> are evens, unless the <b>coin</b> is bent this is an indisputable fact. A 90 minute football match <b>can</b> result in a win for either team or a draw, the true <b>odds</b> for a game are therefore 2/1. The football match though is influenced by other factors, the relative strengths of the two teams, current form, home advantage etc. The fact is though that ...", "dateLastCrawled": "2022-02-01T00:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What&#39;s going to happen when the <b>Earth</b> passes through the Galactic Plane ...", "url": "https://scienceblogs.com/startswithabang/2010/06/03/whats-going-to-happen-when-the", "isFamilyFriendly": true, "displayUrl": "https://<b>scienceblogs.com</b>/startswithabang/2010/06/03/whats-going-to-happen-when-the", "snippet": "Actually the <b>odds</b> are much greater the <b>coin</b> will land on heads after landing on tails 10 times in a row. Think about it. If you flip the <b>coin</b> 100 times, it should land on the same side ~50%", "dateLastCrawled": "2022-01-30T10:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Pareto-Efficient <b>Fairness for Skewed Subgroup Data</b>", "url": "https://aiforsocialgood.github.io/icml2019/accepted/track1/pdfs/24_aisg_icml2019.pdf", "isFamilyFriendly": true, "displayUrl": "https://aiforsocialgood.github.io/icml2019/accepted/track1/pdfs/24_aisg_icml2019.pdf", "snippet": "satis\ufb01es <b>equalized</b> <b>odds</b> with respect to protected attribute A and outcome Y, if Y\u02c6 and A are independent conditional on Y. P(Y\u02c6 =\u02c6y|Y = y,A= m)=P(Y\u02c6 =\u02c6y|Y = y,A= n) 8Y,8m,n 2 A (Pleiss et al., 2017) and (Raghavan et al., 2018) prove that equality of <b>odds</b> <b>can</b>\u2019t be achieved by two models on sep-arate groups which are calibrated , unless both the models achieve perfect accuracy. The main intuition behind this pa-per is the hypothesis that similar impossibility regimes exist in real ...", "dateLastCrawled": "2022-02-02T12:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "EqGNN: <b>Equalized</b> Node Opportunity in Graphs | DeepAI", "url": "https://deepai.org/publication/eqgnn-equalized-node-opportunity-in-graphs", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/eqgnn-<b>equalized</b>-node-opportunity-in-graphs", "snippet": "<b>Equalized</b>-<b>Odds</b> <b>Fair</b> Graph Neural Network Figure 1. The full EqGNN architecture. The blue box represents the sampler model that given a label, samples a dummy sensitive attribute (Section 3.1.1 for details). This model is pretrained independently. The green box represents the classifier, which given a graph and node features, tries to predict its label. The red box represents the discriminator, which minimizes a permutation loss (Section 3.3). Purple arrows represent loss functions while the ...", "dateLastCrawled": "2021-12-12T16:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Group decisions based on confidence weighted majority voting ...", "url": "https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-021-00279-0", "isFamilyFriendly": true, "displayUrl": "https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-021-00279-0", "snippet": "Based on these sequences, individuals decided whether their sequence has more likely been produced by a <b>fair</b> <b>coin</b> (50% red, 50% blue) or a biased <b>coin</b> (60% red, 40% blue). Based on the ambiguity of the sequence, individuals reported a confidence in their own decision. In the group phase, participants combined their evidence into one group decision and confidence. In each trial, participants were incentivized for accurately judging their real group confidence using the matching probability ...", "dateLastCrawled": "2022-02-02T00:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Fair</b> Mixup: Fairness via Interpolation", "url": "https://www.researchgate.net/publication/350005423_Fair_Mixup_Fairness_via_Interpolation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350005423_<b>Fair</b>_Mixup_<b>Fair</b>ness_via_Interpolation", "snippet": "PDF | Training classifiers under fairness constraints such as group fairness, regularizes the disparities of predictions between the groups.... | Find, read and cite all the research you need on ...", "dateLastCrawled": "2022-01-19T04:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is <b>Fair</b>? <b>Exploring Pareto-Efficiency for Fairness Constrained</b> ...", "url": "https://deepai.org/publication/what-is-fair-exploring-pareto-efficiency-for-fairness-constrained-classifiers", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/what-is-<b>fair</b>-<b>exploring-pareto-efficiency-for-fairness</b>...", "snippet": "The potential for learned models to amplify existing societal biases has been broadly recognized. Fairness-aware classifier constraints, which apply equality metrics of performance across subgroups defined on sensitive attributes such as race and gender, seek to rectify inequity but <b>can</b> yield non-uniform degradation in performance for skewed datasets. In certain domains, imbalanced degradation of performance <b>can</b> yield another form of unintentional bias.", "dateLastCrawled": "2021-12-16T19:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What&#39;s going to happen when the <b>Earth</b> passes through the ... - <b>ScienceBlogs</b>", "url": "https://scienceblogs.com/startswithabang/2010/06/03/whats-going-to-happen-when-the", "isFamilyFriendly": true, "displayUrl": "https://<b>scienceblogs.com</b>/startswithabang/2010/06/03/whats-going-to-happen-when-the", "snippet": "The probability of heads would be 50% (assuming, as I do, a <b>fair</b> <b>coin</b>). Similarly, the probabilty of an extraterrestrial impact, a magnetic polarization change or any of the other events you might ...", "dateLastCrawled": "2022-01-30T10:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Workshop Papers | Fairness in AI", "url": "https://www.yongkaiwu.com/FairAI/workshop.html", "isFamilyFriendly": true, "displayUrl": "https://www.yongkaiwu.com/<b>Fair</b>AI/workshop.html", "snippet": "<b>Equalized</b> <b>Odds</b> Implies Partially <b>Equalized</b> Outcomes Under Realistic Assumptions; Costs and Benefits of <b>Fair</b> Representation Learning ; Ethically Aligned Opportunistic Scheduling for Productive Laziness; Semantics Derived Automatically from Language Corpora Contain Human-like Moral Choices; The Right To Confront Your Accuser: Opening the Black Box of Forensic DNA Software; Algorithmic greenlining: An approach to increase diversity; Requirements for an Artificial Agent with Norm Competence ...", "dateLastCrawled": "2022-01-18T07:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Random Assignment Helps Eliminate", "url": "https://groups.google.com/g/cp9a92/c/xonFSTx2iHk", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/cp9a92/c/xonFSTx2iHk", "snippet": "How <b>can</b> we assign experimental units to treatments in a way that is <b>fair</b> to all of the treatments? Access to this page was restricted by the administrator. For all subjects, the probability the subject is treated is at least as great when the subject is in the treatment group as when the subject is in the control group. Rather than randomly assigning access to the program, researchers randomly assign an ncouragement. What is a Claim? The idea of blocking is an important additional principle ...", "dateLastCrawled": "2022-01-29T13:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Paradoxes in <b>Fair</b> Computer-Aided Decision Making", "url": "https://www.aies-conference.com/2019/wp-content/papers/main/AIES-19_paper_216.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aies-conference.com/2019/wp-content/papers/main/AIES-19_paper_216.pdf", "snippet": "likely as white defendants (44.85%, <b>compared</b> to 23.45%) to have been assigned a high risk score (5-10). Fairness, or non-discrimination, in classi\ufb01cation has been studied and debated extensively in the recent past (see (Baro- cas and Selbst 2016) for an extremely thorough overview); research concerning de\ufb01nitions of fairness in classi\ufb01cation dates back to (Pearl 2001) and (Dwork et al. 2012), with more recent de\ufb01nitions tailored to deal with the above-mentioned problems appearing in ...", "dateLastCrawled": "2021-08-28T06:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Research Methods and Statistical Terms Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/3176831/research-methods-and-statistical-terms-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/3176831/research-methods-and-statistical-terms-flash-cards", "snippet": "individuals performances <b>can</b> <b>be compared</b> with the norm group; results from 1 or more large samples with known characteristics. ANOVA. analysis of variance- a test for the significance of differences among three of more means; parametric. T test . inferential statistical test- used to compare two groups; parametric. Chi Square. test of statistical significance for categorical date; non-parametric. Linear Regression. defines a line of best fit for correlational data that <b>can</b> be used as a ...", "dateLastCrawled": "2020-10-23T22:57:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "A <b>machine learning</b> technique that iteratively combines a set of simple and not very accurate classifiers ... Contrast with <b>equalized</b> <b>odds</b> and equality of opportunity, which permit classification results in aggregate to depend on sensitive attributes, but do not permit classification results for certain specified ground-truth labels to depend on sensitive attributes. See &quot;Attacking discrimination with smarter <b>machine learning</b>&quot; for a visualization exploring the tradeoffs when optimizing for ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Residual Unfairness in Fair <b>Machine</b> <b>Learning</b> from Prejudiced Data", "url": "http://proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "snippet": "chine <b>learning</b> has considered some subcomponents of the overall problem we study of <b>learning</b> fair policies from bi-ased datasets. Hardt et al. (2016) formalize the criteria of equal opportunity and <b>equalized</b> <b>odds</b>. Lum &amp; Isaac (2016) show that a predictive policing algorithm for drug enforce-ment in Oakland, trained on police records, will ...", "dateLastCrawled": "2022-01-31T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Human-centric Approach to Fairness in AI", "url": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "isFamilyFriendly": true, "displayUrl": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "snippet": "We embed the evaluation of AI fairness within the best practices of <b>machine</b> <b>learning</b> development and operations such as version control, ... This includes measures such as Demographic Parity / Statistical Parity (Dwork et al., 2012), <b>Equalized</b> <b>Odds</b> Metric (Hardt et al., 2016) and Calibration within Groups (Chouldechova, 2017). They are all statistical measures derived from the predictions of a classification model and differ in terms of which element(s) of the confusion matrix they are ...", "dateLastCrawled": "2022-02-03T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Survey on Bias and Fairness in <b>Machine</b> <b>Learning</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1908.09635/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1908.09635", "snippet": "With the widespread use of AI systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in <b>machine</b> <b>learning</b>, natural language ...", "dateLastCrawled": "2021-11-15T17:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Fighting Money Laundering with Statistics and <b>Machine</b> <b>Learning</b>: An ...", "url": "https://deepai.org/publication/fighting-money-laundering-with-statistics-and-machine-learning-an-introduction-and-review", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/fighting-money-laundering-with-statistics-and-<b>machine</b>...", "snippet": "Third, we present recent <b>machine</b> <b>learning</b> concepts that have the potential to improve AML. The remainder of the paper is organized as follows. Section 2 introduces AML in banks. Section 3 presents our terminology. Sections 4 and 5 review the literature on client risk profiling and suspicious behavior flagging, respectively. Section 6 provides a discussion on future research directions and section 7 concludes the paper. 2 Anti-Money Laundering in Banks. The international framework for AML is ...", "dateLastCrawled": "2022-01-28T21:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "Papers on fairness in <b>machine</b> <b>learning</b>, as is common in fields like computer science, abound with formulae. Even the papers referenced here, though selected not for their theorems and proofs but for the ideas they harbor, are no exception. But to start thinking about fairness as it might apply to an ML process at hand, common language \u2013 and common sense \u2013 will do just fine. If, after analyzing your use case, you judge that the more technical results are relevant to the process in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Mitigating Unwanted Biases with Adversarial Learning</b>", "url": "https://www.aies-conference.com/2018/contents/papers/main/AIES_2018_paper_162.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aies-conference.com/2018/contents/papers/main/AIES_2018_paper_162.pdf", "snippet": "<b>Machine</b> <b>learning</b> is a tool for building models that accurately represent input training data. When undesired biases concern- ing demographic groups are in the training data, well-trained models will re\ufb02ect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously <b>learning</b> a predictor and an ad-versary. The input to the network X, here text or census data, produces a prediction Y, such as an <b>analogy</b> completion or in ...", "dateLastCrawled": "2021-12-17T22:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "Simply put, the goal of classification is to determine a plausible value for an unknown variable Y given an observed variable X.For example, we might try to predict whether a loan applicant will pay back her loan by looking at various characteristics such as credit history, income, and net worth. Classification also applies in situations where the variable Y does not refer to an event that lies in the future. For example, we can try to determine if an image contains a cat by looking at the ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "On Predicting Recidivism: Epistemic Risk, Tradeoffs, and Values in ...", "url": "https://www.cambridge.org/core/journals/canadian-journal-of-philosophy/article/on-predicting-recidivism-epistemic-risk-tradeoffs-and-values-in-machine-learning/7E541FA03E78C3141A65EA99A0CA6E9A", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/canadian-journal-of-philosophy/article/on...", "snippet": "This paper examines the role of value judgments in the design of <b>machine</b>-<b>learning</b> (ML) systems generally and in recidivism-prediction algorithms specifically. Drawing on work on inductive and epistemic risk, the paper argues that ML systems are value laden in ways similar to human decision making, because the development and design of ML systems requires human decisions that involve tradeoffs that reflect values. In many cases, these decisions have significant\u2014and, in some cases, disparate ...", "dateLastCrawled": "2022-01-26T20:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Measuring discrimination in algorithmic <b>decision making</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10618-017-0506-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10618-017-0506-1", "snippet": "A <b>machine</b> <b>learning</b> algorithm is a procedure used for producing a predictive model from historical data. A model is a collection of decision rules used for <b>decision making</b> for new incoming data. The model would take personal characteristics as inputs (for example, income, credit history, employment status), and produce a prediction (for example, credit risk level). Fig. 1. A typical <b>machine</b> <b>learning</b> setting. Full size image. <b>Learning</b> algorithms as such cannot discriminate, because they are ...", "dateLastCrawled": "2022-01-29T20:54:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(equalized odds)  is like +(a fair coin)", "+(equalized odds) is similar to +(a fair coin)", "+(equalized odds) can be thought of as +(a fair coin)", "+(equalized odds) can be compared to +(a fair coin)", "machine learning +(equalized odds AND analogy)", "machine learning +(\"equalized odds is like\")", "machine learning +(\"equalized odds is similar\")", "machine learning +(\"just as equalized odds\")", "machine learning +(\"equalized odds can be thought of as\")", "machine learning +(\"equalized odds can be compared to\")"]}