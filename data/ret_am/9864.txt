{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Tutorial on <b>Fairness</b> in Machine Learning | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-machine-learning-3ff8ba1040cb", "snippet": "4.3 <b>Equalized</b> <b>odds</b>. <b>Equalized</b> <b>odds</b>, also called Separation, Positive Rate Parity, was first proposed in Hardt, Price and Srebro, 2016 and Zafar et al. WWW2017. Formulation: C is independent of A conditional on Y: P\u2080 [C = r | Y = y] = P\u2081 [C = r | Y = y] \u2200 r, y. A weaker notion is: P\u2080 [C \u2260Y] = P\u2081 [C\u2260 Y] which is called Accuracy ...", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Programming Fairness in Algorithms</b> | by Matthew Stewart, PhD Researcher ...", "url": "https://towardsdatascience.com/programming-fairness-in-algorithms-4943a13dd9f8", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>programming-fairness-in-algorithms</b>-4943a13dd9f8", "snippet": "<b>Equalized</b> <b>odds</b> and equality of opportunity are also more flexible and able to incorporate some of the information from the protected variable without resulting in disparate impact. Notice that whilst all of these provide some form of a solution that can be argued to be <b>fair</b>, none of these are particularly satisfying. One reason for this is that ...", "dateLastCrawled": "2022-01-23T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Differentially Private Fair Learning</b> | DeepAI", "url": "https://deepai.org/publication/differentially-private-fair-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>differentially-private-fair-learning</b>", "snippet": "<b>Differentially Private Fair Learning</b>. We design two learning algorithms that simultaneously promise differential privacy and <b>equalized</b> <b>odds</b>, a &#39;fairness&#39; condition that corresponds to equalizing false positive and negative rates across protected groups. Our first algorithm is a simple private implementation of the post-processing approach of ...", "dateLastCrawled": "2021-12-17T11:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine learning fairness notions: Bridging the</b> gap with real-world ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "snippet": "Likewise, no unresolved discrimination might be equivalent to <b>equalized</b> <b>odds</b> (Section 5.3) in a causal context if the set of resolving variables is the singleton set of actual outcomes: {Y}. Compared to counterfactual fairness, no unresolved discrimination is a weaker notion. That is, a counterfactually unfair scenario may be identified as <b>fair</b> based on no unresolved discrimination. This can happen in case one or several variables in the causal graph are identified as resolving.", "dateLastCrawled": "2022-02-03T07:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Bias and Fairness in Machine Learning, Part 1: introducing our dataset ...", "url": "https://freecontent.manning.com/bias-and-fairness-in-machine-learning-part-1-introducing-our-dataset-and-the-problem/", "isFamilyFriendly": true, "displayUrl": "https://freecontent.manning.com/bias-and-<b>fair</b>ness-in-machine-learning-part-1...", "snippet": "<b>Game</b> Development; Java; Microsoft / .NET; Mobile Technology; Programming; Software Engineering; Web Development ; Bias and Fairness in Machine Learning, Part 1: introducing our dataset and the problem. From Feature Engineering Bookcamp by Sinan Ozdemir. This article series covers Recognizing and mitigating bias in our data and model Quantifying fairness through various metrics Applying feature engineering techniques to remove bias from our model without sacrificing model performance. Take 35", "dateLastCrawled": "2022-01-29T20:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Reductions Approach to Fair Classification</b>", "url": "https://www.researchgate.net/publication/323627230_A_Reductions_Approach_to_Fair_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323627230_A_Reductions_Approach_to_<b>Fair</b>...", "snippet": "Recent results have built <b>fair</b> classifiers around various related metrics including demographic parity [2,11,19,20,25], <b>equalized</b> <b>odds</b> [2, 23,46], and equality of opportunity [23,46]. We note that ...", "dateLastCrawled": "2022-01-19T07:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Fairness without the sensitive attribute via Causal Variational ...", "url": "https://www.researchgate.net/publication/354542106_Fairness_without_the_sensitive_attribute_via_Causal_Variational_Autoencoder", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/354542106_<b>Fair</b>ness_without_the_sensitive...", "snippet": "mized by a mini-max <b>game</b> as follows: ... generic mitigation to create <b>a fair</b> <b>equalized</b> <b>odds</b> classi\ufb01er. predictor is allowed since this mitigation is only used during . training and not at ...", "dateLastCrawled": "2022-01-04T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Is poker not <b>a fair</b> <b>game</b>? - General Poker - CardsChat\u2122", "url": "https://www.cardschat.com/forum/general-poker-13/poker-not-a-fair-game-404273/", "isFamilyFriendly": true, "displayUrl": "https://www.cardschat.com/forum/general-poker-13/poker-not-<b>a-fair</b>-<b>game</b>-404273", "snippet": "This is a discussion on Is poker not <b>a fair</b> <b>game</b> ? ... 49900 and I was given a pair of AA guys from my left playing all-in I <b>equalized</b> and he has 6-7 on the board of the street and I lose, and so ...", "dateLastCrawled": "2022-01-30T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is it true or false that equity is at <b>odds</b> with equality and the enemy ...", "url": "https://www.quora.com/Is-it-true-or-false-that-equity-is-at-odds-with-equality-and-the-enemy-of-freedom", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-it-true-or-false-that-equity-is-at-<b>odds</b>-with-equality-and-the...", "snippet": "Answer (1 of 2): It\u2019s all words. Equity, if taken to extremes, could mean communism, that we target from each according to their means to each according to their needs. Which is an absolute recipe for disaster, as we are all men, and man is unable to run such a system. Equality - of what? That is...", "dateLastCrawled": "2022-01-13T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Newcastle vs. Brisbane \u2013 A-League Prediction for February 3 (2022)", "url": "https://www.gamblingsites.com/picks/newcastle-jets-brisbane-roar-a-league-thursday-february-3-2022/", "isFamilyFriendly": true, "displayUrl": "https://www.gamblingsites.com/picks/newcastle-jets-brisbane-roar-a-league-thursday...", "snippet": "The Reds <b>equalized</b> on 88 minutes before netting the winner in stoppage time. Despite finishing the <b>game</b> with 61% possession and 14 shots to their name, Papas\u2019 men ultimately came away with nothing to show for their efforts. The Jets have managed to win just one of their six A-League clashes this season, registering two draws and three losses in the process. They head into Thursday\u2019s match on the back of two successive defeats. Beka Mikeltadze (5 goals, 1 assist), Valentino Yuel (3 goals ...", "dateLastCrawled": "2022-02-02T06:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Tutorial on <b>Fairness</b> in Machine Learning | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-machine-learning-3ff8ba1040cb", "snippet": "<b>Equalized</b> <b>Odds</b> VS Predictive Rate Parity. Assume all events in the joint distribution of (A,C,Y) have positive probability. If A is dependent of Y, either <b>Equalized</b> <b>Odds</b> holds or Predictive Rate Parity but not both. Proof: (Wasserman Theorem 17.2)", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine learning fairness notions: Bridging the</b> gap with real-world ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "snippet": "Likewise, no unresolved discrimination might be equivalent to <b>equalized</b> <b>odds</b> (Section 5.3) in a causal context if the set of resolving variables is the singleton set of actual outcomes: {Y}. Compared to counterfactual fairness, no unresolved discrimination is a weaker notion. That is, a counterfactually unfair scenario may be identified as <b>fair</b> based on no unresolved discrimination. This can happen in case one or several variables in the causal graph are identified as resolving.", "dateLastCrawled": "2022-02-03T07:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Bias and Fairness in Machine Learning, Part 1: introducing our dataset ...", "url": "https://freecontent.manning.com/bias-and-fairness-in-machine-learning-part-1-introducing-our-dataset-and-the-problem/", "isFamilyFriendly": true, "displayUrl": "https://freecontent.manning.com/bias-and-<b>fair</b>ness-in-machine-learning-part-1...", "snippet": "When tasked with making model predictions <b>fair</b> and as unbiased as possible we need to look at a few different ways of formulating and quantifying fairness so that we can quantify how well our ML models are doing. Disparate Treatment vs Disparate Impact. In general, a model\u2014or really any predictive/decision-making process\u2014can suffer from two forms of bias: Disparate Treatment and Disparate Impact. A model is considered to suffer from Disparate Treatment if predictions are in some way ...", "dateLastCrawled": "2022-01-29T20:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Fairness without the sensitive attribute via Causal Variational ...", "url": "https://deepai.org/publication/fairness-without-the-sensitive-attribute-via-causal-variational-autoencoder", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fair</b>ness-without-the-sensitive-attribute-via-causal...", "snippet": "<b>Equalized</b> <b>Odds</b> An algorithm is considered <b>fair</b> if across both demographics S = 0 and S = 1 , the predictor \u02c6 Y has equal false positive rates, and false negative rates Hardt2016 . This constraint enforces that accuracy is equally high in all demographics since the rate of positive and negative classification is equal across the groups.", "dateLastCrawled": "2022-01-21T18:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Programming Fairness in Algorithms</b> | by Matthew Stewart, PhD Researcher ...", "url": "https://towardsdatascience.com/programming-fairness-in-algorithms-4943a13dd9f8", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>programming-fairness-in-algorithms</b>-4943a13dd9f8", "snippet": "This is a combination of statistical parity for true positives and false positives simultaneously and is also know as <b>equalized</b> <b>odds</b>. Illustration of positive rate parity (<b>equalized</b> <b>odds</b>). Notice that in the first group, all those with Y=1 (blue boxes) were classified as positives (C=1). Similarly, in the second group, all those classified as Y=1 were also classified as positive. Of the population in A=1 that obtained Y=0, one of these was classified as C=1, giving a 50% false positive rate ...", "dateLastCrawled": "2022-01-23T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Neural Styling for Interpretable <b>Fair</b> Representations | DeepAI", "url": "https://deepai.org/publication/neural-styling-for-interpretable-fair-representations", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/neural-styling-for-interpretable-<b>fair</b>-representations", "snippet": "<b>equalized</b> <b>odds</b>. HarPriSre16 ; ZafValRodGum17b in which the allocator/predictor and protected characteristics must be independently conditional on the actual outcome (and called equality of opportunity HarPriSre16 ; ZafValRodGum17b if it is conditional only on the positive \u2013 or negative \u2013 outcome). These criteria have also been used to learn <b>fair</b> representations of the given data ZemWuSwePietal13 ; LouSweLiWeletal16 ; BeuCheZhaChi17 ; ZhaLemMit18 ; MadCrePitZem18 . Learning <b>fair</b> ...", "dateLastCrawled": "2022-01-03T08:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Fairness without the sensitive attribute via Causal Variational ...", "url": "https://www.researchgate.net/publication/354542106_Fairness_without_the_sensitive_attribute_via_Causal_Variational_Autoencoder", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/354542106_<b>Fair</b>ness_without_the_sensitive...", "snippet": "mized by a mini-max <b>game</b> as follows: ... generic mitigation to create <b>a fair</b> <b>equalized</b> <b>odds</b> classi\ufb01er. predictor is allowed since this mitigation is only used during . training and not at ...", "dateLastCrawled": "2022-01-04T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A <b>Reductions Approach to Fair Classification</b>", "url": "https://www.researchgate.net/publication/323627230_A_Reductions_Approach_to_Fair_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323627230_A_Reductions_Approach_to_<b>Fair</b>...", "snippet": "Recent results have built <b>fair</b> classifiers around various related metrics including demographic parity [2, 11,19,20,25], <b>equalized</b> <b>odds</b> [2,23,46], and equality of opportunity [23,46]. We note that ...", "dateLastCrawled": "2022-01-19T07:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is poker not <b>a fair</b> <b>game</b>? - General Poker - CardsChat\u2122", "url": "https://www.cardschat.com/forum/general-poker-13/poker-not-a-fair-game-404273/", "isFamilyFriendly": true, "displayUrl": "https://www.cardschat.com/forum/general-poker-13/poker-not-<b>a-fair</b>-<b>game</b>-404273", "snippet": "This is the story of one of my friend who used to think that poker is not <b>a fair</b> <b>game</b>. \u201cWhenever I try to play with my pocket cards someone . Up your <b>game</b> with free cardschat membership. Discuss ...", "dateLastCrawled": "2022-01-30T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Will we get a clarification on what&#39;s inside (and how much it worth) on ...", "url": "https://www.reddit.com/r/lostarkgame/comments/oe9qqy/will_we_get_a_clarification_on_whats_inside_and/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/lostark<b>game</b>/comments/oe9qqy/will_we_get_a_clarification_on...", "snippet": "- silver is <b>odds</b> of this <b>game</b>. you can get them from everywhere, especially in cube. - P2W users cannot upgrade gears, without buying those things from you. - silver work as a roadblock to P2W, too. you can buy silver with cash, but it is super inefficient. - till +6, the chance for success is 100%", "dateLastCrawled": "2021-07-05T15:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>Reductions Approach to Fair Classification</b> | DeepAI", "url": "https://deepai.org/publication/a-reductions-approach-to-fair-classification", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-<b>reductions-approach-to-fair-classification</b>", "snippet": "The first definition\u2014demographic (or statistical) parity\u2014<b>can</b> <b>be thought</b> of as a stronger version of the US Equal Employment Opportunity Commission\u2019s \u201cfour-fifths rule,\u201d which requires that the \u201cselection rate for any race, sex, or ethnic group [must be at least] four-fifths (4/5) (or eighty percent) of the rate for the group with the highest rate.\u201d 1 1 1 See the Uniform Guidelines on Employment Selection Procedures, 29 C.F.R. \u00a71607.4(D) (2015).", "dateLastCrawled": "2021-12-22T07:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Is it true or false that equity is at <b>odds</b> with equality and the enemy ...", "url": "https://www.quora.com/Is-it-true-or-false-that-equity-is-at-odds-with-equality-and-the-enemy-of-freedom", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-it-true-or-false-that-equity-is-at-<b>odds</b>-with-equality-and-the...", "snippet": "Answer (1 of 2): It\u2019s all words. Equity, if taken to extremes, could mean communism, that we target from each according to their means to each according to their needs. Which is an absolute recipe for disaster, as we are all men, and man is unable to run such a system. Equality - of what? That is...", "dateLastCrawled": "2022-01-13T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A <b>Reductions Approach to Fair Classification</b>", "url": "https://www.researchgate.net/publication/323627230_A_Reductions_Approach_to_Fair_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323627230_A_Reductions_Approach_to_<b>Fair</b>...", "snippet": "Recent results have built <b>fair</b> classifiers around various related metrics including demographic parity [2, 11,19,20,25], <b>equalized</b> <b>odds</b> [2,23,46], and equality of opportunity [23,46]. We note that ...", "dateLastCrawled": "2022-01-19T07:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Learning Adversarially <b>Fair</b> and Transferable Representations | DeepAI", "url": "https://deepai.org/publication/learning-adversarially-fair-and-transferable-representations", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/learning-adversarially-<b>fair</b>-and-transferable...", "snippet": "We derive adversarial upper bounds on unfairness that <b>can</b> be used in adversarial training to achieve either demographic parity, <b>equalized</b> <b>odds</b>, or equal opportunity. We are interested in quantitatively comparing two distributions corresponding to the learned group representations, so consider two distributions D 0 and D 1 over the same sample space \u03a9 D , as well as a binary test function \u03bc : \u03a9 D \u2192 { 0 , 1 } .", "dateLastCrawled": "2022-01-05T02:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Draws Method</b> - Betting Systems &amp; Strategy - Punters Lounge Forum", "url": "https://forum.punterslounge.com/topic/122923-draws-method/", "isFamilyFriendly": true, "displayUrl": "https://forum.punterslounge.com/topic/122923-<b>draws-method</b>", "snippet": "Depending on the match <b>odds</b> I would be laying a 2-2 draw at between something like 14 to 33/1, shell out 14 to 33 points to win 1, no thanks. Bookmakers <b>odds</b> &amp; true <b>odds</b>. You <b>can</b> take the term &quot;true <b>odds</b>&quot; in two ways for me. First <b>having</b> studied the event, in this case a football match, you decide what you think the <b>odds</b> for the <b>game</b> should be.", "dateLastCrawled": "2022-02-01T00:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Non-Discriminatory Machine Learning through Convex Fairness Criteria ...", "url": "https://www.researchgate.net/publication/330302454_Non-Discriminatory_Machine_Learning_through_Convex_Fairness_Criteria", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330302454_Non-Discriminatory_Machine_Learning...", "snippet": "<b>Fair</b> classification has been well studied in recent years and a large body of work has focused on formulating the <b>fair</b> classification problem as a constrained optimization problem, e.g ...", "dateLastCrawled": "2022-01-29T21:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Max Min</b> - Bo Waggoner", "url": "https://www.bowaggoner.com/blahg/2019/02-23-fairness-in-ml/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.bowaggoner.com/blahg/2019/02-23-<b>fair</b>ness-in-ml/index.html", "snippet": "A first cut at defining <b>fair</b> decisions could be: everyone gets the same decision. This could be problematic for a few reasons. People might want different things. It might not be possible (e.g. college admissions, where only a certain number of slots are available). It might conflict with the objectives of the principal (e.g. loans should only be given to applicants who <b>can</b> repay).", "dateLastCrawled": "2021-12-29T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The <b>Negative Effects</b> of Gender Roles", "url": "https://www.theodysseyonline.com/negative-effects-gender-roles", "isFamilyFriendly": true, "displayUrl": "https://www.theodysseyonline.com/<b>negative-effects</b>-gender-roles", "snippet": "Speaking of the laughs, this movie knows it\u2019s a comedy and I <b>can</b> totally see the humor playing to <b>a fair</b> number of audiences. Particularly <b>game</b> is Samberg, who nails Johnny\u2019s million-words-a-second tone, and his ever-growing monster transformation means new things are constantly being thrown at you. In addition, while the Johnny/Dracula journey certainly plays into any number of road trip movie cliches, the jokes they get away with are solid.", "dateLastCrawled": "2022-02-03T04:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Will we get a clarification on what&#39;s inside (and how much it worth) on ...", "url": "https://www.reddit.com/r/lostarkgame/comments/oe9qqy/will_we_get_a_clarification_on_whats_inside_and/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/lostark<b>game</b>/comments/oe9qqy/will_we_get_a_clarification_on...", "snippet": "- you <b>can</b> craft Fusion materials from housing island. It cost gathering materials and gold. (mining, logging, fishing and hunting) - gold is main reward of weekly contents. (Abyss raid/dungeon, Commander raid) - silver is <b>odds</b> of this <b>game</b>. you <b>can</b> get them from everywhere, especially in cube.", "dateLastCrawled": "2021-07-05T15:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Short thoughts on the fate of this <b>game</b> and a warning : lostarkgame", "url": "https://www.reddit.com/r/lostarkgame/comments/o19u9q/short_thoughts_on_the_fate_of_this_game_and_a/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/lostark<b>game</b>/comments/o19u9q/short_<b>thoughts</b>_on_the_fate_of...", "snippet": "We all want a good <b>game</b>. We all want THIS <b>game</b> to be successful. In fact, some of us might have already been playing it on the other servers and are \u2026 Press J to jump to the feed. Press question mark to learn the rest of the keyboard shortcuts. Log In Sign Up. User account menu. 0. Short thoughts on the fate of this <b>game</b> and a warning. Discussion. Close. 0. Posted by 19 days ago. Short thoughts on the fate of this <b>game</b> and a warning ...", "dateLastCrawled": "2021-07-06T10:31:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness without the sensitive attribute via Causal Variational ...", "url": "https://deepai.org/publication/fairness-without-the-sensitive-attribute-via-causal-variational-autoencoder", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fair</b>ness-without-the-sensitive-attribute-via-causal...", "snippet": "<b>Equalized</b> <b>Odds</b> An algorithm is considered <b>fair</b> if across both demographics S = 0 and S = 1 , the predictor \u02c6 Y has equal false positive rates, and false negative rates Hardt2016 . This constraint enforces that accuracy is equally high in all demographics since the rate of positive and negative classification is equal across the groups.", "dateLastCrawled": "2022-01-21T18:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine learning fairness notions: Bridging the</b> gap with real-world ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001321", "snippet": "Likewise, no unresolved discrimination might be equivalent to <b>equalized</b> <b>odds</b> (Section 5.3) in a causal context if the set of resolving variables is the singleton set of actual outcomes: {Y}. <b>Compared</b> to counterfactual fairness, no unresolved discrimination is a weaker notion. That is, a counterfactually unfair scenario may be identified as <b>fair</b> based on no unresolved discrimination. This <b>can</b> happen in case one or several variables in the causal graph are identified as resolving.", "dateLastCrawled": "2022-02-03T07:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Fairness without the sensitive attribute via Causal Variational ...", "url": "https://www.researchgate.net/publication/354542106_Fairness_without_the_sensitive_attribute_via_Causal_Variational_Autoencoder", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/354542106_<b>Fair</b>ness_without_the_sensitive...", "snippet": "mized by a mini-max <b>game</b> as follows: ... generic mitigation to create <b>a fair</b> <b>equalized</b> <b>odds</b> classi\ufb01er. predictor is allowed since this mitigation is only used during . training and not at ...", "dateLastCrawled": "2022-01-04T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>Reductions Approach to Fair Classification</b> | DeepAI", "url": "https://deepai.org/publication/a-reductions-approach-to-fair-classification", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-<b>reductions-approach-to-fair-classification</b>", "snippet": "The second definition\u2014<b>equalized</b> <b>odds</b>\u2014was recently proposed by Hardt et al. to remedy two previously noted flaws with demographic parity (Dwork et al., 2012). First, demographic parity permits a classifier which accurately classifies data points with one value A = a , such as the value a with the most data, but makes random predictions for data points with A \u2260 a", "dateLastCrawled": "2021-12-22T07:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Fairness in intellectual property valuation and value</b>-sharing: Towards ...", "url": "https://stockholmiplawreview.com/wp-content/uploads/2020/06/Towards-fair-pricing-in-technology-trade-and-licensing-1-2020.pdf", "isFamilyFriendly": true, "displayUrl": "https://stockholmiplawreview.com/wp-content/uploads/2020/06/Towards-<b>fair</b>-pricing-in...", "snippet": "something across players in <b>a fair</b> <b>game</b> with rules that are reasonable and do not discriminate against any of the \u2013 8 \u2013 STOCKHOLM INTELLECTUAL PROPERTY LAW REVIEW VOLUME 3, ISSUE 1, JUNE 2020 players. Such a principle may be sufficient for acceptance of fairness but it might not be necessary, as the popularity of playing roulette against the <b>odds</b> indicates. Equality in sharing might on the other hand be necessary but not suf - ficient as the problems with equality in cake cutting or pie ...", "dateLastCrawled": "2021-09-01T21:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Reductions Approach to Fair Classification</b>", "url": "https://www.researchgate.net/publication/323627230_A_Reductions_Approach_to_Fair_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323627230_A_Reductions_Approach_to_<b>Fair</b>...", "snippet": "Recent results have built <b>fair</b> classifiers around various related metrics including demographic parity [2,11,19,20,25], <b>equalized</b> <b>odds</b> [2, 23,46], and equality of opportunity [23,46]. We note that ...", "dateLastCrawled": "2022-01-19T07:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>FAIRNESS IN MACHINE LEARNING: STATUS, SOFTWARE, AND SOLUTIONS</b> ...", "url": "https://www.academia.edu/43956823/FAIRNESS_IN_MACHINE_LEARNING_STATUS_SOFTWARE_AND_SOLUTIONS", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43956823/<b>FAIRNESS_IN_MACHINE_LEARNING_STATUS_SOFTWARE_AND</b>...", "snippet": "Although fairness in machine learning is a fairly nascent field, its relevance to daily life is immensely understated. Seeing as the future of everything from criminal justice to credit scoring to shopping lists will be dictated by the use of", "dateLastCrawled": "2021-07-31T04:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Max Min</b> - Bo Waggoner", "url": "https://www.bowaggoner.com/blahg/2019/02-23-fairness-in-ml/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.bowaggoner.com/blahg/2019/02-23-<b>fair</b>ness-in-ml/index.html", "snippet": "A first cut at defining <b>fair</b> decisions could be: everyone gets the same decision. This could be problematic for a few reasons. People might want different things. It might not be possible (e.g. college admissions, where only a certain number of slots are available). It might conflict with the objectives of the principal (e.g. loans should only be given to applicants who <b>can</b> repay).", "dateLastCrawled": "2021-12-29T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Machine Learning \u2013 The Results Are Not the only Thing that Matters ...", "url": "https://link.springer.com/chapter/10.1007/978-3-030-50423-6_46", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-50423-6_46", "snippet": "In the explainability case, Shapley values are used to attain <b>fair</b> distribution of gains between players, where a cooperative <b>game</b> is defined between the features. In addition, some recent works [ 32 , 36 ] show that adversarially trained models <b>can</b> be characterised by increased robustness but also provide clearer feature importance scores, contributing to improved prediction explainability.", "dateLastCrawled": "2021-12-22T00:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Will we get a clarification on what&#39;s inside (and how much it worth) on ...", "url": "https://www.reddit.com/r/lostarkgame/comments/oe9qqy/will_we_get_a_clarification_on_whats_inside_and/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/lostark<b>game</b>/comments/oe9qqy/will_we_get_a_clarification_on...", "snippet": "- you <b>can</b> craft Fusion materials from housing island. It cost gathering materials and gold. (mining, logging, fishing and hunting) - gold is main reward of weekly contents. (Abyss raid/dungeon, Commander raid) - silver is <b>odds</b> of this <b>game</b>. you <b>can</b> get them from everywhere, especially in cube.", "dateLastCrawled": "2021-07-05T15:35:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "A <b>machine learning</b> technique that iteratively combines a set of simple and not very accurate classifiers ... Contrast with <b>equalized</b> <b>odds</b> and equality of opportunity, which permit classification results in aggregate to depend on sensitive attributes, but do not permit classification results for certain specified ground-truth labels to depend on sensitive attributes. See &quot;Attacking discrimination with smarter <b>machine learning</b>&quot; for a visualization exploring the tradeoffs when optimizing for ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Residual Unfairness in Fair <b>Machine</b> <b>Learning</b> from Prejudiced Data", "url": "http://proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "snippet": "chine <b>learning</b> has considered some subcomponents of the overall problem we study of <b>learning</b> fair policies from bi-ased datasets. Hardt et al. (2016) formalize the criteria of equal opportunity and <b>equalized</b> <b>odds</b>. Lum &amp; Isaac (2016) show that a predictive policing algorithm for drug enforce-ment in Oakland, trained on police records, will ...", "dateLastCrawled": "2022-01-31T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Human-centric Approach to Fairness in AI", "url": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "isFamilyFriendly": true, "displayUrl": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "snippet": "We embed the evaluation of AI fairness within the best practices of <b>machine</b> <b>learning</b> development and operations such as version control, ... This includes measures such as Demographic Parity / Statistical Parity (Dwork et al., 2012), <b>Equalized</b> <b>Odds</b> Metric (Hardt et al., 2016) and Calibration within Groups (Chouldechova, 2017). They are all statistical measures derived from the predictions of a classification model and differ in terms of which element(s) of the confusion matrix they are ...", "dateLastCrawled": "2022-02-03T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Survey on Bias and Fairness in <b>Machine</b> <b>Learning</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1908.09635/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1908.09635", "snippet": "With the widespread use of AI systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in <b>machine</b> <b>learning</b>, natural language ...", "dateLastCrawled": "2021-11-15T17:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Mitigating Unwanted Biases with Adversarial Learning</b>", "url": "https://www.aies-conference.com/2018/contents/papers/main/AIES_2018_paper_162.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aies-conference.com/2018/contents/papers/main/AIES_2018_paper_162.pdf", "snippet": "<b>Machine</b> <b>learning</b> is a tool for building models that accurately represent input training data. When undesired biases concern- ing demographic groups are in the training data, well-trained models will re\ufb02ect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously <b>learning</b> a predictor and an ad-versary. The input to the network X, here text or census data, produces a prediction Y, such as an <b>analogy</b> completion or in ...", "dateLastCrawled": "2021-12-17T22:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "Papers on fairness in <b>machine</b> <b>learning</b>, as is common in fields like computer science, abound with formulae. Even the papers referenced here, though selected not for their theorems and proofs but for the ideas they harbor, are no exception. But to start thinking about fairness as it might apply to an ML process at hand, common language \u2013 and common sense \u2013 will do just fine. If, after analyzing your use case, you judge that the more technical results are relevant to the process in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Mitigating Unwanted Biases with Adversarial Learning</b> | DeepAI", "url": "https://deepai.org/publication/mitigating-unwanted-biases-with-adversarial-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>mitigating-unwanted-biases-with-adversarial-learning</b>", "snippet": "<b>Mitigating Unwanted Biases with Adversarial Learning</b>. 01/22/2018 \u2219 by Brian Hu Zhang, et al. \u2219 Google \u2219 Stanford University \u2219 0 \u2219 share . <b>Machine</b> <b>learning</b> is a tool for building models that accurately represent input training data. When undesired biases concerning demographic groups are in the training data, well-trained models will reflect those biases.", "dateLastCrawled": "2021-12-10T20:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "On Predicting Recidivism: Epistemic Risk, Tradeoffs, and Values in ...", "url": "https://www.cambridge.org/core/journals/canadian-journal-of-philosophy/article/on-predicting-recidivism-epistemic-risk-tradeoffs-and-values-in-machine-learning/7E541FA03E78C3141A65EA99A0CA6E9A", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/canadian-journal-of-philosophy/article/on...", "snippet": "This paper examines the role of value judgments in the design of <b>machine</b>-<b>learning</b> (ML) systems generally and in recidivism-prediction algorithms specifically. Drawing on work on inductive and epistemic risk, the paper argues that ML systems are value laden in ways similar to human decision making, because the development and design of ML systems requires human decisions that involve tradeoffs that reflect values. In many cases, these decisions have significant\u2014and, in some cases, disparate ...", "dateLastCrawled": "2022-01-26T20:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "Simply put, the goal of classification is to determine a plausible value for an unknown variable Y given an observed variable X.For example, we might try to predict whether a loan applicant will pay back her loan by looking at various characteristics such as credit history, income, and net worth. Classification also applies in situations where the variable Y does not refer to an event that lies in the future. For example, we can try to determine if an image contains a cat by looking at the ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Measuring discrimination in algorithmic <b>decision making</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10618-017-0506-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10618-017-0506-1", "snippet": "A <b>machine</b> <b>learning</b> algorithm is a procedure used for producing a predictive model from historical data. A model is a collection of decision rules used for <b>decision making</b> for new incoming data. The model would take personal characteristics as inputs (for example, income, credit history, employment status), and produce a prediction (for example, credit risk level). Fig. 1. A typical <b>machine</b> <b>learning</b> setting. Full size image. <b>Learning</b> algorithms as such cannot discriminate, because they are ...", "dateLastCrawled": "2022-01-29T20:54:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(equalized odds)  is like +(having a fair game)", "+(equalized odds) is similar to +(having a fair game)", "+(equalized odds) can be thought of as +(having a fair game)", "+(equalized odds) can be compared to +(having a fair game)", "machine learning +(equalized odds AND analogy)", "machine learning +(\"equalized odds is like\")", "machine learning +(\"equalized odds is similar\")", "machine learning +(\"just as equalized odds\")", "machine learning +(\"equalized odds can be thought of as\")", "machine learning +(\"equalized odds can be compared to\")"]}