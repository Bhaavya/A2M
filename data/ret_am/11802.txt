{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b> In <b>Personalization Algorithms</b> - Thank you, Eve!", "url": "https://www.thankyoueve.com/personalization-algorithm-bias", "isFamilyFriendly": true, "displayUrl": "https://www.thankyoueve.com/personalization-<b>algorithm</b>-<b>bias</b>", "snippet": "Philosophers so far have mostly focused on <b>implicit</b> <b>bias</b> and how such attitudes are related to concepts such as moral responsibility or how such attitudes could be changed 9. But there is also another category of <b>bias</b>, system <b>bias</b>, which is not held by individual agents but refers to the outcome of a system. System <b>bias</b> is not held by a system, e.g. the system does not hold such and such biases (considering that the system is not a social agent), the outcomes of a system are biased towards ...", "dateLastCrawled": "2021-12-22T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Even artificial intelligence can acquire biases against race and gender ...", "url": "https://www.science.org/content/article/even-artificial-intelligence-can-acquire-biases-against-race-and-gender", "isFamilyFriendly": true, "displayUrl": "https://www.science.org/content/article/even-artificial-intelligence-can-acquire...", "snippet": "To test for similar <b>bias</b> in the &quot;minds&quot; of machines, Bryson and colleagues developed a word-embedding association test (WEAT). They started with an established set of &quot;word embeddings,&quot; basically a <b>computer&#39;s</b> definition of a word, based on the contexts in which the word usually appears. So &quot;ice&quot; and &quot;steam&quot; have similar embeddings, because both ...", "dateLastCrawled": "2022-02-02T10:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "CPS 125 <b>Lecture 1: Introduction</b> - Google Slides", "url": "https://docs.google.com/presentation/d/1n4sa41gRTKtn7ReCs3HheH4b7Igvn9YL31-Tt-O0oiw/edit?usp=sharing#!", "isFamilyFriendly": true, "displayUrl": "https://<b>docs.google.com</b>/presentation/d/1n4sa41gRTKtn7ReCs3HheH4b7Igvn9YL31-Tt-O0oiw...", "snippet": "Simplest <b>sorting</b> <b>algorithm</b> is ... Same idea can be used to represent decimal numbers with bits by assigning an <b>implicit</b> decimal point at some location, and treating bits right of that point as negative powers of 2; For example, 1110.1010 2 = 8 + 4 + 2 + 1/2 + 1/8 = 14.625; Fixed point representation gives us uniform precision through its range of possible values, but we need more precision for small numbers than for large numbers; 0.001 and 0.00000001 are vastly different numbers, but if you ...", "dateLastCrawled": "2022-02-02T11:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "4. Problem Solving and Algorithms", "url": "http://sofia.cs.vt.edu/cs1114-ebooklet/chapter4.html", "isFamilyFriendly": true, "displayUrl": "sofia.cs.vt.edu/cs1114-ebooklet/chapter4.html", "snippet": "An <b>algorithm</b> is a plan for solving a problem. A person must design an <b>algorithm</b>. A person must translate an <b>algorithm</b> into a computer program. This point of view sets the stage for a process that we will use to develop solutions to Jeroo problems. The basic process is important because it can be used to solve a wide variety of problems, including ones where the solution will be written in some other programming language. An <b>Algorithm</b> Development Process. Every problem solution starts with a ...", "dateLastCrawled": "2022-02-02T07:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Are Ideal Litigators White? Measuring the</b> Myth of ... - ResearchGate", "url": "https://www.researchgate.net/publication/228189941_Are_Ideal_Litigators_White_Measuring_the_Myth_of_Colorblindness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228189941_Are_Ideal_Litigators_White...", "snippet": "[13] Data from across the globe using the IAT show that <b>implicit</b> <b>bias</b> (as measured by this time latency) is pervas ive, large in magnitude, and non-random in direction.", "dateLastCrawled": "2021-09-01T20:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Understanding perception of algorithmic decisions: Fairness</b>, trust, and ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2053951718756684", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2053951718756684", "snippet": "\u201cI feel <b>like</b> the <b>algorithm</b> might not be as precise in handling the schedule <b>like</b> a human being and might over or under schedule.\u201d (P153). \u201cIt&#39;s not unfair assuming there&#39;s a basis for the <b>computer&#39;s</b> <b>algorithm</b>, but it&#39;s not very fair or fair because there could be errors that only a human could consider.\u201d (P159). \u201cThe <b>algorithm</b> is probably more impartial than a person would be, but there may be some unfairness due to failure to consider human concerns (e.g. maybe Riley is under more ...", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Algorithmic <b>Decision</b>-Making and the Control Problem | SpringerLink", "url": "https://link.springer.com/article/10.1007/s11023-019-09513-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11023-019-09513-7", "snippet": "Footnote 5 But in any case, much <b>like</b> other touted solutions to the control problem, they do not offer a literal solution: rather, they render systems that are mostly dependable (but not better-than-human) less reliable by stealth (as it were), capitalizing on the premise that less reliable systems do not induce the same complacency and <b>bias</b> that attend more reliable systems. Thus catch trials really fall under option (a) in our menu of strategies above.", "dateLastCrawled": "2022-02-02T13:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>The Algorithm Design Manual - Steven S</b>. Skiena | \u00d6zlem Ekici ...", "url": "https://www.academia.edu/48943214/The_Algorithm_Design_Manual_Steven_S_Skiena", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/48943214/<b>The_Algorithm_Design_Manual_Steven_S</b>_Skiena", "snippet": "Second Edition - Springer This book is intended as a manual on <b>algorithm</b> design, providing access to combinatorial <b>algorithm</b> technology for both students and computer professionals. It is divided into two parts: Techniques and Resources. The former", "dateLastCrawled": "2022-02-03T07:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Practice | GeeksforGeeks | A computer science portal for geeks", "url": "https://practice.geeksforgeeks.org/answers/Amit+Khandelwal+1/", "isFamilyFriendly": true, "displayUrl": "https://practice.geeksforgeeks.org/answers/Amit+Khandelwal+1", "snippet": "WCF defines <b>implicit</b> contracts for built-in types such as int and string, but you can easily define explicit opt-in data contracts for custom types. Fault contracts . Define which errors are raised by the service, and how the service handles and propagates errors to its clients. Message contracts. Allow the service to interact directly with messages. Message contracts can be typed or untyped, and are useful in interoperability cases and when there is an existing message format you have to ...", "dateLastCrawled": "2022-02-02T17:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Psychology Unit 7</b> Flashcards | Quizlet", "url": "https://quizlet.com/253854802/psychology-unit-7-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/253854802/<b>psychology-unit-7</b>-flash-cards", "snippet": "analogies that compare human memory to <b>computer&#39;s</b> operations. encoding. processing of information into memory system (extracting meaning) storage. process of retaining encoded information over time. retrieval . process of getting information out of memory storage. parallel processing. processing of many aspects simultaneously; brain&#39;s natural way to process information (contrast with step-by-step processing of <b>computers</b> and of conscious problem solving) connectionism. views memories as ...", "dateLastCrawled": "2021-12-15T20:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b> In <b>Personalization Algorithms</b> - Thank you, Eve!", "url": "https://www.thankyoueve.com/personalization-algorithm-bias", "isFamilyFriendly": true, "displayUrl": "https://www.thankyoueve.com/personalization-<b>algorithm</b>-<b>bias</b>", "snippet": "Philosophers so far have mostly focused on <b>implicit</b> <b>bias</b> and how such attitudes are related to concepts such as moral responsibility or how such attitudes could be changed 9. But there is also another category of <b>bias</b>, system <b>bias</b>, which is not held by individual agents but refers to the outcome of a system. System <b>bias</b> is not held by a system, e.g. the system does not hold such and such biases (considering that the system is not a social agent), the outcomes of a system are biased towards ...", "dateLastCrawled": "2021-12-22T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Even artificial intelligence can acquire biases against race and gender ...", "url": "https://www.science.org/content/article/even-artificial-intelligence-can-acquire-biases-against-race-and-gender", "isFamilyFriendly": true, "displayUrl": "https://www.science.org/content/article/even-artificial-intelligence-can-acquire...", "snippet": "To test for <b>similar</b> <b>bias</b> in the &quot;minds&quot; of machines, Bryson and colleagues developed a word-embedding association test (WEAT). They started with an established set of &quot;word embeddings,&quot; basically a <b>computer&#39;s</b> definition of a word, based on the contexts in which the word usually appears. So &quot;ice&quot; and &quot;steam&quot; have <b>similar</b> embeddings, because both often appear within a few words of &quot;water&quot; and rarely with, say, &quot;fashion.&quot; But to a computer an embedding is represented as a string of numbers, not ...", "dateLastCrawled": "2022-02-02T10:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Floating Point Arithmetic</b> - Drexel CCI", "url": "https://www.cs.drexel.edu/~jjohnson/2012-13/fall/cs281/lectures/pdf/cs281_lec14.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.drexel.edu/~jjohnson/2012-13/fall/cs281/lectures/pdf/cs281_lec14.pdf", "snippet": "\u2022 Exponent: excess representation: actual exponent + <b>Bias</b> ... \u2022 For faster comparisons (for <b>sorting</b>, etc.), allow integer comparisons of floating point numbers: \u2022 Unbiased exponent: \u2022 Biased exponent: 0 1111 1111 000 0000 0000 0000 0000 0000 0 0000 0001 000 0000 0000 0000 0000 0000 1/2 2 0 0111 1110 000 0000 0000 0000 0000 0000 0 1000 0000 000 0000 0000 0000 0000 0000 1/2 2 . Lec 14 Systems Architecture 11 Basic Technique \u2022 Represent the decimal in the form +/- 1.xxx b yx 2 \u2022 And ...", "dateLastCrawled": "2022-02-02T15:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>The following sorting algorithm is of</b> divide and conquer type A Bubble ...", "url": "https://www.coursehero.com/file/p7sn0uq8/The-following-sorting-algorithm-is-of-divide-and-conquer-type-A-Bubble-sort-B/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p7sn0uq8/<b>The-following-sorting-algorithm-is-of</b>-divide...", "snippet": "<b>The following sorting algorithm is of</b> divide and. <b>The following sorting algorithm is of</b> divide- and-conquer type (A) Bubble sort (B) Insertion sort (C) Quick sort (D) None of the above 46. An <b>algorithm</b> that calls itself directly or indi- rectly is known as (A) Recursion (B) Polish notation (C) Traversal <b>algorithm</b> (D) None of the above 47.", "dateLastCrawled": "2021-12-15T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "4. Problem Solving and Algorithms", "url": "http://sofia.cs.vt.edu/cs1114-ebooklet/chapter4.html", "isFamilyFriendly": true, "displayUrl": "sofia.cs.vt.edu/cs1114-ebooklet/chapter4.html", "snippet": "An <b>algorithm</b> is a plan for solving a problem. A person must design an <b>algorithm</b>. A person must translate an <b>algorithm</b> into a computer program. This point of view sets the stage for a process that we will use to develop solutions to Jeroo problems. The basic process is important because it can be used to solve a wide variety of problems, including ones where the solution will be written in some other programming language. An <b>Algorithm</b> Development Process. Every problem solution starts with a ...", "dateLastCrawled": "2022-02-02T07:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Artificial Intelligence - Nature or Nurture?", "url": "https://www.eurogroupconsulting.de/wp-content/uploads/2021/09/DataNavigator_07.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.eurogroupconsulting.de/wp-content/uploads/2021/09/DataNavigator_07.pdf", "snippet": "of the <b>algorithm</b> or the data used for training the AI. What is artificial intelligence? Artificial intelligence comes in different shapes and sizes. Starting with a brief overview of AI before turning to the core question is therefore a sensible task. Artificial intelligence can be defined as intelligence performed by <b>computers</b> or other machines in contrast to natural intelligence shown, for example, by humans. Artificial intelligence can solve problems and make decisions on its own \u2013 at ...", "dateLastCrawled": "2022-01-29T10:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Are Ideal Litigators White? Measuring the</b> Myth of ... - ResearchGate", "url": "https://www.researchgate.net/publication/228189941_Are_Ideal_Litigators_White_Measuring_the_Myth_of_Colorblindness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228189941_Are_Ideal_Litigators_White...", "snippet": "[13] Data from across the globe using the IAT show that <b>implicit</b> <b>bias</b> (as measured by this time latency) is pervas ive, large in magnitude, and non-random in direction.", "dateLastCrawled": "2021-09-01T20:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Practice | GeeksforGeeks | A computer science portal for geeks", "url": "https://practice.geeksforgeeks.org/answers/Amit+Khandelwal+1/", "isFamilyFriendly": true, "displayUrl": "https://practice.geeksforgeeks.org/answers/Amit+Khandelwal+1", "snippet": "WCF defines <b>implicit</b> contracts for built-in types such as int and string, but you can easily define explicit opt-in data ... Sort the temp array using a O(nLogn) time <b>sorting</b> <b>algorithm</b>. 3) Scan the input array from left to right. For every element, count its occurrences in temp[] using binary search. As soon as we find a characterthat occurs more than once, we return the character. This step can be done in O(n Log n) time. An efficient solution is to use Hashing to solve this in O(n) time on ...", "dateLastCrawled": "2022-02-02T17:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Algorithmic <b>Decision</b>-Making and the Control Problem | SpringerLink", "url": "https://link.springer.com/article/10.1007/s11023-019-09513-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11023-019-09513-7", "snippet": "The danger of human operators devolving responsibility to machines and failing to detect cases where they fail has been recognised for many years by industrial psychologists and engineers studying the human operators of complex machines. We call it \u201cthe control problem\u201d, understood as the tendency of the human within a human\u2013machine control loop to become complacent, over-reliant or unduly diffident when faced with the outputs of a reliable autonomous system. While the control problem ...", "dateLastCrawled": "2022-02-02T13:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Psychology Unit 7</b> Flashcards | Quizlet", "url": "https://quizlet.com/253854802/psychology-unit-7-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/253854802/<b>psychology-unit-7</b>-flash-cards", "snippet": "analogies that compare human memory <b>to computer&#39;s</b> operations. encoding. processing of information into memory system (extracting meaning) storage. process of retaining encoded information over time . retrieval. process of getting information out of memory storage. parallel processing. processing of many aspects simultaneously; brain&#39;s natural way to process information (contrast with step-by-step processing of <b>computers</b> and of conscious problem solving) connectionism. views memories as ...", "dateLastCrawled": "2021-12-15T20:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "4. Problem Solving and Algorithms", "url": "http://sofia.cs.vt.edu/cs1114-ebooklet/chapter4.html", "isFamilyFriendly": true, "displayUrl": "sofia.cs.vt.edu/cs1114-ebooklet/chapter4.html", "snippet": "Once we have an <b>algorithm</b>, we <b>can</b> translate it into a computer program in some programming language. Our <b>algorithm</b> development process consists of five major steps. Step 1: Obtain a description of the problem. Step 2: Analyze the problem. Step 3: Develop a high-level <b>algorithm</b>. Step 4: Refine the <b>algorithm</b> by adding more detail. Step 5: Review the <b>algorithm</b>. Step 1: Obtain a description of the problem. This step is much more difficult than it appears. In the following discussion, the word ...", "dateLastCrawled": "2022-02-02T07:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Algorithmic <b>Decision</b>-Making and the Control Problem | SpringerLink", "url": "https://link.springer.com/article/10.1007/s11023-019-09513-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11023-019-09513-7", "snippet": "One <b>can</b> therefore only expect the operator to monitor the <b>computer\u2019s</b> decisions at some meta-level, to decide whether the <b>computer\u2019s</b> decisions are \u201cacceptable\u201d. (1983, p. 776, emphasis added) As we see things, this residual monitoring function of the human operator generates at least four kinds of difficulties that should be treated separately. The first relates to the cognitive limits of human processing power (the \u201ccapacity problem\u201d). Its statement in Bainbridge followed ...", "dateLastCrawled": "2022-02-02T13:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Understanding perception of algorithmic decisions: Fairness</b>, trust, and ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2053951718756684", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2053951718756684", "snippet": "\u201cI feel that if the <b>algorithm</b> is very carefully designed it <b>can</b> help remove harmful prejudices from the hiring process such as [<b>bias</b> based on] race, gender, or sexuality.\u201d (P189). \u201cI think the <b>algorithm</b> is more than capable of assessing the applicability of people [for] the job. I.e., it ought to be able to easily assess GPA, and the number and duration of previous work experience.", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "4 Genetic Algorithms_Steph Forrest.pdf - Genetic Algorithms STEPHANIE ...", "url": "https://www.coursehero.com/file/108771041/4-Genetic-Algorithms-Steph-Forrestpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/108771041/4-Genetic-<b>Algorithms</b>-Steph-Forrestpdf", "snippet": "View 4 Genetic Algorithms_Steph Forrest.pdf from <b>COMPUTER S</b> COS4852 at University of South Africa. Genetic Algorithms STEPHANIE FORREST Department of Computer Science, University of New Mexico,", "dateLastCrawled": "2022-01-29T21:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Information Processing</b> | <b>Simply Psychology</b>", "url": "https://www.simplypsychology.org/information-processing.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.simplypsychology.org</b>/<b>information-processing</b>.html", "snippet": "The idea of <b>information processing</b> was adopted by cognitive psychologists as a model of how human <b>thought</b> works. For example, the eye receives visual information and codes information into electric neural activity which is fed back to the brain where it is \u201cstored\u201d and \u201ccoded\u201d. This information is <b>can</b> be used by other parts of the brain relating to mental activities such as memory, perception and attention. The output (i.e. behavior) might be, for example, to read what you <b>can</b> see on ...", "dateLastCrawled": "2022-02-03T03:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Are Ideal Litigators White? Measuring the</b> Myth of ... - ResearchGate", "url": "https://www.researchgate.net/publication/228189941_Are_Ideal_Litigators_White_Measuring_the_Myth_of_Colorblindness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228189941_Are_Ideal_Litigators_White...", "snippet": "[13] Data from across the globe using the IAT show that <b>implicit</b> <b>bias</b> (as measured by this time latency) is pervas ive, large in magnitude, and non-random in direction.", "dateLastCrawled": "2021-09-01T20:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>The Algorithm Design Manual - Steven S</b>. Skiena | \u00d6zlem Ekici ...", "url": "https://www.academia.edu/48943214/The_Algorithm_Design_Manual_Steven_S_Skiena", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/48943214/<b>The_Algorithm_Design_Manual_Steven_S</b>_Skiena", "snippet": "Second Edition - Springer This book is intended as a manual on <b>algorithm</b> design, providing access to combinatorial <b>algorithm</b> technology for both students and computer professionals. It is divided into two parts: Techniques and Resources. The former", "dateLastCrawled": "2022-02-03T07:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Practice | GeeksforGeeks | A computer science portal for geeks", "url": "https://practice.geeksforgeeks.org/answers/Amit+Khandelwal+1/", "isFamilyFriendly": true, "displayUrl": "https://practice.geeksforgeeks.org/answers/Amit+Khandelwal+1", "snippet": "We <b>can</b> Use <b>Sorting</b> to solve the problem in O(n Log n) time. Following are detailed steps. 1) Copy the given array to an auxiliary array temp[]. 2) Sort the temp array using a O(nLogn) time <b>sorting</b> <b>algorithm</b>. 3) Scan the input array from left to right. For every element, count its occurrences in temp[] using binary search. As soon as we find a characterthat occurs more than once, we return the character. This step <b>can</b> be done in O(n Log n) time. An efficient solution is to use Hashing to ...", "dateLastCrawled": "2022-02-02T17:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Digging deeper or piling it higher? <b>Implicit</b> measurement in ...", "url": "https://www.researchgate.net/publication/257471772_Digging_deeper_or_piling_it_higher_Implicit_measurement_in_organizational_behavior_and_human_resource_management", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/257471772_Digging_deeper_or_piling_it_higher...", "snippet": "First, one <b>can</b> simply investigate the predictive validity of an <b>implicit</b> measure as compared to an explicit measure on an outcome, and see which measure has greater predictive value.", "dateLastCrawled": "2021-08-10T14:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Psychology Unit 7</b> Flashcards | Quizlet", "url": "https://quizlet.com/253854802/psychology-unit-7-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/253854802/<b>psychology-unit-7</b>-flash-cards", "snippet": "analogies that compare human memory to <b>computer&#39;s</b> operations. encoding. processing of information into memory system (extracting meaning) storage. process of retaining encoded information over time. retrieval . process of getting information out of memory storage. parallel processing. processing of many aspects simultaneously; brain&#39;s natural way to process information (contrast with step-by-step processing of <b>computers</b> and of conscious problem solving) connectionism. views memories as ...", "dateLastCrawled": "2021-12-15T20:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Even artificial intelligence <b>can</b> acquire biases against race and gender ...", "url": "https://www.science.org/content/article/even-artificial-intelligence-can-acquire-biases-against-race-and-gender", "isFamilyFriendly": true, "displayUrl": "https://www.science.org/content/article/even-artificial-intelligence-<b>can</b>-acquire...", "snippet": "Hiring by <b>algorithm</b> would give men and women an equal chance at work, the thinking goes, and predicting criminal behavior with big data would sidestep racial prejudice in policing. But a new study shows that <b>computers</b> <b>can</b> be biased as well, especially when they learn from us. When algorithms glean the meaning of words by gobbling up lots of human-written text, they adopt stereotypes very similar to our own.", "dateLastCrawled": "2022-02-02T10:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias</b> In <b>Personalization Algorithms</b> - Thank you, Eve!", "url": "https://www.thankyoueve.com/personalization-algorithm-bias", "isFamilyFriendly": true, "displayUrl": "https://www.thankyoueve.com/personalization-<b>algorithm</b>-<b>bias</b>", "snippet": "This interaction data is then <b>compared</b> to the rest of the user\u2019s profile and the <b>algorithm</b> will now automatically change the personalization based on the data it has gathered. The engine now not only considers data related to the search term, it also considers data related to users initiating the search (their user profiles). 2. <b>Bias</b> In <b>Personalization Algorithms</b>. After introducing proper categories for two understandings of <b>bias</b> relevant to our case, this section will look at the ethical ...", "dateLastCrawled": "2021-12-22T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Transparency in Complex Computational Systems | Philosophy of Science ...", "url": "https://www.cambridge.org/core/journals/philosophy-of-science/article/transparency-in-complex-computational-systems/4DB040EB28172CADF5F2858B62D0952C", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/philosophy-of-science/article/transparency-in...", "snippet": "Because an <b>algorithm</b> <b>can</b> be multiply realized in code, knowing the <b>algorithm</b> does not entail knowing the parts of a program or the relations between its parts. Programs that successfully carry out the same <b>algorithm</b> <b>can</b> be composed of different arrangements of parts, especially if they are written in different types of programing languages, whether procedural, functional, object oriented, or assembly. A program generated by machine learning may fail to be functionally transparent if its ...", "dateLastCrawled": "2022-01-18T17:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Are Ideal Litigators White? Measuring the</b> Myth of ... - ResearchGate", "url": "https://www.researchgate.net/publication/228189941_Are_Ideal_Litigators_White_Measuring_the_Myth_of_Colorblindness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228189941_Are_Ideal_Litigators_White...", "snippet": "[13] Data from across the globe using the IAT show that <b>implicit</b> <b>bias</b> (as measured by this time latency) is pervas ive, large in magnitude, and non-random in direction.", "dateLastCrawled": "2021-09-01T20:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Algorithmic <b>Decision</b>-Making and the Control Problem | SpringerLink", "url": "https://link.springer.com/article/10.1007/s11023-019-09513-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11023-019-09513-7", "snippet": "The danger of human operators devolving responsibility to machines and failing to detect cases where they fail has been recognised for many years by industrial psychologists and engineers studying the human operators of complex machines. We call it \u201cthe control problem\u201d, understood as the tendency of the human within a human\u2013machine control loop to become complacent, over-reliant or unduly diffident when faced with the outputs of a reliable autonomous system. While the control problem ...", "dateLastCrawled": "2022-02-02T13:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Understanding perception of algorithmic decisions: Fairness</b>, trust, and ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2053951718756684", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2053951718756684", "snippet": "One dictionary definition of \u201c<b>algorithm</b>\u201d is \u201ca process or set of rules to be followed in calculations or other problem-solving operations, especially by a computer.\u201d 2 This generic definition includes any rules that people and/or <b>computers</b> <b>can</b> follow. In our paper, we use the term \u201c<b>algorithm</b>\u201d to mean a computational formula that autonomously makes decisions based on statistical models or decision rules without explicit human intervention.", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Digging deeper or piling it higher? <b>Implicit</b> measurement in ...", "url": "https://www.researchgate.net/publication/257471772_Digging_deeper_or_piling_it_higher_Implicit_measurement_in_organizational_behavior_and_human_resource_management", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/257471772_Digging_deeper_or_piling_it_higher...", "snippet": "First, one <b>can</b> simply investigate the predictive validity of an <b>implicit</b> measure as <b>compared</b> to an explicit measure on an outcome, and see which measure has greater predictive value.", "dateLastCrawled": "2021-08-10T14:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Practice | GeeksforGeeks | A computer science portal for geeks", "url": "https://practice.geeksforgeeks.org/answers/Amit+Khandelwal+1/", "isFamilyFriendly": true, "displayUrl": "https://practice.geeksforgeeks.org/answers/Amit+Khandelwal+1", "snippet": "We <b>can</b> Use <b>Sorting</b> to solve the problem in O(n Log n) time. Following are detailed steps. 1) Copy the given array to an auxiliary array temp[]. 2) Sort the temp array using a O(nLogn) time <b>sorting</b> <b>algorithm</b>. 3) Scan the input array from left to right. For every element, count its occurrences in temp[] using binary search. As soon as we find a characterthat occurs more than once, we return the character. This step <b>can</b> be done in O(n Log n) time. An efficient solution is to use Hashing to ...", "dateLastCrawled": "2022-02-02T17:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>The Algorithm Design Manual - Steven S</b>. Skiena | \u00d6zlem Ekici ...", "url": "https://www.academia.edu/48943214/The_Algorithm_Design_Manual_Steven_S_Skiena", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/48943214/<b>The_Algorithm_Design_Manual_Steven_S</b>_Skiena", "snippet": "Second Edition - Springer This book is intended as a manual on <b>algorithm</b> design, providing access to combinatorial <b>algorithm</b> technology for both students and computer professionals. It is divided into two parts: Techniques and Resources. The former", "dateLastCrawled": "2022-02-03T07:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Psych Chapter 6-8</b> Flashcards - <b>Quizlet</b>", "url": "https://quizlet.com/194184339/psych-chapter-6-8-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/194184339/<b>psych-chapter-6-8</b>-flash-cards", "snippet": "Matching new items to a ----- provides a quick and easy method for <b>sorting</b> items into categories (as when comparing feathered creatures to a prototypical bird, such as a robin). prototype . A methodical, logical rule or procedure that guarantees you will solve a particular problem. Contrasts with the usually speedier - but also more error-prone - use of heuristics. <b>algorithm</b>. A simple thinking strategy that often allows you to make judgements and solve problems efficiently; usually speedier ...", "dateLastCrawled": "2021-04-15T01:42:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Implicit/Machine learning gender bias</b> | ReberLab", "url": "https://www.reberlab.psych.northwestern.edu/2018/10/11/implicitmachine-learning-gender-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.reberlab.psych.northwestern.edu/.../10/11/<b>implicitmachine-learning-gender-bias</b>", "snippet": "First, I have found myself describing on a few recent occasions that it is reasonable to think of <b>implicit</b> <b>learning</b> (IL) as the brain\u2019s <b>machine</b> <b>learning</b> (ML) algorithm. ML is a super-hot topic in AI and data science research, so this might be a useful <b>analogy</b> to help people understand what we mean by studying IL. We characterize IL as the statistical extraction of patterns in the environment and the shaping of cognitive processing to maximize efficiency and effectiveness to these patterns ...", "dateLastCrawled": "2020-11-16T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "Often <b>machine</b> <b>learning</b> programs inherit social patterns reflected in their training data without any directed effort by programmers to include such biases. Computer scientists call this algorithmic <b>bias</b>. This paper explores the relationship between <b>machine</b> <b>bias</b> and human cognitive <b>bias</b>. In it, I argue similarities between algorithmic and cognitive biases indicate a disconcerting sense in which sources of <b>bias</b> emerge out of seemingly innocuous patterns of information processing. The emergent ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning</b> | Gendered Innovations", "url": "http://genderedinnovations.stanford.edu/case-studies/machinelearning.html", "isFamilyFriendly": true, "displayUrl": "genderedinnovations.stanford.edu/case-studies/<b>machinelearning</b>.html", "snippet": "As <b>machine learning</b> becomes increasingly ubiquitous in everyday lives, such <b>bias</b>, if uncorrected, can lead to social inequities. Researchers need to understand how gender and ethnicity operate within the context of their algorithm in order to enhance or, at least, not reinforce social equalities. Here we suggest avenues for reducing <b>bias</b> in training data and algorithms in efforts to produce AI that enhances social equalities.", "dateLastCrawled": "2022-01-25T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Harnessing data for unbiased <b>Learning</b> of Machines | by Vivek Gupta | Medium", "url": "https://gvivek.medium.com/harnessing-data-for-unbiased-learning-of-machines-dc614497a29c", "isFamilyFriendly": true, "displayUrl": "https://gvivek.medium.com/harnessing-data-for-un<b>bias</b>ed-<b>learning</b>-of-<b>machines</b>-dc614497a29c", "snippet": "In <b>Machine</b> <b>Learning</b>, the input data reflects stereotypes and biases of the broader society, then the output of the <b>learning</b> algorithm also captures these stereotypes. Here, we will discuss the gender stereotypes in word embedding. word-embedding encode semantic information, they also exhibit hidden biases inherent in the dataset they are trained on associations such as: father:doctor :: mother:nurse. man:computer programmer :: woman:homemaker. The prejudices and stereotypes in these ...", "dateLastCrawled": "2022-01-12T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Fairness Metrics - Data Analytics - Data Science, <b>Machine</b> <b>Learning</b>, AI", "url": "https://vitalflux.com/fairness-metrics-ml-model-sensitivity-bias-detection/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>fairness-metrics-ml-model-sensitivity</b>-<b>bias</b>-detection", "snippet": "There are many different ways in which <b>machine</b> <b>learning</b> ... Instinctively (based on <b>implicit</b> human <b>bias</b>), it is one of the specific \u201cgender\u201d (male or female) against which the model could get biased as like in the real world in predicting whether those with a specific gender could re-offend or not. Thus, one of the protected attributes becomes gender. For the current example, in the real world, one could get biased in favor of female and not (or fail to) classify them as the ones who ...", "dateLastCrawled": "2022-01-20T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Introduction to Natural Language Processing</b> (NLP) and <b>Bias</b> in AI | by ...", "url": "https://towardsdatascience.com/introduction-to-natural-language-processing-nlp-and-bias-in-ai-877d3f3ee680", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>introduction-to-natural-language-processing</b>-nlp-and...", "snippet": "In this post, I will introduce key concepts of NLP such as word embeddings, and we will see how an algorithm can become biased, and how we can remove that <b>bias</b>. Le t \u2019s get started! For hands-on video tutorials on <b>machine</b> <b>learning</b>, deep <b>learning</b>, and artificial intelligence, checkout my YouTube channel.", "dateLastCrawled": "2022-01-20T19:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Learning is Requirements Engineering</b> \u2014 On the Role of Bugs ...", "url": "https://medium.com/analytics-vidhya/machine-learning-is-requirements-engineering-8957aee55ef4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>machine-learning-is-requirements-engineering</b>-8957...", "snippet": "A <b>machine</b>-learned model is not an attempt at implementing an <b>implicit</b> specification; a <b>machine</b>-learned model is a specification! It is a learned description of how the system shall behave. The ...", "dateLastCrawled": "2022-01-19T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word ...", "url": "https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf", "snippet": "signi\ufb01cant risk and challenge for <b>machine</b> <b>learning</b> and its applications. The analogies generated from these embeddings spell out the <b>bias</b> <b>implicit</b> in the data on which they were trained. Hence, word embeddings may serve as a means to extract <b>implicit</b> gender associations from a large text corpus", "dateLastCrawled": "2022-02-02T05:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Man is to Computer Programmer as Woman is</b> to Homemaker? | by Sheldon ...", "url": "https://towardsdatascience.com/man-is-to-computer-programmer-as-woman-is-to-homemaker-e57b07cbde96", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>man-is-to-computer-programmer-as-woman-is</b>-to-homemaker...", "snippet": "The paper discusses gender <b>bias</b> in <b>machine</b> <b>learning</b> as a result of using biased training data and proposes a solution to debias the model. This article contains an overview of the paper and discusses key findings in the python implementation of the paper. Overview. The authors of the paper used Word Embe d ding Model to demonstrate gender <b>bias</b> in the training data. The Word Embedding Model was trained on Google News articles and the vector representation of all words were stored in the ...", "dateLastCrawled": "2022-01-30T22:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "CSWA: <b>Unconscious Bias</b> | American Astronomical Society", "url": "https://aas.org/comms/cswa/resources/unconsciousbias", "isFamilyFriendly": true, "displayUrl": "https://aas.org/comms/cswa/resources/<b>unconsciousbias</b>", "snippet": "The intervention is based on the premise that <b>implicit bias is like</b> a habit that can be broken through a combination of awareness of implicit bias, concern about the effects of that bias, and the application of strategies to reduce bias. In a 12-week longitudinal study, people who received the intervention showed dramatic reductions in implicit race bias. People who were concerned about discrimination or who reported using the strategies showed the greatest reductions. The intervention also ...", "dateLastCrawled": "2022-02-03T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Patrick Forscher</b> \u2013 Research Lead \u2013 Busara Center for Behavioral ...", "url": "https://ch.linkedin.com/in/patrick-forscher-91163854", "isFamilyFriendly": true, "displayUrl": "https://ch.linkedin.com/in/<b>patrick-forscher</b>-91163854", "snippet": "The intervention is based on the premise that <b>implicit bias is like</b> a habit that can be broken through a combination of awareness of implicit bias, concern about the effects of that bias, and the application of strategies to reduce bias. In a 12-week longitudinal study, people who received the intervention showed dramatic reductions in implicit race bias. People who were\u2026 We developed a multi-faceted prejudice habit-breaking intervention to produce long-term reductions in implicit race ...", "dateLastCrawled": "2022-02-03T15:10:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Those designing healthcare algorithms must become actively</b> anti-racist ...", "url": "https://www.nature.com/articles/s41591-020-1020-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41591-020-1020-3", "snippet": "<b>Just as \u2018implicit bias</b>\u2019 training for police does little to change racist behavior 10 \u2014in large part because departmental cultures do not fully support the lessons of anti-racism\u2014healthcare ...", "dateLastCrawled": "2021-11-15T00:12:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(implicit bias)  is like +(computer\u2019s sorting algorithm)", "+(implicit bias) is similar to +(computer\u2019s sorting algorithm)", "+(implicit bias) can be thought of as +(computer\u2019s sorting algorithm)", "+(implicit bias) can be compared to +(computer\u2019s sorting algorithm)", "machine learning +(implicit bias AND analogy)", "machine learning +(\"implicit bias is like\")", "machine learning +(\"implicit bias is similar\")", "machine learning +(\"just as implicit bias\")", "machine learning +(\"implicit bias can be thought of as\")", "machine learning +(\"implicit bias can be compared to\")"]}