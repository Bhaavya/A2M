{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions | DeepAI", "url": "https://deepai.org/publication/stylemesh-style-transfer-for-indoor-3d-scene-reconstructions", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/style<b>mesh</b>-style-transfer-for-indoor-3d-scene...", "snippet": "On the other hand, model-based 3D style transfer methods exist that allow stylization from a <b>sparse</b> set of images, but they require a network at inference time. To this end, we optimize an explicit texture for the reconstructed <b>mesh</b> of a scene and stylize it jointly from all available input images. Our depth- and angle-aware optimization leverages surface normal and depth data of the underlying <b>mesh</b> to create a uniform and consistent stylization for the whole scene. Our experiments show that ...", "dateLastCrawled": "2022-01-21T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Microsoft Patent | Dense depth computations aided by <b>sparse</b> <b>feature</b> ...", "url": "https://patent.nweon.com/21463", "isFamilyFriendly": true, "displayUrl": "https://patent.nweon.com/21463", "snippet": "A system configured for dense depth computations aided by <b>sparse</b> <b>feature</b> matching, the system comprising: a first camera, a second camera, and a third camera; one or more processors; and one or more computer-readable hardware storage devices that store instructions that are executable by the one or more processors to cause the system to at least: generate a first image using the first camera, a second image using the second camera, and a third image using the third camera; generate a <b>sparse</b> ...", "dateLastCrawled": "2022-01-26T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Sparse</b> Low-<b>degree Implicit Surfaces with Applications</b> to High Quality ...", "url": "https://www.researchgate.net/publication/47861609_Sparse_Low-degree_Implicit_Surfaces_with_Applications_to_High_Quality_Rendering_Feature_Extraction_and_Smoothing", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/47861609_<b>Sparse</b>_Low-degree_Implicit_Surfaces...", "snippet": "The framework is based on dictionary learning in which the dictionary consists of the vertices of the reconstructed triangular <b>mesh</b> and the <b>sparse</b> coding matrix encodes the connectivity of the ...", "dateLastCrawled": "2021-12-17T16:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>List of Accepted Papers</b> \u2013 ICIP 2020", "url": "https://2020.ieeeicip.org/list-of-accepted-papers/", "isFamilyFriendly": true, "displayUrl": "https://2020.ieeeicip.org/<b>list-of-accepted-papers</b>", "snippet": "guided <b>sparse</b> <b>feature</b> matching via coarsely defined dense matches: 2633: handloom design generation using generative networks: 1534: hdr image saliency estimation by convex optimization : 2793: hdr imaging from quantization noise: 1542: hdr tomography via modulo radon transform: 1691: heart rate detection from facial videos using a frequency-constrained multilayer <b>sparse</b> coding: 2765: hidden markov modelling and recognition of euler-based motion patterns for automatically detecting risks ...", "dateLastCrawled": "2022-02-02T22:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Tutorial: <b>Meshroom</b> for Beginners \u2014 <b>Meshroom</b> v2021.0.1 documentation", "url": "https://meshroom-manual.readthedocs.io/en/latest/tutorials/sketchfab/sketchfab.html", "isFamilyFriendly": true, "displayUrl": "https://<b>meshroom</b>-manual.readthedocs.io/en/latest/tutorials/sketchfab/sketchfab.html", "snippet": "Decimate the <b>mesh</b> within <b>Meshroom</b> to reduce the number of polygons. Clean up this <b>mesh</b> in an external software, if required (to remove background elements for example) Retexture the cleaned up <b>mesh</b>. Upload model and textures to Sketchfab. To directly publish your model from <b>Meshroom</b>, create a new SketchfabUpload node and connect it to the ...", "dateLastCrawled": "2022-02-03T07:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Photogrammery testing 14: AliceVision Meshroom</b> - Dr Peter L. Falkingham", "url": "https://peterfalkingham.com/2018/08/11/photogrammery-testing-14-alicevision-meshroom/", "isFamilyFriendly": true, "displayUrl": "https://peterfalkingham.com/2018/08/11/<b>photogrammery-testing-14-alicevision-meshroom</b>", "snippet": "Modules can be added to the graph at the bottom of the <b>screen</b>, and clicking on any module will present all of the attributes available to change. I tried again with DepthMap set to downscale 4 and 16 (default 2), as well as reducing some of the iterations and sampling variables, and that reduced the time taken a little. I also added a <b>mesh</b> decimation <b>feature</b>, and lowered texture resolution from 8192 to 4096, and the resulting model was still excellent, and much smaller file size. I also ...", "dateLastCrawled": "2022-02-02T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Assets - <b>Screen Space Displacement Mapping (No Tesselation</b>) - Progress ...", "url": "https://forum.unity.com/threads/screen-space-displacement-mapping-no-tesselation-progress.611659/page-2", "isFamilyFriendly": true, "displayUrl": "https://forum.unity.com/threads/<b>screen-space-displacement-mapping-no-tesselation</b>...", "snippet": "There are some things that need to be considered as really it <b>is like</b> one giant surface <b>mesh</b> pushed from the <b>screen</b> into the 3d world, so for example ray-traced reflections for objects reflecting objects infront of them would be black, as the back faces would not exist and I think shadows would have issues too. not to say there are not ways it could be done. but needs a bit more deep thought. I would love realistic lighting myself, actually I have been chasing this for long time as I think ...", "dateLastCrawled": "2021-12-22T03:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "MeshLab / Discussion / Users: Watertight meshes...", "url": "https://sourceforge.net/p/meshlab/discussion/499532/thread/9b55303d/", "isFamilyFriendly": true, "displayUrl": "https://<b>sourceforge.net</b>/p/<b>mesh</b>lab/discussion/499532/thread/9b55303d", "snippet": "I am also a newbie trying to <b>mesh</b> more 1M+ pointcloud, the issue i am getting at the moment is that meshlab crashes at 400k+ pointclouds under the pointset normalise filter, therefore cannot proceed onto the poison remesh filter. My process is to inport 3M pointcloud, then poison sample, then vertex sample down to about 400k points, then normalise. This works but at a much lower resolution than i <b>like</b>, there is a lot of noise on the pointcloud but not sure this matters. Imiller - 2013-09-25 ...", "dateLastCrawled": "2022-01-21T07:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "So, Nanite | Page 4 - Unity Forum", "url": "https://forum.unity.com/threads/so-nanite.889714/page-4", "isFamilyFriendly": true, "displayUrl": "https://forum.unity.com/threads/so-nanite.889714/page-4", "snippet": "And given the density of teh <b>mesh</b> your forgo global texture since texture are there to supply details to <b>sparse</b> <b>mesh</b>, that&#39;s the key, because texture are always power of two and increase quadratrically in size, while nanite is arbitrary in size, not having texture with their mipmap (for the same level of details) is the big saving you see on nanite. And you can probably run an optimized decimation that remove vertex less contributing to shape before going into nanite anyway.", "dateLastCrawled": "2022-01-30T12:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "5 <b>Best Free Photogrammetry Software For Windows</b>", "url": "https://listoffreeware.com/best-free-photogrammetry-software-windows/", "isFamilyFriendly": true, "displayUrl": "https://listoffreeware.com/best-free-photogrammetry-software-windows", "snippet": "VisualSFM is a <b>free photogrammetry software for Windows</b>, MacOS, and Linux. Using this software, you can create a 3D model using multiple photos of an object taken from multiple angles. To create a realistic looking 3D model <b>mesh</b>, it is necessary to have at least 40 to 50 images. To create a high-quality 3D model or <b>mesh</b>, you can also use around 100 images. As it needs a lot of images to create a 3D <b>mesh</b>, hence this software takes some time to process all images.", "dateLastCrawled": "2022-02-02T14:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Tutorial: <b>Meshroom</b> for Beginners \u2014 <b>Meshroom</b> v2021.0.1 documentation", "url": "https://meshroom-manual.readthedocs.io/en/latest/tutorials/sketchfab/sketchfab.html", "isFamilyFriendly": true, "displayUrl": "https://<b>meshroom</b>-manual.readthedocs.io/en/latest/tutorials/sketchfab/sketchfab.html", "snippet": "SfM: Structure-from-Motion (<b>sparse</b> reconstruction) Infers the rigid scene structure (3D points) with the pose (position and orientation) and internal calibration of all cameras. The result is a set of calibrated cameras with a <b>sparse</b> point cloud (in Alembic file format). MVS: MultiView-Stereo (dense reconstruction) Uses the calibrated cameras from the Structure-from-Motion to generate a dense geometric surface. The final result is a textured <b>mesh</b> (in OBJ file format with the corresponding ...", "dateLastCrawled": "2022-02-03T07:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Mesh</b> Failure Prediction Using Deep Learning Techniques (Technical ...", "url": "https://www.osti.gov/biblio/1601556-mesh-failure-prediction-using-deep-learning-techniques", "isFamilyFriendly": true, "displayUrl": "https://www.osti.gov/biblio/1601556-<b>mesh</b>-failure-prediction-using-deep-learning-techniques", "snippet": "The U.S. Department of Energy&#39;s Office of Scientific and Technical Information", "dateLastCrawled": "2021-09-18T06:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Machine Learning in Drug Discovery: A Review", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8356896/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8356896", "snippet": "Therefore, the MGE-CNN model succussed because of <b>feature</b> extraction, model development, molecular encoding <b>is similar</b> in training for neural networks. The advantage was, the issue can alter through molecular fingerprints because of accessibility of flexibility in the MGE-CNN model. For acquiring great fragments relates to structural alerts, Xu et al. utilized toxic features for fingerprints which characterizes TOX Alerts (Sushko et al.", "dateLastCrawled": "2022-01-27T11:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions | DeepAI", "url": "https://deepai.org/publication/stylemesh-style-transfer-for-indoor-3d-scene-reconstructions", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/style<b>mesh</b>-style-transfer-for-indoor-3d-scene...", "snippet": "Figure 3: Stylizing <b>mesh</b> faces in 2D (<b>screen</b>-space) is dependent on angle and size of the projected geometry. Optimizing the faces of a wall from a small grazing angle leads to stretched-out stylization patterns in world-space (yellow). Regions of <b>similar</b> size can receive more or less patterns, depending on their projected size (green and red). We denote stylization patterns as circles that are optimized from <b>screen</b>-space into texture space.", "dateLastCrawled": "2022-01-21T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "5 <b>Best Free Photogrammetry Software For Windows</b>", "url": "https://listoffreeware.com/best-free-photogrammetry-software-windows/", "isFamilyFriendly": true, "displayUrl": "https://listoffreeware.com/best-free-photogrammetry-software-windows", "snippet": "VisualSFM is a <b>free photogrammetry software for Windows</b>, MacOS, and Linux. Using this software, you can create a 3D model using multiple photos of an object taken from multiple angles. To create a realistic looking 3D model <b>mesh</b>, it is necessary to have at least 40 to 50 images. To create a high-quality 3D model or <b>mesh</b>, you can also use around 100 images. As it needs a lot of images to create a 3D <b>mesh</b>, hence this software takes some time to process all images.", "dateLastCrawled": "2022-02-02T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Microsoft Patent | Dense depth computations aided by <b>sparse</b> <b>feature</b> ...", "url": "https://patent.nweon.com/21463", "isFamilyFriendly": true, "displayUrl": "https://patent.nweon.com/21463", "snippet": "A system configured for dense depth computations aided by <b>sparse</b> <b>feature</b> matching, the system comprising: a first camera, a second camera, and a third camera; one or more processors; and one or more computer-readable hardware storage devices that store instructions that are executable by the one or more processors to cause the system to at least: generate a first image using the first camera, a second image using the second camera, and a third image using the third camera; generate a <b>sparse</b> ...", "dateLastCrawled": "2022-01-26T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "So, Nanite | Page 4 - Unity Forum", "url": "https://forum.unity.com/threads/so-nanite.889714/page-4", "isFamilyFriendly": true, "displayUrl": "https://forum.unity.com/threads/so-nanite.889714/page-4", "snippet": "And given the density of teh <b>mesh</b> your forgo global texture since texture are there to supply details to <b>sparse</b> <b>mesh</b>, that&#39;s the key, because texture are always power of two and increase quadratrically in size, while nanite is arbitrary in size, not having texture with their mipmap (for the same level of details) is the big saving you see on nanite. And you can probably run an optimized decimation that remove vertex less contributing to shape before going into nanite anyway.", "dateLastCrawled": "2022-01-30T12:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Create Marker in Orthomosaic View - Metashape", "url": "https://www.agisoft.com/forum/index.php?topic=6791.0", "isFamilyFriendly": true, "displayUrl": "https://www.agisoft.com/<b>forum</b>/index.php?topic=6791.0", "snippet": "I use a strange workflow that works <b>fine</b> for non-geotagged imagery and it is fast. 1. align 2. rougly level <b>sparse</b> cloud and bounding box with red face down 3. build a <b>mesh</b> in heightfield mode 4. build texture with 4096 size 5. pin GCP&#39;s on model 6. delete <b>mesh</b> model 7. refine blue flags in all photos. (this step will be a lot faster if targets have been used and you enable automatic target projections refinement) If you use this approach with non georeferenced imagery you just need to pin ...", "dateLastCrawled": "2022-01-29T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Scenery and HD <b>Mesh</b> v2: Q&amp;A <b>With Andras Fabian (alpilotx</b>) - Interviews ...", "url": "https://www.avsim.com/home/interviews/scenery-and-hd-mesh-v2-qampa-with-andras-fabian-alpilotx-r2238/", "isFamilyFriendly": true, "displayUrl": "https://www.avsim.com/home/interviews/scenery-and-hd-<b>mesh</b>-v2-qampa-with-andras-fabian...", "snippet": "Oh yes, and this is a <b>feature</b> which is identical with the Global Scenery (this one I didn\u2019t change / improve for HD <b>Mesh</b>). We use a quite detailed climate model (from real climate data at quite high resolution, telling us mean annual rainfall and temperature) to make the scenery look more - uhm - regionalized. We cover climates from cold to hot trough dry and wet (in a multitude of combination). They are represented in many different terrain definitions (TER files - you can see them in ...", "dateLastCrawled": "2022-01-13T09:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Scenery and HD <b>Mesh</b> v2: Q&amp;A <b>With Andras Fabian (alpilotx</b>) - The X-Plane ...", "url": "https://www.avsim.com/forums/topic/442361-scenery-and-hd-mesh-v2-qa-with-andras-fabian-alpilotx/", "isFamilyFriendly": true, "displayUrl": "https://www.avsim.com/forums/topic/442361-scenery-and-hd-<b>mesh</b>-v2-qa-with-andras-fabian...", "snippet": "Oh yes, and this is a <b>feature</b> which is identical with the Global Scenery (this one I didn\u2019t change / improve for HD <b>Mesh</b>). We use a quite detailed climate model (from real climate data at quite high resolution, telling us mean annual rainfall and temperature) to make the scenery look more - uhm - regionalized. We cover climates from cold to hot trough dry and wet (in a multitude of combination). They are represented in many different terrain definitions (TER files - you can see them in ...", "dateLastCrawled": "2022-01-23T14:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Microsoft Patent | Dense depth computations aided by <b>sparse</b> <b>feature</b> ...", "url": "https://patent.nweon.com/21463", "isFamilyFriendly": true, "displayUrl": "https://patent.nweon.com/21463", "snippet": "A system configured for dense depth computations aided by <b>sparse</b> <b>feature</b> matching, the system comprising: a first camera, a second camera, and a third camera; one or more processors; and one or more computer-readable hardware storage devices that store instructions that are executable by the one or more processors to cause the system to at least: generate a first image using the first camera, a second image using the second camera, and a third image using the third camera; generate a <b>sparse</b> ...", "dateLastCrawled": "2022-01-26T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Photogrammery testing 14: AliceVision Meshroom</b> - Dr Peter L. Falkingham", "url": "https://peterfalkingham.com/2018/08/11/photogrammery-testing-14-alicevision-meshroom/", "isFamilyFriendly": true, "displayUrl": "https://peterfalkingham.com/2018/08/11/<b>photogrammery-testing-14-alicevision-meshroom</b>", "snippet": "Modules <b>can</b> be added to the graph at the bottom of the <b>screen</b>, and clicking on any module will present all of the attributes available to change. I tried again with DepthMap set to downscale 4 and 16 (default 2), as well as reducing some of the iterations and sampling variables, and that reduced the time taken a little. I also added a <b>mesh</b> decimation <b>feature</b>, and lowered texture resolution from 8192 to 4096, and the resulting model was still excellent, and much smaller file size. I also ...", "dateLastCrawled": "2022-02-02T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Automatic and topology-preserving gradient mesh generation for</b> ...", "url": "https://www.academia.edu/14720179/Automatic_and_topology_preserving_gradient_mesh_generation_for_image_vectorization", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/14720179/<b>Automatic_and_topology_preserving_gradient</b>_<b>mesh</b>...", "snippet": "By using a triangulation, such methods <b>can</b> deal with a high-dimensional space: the image region <b>can</b> <b>be thought</b> of as general images. However, many irregular triangles typically result, a surface. We <b>can</b> now adapt well-established geometry process- and so the results are not compact. Lecot et al\u2019s \u2018ARDECO\u2019 uses ing techniques to gradient <b>mesh</b> generation. We use an adapted automatic region detection and conversion with centroidal Voronoi parameterization technique to map an arbitrary ...", "dateLastCrawled": "2022-01-13T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "201 questions with answers in <b>MESH GENERATION</b> | Scientific method", "url": "https://www.researchgate.net/topic/Mesh-Generation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Mesh-Generation</b>", "snippet": "Aug 8, 2021. Answer. Zeinah Mohamad Elnassar, No, when you reduce the <b>mesh</b>, firstly, you <b>can</b> get the result faster, if there is a wrong you <b>can</b> repeat it without losing much time. Secondly, if you ...", "dateLastCrawled": "2022-01-23T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Meshmixer</b> Crashes - <b>Autodesk</b> Community", "url": "https://forums.autodesk.com/t5/fusion-360-design-validate/meshmixer-crashes/td-p/5534125", "isFamilyFriendly": true, "displayUrl": "https://<b>forums.autodesk.com</b>/t5/fusion-360-design-validate/<b>meshmixer</b>-crashes/td-p/5534125", "snippet": "I <b>can</b>&#39;t get <b>mesh mixer</b> to crash on amy of my models or the samples so this could be design specific. <b>Can</b> you export the design and send a fusion archive to me and I&#39;ll take a look. Thanks, Bankim. Report. 0 Likes Reply. Message 3 of 22 keqingsong. in reply to: charegb \u200e03-10-2015 06:00 AM. Mark as New; Bookmark; Subscribe; Mute; Subscribe to RSS Feed; Permalink; Print; Report \u200e03-10-2015 06:00 AM. Do you have version 2.8? Looks like the team updated the utility on Jan 30, 2015 - get it ...", "dateLastCrawled": "2022-02-02T13:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Screen</b>-space outline effect for <b>Unity</b> (FREE) | Page 2 - <b>Unity</b> Forum", "url": "https://forum.unity.com/threads/screen-space-outline-effect-for-unity-free.836908/page-2", "isFamilyFriendly": true, "displayUrl": "https://forum.<b>unity</b>.com/threads/<b>screen</b>-space-outline-effect-for-<b>unity</b>-free.836908/page-2", "snippet": "I opened a ticket on github with <b>feature</b> request. Btw, how <b>can</b> I use two different Outline Settings for two layers in URP? I read from your changelog that this should be possible and editor interface kind of implies it, but no matter how I try - I <b>can</b>&#39;t make it to work. I ended up adding additional Outline Renderer <b>Feature</b> and configuring it separately for another layer, but this approach feels wrong. Teea, Nov 14, 2020 #61. ghegi. Joined: Jun 3, 2018 Posts: 28. Teea said: \u2191 @ghegi is it ...", "dateLastCrawled": "2022-01-31T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Assets - <b>Screen</b> <b>Space Displacement Mapping (No Tesselation) - Progress</b> ...", "url": "https://forum.unity.com/threads/screen-space-displacement-mapping-no-tesselation-progress.611659/", "isFamilyFriendly": true, "displayUrl": "https://forum.unity.com/threads/<b>screen</b>-<b>space-displacement-mapping-no-tesselation</b>...", "snippet": "I almost dismissed the idea because I <b>thought</b> using the <b>screen</b> as a <b>mesh</b> would cost to much, but gpu to the rescue, I love compute shaders so much))). So basically is is just a shader and camera that generate <b>screen</b> maps to send to the compute shader for Displacement and drawn with DrawProcedural. Unity just blows my mind with it&#39;s ease of use and made this such a great task to explore. Anyway I will be releasing it soon (hope after weekend) and just wanted to create an awareness for anyone ...", "dateLastCrawled": "2022-02-02T18:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How To Set Up A Home Or Remote Office - Everything You Need To Know", "url": "https://www.joinportal.com/blog/setting-up-a-home-office-for-remote-work/", "isFamilyFriendly": true, "displayUrl": "https://www.joinportal.com/blog/setting-up-a-home-office-for-remote-work", "snippet": "One study by the University of Exeter found that adding plants to a <b>sparse</b> office space <b>can</b> increase productivity by ... so achieving a perfect <b>screen</b> height <b>can</b> be difficult. Ideally, your eye level should hit the top of your monitor when sitting straight. You should then tilt the monitor slightly up to encourage proper posture. If possible, you want the <b>screen</b> to be about 18-24 inches away from your face to reduce eye strain. For laptop users, a laptop stand <b>can</b> help reach these goals ...", "dateLastCrawled": "2022-02-03T04:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "how <b>to merge meshes in nifskope</b> : skyrimmods - <b>reddit</b>", "url": "https://www.reddit.com/r/skyrimmods/comments/hgj8hs/how_to_merge_meshes_in_nifskope/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/skyrimmods/comments/hgj8hs/how_<b>to_merge_meshes_in_nifskope</b>", "snippet": "7- The <b>mesh</b> should look good in the picture, but it still needs a bit of work. Find one of the original <b>mesh</b> pieces of .nif1 and go to NiTriStrips &gt; BSDismemberSkinInstance. At the bottom of the Block Details go to Partitions &gt; Partitions &gt; Body Part. Remember what it says or simply copy the text listed.", "dateLastCrawled": "2021-12-31T02:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Pixels? <b>Triangles? What\u2019s the difference? \u2014 How (I think) Nanite</b> ...", "url": "https://www.reddit.com/r/hardware/comments/gkcd9b/pixels_triangles_whats_the_difference_how_i_think/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/hardware/comments/gkcd9b/pixels_triangles_whats_the...", "snippet": "Because our triangles are covering significantly sized areas on the <b>screen</b>, we also need to include textures that capture the <b>fine</b>-grained detail of the triangle, which includes the suface&#39;s normal map, a texture representing the angles of the pixels, and <b>can</b> also include a height map, representing how far the pixel should jut inward or outward of the plane of the triangle.", "dateLastCrawled": "2021-11-15T10:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Marching Cubes and Histogram Pyramids for 3D Medical Visualization", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321043/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8321043", "snippet": "The histogram pyramids <b>can</b> decrease the number of <b>sparse</b> matrixes that will occur during voxel manipulation. The important <b>feature</b> of the histogram pyramids is the direction of segments in the image. Then this <b>feature</b> will be used for connecting pixels (2D) to form up voxel (3D) during marching cubes implementation. The proposed method is fast and easy to implement and it also produces a smooth result (<b>compared</b> to the traditional marching cubes technique). The experimental results show the ...", "dateLastCrawled": "2021-12-29T10:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Hierarchical Graph Networks for 3D Human Pose Estimation | DeepAI", "url": "https://deepai.org/publication/hierarchical-graph-networks-for-3d-human-pose-estimation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/hierarchical-graph-networks-for-3d-human-pose-estimation", "snippet": "Since <b>sparse</b> <b>mesh</b> <b>can</b> represent the shape information of human body, it contains more abundant and detailed information. Adding additional <b>mesh</b> constraints makes our model extract detail-related features, which is of great help to the evaluation of some joints with high degrees of freedom. In a nutshell, this paper makes the following contributions: We build a novel hierarchical graph network with multi-scale <b>feature</b> fusion. It is based on denser graph topology generated by our multi-scale ...", "dateLastCrawled": "2022-01-24T13:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Mesh</b> Failure Prediction Using Deep Learning Techniques (Technical ...", "url": "https://www.osti.gov/biblio/1601556-mesh-failure-prediction-using-deep-learning-techniques", "isFamilyFriendly": true, "displayUrl": "https://www.osti.gov/biblio/1601556-<b>mesh</b>-failure-prediction-using-deep-learning-techniques", "snippet": "The U.S. Department of Energy&#39;s Office of Scientific and Technical Information", "dateLastCrawled": "2021-09-18T06:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions | DeepAI", "url": "https://deepai.org/publication/stylemesh-style-transfer-for-indoor-3d-scene-reconstructions", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/style<b>mesh</b>-style-transfer-for-indoor-3d-scene...", "snippet": "Figure 3: Stylizing <b>mesh</b> faces in 2D (<b>screen</b>-space) is dependent on angle and size of the projected geometry. Optimizing the faces of a wall from a small grazing angle leads to stretched-out stylization patterns in world-space (yellow). Regions of similar size <b>can</b> receive more or less patterns, depending on their projected size (green and red). We denote stylization patterns as circles that are optimized from <b>screen</b>-space into texture space.", "dateLastCrawled": "2022-01-21T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Machine Learning in Drug Discovery: A Review", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8356896/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8356896", "snippet": "By using deep learning and <b>feature</b> extraction tools, it is mandatory to predict the secondary structure (Spencer et al. 2014) and residing the protein contacts (Li et al. 2017). It precisely gains the information on the connection among structure and sequence from <b>feature</b> extraction. The further goal is to predict the 3D- protein structure by utilizing deep learning techniques for improving the accuracy. To retrieve information from drug design of protein-protein computer structure, then it ...", "dateLastCrawled": "2022-01-27T11:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Sparse</b> Low-<b>degree Implicit Surfaces with Applications</b> to High Quality ...", "url": "https://www.researchgate.net/publication/47861609_Sparse_Low-degree_Implicit_Surfaces_with_Applications_to_High_Quality_Rendering_Feature_Extraction_and_Smoothing", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/47861609_<b>Sparse</b>_Low-degree_Implicit_Surfaces...", "snippet": "<b>Compared</b> to other estimation algorithms, this weighted bicubic Bezier patch more accurately obtains the normal vector and curvature estimation of a triangular <b>mesh</b> model. Furthermore, we define ...", "dateLastCrawled": "2021-12-17T16:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Microsoft Patent | Dense depth computations aided by <b>sparse</b> <b>feature</b> ...", "url": "https://patent.nweon.com/21463", "isFamilyFriendly": true, "displayUrl": "https://patent.nweon.com/21463", "snippet": "A system configured for dense depth computations aided by <b>sparse</b> <b>feature</b> matching, the system comprising: a first camera, a second camera, and a third camera; one or more processors; and one or more computer-readable hardware storage devices that store instructions that are executable by the one or more processors to cause the system to at least: generate a first image using the first camera, a second image using the second camera, and a third image using the third camera; generate a <b>sparse</b> ...", "dateLastCrawled": "2022-01-26T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "So, Nanite | Page 4 - Unity Forum", "url": "https://forum.unity.com/threads/so-nanite.889714/page-4", "isFamilyFriendly": true, "displayUrl": "https://forum.unity.com/threads/so-nanite.889714/page-4", "snippet": "And given the density of teh <b>mesh</b> your forgo global texture since texture are there to supply details to <b>sparse</b> <b>mesh</b>, that&#39;s the key, because texture are always power of two and increase quadratrically in size, while nanite is arbitrary in size, not having texture with their mipmap (for the same level of details) is the big saving you see on nanite. And you <b>can</b> probably run an optimized decimation that remove vertex less contributing to shape before going into nanite anyway.", "dateLastCrawled": "2022-01-30T12:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Scenery and HD <b>Mesh</b> v2: Q&amp;A <b>With Andras Fabian (alpilotx</b>) - Interviews ...", "url": "https://www.avsim.com/home/interviews/scenery-and-hd-mesh-v2-qampa-with-andras-fabian-alpilotx-r2238/", "isFamilyFriendly": true, "displayUrl": "https://www.avsim.com/home/interviews/scenery-and-hd-<b>mesh</b>-v2-qampa-with-andras-fabian...", "snippet": "One of its big pluses <b>compared</b> to the default Global Scenery is - as its name suggests - the much higher density of its triangle <b>mesh</b> (about 2-3 times denser, which by the way is an irregular triangle <b>mesh</b>). This is very positive in at least two ways: First of all, it of course allows a much better representation of the underlying elevation raster data (a more detailed triangle <b>mesh</b> <b>can</b> represent much more elevation &quot;points&quot;, much more accurately) Secondly, this also allows a much more ...", "dateLastCrawled": "2022-01-13T09:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Scenery and HD <b>Mesh</b> v2: Q&amp;A <b>With Andras Fabian (alpilotx</b>) - The X-Plane ...", "url": "https://www.avsim.com/forums/topic/442361-scenery-and-hd-mesh-v2-qa-with-andras-fabian-alpilotx/", "isFamilyFriendly": true, "displayUrl": "https://www.avsim.com/forums/topic/442361-scenery-and-hd-<b>mesh</b>-v2-qa-with-andras-fabian...", "snippet": "One of its big pluses <b>compared</b> to the default Global Scenery is - as its name suggests - the much higher density of its triangle <b>mesh</b> (about 2-3 times denser, which by the way is an irregular triangle <b>mesh</b>). This is very positive in at least two ways: First of all, it of course allows a much better representation of the underlying elevation raster data (a more detailed triangle <b>mesh</b> <b>can</b> represent much more elevation &quot;points&quot;, much more accurately) Secondly, this also allows a much more ...", "dateLastCrawled": "2022-01-23T14:16:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "An E\ufb03cient <b>Sparse</b> Metric <b>Learning</b> in High ... - <b>Machine</b> <b>Learning</b>", "url": "http://machinelearning.org/archive/icml2009/papers/46.pdf", "isFamilyFriendly": true, "displayUrl": "<b>machinelearning</b>.org/archive/icml2009/papers/46.pdf", "snippet": "An E\ufb03cient <b>Sparse</b> Metric <b>Learning</b> in High-Dimensional Space via!1-Penalized Log-Determinant Regularization Guo-Jun Qi qi4@illinois.edu Depart. ECE, University of Illinois at Urbana-Champaign, 405 North Mathews Avenue, Urbana, IL 61801 USA Jinhui Tang, Zheng-Jun Zha, Tat-Seng Chua {tangjh, zhazj, chuats}@comp.nus.edu.sg School of Computing, National University of Singapore, Computing 1, 13 Computing Drive, Singapore 117417 Hong-Jiang Zhang hjzhang@microsoft.com Microsoft Advanced Technology ...", "dateLastCrawled": "2021-11-19T11:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "9.5 <b>Shapley</b> Values | Interpretable <b>Machine</b> <b>Learning</b>", "url": "https://christophm.github.io/interpretable-ml-book/shapley.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-book/<b>shapley</b>.html", "snippet": "Let us reuse the game <b>analogy</b>: We start with an empty team, add the <b>feature</b> value that would contribute the most to the prediction and iterate until all <b>feature</b> values are added. How much each <b>feature</b> value contributes depends on the respective <b>feature</b> values that are already in the \u201cteam\u201d, which is the big drawback of the breakDown method. It is faster than the <b>Shapley</b> value method, and for models without interactions, the results are the same.", "dateLastCrawled": "2022-02-02T05:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Introduction to Matrices and Matrix Arithmetic for <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/introduction-matrices-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/introduction-matrices-<b>machine-learning</b>", "snippet": "The geometric <b>analogy</b> used to help understand vectors and some of their operations does not hold with matrices. Further, a vector itself may be considered a matrix with one column and multiple rows. Often the dimensions of the matrix are denoted as m and n for the number of rows and the number of columns. Now that we know what a matrix is, let\u2019s look at defining one in Python. Defining a Matrix. We can represent a matrix in Python using a two-dimensional NumPy array. A NumPy array can be ...", "dateLastCrawled": "2022-02-02T11:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Lecture 4: \\(k\\)-Nearest Neighbours and SVM RBFs \u2014 CPSC 330 Applied ...", "url": "https://ubc-cs.github.io/cpsc330/lectures/04_kNNs-SVM-RBF.html", "isFamilyFriendly": true, "displayUrl": "https://ubc-cs.github.io/cpsc330/lectures/04_kNNs-SVM-RBF.html", "snippet": "<b>Analogy</b>-based models ... It does not work well on datasets with many features or where most <b>feature</b> values are 0 most of the time (<b>sparse</b> datasets). Attention. For regular \\(k\\) -NN for supervised <b>learning</b> (not with <b>sparse</b> matrices), you should scale your features. We\u2019ll be looking into it soon. Parametric vs non parametric\u00b6 You might see a lot of definitions of these terms. A simple way to think about this is: do you need to store at least \\(O(n)\\) worth of stuff to make predictions? If ...", "dateLastCrawled": "2022-01-11T11:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine learning MCQs</b> | T4Tutorials.com", "url": "https://t4tutorials.com/machine-learning-mcqs/", "isFamilyFriendly": true, "displayUrl": "https://t4tutorials.com/<b>machine-learning-mcqs</b>", "snippet": "<b>Machine learning MCQs</b>. 1. The general concept and process of forming definitions from examples of concepts to be learned. E. All of these. F. None of these. 2. The computer is the best <b>learning</b> for.", "dateLastCrawled": "2022-01-30T16:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "9.6 <b>SHAP</b> (SHapley Additive exPlanations) | Interpretable <b>Machine</b> <b>Learning</b>", "url": "https://christophm.github.io/interpretable-ml-book/shap.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-book/<b>shap</b>.html", "snippet": "9.6 <b>SHAP</b> (SHapley Additive exPlanations). This chapter is currently only available in this web version. ebook and print will follow. <b>SHAP</b> (SHapley Additive exPlanations) by Lundberg and Lee (2017) 69 is a method to explain individual predictions. <b>SHAP</b> is based on the game theoretically optimal Shapley values.. There are two reasons why <b>SHAP</b> got its own chapter and is not a subchapter of Shapley values.First, the <b>SHAP</b> authors proposed KernelSHAP, an alternative, kernel-based estimation ...", "dateLastCrawled": "2022-02-03T01:34:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(sparse feature)  is like +(fine mesh screen)", "+(sparse feature) is similar to +(fine mesh screen)", "+(sparse feature) can be thought of as +(fine mesh screen)", "+(sparse feature) can be compared to +(fine mesh screen)", "machine learning +(sparse feature AND analogy)", "machine learning +(\"sparse feature is like\")", "machine learning +(\"sparse feature is similar\")", "machine learning +(\"just as sparse feature\")", "machine learning +(\"sparse feature can be thought of as\")", "machine learning +(\"sparse feature can be compared to\")"]}