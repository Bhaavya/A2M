{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Mitigating <b>implicit bias in machine learning</b>", "url": "https://faraday.ai/blog/implicit-bias-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://faraday.ai/blog/<b>implicit</b>-<b>bias</b>-<b>machine</b>-<b>learning</b>", "snippet": "How to minimize the effects of <b>implicit bias in machine learning</b>, from data sourcing to model predictions. An algorithm contains the biases of its builder. At Faraday, we have a handful of approaches we use to minimize these effects at each level of our <b>machine</b> <b>learning</b> pipeline. Blog. \u2261 20 Oct 2020 \u2022 3 min read The weighted scale: Mitigating <b>implicit</b> <b>bias</b> in data science. An algorithm contains the biases of its builder. At Faraday, we have a handful of approaches we use to minimize ...", "dateLastCrawled": "2021-12-24T05:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bias</b> in <b>Machine</b> <b>Learning</b> Algorithms | by Foxh0und | Medium", "url": "https://foxh0und.medium.com/bias-in-machine-learning-algorithms-4d70bb1bcf15", "isFamilyFriendly": true, "displayUrl": "https://foxh0und.medium.com/<b>bias</b>-in-<b>machine</b>-<b>learning</b>-algorithms-4d70bb1bcf15", "snippet": "Broadly, <b>machine</b> <b>learning</b> algorithms learn patterns in datasets and map input data to outputs based on their model. Though the models and algorithms seem mathematical and objective, they are nevertheless susceptible to <b>implicit</b> <b>bias</b>. Some of the most pervasive biases in <b>machine</b> <b>learning</b> algorithms are often fed into a feedback loop that ...", "dateLastCrawled": "2022-01-14T14:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> Fairness: Types of <b>Bias</b> | by Svs Nagesh | Medium", "url": "https://nageshsomayajula.medium.com/machine-learning-fairness-types-of-bias-82bcf3df2d47", "isFamilyFriendly": true, "displayUrl": "https://nageshsomayajula.medium.com/<b>machine</b>-<b>learning</b>-fairness-types-of-<b>bias</b>-82bcf3df2d47", "snippet": "The most common <b>machine</b> <b>learning</b> <b>bias</b> exist in real-time data are \u2013 Reporting <b>bias</b>. 1. Publication <b>bias</b>. 2. Time lag <b>bias</b>. 3. Location <b>bias</b>. 4. Citation <b>bias</b>. 5. Language <b>bias</b>. Automation <b>bias</b>. Selection <b>bias</b>. 1.Coverage <b>bias</b>. 2. Non-response <b>bias</b>. 3.Sampling <b>bias</b>. Group attribution <b>bias</b>. 1. In-group <b>bias</b>. 2. Out-group homogeneity <b>bias</b>. <b>Implicit</b> <b>bias</b>. 1. Confirmation <b>bias</b>. 2. Experimenter\u2019s <b>bias</b>. 3. Racial <b>Bias</b>. 4. Gender <b>Bias</b>. Various other types of <b>Bias</b> \u00b7 Algorithms <b>bias</b> \u00b7 Academic ...", "dateLastCrawled": "2022-01-30T12:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Understanding Racial Bias in Machine Learning Algorithms</b> | by The ...", "url": "https://betterprogramming.pub/understanding-racial-bias-in-machine-learning-algorithms-1c5afe76f8b", "isFamilyFriendly": true, "displayUrl": "https://betterprogramming.pub/<b>understanding-racial-bias-in-machine-learning-algorithms</b>...", "snippet": "<b>Implicit</b> <b>bias</b> is pervasive in the tech industry \u2014 in hiring practices, but also in the products and technologies that well-intentioned developers create. In particular, researchers identify <b>machine</b> <b>learning</b> and artificial intelligence as technologies that suffer from <b>implicit</b> racial biases. If software development is truly \u201ceating the world ...", "dateLastCrawled": "2022-01-25T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Understanding <b>Bias</b> in <b>Machine</b> <b>Learning</b> Models - Arize AI", "url": "https://arize.com/blog/understanding-bias-in-ml-models/", "isFamilyFriendly": true, "displayUrl": "https://arize.com/blog/understanding-<b>bias</b>-in-ml-models", "snippet": "For decades, <b>bias</b> in <b>machine</b> <b>learning</b> has been recognized as a potential concern, but it remains a complex and challenging issue for <b>machine</b> <b>learning</b> researchers and engineers when deploying models into production. The COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) algorithm, which is utilized in US court systems to estimate the probability that a defendant will be a reoffender, is the most prominent example of AI <b>bias</b> and the negative implications on society ...", "dateLastCrawled": "2022-02-01T07:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Research shows AI is often biased. Here&#39;s how to make algorithms work ...", "url": "https://www.weforum.org/agenda/2021/07/ai-machine-learning-bias-discrimination/", "isFamilyFriendly": true, "displayUrl": "https://www.weforum.org/agenda/2021/07/ai-<b>machine</b>-<b>learning</b>-<b>bias</b>-discrimination", "snippet": "Ridding AI and <b>machine</b> <b>learning</b> of <b>bias</b> involves taking their many uses into consideration Image: British Medical Journal To list some of the source of fairness and non-discrimination risks in the use of artificial intelligence, these include: <b>implicit</b> <b>bias</b>, sampling <b>bias</b>, temporal <b>bias</b>, over-fitting to training data, and edge cases and outliers.", "dateLastCrawled": "2022-01-31T15:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "The story of Tay highlights an obstacle facing developers of <b>machine</b> <b>learning</b> programs: algorithmic <b>bias</b>. An AI <b>like</b> Tay, which uses <b>machine</b> <b>learning</b> to capitalize on (or \u201clearn\u201d from) statistical regularities in human-generated datasets, tends to pick up social patterns that manifest in human behavior and that are reflected in the data on which it is trained. In many of these cases, we have reason to suspect that programmers are not explicitly writing biases toward marginalized ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Measuring Bias in</b> <b>Machine Learning</b>: The <b>Statistical Bias</b> Test", "url": "https://www.datacamp.com/community/blog/measuring-bias-in-ml", "isFamilyFriendly": true, "displayUrl": "https://www.datacamp.com/community/blog/<b>measuring-bias-in</b>-ml", "snippet": "The question of <b>bias</b> in <b>machine learning</b> models has been the subject of a lot of attention in recent years. Stories of models going wrong make headlines, and humanitarian lawyers, politicians, and journalists have all contributed to the conversation about what ethics and values we want to be reflected in the models we build. While human <b>bias</b> is a thorny issue and not always easily defined, <b>bias</b> in <b>machine learning</b> is, at the end of the day, mathematical. There are many different types of ...", "dateLastCrawled": "2022-01-29T07:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Analyzing &amp; <b>Preventing Unconscious Bias in Machine Learning</b>", "url": "https://www.infoq.com/presentations/unconscious-bias-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.infoq.com/presentations/unconscious-<b>bias</b>-<b>machine</b>-<b>learning</b>", "snippet": "So, one is that <b>machine</b> <b>learning</b> can actually amplify <b>bias</b>. There is an interesting paper called &quot;Men also <b>like</b> shopping&quot; where they looked at a dataset. These are kind commonly site datasets ...", "dateLastCrawled": "2022-02-03T03:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Mitigating <b>Bias</b> in <b>Machine Learning</b>: An introduction to ...", "url": "https://towardsdatascience.com/mitigating-bias-in-machine-learning-an-introduction-to-mlfairnesspipeline-42e007dce0a5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/mitigating-<b>bias</b>-in-<b>machine-learning</b>-an-introduction-to...", "snippet": "<b>Bias</b> in <b>Machine Learning</b>. <b>Bias</b> takes many different forms and impact all groups of people. It can range from <b>implicit</b> to expli c it and is often very difficult to detect. In the field of <b>machine learning</b> <b>bias</b> is often subtle and hard to identify, let alone solve. Why is this a problem? <b>Implicit</b> <b>bias</b> in <b>machine learning</b> has very real consequences including denial of a loan, a lengthier prison sentence, and many other harmful outcomes for underprivileged groups. The data scientists designing ...", "dateLastCrawled": "2022-02-02T01:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Biases in <b>machine</b> <b>learning</b> models and big data analytics: The ...", "url": "http://international-review.icrc.org/articles/biases-machine-learning-big-data-analytics-ihl-implications-913", "isFamilyFriendly": true, "displayUrl": "international-review.icrc.org/articles/<b>bias</b>es-<b>machine</b>-<b>learning</b>-big-data-analytics-ihl...", "snippet": "A common <b>implicit</b> <b>bias</b> is confirmation <b>bias</b>, where individuals or model builders unconsciously process data in ways that affirm pre-existing beliefs and hypotheses.25 Within the context of international investigations, confirmation <b>bias</b> can cause investigators or prosecutors to miss the exculpatory quality of evidence or to discount its value, which can lead to a failure to disclose or collect that data.26 Similarly, in the pressurized theatre of war, confirmation <b>bias</b> can cause combatants ...", "dateLastCrawled": "2022-02-01T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "Often <b>machine</b> <b>learning</b> programs inherit social patterns reflected in their training data without any directed effort by programmers to include such biases. Computer scientists call this algorithmic <b>bias</b>. This paper explores the relationship between <b>machine</b> <b>bias</b> and human cognitive <b>bias</b>. In it, I argue similarities between algorithmic and cognitive biases indicate a disconcerting sense in which sources of <b>bias</b> emerge out of seemingly innocuous patterns of information processing. The emergent ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Understanding Racial Bias in Machine Learning Algorithms</b> | by The ...", "url": "https://betterprogramming.pub/understanding-racial-bias-in-machine-learning-algorithms-1c5afe76f8b", "isFamilyFriendly": true, "displayUrl": "https://betterprogramming.pub/<b>understanding-racial-bias-in-machine-learning-algorithms</b>...", "snippet": "<b>Implicit</b> <b>bias</b> is pervasive in the tech industry \u2014 in hiring practices, but also in the products and technologies that well-intentioned developers create. In particular, researchers identify <b>machine</b> <b>learning</b> and artificial intelligence as technologies that suffer from <b>implicit</b> racial biases. If software development is truly \u201ceating the world ...", "dateLastCrawled": "2022-01-25T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bias and Fairness in Machine Learning</b> - Abhishek Tiwari", "url": "https://www.abhishek-tiwari.com/bias-and-fairness-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.abhishek-tiwari.com/<b>bias-and-fairness-in-machine-learning</b>", "snippet": "In AI and <b>machine</b> <b>learning</b>, the future resembles the past and <b>bias</b> refers to prior information. There has been a growing interest in identifying the harmful biases in the <b>machine</b> <b>learning</b>. Often these harmful biases are just the reflection or amplification of human biases which algorithms learn from training data. Some training data sets such as text, medical, criminal, educational, financial etc. are more susceptible to human biases compared to others. For example, weather data is little or ...", "dateLastCrawled": "2022-01-29T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Potential Biases in <b>Machine</b> <b>Learning</b> Algorithms Using Electronic Health ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6347576/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6347576", "snippet": "<b>Machine</b> <b>learning</b> hasgen-erated substantial advances in medical imaging, for example, through improved detection of colonic polyps, cerebral microbleeding, and diabetic retinopathy. 2 Predictive modelingwith electronic health records usingdeep <b>learning</b> can accurately predict in-hospital mortality, 30-day unplanned readmission, prolonged length of stay, and final discharge diagnoses.3 Integration of <b>machine</b> <b>learning</b> with clinical decision support tools, such as computerized alerts or ...", "dateLastCrawled": "2022-01-27T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>The Implicit Bias Challenge</b> - JobSync", "url": "https://www.jobsync.io/the-implicit-bias-challenge/", "isFamilyFriendly": true, "displayUrl": "https://www.jobsync.io/<b>the-implicit-bias-challenge</b>", "snippet": "Sexism, racism and other unrecognized biases can be built into <b>machine</b>-<b>learning</b> algorithms underlying the intelligence and shape the way people are categorized and addressed. This risks perpetuating an already vicious cycle of <b>bias</b>\u2026The truth is that most of the programming and data analytics are being created globally by white males\u2026has shown that women are less likely than men to be shown ads on Google for executive jobs\u2026these algorithmic flaws are not easy to detect. Ingrained <b>bias</b> ...", "dateLastCrawled": "2022-01-25T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The <b>Implicit Bias of Gradient Descent</b> on Separable Data", "url": "https://jmlr.csail.mit.edu/papers/volume19/18-188/18-188.pdf", "isFamilyFriendly": true, "displayUrl": "https://jmlr.csail.mit.edu/papers/volume19/18-188/18-188.pdf", "snippet": "Journal of <b>Machine</b> <b>Learning</b> Research 19 (2018) 1-57 Submitted 4/18; Published 11/18 The <b>Implicit Bias of Gradient Descent</b> on Separable Data Daniel Soudry DANIEL.SOUDRY@GMAIL COM Elad Hoffer ELAD.HOFFER@GMAIL COM Mor Shpigel Nacson MOR.SHPIGEL@GMAIL COM Department of Electrical Engineering,Technion Haifa, 320003, Israel Suriya Gunasekar SURIYA@TTIC.EDU Nathan Srebro NATI@TTIC.EDU Toyota Technological Institute at Chicago Chicago, Illinois 60637, USA Editor: Leon Bottou Abstract We examine ...", "dateLastCrawled": "2022-01-30T18:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Discussion Questions About <b>Implicit</b> <b>Bias</b> and <b>Similar</b> Products and ...", "url": "https://www.listalternatives.com/discussion-questions-about-implicit-bias", "isFamilyFriendly": true, "displayUrl": "https://www.listalternatives.com/discussion-questions-about-<b>implicit</b>-<b>bias</b>", "snippet": "<b>Implicit</b> <b>Bias</b> <b>Implicit</b> <b>bias</b> exists when people unconsciously hold attitudes toward others or associate stereotypes with them. Discussion Questions 1. In a presentation, Professor Will Cox shows two news photos published in the wake of Hurricane Katrina. One shows a young black man walking through swirling water holding a carton of soda.", "dateLastCrawled": "2022-02-03T07:01:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Artificial Intelligence Has An <b>Implicit</b> <b>Bias</b> Diversity Dilemma", "url": "https://carpenterwellington.com/post/artificial-intelligence-implicit-bias-diversity-dilemma/", "isFamilyFriendly": true, "displayUrl": "https://carpenterwellington.com/post/artificial-intelligence-<b>implicit</b>-<b>bias</b>-diversity...", "snippet": "Growing Concern About <b>Implicit</b> <b>Bias</b>. There is growing concern about <b>implicit</b> biases built into artificial intelligence systems. These biases could lead to unfair outcomes. The foundation of these systems is the data inputs and the people behind designing the technology. If the <b>implicit</b> biases of the people building the technology skew the data, that will carry forward to skewed outputs. After all, <b>machine</b> <b>learning</b> algorithms are limited to the data sets available to them. Few Women, Fewer ...", "dateLastCrawled": "2022-01-26T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>The Implicit Bias Challenge</b> - JobSync", "url": "https://www.jobsync.io/the-implicit-bias-challenge/", "isFamilyFriendly": true, "displayUrl": "https://www.jobsync.io/<b>the-implicit-bias-challenge</b>", "snippet": "Sexism, racism and other unrecognized biases <b>can</b> be built into <b>machine</b>-<b>learning</b> algorithms underlying the intelligence and shape the way people are categorized and addressed. This risks perpetuating an already vicious cycle of <b>bias</b>\u2026The truth is that most of the programming and data analytics are being created globally by white males\u2026has shown that women are less likely than men to be shown ads on Google for executive jobs\u2026these algorithmic flaws are not easy to detect. Ingrained <b>bias</b> ...", "dateLastCrawled": "2022-01-25T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bias and discrimination in machine learning</b> \u00b7 Merlin Rebrovi\u0107", "url": "https://merlin.rebrovic.net/blog/ml-bias", "isFamilyFriendly": true, "displayUrl": "https://merlin.rebrovic.net/blog/ml-<b>bias</b>", "snippet": "A man\u2019s visa application was rejected in New Zealand because the <b>machine</b> <b>thought</b> his eyes were closed on his photo. ... and held an <b>implicit</b> <b>bias</b> against those who were not in that population. The fix for this, and for the more general problem of <b>bias and discrimination in machine learning</b>, is hard for many reasons: People don\u2019t realize they aren\u2019t inclusive. It\u2019s easy to recognize a movie star in the latest blockbuster. In contrast, it\u2019s hard to notice that a small-time actor, who ...", "dateLastCrawled": "2021-12-28T23:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Analyzing &amp; <b>Preventing Unconscious Bias in Machine Learning</b>", "url": "https://www.infoq.com/presentations/unconscious-bias-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.infoq.com/presentations/unconscious-<b>bias</b>-<b>machine</b>-<b>learning</b>", "snippet": "So, one is that <b>machine</b> <b>learning</b> <b>can</b> actually amplify <b>bias</b>. There is an interesting paper called &quot;Men also like shopping&quot; where they looked at a dataset. These are kind commonly site datasets ...", "dateLastCrawled": "2022-02-03T03:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "News and Media <b>Bias</b> Detection using <b>Machine Learning</b> | by Jerry Wei ...", "url": "https://towardsdatascience.com/news-and-media-bias-detection-using-machine-learning-a-potential-way-to-find-fake-news-13c766aa3988", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/news-and-media-<b>bias</b>-detection-using-<b>machine-learning</b>-a...", "snippet": "<b>Machine learning</b> has recently seen a huge increase because of a rise in both available data and computational power. Researchers have also been working to make even more complex neural networks with more and more layers (deep <b>learning</b>), which allows them to solve even harder problems. <b>Machine learning</b> itself has a bunch of applications in almost every field imaginable; recent advances in <b>machine learning</b> include self-driving cars, language translation, and facial recognition. I previously ...", "dateLastCrawled": "2022-01-20T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Implicit Bias: Sharing Our Stories</b> \u2013 Ensemble <b>Learning</b>", "url": "https://ensemblelearning.org/implicit-bias-sharing-our-stories/", "isFamilyFriendly": true, "displayUrl": "https://ensemble<b>learning</b>.org/<b>implicit-bias-sharing-our-stories</b>", "snippet": "If you want to think more about your own <b>implicit</b> biases, it <b>can</b> be helpful to start with a test that measures them. We like the Harvard Project <b>Implicit</b> tests (bonus: your data is used to anonymously power Harvard\u2019s research!). If you or your staff are interested in Ensemble <b>Learning</b>\u2019s tools to identify, measure, and combat <b>implicit</b> <b>bias</b>, reach out to Dr. Leigh Mingle at lmingle@ensemblelearning.org for more information.", "dateLastCrawled": "2022-02-02T05:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Social Bias in Machine Learning</b> | <b>Machine</b> <b>Learning</b> Medium", "url": "https://machinelearningmedium.com/2018/10/09/algorithmic-fairness/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>medium.com/2018/10/09/algorithmic-fairness", "snippet": "Recently <b>machine</b> <b>learning</b> has seen its utilitization in a lot of important decision making pipelines such as predicting time of recidivism, college acceptance, loan approvals etc., and hence it becomes increasingly important to question the <b>machine</b> <b>learning</b> models being developed in terms of <b>implicit</b> <b>bias</b> that they might be inheriting from the data that they train on. In order to do away with such biases in a <b>machine</b> <b>learning</b> algorithm one needs to understand how exactly does <b>bias</b> creep in ...", "dateLastCrawled": "2021-12-28T06:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Survivorship bias</b> in Data Science and <b>Machine</b> <b>Learning</b> | by Gonzalo ...", "url": "https://towardsdatascience.com/survivorship-bias-in-data-science-and-machine-learning-4581419b3bca", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>survivorship-bias</b>-in-data-science-and-<b>machine</b>-<b>learning</b>...", "snippet": "Fraud prevention: <b>survivorship bias</b> within the data science, <b>machine</b> <b>learning</b> and artificial intelligence world for fraud prevention <b>can</b> be also very dangerous. Usually, our clients at Ravelin come to us already using some kind of solution for fraud prevention. Whether it is a rules system, manual reviews of customers or other. Imagine if for building our clients\u2019 <b>machine</b> <b>learning</b> model we would take only those fraudsters that got through the client previous solution. We would be using ...", "dateLastCrawled": "2022-01-28T15:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Frontiers | Addressing Fairness, <b>Bias</b>, and Appropriate Use of ...", "url": "https://www.frontiersin.org/articles/10.3389/frai.2020.561802/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/frai.2020.561802", "snippet": "While the <b>bias</b> found in other application domains of <b>machine</b> <b>learning</b> (finance, employment, law enforcement, etc.) may often be due to sampling <b>bias</b> or <b>implicit</b> cultural <b>bias</b>, the domain of health also contains true systematic <b>bias</b> inherent in biological processes which may not be possible to mitigate or \u201crepair.\u201d In the domain of health, there are true genetic differences across different races and ethnic groups which affect disease prevalence, and these differences cannot (and should ...", "dateLastCrawled": "2022-01-29T07:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "We all have <b>implicit</b> biases. So what <b>can</b> we do about it? | Dushaw ...", "url": "https://www.vexplode.com/en/tedx/we-all-have-implicit-biases-so-what-can-we-do-about-it-dushaw-hockett-tedxmidatlanticsalon/", "isFamilyFriendly": true, "displayUrl": "https://www.vexplode.com/en/tedx/we-all-have-<b>implicit</b>-<b>bias</b>es-so-what-<b>can</b>-we-do-about...", "snippet": "science of <b>implicit</b> <b>bias</b> says that you <b>can</b> be a school administrator and say that you are deeply committed to nurturing and building up young people and yet be the same school administrator who leads your school and high rates of suspensions and expulsions of young people and both of those things would be true consciously you\u2019re deeply committed to building young people up unconsciously you\u2019re doing harm in the process the science of them quizzes by says that you <b>can</b> be a law enforcement ...", "dateLastCrawled": "2022-02-03T06:01:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans <b>can</b> be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans <b>can</b> introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we <b>can</b> detect <b>bias</b> in <b>machine learning</b> models and how it <b>can</b> be eliminated. Types of <b>bias</b> . <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools from many of the leaders in <b>machine learning</b> development. Detecting <b>bias</b> starts with the data set. A data set might not represent the problem space ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Mitigating <b>Bias</b> in <b>Machine Learning</b>: An introduction to ...", "url": "https://towardsdatascience.com/mitigating-bias-in-machine-learning-an-introduction-to-mlfairnesspipeline-42e007dce0a5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/mitigating-<b>bias</b>-in-<b>machine-learning</b>-an-introduction-to...", "snippet": "<b>Bias</b> in <b>Machine Learning</b>. <b>Bias</b> takes many different forms and impact all groups of people. It <b>can</b> range from <b>implicit</b> to expli c it and is often very difficult to detect. In the field of <b>machine learning</b> <b>bias</b> is often subtle and hard to identify, let alone solve. Why is this a problem? <b>Implicit</b> <b>bias</b> in <b>machine learning</b> has very real consequences including denial of a loan, a lengthier prison sentence, and many other harmful outcomes for underprivileged groups. The data scientists designing ...", "dateLastCrawled": "2022-02-02T01:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bias and Fairness in Machine Learning</b> - Abhishek Tiwari", "url": "https://www.abhishek-tiwari.com/bias-and-fairness-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.abhishek-tiwari.com/<b>bias-and-fairness-in-machine-learning</b>", "snippet": "In AI and <b>machine</b> <b>learning</b>, the future resembles the past and <b>bias</b> refers to prior information. There has been a growing interest in identifying the harmful biases in the <b>machine</b> <b>learning</b>. Often these harmful biases are just the reflection or amplification of human biases which algorithms learn from training data. Some training data sets such as text, medical, criminal, educational, financial etc. are more susceptible to human biases <b>compared</b> to others. For example, weather data is little or ...", "dateLastCrawled": "2022-01-29T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bias</b> and Fairness in Multimodal <b>Machine</b> <b>Learning</b>: A Case Study of ...", "url": "https://dl.acm.org/doi/pdf/10.1145/3462244.3479897", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/pdf/10.1145/3462244.3479897", "snippet": "<b>Bias</b> and fairness in <b>machine</b> <b>learning</b> are not simply a byprod-uct of the representativeness or correspondence of a data set to its target population. <b>Bias</b> and unfairness emerge as a result of human decisions made throughout the model development process. The data-driven approach of throwing all available predictors into a 268. ICMI \u201921, October 18\u201322, 2021, Montr\u00e9al, QC, Canada Booth, et al. model and seeing what sticks is useful for maximizing accuracy, but if the most useful ...", "dateLastCrawled": "2022-01-05T02:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Potential Biases in <b>Machine</b> <b>Learning</b> Algorithms Using Electronic Health ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6347576/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6347576", "snippet": "<b>Machine</b> <b>learning</b> hasgen-erated substantial advances in medical imaging, for example, through improved detection of colonic polyps, cerebral microbleeding, and diabetic retinopathy. 2 Predictive modelingwith electronic health records usingdeep <b>learning</b> <b>can</b> accurately predict in-hospital mortality, 30-day unplanned readmission, prolonged length of stay, and final discharge diagnoses.3 Integration of <b>machine</b> <b>learning</b> with clinical decision support tools, such as computerized alerts or ...", "dateLastCrawled": "2022-01-27T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>What is unconscious bias</b>? How does it affect you?", "url": "https://caseguard.com/articles/what-is-unconscious-bias/", "isFamilyFriendly": true, "displayUrl": "https://caseguard.com/articles/<b>what-is-unconscious-bias</b>", "snippet": "The first step to combating unconscious <b>bias</b> in <b>machine</b> <b>learning</b> is identify what <b>bias</b> in the data is being fed <b>to machine</b> <b>learning</b>. The algorithms that <b>machine</b> <b>learning</b> is predicated upon <b>can</b> only function based on the data being given. If a data set has inherently marginalized a certain demographic of people, that will obviously be made apparent through <b>machine</b> <b>learning</b> as well. Another angle is to analyze the processes designed to catch unconscious <b>bias</b> present in <b>machine</b> <b>learning</b> and ...", "dateLastCrawled": "2022-01-30T06:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Artificial Intelligence Has An <b>Implicit</b> <b>Bias</b> Diversity Dilemma", "url": "https://carpenterwellington.com/post/artificial-intelligence-implicit-bias-diversity-dilemma/", "isFamilyFriendly": true, "displayUrl": "https://carpenterwellington.com/post/artificial-intelligence-<b>implicit</b>-<b>bias</b>-diversity...", "snippet": "Growing Concern About <b>Implicit</b> <b>Bias</b>. There is growing concern about <b>implicit</b> biases built into artificial intelligence systems. These biases could lead to unfair outcomes. The foundation of these systems is the data inputs and the people behind designing the technology. If the <b>implicit</b> biases of the people building the technology skew the data, that will carry forward to skewed outputs. After all, <b>machine</b> <b>learning</b> algorithms are limited to the data sets available to them. Few Women, Fewer ...", "dateLastCrawled": "2022-01-26T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Measuring Bias in</b> <b>Machine Learning</b>: The <b>Statistical Bias</b> Test", "url": "https://www.datacamp.com/community/blog/measuring-bias-in-ml", "isFamilyFriendly": true, "displayUrl": "https://www.datacamp.com/community/blog/<b>measuring-bias-in</b>-ml", "snippet": "The question of <b>bias</b> in <b>machine learning</b> models has been the subject of a lot of attention in recent years. Stories of models going wrong make headlines, and humanitarian lawyers, politicians, and journalists have all contributed to the conversation about what ethics and values we want to be reflected in the models we build. While human <b>bias</b> is a thorny issue and not always easily defined, <b>bias</b> in <b>machine learning</b> is, at the end of the day, mathematical. There are many different types of ...", "dateLastCrawled": "2022-01-29T07:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to Fix <b>Bias in Machine Learning Algorithms</b>? - Yields.io", "url": "https://www.yields.io/blog/how-to-fix-bias-in-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.yields.io/blog/how-to-fix-<b>bias-in-machine-learning-algorithms</b>", "snippet": "Pre-existing <b>bias</b> in algorithms is a consequence of underlying social and institutional ideologies, which <b>can</b> have an impact on the designers or programmers of the software \u2013 human <b>bias</b> in <b>machine</b> <b>learning</b>. These preconceptions <b>can</b> be explicit and conscious, or <b>implicit</b> and unconscious. In general, <b>bias</b> <b>can</b> appear in algorithms through both the modeling approach but also through the use of poor data, or data from a biased source.", "dateLastCrawled": "2022-01-25T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Human <b>Bias</b> in <b>Machine Learning</b>. A brief exploration on the impacts that ...", "url": "https://towardsdatascience.com/bias-what-it-means-in-the-big-data-world-6e64893e92a1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bias</b>-what-it-means-in-the-big-data-world-6e64893e92a1", "snippet": "The classic example used to describe this <b>bias</b> is a <b>machine learning</b> model that\u2019s designed to differentiate between men and women in pictures. The training data contains more pictures of women in kitchens than men in kitchens, or more pictures of men coding than women, then the algorithm is trained to make incorrect inferences about the gender of people engaged in those activities due to prejudices that occur in the real world, represented in the data. Sentiment Analysis is the use of ...", "dateLastCrawled": "2022-02-02T02:18:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Implicit/Machine learning gender bias</b> | ReberLab", "url": "https://www.reberlab.psych.northwestern.edu/2018/10/11/implicitmachine-learning-gender-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.reberlab.psych.northwestern.edu/.../10/11/<b>implicitmachine-learning-gender-bias</b>", "snippet": "First, I have found myself describing on a few recent occasions that it is reasonable to think of <b>implicit</b> <b>learning</b> (IL) as the brain\u2019s <b>machine</b> <b>learning</b> (ML) algorithm. ML is a super-hot topic in AI and data science research, so this might be a useful <b>analogy</b> to help people understand what we mean by studying IL. We characterize IL as the statistical extraction of patterns in the environment and the shaping of cognitive processing to maximize efficiency and effectiveness to these patterns ...", "dateLastCrawled": "2020-11-16T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "Confirmation <b>bias</b> is a form of <b>implicit</b> <b>bias</b>. ... addition and subtraction of embeddings can solve word <b>analogy</b> tasks. The dot product of two embeddings is a measure of their similarity. empirical risk minimization (ERM) Choosing the function that minimizes loss on the training set. Contrast with structural risk minimization. encoder . #language. In general, any ML system that converts from a raw, sparse, or external representation into a more processed, denser, or more internal ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "Often <b>machine</b> <b>learning</b> programs inherit social patterns reflected in their training data without any directed effort by programmers to include such biases. Computer scientists call this algorithmic <b>bias</b>. This paper explores the relationship between <b>machine</b> <b>bias</b> and human cognitive <b>bias</b>. In it, I argue similarities between algorithmic and cognitive biases indicate a disconcerting sense in which sources of <b>bias</b> emerge out of seemingly innocuous patterns of information processing. The emergent ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Harnessing data for unbiased <b>Learning</b> of Machines | by Vivek Gupta | Medium", "url": "https://gvivek.medium.com/harnessing-data-for-unbiased-learning-of-machines-dc614497a29c", "isFamilyFriendly": true, "displayUrl": "https://gvivek.medium.com/harnessing-data-for-un<b>bias</b>ed-<b>learning</b>-of-<b>machines</b>-dc614497a29c", "snippet": "In <b>Machine</b> <b>Learning</b>, the input data reflects stereotypes and biases of the broader society, then the output of the <b>learning</b> algorithm also captures these stereotypes. Here, we will discuss the gender stereotypes in word embedding. word-embedding encode semantic information, they also exhibit hidden biases inherent in the dataset they are trained on associations such as: father:doctor :: mother:nurse. man:computer programmer :: woman:homemaker. The prejudices and stereotypes in these ...", "dateLastCrawled": "2022-01-12T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning</b> | Gendered Innovations", "url": "http://genderedinnovations.stanford.edu/case-studies/machinelearning.html", "isFamilyFriendly": true, "displayUrl": "genderedinnovations.stanford.edu/case-studies/<b>machinelearning</b>.html", "snippet": "As <b>machine learning</b> becomes increasingly ubiquitous in everyday lives, such <b>bias</b>, if uncorrected, can lead to social inequities. Researchers need to understand how gender and ethnicity operate within the context of their algorithm in order to enhance or, at least, not reinforce social equalities. Here we suggest avenues for reducing <b>bias</b> in training data and algorithms in efforts to produce AI that enhances social equalities.", "dateLastCrawled": "2022-01-25T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word ...", "url": "https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf", "snippet": "signi\ufb01cant risk and challenge for <b>machine</b> <b>learning</b> and its applications. The analogies generated from these embeddings spell out the <b>bias</b> <b>implicit</b> in the data on which they were trained. Hence, word embeddings may serve as a means to extract <b>implicit</b> gender associations from a large text corpus", "dateLastCrawled": "2022-02-02T05:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fairness Metrics - Data Analytics - Data Science, <b>Machine</b> <b>Learning</b>, AI", "url": "https://vitalflux.com/fairness-metrics-ml-model-sensitivity-bias-detection/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>fairness-metrics-ml-model-sensitivity</b>-<b>bias</b>-detection", "snippet": "There are many different ways in which <b>machine</b> <b>learning</b> ... Instinctively (based on <b>implicit</b> human <b>bias</b>), it is one of the specific \u201cgender\u201d (male or female) against which the model could get biased as like in the real world in predicting whether those with a specific gender could re-offend or not. Thus, one of the protected attributes becomes gender. For the current example, in the real world, one could get biased in favor of female and not (or fail to) classify them as the ones who ...", "dateLastCrawled": "2022-01-20T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning is Requirements Engineering</b> \u2014 On the Role of Bugs ...", "url": "https://medium.com/analytics-vidhya/machine-learning-is-requirements-engineering-8957aee55ef4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>machine-learning-is-requirements-engineering</b>-8957...", "snippet": "A <b>machine</b>-learned model is not an attempt at implementing an <b>implicit</b> specification; a <b>machine</b>-learned model is a specification! It is a learned description of how the system shall behave. The ...", "dateLastCrawled": "2022-01-19T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Man is to Computer Programmer as Woman is</b> to Homemaker? | by Sheldon ...", "url": "https://towardsdatascience.com/man-is-to-computer-programmer-as-woman-is-to-homemaker-e57b07cbde96", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>man-is-to-computer-programmer-as-woman-is</b>-to-homemaker...", "snippet": "The paper discusses gender <b>bias</b> in <b>machine</b> <b>learning</b> as a result of using biased training data and proposes a solution to debias the model. This article contains an overview of the paper and discusses key findings in the python implementation of the paper. Overview. The authors of the paper used Word Embe d ding Model to demonstrate gender <b>bias</b> in the training data. The Word Embedding Model was trained on Google News articles and the vector representation of all words were stored in the ...", "dateLastCrawled": "2022-01-30T22:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "CSWA: <b>Unconscious Bias</b> | American Astronomical Society", "url": "https://aas.org/comms/cswa/resources/unconsciousbias", "isFamilyFriendly": true, "displayUrl": "https://aas.org/comms/cswa/resources/<b>unconsciousbias</b>", "snippet": "The intervention is based on the premise that <b>implicit bias is like</b> a habit that can be broken through a combination of awareness of implicit bias, concern about the effects of that bias, and the application of strategies to reduce bias. In a 12-week longitudinal study, people who received the intervention showed dramatic reductions in implicit race bias. People who were concerned about discrimination or who reported using the strategies showed the greatest reductions. The intervention also ...", "dateLastCrawled": "2022-02-03T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Patrick Forscher</b> \u2013 Research Lead \u2013 Busara Center for Behavioral ...", "url": "https://ch.linkedin.com/in/patrick-forscher-91163854", "isFamilyFriendly": true, "displayUrl": "https://ch.linkedin.com/in/<b>patrick-forscher</b>-91163854", "snippet": "The intervention is based on the premise that <b>implicit bias is like</b> a habit that can be broken through a combination of awareness of implicit bias, concern about the effects of that bias, and the application of strategies to reduce bias. In a 12-week longitudinal study, people who received the intervention showed dramatic reductions in implicit race bias. People who were\u2026 We developed a multi-faceted prejudice habit-breaking intervention to produce long-term reductions in implicit race ...", "dateLastCrawled": "2022-02-03T15:10:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Those designing healthcare algorithms must become actively</b> anti-racist ...", "url": "https://www.nature.com/articles/s41591-020-1020-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41591-020-1020-3", "snippet": "<b>Just as \u2018implicit bias</b>\u2019 training for police does little to change racist behavior 10 \u2014in large part because departmental cultures do not fully support the lessons of anti-racism\u2014healthcare ...", "dateLastCrawled": "2021-11-15T00:12:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(implicit bias)  is like +(machine learning)", "+(implicit bias) is similar to +(machine learning)", "+(implicit bias) can be thought of as +(machine learning)", "+(implicit bias) can be compared to +(machine learning)", "machine learning +(implicit bias AND analogy)", "machine learning +(\"implicit bias is like\")", "machine learning +(\"implicit bias is similar\")", "machine learning +(\"just as implicit bias\")", "machine learning +(\"implicit bias can be thought of as\")", "machine learning +(\"implicit bias can be compared to\")"]}