{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Empirical <b>risk</b> <b>minimization</b> The VC dimension <b>Structural</b> <b>Risk</b> ...", "url": "https://people.engr.tamu.edu/rgutier/lectures/pr/pr_l21.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.engr.tamu.edu/rgutier/lectures/pr/pr_l21.pdf", "snippet": "\u2022 <b>Structural</b> <b>Risk</b> <b>Minimization</b> \u2013Another formal term for an intuitive concept: the optimal model is found by striking a balance between the empirical <b>risk</b> and the VC dimension \u2022 The <b>SRM</b> principle proceeds as follows \u2013Construct a nested structure for family of function classes \ud835\udc391\u2282\ud835\udc392\u2282 \u22ef\ud835\udc39 with non-decreasing VC dimensions (\u210e1", "dateLastCrawled": "2021-12-12T19:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Model Selection in Machine Learning | by ANUSHKA BAJPAI | Medium", "url": "https://medium.com/@anushkhabajpai/model-selection-in-machine-learning-c568e5a42dcc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@anushkhabajpai/model-selection-in-machine-learning-c568e5a42dcc", "snippet": "<b>Structural</b> <b>Risk</b> <b>Minimization</b> (<b>SRM</b>) Machine learning models face the inevitable problem of defining a generalized theory from a set of finite data. This leads to cases of overfitting where the ...", "dateLastCrawled": "2022-01-29T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Fast minimization of structural risk by nearest neighbor</b> rule ...", "url": "https://www.academia.edu/10949188/Fast_minimization_of_structural_risk_by_nearest_neighbor_rule", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/10949188/<b>Fast_minimization_of_structural_risk_by</b>_nearest...", "snippet": "In addition to the computational cost, a natural question often T HE <b>STRUCTURAL</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) principle [1]\u2013[3] is a technique for nonparametric inference which has found application in classification and estimation problems. arises, namely that of selecting a convenient nonlinear space in which to construct the linear discriminant. It is essentially based on an empirical <b>risk</b> <b>minimization</b> (ERM) Toward improving the computational complexity in the principle, in an effort to ...", "dateLastCrawled": "2022-01-18T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Rademacher penalties and <b>structural</b> <b>risk</b> <b>minimization</b>", "url": "https://www.researchgate.net/publication/3080443_Rademacher_penalties_and_structural_risk_minimization", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3080443_Rademacher_penalties_and_<b>structural</b>...", "snippet": "Abstract. We suggest a penalty function to be used in various problems of <b>structural</b> <b>risk</b> <b>minimization</b>. This penalty is data dependent and is based on the sup-norm of the so-called Rademacher ...", "dateLastCrawled": "2022-01-29T07:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Support Vector Machine Implementations for Classification &amp; Clustering", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1683575/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC1683575", "snippet": "SVMs are variational-calculus based methods that are constrained to have <b>structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>), i.e., they provide noise tolerant solutions for pattern recognition. The SVM approach encapsulates a significant amount of model-fitting information in the choice of its kernel. In work thus far, novel, information-theoretic, kernels have been successfully employed for notably better performance over standard kernels. Currently there are two approaches for implementing multiclass SVMs ...", "dateLastCrawled": "2021-11-29T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Off-line structural risk minimization and BARTMAP</b>-S | Request PDF", "url": "https://www.researchgate.net/publication/3950214_Off-line_structural_risk_minimization_and_BARTMAP-S", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3950214_<b>Off-line_structural_risk_minimization</b>...", "snippet": "According to [28] there are four steps to implement the <b>structural</b> <b>risk</b> <b>minimization</b> (see section <b>Structural</b> <b>risk</b> <b>minimization</b>), of which the first step is to choose a class of functions with ...", "dateLastCrawled": "2021-12-17T19:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Model selection.pdf - CS-E4710 Machine Learning Supervised Methods ...", "url": "https://www.coursehero.com/file/123571062/Model-selectionpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/123571062/Model-selectionpdf", "snippet": "<b>SRM</b> model selection: pros and cons \u2022 <b>Structural</b> <b>risk</b> <b>minimization</b> benefits from strong learning guarantees \u2022 However, the assumption of a countable decomposition of the hypothesis class is a restrictive one \u2022 The computational price to pay is large, especially when a large number of hypothesis classes H k has to be processed 17", "dateLastCrawled": "2022-01-22T21:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Overfittingand Model Selection</b>", "url": "https://www.cs.cmu.edu/~epxing/Class/10701/slides/lecture10-fit.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~epxing/Class/10701/slides/lecture10-fit.pdf", "snippet": "Generalization Theory and <b>Structural</b> <b>Risk</b> <b>Minimization</b> The battle against overfitting: each learning algorithm has some &quot;free knobs&quot; that one can &quot;tune&quot; (i.e., heck) to make the algorithm generalizes better to test data. But is there a more principled way? Cross validation Regularization Feature selection", "dateLastCrawled": "2022-02-03T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Model complexity control for hydrologic prediction - Schoups - 2008 ...", "url": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2008WR006836", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2008WR006836", "snippet": "A comparison of various model complexity control methods shows that <b>structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) is preferable to other methods, as it consistently identifies parsimonious models with unique parameters, even in cases where the assumption of data independence is violated. Methods developed for application with large data sets, such as AIC, tend to select models that are too complex, and which suffer from parameter equifinality. Cross validation is computationally intensive and sensitive ...", "dateLastCrawled": "2022-01-08T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Non_Uniform_MDL - Chapter 1 Minimum Description Length The notions of ...", "url": "https://www.coursehero.com/file/7857156/Non-Uniform-MDL/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/7857156/Non-Uniform-MDL", "snippet": "12 Minimum Description Length 1.4 <b>Structural</b> <b>Risk</b> <b>Minimization</b> - a generic non-uniform learner The next issue we would <b>like</b> to address is the scope of non-uniformly learnable classes. The following theorem generalizes our previous learnability result, from countable classes to classes that are countable unions of PAC-learnable classes. Theorem 4. If a class of models H is a countable union of classes, {H n} n 2 N, so that each of these classes has the uniform convergence property, then H is ...", "dateLastCrawled": "2022-01-09T20:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Risk Minimization</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/risk-minimization", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>risk-minimization</b>", "snippet": "3.1 <b>Structural</b> <b>Risk Minimization</b>. The basic idea of <b>structural</b> <b>risk minimization</b> is to estimate an upper bound of the expected <b>risk</b>, E [ L ( y, z ( \u03b8 y)], in terms of the observable empirical <b>risk</b>, L e m p ( y, z ( \u03b8 y)), given data sample y and a confidence interval, the value of which depends on a measure of model complexity and sample size, n.", "dateLastCrawled": "2022-01-25T07:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Fast minimization of structural risk by nearest neighbor</b> rule ...", "url": "https://www.academia.edu/10949188/Fast_minimization_of_structural_risk_by_nearest_neighbor_rule", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/10949188/<b>Fast_minimization_of_structural_risk_by</b>_nearest...", "snippet": "In addition to the computational cost, a natural question often T HE <b>STRUCTURAL</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) principle [1]\u2013[3] is a technique for nonparametric inference which has found application in classification and estimation problems. arises, namely that of selecting a convenient nonlinear space in which to construct the linear discriminant. It is essentially based on an empirical <b>risk</b> <b>minimization</b> (ERM) Toward improving the computational complexity in the principle, in an effort to ...", "dateLastCrawled": "2022-01-18T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Model Selection in Machine Learning | by ANUSHKA BAJPAI | Medium", "url": "https://medium.com/@anushkhabajpai/model-selection-in-machine-learning-c568e5a42dcc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@anushkhabajpai/model-selection-in-machine-learning-c568e5a42dcc", "snippet": "<b>Structural</b> <b>Risk</b> <b>Minimization</b> (<b>SRM</b>) Machine learning models face the inevitable problem of defining a generalized theory from a set of finite data. This leads to cases of overfitting where the ...", "dateLastCrawled": "2022-01-29T03:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Rademacher penalties and <b>structural</b> <b>risk</b> <b>minimization</b>", "url": "https://www.researchgate.net/publication/3080443_Rademacher_penalties_and_structural_risk_minimization", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3080443_Rademacher_penalties_and_<b>structural</b>...", "snippet": "Abstract. We suggest a penalty function to be used in various problems of <b>structural</b> <b>risk</b> <b>minimization</b>. This penalty is data dependent and is based on the sup-norm of the so-called Rademacher ...", "dateLastCrawled": "2022-01-29T07:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Off-line structural risk minimization and BARTMAP</b>-S | Request PDF", "url": "https://www.researchgate.net/publication/3950214_Off-line_structural_risk_minimization_and_BARTMAP-S", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3950214_<b>Off-line_structural_risk_minimization</b>...", "snippet": "According to [28] there are four steps to implement the <b>structural</b> <b>risk</b> <b>minimization</b> (see section <b>Structural</b> <b>risk</b> <b>minimization</b>), of which the first step is to choose a class of functions with ...", "dateLastCrawled": "2021-12-17T19:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "THE STUDY OF KERNEL METHODS", "url": "https://www.cse.cuhk.edu.hk/irwin.king/_media/presentations/kernel_wangwei.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cse.cuhk.edu.hk/irwin.king/_media/presentations/kernel_wangwei.pdf", "snippet": "<b>Structural</b> <b>Risk</b> <b>Minimization</b> where R is the radius of the smallest ball around the training data, R is fixed for a given data set. wx b\u22c5 +=1 wx b\u22c5 +=\u22121 Y=1 Y=-1 d+ d-wx b\u22c5 +=0 1 dd +\u2212w == Margin is the minimal distance of a sample to the decision surface hfw\u221d (2)", "dateLastCrawled": "2021-11-20T17:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Model selection.pdf - CS-E4710 Machine Learning Supervised Methods ...", "url": "https://www.coursehero.com/file/123571062/Model-selectionpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/123571062/Model-selectionpdf", "snippet": "<b>SRM</b> model selection: pros and cons \u2022 <b>Structural</b> <b>risk</b> <b>minimization</b> benefits from strong learning guarantees \u2022 However, the assumption of a countable decomposition of the hypothesis class is a restrictive one \u2022 The computational price to pay is large, especially when a large number of hypothesis classes H k has to be processed 17", "dateLastCrawled": "2022-01-22T21:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Model complexity control for hydrologic prediction - Schoups - 2008 ...", "url": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2008WR006836", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2008WR006836", "snippet": "A comparison of various model complexity control methods shows that <b>structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) is preferable to other methods, as it consistently identifies parsimonious models with unique parameters, even in cases where the assumption of data independence is violated. Methods developed for application with large data sets, such as AIC, tend to select models that are too complex, and which suffer from parameter equifinality. Cross validation is computationally intensive and sensitive ...", "dateLastCrawled": "2022-01-08T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Non_Uniform_MDL - Chapter 1 Minimum Description Length The notions of ...", "url": "https://www.coursehero.com/file/7857156/Non-Uniform-MDL/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/7857156/Non-Uniform-MDL", "snippet": "12 Minimum Description Length 1.4 <b>Structural</b> <b>Risk</b> <b>Minimization</b> - a generic non-uniform learner The next issue we would like to address is the scope of non-uniformly learnable classes. The following theorem generalizes our previous learnability result, from countable classes to classes that are countable unions of PAC-learnable classes. Theorem 4. If a class of models H is a countable union of classes, {H n} n 2 N, so that each of these classes has the uniform convergence property, then H is ...", "dateLastCrawled": "2022-01-09T20:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "5.2 The Simple Microchoice Bound", "url": "https://www.cs.cmu.edu/~jcl/papers/thesis/mathml/thesisse22.xml", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~jcl/papers/thesis/mathml/thesisse22.xml", "snippet": "More generally, the microchoice bound <b>is similar</b> <b>to Occam\u2019s</b> <b>razor</b> or <b>SRM</b> bounds when each k-ary choice in the tree corresponds to log k bits in the natural encoding of the final hypothesis h. However, sometimes this may not be the case. Consider, for instance, a local optimization algorithm in which there are n parameters and each step adds or subtracts 1 from one of the parameters. Suppose in addition the algorithm knows certain constraints that these parameters must satisfy (perhaps a ...", "dateLastCrawled": "2020-12-16T22:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Learning Theory: Purely Theoretical? | Laboratory for Intelligent ...", "url": "https://lips.cs.princeton.edu/learning-theory-purely-theoretical/", "isFamilyFriendly": true, "displayUrl": "https://lips.cs.princeton.edu/learning-theory-purely-theoretical", "snippet": "In the case of StatLT, there is Vapnik\u2019s <b>structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) framework, which provides generalization guarantees in terms of <b>risk</b> bounds. <b>SRM</b> led to the development of support vector machines, which have proven very useful in practice, independent of their theoretical properties. SVMs are a popular out-of-the-box classifier option since they require minimal tuning and, with the proper precautions, work quite well on most data sets. Hence, for many practitioners, the cost of ...", "dateLastCrawled": "2022-01-20T10:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Off-line structural risk minimization and BARTMAP</b>-S | Request PDF", "url": "https://www.researchgate.net/publication/3950214_Off-line_structural_risk_minimization_and_BARTMAP-S", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3950214_<b>Off-line_structural_risk_minimization</b>...", "snippet": "According to [28] there are four steps to implement the <b>structural</b> <b>risk</b> <b>minimization</b> (see section <b>Structural</b> <b>risk</b> <b>minimization</b>), of which the first step is to choose a class of functions with ...", "dateLastCrawled": "2021-12-17T19:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Chervonenkis - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/mathematics/chervonenkis", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/mathematics/chervonenkis", "snippet": "The Vapnik-Chervonenkis (VC) theory provides a general measure of complexity and proves bounds on errors as a function of complexity. <b>Structural</b> <b>risk</b> <b>minimization</b> is the <b>minimization</b> of these bounds, which depend on the empirical <b>risk</b> and the capacity of the function class (Vapnik, 1995 ).", "dateLastCrawled": "2021-12-13T01:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>understanding-machine-learning</b>-theory-algorithms[1] Pages 1 - 50 - Flip ...", "url": "https://fliphtml5.com/flqg/grxi/basic", "isFamilyFriendly": true, "displayUrl": "https://fliphtml5.com/flqg/grxi/basic", "snippet": "We describethe Empirical <b>Risk</b> <b>Minimization</b> (ERM), <b>Structural</b> <b>Risk</b> <b>Minimization</b> (<b>SRM</b>),and Minimum Description Length (MDL) learning rules, which shows \u201chow cana machine learn\u201d. We quantify the amount of data needed for learning usingthe ERM, <b>SRM</b>, and MDL rules and show how learning might fail by deriving viii a \u201cno-free-lunch\u201d theorem. We also discuss how much computation time is re- quired for learning. In the second part of the book we describe various learning algorithms. For some ...", "dateLastCrawled": "2021-12-18T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding Machine Learning: From Theory To Algorithms 1107057132 ...", "url": "https://ebin.pub/understanding-machine-learning-from-theory-to-algorithms-1107057132-9781107057135.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/understanding-machine-learning-from-theory-to-algorithms-1107057132...", "snippet": "7.2 <b>Structural</b> <b>Risk</b> <b>Minimization</b> 7.3 Minimum Description Length and <b>Occam&#39;s</b> <b>Razor</b> 7.3.1 <b>Occam&#39;s</b> <b>Razor</b> 7.4 Other Notions of Learnability \u2013 Consistency 7.5 Discussing the Different Notions of Learnability 7.5.1 The No-Free-Lunch Theorem Revisited 7.6 Summary 7.7 Bibliographic Remarks 7.8 Exercises 8 The Runtime of Learning", "dateLastCrawled": "2021-12-31T17:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "5.2 The Simple Microchoice Bound", "url": "https://www.cs.cmu.edu/~jcl/papers/thesis/mathml/thesisse22.xml", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~jcl/papers/thesis/mathml/thesisse22.xml", "snippet": "Pictorially, this algorithm <b>can</b> <b>be thought</b> of as taking a \u201csupply\u201d of probability at the root of the choice tree. ... , thus in this case these theorems yield similar bounds to a simple application of <b>Occam\u2019s</b> <b>razor</b> or <b>SRM</b>. More generally, the microchoice bound is similar to <b>Occam\u2019s</b> <b>razor</b> or <b>SRM</b> bounds when each k-ary choice in the tree corresponds to log k bits in the natural encoding of the final hypothesis h. However, sometimes this may not be the case. Consider, for instance, a ...", "dateLastCrawled": "2020-12-16T22:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Understanding Machine Learning: From Theory</b> to Algorithms ...", "url": "https://www.academia.edu/27872471/Understanding_Machine_Learning_From_Theory_to_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/27872471", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-28T13:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Microchoice bounds and self bounding learning algorithms | DeepDyve", "url": "https://www.deepdyve.com/lp/association-for-computing-machinery/microchoice-bounds-and-self-bounding-learning-algorithms-Jq0JdEx8Mg", "isFamilyFriendly": true, "displayUrl": "https://www.deepdyve.com/lp/association-for-computing-machinery/microchoice-bounds-and...", "snippet": "In fact, the Microchoice bound <b>can</b> be viewed as a compelling choice of nested hypothesis spaces on which to apply <b>Structural</b> <b>Risk</b> <b>minimization</b>. Self bounding Learning algorithms were first suggested by Yoav Freund [Fre98]. Work developing approximately Self Bounding Learning algorithms was also done by Pedro Domingos [Dom98]. In the second half of this paper, we show how the Microchoice bound <b>can</b> be combined with the query-tree approach of Freund to produce a variant on the query tree that ...", "dateLastCrawled": "2020-12-07T17:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Neglected machine learning ideas | Hacker News", "url": "https://news.ycombinator.com/item?id=8120053", "isFamilyFriendly": true, "displayUrl": "https://news.ycombinator.com/item?id=8120053", "snippet": "What Vapnik showed was that it is better to learn the classifier directly (he called it <b>structural</b> <b>risk</b> <b>minimization</b>, <b>SRM</b>, for short), without any parametric assumptions whatsoever. The main reasoning is that density estimation is freaking hard, and depending on a freaking hard task as a pre-requisite is backwards. Learning to classify is actually easier than learning densities. It was one of those paradigm shifts that come to a field only once in a while.", "dateLastCrawled": "2019-11-06T04:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "\uae30\uacc4\ud559\uc2b5 \ud604\uc7ac\uc640\ubbf8\ub798 <b>Pdf</b> - SlideShare", "url": "https://www.slideshare.net/ssuser35442b1/pdf-74016711", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ssuser35442b1/<b>pdf</b>-74016711", "snippet": "\uae30\uacc4\ud559\uc2b5\uc758 \uc774\uc288 2. \uae30\uc220\ub3d9\ud5a5 \uacfc\ub2e4\ud559\uc2b5(Overfitting) \uc815\uaddc\ud654 &amp; SRMBias-Variance Tradeoff \u00fc \uacfc\ub2e4\ud559\uc2b5(Overfitting) \u00fc \ubaa8\ub378\ubcf5\uc7a1\ub3c4 \u00fc <b>Occam\u2019s</b> <b>Razor</b> \u00fc \uc815\uaddc\ud654 \u00fc <b>SRM</b>(<b>Structural</b> <b>Risk</b> <b>Minimization</b>) \u00fc MAP(Maximum A Posteriori) \u00fc MDL(Minimum Description Length) 25. \uae30\uacc4\ud559\uc2b5\uc758 \uc774\uc288 2. \uae30\uc220\ub3d9\ud5a5 26.", "dateLastCrawled": "2021-12-29T16:03:00.0000000Z", "language": "ko", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Minimizing Structural Risk on Decision Tree Classification</b>", "url": "https://www.researchgate.net/publication/225441256_Minimizing_Structural_Risk_on_Decision_Tree_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/225441256_Minimizing_<b>Structural</b>_<b>Risk</b>_on...", "snippet": "Following <b>structural</b> <b>risk</b> <b>minimization</b> suggested by Vapnik, we <b>can</b> determine a desirable number of rules with the best generalization performance. The suggested method is <b>compared</b> with C4.5 ...", "dateLastCrawled": "2021-12-23T15:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Risk Minimization</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/risk-minimization", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>risk-minimization</b>", "snippet": "The <b>structural</b> <b>risk minimization</b> principle, discussed in the previous section, belongs to a more general class of methods that estimate the order of a system by considering, simultaneously, the model complexity and a performance index. Depending on the function used to measure the model complexity and the corresponding performance index, different criteria result. In this section we will focus on one of such criteria, which provides a Bayesian theory flavor to the model selection problem ...", "dateLastCrawled": "2022-01-25T07:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Fast minimization of structural risk by nearest neighbor</b> rule ...", "url": "https://www.academia.edu/10949188/Fast_minimization_of_structural_risk_by_nearest_neighbor_rule", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/10949188/<b>Fast_minimization_of_structural_risk_by</b>_nearest...", "snippet": "In addition to the computational cost, a natural question often T HE <b>STRUCTURAL</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) principle [1]\u2013[3] is a technique for nonparametric inference which has found application in classification and estimation problems. arises, namely that of selecting a convenient nonlinear space in which to construct the linear discriminant. It is essentially based on an empirical <b>risk</b> <b>minimization</b> (ERM) Toward improving the computational complexity in the principle, in an effort to ...", "dateLastCrawled": "2022-01-18T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Model selection.pdf - CS-E4710 Machine Learning Supervised Methods ...", "url": "https://www.coursehero.com/file/123571062/Model-selectionpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/123571062/Model-selectionpdf", "snippet": "<b>SRM</b> model selection: pros and cons \u2022 <b>Structural</b> <b>risk</b> <b>minimization</b> benefits from strong learning guarantees \u2022 However, the assumption of a countable decomposition of the hypothesis class is a restrictive one \u2022 The computational price to pay is large, especially when a large number of hypothesis classes H k has to be processed 17", "dateLastCrawled": "2022-01-22T21:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Machine learning theory", "url": "http://sharif.edu/~beigy/courses/13982/40718/Lect-10.pdf", "isFamilyFriendly": true, "displayUrl": "sharif.edu/~beigy/courses/13982/40718/Lect-10.pdf", "snippet": "<b>Structural</b> <b>risk</b> <b>minimization</b> The bound that the <b>SRM</b> rule wishes to minimize is given in the following theorem. Theorem Let w : N 7![0;1] be a function such that P1 n=1 w(n) 1. Let H be a hypothesis class that <b>can</b> be written as H = S n2N H n, where for each n, H n satis es the uniform convergence property with a sample complexity function mUC Hn ...", "dateLastCrawled": "2021-06-18T03:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Model complexity control for hydrologic prediction - Schoups - 2008 ...", "url": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2008WR006836", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2008WR006836", "snippet": "A comparison of various model complexity control methods shows that <b>structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) is preferable to other methods, as it consistently identifies parsimonious models with unique parameters, even in cases where the assumption of data independence is violated. Methods developed for application with large data sets, such as AIC, tend to select models that are too complex, and which suffer from parameter equifinality. Cross validation is computationally intensive and sensitive ...", "dateLastCrawled": "2022-01-08T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Off-line structural risk minimization and BARTMAP</b>-S | Request PDF", "url": "https://www.researchgate.net/publication/3950214_Off-line_structural_risk_minimization_and_BARTMAP-S", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3950214_<b>Off-line_structural_risk_minimization</b>...", "snippet": "According to [28] there are four steps to implement the <b>structural</b> <b>risk</b> <b>minimization</b> (see section <b>Structural</b> <b>risk</b> <b>minimization</b>), of which the first step is to choose a class of functions with ...", "dateLastCrawled": "2021-12-17T19:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Model complexity control for hydrologic prediction", "url": "https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1029/2008WR006836", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1029/2008WR006836", "snippet": "Akaike\u2019s information criterion (AIC), and <b>structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>). Results show that simulation of water flow using non-physically-based models (polynomials in this case) leads to increasingly better calibration fits as the model complexity (polynomial order) increases. However, prediction uncertainty worsens for complex non-physically-based models because of overfitting of noisy data. Incorporation of physically based constraints into the model (e.g., storage-discharge ...", "dateLastCrawled": "2021-12-21T18:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Non_Uniform_MDL - Chapter 1 Minimum Description Length The notions of ...", "url": "https://www.coursehero.com/file/7857156/Non-Uniform-MDL/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/7857156/Non-Uniform-MDL", "snippet": "12 Minimum Description Length 1.4 <b>Structural</b> <b>Risk</b> <b>Minimization</b> - a generic non-uniform learner The next issue we would like to address is the scope of non-uniformly learnable classes. The following theorem generalizes our previous learnability result, from countable classes to classes that are countable unions of PAC-learnable classes. Theorem 4. If a class of models H is a countable union of classes, {H n} n 2 N, so that each of these classes has the uniform convergence property, then H is ...", "dateLastCrawled": "2022-01-09T20:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Optimization Methods for Machine Learning (OMML)", "url": "https://www.diag.uniroma1.it/~palagi/didattica/sites/default/files/allegati/OMML_2nd_lect_2017-18.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.diag.uniroma1.it/~palagi/didattica/sites/default/files/allegati/OMML_2nd...", "snippet": "According <b>to Occam\u2019s</b> <b>razor</b> principle, we should seek simpler models over complex ones and optimize the tradeoff between model complexity and the accuracy of model\u2019s description of the training data. Models that are too complex (i.e., that fit the training data very well) or too simple (i.e., that fit the data poorly) provide poor prediction for future data. <b>Minimization</b> of empirical <b>risk</b>: parametric regression 01/10/2017 33 Let\u2019s consider N =10 data points, shown as blue circles, each ...", "dateLastCrawled": "2022-01-26T13:51:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Frontiers | A <b>Machine Learning Approach to Prioritizing Functionally</b> ...", "url": "https://www.frontiersin.org/articles/10.3389/fpls.2021.639253/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fpls.2021.639253", "snippet": "Support Vector <b>Machine</b> (SVM) is another approach for variable clustering based on <b>structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) theory (Vanitha et al., 2015). Both RF and SVM have been widely applied for decision making upon input of a large dataset. Therefore, we also utilized these two <b>machine</b> <b>learning</b> approaches to predict functionally active and inactive", "dateLastCrawled": "2022-01-31T01:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>GitHub</b> - gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Loss function 3.1 Categories 3.2 Empirical <b>risk</b> <b>minimization</b> (ERM) and <b>Structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) 3.2.1 MLE 3.2.2 MAP 4. Evaluation metrics 4.1 Accuracy, precision, recall and F1 4.2 ROC, AUC 4.3 BLEU 5. Sample projects 6. Classical questions 6.1 Why is logistic regression a generalized linear model ?", "dateLastCrawled": "2021-09-12T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "PAC, Generalization and <b>SRM</b>", "url": "https://elearning.unipd.it/math/mod/resource/view.php?id=38143", "isFamilyFriendly": true, "displayUrl": "https://e<b>learning</b>.unipd.it/math/mod/resource/view.php?id=38143", "snippet": "Connection to <b>learning</b> Measuring the complexity of the hypotheses space (VC-Dimension) VC-Dimension of hyperplanes <b>Structural</b> <b>Risk</b> <b>Minimization</b> Exercises VC-Dimension of other hypothesis spaces, e.g. intervals in R : h(x) = +1 if a &lt;= x &lt;= b;h(x) = 1 otherwise: Fabio Aiolli PAC, Generalization and <b>SRM</b> October 6th, 202122/22", "dateLastCrawled": "2021-11-19T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Structural Risk Minimization for Character Recognition</b>", "url": "https://proceedings.neurips.cc/paper/1991/file/10a7cdd970fe135cf4f7bb55c0e3b59f-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/1991/file/10a7cdd970fe135cf4f7bb55c0e3b59f-Paper.pdf", "snippet": "<b>Structural Risk Minimization for Character Recognition</b> I. Guyon, V. Vapnik, B. Boser, L. Bottou, and S. A. Solla AT&amp;T Bell Laboratories Holmdel, NJ 07733, USA Abstract The method of <b>Structural</b> <b>Risk</b> <b>Minimization</b> refers to tuning the capacity of the classifier to the available amount of training data. This capac\u00ad", "dateLastCrawled": "2022-02-01T13:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Loss function 3.1 Categories 3.2 Empirical <b>risk</b> <b>minimization</b> (ERM) and <b>Structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) 3.2.1 MLE 3.2.2 MAP 4. Evaluation metrics 4.1 Accuracy, precision, recall and F1 4.2 ROC, AUC 4.3 BLEU 5. Sample projects 6. Classical questions 6.1 Why is logistic regression a generalized linear model ?", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Tutorial On Support Vector Machines For Pattern Recognition Pdf ...", "url": "https://elizabethsid.org/for-pdf/11704-a-tutorial-on-support-vector-machines-for-pattern-recognition-pdf-565-290.php", "isFamilyFriendly": true, "displayUrl": "https://elizabethsid.org/for-pdf/11704-a-tutorial-on-support-vector-<b>machines</b>-for...", "snippet": "The paper starts with an overview of <b>structural</b> <b>risk</b> <b>minimization</b> <b>SRM</b> principle, and describes the mechanism of how to construct SVM. For a two-class pattern recognition problem, we discuss in detail the classification mechanism of SVM in three cases of linearly separable, linearly nonseparable and nonlinear. Finally, for nonlinear case, we give a new function mapping technique: By choosing an appropriate kernel function, the SVM can map the low-dimensional input space into the high ...", "dateLastCrawled": "2022-01-19T18:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Support Vector Machines: Theory and Applications</b>", "url": "https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221621494_Support_Vector_<b>Machine</b>s", "snippet": "hypothesis spaces is known as <b>Structural</b> <b>Risk</b> <b>Minimization</b> (<b>SRM</b>) (Vapnik, 1998). An important question that arises in SLT is that of meas uring the &quot;complexity&quot; of a hypothesis space - which, as ...", "dateLastCrawled": "2022-02-02T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Data gravitation based classification", "url": "http://www.isda03.softcomputing.net/dgc.pdf", "isFamilyFriendly": true, "displayUrl": "www.isda03.softcomputing.net/dgc.pdf", "snippet": "SVM is a relatively new <b>machine</b> <b>learning</b> method based on the statistical <b>learning</b> theory and <b>structural</b> <b>risk</b> <b>minimization</b> (<b>SRM</b>) principle. SVM is gaining popularity due to many attractive features, and promising empirical performance. SVM is based on the hypothesis that the training samples obey a certain distribution, which restricts its application scope. Rough set [17] theory has also been applied to classi\ufb01cation in recent years especially for feature selection [10] or as a ...", "dateLastCrawled": "2021-12-23T20:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Topics in <b>Machine</b> <b>Learning</b> (TIML-09)", "url": "https://www.cse.iitb.ac.in/~saketh/teaching/cs689.html", "isFamilyFriendly": true, "displayUrl": "https://www.cse.iitb.ac.in/~saketh/teaching/cs689.html", "snippet": "Introduction to Statistical <b>Learning</b> Theory (SLT): Definitions of loss function, <b>risk</b>, empirical <b>risk</b>, motivation for Empirical <b>Risk</b> <b>Minimization</b> (ERM) Further Reading, Supplementary: Jan 12: Consistency of ERM, Sufficient condition for ERM as one-sided uniform convergence, Analysis for finite sets of functions and extensions to general case using Symmetrization trick, Shattering Coeff. Further Reading, Supplementary: Jan 15: Shattering coeff., growth function, VC dimension, Annealed Entropy ...", "dateLastCrawled": "2022-01-11T09:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) A comparative <b>analysis of structural risk minimization by support</b> ...", "url": "https://www.academia.edu/10904454/A_comparative_analysis_of_structural_risk_minimization_by_support_vector_machines_and_nearest_neighbor_rule", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/10904454/A_comparative_analysis_of_<b>structural</b>_<b>risk</b>...", "snippet": "A Comparative <b>Analysis of Structural Risk Minimization by Support Vector Machines</b> and Nearest Neighbor Rule Bilge Kara\u00b8cal\u0131 , Rajeev Ramanath, Wesley E. Snyder a,b,c a Dept. of Radiology, University of Pennsylvania, Philadephia, PA 19104 b Dept. of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC 27695-7914 c Dept. of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC 27695-7911 Abstract Support Vector Machines (SVMs) are by ...", "dateLastCrawled": "2021-07-19T02:43:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(structural risk minimization (srm))  is like +(Occam\u2019s razor)", "+(structural risk minimization (srm)) is similar to +(Occam\u2019s razor)", "+(structural risk minimization (srm)) can be thought of as +(Occam\u2019s razor)", "+(structural risk minimization (srm)) can be compared to +(Occam\u2019s razor)", "machine learning +(structural risk minimization (srm) AND analogy)", "machine learning +(\"structural risk minimization (srm) is like\")", "machine learning +(\"structural risk minimization (srm) is similar\")", "machine learning +(\"just as structural risk minimization (srm)\")", "machine learning +(\"structural risk minimization (srm) can be thought of as\")", "machine learning +(\"structural risk minimization (srm) can be compared to\")"]}