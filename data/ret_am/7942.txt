{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Portrait Segmentation Using Ensemble of Heterogeneous Deep-Learning Models", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7915081/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7915081", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) metric, <b>IoU</b> standard deviation and false prediction rate were used to evaluate the performance. Cost efficiency was calculated to analyze the efficiency of segmentation. The experiment results show that the proposed ensemble approach can perform with higher accuracy and lower errors than single deep-learning-based portrait segmentation models. The results also show that the ensemble of deep-learning models typically increases the use of memory and computing ...", "dateLastCrawled": "2021-11-17T21:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "High-throughput segmentation of unmyelinated axons by deep learning", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8786854/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8786854", "snippet": "where true positive (TP) denotes an instance detected by automated segmentation and matching an instance in the manual segmentation with an <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) score of 0.5, or higher, false positive (FP) denotes an instance detected by automated segmentation but that do not match an instance in the manual segmentation with an <b>IoU</b> score of 0.5 or higher, false negative (FN) denotes an instance in the manual segmentation but not detected by automated segmentation with an <b>IoU</b> score ...", "dateLastCrawled": "2022-01-28T09:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "function to measure <b>intersection</b> <b>over</b> <b>union</b> Code Example - codegrepper.com", "url": "https://www.codegrepper.com/code-examples/python/function+to+measure+intersection+over+union", "isFamilyFriendly": true, "displayUrl": "https://www.codegrepper.com/.../python/function+to+measure+<b>intersection</b>+<b>over</b>+<b>union</b>", "snippet": "# function to compute the <b>IoU</b> function def bb_<b>intersection</b>_<b>over</b>_<b>union</b>(boxA, boxB): # determine the (x, y)-coordinates of the <b>intersection</b> rectangle xA = max(boxA[0 ...", "dateLastCrawled": "2021-12-15T10:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Distance-based confidence generation and aggregation of classifier for ...", "url": "https://www.sciencedirect.com/science/article/pii/S1319157821002718", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1319157821002718", "snippet": "The performance of the proposed <b>system</b> is evaluated in terms of precision, recall, accuracy, <b>intersection</b> <b>over</b> <b>union</b> (<b>IOU</b>), true positive rate (TPR), and processing time and compared with current state of art methods reported in the literature. The proposed <b>system</b> achieved precision, recall, accuracy, <b>IOU</b>, and TPR of 96.79%, 96.92%, 97.8%, 96.08% and 96%, respectively with the processing time three times smaller than those of the existing state of art methods. The experimental results ...", "dateLastCrawled": "2022-01-06T00:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "DeepSponsorBlock", "url": "http://cs230.stanford.edu/projects_fall_2020/reports/55822706.pdf", "isFamilyFriendly": true, "displayUrl": "cs230.stanford.edu/projects_fall_2020/reports/55822706.pdf", "snippet": "Our model achieves a median <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IOU</b>) of 0.69 on a test set of \u02d83000 videos, which means our model\u2019s predictions tend to have a high degree of overlap with the ground-truth labels. 1 Introduction Internet users have taken a variety of measures to limit the presence of ads in their Internet experiences, including installing ad blockers [1] and paying for ad-free versions of services, <b>like</b> YouTube Premium. However, in the past few years, advertisers have started paying ...", "dateLastCrawled": "2022-02-03T05:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Lumbar spine discs classification based on deep ... - ScienceDirect.com", "url": "https://www.sciencedirect.com/science/article/pii/S2214751920303984", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2214751920303984", "snippet": "The <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) was calculated as the ratio between the <b>intersection</b> (number of predicted pixels) and the <b>union</b> (the sum of number of incorrectly and correctly predicted pixels) (as shown in Fig. 4). (3): The number of pixels of class c (background, apophyse or disc) correctly predicted pixels.: The total number of pixels predicted to class c.: The total number of pixels of class c.", "dateLastCrawled": "2022-01-28T08:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Automated Via Detection for PCB Reverse Engineering", "url": "https://dforte.ece.ufl.edu/wp-content/uploads/sites/65/2021/01/ISTFA_autoViaDetect_Revised_11102020.pdf", "isFamilyFriendly": true, "displayUrl": "https://dforte.ece.ufl.edu/wp-content/uploads/sites/65/2021/01/ISTFA_autoViaDetect...", "snippet": "0.886, 0.936, 0.973, for <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>), Dice Coefficient, and Structural Similarity Index. These results vastly outperform our tuned implementation of Mask R-CNN. I. Introduction Two terms that dominate discussion of modern technology are automation and cyber-security, albeit for different reasons. In", "dateLastCrawled": "2022-01-27T15:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Video-Based Parking Occupancy Detection for Smart Control <b>System</b>", "url": "https://www.mdpi.com/2076-3417/10/3/1079/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2076-3417/10/3/1079/htm", "snippet": "The bounding box prediction standard is <b>intersection</b> <b>over</b> <b>union</b> (<b>IOU</b>), which is used to measure the accuracy of object detectors on datasets. The optimal situation is <b>IOU</b> = 1, signifying that a predicted bounding box completely coincides with the bounding box of a real insulator. The characteristics of the overlapping area are used in bounding boxes, which fits real objects to calculate the area. To enhance the detection accuracy of small objects, YOLO v3 uses a Feature Pyramid Network ...", "dateLastCrawled": "2022-01-12T14:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "High-throughput segmentation of unmyelinated axons by deep learning ...", "url": "https://www.nature.com/articles/s41598-022-04854-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-022-04854-3", "snippet": "PQ pairs annotated and predicted instances, restricting matches to an <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) score of 0.5 or more because a uniqueness theorem 28 ensures that each annotated region is ...", "dateLastCrawled": "2022-01-24T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Predicting driver behaviour at intersections based on driver gaze and ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-its.2020.0087", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-its.2020.0087", "snippet": "For a computer <b>system</b> <b>like</b> an ADAS, it will need to analyse the actions of the driver, vehicle parameters and the surrounding environment to predict an upcoming manoeuvre. The aim of this work is to predict the next driving manoeuvre at an <b>intersection</b> using information about the state of the TL prior to a manoeuvre. The driver&#39;s behaviour will be modelled for three different manoeuvres: turning left, turning right, and driving straight.", "dateLastCrawled": "2022-01-10T21:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Portrait Segmentation Using Ensemble of Heterogeneous Deep-Learning Models", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7915081/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7915081", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) metric, <b>IoU</b> standard deviation and false prediction rate were used to evaluate the performance. Cost efficiency was calculated to analyze the efficiency of segmentation. The experiment results show that the proposed ensemble approach can perform with higher accuracy and lower errors than single deep-learning-based portrait segmentation models. The results also show that the ensemble of deep-learning models typically increases the use of memory and computing ...", "dateLastCrawled": "2021-11-17T21:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "High-throughput segmentation of unmyelinated axons by deep learning", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8786854/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8786854", "snippet": "where true positive (TP) denotes an instance detected by automated segmentation and matching an instance in the manual segmentation with an <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) score of 0.5, or higher, false positive (FP) denotes an instance detected by automated segmentation but that do not match an instance in the manual segmentation with an <b>IoU</b> score of 0.5 or higher, false negative (FN) denotes an instance in the manual segmentation but not detected by automated segmentation with an <b>IoU</b> score ...", "dateLastCrawled": "2022-01-28T09:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Scaling the U-net: segmentation of biodegradable bone implants in high ...", "url": "https://europepmc.org/article/PMC/PMC8688506", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC8688506", "snippet": "In a systematic evaluation we compare the performance of scaling the U-net by <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) and quantitative measurements of osseointegration and degradation parameters. Overall, we observe that a compound scaling of the U-net and multi-axes prediction fusing with soft <b>voting</b> yields the highest <b>IoU</b> for the class &quot;degradation layer&quot;. Finally, the quantitative analysis showed that the parameters calculated with model segmentation deviated less from the high quality results than ...", "dateLastCrawled": "2022-01-07T07:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "DeepSponsorBlock", "url": "http://cs230.stanford.edu/projects_fall_2020/reports/55822706.pdf", "isFamilyFriendly": true, "displayUrl": "cs230.stanford.edu/projects_fall_2020/reports/55822706.pdf", "snippet": "Our model achieves a median <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IOU</b>) of 0.69 on a test set of \u02d83000 videos, which means our model\u2019s predictions tend to have a high degree of overlap with the ground-truth labels. 1 Introduction Internet users have taken a variety of measures to limit the presence of ads in their Internet experiences, including installing ad blockers [1] and paying for ad-free versions of services, like YouTube Premium. However, in the past few years, advertisers have started paying ...", "dateLastCrawled": "2022-02-03T05:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Abstract and Figures - researchgate.net", "url": "https://www.researchgate.net/publication/354591252_Shape_Similarity_Intersection-Over-Union_Loss_Hybrid_Model_for_Detection_of_Synthetic_Aperture_Radar_Small_Ship_Objects_in_Complex_Scenes", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/354591252_Shape_<b>Similar</b>ity_<b>Intersection</b>-<b>Over</b>...", "snippet": "With the continuous development and utilization of marine environments, the demand for accurate identification of ship targets at sea is increasing in both military and civilian f", "dateLastCrawled": "2022-01-31T18:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Automated processing of X-ray computed tomography images via panoptic ...", "url": "https://vertexdoc.com/doc/automated-processing-of-x-ray-computed-tomography-images-via-panoptic-segmentation-for-modeling-woven-composite-textiles", "isFamilyFriendly": true, "displayUrl": "https://vertexdoc.com/doc/automated-processing-of-x-ray-computed-tomography-images-via...", "snippet": "Frame-to-frame instance tracking is accomplished via an <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) approach adopted from video panoptic segmentation for assembling a 3D geometric model. A corrective recognition algorithm is developed to improve the recognition quality (RQ). The panoptic quality (PQ) metric is adopted to provide a new universal evaluation metric for reconstructed woven composite textiles. It is found that the panoptic segmentation network generalizes well to new CT images that are <b>similar</b> ...", "dateLastCrawled": "2022-02-04T11:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "MANUSCRIPT 1 Crafting GBD-Net for Object Detection", "url": "https://wlouyang.github.io/Papers/Zeng2017_GBD_PAMI.pdf", "isFamilyFriendly": true, "displayUrl": "https://wlouyang.github.io/Papers/Zeng2017_GBD_PAMI.pdf", "snippet": "positive for an object category if the <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) between the candidate box and the ground-truth box is greater than a threshold. When a candidate box covers only a part of the ground-truth regions, there are some potential problems. Xingyu Zeng (equal contribution), Wanli Ouyang (equal contribution), Tong Xiao, Kun Wang, Hongsheng Li, Zhe Wang, Hui Zhou and Xiaogang Wang are with the Department of Electronic Engineering at the Chinese University of Hong Kong, Hong Kong ...", "dateLastCrawled": "2022-01-14T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Distance-based confidence generation and aggregation of classifier for ...", "url": "https://www.sciencedirect.com/science/article/pii/S1319157821002718", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1319157821002718", "snippet": "The performance of the proposed <b>system</b> is evaluated in terms of precision, recall, accuracy, <b>intersection</b> <b>over</b> <b>union</b> (<b>IOU</b>), true positive rate (TPR), and processing time and compared with current state of art methods reported in the literature. The proposed <b>system</b> achieved precision, recall, accuracy, <b>IOU</b>, and TPR of 96.79%, 96.92%, 97.8%, 96.08% and 96%, respectively with the processing time three times smaller than those of the existing state of art methods. The experimental results ...", "dateLastCrawled": "2022-01-06T00:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "High-throughput segmentation of unmyelinated axons by deep learning ...", "url": "https://www.nature.com/articles/s41598-022-04854-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-022-04854-3", "snippet": "PQ pairs annotated and predicted instances, restricting matches to an <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) score of 0.5 or more because a uniqueness theorem 28 ensures that each annotated region is ...", "dateLastCrawled": "2022-01-24T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Understanding <b>YOLO</b> | HackerNoon", "url": "https://hackernoon.com/understanding-yolo-f5a74bbc7967", "isFamilyFriendly": true, "displayUrl": "https://hackernoon.com/understanding-<b>yolo</b>-f5a74bbc7967", "snippet": "Otherwise we want the confidence score to equal the <b>intersection</b> <b>over</b> <b>union</b> (<b>IOU</b>) between the predicted box and the ground truth. Note that the confidence reflects the presence or absence of an object of any class. In case you don&#39;t know what <b>IOU</b> is, take a look here. Now that we understand the 5 components of the box prediction, remember that each grid cell makes B of those predictions, so there are in total S x S x B * 5 outputs related to bounding box predictions. It is also necessary to ...", "dateLastCrawled": "2022-02-02T23:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bounding Box</b> Embedding for Single Shot Person Instance ... - DeepAI", "url": "https://deepai.org/publication/bounding-box-embedding-for-single-shot-person-instance-segmentation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>bounding-box</b>-embedding-for-single-shot-person-instance...", "snippet": "In fact, this method <b>can</b> <b>be thought</b> of as a \u201cdense\u201d object detector, in which each pixel is allowed a proposal. ... or \u201c<b>intersection</b>-<b>over</b>-<b>union</b>\u201d (<b>IoU</b>). Although this approach <b>can</b> in theory be used on any arbitrary number of object classes, as <b>bounding box</b> regressors <b>can</b> be class-agnostic [19, 17], we test our approach only on the person class as it allows for quicker training and easier evaluation, and person class results on the COCO dataset for several state-of-the-art methods have ...", "dateLastCrawled": "2022-01-30T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Insect Detection and Classification Based on</b> an Improved ...", "url": "https://www.researchgate.net/publication/329263432_Insect_Detection_and_Classification_Based_on_an_Improved_Convolutional_Neural_Network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/329263432_Insect_Detection_and_Classification...", "snippet": "<b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) overlap ratio with the ground truth box; otherwise, it was assigned to . a negative label if the <b>IoU</b> of the proposal region was lower than the <b>IoU</b> threshold of all ...", "dateLastCrawled": "2022-01-30T23:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>R-FCN: Object Detection via</b> Region-based Fully ... - arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1605.06409/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1605.06409", "snippet": "We define positive examples as the RoIs that have <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) overlap with a ground-truth box of at least 0.5, and negative otherwise. It is easy for our method to adopt online hard example mining (OHEM) Shrivastava2016 during training. Our negligible per-RoI computation enables nearly cost-free example mining. Assuming N proposals per image, in the forward pass, we evaluate the loss of all N proposals. Then we sort all RoIs (positive and negative) by loss and select B RoIs ...", "dateLastCrawled": "2022-01-25T19:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Review of Vehicle Detection Systems in Advanced Driver Assistant ...", "url": "https://link.springer.com/article/10.1007/s11831-019-09321-3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11831-019-09321-3", "snippet": "Hence condition for objects to be said as covered is given by computing the <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) (e.g. ). The ... <b>System</b> complexity <b>can</b> be compromised a bit if accuracy is high and time complexity is low enough to handle real time scenarios of vehicle detection. Hence the future might look forward to improve the accuracy of Fast or Faster RCNN for vehicle detection on aerial images The challenge of missing small vehicles in aerial images could <b>be thought</b> of solving by adopting an ...", "dateLastCrawled": "2021-11-25T07:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Weakly <b>Supervised Precise Segmentation for Historical Document Images</b> ...", "url": "https://www.researchgate.net/publication/332637070_Weakly_Supervised_Precise_Segmentation_for_Historical_Document_Images", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/332637070_Weakly_Supervised_Precise...", "snippet": "In particular, our approach yields a significant improvement under a large <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) of 0.8. The robustness and generality are also proved by experiments on the scene text ...", "dateLastCrawled": "2022-02-01T02:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Multi-Person <b>tracking by multi-scale detection in Basketball</b> ... - DeepAI", "url": "https://deepai.org/publication/multi-person-tracking-by-multi-scale-detection-in-basketball-scenarios", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/multi-person-<b>tracking-by-multi-scale-detection</b>-in...", "snippet": "(b) C i (B t 1, B t 2) = <b>IoU</b> (H t 1 (B t 1), H t 2 (B t 2)) is the <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) value of the transformation by H t 1 and H t 2 of the two bounding boxes, respectively. (c) The content of B t 1 and B t 2 is compared by considering only the pairs of anatomical keypoints (joints between limbs) present or detected in both B t 1 and B t 2 , denoted here as p k 1 and p k 2 , respectively.", "dateLastCrawled": "2021-12-07T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A crowdsourcing semi-automatic image segmentation platform for cell ...", "url": "https://www.sciencedirect.com/science/article/pii/S0010482520305357", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0010482520305357", "snippet": "Similarly , investigated the correlation between human annotators&#39; effort and their performance in the annotation task, as measured by <b>IoU</b> (<b>Intersection</b> <b>over</b> <b>Union</b>), where the annotator&#39;s effort is quantified by three metrics: segmentation time, number of points and average time per point . Crowdsourced the task of CT lung scans annotation and investigated the correlation between users&#39; behavior (time spent) and the quality of the annotation, and found that there is not a strong correlation ...", "dateLastCrawled": "2022-01-05T02:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Calorie counter using python.docx - Calorie counter using python ...", "url": "https://www.coursehero.com/file/107132983/Calorie-counter-using-pythondocx/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/107132983/Calorie-counter-using-pythondocx", "snippet": "For an object detection model, the threshold is the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) that scores the detected objects. Once the AP is measured for each class in the dataset, the mAP is calculated. 3. Maniuk, I. (2016). Life Cycle of Extreme Programming. Extreme programming is an iterative software development methodology which aims to produce higher quality software and helps in providing an optimal solution. Extreme Programming differs from other software development methodologies as it ...", "dateLastCrawled": "2021-12-30T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "GitHub - jeevu94/ml-notes: Personal notes on ML", "url": "https://github.com/jeevu94/ml-notes", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/jeevu94/ml-notes", "snippet": "<b>IoU</b>. <b>IoU</b> is short for <b>Intersection</b> <b>over</b> <b>Union</b>, it is a metric used to evaluate objection detection algorithm. Basically, it is the <b>intersection</b> of predicted box and ground-truth box divided by the <b>union</b> of the two boxes. <b>IoU</b> = 1 means a perfect detector. A typical threshhold for a good detector is 0.5. Normalization. Feature scaling is a method used to standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is ...", "dateLastCrawled": "2022-01-20T20:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Computer Vision for Autonomous Vehicles: Problems, Datasets and State ...", "url": "https://www.arxiv-vanity.com/papers/1704.05519/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1704.05519", "snippet": "The performance is assessed for three level of difficulties using PASCAL VOC <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IOU</b>) (Everingham et al. ). Easy examples have a minimum bounding box height of 40 px and are fully visible, whereas moderate examples have a minimum height of 25 px including partial occlusion and hard examples have the same minimum height but includes the maximum occlusion level. In Table", "dateLastCrawled": "2021-12-19T19:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Scaling the U-net: segmentation of biodegradable bone implants in high ...", "url": "https://europepmc.org/article/PMC/PMC8688506", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC8688506", "snippet": "In a systematic evaluation we compare the performance of scaling the U-net by <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) and quantitative measurements of osseointegration and degradation parameters. Overall, we observe that a compound scaling of the U-net and multi-axes prediction fusing with soft <b>voting</b> yields the highest <b>IoU</b> for the class &quot;degradation layer&quot;. Finally, the quantitative analysis showed that the parameters calculated with model segmentation deviated less from the high quality results than ...", "dateLastCrawled": "2022-01-07T07:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Distance-based confidence generation and aggregation of classifier for ...", "url": "https://www.sciencedirect.com/science/article/pii/S1319157821002718", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1319157821002718", "snippet": "The performance of the proposed <b>system</b> is evaluated in terms of precision, recall, accuracy, <b>intersection</b> <b>over</b> <b>union</b> (<b>IOU</b>), true positive rate (TPR), and processing time and <b>compared</b> with current state of art methods reported in the literature. The proposed <b>system</b> achieved precision, recall, accuracy, <b>IOU</b>, and TPR of 96.79%, 96.92%, 97.8%, 96.08% and 96%, respectively with the processing time three times smaller than those of the existing state of art methods. The experimental results ...", "dateLastCrawled": "2022-01-06T00:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Optimizing Expected Intersection-Over-Union with Candidate-Constrained</b> ...", "url": "https://www.researchgate.net/publication/300408538_Optimizing_Expected_Intersection-Over-Union_with_Candidate-Constrained_CRFs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/300408538_Optimizing_Expected_<b>Intersection</b>...", "snippet": "The <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) is usually used to measure the performance of any object category segmentation method. In this paper, we propose an approach for directly optimizing this <b>IoU</b> ...", "dateLastCrawled": "2022-01-18T20:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Automatic Detection and Classification of Focal Liver Lesions Based on ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7878526/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7878526", "snippet": "CNN, convolutional neural network; <b>IoU</b>, <b>intersection</b>-<b>over</b>-<b>union</b>. The bold values represent the results obtained from our proposed model. To evaluate the performance of our detection networks, we <b>compared</b> our results with RetinaNet, a commonly adopted detection network ( 33 ), and with the original Faster R-CNN ( 28 ).", "dateLastCrawled": "2022-01-27T00:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Abstract and Figures - researchgate.net", "url": "https://www.researchgate.net/publication/354591252_Shape_Similarity_Intersection-Over-Union_Loss_Hybrid_Model_for_Detection_of_Synthetic_Aperture_Radar_Small_Ship_Objects_in_Complex_Scenes", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/354591252_Shape_Similarity_<b>Intersection</b>-<b>Over</b>...", "snippet": "With the continuous development and utilization of marine environments, the demand for accurate identification of ship targets at sea is increasing in both military and civilian f", "dateLastCrawled": "2022-01-31T18:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "1,*, Yung-Cheol Byun 2,* and Addapalli V. N. Krishna", "url": "https://res.mdpi.com/d_attachment/entropy/entropy-23-00197/article_deploy/entropy-23-00197-v2.pdf", "isFamilyFriendly": true, "displayUrl": "https://res.mdpi.com/d_attachment/entropy/entropy-23-00197/article_deploy/entropy-23...", "snippet": "using a simple soft <b>voting</b> method and weighted soft <b>voting</b> method, were experimented. <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) metric, <b>IoU</b> standard deviation and false prediction rate were used to evaluate the performance. Cost ef\ufb01ciency was calculated to analyze the ef\ufb01ciency of segmentation. The experiment results show that the proposed ensemble approach <b>can</b> perform with higher accuracy and lower errors than single deep-learning-based portrait segmentation models. The results also show that the ...", "dateLastCrawled": "2022-02-03T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Road surface damage detection based on hierarchical architecture using ...", "url": "https://www.sciencedirect.com/science/article/pii/S0926580521002843", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0926580521002843", "snippet": "Training and prediction method with multiple loss functions and weighted soft <b>voting</b>. ... For a more detailed explanation, the background <b>intersection</b> <b>over</b> <b>union</b> (b-<b>IoU</b>) and distress <b>intersection</b> <b>over</b> <b>union</b> (d-<b>IoU</b>) were calculated to determine the detection accuracy for each class. b-<b>IoU</b> refers to the detection accuracy for areas not related to road damage, and d-<b>IoU</b> refers to the detection accuracy for road damage areas. b-<b>IoU</b> and d-<b>IoU</b> are accuracies that correspond to each class in Eq ...", "dateLastCrawled": "2021-12-14T04:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "MANUSCRIPT 1 Crafting GBD-Net for Object Detection", "url": "https://wlouyang.github.io/Papers/Zeng2017_GBD_PAMI.pdf", "isFamilyFriendly": true, "displayUrl": "https://wlouyang.github.io/Papers/Zeng2017_GBD_PAMI.pdf", "snippet": "positive for an object category if the <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) between the candidate box and the ground-truth box is greater than a threshold. When a candidate box covers only a part of the ground-truth regions, there are some potential problems. Xingyu Zeng (equal contribution), Wanli Ouyang (equal contribution), Tong", "dateLastCrawled": "2022-01-14T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "High-throughput segmentation of unmyelinated axons by deep learning ...", "url": "https://www.nature.com/articles/s41598-022-04854-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-022-04854-3", "snippet": "PQ pairs annotated and predicted instances, restricting matches to an <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) score of 0.5 or more because a uniqueness theorem 28 ensures that each annotated region is ...", "dateLastCrawled": "2022-01-24T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Description of shape patterns using circular arcs for object detection</b> ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-cvi.2011.0180", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-cvi.2011.0180", "snippet": "For each test image, the object detection <b>system</b> generates a number of bounding boxes as candidates for object detection. Each detection candidate is <b>compared</b> with the ground truth, and the detection is judged by the <b>intersection</b>-<b>over</b>-<b>union</b> (<b>IoU</b>) ratio of the two bounding boxes. We used either a 20% or a 50% criterion for the evaluation.", "dateLastCrawled": "2022-01-28T16:37:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "13.4. <b>Anchor</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/anchor.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>anchor</b>.html", "snippet": "<b>Intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>), also known as Jaccard index, measures the similarity of two bounding boxes. It is the ratio of their <b>intersection</b> area to their <b>union</b> area. In a training set, we need two types of labels for each <b>anchor</b> box. One is the class of the object relevant to the <b>anchor</b> box and the other is the offset of the ground-truth ...", "dateLastCrawled": "2022-01-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep Hybrid Convolutional Neural Network for Segmentation of Melanoma ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8592765/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8592765", "snippet": "<b>Machine</b> <b>learning</b> algorithms have been widely used in cancer research [2 ... <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) is a task outputting a prediction range. In order for <b>IoU</b> to be used to detect objects of any size and shape, it is necessary to mark the range of the detected object in the training set image and measure the correlation between the ground-truth and the prediction. <b>IoU</b> = TP TP + FP + FN. (6) 3. Experiment. 3.1. Dataset. 3.1.1. International Skin Imaging Collaboration 2018 Dataset . The ...", "dateLastCrawled": "2021-11-20T10:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "The <b>intersection</b> of two sets divided by their <b>union</b>. In <b>machine-learning</b> image-detection tasks, <b>IoU</b> is used to measure the accuracy of the model\u2019s predicted bounding box with respect to the ground-truth bounding box. In this case, the <b>IoU</b> for the two boxes is the ratio between the overlapping area and the total area, and its value ranges from ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>What is intersection over union in deep</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-intersection-over-union-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-intersection-over-union-in-deep</b>-<b>learning</b>", "snippet": "Answer (1 of 2): Generally <b>Intersection</b> <b>over</b> <b>union</b>(<b>IOU</b>) is a measure of overlap between two bounding box . In computer vision it is used for correctly detecting an object.To know object detection first you have to know about object localization . Object localization refers to figuring out where i...", "dateLastCrawled": "2022-01-19T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Crack identification for bridge condition monitoring using deep ...", "url": "https://www.jvejournals.com/article/22032", "isFamilyFriendly": true, "displayUrl": "https://www.jvejournals.com/article/22032", "snippet": "By that <b>analogy</b>, several different CNN models are obtained and the accuracy of patch classification could be improved by using all models together. Finally, 80 test images are processed by the feedback-update CNN models and FCN model with a sliding window technique to generate crack identification results. <b>Intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) is calculated as an index to quantificationally evaluate the accuracy of the proposed method. Orthotropic steel bridge decks and steel box girders are key ...", "dateLastCrawled": "2021-12-22T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Unraveling the deep <b>learning</b> gearbox in optical coherence tomography ...", "url": "https://www.nature.com/articles/s42003-021-01697-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42003-021-01697-y", "snippet": "In that previous study, the <b>intersection</b> <b>over</b> <b>union</b> (<b>IOU</b>) scores was applied. In the proposed analysis in cynomolgus monkeys, that score was changed to the Hamming distance metric to additionally ...", "dateLastCrawled": "2022-01-31T21:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "CNN\u2010based novelty detection for terrestrial and extra\u2010terrestrial ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/csy2.12013", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/csy2.12013", "snippet": "In particular, an <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) threshold r for NMS is used, and the remaining RoIs are propagated to the CN for classification. 2.2 Classification Network (CN) Faster R-CNN utilises the Fast R-CNN architecture [ 14 ] to classify the detected regions proposed by the RPN.", "dateLastCrawled": "2021-12-31T19:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Unsupervised part representation by Flow Capsules \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2011.13920/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2011.13920", "snippet": "Tab. 3 compares the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) of our masks against PSD and R-NEM (van2018relational). Although PSD receives the ground truth optical flow during training, FlowCapsules consistently have better or equal IoUs during testing on both the Geo and Exercise datasets. One other significant difference between PSD and FlowCapsules lies in how they generate the masks. FlowCapsules generate the", "dateLastCrawled": "2022-01-06T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Neural Networks Training in Delhi</b> Archives - DexLab Analytics | Big ...", "url": "https://m.dexlabanalytics.com/blog/tag/neural-networks-training-in-delhi", "isFamilyFriendly": true, "displayUrl": "https://m.dexlabanalytics.com/blog/tag/<b>neural-networks-training-in-delhi</b>", "snippet": "<b>Machine</b> <b>Learning</b> is growing as fast as ever in the age we are living, ... <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>)-balanced Loss Functions for Single-stage Object Detection. The <b>IoU</b>-balanced classification loss focuses on positive scenarios with high <b>IoU</b> can increase the correlation between classification and the task of localization. The loss aims at decreasing the gradient of the examples with low <b>IoU</b> and increasing the gradient of examples with high <b>IoU</b>. This increases the localization accuracy of ...", "dateLastCrawled": "2021-12-05T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Calculating IOU of masks using tensorflow</b> : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/ns8c8q/calculating_iou_of_masks_using_tensorflow/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/ns8c8q/calculating_<b>iou</b>_of_masks...", "snippet": "<b>Calculating IOU of masks using tensorflow</b>. Hello! I&#39;m trying to speed up a process from my computer vision pipeline where I calculate <b>IOU</b> of two binary masks by using tensorflow 1.15. I&#39;ll post a snippet of code showing how I&#39;m doing it with numpy and how I&#39;m trying to do it with tensorflow, so far tensorflow is waaaay slower and was hoping someone could point out why that is happening. ...", "dateLastCrawled": "2021-12-28T03:28:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(intersection over union (iou))  is like +(voting system)", "+(intersection over union (iou)) is similar to +(voting system)", "+(intersection over union (iou)) can be thought of as +(voting system)", "+(intersection over union (iou)) can be compared to +(voting system)", "machine learning +(intersection over union (iou) AND analogy)", "machine learning +(\"intersection over union (iou) is like\")", "machine learning +(\"intersection over union (iou) is similar\")", "machine learning +(\"just as intersection over union (iou)\")", "machine learning +(\"intersection over union (iou) can be thought of as\")", "machine learning +(\"intersection over union (iou) can be compared to\")"]}