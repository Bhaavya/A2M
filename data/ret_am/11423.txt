{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian</b> vs <b>Neural</b> Networks \u2013 Ehud Reiter&#39;s Blog", "url": "https://ehudreiter.com/2021/07/05/bayesian-vs-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://ehudreiter.com/2021/07/05/<b>bayesian</b>-vs-<b>neural</b>-<b>networks</b>", "snippet": "We have a small <b>group</b> that meets monthly to discuss this, and last week we ended up also talking about why <b>people</b> would use <b>Bayesian</b> models instead of <b>neural</b> networks, focusing on medical decision support (not NLP). Which I found very interesting and thought-provoking. One relatively obvious reason to avoid black-box <b>neural</b> models is justifiability (which relates to explanation). Ie, if I build a medical diagnosis system as a <b>Bayesian</b> model, I can explain to doctors (and regulators) exactly ...", "dateLastCrawled": "2022-02-01T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "The paper &quot;What Are <b>Bayesian</b> <b>Neural</b> <b>Network</b> Posteriors Really <b>Like</b>?&quot; by P. Izmailov, S. Vikram, M. Hoffman and A. Wilson addresses ideas to improve the predictive accuracy of <b>Bayesian</b> <b>neural</b> networks. The beginning of the abstract is: &quot;The posterior over <b>Bayesian</b> <b>neural</b> <b>network</b> (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as mean-field variational inference or ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian Belief Networks</b>: An Introduction In 6 Easy Points", "url": "https://www.jigsawacademy.com/blogs/data-science/bayesian-belief-network", "isFamilyFriendly": true, "displayUrl": "https://www.<b>jigsawacademy</b>.com/blogs/data-science/<b>bayesian</b>-belief-<b>network</b>", "snippet": "The graph of a <b>Bayesian</b> <b>Network</b> is useful. It is readable to both computers and humans; both can interpret the information, unlike some networks <b>like</b> <b>neural</b> networks, which humans can\u2019t read. Disadvantages. The most significant disadvantage is that there is no universally acknowledged method for constructing networks from data. There have ...", "dateLastCrawled": "2022-02-03T06:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bayesian</b> <b>Network</b> as a Decision Tool for Predicting ALS Disease", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7912628/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7912628", "snippet": "<b>Bayesian</b> <b>network</b> has produced more successful results than other methods according to all comparison criteria for the Neurological Control <b>group</b>, as in the ALS <b>group</b>. For this <b>group</b>, the <b>Bayesian</b> <b>Network</b>\u2019s ACC value has been found as (0.902). The Kappa values of other methods indicate that the results obtained are random, while the Kappa value (0.677) was found for <b>Bayesian</b> <b>network</b>.", "dateLastCrawled": "2022-01-11T04:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Comprehensive Introduction to <b>Bayesian</b> Deep Learning - Joris Baan", "url": "https://jorisbaan.nl/2021/03/02/introduction-to-bayesian-deep-learning.html", "isFamilyFriendly": true, "displayUrl": "https://jorisbaan.nl/2021/03/02/introduction-to-<b>bayesian</b>-deep-learning.html", "snippet": "A <b>Bayesian</b> <b>Neural</b> <b>Network</b> (BNN) is simply posterior inference applied to a <b>neural</b> <b>network</b> architecture. To be precise, a prior distribution is specified for each weight and bias. Because of their huge parameter space, however, inferring the posterior is even more difficult than usual. So why do <b>Bayesian</b> DL at all? The classic answer is to obtain a realistic expression of uncertainty, or calibration. A classifier is considered calibrated if the probability (confidence) of a class prediction ...", "dateLastCrawled": "2022-02-03T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>quick intro to Bayesian neural networks</b> - matthewmcateer.me", "url": "https://matthewmcateer.me/blog/a-quick-intro-to-bayesian-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://matthewmcateer.me/blog/a-<b>quick-intro-to-bayesian-neural-networks</b>", "snippet": "Our model is a <b>neural</b> <b>network</b> with two DenseVariational hidden layers, each having 20 units, and one DenseVariational output layer with one unit. Instead of modeling a full probability distribution p (y \u2223 x, w) p(y \\lvert \\mathbf{x},\\mathbf{w}) p (y \u2223 x, w) as output the <b>network</b> simply outputs the mean of the corresponding Gaussian distribution. In other words, we do not model aleatoric uncertainty here and assume it is known.", "dateLastCrawled": "2021-05-30T11:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bayesian</b> <b>neural</b> networks and out-of-distribution data? - Cross Validated", "url": "https://stats.stackexchange.com/questions/511864/bayesian-neural-networks-and-out-of-distribution-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/511864/<b>bayesian</b>-<b>neural</b>-<b>networks</b>-and-out-of...", "snippet": "In a <b>Bayesian</b> <b>neural</b> <b>network</b> (for classification) the posterior predictive distribution is $$ P(y=c \\mid {\\bf x}, \\mathcal D_{train}) = \\int P(y=c \\mid {\\bf x}, \\theta) p(\\theta \\mid \\mathcal D_{train}) d\\theta $$ Let&#39;s assume that we have enough training data $\\mathcal D_{train}$ such that if $\\bf x$ is quite similar to the training data the uncertainty in the posterior (predictive) prediction is low. So, we assume that in this region we have low aleatoric uncertainty and due to the amount ...", "dateLastCrawled": "2022-01-28T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Neural</b> <b>Network</b> Hyperparameter Tuning using <b>Bayesian</b> Optimization", "url": "https://analyticsindiamag.com/neural-network-hyperparameter-tuning-using-bayesian-optimization/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/<b>neural</b>-<b>network</b>-hyperparameter-tuning-using-<b>bayesian</b>...", "snippet": "There are various techniques <b>like</b> grid search, random search, etc. that are used for this purpose. This process of hyperparameters tuning is usually performed very slowly. The <b>Bayesian</b> statistics can also be used for parameter tuning and also it can make the process faster especially in the case of <b>neural</b> networks. In this article, we are going to discuss the process of hyperparameter tuning in <b>neural</b> networks using <b>Bayesian</b> optimization. The major points that we will discuss here are listed ...", "dateLastCrawled": "2022-02-03T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "GitHub - mainkoon81/<b>Study-09-MachineLearning-D</b>: **DeepLearning** (CNN ...", "url": "https://github.com/mainkoon81/Study-09-MachineLearning-D", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/mainkoon81/<b>Study-09-MachineLearning-D</b>", "snippet": "<b>Bayesian</b> <b>Neural</b> <b>Network</b>. 10 years ago, <b>people</b> used to think that <b>Bayesian</b> methods are mostly suited for small datasets because it&#39;s computationally expensive. In the era of Big data, our <b>Bayesian</b> methods met deep learning, and <b>people</b> started to make some mixture models that has <b>neural</b> networks inside of a probabilistic model.", "dateLastCrawled": "2021-10-29T10:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[2104.14421] What Are <b>Bayesian</b> <b>Neural</b> <b>Network</b> Posteriors Really <b>Like</b> ...", "url": "https://www.reddit.com/r/MachineLearning/comments/n1w1aq/210414421_what_are_bayesian_neural_network/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/n1w1aq/210414421_what_are_<b>bayesian</b>_<b>neural</b>_<b>network</b>", "snippet": "Abstract: The posterior over <b>Bayesian</b> <b>neural</b> <b>network</b> (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as mean-field variational inference or stochastic-gradient Markov chain Monte Carlo (SGMCMC). To investigate foundational questions in <b>Bayesian</b> deep learning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern architectures. We show that (1) BNNs can ...", "dateLastCrawled": "2021-06-24T13:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian</b> vs <b>Neural</b> Networks \u2013 Ehud Reiter&#39;s Blog", "url": "https://ehudreiter.com/2021/07/05/bayesian-vs-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://ehudreiter.com/2021/07/05/<b>bayesian</b>-vs-<b>neural</b>-<b>networks</b>", "snippet": "We have a small <b>group</b> that meets monthly to discuss this, and last week we ended up also talking about why <b>people</b> would use <b>Bayesian</b> models instead of <b>neural</b> networks, focusing on medical decision support (not NLP). Which I found very interesting and thought-provoking. One relatively obvious reason to avoid black-box <b>neural</b> models is justifiability (which relates to explanation). Ie, if I build a medical diagnosis system as a <b>Bayesian</b> model, I can explain to doctors (and regulators) exactly ...", "dateLastCrawled": "2022-02-01T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "The other two outputs were <b>similar</b>. Recent Research on <b>Bayesian</b> <b>Neural</b> Networks The 2021 ICML virtual event was held July 18-24. A search for &quot;<b>bayesian</b> <b>neural</b>&quot; returned over 30 presentations. A brief summary of four of these presentations provides a glimpse into current research on <b>Bayesian</b> <b>neural</b> networks. The two images in Figure 3 are representative pages from the presentations. The point is that research targets a very small <b>group</b> <b>of people</b> with deep mathematical backgrounds and so there ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What&#39;s the likelihood in <b>Bayesian</b> <b>Neural</b> Networks? - Artificial ...", "url": "https://ai.stackexchange.com/questions/26864/whats-the-likelihood-in-bayesian-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/.../26864/whats-the-likelihood-in-<b>bayesian</b>-<b>neural</b>-<b>networks</b>", "snippet": "The likelihood depends on the task that you are solving, so this <b>is similar</b> to traditional <b>neural</b> networks (in fact, even these <b>neural</b> networks have a probabilistic/<b>Bayesian</b> interpretation!).. For binary classification, you should probably use a Bernoulli, which, in practice, corresponds to using a sigmoid with a binary cross-entropy (you can show that the minimization of the cross-entropy is equivalent to the maximization of Bernoulli p.m.f.)", "dateLastCrawled": "2022-01-17T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bayesian</b> <b>neural</b> networks and out-of-distribution data? - Cross Validated", "url": "https://stats.stackexchange.com/questions/511864/bayesian-neural-networks-and-out-of-distribution-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/511864/<b>bayesian</b>-<b>neural</b>-<b>networks</b>-and-out-of...", "snippet": "In a <b>Bayesian</b> <b>neural</b> <b>network</b> (for classification) the posterior predictive distribution is $$ P(y=c \\mid {\\bf x}, \\mathcal D_{train}) = \\int P(y=c \\mid {\\bf x}, \\theta) p(\\theta \\mid \\mathcal D_{train}) d\\theta $$ Let&#39;s assume that we have enough training data $\\mathcal D_{train}$ such that if $\\bf x$ is quite <b>similar</b> to the training data the uncertainty in the posterior (predictive) prediction is low. So, we assume that in this region we have low aleatoric uncertainty and due to the amount ...", "dateLastCrawled": "2022-01-28T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bayesian</b> Fully Convolutional Networks for Brain Image Registration", "url": "https://www.hindawi.com/journals/jhe/2021/5528160/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/jhe/2021/5528160", "snippet": "Moreover, the proposed method introduces <b>group</b> normalization, which is conducive to the <b>network</b> convergence of the <b>Bayesian</b> <b>neural</b> <b>network</b>. Some representative learning-based image registration methods are compared with the proposed method on different image datasets. Experimental results show that the registration accuracy of the proposed method is better than that of the methods, and its antifolding performance is comparable to that of fast image registration and VoxelMorph. Furthermore ...", "dateLastCrawled": "2022-01-29T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Dynamic Bayesian network modeling of</b> fMRI: A comparison of <b>group</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1053811908001195", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1053811908001195", "snippet": "<b>Bayesian</b> <b>network</b> (BN) modeling has recently been introduced as a tool for determining the dependencies between brain regions from functional-magnetic-resonance-imaging (fMRI) data. However, studies to date have yet to explore the optimum way for meaningfully combining individually determined BN models to make <b>group</b> inferences. We contrasted the results from three broad approaches: the \u201cvirtual-typical- subject\u201d (VTS) approach which pools or averages <b>group</b> data as if they are sampled from ...", "dateLastCrawled": "2021-11-27T17:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is the relationship between Deep Belief <b>Network</b> (DBN) and <b>Bayesian</b> ...", "url": "https://www.quora.com/What-is-the-relationship-between-Deep-Belief-Network-DBN-and-Bayesian-Network-or-Belief-Network-I-know-what-is-Bayesian-network-My-question-is-that-is-deep-belief-network-a-kind-of-belief-network-or-it-is-just-a-similar-name", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-relationship-between-Deep-Belief-<b>Network</b>-DBN-and...", "snippet": "Answer (1 of 2): A deep belief <b>network</b> is nowadays referred to a deep <b>neural</b> <b>network</b>. At the time of development it was difficult to get <b>neural</b> <b>network</b> papers published. I think that this name was a rebranding to work around that issue. In a <b>Bayesian</b> <b>network</b>, links model probabilistic dependence...", "dateLastCrawled": "2022-01-06T20:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is <b>the difference between Bayesian Network and Graphical</b> Models ...", "url": "https://www.quora.com/What-is-the-difference-between-Bayesian-Network-and-Graphical-Models", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-difference-between-Bayesian-Network-and-Graphical</b>-Models", "snippet": "Answer (1 of 3): Different communities have used the terms, but they seem to be, sometimes, interchangeable. A <b>Bayesian</b> <b>network</b> is often considered to be a directed graphical model, whereas you can also have undirected graphical models (usually, a Markov random field), factor graphs (which are n...", "dateLastCrawled": "2022-01-28T00:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "GitHub - mainkoon81/<b>Study-09-MachineLearning-D</b>: **DeepLearning** (CNN ...", "url": "https://github.com/mainkoon81/Study-09-MachineLearning-D", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/mainkoon81/<b>Study-09-MachineLearning-D</b>", "snippet": "<b>Bayesian</b> <b>Neural</b> <b>Network</b>. 10 years ago, <b>people</b> used to think that <b>Bayesian</b> methods are mostly suited for small datasets because it&#39;s computationally expensive. In the era of Big data, our <b>Bayesian</b> methods met deep learning, and <b>people</b> started to make some mixture models that has <b>neural</b> networks inside of a probabilistic model.", "dateLastCrawled": "2021-10-29T10:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[2104.14421] What Are <b>Bayesian</b> <b>Neural</b> <b>Network</b> Posteriors Really Like ...", "url": "https://www.reddit.com/r/MachineLearning/comments/n1w1aq/210414421_what_are_bayesian_neural_network/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/n1w1aq/210414421_what_are_<b>bayesian</b>_<b>neural</b>_<b>network</b>", "snippet": "Abstract: The posterior over <b>Bayesian</b> <b>neural</b> <b>network</b> (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as mean-field variational inference or stochastic-gradient Markov chain Monte Carlo (SGMCMC). To investigate foundational questions in <b>Bayesian</b> deep learning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern architectures. We show that (1) BNNs can ...", "dateLastCrawled": "2021-06-24T13:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "At first <b>thought</b>, <b>Bayesian</b> <b>neural</b> networks don&#39;t seem to make much sense. However, BNNs have two advantages over standard <b>neural</b> networks. First, the built-in variability in BNNs makes them resistant to model overfitting. Model overfitting occurs when a <b>neural</b> <b>network</b> is trained too well. Even though the trained model predicts with high accuracy on the training data, when presented with new previously unseen data, the overfitted model predicts poorly. A second advantage of <b>Bayesian</b> <b>neural</b> ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian</b> vs <b>Neural</b> Networks \u2013 Ehud Reiter&#39;s Blog", "url": "https://ehudreiter.com/2021/07/05/bayesian-vs-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://ehudreiter.com/2021/07/05/<b>bayesian</b>-vs-<b>neural</b>-<b>networks</b>", "snippet": "We have a small <b>group</b> that meets monthly to discuss this, and last week we ended up also talking about why <b>people</b> would use <b>Bayesian</b> models instead of <b>neural</b> networks, focusing on medical decision support (not NLP). Which I found very interesting and <b>thought</b>-provoking. One relatively obvious reason to avoid black-box <b>neural</b> models is justifiability (which relates to explanation). Ie, if I build a medical diagnosis system as a <b>Bayesian</b> model, I <b>can</b> explain to doctors (and regulators) exactly ...", "dateLastCrawled": "2022-02-01T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian Network - The Decision Lab</b>", "url": "https://thedecisionlab.com/reference-guide/statistics/bayesian-network/", "isFamilyFriendly": true, "displayUrl": "https://thedecisionlab.com/reference-guide/statistics/<b>bayesian-network</b>", "snippet": "Silver collected data months prior to voting on how <b>people</b> <b>thought</b> they would vote. Of course, there <b>can</b> always be discrepancies between how <b>people</b> think they will vote and how they actually vote. Luckily, that did not pose an issue for Silver, because Bayes\u2019 theorem allows shifts in hypothesis depending on new information collected. Silver started off with a \u2018nowcast\u2019, which determined the probability of the outcome of each state if voting was to happen on any given day. Various ...", "dateLastCrawled": "2022-01-30T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bayesian</b> <b>Network</b> as a Decision Tool for Predicting ALS Disease", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7912628/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7912628", "snippet": "<b>Bayesian</b> <b>network</b> has produced more successful results than other methods according to all comparison criteria for the Neurological Control <b>group</b>, as in the ALS <b>group</b>. For this <b>group</b>, the <b>Bayesian</b> <b>Network</b>\u2019s ACC value has been found as (0.902). The Kappa values of other methods indicate that the results obtained are random, while the Kappa value (0.677) was found for <b>Bayesian</b> <b>network</b>.", "dateLastCrawled": "2022-01-11T04:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Comprehensive Introduction to <b>Bayesian</b> Deep Learning - Joris Baan", "url": "https://jorisbaan.nl/2021/03/02/introduction-to-bayesian-deep-learning.html", "isFamilyFriendly": true, "displayUrl": "https://jorisbaan.nl/2021/03/02/introduction-to-<b>bayesian</b>-deep-learning.html", "snippet": "\u201cA <b>neural</b> <b>network</b> <b>can</b> represent many models that are consistent with our observations. By selecting only one, in a classical procedure, we lose uncertainty when the models disagree for a test point.\u201d Recent Approaches To (Approximate) <b>Bayesian</b> Deep Learning . A number <b>of people</b> have recently been trying to combine the advantages of a traditional <b>neural</b> <b>network</b> (e.g. computationally efficient training using SGD &amp; back propagation) with the advantages of a <b>Bayesian</b> approach (e.g ...", "dateLastCrawled": "2022-02-03T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "machine learning - What are the <b>downsides of bayesian neural networks</b> ...", "url": "https://stats.stackexchange.com/questions/311008/what-are-the-downsides-of-bayesian-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/311008", "snippet": "<b>Bayesian</b> <b>neural</b> nets (BNN) are very popular topic. With development of variational approximation it became possible to train such models much faster then with Monte Carlo sampling. BNNs allow such interesting features as natural regularisation and even uncertainty estimation. So, the question is: why haven&#39;t we still completely migrated on BNNs? I <b>can</b> assume that variational inference does not provide enough accuracy. Is it the only reason? machine-learning deep-learning <b>bayesian</b>-<b>network</b> ...", "dateLastCrawled": "2022-01-07T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Brief <b>Introduction to Graphical Models and Bayesian Networks</b>", "url": "https://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html", "snippet": "<b>Neural</b> Computation 11(2) (1999) pp.305-345 Temporal models Dynamic <b>Bayesian</b> Networks (DBNs) are directed graphical models of stochastic processes. They generalise hidden Markov models (HMMs) and linear dynamical systems (LDSs) by representing the hidden (and observed) state in terms of state variables, which <b>can</b> have complex interdependencies. The graphical structure provides an easy way to specify these conditional independencies, and hence to provide a compact parameterization of the model ...", "dateLastCrawled": "2022-02-01T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Why hasn&#39;t the <b>Bayesian network been as successful</b> as the Deep <b>Neural</b> ...", "url": "https://www.quora.com/Why-hasnt-the-Bayesian-network-been-as-successful-as-the-Deep-Neural-Network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-hasnt-the-<b>Bayesian-network-been-as-successful</b>-as-the-Deep...", "snippet": "Answer (1 of 5): Well, the definition of \u201csuccessful\u201d is important, here. <b>Bayesian</b> networks are arguably more successful than deep <b>neural</b> networks to date. They are widely applied across industries and <b>can</b> readily be used for inference, modelling, and prediction. Presumably your question is real...", "dateLastCrawled": "2022-01-15T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "machine learning - <b>Bayesian</b> Perceptron: Why to marginalize over neuron ...", "url": "https://ai.stackexchange.com/questions/26950/bayesian-perceptron-why-to-marginalize-over-neurons-output-instead-of-its-wei", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/26950/<b>bayesian</b>-perceptron-why-to-marginalize...", "snippet": "I found a very interesting paper on the internet that tries to apply <b>Bayesian</b> inference with a gradient-free online-learning approach: <b>Bayesian</b> Perceptron: Towards fully <b>Bayesian</b> <b>Neural</b> Networks. I would love to understand this work, but unfortunately I am reaching my limits with my <b>Bayesian</b> knowledge.", "dateLastCrawled": "2022-01-21T16:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Bayesian</b> Dark Knowledge &lt;paper by Kevin Murphy&#39;s <b>group</b> at Google ...", "url": "https://www.reddit.com/r/MachineLearning/comments/3a2crl/bayesian_dark_knowledge_paper_by_kevin_murphys/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/MachineLearning/comments/3a2crl/<b>bayesian</b>_dark_knowledge_paper...", "snippet": "e.g. if you make your <b>neural</b> <b>network</b> 1 layer then it should be able to match the performance of a linear regression baseline, if it doesn\u2019t then you have a bug! e.g. if adding a feature improves the performance of linear regression then it should probably also improve the performance of your <b>neural</b> net unless you have a bug! Hyperparameter optimisation <b>can</b> help a bit (especially for the learning rate) but in general there are default hyperparameters that <b>can</b> do quite well and so closely ...", "dateLastCrawled": "2021-03-24T12:01:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bayesian</b> <b>Network</b> as a Decision Tool for Predicting ALS Disease", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7912628/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7912628", "snippet": "<b>Bayesian</b> <b>network</b> has produced more successful results than other methods according to all comparison criteria for the Neurological Control <b>group</b>, as in the ALS <b>group</b>. For this <b>group</b>, the <b>Bayesian</b> <b>Network</b>\u2019s ACC value has been found as (0.902). The Kappa values of other methods indicate that the results obtained are random, while the Kappa value (0.677) was found for <b>Bayesian</b> <b>network</b>.", "dateLastCrawled": "2022-01-11T04:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian</b> Fully Convolutional Networks for Brain Image Registration", "url": "https://www.hindawi.com/journals/jhe/2021/5528160/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/jhe/2021/5528160", "snippet": "Moreover, the proposed method introduces <b>group</b> normalization, which is conducive to the <b>network</b> convergence of the <b>Bayesian</b> <b>neural</b> <b>network</b>. Some representative learning-based image registration methods are <b>compared</b> with the proposed method on different image datasets. Experimental results show that the registration accuracy of the proposed method is better than that of the methods, and its antifolding performance is comparable to that of fast image registration and VoxelMorph. Furthermore ...", "dateLastCrawled": "2022-01-29T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "A <b>Bayesian</b> <b>neural</b> <b>network</b> (BNN) has weights and biases that are probability distributions instead of single fixed values. Each time a <b>Bayesian</b> <b>neural</b> <b>network</b> computes output, the values of the weights and biases will change slightly, and so the computed output will be slightly different every time. To make a prediction using a BNN, one approach is to feed the input to the BNN several times and average the results. At first thought, <b>Bayesian</b> <b>neural</b> networks don&#39;t seem to make much sense ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "machine learning - Difference between Bayes <b>network</b>, <b>neural</b> <b>network</b> ...", "url": "https://stats.stackexchange.com/questions/94511/difference-between-bayes-network-neural-network-decision-tree-and-petri-nets", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/94511", "snippet": "<b>Bayesian</b> <b>Network</b>: The <b>Bayesian</b> <b>Network</b> is a directed acyclic graph, which more like the flowchart, only that the flow chart <b>can</b> have cyclic loops. The <b>Bayesian</b> <b>network</b> unlike the flow chart <b>can</b> have multiple start points. It basically traces the propagation of events across multiple ambiguous points, where the event diverges probabilistically between pathways. Obviously, at any given point in the <b>network</b>, the probability of that node being visited is dependent on the joint probability of the ...", "dateLastCrawled": "2022-01-28T22:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "machine learning - What are the <b>downsides of bayesian neural networks</b> ...", "url": "https://stats.stackexchange.com/questions/311008/what-are-the-downsides-of-bayesian-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/311008", "snippet": "<b>Bayesian</b> <b>neural</b> nets (BNN) are very popular topic. With development of variational approximation it became possible to train such models much faster then with Monte Carlo sampling. BNNs allow such interesting features as natural regularisation and even uncertainty estimation. So, the question is: why haven&#39;t we still completely migrated on BNNs? I <b>can</b> assume that variational inference does not provide enough accuracy. Is it the only reason? machine-learning deep-learning <b>bayesian</b>-<b>network</b> ...", "dateLastCrawled": "2022-01-07T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bayesian Belief Networks</b>: An Introduction In 6 Easy Points", "url": "https://www.jigsawacademy.com/blogs/data-science/bayesian-belief-network", "isFamilyFriendly": true, "displayUrl": "https://www.<b>jigsawacademy</b>.com/blogs/data-science/<b>bayesian</b>-belief-<b>network</b>", "snippet": "Hence, only the person creating the <b>network</b> <b>can</b> exploit causal influences. <b>Neural</b> networks are an advantage <b>compared</b> to this, as they learn different patterns and aren\u2019t limited to only the creator. The <b>Bayesian</b> <b>network</b> fails to define cyclic relationships\u2014for example, deflection of airplane wings and fluid pressure field around it. The ...", "dateLastCrawled": "2022-02-03T06:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Bayesian</b> <b>Neural</b> <b>Network</b> Classification of Head Movement Direction ...", "url": "https://www.researchgate.net/publication/224634487_Bayesian_Neural_Network_Classification_of_Head_Movement_Direction_using_Various_Advanced_Optimisation_Training_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/224634487_<b>Bayesian</b>_<b>Neural</b>_<b>Network</b>...", "snippet": "<b>Bayesian</b> <b>Neural</b> <b>Network</b> Classification of Head Movement <b>Direction using Various Advanced Optimisation Training Algorithms</b> March 2006 DOI: 10.1109/BIOROB.2006.1639224", "dateLastCrawled": "2021-08-09T14:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A <b>quick intro to Bayesian neural networks</b> - matthewmcateer.me", "url": "https://matthewmcateer.me/blog/a-quick-intro-to-bayesian-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://matthewmcateer.me/blog/a-<b>quick-intro-to-bayesian-neural-networks</b>", "snippet": "Pretty impressive! This illustrates one of the other add-ons we <b>can</b> easily make for <b>bayesian</b> <b>neural</b> networks: a probability cutoff. In this case, if none of our probabilities exceed 0.2, we <b>can</b> get our <b>network</b> to refuse to classify the images. Of course, it wasn\u2019t always like this. It took our <b>network</b> a while before it was correctly able to ...", "dateLastCrawled": "2021-05-30T11:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Naive Bayesian Classification</b>. The Naive <b>Bayesian</b> classifier is based ...", "url": "https://medium.com/incwell-bootcamp/naive-bayesian-classification-2c585fbe1817", "isFamilyFriendly": true, "displayUrl": "https://medium.com/incwell-bootcamp/<b>naive-bayesian-classification</b>-2c585fbe1817", "snippet": "It is a multi-layer feed forward <b>neural</b> <b>network</b> or simply <b>neural</b> <b>network</b> which is easy to apply and predicts the class of test data set fast. It requires less training data <b>compared</b> to other models.", "dateLastCrawled": "2022-01-27T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>can</b> I use <b>Bayesian networks for unsupervised learning</b>? If it is ...", "url": "https://www.quora.com/How-can-I-use-Bayesian-networks-for-unsupervised-learning-If-it-is-possible-is-there-an-example-where-you-have-applied-Bayesian-Networks-for-unsupervised-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>can</b>-I-use-<b>Bayesian-networks-for-unsupervised-learning</b>-If-it...", "snippet": "Answer (1 of 2): It&#39;s more of a pathway-mining method. I&#39;ve used it to explore connections between factors before, but it&#39;s more of an analysis to explore relationships in the data, rather than a clustering-type analysis. It&#39;s a bit of a conditional clustering of variables rather than a clusterin...", "dateLastCrawled": "2022-01-15T03:58:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>machine</b> <b>learning</b> approach to <b>Bayesian</b> parameter estimation | npj ...", "url": "https://www.nature.com/articles/s41534-021-00497-w", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-021-00497-w", "snippet": "The parameter estimation discussed in this manuscript is divided in two parts: i) a <b>neural</b> <b>network</b> is trained and ii) <b>Bayesian</b> estimation performed on a test set, which we detail below.", "dateLastCrawled": "2022-02-03T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "9.7. <b>Bayesian</b> <b>neural</b> networks \u2014 <b>Learning</b> from data", "url": "https://furnstahl.github.io/Physics-8820/notebooks/Machine_learning/Bayesian_neural_networks_tif285.html", "isFamilyFriendly": true, "displayUrl": "https://furnstahl.github.io/.../<b>Machine</b>_<b>learning</b>/<b>Bayesian</b>_<b>neural</b>_<b>networks</b>_tif285.html", "snippet": "<b>Bayesian</b> <b>neural</b> networks differ from plain <b>neural</b> networks in that their weights are assigned a probability distribution instead of a single value or point estimate. These probability distributions describe the uncertainty in weights and can be used to estimate uncertainty in predictions. Training a <b>Bayesian</b> <b>neural</b> <b>network</b> via variational inference learns the parameters of these distributions instead of the weights directly.", "dateLastCrawled": "2021-12-21T06:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bayesian</b> <b>Neural Network</b> Series Post 2: Background Knowledge | by Kumar ...", "url": "https://medium.com/neuralspace/bayesian-neural-network-series-post-2-background-knowledge-fdec6ac62d43", "isFamilyFriendly": true, "displayUrl": "https://medium.com/<b>neural</b>space/<b>bayesian</b>-<b>neural-network</b>-series-post-2-background...", "snippet": "I will try to brief the <b>neural</b> networks <b>analogy</b> with the brain and will spend more time explaining the Probabilistic <b>Machine</b> <b>Learning</b> segments that we will work on in future. Brain Analogies. A ...", "dateLastCrawled": "2022-01-30T12:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Researchers Explore <b>Bayesian</b> <b>Neural</b> Networks -- Pure AI", "url": "https://pureai.com/articles/2021/09/07/bayesian-neural-networks.aspx", "isFamilyFriendly": true, "displayUrl": "https://pureai.com/articles/2021/09/07/<b>bayesian</b>-<b>neural</b>-<b>networks</b>.aspx", "snippet": "<b>Bayesian</b> <b>neural</b> networks are best explained using an <b>analogy</b> example. Suppose that instead of a <b>neural</b> <b>network</b>, you have a prediction equation y = (8.5 * x1) + (9.5 * x2) + 2.5 where y is the predicted income of an employee, x1 is normalized age, and x2 is years of job tenure. The predicted income of a 30-year old who has been on the job for 4 years would be y = (8.5 * 3.0) + (9.5 * 4.0) + 2.5 = 64.5 = $64,500. If you feed the same (age, tenure) input of (3.0, 4.0) to the prediction equation ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep <b>neural</b> <b>network</b> models, and it has been used for conducting ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bayesian Belief Network in Artificial Intelligence</b> - Javatpoint", "url": "https://www.javatpoint.com/bayesian-belief-network-in-artificial-intelligence", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>bayesian-belief-network-in-artificial-intelligence</b>", "snippet": "<b>Bayesian Belief Network in artificial intelligence</b>. <b>Bayesian</b> belief <b>network</b> is key computer technology for dealing with probabilistic events and to solve a problem which has uncertainty. We can define a <b>Bayesian</b> <b>network</b> as: &quot;A <b>Bayesian</b> <b>network</b> is a probabilistic graphical model which represents a set of variables and their conditional ...", "dateLastCrawled": "2022-02-02T21:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "ML MCQ all 5 - <b>Machine</b> <b>Learning</b> MCQ&#39;s - KCS 052 - StuDocu", "url": "https://www.studocu.com/in/document/dr-apj-abdul-kalam-technical-university/machine-learning-techniques/ml-mcq-all-5-machine-learning-mcqs/16412586", "isFamilyFriendly": true, "displayUrl": "https://www.studocu.com/.../ml-mcq-all-5-<b>machine</b>-<b>learning</b>-mcqs/16412586", "snippet": "Which of the following is not numerical functions in the various function representation of <b>Machine</b> <b>Learning</b>? (A) <b>Neural</b> <b>Network</b> (B) Support Vector Machines (C) Case-based (D) Linear Regression. Answer Correct option is C . FIND-S Algorithm starts from the most specific hypothesis and generalize it by considering only ____ examples. (A) Negative (B) Positive (C) Negative or Positive (D) None of the above; Answer Correct option is B. FIND-S algorithm ignores ___ examples. (A) Negative (B ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Neural Networks and Learning Machines</b> - uniba.sk", "url": "https://dai.fmph.uniba.sk/courses/NN/haykin.neural-networks.3ed.2009.pdf", "isFamilyFriendly": true, "displayUrl": "https://dai.fmph.uniba.sk/courses/NN/haykin.<b>neural</b>-<b>networks</b>.3ed.2009.pdf", "snippet": "<b>Neural Networks and Learning Machines</b> Third Edition Simon Haykin McMaster University Hamilton, Ontario, Canada New York Boston San Francisco London Toronto Sydney Tokyo Singapore Madrid Mexico City Munich Paris Cape Town Hong Kong Montreal. Library of Congress Cataloging-in-Publication Data Haykin, Simon <b>Neural networks and learning machines</b> / Simon Haykin.\u20143rd ed. p. cm. Rev. ed of: <b>Neural</b> networks. 2nd ed., 1999. Includes bibliographical references and index. ISBN-13: 978-0-13-147139-9 ...", "dateLastCrawled": "2022-02-02T00:48:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bayesian neural network)  is like +(group of people)", "+(bayesian neural network) is similar to +(group of people)", "+(bayesian neural network) can be thought of as +(group of people)", "+(bayesian neural network) can be compared to +(group of people)", "machine learning +(bayesian neural network AND analogy)", "machine learning +(\"bayesian neural network is like\")", "machine learning +(\"bayesian neural network is similar\")", "machine learning +(\"just as bayesian neural network\")", "machine learning +(\"bayesian neural network can be thought of as\")", "machine learning +(\"bayesian neural network can be compared to\")"]}