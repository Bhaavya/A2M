{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Learning</b> Invariances in Neural Networks | DeepAI", "url": "https://deepai.org/publication/learning-invariances-in-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>learning</b>-<b>invariance</b>s-in-neural-networks", "snippet": "Given <b>data</b> that has <b>invariance</b> to some augmentation, the training loss will not be improved by widening our distribution over this augmentation, even if it helps generalization: we would want a model to be invariant to rotations of a \u20186\u2019 <b>up</b> until it looks more <b>like</b> a \u20189\u2019, but no <b>invariance</b> will achieve <b>the same</b> training loss. However, it is sufficient to add a simple regularization term to encourage the model to discover invariances. In practice we find that the final distribution ...", "dateLastCrawled": "2022-01-28T13:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A high-bias, low-variance introduction to <b>Machine</b> <b>Learning</b> for physicists", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6688775/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6688775", "snippet": "<b>Machine</b> <b>Learning</b> (ML), <b>data</b> science, and statistics are fields that describe how to learn from, and make predictions about, <b>data</b>. The availability of big datasets is a hallmark of modern science, including physics, where <b>data</b> analysis has become an important component of diverse areas, such as experimental particle physics, observational astronomy and cosmology, condensed matter physics, biophysics, and quantum computing. Moreover, ML and <b>data</b> science are playing increasingly important roles ...", "dateLastCrawled": "2022-02-02T11:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Review of deep <b>learning</b>: concepts, CNN ... - Journal of Big <b>Data</b>", "url": "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00444-8", "isFamilyFriendly": true, "displayUrl": "https://journalofbig<b>data</b>.springeropen.com/articles/10.1186/s40537-021-00444-8", "snippet": "In the last few years, the deep <b>learning</b> (DL) computing paradigm has been deemed the Gold Standard in the <b>machine</b> <b>learning</b> (ML) community. Moreover, it has gradually become the most widely used computational approach in the field of ML, thus achieving outstanding <b>results</b> on several complex cognitive tasks, matching or even beating those provided by human performance. One of the benefits of DL is the ability to learn massive amounts of <b>data</b>. The DL field has grown fast in the last few years ...", "dateLastCrawled": "2022-02-02T04:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Amp: A <b>modular approach to machine learning in atomistic simulations</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0010465516301266", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0010465516301266", "snippet": "In this scheme, permutation <b>invariance</b> is achieved by assuming that <b>the same</b> <b>machine</b>-<b>learning</b> model parameters (for example weights and biases for neural networks) apply to atoms of <b>the same</b> chemical species. This scheme can always be used for atomic images with different numbers of atoms (system sizes). Also, either or both the training and test <b>data</b> sets can be inhomogeneous with respect to periodicity of atomic configurations. Importantly, the atom-centered scheme relies on a locality ...", "dateLastCrawled": "2021-12-17T22:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning Papers Notes (CNN</b>) - <b>Learning</b>-Deep-<b>Learning</b>", "url": "https://patrick-llgc.github.io/Learning-Deep-Learning/start/first_cnn_papers_notes.html", "isFamilyFriendly": true, "displayUrl": "https://patrick-llgc.github.io/<b>Learning</b>-Deep-<b>Learning</b>/start/first_cnn_papers_notes.html", "snippet": "Multi-scale training takes in images with varying image <b>size</b> during training (varying <b>input</b> <b>size</b> by multiples of 32, the downscaling factor of the network). This +1.5% mAP. This is akin to <b>data</b> augmentation. It keeps <b>the same</b> network architecture and weighting as the whole network is convolutional (no FC layers). This allows detection of differently <b>scaled</b> images, a smooth tradeoff between speed and accuracy.", "dateLastCrawled": "2022-02-03T09:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning scale-variant and scale-invariant features</b> for deep image ...", "url": "https://www.sciencedirect.com/science/article/pii/S0031320316301224", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320316301224", "snippet": "A 2\u00d72 filter applied to the output of 4 filters of <b>the same</b> <b>size</b> in a lower layer corresponds to a 4\u00d74 region in <b>the input</b> image. Because training CNNs on an image dataset <b>results</b> in a hierarchy of feature representations with increasing spatial extent, a network capable of analysing the entire range from fine to coarse visual characteristics in an image requires many stages in order to capture all the intermediate scales. Moreover, as to not discard information by subsampling between ...", "dateLastCrawled": "2022-01-12T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Time Series Prediction with LSTM Recurrent Neural Networks in Python ...", "url": "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/time-series-prediction-lstm-recurrent-neural...", "snippet": "Time series prediction problems are a difficult type of predictive modeling problem. Unlike regression predictive modeling, time series also adds the complexity of a sequence dependence among <b>the input</b> variables. A powerful type of neural network designed to handle sequence dependence is called recurrent neural networks. The Long Short-Term Memory network or LSTM network is a type of recurrent neural network used", "dateLastCrawled": "2022-02-02T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Feature extraction and <b>machine</b> <b>learning</b> techniques for identifying ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255507", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255507", "snippet": "<b>Machine</b> <b>learning</b> applications rely on a consistent unit of analysis to produce meaningful <b>results</b>. Accordingly, this step of our analysis pipeline is designed to disaggregate complex map scans, which include a wide variety of building types, labels, text, and other information, into a collection of individual building-level images, allowing us to feed a consistent set of discretely coded building-level <b>data</b> into our ensemble <b>machine</b> <b>learning</b> classifier. We target circular infrastructure ...", "dateLastCrawled": "2021-12-31T15:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Should <b>the input</b> <b>of a convolution neural network be square</b>? - Quora", "url": "https://www.quora.com/Should-the-input-of-a-convolution-neural-network-be-square", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Should-<b>the-input</b>-<b>of-a-convolution-neural-network-be-square</b>", "snippet": "Answer: In short, there is no need for <b>the input</b> of a convolutional neural network to be square. More elaborate answer: Requirement for <b>the input</b> of a convolutional neural network (CNN) to be square came from the (now obsolete) requirement for <b>the input</b> to have fixed <b>size</b>. If you deal with imag...", "dateLastCrawled": "2021-12-31T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Understanding Machine Learning: From Theory</b> to Algorithms [pdf] [PDF ...", "url": "https://authorzilla.com/JjpMG/understanding-machine-learning-from-theory-to-algorithms-pdf.html", "isFamilyFriendly": true, "displayUrl": "https://authorzilla.com/JjpMG/<b>understanding-machine-learning-from-theory</b>-to-<b>algorithms</b>...", "snippet": "The question is therefore <b>whether</b> there exist a <b>learning</b> <b>algorithm</b> A and a training set <b>size</b> m, such that for every distribution D, if A receives m i.i.d. examples from D, there is a high chance it outputs a predictor h that has a low risk. The first part of this chapter addresses this question formally. The No-Free- Lunch theorem states that ...", "dateLastCrawled": "2022-02-03T04:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A high-bias, low-variance introduction to <b>Machine</b> <b>Learning</b> for physicists", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6688775/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6688775", "snippet": "<b>Machine</b> <b>Learning</b> (ML), <b>data</b> science, and statistics are fields that describe how to learn from, and make predictions about, <b>data</b>. The availability of big datasets is a hallmark of modern science, including physics, where <b>data</b> analysis has become an important component of diverse areas, such as experimental particle physics, observational astronomy and cosmology, condensed matter physics, biophysics, and quantum computing. Moreover, ML and <b>data</b> science are playing increasingly important roles ...", "dateLastCrawled": "2022-02-02T11:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A deep <b>learning</b> framework for neuroscience", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7115933/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7115933", "snippet": "But, some readers may doubt <b>whether</b> the sort of objective functions used in <b>machine</b> <b>learning</b> are relevant to the brain. For example, the cross-entropy objective function used in ANNs trained on categorization tasks is unlikely to be used in the brain, since it requires specification of the correct category for each sensory <b>input</b>. Other objective functions are more ecologically plausible, though. Examples include the description length objective function used in predictive coding models", "dateLastCrawled": "2022-01-25T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Amp: A <b>modular approach to machine learning in atomistic simulations</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0010465516301266", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0010465516301266", "snippet": "In this scheme, permutation <b>invariance</b> is achieved by assuming that <b>the same</b> <b>machine</b>-<b>learning</b> model parameters (for example weights and biases for neural networks) apply to atoms of <b>the same</b> chemical species. This scheme can always be used for atomic images with different numbers of atoms (system sizes). Also, either or both the training and test <b>data</b> sets can be inhomogeneous with respect to periodicity of atomic configurations. Importantly, the atom-centered scheme relies on a locality ...", "dateLastCrawled": "2021-12-17T22:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning Papers Notes (CNN</b>) - <b>Learning</b>-Deep-<b>Learning</b>", "url": "https://patrick-llgc.github.io/Learning-Deep-Learning/start/first_cnn_papers_notes.html", "isFamilyFriendly": true, "displayUrl": "https://patrick-llgc.github.io/<b>Learning</b>-Deep-<b>Learning</b>/start/first_cnn_papers_notes.html", "snippet": "Multi-scale training takes in images with varying image <b>size</b> during training (varying <b>input</b> <b>size</b> by multiples of 32, the downscaling factor of the network). This +1.5% mAP. This is akin to <b>data</b> augmentation. It keeps <b>the same</b> network architecture and weighting as the whole network is convolutional (no FC layers). This allows detection of differently <b>scaled</b> images, a smooth tradeoff between speed and accuracy.", "dateLastCrawled": "2022-02-03T09:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Feature extraction and <b>machine</b> <b>learning</b> techniques for identifying ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255507", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255507", "snippet": "A five-fold cross-validation approach <b>produces</b> five separate model test <b>results</b>, each of which is tested on 20% (N = 1,336) of the total training <b>data</b>. For CNN model training, the four folds selected for each model training iteration, representing 80% of the dataset in total, were further split into training and validation samples (85%, N = 4,544 and 15%, N = 802, respectively). Validation <b>data</b> are used to iteratively assess CNN model fit across all 80 training epochs\u2013an approach that ...", "dateLastCrawled": "2021-12-31T15:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Time Series Prediction with LSTM Recurrent Neural Networks in Python ...", "url": "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/time-series-prediction-lstm-recurrent-neural...", "snippet": "Time series prediction problems are a difficult type of predictive modeling problem. Unlike regression predictive modeling, time series also adds the complexity of a sequence dependence among <b>the input</b> variables. A powerful type of neural network designed to handle sequence dependence is called recurrent neural networks. The Long Short-Term Memory network or LSTM network is a type of recurrent neural network used", "dateLastCrawled": "2022-02-02T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Should <b>the input</b> <b>of a convolution neural network be square</b>? - Quora", "url": "https://www.quora.com/Should-the-input-of-a-convolution-neural-network-be-square", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Should-<b>the-input</b>-<b>of-a-convolution-neural-network-be-square</b>", "snippet": "Answer: In short, there is no need for <b>the input</b> of a convolutional neural network to be square. More elaborate answer: Requirement for <b>the input</b> of a convolutional neural network (CNN) to be square came from the (now obsolete) requirement for <b>the input</b> to have fixed <b>size</b>. If you deal with imag...", "dateLastCrawled": "2021-12-31T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Understanding Machine Learning: From Theory</b> to Algorithms [pdf] [PDF ...", "url": "https://authorzilla.com/JjpMG/understanding-machine-learning-from-theory-to-algorithms-pdf.html", "isFamilyFriendly": true, "displayUrl": "https://authorzilla.com/JjpMG/<b>understanding-machine-learning-from-theory</b>-to-<b>algorithms</b>...", "snippet": "The question is therefore <b>whether</b> there exist a <b>learning</b> <b>algorithm</b> A and a training set <b>size</b> m, such that for every distribution D, if A receives m i.i.d. examples from D, there is a high chance it outputs a predictor h that has a low risk. The first part of this chapter addresses this question formally. The No-Free- Lunch theorem states that ...", "dateLastCrawled": "2022-02-03T04:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Towards the One <b>Learning</b> <b>Algorithm</b> Hypothesis: A System-theoretic ...", "url": "https://www.researchgate.net/publication/356818078_Towards_the_One_Learning_Algorithm_Hypothesis_A_System-theoretic_Approach", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/356818078_Towards_the_One_<b>Learning</b>_<b>Algorithm</b>...", "snippet": "Regarding (iii), we introduce a novel <b>learning</b> <b>algorithm</b> that constructs progressively growing knowledge representations in multiple resolutions. The proposed <b>algorithm</b> is an extension of the ...", "dateLastCrawled": "2022-01-25T01:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Convolutional Neural Network for Copy-Move Forgery Detection</b>", "url": "https://www.researchgate.net/publication/336532316_Convolutional_Neural_Network_for_Copy-Move_Forgery_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/336532316_<b>Convolutional_Neural_Network_for</b>...", "snippet": "the training cycle, for <b>the same</b> <b>data</b> in <b>the same</b> training environment, using minibatch 64, there are 154 iterations and for 7 epochs, there are 22 iterations for each epoch. On the other hand ...", "dateLastCrawled": "2022-01-25T20:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A high-bias, low-variance introduction to <b>Machine</b> <b>Learning</b> for physicists", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6688775/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6688775", "snippet": "<b>Machine</b> <b>Learning</b> (ML), <b>data</b> science, and statistics are fields that describe how to learn from, and make predictions about, <b>data</b>. The availability of big datasets is a hallmark of modern science, including physics, where <b>data</b> analysis has become an important component of diverse areas, such as experimental particle physics, observational astronomy and cosmology, condensed matter physics, biophysics, and quantum computing. Moreover, ML and <b>data</b> science are playing increasingly important roles ...", "dateLastCrawled": "2022-02-02T11:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A deep <b>learning</b> framework for neuroscience", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7115933/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7115933", "snippet": "But, some readers may doubt <b>whether</b> the sort of objective functions used in <b>machine</b> <b>learning</b> are relevant to the brain. For example, the cross-entropy objective function used in ANNs trained on categorization tasks is unlikely to be used in the brain, since it requires specification of the correct category for each sensory <b>input</b>. Other objective functions are more ecologically plausible, though. Examples include the description length objective function used in predictive coding models", "dateLastCrawled": "2022-01-25T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Understanding Machine Learning: From Theory</b> to Algorithms | Keep ...", "url": "https://www.academia.edu/40679311/Understanding_Machine_Learning_From_Theory_to_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/40679311/<b>Understanding_Machine_Learning_From_Theory</b>_to_<b>Algorithms</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-23T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Time Series Prediction with LSTM Recurrent Neural Networks in Python ...", "url": "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/time-series-prediction-lstm-recurrent-neural...", "snippet": "Time series prediction problems are a difficult type of predictive modeling problem. Unlike regression predictive modeling, time series also adds the complexity of a sequence dependence among <b>the input</b> variables. A powerful type of neural network designed to handle sequence dependence is called recurrent neural networks. The Long Short-Term Memory network or LSTM network is a type of recurrent neural network used", "dateLastCrawled": "2022-02-02T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Bishop Pattern Recognition And Machine Learning Springer</b> | Xinyue ...", "url": "https://www.academia.edu/34528598/Bishop_Pattern_Recognition_And_Machine_Learning_Springer", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/34528598/<b>Bishop_Pattern_Recognition_And_Machine_Learning_Springer</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-02T07:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Convolution</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/mathematics/convolution", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/mathematics/<b>convolution</b>", "snippet": "<b>Convolution</b> leverages three important ideas that <b>can</b> help improve a <b>machine</b> <b>learning</b> system: Sparse interactions parameter sharing equivariant representations. (Goodfellow et al., 2016, p. 335). We <b>can</b> cite, also, the valid <b>convolution</b>, in which. all pixels in the output are a function of <b>the same</b> number of pixels in <b>the input</b>, so the behavior of an output pixel is somewhat more regular. However, the <b>size</b> of the output shrinks at each layer. If <b>the input</b> image has width m and the kernel has ...", "dateLastCrawled": "2022-01-18T14:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Understanding Machine Learning: From Theory</b> to Algorithms [pdf] [PDF ...", "url": "https://authorzilla.com/JjpMG/understanding-machine-learning-from-theory-to-algorithms-pdf.html", "isFamilyFriendly": true, "displayUrl": "https://authorzilla.com/JjpMG/<b>understanding-machine-learning-from-theory</b>-to-<b>algorithms</b>...", "snippet": "The learner processes <b>input</b> <b>data</b> with the goal of coming <b>up</b> with some summary, or compressed version of that <b>data</b>. Clustering a <b>data</b> set into subsets of similar objets is a typical example of such a task. There is also an intermediate <b>learning</b> setting in which, while the training examples contain more information than the test examples, the learner is required to predict even more information for the test exam- ples. For example, one may try to learn a value function that describes for each ...", "dateLastCrawled": "2022-02-03T04:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Protein model quality assessment using 3D oriented convolutional</b> neural ...", "url": "https://www.researchgate.net/publication/335921632_Protein_model_quality_assessment_using_3D_oriented_convolutional_neural_networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335921632_Protein_model_quality_assessment...", "snippet": "The first covers single-model quality assessment approaches, which take a single structural model as an <b>input</b>, extract features that <b>can</b> reflect model information, and use <b>machine</b> <b>learning</b> methods ...", "dateLastCrawled": "2022-01-02T07:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Should <b>the input</b> <b>of a convolution neural network be square</b>? - Quora", "url": "https://www.quora.com/Should-the-input-of-a-convolution-neural-network-be-square", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Should-<b>the-input</b>-<b>of-a-convolution-neural-network-be-square</b>", "snippet": "Answer: In short, there is no need for <b>the input</b> of a convolutional neural network to be square. More elaborate answer: Requirement for <b>the input</b> of a convolutional neural network (CNN) to be square came from the (now obsolete) requirement for <b>the input</b> to have fixed <b>size</b>. If you deal with imag...", "dateLastCrawled": "2021-12-31T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>GitHub</b> - <b>BaptisteBlouin/EventExtractionPapers</b>: A list of NLP resources ...", "url": "https://github.com/BaptisteBlouin/EventExtractionPapers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/BaptisteBlouin/EventExtractionPapers", "snippet": "RAPIER is a bottom-<b>up</b> <b>learning</b> <b>algorithm</b> that incorporates techniques from several inductive logic programming systems. We have implemented the <b>algorithm</b> in a system that allows patterns to have constraints on the words, part-of-speech tags, and semantic classes present in the filler and the surrounding text. We present encouraging experimental <b>results</b> on two domains.", "dateLastCrawled": "2022-01-31T02:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A high-bias, low-variance introduction to <b>Machine</b> <b>Learning</b> for physicists", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6688775/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6688775", "snippet": "<b>Machine</b> <b>Learning</b> (ML), <b>data</b> science, and statistics are fields that describe how to learn from, and make predictions about, <b>data</b>. The availability of big datasets is a hallmark of modern science, including physics, where <b>data</b> analysis has become an important component of diverse areas, such as experimental particle physics, observational astronomy and cosmology, condensed matter physics, biophysics, and quantum computing. Moreover, ML and <b>data</b> science are playing increasingly important roles ...", "dateLastCrawled": "2022-02-02T11:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Review of deep <b>learning</b>: concepts, CNN ... - Journal of Big <b>Data</b>", "url": "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00444-8", "isFamilyFriendly": true, "displayUrl": "https://journalofbig<b>data</b>.springeropen.com/articles/10.1186/s40537-021-00444-8", "snippet": "In the last few years, the deep <b>learning</b> (DL) computing paradigm has been deemed the Gold Standard in the <b>machine</b> <b>learning</b> (ML) community. Moreover, it has gradually become the most widely used computational approach in the field of ML, thus achieving outstanding <b>results</b> on several complex cognitive tasks, matching or even beating those provided by human performance. One of the benefits of DL is the ability to learn massive amounts of <b>data</b>. The DL field has grown fast in the last few years ...", "dateLastCrawled": "2022-02-02T04:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Towards the One <b>Learning</b> <b>Algorithm</b> Hypothesis: A System-theoretic ...", "url": "https://www.researchgate.net/publication/356818078_Towards_the_One_Learning_Algorithm_Hypothesis_A_System-theoretic_Approach", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/356818078_Towards_the_One_<b>Learning</b>_<b>Algorithm</b>...", "snippet": "Regarding (iii), we introduce a novel <b>learning</b> <b>algorithm</b> that constructs progressively growing knowledge representations in multiple resolutions. The proposed <b>algorithm</b> is an extension of the ...", "dateLastCrawled": "2022-01-25T01:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Time Series Prediction with LSTM Recurrent Neural Networks in Python ...", "url": "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/time-series-prediction-lstm-recurrent-neural...", "snippet": "Instead of phrasing the past observations as separate <b>input</b> features, we <b>can</b> use them as time steps of the one <b>input</b> feature, which is indeed a more accurate framing of the problem. We <b>can</b> do this using <b>the same</b> <b>data</b> representation as in the previous window-based example, except when we reshape the <b>data</b>, we set the columns to be the time steps dimension and change the features dimension back to 1.", "dateLastCrawled": "2022-02-02T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Feature extraction and <b>machine</b> <b>learning</b> techniques for identifying ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255507", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255507", "snippet": "<b>Machine</b> <b>learning</b> applications rely on a consistent unit of analysis to produce meaningful <b>results</b>. Accordingly, this step of our analysis pipeline is designed to disaggregate complex map scans, which include a wide variety of building types, labels, text, and other information, into a collection of individual building-level images, allowing us to feed a consistent set of discretely coded building-level <b>data</b> into our ensemble <b>machine</b> <b>learning</b> classifier. We target circular infrastructure ...", "dateLastCrawled": "2021-12-31T15:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Deep <b>Learning</b> and Its Application to Function Approximation for ...", "url": "https://www.researchgate.net/publication/354643984_Deep_Learning_and_Its_Application_to_Function_Approximation_for_MR_in_Medicine_An_Overview", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/354643984_Deep_<b>Learning</b>_and_Its_Application...", "snippet": "(DL), which is a <b>machine</b> <b>learning</b> (ML) <b>algorithm</b> using DNNs, has been used in various fields, including MR. The aim of this article is to help the readers develop", "dateLastCrawled": "2021-11-23T15:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Bishop Pattern Recognition And Machine Learning Springer</b> | Xinyue ...", "url": "https://www.academia.edu/34528598/Bishop_Pattern_Recognition_And_Machine_Learning_Springer", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/34528598/<b>Bishop_Pattern_Recognition_And_Machine_Learning_Springer</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-02T07:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Should <b>the input</b> <b>of a convolution neural network be square</b>? - Quora", "url": "https://www.quora.com/Should-the-input-of-a-convolution-neural-network-be-square", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Should-<b>the-input</b>-<b>of-a-convolution-neural-network-be-square</b>", "snippet": "Answer: In short, there is no need for <b>the input</b> of a convolutional neural network to be square. More elaborate answer: Requirement for <b>the input</b> of a convolutional neural network (CNN) to be square came from the (now obsolete) requirement for <b>the input</b> to have fixed <b>size</b>. If you deal with imag...", "dateLastCrawled": "2021-12-31T03:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Convolutional Neural Network for Copy-Move Forgery Detection</b>", "url": "https://www.researchgate.net/publication/336532316_Convolutional_Neural_Network_for_Copy-Move_Forgery_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/336532316_<b>Convolutional_Neural_Network_for</b>...", "snippet": "A novel neural network-based copy-move forgery de tection strategy was proposed in th is work. The convolutional neural network (CNN) was built with MATLAB due to its ease of use and its. support ...", "dateLastCrawled": "2022-01-25T20:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Intangible Assets Evaluation: The Machine Learning Perspective</b> ...", "url": "https://www.researchgate.net/publication/283425690_Intangible_Assets_Evaluation_The_Machine_Learning_Perspective", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/283425690_Intangible_Assets_Evaluation_The...", "snippet": "In addition, this paper shows that <b>machine</b> <b>learning</b> <b>can</b> be used effectively for the problem of intangible assets evaluation. To be specific, five classification algorithms are considered: decision ...", "dateLastCrawled": "2022-01-20T13:30:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "[2109.12926v1] ML4ML: Automated <b>Invariance</b> Testing for <b>Machine</b> <b>Learning</b> ...", "url": "https://arxiv.org/abs/2109.12926v1", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2109.12926v1", "snippet": "In <b>machine</b> <b>learning</b> workflows, determining <b>invariance</b> qualities of a model is a common testing procedure. In this paper, we propose an automatic testing framework that is applicable to a variety of <b>invariance</b> qualities. We draw an <b>analogy</b> between <b>invariance</b> testing and medical image analysis and propose to use variance matrices as ``imagery&#39;&#39; testing data. This enables us to employ <b>machine</b> <b>learning</b> techniques for analysing such ``imagery&#39;&#39; testing data automatically, hence facilitating ML4ML ...", "dateLastCrawled": "2022-01-20T15:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "ML4ML: Automated <b>Invariance</b> Testing for <b>Machine</b> <b>Learning</b> Models - NASA/ADS", "url": "https://ui.adsabs.harvard.edu/abs/2021arXiv210912926L/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2021arXiv210912926L/abstract", "snippet": "In <b>machine</b> <b>learning</b> workflows, determining <b>invariance</b> qualities of a model is a common testing procedure. In this paper, we propose an automatic testing framework that is applicable to a variety of <b>invariance</b> qualities. We draw an <b>analogy</b> between <b>invariance</b> testing and medical image analysis and propose to use variance matrices as ``imagery&#39;&#39; testing data. This enables us to employ <b>machine</b> <b>learning</b> techniques for analysing such ``imagery&#39;&#39; testing data automatically, hence facilitating ML4ML ...", "dateLastCrawled": "2021-11-01T00:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Size</b>\u2010Extensive <b>Molecular Machine Learning with Global Representations</b> ...", "url": "https://chemistry-europe.onlinelibrary.wiley.com/doi/full/10.1002/syst.201900052", "isFamilyFriendly": true, "displayUrl": "https://chemistry-europe.onlinelibrary.wiley.com/doi/full/10.1002/syst.201900052", "snippet": "1 Introduction. In recent years, <b>machine</b>-<b>learning</b> (ML) methods are increasingly applied to the prediction of molecular properties such as atomization and orbital energies, dipole moments and ionization potentials. 1-9 One of the main promises of ML in chemistry is that it allows surpassing the <b>size</b> and time scales accessible to accurate first-principles electronic structure calculations, e. g. based on density-functional theory (DFT).This is particularly relevant in a high-throughput setting ...", "dateLastCrawled": "2022-01-16T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Machine</b> <b>Learning</b>, <b>Machine</b> Vision, and the Brain | Christian ...", "url": "https://www.academia.edu/8040540/Machine_Learning_Machine_Vision_and_the_Brain", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/8040540/<b>Machine</b>_<b>Learning</b>_<b>Machine</b>_Vision_and_the_Brain", "snippet": "In fact, the <b>invariance</b> of the view-tuned neurons to image-plane trans- formation and to changes in illumination has been tested experimentally by Logothetis, Pauls, and Poggio (1995) who report an average rotation <b>invariance</b> over 30 degrees, translation <b>invariance</b> over 2 degrees, and <b>size</b> <b>invariance</b> of up to 1 octave around the training view. These recent data put in sharp focus and in quantitative terms the question of the circuitry underlying the properties of the view-tuned cells. The ...", "dateLastCrawled": "2022-01-26T21:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Size\u00e2 Extensive Molecular <b>Machine</b> <b>Learning</b> with Global Representations", "url": "https://chemistry-europe.onlinelibrary.wiley.com/doi/pdf/10.1002/syst.201900052", "isFamilyFriendly": true, "displayUrl": "https://chemistry-europe.onlinelibrary.wiley.com/doi/pdf/10.1002/syst.201900052", "snippet": "<b>Size</b>-Extensive Molecular <b>Machine</b> <b>Learning</b> with Global Representations** Hyunwook Jung+,[a, b] Sina Stocker+,[a] Christian Kunkel,[a] Harald Oberhofer,[a] Byungchan Han,[b] Karsten Reuter,[a] and Johannes T. Margraf*[a] <b>Machine</b> <b>learning</b> (ML) models are increasingly used in combi-nation with electronic structure calculations to predict molec-ular properties at a much lower computational cost in high-throughput settings. Such ML models require representations thatencode themolecular structure ...", "dateLastCrawled": "2022-01-30T02:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Integrating <b>Machine Learning</b> with Physics-Based Modeling | DeepAI", "url": "https://deepai.org/publication/integrating-machine-learning-with-physics-based-modeling", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/integrating-<b>machine-learning</b>-with-physics-based-modeling", "snippet": "Instead, data generation and training is an interactive process: Data is generated and labeled on the fly as model training proceeds. In <b>analogy</b> with multi-scale modeling, we refer to the former class of problems \u201csequential <b>machine learning</b>\u201d problems and the latter kind \u201cconcurrent <b>machine learning</b>\u201d problems.", "dateLastCrawled": "2022-01-27T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Perceptual invariance</b> in <b>Humans and Machines</b> | The Center for Brains ...", "url": "https://cbmm.mit.edu/video/perceptual-invariance-humans-and-machines", "isFamilyFriendly": true, "displayUrl": "https://cbmm.mit.edu/video/<b>perceptual-invariance</b>-<b>humans-and-machines</b>", "snippet": "I&#39;d argue that adversarial images is not just probably one of the most important problems in current <b>machine</b> <b>learning</b> or computer vision, but probably vision science. I feel like-- and I&#39;m stepping aside from the whole theme of <b>perceptual invariance</b>, and metamers, and foveation, and vision-- but I think if you go back to how advances in vision have happened over the years, over the past maybe 50 years or 60, there&#39;s discoveries that have been made from single cell electrophysiology. For ...", "dateLastCrawled": "2021-12-15T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Training Invariant Support Vector Machines</b>", "url": "https://people.eecs.berkeley.edu/~malik/cs294/decoste-scholkopf.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.eecs.berkeley.edu/~malik/cs294/decoste-scholkopf.pdf", "snippet": "<b>Machine</b> <b>Learning</b>, 46, 161\u2013190, 2002 c 2002 Kluwer Academic Publishers. Manufactured in The Netherlands. <b>Training Invariant Support Vector Machines</b> DENNIS DECOSTE decoste@aig.jpl.nasa.gov Jet Propulsion Laboratory, MS 126-347, 4800 Oak Grove Drive, Pasadena, CA 91109, USA; California Institute of Technology BERNHARD SCHOLKOPF bs@conclu.de\u00a8 Max-Planck-Institut fuer biologische Kybernetik, Spemannstr. 38, 72076 Tubingen, Germany\u00a8 Editor: Nello Cristianini Abstract. Practical experience has ...", "dateLastCrawled": "2022-01-30T19:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Model 1: accuracy = 92%. Model 2: accuracy = 95%. Model 2 has higher accuracy than model 1, but model 2 is useless. This is called accuracy paradox, which means the model with higher accuracy may not have better generalization power. In general, when TP &lt; FP, the accuracy will always increase when we change the classifier to always output &#39;negative&#39;.Conversely, when TN &lt; FN, the same will happen when we change the classifier to always output &#39;positive&#39; [1].. Recall@k", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "13_CNN1___MachineLearningCOMP5450_Fall2019.pdf - <b>Machine</b> <b>Learning</b> Dr ...", "url": "https://www.coursehero.com/file/75577826/13-CNN1-MachineLearningCOMP5450-Fall2019pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/75577826/13-CNN1-<b>MachineLearning</b>COMP5450-Fall2019pdf", "snippet": "13_CNN1___MachineLearningCOMP5450_Fall2019.pdf - <b>Machine</b> <b>Learning</b> Dr Jerome J Braun This Lecture Convolutional Neural Networks I Course <b>Machine</b> <b>Learning</b>. 13_CNN1___MachineLearningCOMP5450_Fall2019.pdf - <b>Machine</b>... School University of Massachusetts, Lowell; Course Title COMP 5450; Type. Notes. Uploaded By PrivateHeat13048. Pages 34 This preview shows page 1 - 8 out of 34 pages. Students who viewed this also studied. SRI SAIRAM ENGINEERING COLLEGE \u2022 MATH 2335. Week 3 quiz. 7 pages. Week 3 ...", "dateLastCrawled": "2022-01-19T01:07:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(size invariance)  is like +(a machine learning algorithm that produces the same results regardless of whether the input data is scaled up or down)", "+(size invariance) is similar to +(a machine learning algorithm that produces the same results regardless of whether the input data is scaled up or down)", "+(size invariance) can be thought of as +(a machine learning algorithm that produces the same results regardless of whether the input data is scaled up or down)", "+(size invariance) can be compared to +(a machine learning algorithm that produces the same results regardless of whether the input data is scaled up or down)", "machine learning +(size invariance AND analogy)", "machine learning +(\"size invariance is like\")", "machine learning +(\"size invariance is similar\")", "machine learning +(\"just as size invariance\")", "machine learning +(\"size invariance can be thought of as\")", "machine learning +(\"size invariance can be compared to\")"]}