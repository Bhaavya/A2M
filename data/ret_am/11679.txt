{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Google AI Blog: <b>Equality</b> <b>of Opportunity</b> in <b>Machine</b> <b>Learning</b>", "url": "https://ai.googleblog.com/2016/10/equality-of-opportunity-in-machine.html", "isFamilyFriendly": true, "displayUrl": "https://ai.googleblog.com/2016/10/<b>equality</b>-<b>of-opportunity</b>-in-<b>machine</b>.html", "snippet": "As <b>machine</b> <b>learning</b> technology progresses rapidly, there is much interest in understanding its societal impact. A particularly successful branch of <b>machine</b> <b>learning</b> is supervised <b>learning</b>. With enough past data and computational resources, <b>learning</b> algorithms often produce surprisingly effective predictors of future events. To take one hypothetical example: an <b>algorithm</b> could, for example, be used to predict with high accuracy who will pay back their loan. Lenders might then use such a ...", "dateLastCrawled": "2022-02-02T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Equality of Opportunity in Machine Learning</b> | googblogs.com", "url": "https://www.googblogs.com/equality-of-opportunity-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.googblogs.com/<b>equality-of-opportunity-in-machine-learning</b>", "snippet": "<b>Equality of Opportunity in Machine Learning</b>. Posted by Moritz Hardt, Research Scientist, Google Brain Team As <b>machine</b> <b>learning</b> technology progresses rapidly, there is much interest in understanding its societal impact. A particularly successful branch of <b>machine</b> <b>learning</b> is supervised <b>learning</b>. With enough past data and computational resources, <b>learning</b> algorithms often produce surprisingly effective predictors of future events. To take one hypothetical example: an <b>algorithm</b> could, for ...", "dateLastCrawled": "2021-12-17T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Algorithmic Discrimination and Equality of Opportunity</b> \u2013 Data Science ...", "url": "https://blogs.ischool.berkeley.edu/w231/2018/04/07/algorithmic-discrimination-and-equality-of-opportunity/", "isFamilyFriendly": true, "displayUrl": "https://blogs.ischool.berkeley.edu/w231/2018/04/07/<b>algorithm</b>ic-discrimination-and...", "snippet": "Historically, judges have made these subjective determinations based on personal experience and professional expertise; the introduction of an objective, data-driven <b>algorithm</b> into these settings seems <b>like</b> a sensible thing to do. Indeed, it sounds <b>like</b> a marquee application for the field of <b>machine</b> <b>learning</b>.", "dateLastCrawled": "2022-01-29T17:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Equality</b> <b>of Opportunity</b> in Supervised <b>Learning</b>", "url": "https://home.ttic.edu/~nati/Publications/HardtPriceSrebro2016.pdf", "isFamilyFriendly": true, "displayUrl": "https://home.ttic.edu/~nati/Publications/HardtPriceSrebro2016.pdf", "snippet": "<b>Equality</b> <b>of Opportunity</b> in Supervised <b>Learning</b> Moritz Hardt Eric Price Nathan Srebro October 7, 2016 Abstract We propose a criterion for discrimination against a speci\ufb01ed sensitive attribute in su- pervised <b>learning</b>, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are avail-able, we show how to optimally adjust any learned predictor so as to remove discrimination according to our ...", "dateLastCrawled": "2022-01-31T14:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Equality of Opportunity in Supervised Learning</b>", "url": "https://www.researchgate.net/publication/308980568_Equality_of_Opportunity_in_Supervised_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../308980568_<b>Equality_of_Opportunity_in_Supervised_Learning</b>", "snippet": "This notion is similar to the well studied notion of equal <b>opportunity</b> in the <b>machine</b> <b>learning</b> literature (see [10]). With this in mind, the proposed <b>algorithm</b> iteratively constructs allocations ...", "dateLastCrawled": "2022-01-15T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bias and Fairness in Machine Learning</b> - Abhishek Tiwari", "url": "https://www.abhishek-tiwari.com/bias-and-fairness-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.abhishek-tiwari.com/<b>bias-and-fairness-in-machine-learning</b>", "snippet": "<b>Equality</b> <b>of Opportunity</b> in Supervised <b>Learning</b> \u21a9\ufe0e. Attacking discrimination with smarter <b>machine</b> <b>learning</b> \u21a9\ufe0e. FairML is a python toolbox auditing the <b>machine</b> <b>learning</b> models for bias. \u21a9\ufe0e. FairML: Auditing Black-Box Predictive Models \u21a9\ufe0e. Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings \u21a9\ufe0e", "dateLastCrawled": "2022-01-29T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[PDF] <b>Equality of Opportunity in Supervised Learning</b> | Semantic Scholar", "url": "https://www.semanticscholar.org/paper/Equality-of-Opportunity-in-Supervised-Learning-Hardt-Price/d42b11ce90c9c69a20ed015b73dc33e0e4100a7b", "isFamilyFriendly": true, "displayUrl": "https://www.semanticscholar.org/paper/<b>Equality-of-Opportunity-in-Supervised-Learning</b>...", "snippet": "<b>Equality of Opportunity in Supervised Learning</b> @inproceedings{Hardt2016EqualityOO, title={<b>Equality of Opportunity in Supervised Learning</b>}, author={Moritz Hardt and Eric Price and Nathan Srebro}, booktitle={NIPS}, year={2016} } Moritz Hardt, Eric Price, Nathan Srebro; Published in NIPS 7 October 2016; Computer Science, Mathematics; We propose a criterion for discrimination against a specified sensitive attribute in supervised <b>learning</b>, where the goal is to predict some target based on ...", "dateLastCrawled": "2021-12-16T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Equality</b> of <b>Learning Opportunity in Personalized Recommendations</b>", "url": "https://www.researchgate.net/publication/342027329_Equality_of_Learning_Opportunity_in_Personalized_Recommendations", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342027329_<b>Equality</b>_of_<b>Learning</b>_<b>Opportunity</b>_in...", "snippet": "<b>Equality</b> of <b>Learning Opportunity in Personalized Recommendations</b> 19 in general, it is hard to plug-in the balancing phase into the internal logic of a recommender system, we propose to re-arrange ...", "dateLastCrawled": "2021-11-18T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Discrimination by <b>algorithm</b>: scientists devise test to detect AI bias ...", "url": "https://www.theguardian.com/technology/2016/dec/19/discrimination-by-algorithm-scientists-devise-test-to-detect-ai-bias", "isFamilyFriendly": true, "displayUrl": "https://<b>www.theguardian.com</b>/technology/2016/dec/19/discrimination-by-<b>algorithm</b>...", "snippet": "Their approach, called <b>Equality</b> <b>of Opportunity</b> in Supervised <b>Learning</b>, works on the basic principle that when an <b>algorithm</b> makes a decision about an individual - be it to show them an online ad or ...", "dateLastCrawled": "2021-12-09T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A Tutorial on <b>Fairness</b> in <b>Machine</b> <b>Learning</b> | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-<b>machine</b>-<b>learning</b>-3ff8ba1040cb", "snippet": "<b>Machine</b> <b>Learning</b>, the most widely used AI techniques, relies heavily on data. It is a common misconception that AI is absolutely objective. AI is objective only in the sense of <b>learning</b> what human teaches. The data provided by human can be highly-biased. It has been found in 2016 that COMPAS, the <b>algorithm</b> used for recidivism prediction produces much higher false positive rate for black people than white people(see Fig2, Larson et al. ProPublica, 2016). Fig2: The bias in COMPAS. (from Larson ...", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Equality</b> <b>of opportunity</b> in travel behavior prediction with deep neural ...", "url": "https://www.sciencedirect.com/science/article/pii/S0968090X21004058", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0968090X21004058", "snippet": "Although researchers increasingly adopt <b>machine</b> <b>learning</b> to model travel behavior, they predominantly focus on prediction accuracy, ignoring the ethical challenges embedded in <b>machine</b> <b>learning</b> algorithms. This study introduces an important missing dimension - computational fairness - to travel behavior analysis. It highlights the accuracy-fairness tradeoff instead of the single dimensional focus on prediction accuracy in the contexts of deep neural network (DNN) and discrete choice models ...", "dateLastCrawled": "2022-01-20T13:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "<b>Equality</b> <b>of opportunity</b> suggests that people <b>similar</b> in real life (\\(Y\\)) get classified similarly (\\(\\hat{Y}\\)). ... From a <b>machine</b> <b>learning</b> perspective, the interesting point is the classification of metrics into bias-preserving and bias-transforming. The terms speak for themselves: Metrics in the first group reflect biases in the dataset used for training; ones in the second do not. In that way, the distinction parallels Friedler, Scheidegger, and Venkatasubramanian \u2019s confrontation of ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Identifying the roots of inequality <b>of opportunity</b> in South Korea by ...", "url": "https://www.nature.com/articles/s41599-021-01026-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41599-021-01026-y", "snippet": "In addition, the <b>machine</b> <b>learning</b> <b>algorithm</b> is limited, thereby making it difficult to interpret the estimated results without knowledge of the process between the input and output of data, like a ...", "dateLastCrawled": "2022-02-03T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "[PDF] <b>Equality of Opportunity in Supervised Learning</b> | Semantic Scholar", "url": "https://www.semanticscholar.org/paper/Equality-of-Opportunity-in-Supervised-Learning-Hardt-Price/d42b11ce90c9c69a20ed015b73dc33e0e4100a7b", "isFamilyFriendly": true, "displayUrl": "https://www.semanticscholar.org/paper/<b>Equality-of-Opportunity-in-Supervised-Learning</b>...", "snippet": "<b>Equality of Opportunity in Supervised Learning</b> @inproceedings{Hardt2016EqualityOO, title={<b>Equality of Opportunity in Supervised Learning</b>}, author={Moritz Hardt and Eric Price and Nathan Srebro}, booktitle={NIPS}, year={2016} } Moritz Hardt, Eric Price, Nathan Srebro; Published in NIPS 7 October 2016; Computer Science, Mathematics; We propose a criterion for discrimination against a specified sensitive attribute in supervised <b>learning</b>, where the goal is to predict some target based on ...", "dateLastCrawled": "2021-12-16T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Tutorial #1: <b>bias and fairness in AI</b> - Borealis AI", "url": "https://www.borealisai.com/en/blog/tutorial1-bias-and-fairness-ai/", "isFamilyFriendly": true, "displayUrl": "https://www.borealisai.com/en/blog/tutorial1-bias-and-fairness-ai", "snippet": "Complementary to this is individual fairness which mandates that <b>similar</b> individuals should be treated similarly regardless of group membership. In this blog, we&#39;ll mainly focus on group fairness, three definitions of which include: (i) demographic parity, (ii) <b>equality</b> of odds, and (iii) <b>equality</b> <b>of opportunity</b>. We now discuss each in turn. Demographic Parity. Demographic parity or statistical parity suggests that a predictor is unbiased if the prediction $\\hat{y}$ is independent of the ...", "dateLastCrawled": "2022-02-02T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bias and Fairness in Machine Learning</b> - Abhishek Tiwari", "url": "https://www.abhishek-tiwari.com/bias-and-fairness-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.abhishek-tiwari.com/<b>bias-and-fairness-in-machine-learning</b>", "snippet": "<b>Equality</b> <b>of Opportunity</b> in Supervised <b>Learning</b> \u21a9\ufe0e. Attacking discrimination with smarter <b>machine</b> <b>learning</b> \u21a9\ufe0e. FairML is a python toolbox auditing the <b>machine</b> <b>learning</b> models for bias. \u21a9\ufe0e. FairML: Auditing Black-Box Predictive Models \u21a9\ufe0e. Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings \u21a9\ufe0e", "dateLastCrawled": "2022-01-29T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Equality</b> of <b>Learning Opportunity in Personalized Recommendations</b>", "url": "https://www.researchgate.net/publication/342027329_Equality_of_Learning_Opportunity_in_Personalized_Recommendations", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342027329_<b>Equality</b>_of_<b>Learning</b>_<b>Opportunity</b>_in...", "snippet": "In this paper, we introduced a new metric of <b>learning</b> <b>opportunity</b> <b>equality</b>. among learners in the context of personalized recommendations. Then, we. proposed a re-ranking procedure able to ...", "dateLastCrawled": "2021-11-18T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fairness in <b>Machine</b> <b>Learning</b> - Yunsheng B", "url": "http://yunshengb.com/wp-content/uploads/2018/02/Fairness-presentation.pdf", "isFamilyFriendly": true, "displayUrl": "yunshengb.com/wp-content/uploads/2018/02/Fairness-presentation.pdf", "snippet": "Make decisions by <b>machine</b> <b>learning</b>:! Software can make decision \u201cfree of human biases\u201d Fairness in Supervised <b>Learning</b> Make decisions by <b>machine</b> <b>learning</b>:! \u201cSoftware is not free of human influence. [...] <b>Algorithm</b> can reinforce human prejudice.\u201d <b>Equality</b> <b>of opportunity</b> \u2022 Narrow notions: treats <b>similar</b> people similarly on the basis of relevant features, given their current degree of similarity \u2022 Broader notions: organizing society, people of equal talents and ambition can achieve ...", "dateLastCrawled": "2021-11-18T10:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fairness in Algorithmic Decision", "url": "https://data-psl.github.io/lectures2021/slides/psl-pw2021-kirat.pdf", "isFamilyFriendly": true, "displayUrl": "https://data-psl.github.io/lectures2021/slides/psl-pw2021-kirat.pdf", "snippet": "and/or benchmark data for an <b>algorithm</b> doesn [t represent the target population. The Prediction Problem. Fairness metrics: incompatibilities See : Hardt, Price &amp; Srebro, <b>Equality</b> <b>of opportunity</b> in <b>machine</b> <b>learning</b>, 2016 : access to bank credit by origin (FICO dataset, USA)-&gt; score scale : increasing risk of default. Fairness metrics: incompatibilities Tutorial: Martin Wattenberg, Fernanda Vi\u00e9gas, and Moritz Hardt, Attacking discrimination with smarter <b>machine</b> <b>learning</b> (companion to Hardt ...", "dateLastCrawled": "2021-11-27T08:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "We Want Fair AI Algorithms \u2013 But How To Define Fairness? (Fairness ...", "url": "https://mostly.ai/blog/we-want-fair-ai-algorithms-but-how-to-define-fairness/", "isFamilyFriendly": true, "displayUrl": "https://<b>mostly.ai</b>/blog/we-want-fair-ai-<b>algorithms</b>-but-how-to-define-fairness", "snippet": "An integral part of the factory is a <b>machine</b> <b>learning</b> <b>algorithm</b> that automatically analyzes tomatoes on the conveyor belt and classifies them into fresh and bad (or rotten) tomatoes. Fresh tomatoes are transferred into the \u201cAcceptable\u201d bin and ultimately end up in the spaghetti sauce, rotten tomatoes end up in the \u201cDiscard\u201d bin and are thrown away. Consider there exist only two kinds of tomatoes worldwide: 80% of all tomatoes are red tomatoes and 20% of them are yellow. Apart from ...", "dateLastCrawled": "2022-01-29T01:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>A Moral Framework for Understanding Fair ML through Economic</b> Models of ...", "url": "https://www.cs.cmu.edu/~hheidari/heidari2019moral.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~hheidari/heidari2019moral.pdf", "snippet": "<b>Equality</b> <b>of Opportunity</b> (EOP), Fairness for <b>Machine</b> <b>Learning</b>, Rawlsian and Luck Egalitarian EOP, Statistical Parity, <b>Equality</b> of Odds, Predictive Value Parity ACM Reference Format: Hoda Heidari, Michele Loi, Krishna P. Gummadi, and Andreas Krause. 2019. <b>A Moral Framework for Understanding Fair ML, through Economic</b> Models of <b>Equality</b> <b>of Opportunity</b>. In FAT* \u201919: Conference on Fairness, Account-ability, and Transparency (FAT* \u201919), January 29\u201331, 2019, Atlanta, GA, USA. ACM,NewYork,NY ...", "dateLastCrawled": "2021-09-09T14:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Rawlsian Fairness for Machine Learning</b> - Semantic Scholar", "url": "https://www.semanticscholar.org/paper/Rawlsian-Fairness-for-Machine-Learning-Joseph-Kearns/2d55ff4542eaae18dcd10c2cd74199396e260402", "isFamilyFriendly": true, "displayUrl": "https://www.semanticscholar.org/paper/<b>Rawlsian-Fairness-for-Machine-Learning</b>-Joseph...", "snippet": "Motivated by concerns that automated decision-making procedures <b>can</b> unintentionally lead to discriminatory behavior, we study a technical definition of fairness modeled after John Rawls&#39; notion of &quot;fair <b>equality</b> <b>of opportunity</b>&quot;. In the context of a simple model of online decision making, we give an <b>algorithm</b> that satisfies this fairness constraint, while still being able to learn at a rate that is comparable to (but necessarily worse than) that of the best algorithms absent a fairness ...", "dateLastCrawled": "2021-12-21T06:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Differentiating Bias and Fairness in <b>Machine</b> <b>Learning</b>", "url": "https://www.closedloop.ai/post/bias-v-fairness-in-ml", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/bias-v-fairness-in-ml", "snippet": "We have discussed our metric for fairness, Group Benefit <b>Equality</b>, and ... It should <b>be thought</b> of as a more holistic approach to understanding how your model is altered by the dynamics affecting the subpopulation. \u200d The starting point for algorithmic bias must always be an examination of the data itself. If the dataset is collected under unequal conditions, it is very unlikely that the resulting model will be able to overcome this problem. In sociology, they have a concept called \u201cWEIRD ...", "dateLastCrawled": "2021-12-28T14:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Handling Discriminatory Biases in Data for <b>Machine Learning</b> | by ...", "url": "https://towardsdatascience.com/machine-learning-and-discrimination-2ed1a8b01038", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine-learning</b>-and-<b>discrimination</b>-2ed1a8b01038", "snippet": "Food for <b>Thought</b>. To end such a long and serious article, I leave you with a quote from Google about <b>discrimination</b> in <b>machine learning</b> to mull over. \u201cOptimizing for equal <b>opportunity</b> is just one of many tools that <b>can</b> be used to improve <b>machine learning</b> systems \u2014 and mathematics alone is unlikely to lead to the best solutions. Attacking ...", "dateLastCrawled": "2022-01-29T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Equality</b> <b>of Opportunity</b> in Rankings", "url": "https://www.k4all.org/wp-content/uploads/2017/09/WPOC2017_paper_9.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.k4all.org/wp-content/uploads/2017/09/WPOC2017_paper_9.pdf", "snippet": "<b>Equality</b> <b>of Opportunity</b> in Rankings Extended Abstract Ashudeep Singh Cornell University Ithaca, NY ashudeep@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY tj@cs.cornell.edu ABSTRACT With the ubiquity of algorithmic methods for ranking in systems like search engines, recommendations, and advertisements, it be-comes essential to ensure that these systems do not impact different groups at different rates. In this work, we focus on defining the no-tions of fairness in such ...", "dateLastCrawled": "2021-11-19T10:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "When Good Algorithms Go Sexist: Why and How to Advance AI <b>Gender</b> Equity", "url": "https://ssir.org/articles/entry/when_good_algorithms_go_sexist_why_and_how_to_advance_ai_gender_equity", "isFamilyFriendly": true, "displayUrl": "https://ssir.org/articles/entry/when_good_<b>algorithms</b>_go_sexist_why_and_how_to_advance...", "snippet": "Customer service employees were unable to explain why the <b>algorithm</b> deemed the wife significantly less creditworthy. Many institutions make decisions based on artificial intelligence (AI) systems using <b>machine</b> <b>learning</b> (ML), whereby a series of algorithms takes and learns from massive amounts of data to find patterns and make predictions. These systems inform how much credit financial institutions offer different customers, who the health care system prioritizes for COVID-19 vaccines, and ...", "dateLastCrawled": "2022-01-28T04:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Big data and <b>machine learning</b> algorithms for health-care delivery - The ...", "url": "https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(19)30149-4/fulltext", "isFamilyFriendly": true, "displayUrl": "https://<b>www.thelancet.com</b>/journals/lanonc/article/PIIS1470-2045(19)30149-4/fulltext", "snippet": "Analysis of big data by <b>machine learning</b> offers considerable advantages for assimilation and evaluation of large amounts of complex health-care data. However, to effectively use <b>machine learning</b> tools in health care, several limitations must be addressed and key issues considered, such as its clinical implementation and ethics in health-care delivery. Advantages of <b>machine learning</b> include flexibility and scalability compared with traditional biostatistical methods, which makes it deployable ...", "dateLastCrawled": "2022-01-25T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "2. What is Fairness? \u2014 Fairness &amp; Algorithmic Decision Making", "url": "https://afraenkel.github.io/fairness-book/content/02-frameworks.html", "isFamilyFriendly": true, "displayUrl": "https://afraenkel.github.io/fairness-book/content/02-frameworks.html", "snippet": "One limitation of Formal <b>Equality</b> <b>of Opportunity</b> (FEO) is that while the distribution of goods is open to all, the ability to take advantage of such an <b>opportunity</b> may effectively be non-existent. For example, a job may be available through passing an arbitrary examination that only very wealthy pass (because only they <b>can</b> afford the training). While this job is theoretically available to everyone (satisfying formal EO), it in practice is only available to the very wealthy.", "dateLastCrawled": "2022-01-31T18:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "MLW 2019: Aligning on the role of AI in preparing ... - <b>Learning</b> <b>Equality</b>", "url": "https://blog.learningequality.org/mlw-2019-aligning-on-the-role-of-ai-in-preparing-curriculum-for-emergency-contexts-a974fa5c2260", "isFamilyFriendly": true, "displayUrl": "https://blog.<b>learningequality</b>.org/mlw-2019-aligning-on-the-role-of-ai-in-preparing...", "snippet": "The week was full of <b>learning</b>, connecting, and sharing with our peers in the field. We attended <b>thought</b>-provoking sessions that illustrated the risks, especially for marginalized and vulnerable communities, of excluding humane principles in the development of AI as it becomes more ubiquitous in education and the world at large. However, these sessions also revealed the deep potential that AI holds to empower a wide range of initiatives \u2014 from creating more effective personalized digital ...", "dateLastCrawled": "2022-01-27T19:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Dangers of an Artificially Intelligent Future - The Decision Lab", "url": "https://thedecisionlab.com/insights/society/the-dangers-of-an-artificially-intelligent-future/", "isFamilyFriendly": true, "displayUrl": "https://thedecisionlab.com/insights/society/the-dangers-of-an-artificially-intelligent...", "snippet": "This is a basic image processing <b>machine</b> <b>learning</b> <b>algorithm</b>: Google uses your responses to train its AI and make it better at image recognition. Datasets used to program more advanced <b>machine</b> <b>learning</b> algorithms include collections of human faces for facial recognition software, information about successful employees for application screening software, and locations of police arrests for predictive policing software. So, how intelligent is our artificially \u201cintelligent\u201d future? How algor", "dateLastCrawled": "2022-01-22T11:52:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Equality</b> <b>of opportunity</b> in travel behavior prediction with deep neural ...", "url": "https://www.sciencedirect.com/science/article/pii/S0968090X21004058", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0968090X21004058", "snippet": "While we use <b>equality</b> <b>of opportunity</b> as the fairness metric in this research, scholars <b>can</b> also consider other metrics to measure computational fairness. Another future research direction is to study fairness issues with <b>machine</b> <b>learning</b> models other than DNN and BLR. In addition, while we try to address computational fairness through an ...", "dateLastCrawled": "2022-01-20T13:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Identifying the roots of inequality <b>of opportunity</b> in South Korea by ...", "url": "https://www.nature.com/articles/s41599-021-01026-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41599-021-01026-y", "snippet": "In addition, the <b>machine</b> <b>learning</b> <b>algorithm</b> is limited, thereby making it difficult to interpret the estimated results without knowledge of the process between the input and output of data, like a ...", "dateLastCrawled": "2022-02-03T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A New Metric for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare", "url": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "<b>Equality</b> <b>of Opportunity</b> occurs when the sensitivity for the two groups are the same (tp/(tp+fn) ). Our metric differs by this mathematically by the presence of the false positive term in the numerator. If such a similar term exists, why would one elect to report fairness using a different metric? The strength of group benefit <b>equality</b> is its transparency and ease of explanation. One huge strength of group benefit <b>equality</b> is having a default objective for tuning the decision threshold. Even ...", "dateLastCrawled": "2022-02-01T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bias and Fairness in Machine Learning</b> - Abhishek Tiwari", "url": "https://www.abhishek-tiwari.com/bias-and-fairness-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.abhishek-tiwari.com/<b>bias-and-fairness-in-machine-learning</b>", "snippet": "Wall Street Journal investigators showed that Staples\u2019 online pricing <b>algorithm</b> discriminated against lower-income people; Black people were more likely to be assessed as having a higher risk of recidivism when using commercial prediction tools such as COMPAS ; An insurance company that used <b>machine</b> <b>learning</b> to workout insurance premiums involuntarily discriminated against elderly patients; A credit card company used tracking information to personalize offers steering minorities into ...", "dateLastCrawled": "2022-01-29T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A New Metric for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare ...", "url": "https://towardsdatascience.com/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare-closedloop-ai-fc07b9c83487", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-new-metric-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "<b>Equality</b> <b>of Opportunity</b> occurs when the sensitivity for the two groups are the same (tp/(tp+fn)). Our metric differs by this mathematically by the presence of the false positive term in the numerator. If such a similar term exists, why would one elect to report fairness using a different metric? The strength of group benefit <b>equality</b> is its transparency and ease of explanation. One huge strength of group benefit <b>equality</b> is having a default objective for tuning the decision threshold. Even ...", "dateLastCrawled": "2022-01-17T14:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "&#39;<b>Un&#39;Fair Machine Learning Algorithms</b> by Runshan Fu, Manmohan Aseri ...", "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3408275", "isFamilyFriendly": true, "displayUrl": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3408275", "snippet": "In response, several ``<b>fair\u201d machine learning algorithms</b> that require impact parity (e.g., equal <b>opportunity</b>) have recently been proposed to adjust for the societal inequalities; advocates propose changing the law to allow the use of protected class-specific decision rules. We show that these ``fair&#39;&#39; algorithms that require impact parity, while conceptually appealing, <b>can</b> make everyone worse off, including the very class they aim to protect. <b>Compared</b> to the current law, which requires ...", "dateLastCrawled": "2022-01-29T16:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Comparison of <b>machine</b>-<b>learning</b> models for predicting short-term ...", "url": "https://www.sciencedirect.com/science/article/pii/S0378778821007891", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0378778821007891", "snippet": "15 <b>machine</b>-<b>learning</b> models were <b>compared</b> from aspects of accuracy, stability and computation time. \u2022 GPR and SVM were recommended for small and large building load datasets, respectively. Abstract. Short-term building energy consumption prediction is of great significance to the optimal operation of building energy systems and conservation. <b>Machine</b>-<b>learning</b> models are widely used due to their high prediction accuracy and efficiency in dealing with high-dimensional nonlinear problems. To ...", "dateLastCrawled": "2022-01-13T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Equality</b> of <b>Learning Opportunity in Personalized Recommendations</b>", "url": "https://www.researchgate.net/publication/342027329_Equality_of_Learning_Opportunity_in_Personalized_Recommendations", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342027329_<b>Equality</b>_of_<b>Learning</b>_<b>Opportunity</b>_in...", "snippet": "In this paper, we introduced a new metric of <b>learning</b> <b>opportunity</b> <b>equality</b>. among learners in the context of personalized recommendations. Then, we. proposed a re-ranking procedure able to ...", "dateLastCrawled": "2021-11-18T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Big data and <b>machine learning</b> algorithms for health-care delivery - The ...", "url": "https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(19)30149-4/fulltext", "isFamilyFriendly": true, "displayUrl": "https://<b>www.thelancet.com</b>/journals/lanonc/article/PIIS1470-2045(19)30149-4/fulltext", "snippet": "Analysis of big data by <b>machine learning</b> offers considerable advantages for assimilation and evaluation of large amounts of complex health-care data. However, to effectively use <b>machine learning</b> tools in health care, several limitations must be addressed and key issues considered, such as its clinical implementation and ethics in health-care delivery. Advantages of <b>machine learning</b> include flexibility and scalability <b>compared</b> with traditional biostatistical methods, which makes it deployable ...", "dateLastCrawled": "2022-01-25T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Underdiagnosis bias of artificial intelligence algorithms applied to ...", "url": "https://www.nature.com/articles/s41591-021-01595-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41591-021-01595-0", "snippet": "This is an especially dangerous outcome for <b>machine</b> <b>learning</b> models in healthcare, given that existing biases in health practice risk being magnified, rather than ameliorated, by algorithmic ...", "dateLastCrawled": "2022-02-02T21:08:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "A <b>machine learning</b> technique that iteratively combines a set of simple and not very accurate classifiers ... Contrast with equalized odds and <b>equality</b> <b>of opportunity</b>, which permit classification results in aggregate to depend on sensitive attributes, but do not permit classification results for certain specified ground-truth labels to depend on sensitive attributes. See &quot;Attacking discrimination with smarter <b>machine learning</b>&quot; for a visualization exploring the tradeoffs when optimizing for ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> | Gendered Innovations", "url": "http://genderedinnovations.stanford.edu/case-studies/machinelearning.html", "isFamilyFriendly": true, "displayUrl": "genderedinnovations.stanford.edu/case-studies/<b>machinelearning</b>.html", "snippet": "As <b>machine learning</b> becomes increasingly ubiquitous in everyday lives, such bias, if uncorrected, can lead to social inequities. Researchers need to understand how gender and ethnicity operate within the context of their algorithm in order to enhance or, at least, not reinforce social equalities. Here we suggest avenues for reducing bias in training data and algorithms in efforts to produce AI that enhances social equalities.", "dateLastCrawled": "2022-01-25T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "<b>Equality</b> <b>of opportunity</b> suggests that people similar in real life (\\(Y\\)) get classified similarly ... From a <b>machine</b> <b>learning</b> perspective, the interesting point is the classification of metrics into bias-preserving and bias-transforming. The terms speak for themselves: Metrics in the first group reflect biases in the dataset used for training; ones in the second do not. In that way, the distinction parallels Friedler, Scheidegger, and Venkatasubramanian \u2019s confrontation of two ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A New Metric for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare ...", "url": "https://towardsdatascience.com/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare-closedloop-ai-fc07b9c83487", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-new-metric-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "<b>Equality</b> <b>of Opportunity</b> occurs when the sensitivity for the two groups are the same (tp/(tp+fn)). Our metric differs by this mathematically by the presence of the false positive term in the numerator. If such a similar term exists, why would one elect to report fairness using a different metric? The strength of group benefit <b>equality</b> is its transparency and ease of explanation. One huge strength of group benefit <b>equality</b> is having a default objective for tuning the decision threshold. Even ...", "dateLastCrawled": "2022-01-17T14:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning \u2013 An automotive analogy</b> - BCS Consulting", "url": "https://www.bcsconsulting.com/blog/machine-learning-automotive-analogy/", "isFamilyFriendly": true, "displayUrl": "https://www.bcsconsulting.com/blog/<b>machine</b>-<b>learning</b>-automotive-<b>analogy</b>", "snippet": "<b>Machine Learning \u2013 An automotive analogy</b>. Gonzalo Gonzalez. 12th April, 2018. Progress in emerging technologies, such as <b>machine</b> <b>learning</b>, is creating alternatives to labour intensive risk modelling activities. Banks will require vision, investment and enduring strategic actions to truly leverage the full range of potential benefits . The roadmap defined for autonomous electric cars by tech giants and cars manufacturers include: changes to usage and storage of fuel; investment in talent ...", "dateLastCrawled": "2021-12-13T13:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Analogical proportions</b>: From <b>equality</b> to inequality - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0888613X17306096", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0888613X17306096", "snippet": "Later on, a <b>machine</b> <b>learning</b>-oriented view where <b>analogical proportions</b> are represented in terms of Kolmogorov algorithmic complexity has been presented in . A similar, but simplified modeling, still expressing that a and b differ as c and d differ, can be found in [1] , where the complexities of the target and source universes have not to be taken into account, since they are identical in this latter case.", "dateLastCrawled": "2021-11-13T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Adversarial Approaches to Debiasing Word Embeddings", "url": "https://web.stanford.edu/class/cs224n/reports/final_reports/report101.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/cs224n/reports/final_reports/report101.pdf", "snippet": "analogies and identify the gender bias of the <b>analogy</b>, paired with a generator that only minimizes the discriminator\u2019s ability to identify the gender bias. Preliminary results on the WEAT scoring system show that both methods were successful in eliminating bias on commonly-used job words; qualitative analysis on similar words also show that racially or gender charged synonyms were considered less relevant to the debiased vector. 1 Introduction <b>Machine</b> <b>learning</b> for natural language ...", "dateLastCrawled": "2022-01-25T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fairness Through Awareness", "url": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "snippet": "\u201c<b>Equality</b> <b>of opportunity</b> de\ufb01nes an important welfare criterion in political philosophy and policy analysis. Philosophers de\ufb01ne <b>equality</b> <b>of opportunity</b> as the requirement that an individual\u2019s well being be independent of his or her irrelevant characteristics. The di erence among philosophers is mainly about which characteristics should be", "dateLastCrawled": "2022-01-29T03:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Socialist equality of opportunity</b> \u2013 TOWARDS LIFE-KNOWLEDGE", "url": "https://bsahely.com/life-value-onto-axiology/socialist-equality-of-opportunity/", "isFamilyFriendly": true, "displayUrl": "https://bsahely.com/life-value-onto-axiology/<b>socialist-equality-of-opportunity</b>", "snippet": "<b>Socialist equality of opportunity</b>: The principle that seeks to correct for all disadvantages for which the agent cannot herself reasonably be held responsible, whether they be disadvantages that reflect social misfortune or disadvantages that reflect natural misfortune. See Left-liberal <b>equality</b> <b>of opportunity</b>.. Source: \u2018What is Good? What is Bad? The Value of All Values across Time, Place and Theories\u2019 by John McMurtry, Philosophy and World Problems, Volume I-III, UNESCO in partnership ...", "dateLastCrawled": "2022-01-29T07:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Equity vs. <b>Equality</b>: What\u2019s the Difference? | Online Public Health", "url": "https://onlinepublichealth.gwu.edu/resources/equity-vs-equality/", "isFamilyFriendly": true, "displayUrl": "https://onlinepublichealth.gwu.edu/resources/equity-vs-<b>equality</b>", "snippet": "November 5, 2020. While the terms equity and <b>equality</b> may sound similar, the implementation of one versus the other can lead to dramatically different outcomes for marginalized people. <b>Equality</b> means each individual or group of people is given the same resources or opportunities. Equity recognizes that each person has different circumstances ...", "dateLastCrawled": "2022-02-03T06:10:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Philosophical Issues in Economics", "url": "https://www.ibiblio.org/philecon/Publications/publications.doc", "isFamilyFriendly": true, "displayUrl": "https://www.ibiblio.org/philecon/Publications/publications.doc", "snippet": ": Tawney\u2019s definition of <b>equality of opportunity is similar</b> to that of the Friedmans but does consider class, economic, and social position to be actual obstacles that can limit or enhance an individual\u2019s ability to act. He believes that in so far social arrangements can achieve it, everyone should have equal opportunity to enjoy a worthwhile life (Tawney 1964:122). To achieve this Tawney promotes a society that communally provides welfare services by pooling surplus resources by means ...", "dateLastCrawled": "2022-01-20T11:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Equality of <b>Educational Opportunity</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/equal-ed-opportunity/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/equal-ed-opportunity", "snippet": "It might be argued that <b>just as equality of opportunity</b> to become a flourishing individual is a matter of justice, so too is equality of opportunity to develop civic skills, and to participate effectively in political deliberations. The structure and appropriate content of civic education is debated extensively. While some argue that citizenship education can be narrowly construed so as to not encroach upon individuals\u2019 private commitments, others claim it is a far more demanding ...", "dateLastCrawled": "2022-02-03T04:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "American Education (sociocultural, Political, And Historical Studies In ...", "url": "https://idoc.pub/documents/american-education-sociocultural-political-and-historical-studies-in-education-18th-edition-d47emk33myn2", "isFamilyFriendly": true, "displayUrl": "https://idoc.pub/documents/american-education-sociocultural-political-and-historical...", "snippet": "Service-<b>learning</b> combines service to the community with student <b>learning</b> in a way that improves both the student and the community. As they participate in their community service projects, actively meeting the needs of communities, youth develop practical skills, selfesteem, and a sense of civic responsibility. Service <b>learning</b> is a form of civic education rather than an education for direct involvement in politics. It is based on a belief that voluntary engagement in civic organizations and ...", "dateLastCrawled": "2022-01-16T11:12:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(equality of opportunity)  is like +(machine learning algorithm)", "+(equality of opportunity) is similar to +(machine learning algorithm)", "+(equality of opportunity) can be thought of as +(machine learning algorithm)", "+(equality of opportunity) can be compared to +(machine learning algorithm)", "machine learning +(equality of opportunity AND analogy)", "machine learning +(\"equality of opportunity is like\")", "machine learning +(\"equality of opportunity is similar\")", "machine learning +(\"just as equality of opportunity\")", "machine learning +(\"equality of opportunity can be thought of as\")", "machine learning +(\"equality of opportunity can be compared to\")"]}