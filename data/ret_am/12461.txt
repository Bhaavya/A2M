{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Misleading Metrics and Irrelevant Research (Accuracy and F1) | Clustify ...", "url": "https://blog.cluster-text.com/2018/12/12/misleading-metrics-and-irrelevant-research-accuracy-and-f1/", "isFamilyFriendly": true, "displayUrl": "https://blog.cluster-text.com/2018/12/12/misleading-metrics-and-ir<b>relevant</b>-re<b>search</b>...", "snippet": "The key performance metrics for ediscovery are <b>precision</b> and <b>recall</b>. <b>Recall</b>, R, is the <b>percentage</b> of all <b>relevant</b> <b>documents</b> that have been <b>found</b>. High <b>recall</b> is critical to defensibility. <b>Precision</b>, P, is the <b>percentage</b> <b>of documents</b> predicted to be <b>relevant</b> that actually are <b>relevant</b>. High <b>precision</b> is desirable to avoid wasting time reviewing non-<b>relevant</b> <b>documents</b> (if <b>documents</b> will be reviewed to confirm relevance and check for privilege before production). In other words, <b>precision</b> is ...", "dateLastCrawled": "2022-01-30T23:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Evaluation of ranked retrieval results</b> - Stanford University", "url": "https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html", "isFamilyFriendly": true, "displayUrl": "https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval...", "snippet": "R-<b>precision</b> adjusts for the size of the set <b>of relevant</b> <b>documents</b>: A perfect system could score 1 on this metric for each query, whereas, even a perfect system could only achieve a <b>precision</b> at 20 of 0.4 if there were only 8 <b>documents</b> in the collection <b>relevant</b> to an information need. Averaging this measure across queries thus makes more sense. This measure is harder to explain to naive users than <b>Precision</b> at", "dateLastCrawled": "2022-02-03T02:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Predictive Coding Performance and the Silly</b> F1 Score | Clustify Blog ...", "url": "https://blog.cluster-text.com/2013/05/08/predictive-coding-performance-and-the-silly-f1-score/", "isFamilyFriendly": true, "displayUrl": "https://blog.cluster-text.com/2013/05/08/<b>predictive-coding-performance-and-the-silly</b>-f...", "snippet": "If we were designing a web <b>search</b> <b>engine</b> to compete with Google, algorithm 3 might be pretty attractive because the <b>precision</b> at low <b>recall</b> is far more important than the <b>precision</b> at high <b>recall</b> since most people will only look at the first page or two of <b>search</b> results, not the 1000 th page. E-Discovery is very different from web <b>search</b> in that regard \u2014 you need to find most of the <b>relevant</b> <b>documents</b>, not just the 10 or 20 best ones. <b>Precision</b> at high <b>recall</b> is critical for e-discovery ...", "dateLastCrawled": "2021-12-21T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "7 Ways to Improve Your Website\u2019s or Intranet\u2019s Built-In <b>Search</b> <b>Engine</b>", "url": "https://www.nngroup.com/articles/internal-website-search/", "isFamilyFriendly": true, "displayUrl": "https://www.nngroup.com/articles/internal-website-<b>search</b>", "snippet": "The <b>recall</b> would be 100/300 or 33%, as the <b>search</b> <b>engine</b> only <b>found</b> 100 of the 300 Indian recipes available on the site, which means that 200 Indian recipes didn\u2019t show up on our <b>search</b>-results page at all. A perfect <b>search</b> <b>engine</b> would give us only 300 results total, corresponding to the 300 Indian recipes available on the site, so it would have 300/300 or 100% <b>precision</b> and <b>recall</b>. However, in the real world, that rarely happens. Different techniques that we discuss below trade off ...", "dateLastCrawled": "2022-01-23T23:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Evaluation of Information Retrieval Systems", "url": "https://clgiles.ist.psu.edu/IST441/materials/powerpoint/eval-week3/retrieval-evaluation.ppt", "isFamilyFriendly": true, "displayUrl": "https://clgiles.ist.psu.edu/IST441/materials/powerpoint/eval-week3/retrieval...", "snippet": "(Assuming a large collection) Most docs aren\u2019t <b>relevant</b> Most docs aren\u2019t retrieved Inflates the accuracy value Doc is <b>Relevant</b> Doc is NOT <b>relevant</b> Doc is retrieved a b Doc is NOT retrieved c d The F-Measure Combine <b>Precision</b> and <b>Recall</b> into one number P = <b>precision</b> R = <b>recall</b> F = [0,1] F = 1; when all ranked <b>documents</b> are <b>relevant</b> F = 0; no <b>relevant</b> <b>documents</b> have been retrieved Harmonic mean \u2013 average of rates AKA F1 measure, F-score The E-Measure Other ways to combine <b>Precision</b> and ...", "dateLastCrawled": "2022-01-29T16:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>An example information retrieval problem</b>", "url": "https://nlp.stanford.edu/IR-book/html/htmledition/an-example-information-retrieval-problem-1.html", "isFamilyFriendly": true, "displayUrl": "https://nlp.stanford.edu/IR-book/html/htmledition/an-example-information-retrieval...", "snippet": "<b>Precision</b>: What fraction of the returned results are <b>relevant</b> to the information need? <b>Recall</b>: What fraction of the <b>relevant</b> <b>documents</b> in the collection were returned by the system? Detailed discussion of relevance and evaluation measures including <b>precision</b> and <b>recall</b> is <b>found</b> in Chapter 8. We now cannot build a term-document matrix in a naive ...", "dateLastCrawled": "2022-02-02T16:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "200 Practice <b>Questions</b> For Azure <b>AI-900</b> Fundamentals Exam | by Bhargav ...", "url": "https://medium.com/bb-tutorials-and-thoughts/200-practice-questions-for-azure-ai-900-fundamentals-exam-e981d28ce91d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/bb-tutorials-and-thoughts/200-practice-<b>questions</b>-for-azure-<b>ai-900</b>...", "snippet": "For example, if there are 10 images of apples, and the model <b>found</b> 7 of them, then the <b>recall</b> is 0.7 (70%). Average <b>Precision</b> (AP): An overall metric that takes into account both <b>precision</b> and ...", "dateLastCrawled": "2022-01-30T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Elasticsearch Query-Time Strategies and Techniques for Relevance</b>: Part I", "url": "https://compose.com/articles/elasticsearch-query-time-strategies-and-techniques-for-relevance-part-i/", "isFamilyFriendly": true, "displayUrl": "https://compose.com/articles/<b>elasticsearch-query-time-strategies-and-techniques</b>-for...", "snippet": "Performing the <b>search</b> gives us some of those <b>relevant</b> <b>documents</b> and also some non-<b>relevant</b> <b>documents</b> in the result set. If we get back 50 <b>search</b> results, but only 25 of them are part of the set deemed <b>relevant</b>, then our <b>precision</b> is 50% (25 <b>relevant</b> retrieved <b>documents</b> / 50 retrieved <b>documents</b>), but our <b>recall</b> is 83% (25 <b>relevant</b> retrieved <b>documents</b> / 30 <b>relevant</b> <b>documents</b>).", "dateLastCrawled": "2022-01-28T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Recommendation systems</b>: Principles, methods and evaluation - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1110866515000341", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1110866515000341", "snippet": "F-measure defined below helps to simplify <b>precision</b> and <b>recall</b> into a single metric. The resulting value makes comparison between algorithms and across data sets very simple and straightforward . (8) F-measure = 2 PR P + R. Coverage has to do with the <b>percentage</b> of items and users that a recommender system can provide predictions. Prediction ...", "dateLastCrawled": "2022-02-02T18:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Lesson 7 - Understanding GIS Error, Accuracy, and <b>Precision</b>, and Metadata", "url": "https://www.e-education.psu.edu/geog469/book/export/html/252", "isFamilyFriendly": true, "displayUrl": "https://www.e-education.psu.edu/geog469/book/export/html/252", "snippet": "Data sources may simply be to old to be useful or <b>relevant</b> to current GIS projects. Past collection standards may be unknown, non-existent, or not currently acceptable. For instance, John Wesley Powell&#39;s nineteenth century survey data of the Grand Canyon lacks the <b>precision</b> of data that can be developed and used today. Additionally, much of the information base may have subsequently changed through erosion, deposition, and other geomorphic processes. Despite the power of GIS, reliance on old ...", "dateLastCrawled": "2022-02-02T13:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Precision and recall</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Precision_and_recall", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Precision_and_recall</b>", "snippet": "Introduction. In information retrieval, the instances are <b>documents</b> and the task is to return a set <b>of relevant</b> <b>documents</b> given a <b>search</b> term.<b>Recall</b> is the number <b>of relevant</b> <b>documents</b> retrieved <b>by a search</b> divided by the total number of existing <b>relevant</b> <b>documents</b>, while <b>precision</b> is the number <b>of relevant</b> <b>documents</b> retrieved <b>by a search</b> divided by the total number <b>of documents</b> retrieved by that <b>search</b>.. In a classification task, the <b>precision</b> for a class is the number of true positives (i ...", "dateLastCrawled": "2022-02-05T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Elasticsearch Query-Time Strategies and Techniques for Relevance</b>: Part I", "url": "https://compose.com/articles/elasticsearch-query-time-strategies-and-techniques-for-relevance-part-i/", "isFamilyFriendly": true, "displayUrl": "https://compose.com/articles/<b>elasticsearch-query-time-strategies-and-techniques</b>-for...", "snippet": "<b>Precision</b> <b>vs</b> <b>Recall</b>. If you&#39;re responsible for <b>search</b>, then you should have a basic understanding of <b>precision</b> and <b>recall</b>. These two measures will shape the strategies we&#39;ll focus on in this article. <b>Precision</b> is the number <b>of relevant</b> <b>documents</b> retrieved divided by the total number of retrieved <b>documents</b>. <b>Precision</b> = <b>relevant</b> <b>documents</b> retrieved / retrieved <b>documents</b>. <b>Recall</b> is the number <b>of relevant</b> <b>documents</b> retrieved divided by the total of all <b>relevant</b> <b>documents</b>. <b>Recall</b> = <b>relevant</b> ...", "dateLastCrawled": "2022-01-28T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A COMPARATIVE EVALUATION OF THE <b>RECALL</b> AND <b>PRECISION</b> OF <b>SEARCH</b> ENGINES ...", "url": "https://www.thefreelibrary.com/A+COMPARATIVE+EVALUATION+OF+THE+RECALL+AND+PRECISION+OF+SEARCH...-a0416324953", "isFamilyFriendly": true, "displayUrl": "https://www.thefreelibrary.com/A+COMPARATIVE+EVALUATION+OF+THE+<b>RECALL</b>+AND+<b>PRECISION</b>+OF...", "snippet": "This study aimed to determine and compare the <b>precision</b> and <b>recall</b> of <b>search</b> <b>engine</b> and meta <b>search</b> <b>engine</b> in retrieval of medical images. This study was applied and comparative-monitoring survey. The population was including five <b>engine</b> <b>search</b>; Ask, Bing, Google, Lycos, Yahoo and four meta <b>search</b> engines of Excite, Dogpile, Mamma and Metacrawler. 30 keywords were selected by medical experts and were searched in these engines and meta <b>search</b> <b>engine</b>. The first ten results of each <b>search</b> ...", "dateLastCrawled": "2021-02-24T19:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Evaluation of Information Retrieval Systems", "url": "https://clgiles.ist.psu.edu/IST441/materials/powerpoint/eval-week3/retrieval-evaluation.ppt", "isFamilyFriendly": true, "displayUrl": "https://clgiles.ist.psu.edu/IST441/materials/powerpoint/eval-week3/retrieval...", "snippet": "(Assuming a large collection) Most docs aren\u2019t <b>relevant</b> Most docs aren\u2019t retrieved Inflates the accuracy value Doc is <b>Relevant</b> Doc is NOT <b>relevant</b> Doc is retrieved a b Doc is NOT retrieved c d The F-Measure Combine <b>Precision</b> and <b>Recall</b> into one number P = <b>precision</b> R = <b>recall</b> F = [0,1] F = 1; when all ranked <b>documents</b> are <b>relevant</b> F = 0; no <b>relevant</b> <b>documents</b> have been retrieved Harmonic mean \u2013 average of rates AKA F1 measure, F-score The E-Measure Other ways to combine <b>Precision</b> and ...", "dateLastCrawled": "2022-01-29T16:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Things Not Strings: <b>Understanding Search Intent with Better</b> <b>Recall</b>", "url": "https://doordash.engineering/2020/12/15/understanding-search-intent-with-better-recall/", "isFamilyFriendly": true, "displayUrl": "https://doordash.<b>engine</b>ering/2020/12/15/<b>understanding-search-intent-with-better</b>-<b>recall</b>", "snippet": "Rethinking our fixes on the <b>recall</b> and <b>precision</b> fronts. For the first iteration, we wanted to create the simplest possible <b>search</b> pipeline that could help fix our <b>recall</b> and <b>precision</b> problems. Accordingly, we made the following changes in the two steps of our <b>search</b> pipeline: On the <b>recall</b> front, we built a three-part pipeline which identifies, interprets, and elaborates upon any query within the base set. This pipeline would help test our hypothesis that the <b>recall</b> can improve if we treat ...", "dateLastCrawled": "2022-01-29T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "200 Practice <b>Questions</b> For Azure <b>AI-900</b> Fundamentals Exam | by Bhargav ...", "url": "https://medium.com/bb-tutorials-and-thoughts/200-practice-questions-for-azure-ai-900-fundamentals-exam-e981d28ce91d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/bb-tutorials-and-thoughts/200-practice-<b>questions</b>-for-azure-<b>ai-900</b>...", "snippet": "For example, if there are 10 images of apples, and the model <b>found</b> 7 of them, then the <b>recall</b> is 0.7 (70%). Average <b>Precision</b> (AP) : An overall metric that takes into account both <b>precision</b> and ...", "dateLastCrawled": "2022-01-30T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Lesson 7 - Understanding GIS Error, Accuracy, and <b>Precision</b>, and Metadata", "url": "https://www.e-education.psu.edu/geog469/book/export/html/252", "isFamilyFriendly": true, "displayUrl": "https://www.e-education.psu.edu/geog469/book/export/html/252", "snippet": "Map <b>precision</b> <b>is similar</b> to decimal <b>precision</b>. Precise location data may measure position to a fraction of a unit (meters, feet, inches, etc.). <b>Precision</b> attribute information may specify the characteristics of features in great detail. As an example of <b>precision</b>, say you try on two pairs of shoes of the same size but different colors. One pair fits as you would expect, but the other pair is too short. Do you suspect a quality issue with the shoes or do you buy the shoes that fit? Would you ...", "dateLastCrawled": "2022-02-02T13:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>The extended Boolean model versus ranked retrieval</b>", "url": "https://nlp.stanford.edu/IR-book/html/htmledition/the-extended-boolean-model-versus-ranked-retrieval-1.html", "isFamilyFriendly": true, "displayUrl": "https://nlp.stanford.edu/IR-book/html/htmledition/<b>the-extended-boolean-model-versus</b>...", "snippet": "Moreover, over time, web <b>search</b> engines have added at least partial implementations of some of the most popular operators from extended Boolean models: phrase <b>search</b> is especially popular and most have a very partial implementation of Boolean operators. Nevertheless, while these options are liked by expert searchers, they are little used by most people and are not the main focus in work on trying to improve web <b>search</b> <b>engine</b> performance.", "dateLastCrawled": "2022-02-03T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Classify Text Using spaCy \u2013 <b>Dataquest</b>", "url": "https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>dataquest</b>.io/blog/tutorial-text-classification-in-python-using-spacy", "snippet": "It\u2019s also used in advertisement matching\u2014determining the subject of a body of text and assigning a <b>relevant</b> advertisement automatically. And it\u2019s used in chatbots, voice assistants, and other applications where machines need to understand and quickly respond to input that comes in the form of natural human language. Analyzing and Processing Text With spaCy. spaCy is an open-source natural language processing library for Python. It is designed particularly for production use, and it can ...", "dateLastCrawled": "2022-02-02T14:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning and Data Mining</b>: 19 Mining Text And Web Data - SlideShare", "url": "https://www.slideshare.net/pierluca.lanzi/machine-learning-and-data-mining-19-mining-text-and-web-data", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/pierluca.lanzi/<b>machine-learning-and-data-mining</b>-19-mining...", "snippet": "Text Databases and Information Retrieval 15 Text databases (document databases) Large collections <b>of documents</b> from various sources: news articles, research papers, books, digital libraries, E-mail messages, and Web pages, library database, etc. Data stored is usually semi-structured Traditional information retrieval techniques become inadequate for the increasingly vast amounts of text data Information retrieval A field developed in parallel with database systems Information is organized ...", "dateLastCrawled": "2022-01-20T00:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Elasticsearch Query-Time Strategies and Techniques for Relevance</b>: Part I", "url": "https://compose.com/articles/elasticsearch-query-time-strategies-and-techniques-for-relevance-part-i/", "isFamilyFriendly": true, "displayUrl": "https://compose.com/articles/<b>elasticsearch-query-time-strategies-and-techniques</b>-for...", "snippet": "<b>Precision</b> <b>vs</b> <b>Recall</b>. If you&#39;re responsible for <b>search</b>, then you should have a basic understanding of <b>precision</b> and <b>recall</b>. These two measures will shape the strategies we&#39;ll focus on in this article. <b>Precision</b> is the number <b>of relevant</b> <b>documents</b> retrieved divided by the total number of retrieved <b>documents</b>. <b>Precision</b> = <b>relevant</b> <b>documents</b> ...", "dateLastCrawled": "2022-01-28T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Predictive Coding Performance and the Silly</b> F1 Score | Clustify Blog ...", "url": "https://blog.cluster-text.com/2013/05/08/predictive-coding-performance-and-the-silly-f1-score/", "isFamilyFriendly": true, "displayUrl": "https://blog.cluster-text.com/2013/05/08/<b>predictive-coding-performance-and-the-silly</b>-f...", "snippet": "If we were designing a web <b>search</b> <b>engine</b> to compete with Google, algorithm 3 might be pretty attractive because the <b>precision</b> at low <b>recall</b> is far more important than the <b>precision</b> at high <b>recall</b> since most people will only look at the first page or two of <b>search</b> results, not the 1000 th page. E-Discovery is very different from web <b>search</b> in that regard \u2014 you need to find most of the <b>relevant</b> <b>documents</b>, not just the 10 or 20 best ones. <b>Precision</b> at high <b>recall</b> is critical for e-discovery ...", "dateLastCrawled": "2021-12-21T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "200 Practice <b>Questions</b> For Azure <b>AI-900</b> Fundamentals Exam | by Bhargav ...", "url": "https://medium.com/bb-tutorials-and-thoughts/200-practice-questions-for-azure-ai-900-fundamentals-exam-e981d28ce91d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/bb-tutorials-and-<b>thoughts</b>/200-practice-<b>questions</b>-for-azure-<b>ai-900</b>...", "snippet": "<b>Recall</b>: What <b>percentage</b> of class predictions did the model correctly identify? For example, if there are 10 images of apples, and the model <b>found</b> 7 of them, then the <b>recall</b> is 0.7 (70%).", "dateLastCrawled": "2022-01-30T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Language Log \u00bb Moving low-hanging fruit <b>forward at the end of</b> the day", "url": "https://languagelog.ldc.upenn.edu/nll/?p=1768", "isFamilyFriendly": true, "displayUrl": "https://languagelog.ldc.upenn.edu/nll/?p=1768", "snippet": "We use it in the sense of narrowing a <b>search</b>, or balancing <b>recall</b> and <b>precision</b> (i.e. number <b>of documents</b> returned <b>vs</b>. <b>percentage</b> <b>of relevant</b> <b>documents</b> returned), but I&#39;ve also heard it used for things such as navigating menus in a GUI. As a relatively enlightened thinker with regard to the dangers of prescriptivism and as a professional Grammarian (my actual job title) for a company that uses NLP technology, you might think that I&#39;d be unaffected by peevishness about such terms. And yet, I ...", "dateLastCrawled": "2021-12-29T20:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>An example information retrieval problem</b>", "url": "https://nlp.stanford.edu/IR-book/html/htmledition/an-example-information-retrieval-problem-1.html", "isFamilyFriendly": true, "displayUrl": "https://nlp.stanford.edu/IR-book/html/htmledition/an-example-information-retrieval...", "snippet": "In it, a system aims to provide <b>documents</b> from within the collection <b>that are relevant</b> to an arbitrary user information need, communicated to the system by means of a one-off, user-initiated query. An information need is the topic about which the user desires to know more, and is differentiated from a query , which is what the user conveys to the computer in an attempt to communicate the information need.", "dateLastCrawled": "2022-02-02T16:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Recommendation systems</b>: Principles, methods and evaluation - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1110866515000341", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1110866515000341", "snippet": "Once a neighbor of a user is <b>found</b>, different algorithms <b>can</b> be used to combine the preferences of neighbors to generate recommendations. Due to the effectiveness of these techniques, they have achieved widespread success in real life applications. Memory-based CF <b>can</b> be achieved in two ways through user-based and item-based techniques. User based collaborative filtering technique calculates similarity between users by comparing their ratings on the same item, and it then computes the ...", "dateLastCrawled": "2022-02-02T18:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Patent</b> retrieval: a literature review | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10115-018-1322-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10115-018-1322-7", "snippet": "Technology-assisted review, such as <b>patent</b> retrieval, is a total-<b>recall</b> task where it is required to find all <b>relevant</b> <b>documents</b> to the <b>search</b> request with reasonable effort (time and cost). It is thus a human-in-the-loop process where a human expert manually annotates a subset of the <b>documents</b> as <b>relevant</b> or irrelevant. The underlying algorithm subsequently builds a ranking model by training on such annotations and uses this model to promote more <b>relevant</b> results and demote irrelevant ones ...", "dateLastCrawled": "2021-12-02T18:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Increasing evaluation sensitivity to diversity</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10791-012-9218-8", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10791-012-9218-8", "snippet": "A commercial web <b>search</b> <b>engine</b>\u2014which, in theory, indexes the entire web\u2014must retrieve <b>relevant</b> <b>documents</b> for every <b>search</b> intent, no matter how rare. In this context, it is important to find those intents that the <b>search</b> <b>engine</b> is unable to satisfy so that the situation <b>can</b> be rectified. TREC collections, however, are more artificial. Designed to evaluate <b>search</b> engines, they consist of a first tier web crawl and topics created by visually inspecting the <b>search</b> logs of a commercial ...", "dateLastCrawled": "2021-10-11T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Data Science&amp;Big <b>Data Analytics</b> | Vijaya Lakshmi - Academia.edu", "url": "https://www.academia.edu/36833452/Data_Science_and_Big_Data_Analytics", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/36833452/Data_Science_and_Big_<b>Data_Analytics</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-02T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Get Homework Help with <b>Chegg</b> Study | <b>Chegg</b>.com", "url": "https://www.chegg.com/study", "isFamilyFriendly": true, "displayUrl": "https://www.<b>chegg</b>.com/study", "snippet": "Q: 1. We wish to approximate the function f(x) = sin(?). = (a) (2 points) Expand f(x) in a Taylor series about Xo = 1 to at least three terms. You do not need to comput A:See Answer; Q: Lab 3 \u2013 Editing for Effective Technical Prose Style (2) Edit the following sentences to reinforce meaning. Briefly explain the stylistic problems in each sentence an A:See Answer; Q: Challenge is to design a backpack that is best suited for the needs, wants, and price sensitivity of the Outdoor Enthusiast ...", "dateLastCrawled": "2022-02-02T22:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Misleading Metrics and Irrelevant Research (Accuracy and F1) | Clustify ...", "url": "https://blog.cluster-text.com/2018/12/12/misleading-metrics-and-irrelevant-research-accuracy-and-f1/", "isFamilyFriendly": true, "displayUrl": "https://blog.cluster-text.com/2018/12/12/misleading-metrics-and-ir<b>relevant</b>-re<b>search</b>...", "snippet": "<b>Recall</b>, R, is the <b>percentage</b> of all <b>relevant</b> <b>documents</b> that have been <b>found</b>. High <b>recall</b> is critical to defensibility. <b>Precision</b>, P, is the <b>percentage</b> <b>of documents</b> predicted to be <b>relevant</b> that actually are <b>relevant</b>. High <b>precision</b> is desirable to avoid wasting time reviewing non-<b>relevant</b> <b>documents</b> (if <b>documents</b> will be reviewed to confirm ...", "dateLastCrawled": "2022-01-30T23:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Evaluation of Information Retrieval Systems", "url": "https://clgiles.ist.psu.edu/IST441/materials/powerpoint/eval-week3/retrieval-evaluation.ppt", "isFamilyFriendly": true, "displayUrl": "https://clgiles.ist.psu.edu/IST441/materials/powerpoint/eval-week3/retrieval...", "snippet": "<b>Precision</b> is the <b>percentage</b> <b>of relevant</b> <b>documents</b> <b>compared</b> to what is returned! What different situations of <b>recall</b> and <b>precision</b> <b>can</b> we have? Experimental Results Much of IR is experimental! Formal methods are lacking Role of artificial intelligence hopes to change this Derive much insight from these results Retrieve one document at a time without replacement and in order. Given: only 25 <b>documents</b> of which 5 are <b>relevant</b> (D1, D2, D4, D15, D25) Calculate <b>precision</b> and <b>recall</b> after each ...", "dateLastCrawled": "2022-01-29T16:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 2, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Precision and recall</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Precision_and_recall", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Precision_and_recall</b>", "snippet": "Introduction. In information retrieval, the instances are <b>documents</b> and the task is to return a set <b>of relevant</b> <b>documents</b> given a <b>search</b> term.<b>Recall</b> is the number <b>of relevant</b> <b>documents</b> retrieved <b>by a search</b> divided by the total number of existing <b>relevant</b> <b>documents</b>, while <b>precision</b> is the number <b>of relevant</b> <b>documents</b> retrieved <b>by a search</b> divided by the total number <b>of documents</b> retrieved by that <b>search</b>.. In a classification task, the <b>precision</b> for a class is the number of true positives (i ...", "dateLastCrawled": "2022-02-05T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Predictive Coding Performance and the Silly</b> F1 Score | Clustify Blog ...", "url": "https://blog.cluster-text.com/2013/05/08/predictive-coding-performance-and-the-silly-f1-score/", "isFamilyFriendly": true, "displayUrl": "https://blog.cluster-text.com/2013/05/08/<b>predictive-coding-performance-and-the-silly</b>-f...", "snippet": "If we were designing a web <b>search</b> <b>engine</b> to compete with Google, algorithm 3 might be pretty attractive because the <b>precision</b> at low <b>recall</b> is far more important than the <b>precision</b> at high <b>recall</b> since most people will only look at the first page or two of <b>search</b> results, not the 1000 th page. E-Discovery is very different from web <b>search</b> in that regard \u2014 you need to find most of the <b>relevant</b> <b>documents</b>, not just the 10 or 20 best ones. <b>Precision</b> at high <b>recall</b> is critical for e-discovery ...", "dateLastCrawled": "2021-12-21T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "200 Practice <b>Questions</b> For Azure <b>AI-900</b> Fundamentals Exam | by Bhargav ...", "url": "https://medium.com/bb-tutorials-and-thoughts/200-practice-questions-for-azure-ai-900-fundamentals-exam-e981d28ce91d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/bb-tutorials-and-thoughts/200-practice-<b>questions</b>-for-azure-<b>ai-900</b>...", "snippet": "<b>Recall</b>: What <b>percentage</b> of class predictions did the model correctly identify? For example, if there are 10 images of apples, and the model <b>found</b> 7 of them, then the <b>recall</b> is 0.7 (70%).", "dateLastCrawled": "2022-01-30T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Automated Indexing", "url": "https://www.nal.usda.gov/sites/default/files/resources/nfais_automated_indexing_april_10_2014_1.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.nal.usda.gov/sites/default/files/resources/nfais_automated_indexing_april...", "snippet": "document <b>can</b> more easily be <b>found</b> in an information system / database. Automated Indexing uses computer software to scan the document and select terms to describe the subject content. Machine-Aided Indexing uses computer software to scan the document and select terms to describe the subject content AND is reviewed and edited by Human indexers. Human indexers add terms missed by the computer or delete terms assigned by the computer that are incorrect. What is \u201cindexing\u201d? Measuring ...", "dateLastCrawled": "2021-09-17T19:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Lesson 7 - Understanding GIS Error, Accuracy, and <b>Precision</b>, and Metadata", "url": "https://www.e-education.psu.edu/geog469/book/export/html/252", "isFamilyFriendly": true, "displayUrl": "https://www.e-education.psu.edu/geog469/book/export/html/252", "snippet": "Data sources may simply be to old to be useful or <b>relevant</b> to current GIS projects. Past collection standards may be unknown, non-existent, or not currently acceptable. For instance, John Wesley Powell&#39;s nineteenth century survey data of the Grand Canyon lacks the <b>precision</b> of data that <b>can</b> be developed and used today. Additionally, much of the ...", "dateLastCrawled": "2022-02-02T13:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Text Summarization in Python: Extractive vs. Abstractive</b> techniques ...", "url": "https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/", "isFamilyFriendly": true, "displayUrl": "https://rare-technologies.com/<b>text-summarization-in-python-extractive-vs-abstractive</b>...", "snippet": "The above ratios <b>can</b> be interpreted as the amount <b>of relevant</b> information that our algorithm managed to extract from the set of all the <b>relevant</b> information, which is exactly the definition of <b>recall</b>, and hence Rouge is <b>recall</b> based. More examples of how to calculate the scores are in this gist. The BLEU metric; BLEU metric is a modified form of <b>precision</b>, extensively used in machine translation evaluation. <b>Precision</b> is the ratio of the number of words that co-occur in both gold and model ...", "dateLastCrawled": "2022-01-31T16:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "what does <b>recall</b> refers to in math definition - Yahoo <b>Search</b> Results", "url": "https://search.yahoo.com/reviews?q=what+does+recall+refers+to+in+math+definition&ei=UTF-8&v_t=rs-bot&fr2=p%3As%2Cv%3Aw%2Cm%3Ars-bottom", "isFamilyFriendly": true, "displayUrl": "https://<b>search.yahoo.com</b>/reviews?q=what+does+<b>recall</b>+refers+to+in+math+definition&amp;ei=UTF...", "snippet": "<b>Recall</b>, sometimes referred to as \u2018sensitivity, is the fraction of retrieved instances among all <b>relevant</b> instances.A perfect classifier has <b>precision</b> and <b>recall</b> both equal to 1. It is often possible to calibrate the number of results returned by a model and improve <b>precision</b> at the expense of <b>recall</b>, or vice versa.", "dateLastCrawled": "2022-01-06T03:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "On the choice of effectiveness measures for learning to rank | SpringerLink", "url": "https://link.springer.com/article/10.1007%2Fs10791-009-9116-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10791-009-9116-x", "snippet": "Out of the many evaluation metrics proposed in IR, <b>precision</b> at cutoff k (PC(k)), average <b>precision</b> (AP), and NDCG are three of the most commonly used metrics.. Assuming that the user is only interested in top k <b>documents</b>, PC(k) is defined as the proportion <b>of relevant</b> <b>documents</b> up to rank k.A typical value for k is 10, based on web <b>search</b> engines.. AP <b>can</b> be defined as the average of <b>precision</b> values at each <b>relevant</b> document.", "dateLastCrawled": "2022-01-09T23:54:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>An Intuitive Explanation to Precision, Recall and</b> Accuracy", "url": "https://www.linkedin.com/pulse/intuitive-explanation-precision-recall-accuracy-daniel-d-souza/", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/intuitive-explanation-<b>precision</b>-<b>recall</b>-accuracy-daniel...", "snippet": "Earlier this year, at an interview in New York I was asked about the <b>recall</b> and <b>precision</b> of one of my <b>Machine</b> <b>Learning</b> Projects. For a couple of minutes following that, the interviewer sat back ...", "dateLastCrawled": "2021-10-21T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Model Scores and Ratings - Tealium <b>Learning</b> Center", "url": "https://community.tealiumiq.com/t5/Tealium-Predict-ML/Model-Scores-and-Ratings/ta-p/33164", "isFamilyFriendly": true, "displayUrl": "https://community.tealiumiq.com/t5/Tealium-Predict-ML/Model-Scores-and-Ratings/ta-p/33164", "snippet": "<b>Precision</b> <b>vs</b>. <b>Recall</b> <b>Analogy</b>. Using the same example of red and green apples, the following list describes expected results based on high or low <b>Precision</b> or <b>Recall</b>. High <b>Precision</b>, low <b>Recall</b> = a short list of red apples that is fairly accurate. High <b>Precision</b>, high <b>recall</b> = a longer list of red apples that is fairly accurate; Low <b>Precision</b>, low <b>Recall</b> = a short list of red apples that is fairly inaccurate. This list contains more green apples. Low <b>Precision</b>, high <b>Recall</b> = a long list of ...", "dateLastCrawled": "2022-01-09T16:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Explaining <b>precision</b> and <b>recall</b>. The first days and weeks of getting ...", "url": "https://medium.com/@klintcho/explaining-precision-and-recall-c770eb9c69e9", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@klintcho/explaining-<b>precision</b>-and-<b>recall</b>-c770eb9c69e9", "snippet": "There are a lot more to say about <b>precision</b>/<b>recall</b>, but this will hopefully provide a good introduction. In general one take away when building <b>machine</b> <b>learning</b> applications for the real world.", "dateLastCrawled": "2022-01-27T17:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What are the definitions of <b>Precision</b> and <b>Recall</b>? | Towards Data Science", "url": "https://towardsdatascience.com/precision-and-recall-88a3776c8007", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>precision</b>-and-<b>recall</b>-88a3776c8007", "snippet": "For some, this can be a great way to memorise something too. Reddit user u/question_23 used a common <b>analogy</b> for <b>Precision</b> and <b>Recall</b> in a very nice way in this post, which I\u2019ve paraphrased below: Explain it like fishing with a net. You use a wide net, and catch 80 of 100 total fish in a lake. That\u2019s 80% <b>recall</b>. But you also get 80 rocks in your net. That means 50% <b>precision</b>, half of the net\u2019s contents is junk. You could use a smaller net and target one pocket of the lake where there ...", "dateLastCrawled": "2022-01-14T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "When Accuracy Isn\u2019t Enough, Use <b>Precision</b> and <b>Recall</b> to Evaluate ...", "url": "https://builtin.com/data-science/precision-and-recall", "isFamilyFriendly": true, "displayUrl": "https://builtin.com/data-science/<b>precision</b>-and-<b>recall</b>", "snippet": "By altering the threshold, we try to achieve the right <b>precision</b> <b>vs</b>. <b>recall</b> balance. A ROC curve plots the true positive rate on the y-axis versus the false positive rate on the x-axis. The true positive rate (TPR) is the <b>recall</b>, and the false positive rate (FPR) is the probability of a false alarm. Both of these can be calculated from the confusion matrix: A typical ROC curve looks like this: Receiver operating characteristic curve. The black diagonal line indicates a random classifier, and ...", "dateLastCrawled": "2022-02-02T02:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Use <b>machine learning for software development estimation</b>", "url": "https://uruit.com/blog/software-estimation-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://uruit.com/blog/software-estimation-<b>machine</b>-<b>learning</b>", "snippet": "F1 = 2 x (<b>precision</b> x <b>recall</b>) / (<b>precision</b> + <b>recall</b>) With this introduction to what a confusion matrix is, and the metrics that we can calculate, now let\u2019s define a helper method to help us plot a pretty confusion matrix like the one in the image above. Later, after obtaining the final results we will see how to examine a confusion matrix and ...", "dateLastCrawled": "2022-02-03T11:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning Accuracy</b>: True <b>vs</b>. False Positive/Negative", "url": "https://research.aimultiple.com/machine-learning-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://research.aimultiple.com/<b>machine-learning-accuracy</b>", "snippet": "In this article, we focused on comparing different <b>machine</b> <b>learning</b> models and the value they generate for your business. Based on the 4 types of results of a model (e.g. true positives etc.), other ratios are derived by statisticans to discuss model quality. The most common ones are <b>precision</b> and <b>recall</b>, sensitivity and specifity and F1 score ...", "dateLastCrawled": "2022-02-03T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "More Performance Evaluation Metrics for Classification Problems You ...", "url": "https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/04/performance-evaluation-metrics-classification.html", "snippet": "The key classification metrics: Accuracy, <b>Recall</b>, <b>Precision</b>, ... Let me put it in an interesting scenario in terms of pregnancy <b>analogy</b> to explain the terms of TP, FP, FN, TN. We can then understand <b>Recall</b>, <b>Precision</b>, Specificity, Accuracy, and, most importantly, the AUC-ROC Curve. image source . The equations of 4 key classification metrics . <b>Recall</b> versus <b>Precision</b> . <b>Precision</b> is the ratio of True Positives to all the positives predicted by the model. Low <b>precision</b>: the more False ...", "dateLastCrawled": "2022-01-26T05:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - How to calculate <b>precision</b> and <b>recall</b> in a 3 x 3 ...", "url": "https://stats.stackexchange.com/questions/91044/how-to-calculate-precision-and-recall-in-a-3-x-3-confusion-matrix", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/91044/how-to-calculate-<b>precision</b>-and-<b>recall</b>...", "snippet": "How can I calculate <b>precision</b> and <b>recall</b> so It become easy to calculate F1-score. The normal <b>confusion matrix</b> is a 2 x 2 dimension. However, when it become 3 x 3 I don&#39;t know how to calculate <b>precision</b> and <b>recall</b>. <b>machine</b>-<b>learning</b> <b>precision</b>-<b>recall</b>. Share. Cite. Improve this question. Follow edited Mar 23 &#39;14 at 11:58. TooTone. 3,621 24 24 silver badges 33 33 bronze badges. asked Mar 23 &#39;14 at 8:26. user22149 user22149. 163 1 1 gold badge 1 1 silver badge 4 4 bronze badges $\\endgroup$ 0. Add ...", "dateLastCrawled": "2022-01-30T05:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Preliminary performance study of a brief review on <b>machine</b> <b>learning</b> ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "snippet": "<b>Analogy</b>-based effort estimation is the major task of software engineering which estimates the effort required for new software projects using existing histories for corresponding development and management. In general, the high accuracy of software effort estimation techniques can be a non-solvable problem we named as multi-objective problem. Recently, most of the authors have been used <b>machine</b> <b>learning</b> techniques for the same process however not possible to meet the higher performance ...", "dateLastCrawled": "2022-01-02T12:16:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(recall vs precision)  is like +(percentage of relevant documents that are found by a search engine vs percentage of documents that are relevant that are found by a search engine)", "+(recall vs precision) is similar to +(percentage of relevant documents that are found by a search engine vs percentage of documents that are relevant that are found by a search engine)", "+(recall vs precision) can be thought of as +(percentage of relevant documents that are found by a search engine vs percentage of documents that are relevant that are found by a search engine)", "+(recall vs precision) can be compared to +(percentage of relevant documents that are found by a search engine vs percentage of documents that are relevant that are found by a search engine)", "machine learning +(recall vs precision AND analogy)", "machine learning +(\"recall vs precision is like\")", "machine learning +(\"recall vs precision is similar\")", "machine learning +(\"just as recall vs precision\")", "machine learning +(\"recall vs precision can be thought of as\")", "machine learning +(\"recall vs precision can be compared to\")"]}