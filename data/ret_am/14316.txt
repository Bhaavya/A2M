{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Spatial</b> <b>pooling</b> inherent to intrinsic signal optical imaging might ...", "url": "https://www.pnas.org/content/115/30/E6967", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/115/30/E6967", "snippet": "Using intrinsic signal optical imaging, Chen et al. (1) show that disparity <b>information</b> in <b>visual</b> area V2 is decodable from correlated random dot stereograms (cRDSs), but not from anticorrelated RDSs (aRDSs). The authors conclude that \u201cV2 is the initial locus of false matching elimination,\u201d indicating that the correspondence problem is solved within or immediately after V2. We disagree with this conclusion based on previous single-unit studies. <b>Two</b> immediate downstream areas of V2 ...", "dateLastCrawled": "2021-01-26T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Spatial</b> <b>pooling</b> inherent to intrinsic signal optical imaging ...", "url": "https://www.researchgate.net/publication/326239086_Spatial_pooling_inherent_to_intrinsic_signal_optical_imaging_might_cause_V2_to_resemble_a_solution_to_the_stereo_correspondence_problem", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/326239086_<b>Spatial</b>_<b>pooling</b>_inherent_to...", "snippet": "The goal of this project is to explore and understand the neural processing during active search in <b>visual</b> scenes. In natural vision, <b>our</b> <b>eyes</b> move in a ballistic fashion 3-4 times a second ...", "dateLastCrawled": "2021-12-14T17:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Visual</b>\u2013auditory <b>spatial</b> processing in auditory cortical neurons", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4340571/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4340571", "snippet": "<b>Our</b> results show that <b>visual</b> inputs to auditory cortex do indeed increase the <b>information</b> about stimulus location in the responses of the neurons and that the extent to which they do so varies in a predictable fashion according to the source of the inputs from extrastriate <b>visual</b> cortex. 2. Results. The extracellular responses of 305 single units were recorded from 5 auditory fields in 5 ferrets. Fig. 1 illustrates the location of all the auditory fields that have so far been identified in ...", "dateLastCrawled": "2022-01-21T12:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is the difference between simple max <b>pooling</b> and <b>spatial</b> pyramid ...", "url": "https://www.quora.com/What-is-the-difference-between-simple-max-pooling-and-spatial-pyramid-pooling-Im-seeing-these-terms-a-lot-lately-in-papers-where-the-authors-need-to-get-a-feature-vector", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-simple-max-<b>pooling</b>-and-<b>spatial</b>...", "snippet": "Answer (1 of 2): I would rather treat both concepts independently. <b>Spatial</b> pyramid matching is, conceptually, a method of building a more abstract representation of the images preserving some <b>spatial</b> <b>information</b> by spatially dividing images in some special way. Such higher order representation in...", "dateLastCrawled": "2022-01-24T16:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Multi-Modal Factorized Bilinear <b>Pooling</b> With Co-Attention Learning for ...", "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Yu_Multi-Modal_Factorized_Bilinear_ICCV_2017_paper.pdf?source=post_page---------------------------", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Yu_Multi-Modal_Factorized...", "snippet": "Multi-modal Factorized Bilinear <b>Pooling</b> with Co-Attention Learning for <b>Visual</b> Question Answering ... close performance <b>like</b> human beings, is an important step towards enabling arti\ufb01cial intelligence in general. Existing VQA approaches usually have three stages: (1) representing the images as <b>visual</b> features and questions as textual features; (2) <b>combining</b> these multi-modal features to obtain fused image-question features; (3) using the integrated image-question features to learn a multi ...", "dateLastCrawled": "2022-01-29T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Spatially Enhanced Bags of <b>Visual Words Representation to Improve</b> ...", "url": "https://link.springer.com/article/10.1007%2Fs11265-017-1324-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11265-017-1324-9", "snippet": "In , a pairwise <b>spatial</b> histogram is defined according to a discretization of the <b>spatial</b> neighborhood into several bins encoding the relative <b>spatial</b> position (distance and angle) of <b>two</b> <b>visual</b> words. Therefore, <b>combining</b> the frequency of occurrence and <b>spatial</b> <b>information</b> of <b>visual</b> words should be a promising direction for improving the image characterization.", "dateLastCrawled": "2022-01-25T15:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep gaze <b>pooling</b>: Inferring and visually decoding search intents from ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231220300667", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231220300667", "snippet": "We further show the application of <b>our</b> Gaze <b>Pooling</b> Layer in <b>two</b> different frameworks, for prediction and decoding of the <b>visual</b> search targets of users from their gaze data during <b>visual</b> search. The proposed layer is parameter-free and does not need any gaze data to be trained on. In the following, we describe the major components of <b>our</b> method in detail: the Gaze <b>Pooling</b> Layer, search target prediction and search target decoder. Finally, we also discuss different integration schemes across ...", "dateLastCrawled": "2021-12-15T18:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Holistic face recognition is an emergent phenomenon of <b>spatial</b> ...", "url": "https://www.nature.com/articles/s41467-021-24806-1", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-021-24806-1", "snippet": "<b>Spatial</b> processing by receptive fields is a core property of the <b>visual</b> system. However, it is unknown how <b>spatial</b> processing in high-level regions contributes to recognition behavior. As face ...", "dateLastCrawled": "2022-02-03T14:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Do convolutional neural networks learn to be spatially ... - Quora", "url": "https://www.quora.com/Do-convolutional-neural-networks-learn-to-be-spatially-invariant-at-the-last-layer-of-the-network-fully-connected-layer-Convolution-layers-produce-spatially-equivariant-output-but-what-about-the-spatial-invariance", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Do-convolutional-neural-ne<b>two</b>rks-learn-to-be-<b>spatial</b>ly-invariant...", "snippet": "Answer (1 of 4): <b>Spatial</b> invariance comes from the convolutional layers. That in fact is the point of using convolutional filters. A convolutional filter takes in an image, calculates a moving average of the pixel values, and uses that value for a single pixel in the feature map it is creating. ...", "dateLastCrawled": "2022-01-13T11:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Remote Sensing | Free Full-Text | Multi-Modality and Multi-Scale ...", "url": "https://www.mdpi.com/2072-4292/13/18/3771/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/13/18/3771/htm", "snippet": "Land cover classification from very high-resolution (VHR) remote sensing images is a challenging task due to the complexity of geography scenes and the varying shape and size of ground targets. It is difficult to utilize the spectral data directly, or to use traditional multi-scale feature extraction methods, to improve VHR remote sensing image classification results. To address the problem, we proposed a multi-modality and multi-scale attention fusion network for land cover classification ...", "dateLastCrawled": "2022-02-02T07:57:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Spatial</b> <b>pooling</b> inherent to intrinsic signal optical imaging might ...", "url": "https://www.pnas.org/content/115/30/E6967", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/115/30/E6967", "snippet": "Using intrinsic signal optical imaging, Chen et al. (1) show that disparity <b>information</b> in <b>visual</b> area V2 is decodable from correlated random dot stereograms (cRDSs), but not from anticorrelated RDSs (aRDSs). The authors conclude that \u201cV2 is the initial locus of false matching elimination,\u201d indicating that the correspondence problem is solved within or immediately after V2. We disagree with this conclusion based on previous single-unit studies. <b>Two</b> immediate downstream areas of V2 ...", "dateLastCrawled": "2021-01-26T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Spatial</b> <b>pooling</b> inherent to intrinsic signal optical imaging ...", "url": "https://www.researchgate.net/publication/326239086_Spatial_pooling_inherent_to_intrinsic_signal_optical_imaging_might_cause_V2_to_resemble_a_solution_to_the_stereo_correspondence_problem", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/326239086_<b>Spatial</b>_<b>pooling</b>_inherent_to...", "snippet": "1 Chen G, Lu HD, Tanigawa H, Roe AW (2017) Solving <b>visual</b> correspondence between the <b>two</b> <b>eyes</b> via domain-based population encoding in nonhuman primates. Proc Natl Acad Sci USA 114:13024 \u2013 13029.", "dateLastCrawled": "2021-12-14T17:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is the difference between simple max <b>pooling</b> and <b>spatial</b> pyramid ...", "url": "https://www.quora.com/What-is-the-difference-between-simple-max-pooling-and-spatial-pyramid-pooling-Im-seeing-these-terms-a-lot-lately-in-papers-where-the-authors-need-to-get-a-feature-vector", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-simple-max-<b>pooling</b>-and-<b>spatial</b>...", "snippet": "Answer (1 of 2): I would rather treat both concepts independently. <b>Spatial</b> pyramid matching is, conceptually, a method of building a more abstract representation of the images preserving some <b>spatial</b> <b>information</b> by spatially dividing images in some special way. Such higher order representation in...", "dateLastCrawled": "2022-01-24T16:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Integration of Multiple <b>Spatial</b> Frequency Channels in Disparity ...", "url": "https://www.academia.edu/69070821/Integration_of_Multiple_Spatial_Frequency_Channels_in_Disparity_Sensitive_Neurons_in_the_Primary_Visual_Cortex", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69070821/Integration_of_Multiple_<b>Spatial</b>_Frequency_Channels...", "snippet": "For <b>our</b> vivid perception of a 3-D world, the stereoscopic function begins in <b>our</b> brain by detecting slight shifts of image features between the <b>two</b> <b>eyes</b>, called binocular disparity. The primary <b>visual</b> cortex is the first stage of this processing, and", "dateLastCrawled": "2022-01-22T05:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Challenges to <b>pooling</b> models of crowding: Implications for <b>visual</b> ...", "url": "https://europepmc.org/article/MED/31348486", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/31348486", "snippet": "Determining the tilt of the central target is easier when flankers have dissimilar orientation (bottom) versus <b>similar</b> (top). In each row, the <b>two</b> images on the right show <b>two</b> mongrels, visualizations of the <b>information</b> available according to <b>our</b> high-definition <b>pooling</b> model. The target and its orientation are clearer in the <b>two</b> mongrels for the dissimilar condition; high-definition <b>pooling</b> better encodes the target in that condition. High-definition <b>pooling</b> predicts this orientation ...", "dateLastCrawled": "2021-10-16T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Integration of Multiple <b>Spatial</b> Frequency Channels in Disparity ...", "url": "https://www.researchgate.net/publication/279990202_Integration_of_Multiple_Spatial_Frequency_Channels_in_Disparity-Sensitive_Neurons_in_the_Primary_Visual_Cortex", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/279990202_Integration_of_Multiple_<b>Spatial</b>...", "snippet": "Unlabelled: For <b>our</b> vivid perception of a 3-D world, the stereoscopic function begins in <b>our</b> brain by detecting slight shifts of image features between the <b>two</b> <b>eyes</b>, called binocular disparity.", "dateLastCrawled": "2022-01-29T21:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers", "url": "https://papers.nips.cc/paper/2021/file/67f7fb873eaf29526a11a9b7ac33bfac-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2021/file/67f7fb873eaf29526a11a9b7ac33bfac-Paper.pdf", "snippet": "<b>information</b>, they can also contain redundant <b>spatial</b> <b>information</b> from neighboring frames. Vanilla self-attention applied to videos compares pairs of image patches extracted at all possible <b>spatial</b> locations and frames. This can lead it to focus on the redundant <b>spatial</b> <b>information</b> rather than the temporal <b>information</b>, as we show by comparing normalization strategies in <b>our</b> experiments. We therefore contribute a variant of self-attention, called trajectory attention, which is better able to ...", "dateLastCrawled": "2022-02-03T01:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Eye growth in sharks: Ecological implications for changes in retinal ...", "url": "https://www.cambridge.org/core/journals/visual-neuroscience/article/abs/eye-growth-in-sharks-ecological-implications-for-changes-in-retinal-topography-and-visual-resolution/01C69E1F04A3649AC458B9E376F481A2", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/j<b>our</b>nals/<b>visual</b>-neuroscience/article/abs/eye-growth-in...", "snippet": "By <b>combining</b> the <b>information</b> on the <b>visual</b> field with the retinal topography maps and eye position in the chondrocranium, it is possible to reconstruct a schematic view of the animals\u2019 <b>visual</b> field. The central area in C. plumbeus increases <b>visual</b> sampling of the fronto-lateral <b>visual</b> field . The ventral area in S. mitsukurii increases <b>visual</b> sampling of the dorso-frontal <b>visual</b> field, and the central area increases sampling of the lateral <b>visual</b> field . <b>Spatial</b> resolving power. The ...", "dateLastCrawled": "2022-01-16T10:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Remote Sensing | Free Full-Text | Multi-Modality and Multi-Scale ...", "url": "https://www.mdpi.com/2072-4292/13/18/3771/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/13/18/3771/htm", "snippet": "Land cover classification from very high-resolution (VHR) remote sensing images is a challenging task due to the complexity of geography scenes and the varying shape and size of ground targets. It is difficult to utilize the spectral data directly, or to use traditional multi-scale feature extraction methods, to improve VHR remote sensing image classification results. To address the problem, we proposed a multi-modality and multi-scale attention fusion network for land cover classification ...", "dateLastCrawled": "2022-02-02T07:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Do convolutional neural networks learn to be spatially ... - Quora", "url": "https://www.quora.com/Do-convolutional-neural-networks-learn-to-be-spatially-invariant-at-the-last-layer-of-the-network-fully-connected-layer-Convolution-layers-produce-spatially-equivariant-output-but-what-about-the-spatial-invariance", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Do-convolutional-neural-ne<b>two</b>rks-learn-to-be-<b>spatial</b>ly-invariant...", "snippet": "Answer (1 of 4): <b>Spatial</b> invariance comes from the convolutional layers. That in fact is the point of using convolutional filters. A convolutional filter takes in an image, calculates a moving average of the pixel values, and uses that value for a single pixel in the feature map it is creating. ...", "dateLastCrawled": "2022-01-13T11:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Spatial</b> <b>pooling</b> inherent to intrinsic signal optical imaging might ...", "url": "https://www.pnas.org/content/115/30/E6967", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/115/30/E6967", "snippet": "Using intrinsic signal optical imaging, Chen et al. (1) show that disparity <b>information</b> in <b>visual</b> area V2 is decodable from correlated random dot stereograms (cRDSs), but not from anticorrelated RDSs (aRDSs). The authors conclude that \u201cV2 is the initial locus of false matching elimination,\u201d indicating that the correspondence problem is solved within or immediately after V2. We disagree with this conclusion based on previous single-unit studies. <b>Two</b> immediate downstream areas of V2 ...", "dateLastCrawled": "2021-01-26T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Challenges to <b>pooling</b> models of crowding: Implications for <b>visual</b> ...", "url": "https://europepmc.org/article/MED/31348486", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/31348486", "snippet": "In each row, the <b>two</b> images on the right show <b>two</b> mongrels, visualizations of the <b>information</b> available according to <b>our</b> high-definition <b>pooling</b> model. The target&#39;s identity is clearer in the <b>two</b> mongrels for the dissimilar condition. High-definition <b>pooling</b> better encodes the target in that condition. High-definition <b>pooling</b> predicts a sign-of-contrast similarity effect without <b>pooling</b> at a sign-of-contrast processing stage.", "dateLastCrawled": "2021-10-16T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Effects of generalized <b>pooling</b> on binocular disparity selectivity of ...", "url": "https://royalsocietypublishing.org/doi/10.1098/rstb.2015.0266", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rstb.2015.0266", "snippet": "When we see the three-dimensional world with <b>two</b> <b>eyes</b>, slightly different <b>two</b>-dimensional images are projected onto the left and right retinae, due to the horizontal displacement of the <b>eyes</b>. The difference between the <b>two</b> retinal images (binocular disparity) is a sufficient cue for <b>our</b> depth perception 1,2]. Since the discovery that the convergence of the signals from left and right <b>eyes</b> takes place in the early <b>visual</b> cortex , responses of neurons under stereoscopic viewing conditions have ...", "dateLastCrawled": "2021-12-14T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Bird <b>colour vision: behavioural thresholds reveal receptor noise</b> ...", "url": "https://journals.biologists.com/jeb/article/218/2/184/14274/Bird-colour-vision-behavioural-thresholds-reveal", "isFamilyFriendly": true, "displayUrl": "https://j<b>our</b>nals.biologists.com/jeb/article/218/2/184/14274/Bird-col<b>our</b>-vision...", "snippet": "It is proposed that <b>visual</b> systems <b>can</b> use <b>spatial</b> <b>pooling</b> to reduce the effect of photon-shot noise (e.g. Warrant, ... In <b>our</b> model we needed to assume less <b>spatial</b> <b>pooling</b> (between <b>two</b>- and 11-fold integrative fields) to explain discrimination of the colour pairs O2-O+ and G2-G+, at 10 cd m \u22122 and more <b>spatial</b> <b>pooling</b> (20- to 25-fold integrative fields) to explain discrimination of O3-O+, G3-G+, O4-O+ and G4-G+ at dimmer light intensities. This fits the expectation that <b>spatial</b> <b>pooling</b> ...", "dateLastCrawled": "2022-01-29T15:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Will capsule networks replace neural networks? - Peng Liu", "url": "https://rocmind.com/2019/06/22/will-capsule-networks-replace-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://rocmind.com/2019/06/22/will-capsule-ne<b>two</b>rks-replace-neural-ne<b>two</b>rks", "snippet": "Hinton argues, that when we do image recognition with <b>our</b> brain we do perform some kind of inverse graphics solutions; from <b>visual</b> <b>information</b> received by <b>eyes</b>, they deconstruct a hierarchical representation of the world around us and try to match it with already learned patterns and relationships stored in the brain. This is how recognition happens. And the key idea is that representation of objects in the brain does not depend on view angle. We just need to make the internal representation ...", "dateLastCrawled": "2021-12-12T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Integration of Multiple Spatial Frequency Channels in Disparity</b> ...", "url": "https://www.jneurosci.org/content/35/27/10025", "isFamilyFriendly": true, "displayUrl": "https://www.jneurosci.org/content/35/27/10025", "snippet": "For <b>our</b> vivid perception of a 3-D world, the stereoscopic function begins in <b>our</b> brain by detecting slight shifts of image features between the <b>two</b> <b>eyes</b>, called binocular disparity. The primary <b>visual</b> cortex is the first stage of this processing, and neurons there are tuned to a limited range of <b>spatial</b> frequencies (SFs). However, <b>our</b> <b>visual</b> world is generally highly complex, composed of numerous features at a variety of scales, thereby having broadband SF spectra. This means that binocular ...", "dateLastCrawled": "2021-08-06T17:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Beyond Bilinear: Generalized Multi-modal Factorized High</b>-order <b>Pooling</b> ...", "url": "https://deepai.org/publication/beyond-bilinear-generalized-multi-modal-factorized-high-order-pooling-for-visual-question-answering", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>beyond-bilinear-generalized-multi-modal-factorized-high</b>...", "snippet": "To support the VQA task, we need to address the following three issues effectively (see the example in Fig. 1): (1) extracting discriminative features for image and question representations; (2) <b>combining</b> the <b>visual</b> features from the image and the textual features from the question to generate the fused image-question features; (3) using the fused image-question features to learn a multi-class classifier for predicting the best-matching answer correctly. Deep neural networks (DNNs) are very ...", "dateLastCrawled": "2022-01-01T00:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Foveated Convolutions: Improving <b>Spatial</b> Transformer Networks by ...", "url": "https://eprints.soton.ac.uk/441204/1/5_CameraReadySubmission_workshop.pdf", "isFamilyFriendly": true, "displayUrl": "https://eprints.soton.ac.uk/441204/1/5_CameraReadySubmission_workshop.pdf", "snippet": "In nature, <b>visual</b> attention is the movement of the <b>eyes</b> [25], and often body [12], which enables us to process intractable quantities of <b>information</b> by restating the problem as one of time rather than bandwidth or functional capacity. In general, one <b>can</b> deal with a simpli\ufb01cation by considering the <b>eyes</b> to act as one perceptive unit since stereopsis has only a limited affect [20]. The validity of this approach <b>can</b> be easily veri\ufb01ed should the reader close one eye and note that depth ...", "dateLastCrawled": "2022-02-02T14:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Do convolutional neural networks learn to be spatially ... - Quora", "url": "https://www.quora.com/Do-convolutional-neural-networks-learn-to-be-spatially-invariant-at-the-last-layer-of-the-network-fully-connected-layer-Convolution-layers-produce-spatially-equivariant-output-but-what-about-the-spatial-invariance", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Do-convolutional-neural-ne<b>two</b>rks-learn-to-be-<b>spatial</b>ly-invariant...", "snippet": "Answer (1 of 4): <b>Spatial</b> invariance comes from the convolutional layers. That in fact is the point of using convolutional filters. A convolutional filter takes in an image, calculates a moving average of the pixel values, and uses that value for a single pixel in the feature map it is creating. ...", "dateLastCrawled": "2022-01-13T11:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) A Model <b>of Partial Reference Frame Transforms Through Pooling</b> of ...", "url": "https://www.researchgate.net/publication/224976933_A_Model_of_Partial_Reference_Frame_Transforms_Through_Pooling_of_Gain-Modulated_Responses", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/224976933", "snippet": "We demonstrate that certain types of mixed-frame responses <b>can</b> be generated by <b>pooling</b> gain-modulated responses-similar to how complex cells in the <b>visual</b> cortex are <b>thought</b> to pool the responses ...", "dateLastCrawled": "2022-02-02T12:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Visual</b>\u2013auditory <b>spatial</b> processing in auditory cortical neurons", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4340571/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4340571", "snippet": "In order to assess the overall effects of the <b>visual</b> stimuli on auditory <b>spatial</b> sensitivity, we also determined the proportion of units in each cortical area whose responses transmitted more <b>information</b> about stimulus location when spatially aligned <b>visual</b> and auditory stimuli were presented together <b>compared</b> to the responses to sound alone (Fig. 6B). Around 10\u201320% of auditory units in all cortical areas showed enhanced <b>spatial</b> tuning in the presence of bisensory stimuli, with the ...", "dateLastCrawled": "2022-01-21T12:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Spatial</b> Pyramid <b>Pooling</b> in Deep Convolutional Networks for <b>Visual</b> ...", "url": "https://www.researchgate.net/publication/263237865_Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/263237865_<b>Spatial</b>_Pyramid_<b>Pooling</b>_in_Deep...", "snippet": "In this work, we equip the networks with a more principled <b>pooling</b> strategy, \u201c<b>spatial</b> pyramid <b>pooling</b>\u201d, to eliminate the above requirement. The new network structure, called SPP-net, <b>can</b> ...", "dateLastCrawled": "2022-02-02T11:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Pooling</b> in convolutional neural networks for medical image analysis: a ...", "url": "https://link.springer.com/article/10.1007/s00521-022-06953-8", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-022-06953-8", "snippet": "Mixed-<b>pooling</b> , Hybrid <b>pooling</b> , Stochastic <b>pooling</b> , Rank-Based Stochastic <b>pooling</b> , Max <b>pooling</b> dropout , Stochastic <b>Spatial</b> Sampling (S3 <b>pooling</b>) and Fractional Max <b>pooling</b> are proposed to reduce overfitting by introducing various forms of randomness in <b>pooling</b> configurations and/or the way the <b>pooling</b> is performed in the training process. Because of this randomness in training, the trained model <b>can</b> be thought as an ensemble of similar networks, with each random <b>pooling</b> configuration ...", "dateLastCrawled": "2022-02-01T12:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Multi-Modal Factorized Bilinear <b>Pooling</b> With Co-Attention Learning for ...", "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Yu_Multi-Modal_Factorized_Bilinear_ICCV_2017_paper.pdf?source=post_page---------------------------", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Yu_Multi-Modal_Factorized...", "snippet": "superior performance for VQA <b>compared</b> with other bilin-ear <b>pooling</b> approaches. For \ufb01ne-grained image and ques-tion representation, we develop a \u2018co-attention\u2019 mechanism using an end-to-end deep network architecture to jointly learn both the image and question attentions. <b>Combining</b> the proposed MFB approach with co-attention learning in a new network architecture provides a uni\ufb01ed model for VQA. <b>Our</b> experimental results demonstrate that the single MFB with co-attention model achieves ...", "dateLastCrawled": "2022-01-29T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Strip <b>pooling</b> channel <b>spatial</b> attention network for the segmentation of ...", "url": "https://www.sciencedirect.com/science/article/pii/S0098300421002259", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0098300421002259", "snippet": "Although Atrous <b>Spatial</b> Pyramid <b>Pooling</b> (ASPP) in DeepLabv3+ <b>can</b> help the algorithm to obtain multi-scale <b>information</b>, it is easy to lose the continuous performance of <b>spatial</b> <b>information</b> due to the adoption of dilated convolutions in this module, which leads to a small range of loopholes in the results. HRNet, PSPNet and GAFRNet adopts multi-scale <b>pooling</b> and convolution network with deep layers, so the phenomenon of intra-class inconsistency between cloud and its shadow in the image is ...", "dateLastCrawled": "2022-01-13T01:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Spatial</b> <b>pooling</b> of one-dimensional second-order motion signals ...", "url": "https://www.researchgate.net/publication/49675145_Spatial_pooling_of_one-dimensional_second-order_motion_signals", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/49675145_<b>Spatial</b>_<b>pooling</b>_of_one-dimensional...", "snippet": "This study examined <b>spatial</b>-frequency effects on a motion-<b>pooling</b> process in which spatially distributed local one-dimensional motion signals are integrated into the perception of global <b>two</b> ...", "dateLastCrawled": "2021-12-23T15:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Integration of Multiple Spatial Frequency Channels in Disparity</b> ...", "url": "https://www.jneurosci.org/content/35/27/10025", "isFamilyFriendly": true, "displayUrl": "https://www.jneurosci.org/content/35/27/10025", "snippet": "For <b>our</b> vivid perception of a 3-D world, the stereoscopic function begins in <b>our</b> brain by detecting slight shifts of image features between the <b>two</b> <b>eyes</b>, called binocular disparity. The primary <b>visual</b> cortex is the first stage of this processing, and neurons there are tuned to a limited range of <b>spatial</b> frequencies (SFs). However, <b>our</b> <b>visual</b> world is generally highly complex, composed of numerous features at a variety of scales, thereby having broadband SF spectra. This means that binocular ...", "dateLastCrawled": "2021-08-06T17:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Beyond Bilinear: Generalized Multi-modal Factorized High</b>-order <b>Pooling</b> ...", "url": "https://deepai.org/publication/beyond-bilinear-generalized-multi-modal-factorized-high-order-pooling-for-visual-question-answering", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>beyond-bilinear-generalized-multi-modal-factorized-high</b>...", "snippet": "<b>Compared</b> with image-text retrieval and image captioning (which just require the underlying algorithms to search or generate a free-form text description for a given image), <b>visual</b> question answering (VQA) is a more challenging task that requires fine-grained understanding of the semantics of both the images and the questions as well as supports complex reasoning to predict the best-matching answer correctly.", "dateLastCrawled": "2022-01-01T00:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Integration of Multiple <b>Spatial</b> Frequency Channels in Disparity ...", "url": "https://www.academia.edu/69070821/Integration_of_Multiple_Spatial_Frequency_Channels_in_Disparity_Sensitive_Neurons_in_the_Primary_Visual_Cortex", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69070821/Integration_of_Multiple_<b>Spatial</b>_Frequency_Channels...", "snippet": "For <b>our</b> vivid perception of a 3-D world, the stereoscopic function begins in <b>our</b> brain by detecting slight shifts of image features between the <b>two</b> <b>eyes</b>, called binocular disparity. The primary <b>visual</b> cortex is the first stage of this processing, and", "dateLastCrawled": "2022-01-22T05:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Do convolutional neural networks learn to be spatially ... - Quora", "url": "https://www.quora.com/Do-convolutional-neural-networks-learn-to-be-spatially-invariant-at-the-last-layer-of-the-network-fully-connected-layer-Convolution-layers-produce-spatially-equivariant-output-but-what-about-the-spatial-invariance", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Do-convolutional-neural-ne<b>two</b>rks-learn-to-be-<b>spatial</b>ly-invariant...", "snippet": "Answer (1 of 4): <b>Spatial</b> invariance comes from the convolutional layers. That in fact is the point of using convolutional filters. A convolutional filter takes in an image, calculates a moving average of the pixel values, and uses that value for a single pixel in the feature map it is creating. ...", "dateLastCrawled": "2022-01-13T11:46:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Max <b>Pooling</b> - <b>Machine</b> <b>Learning</b> | AI | Data Science Career", "url": "https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-2-max-pooling/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>superdatascience</b>.com/.../<b>convolutional-neural-networks-cnn-step</b>-2-max-<b>pooling</b>", "snippet": "Again, max <b>pooling</b> is concerned with teaching your convolutional neural network to recognize that despite all of these differences that we mentioned, they are all images of cheetah. In order to do that, the network needs to acquire a property that is known as \u201c<b>spatial</b> variance.\u201d", "dateLastCrawled": "2022-01-28T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6.5. <b>Pooling</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_convolutional-neural-networks/pooling.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_convolutional-neural-networks/<b>pooling</b>.html", "snippet": "6.5.1. Maximum <b>Pooling</b> and Average <b>Pooling</b>\u00b6. Like convolutional layers, <b>pooling</b> operators consist of a fixed-shape window that is slid over all regions in the input according to its stride, computing a single output for each location traversed by the fixed-shape window (sometimes known as the <b>pooling</b> window).However, unlike the cross-correlation computation of the inputs and kernels in the convolutional layer, the <b>pooling</b> layer contains no parameters (there is no kernel).Instead, <b>pooling</b> ...", "dateLastCrawled": "2022-02-01T14:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning in Nanoscience: Big Data</b> at Small Scales", "url": "https://par.nsf.gov/servlets/purl/10149733", "isFamilyFriendly": true, "displayUrl": "https://par.nsf.gov/servlets/purl/10149733", "snippet": "<b>Machine</b> <b>Learning</b> is widely contributing to the recognition and classi\ufb01cation of key features in nanoscience data sets. For example, in X-ray spectroscopy an ANN (Figure 3A) was trained on simulated X-ray absorption \ufb01ne structure (EXAFS) spectra generated by molecular dynamics simulations. Then, using this trained model, researchers extracted partial radial distribution functions that yielded insight into the chemical structure beyond the \ufb01rst atomic coordination shell.13 This new ...", "dateLastCrawled": "2022-01-12T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Delving Deep into <b>Spatial</b> <b>Pooling</b> for Squeeze-and-Excitation Networks ...", "url": "https://www.researchgate.net/publication/353278714_Delving_Deep_into_Spatial_Pooling_for_Squeeze-and-Excitation_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353278714_Delving_Deep_into_<b>Spatial</b>_<b>Pooling</b>...", "snippet": "The <b>machine</b> <b>learning</b> community has been overwhelmed by a plethora of deep <b>learning</b> based approaches. Many challenging computer vision tasks such as detection, localization, recognition and ...", "dateLastCrawled": "2022-01-11T13:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Convolutional Neural Networks (CNN)- Step</b> 2 \u2013 Max <b>Pooling</b> - Mohamed DHAOUI", "url": "https://mohameddhaoui.github.io/deeplearning/CNN_tuto2/", "isFamilyFriendly": true, "displayUrl": "https://mohameddhaoui.github.io/deep<b>learning</b>/CNN_tuto2", "snippet": "What is <b>Pooling</b>? Instead of verbally defining <b>pooling</b>, we\u2019ll start off this tutorial with an example right away. The Cheetah Example . In the example above, the same cheetah image is presented in different ways. It is normal in its first version, rotated in the second, and horizontally squashed in the third. The purpose of max <b>pooling</b> is enabling the convolutional neural network to detect the cheetah when presented with the image in any manner. This second example is more advanced. Here we ...", "dateLastCrawled": "2021-11-12T11:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "6.3. <b>Padding</b> and Stride \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_convolutional-neural-networks/<b>padding</b>-and-strides.html", "snippet": "In the previous example of Fig. 6.2.1, our input had both a height and width of 3 and our convolution kernel had both a height and width of 2, yielding an output representation with dimension \\(2\\times2\\).As we generalized in Section 6.2, assuming that the input shape is \\(n_h\\times n_w\\) and the convolution kernel shape is \\(k_h\\times k_w\\), then the output shape will be \\((n_h-k_h+1) \\times (n_w-k_w+1)\\).Therefore, the output shape of the convolutional layer is determined by the shape of ...", "dateLastCrawled": "2022-02-02T15:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Graph Convolutional</b> Networks \u2014Deep <b>Learning</b> on Graphs | by Francesco ...", "url": "https://towardsdatascience.com/graph-convolutional-networks-deep-99d7fee5706f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>graph-convolutional</b>-networks-deep-99d7fee5706f", "snippet": "<b>Machine</b> <b>Learning</b> tasks on graphs (image by author) Unfortunately, ... We will find a solution to this problem by working in <b>analogy</b> with the classical Fourier transform. Let\u2019s take the case of a function defined on the real line. Its Fourier transform is its decomposition in frequency terms, obtained by projecting the function on an orthonormal basis of sinusoidal waves. And in fact, these waves are precisely the eigenfunctions of the Laplacian: Fourier transform in 1D (image by author) So ...", "dateLastCrawled": "2022-02-02T02:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Emerging Techniques in Machine Learning for Processing Satellite Images</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/B9780128194126000158", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/B9780128194126000158", "snippet": "The combination of these techniques and data-driven computing tools such as <b>machine</b> <b>learning</b> (ML) and artificial intelligence (AI) approaches have led to increased accuracy in satellite image processing, that is, practical information from satellite imagery during flood events can be extracted using ML and AI methods (Chen et al., 2018, Yang and Cervone, 2019). These methods are based on ideas how information is processed in biological systems. One of the advantages of such \u201csoft ...", "dateLastCrawled": "2021-09-15T11:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Sequence Classification with LSTM Recurrent Neural Networks in Python ...", "url": "https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/sequence-classification-", "snippet": "Convolutional neural networks excel at <b>learning</b> the <b>spatial</b> structure in input data. The IMDB review data does have a one-dimensional <b>spatial</b> structure in the sequence of words in reviews and the CNN may be able to pick out invariant features for good and bad sentiment. This learned <b>spatial</b> features may then be learned as sequences by an LSTM layer. We can easily add a one-dimensional CNN and max <b>pooling</b> layers after the Embedding layer which then feed the consolidated features to the LSTM ...", "dateLastCrawled": "2022-02-02T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - Convolutional neural networks vs <b>downsampling</b> ...", "url": "https://stackoverflow.com/questions/38097111/convolutional-neural-networks-vs-downsampling", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/38097111", "snippet": "Can you break this term down into a simple, understandable image/<b>analogy</b>? edit: Rephrase after 1st answer: Can <b>pooling</b> be understood as <b>downsampling</b> of weight matrices? <b>machine</b>-<b>learning</b> neural-network deep-<b>learning</b> conv-neural-network convolution. Share. Improve this question. Follow edited Mar 6 &#39;19 at 14:09. user2305193. asked Jun 29 &#39;16 at 10:35. user2305193 user2305193. 2,147 14 14 silver badges 37 37 bronze badges. 1. popular question with no upvotes, I can only presume people come here ...", "dateLastCrawled": "2022-01-13T12:57:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>When Unsupervised Domain Adaptation Meets Tensor Representations</b>", "url": "https://www.researchgate.net/publication/318559982_When_Unsupervised_Domain_Adaptation_Meets_Tensor_Representations", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/318559982_When_Unsupervised_Domain_Adaptation...", "snippet": "Abstract and Figures. Domain adaption (DA) allows <b>machine</b> <b>learning</b> methods trained on data sampled from one distribution to be applied to data sampled from another. It is thus of great practical ...", "dateLastCrawled": "2022-01-12T22:06:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> Understanding: April 2010", "url": "https://machineunderstanding.blogspot.com/2010/04/", "isFamilyFriendly": true, "displayUrl": "https://<b>machine</b>understanding.blogspot.com/2010/04", "snippet": "&quot;<b>Spatial pooling can be thought of as</b> a quantization process that maps a potentially infinite number of input patters to a finite number of quantization centers.&quot; Which in other lit Numenta calls quantization points. Data, in our HTM world, has a spatial aspect. This might not be change along a spatial dimension; space has a more general sense. For instance, the space might be a range of voltages, or sets of voltages from an EKG, for instance. Spatial data usually varies so complexly that we ...", "dateLastCrawled": "2021-11-27T17:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> Understanding: 2010", "url": "https://machineunderstanding.blogspot.com/2010/", "isFamilyFriendly": true, "displayUrl": "https://<b>machine</b>understanding.blogspot.com/2010", "snippet": "&quot;<b>Spatial pooling can be thought of as</b> a quantization process that maps a potentially infinite number of input patters to a finite number of quantization centers.&quot; Which in other lit Numenta calls quantization points. Data, in our HTM world, has a spatial aspect. This might not be change along a spatial dimension; space has a more general sense. For instance, the space might be a range of voltages, or sets of voltages from an EKG, for instance. Spatial data usually varies so complexly that we ...", "dateLastCrawled": "2021-12-11T03:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "VERILOG IMPLEMENTATION OF A NODE OF HIERARCHICAL TEMPORAL MEMORY", "url": "https://1library.net/document/zx9r234z-verilog-implementation-node-hierarchical-temporal-memory.html", "isFamilyFriendly": true, "displayUrl": "https://1library.net/document/zx9r234z-verilog-implementation-node-hierarchical...", "snippet": "on how the neocortex perform these functions.HTM is the <b>machine</b> <b>learning</b> technology that replicates the structural and algorithmic properties of neocortex.[2] The paper aims at implementing a <b>learning</b> HTM node suitable for running experiments and possible further elaboration of the implementation based on the experimental results. The implementation is applied for <b>learning</b> to recognize visual two dimensional patterns. The hierarchical temporal algorithm focuses on the functioning of the ...", "dateLastCrawled": "2021-12-20T20:55:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(spatial pooling)  is like +(combining visual information from our two eyes)", "+(spatial pooling) is similar to +(combining visual information from our two eyes)", "+(spatial pooling) can be thought of as +(combining visual information from our two eyes)", "+(spatial pooling) can be compared to +(combining visual information from our two eyes)", "machine learning +(spatial pooling AND analogy)", "machine learning +(\"spatial pooling is like\")", "machine learning +(\"spatial pooling is similar\")", "machine learning +(\"just as spatial pooling\")", "machine learning +(\"spatial pooling can be thought of as\")", "machine learning +(\"spatial pooling can be compared to\")"]}