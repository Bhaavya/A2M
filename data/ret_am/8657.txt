{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Survey paper for Different Video Stabilization Techniques", "url": "https://www.irjet.net/archives/V4/i3/IRJET-V4I3723.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.irjet.net/archives/V4/i3/IRJET-V4I3723.pdf", "snippet": "produced by <b>translational</b> and rotational movements and by the <b>zoom</b> of the <b>camera</b> and the local motion of objects. Vibrations and shocks always occur on the <b>camera</b> while platform is moving. Other effects such as wind may also cause distortion. These causes degradations on the quality of the video. Video stabilization is the technique of generating a stabilized video sequence, where image motion by the <b>camera</b>\u2019s undesirable shake. It removes those undesired motions while preserving the ...", "dateLastCrawled": "2021-10-12T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Self-<b>Calibration of a Rotating Camera With a Translational Offset</b>", "url": "https://www.researchgate.net/publication/3299423_Self-Calibration_of_a_Rotating_Camera_With_a_Translational_Offset", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3299423_Self-<b>Calibration_of_a_Rotating_Camera</b>...", "snippet": "The <b>zoom</b> calibration regards each <b>zoom</b> setting as a monofocal <b>camera</b>, and takes advantage of both the pattern-based and the rotation-based approaches. A rotation sensor is utilized to overcome the ...", "dateLastCrawled": "2021-11-15T01:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Meade 494 User Guide", "url": "https://in.avaqin.com/uploads/7bdba158ebeaa0c03c5a9f445c2d6605/meade+494+user+guide+pdf", "isFamilyFriendly": true, "displayUrl": "https://in.avaqin.com/uploads/7bdba158ebeaa0c03c5a9f445c2d6605/meade+494+user+guide+pdf", "snippet": "We would <b>like</b> to show you a description here but the site won\u2019t allow us. AFTAC Alumni Association 285. Meade Instruments 20-60x60 Spotting Scopewatreproof Withtripod 286. Meade Instruments Starnavigator 102 Goto Refractor Telescope 287. Sony 11-18mm F/4.5-5.6 <b>Lens</b> For Digital Slr <b>Camera</b> - Sao-1118 288. Pentax 02 Standard <b>Zoom</b> <b>Lens</b> 289. Power 2000 Acd-262 Digital <b>Camera</b> Battery 290. Wildgame Innovations Remington 900 Laser Sai along Find 291. Risks and Precautions of Genetically Modified ...", "dateLastCrawled": "2022-02-02T05:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Physical Optics Laboratory", "url": "http://aboutme.samexent.com/classes/spring09/ee5622/EE5622_Exp4.pdf", "isFamilyFriendly": true, "displayUrl": "aboutme.samexent.com/classes/spring09/ee5622/EE5622_Exp4.pdf", "snippet": "<b>Translational</b> <b>invariance</b>: Place the slide of the square in the slide holder and adjust the aperture to illuminate the entire slide. Move the slide back and forth, and note any changes in the diffraction pattern. Explain. HeNe laser ND wheel Spatial filter 10 cm <b>lens</b> SORL Slide <b>lens</b> holder Iris CCD <b>camera</b> d f . 2. Symmetries: Place the slide of the three symbols (A, T, and+), in the slide holder and adjust the aperture to illuminate a single symbol. Explain the symmetries of the diffraction ...", "dateLastCrawled": "2021-09-07T10:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Optical design of a 2\u00d7 <b>zoom lens for miniature imaging systems</b> ...", "url": "https://www.researchgate.net/publication/335501968_Optical_design_of_a_2_zoom_lens_for_miniature_imaging_systems", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335501968_Optical_design_of_a_2_<b>zoom</b>_<b>lens</b>_for...", "snippet": "The optical design of a compact 2 \u00d7 <b>zoom</b> <b>lens</b> in a <b>lens</b> barrel for miniature cameras is reported. The magnification in the optical system is achieved by means of changing positions of <b>lens</b> ...", "dateLastCrawled": "2021-11-09T02:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Quantitative phase microscopy using quadriwave lateral shearing ...", "url": "https://iopscience.iop.org/article/10.1088/1361-6463/abfbf9", "isFamilyFriendly": true, "displayUrl": "https://iopscience.iop.org/article/10.1088/1361-6463/abfbf9", "snippet": "The <b>translational</b> <b>invariance</b> of the transmitted light after a chessboard grating (provided a polychromatic light is used, see figure 3(f)) has been coined the &#39;panchromatic Talbot effect&#39;. However, a Talbot effect is rather a phenomenon of image replication at periodic distances, not an <b>invariance</b> by translation. What happens between the grating and the sensor rather belongs to the family of propagation-invariant optical waves, the most famous members of this family being the Bessel beams ...", "dateLastCrawled": "2021-11-12T02:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "IJGI | Free Full-Text | Panoramic Mapping with Information ... - MDPI", "url": "https://www.mdpi.com/2220-9964/9/11/689/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2220-9964/9/11/689/htm", "snippet": "The researchers mounted a full-frame digital single-<b>lens</b> reflex <b>camera</b> (CANON EOS 6D Mark II, Canon, Tokyo, Japan) equipped with an ultra-wide-angle <b>zoom</b> <b>lens</b> (Canon EF 16\u201335 mm F/4L IS USM, Canon, Tokyo, Japan) on a panoramic instrument (GigaPan EPIC Pro V, GigaPan, Portland, OR, USA; Figure 2) and tripod. To use the GigaPan, the horizontal and vertical coverage must be set, after which the machine automatically rotates and accurately divides the scene into several grid images; these ...", "dateLastCrawled": "2021-10-23T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 7, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Super-resolution imaging</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Super-resolution_imaging", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Super-resolution_imaging</b>", "snippet": "<b>Super-resolution imaging</b> (SR) is a class of techniques that enhance (increase) the resolution of an imaging system. In optical SR the diffraction limit of systems is transcended, while in geometrical SR the resolution of digital imaging sensors is enhanced.. In some radar and sonar imaging applications (e.g. magnetic resonance imaging (MRI), high-resolution computed tomography), subspace decomposition-based methods (e.g. MUSIC) and compressed sensing-based algorithms (e.g., SAMV) are ...", "dateLastCrawled": "2022-02-03T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Science of Photography Archives - Andy Astburys&#39; Photography ...", "url": "https://www.wildlifeinpixels.net/blog/category/the-science-of-photography/", "isFamilyFriendly": true, "displayUrl": "https://www.wildlifeinpixels.net/blog/category/the-science-of-photography", "snippet": "Yes, if we shoot a DX format <b>camera</b> using an FX <b>lens</b> we get the \u2018illusion\u2019 of a magnified subject \u2013 but that\u2019s all it is \u2013 an illusion. Yes, if we shoot the same shot on a 20Mp FX and crop it to look <b>like</b> the shot from a 20Mp DX, then the subject in the DX shot will have twice as many pixels in it, because of the higher <b>translational</b> density \u2013 but at what cost.", "dateLastCrawled": "2021-12-23T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why are modern 50mm lenses so damned complicated? | Hacker News", "url": "https://news.ycombinator.com/item?id=27104271", "isFamilyFriendly": true, "displayUrl": "https://news.ycombinator.com/item?id=27104271", "snippet": "Depth of field is a matter of the distance from the <b>camera</b> to the subject, the aperture of the <b>lens</b> and the focal length of the <b>lens</b>. Larger formats allow you to stand closer to the subject while retaining a wider view than for a smaller format <b>camera</b>. Take the 80mm f2.8 <b>lens</b> on a Rolleiflex TLR. If you stand where you can frame a head and shoulders portrait, you&#39;re standing closer than you would for the same framing on a smaller format <b>camera</b> with an 80mm <b>lens</b>. You would have to stand back ...", "dateLastCrawled": "2021-11-26T04:00:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Self-<b>Calibration of a Rotating Camera With a Translational Offset</b>", "url": "https://www.researchgate.net/publication/3299423_Self-Calibration_of_a_Rotating_Camera_With_a_Translational_Offset", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3299423_Self-<b>Calibration_of_a_Rotating_Camera</b>...", "snippet": "The <b>zoom</b> calibration regards each <b>zoom</b> setting as a monofocal <b>camera</b>, and takes advantage of both the pattern-based and the rotation-based approaches. A rotation sensor is utilized to overcome the ...", "dateLastCrawled": "2021-11-15T01:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Quantitative phase microscopy using quadriwave lateral shearing ...", "url": "https://iopscience.iop.org/article/10.1088/1361-6463/abfbf9", "isFamilyFriendly": true, "displayUrl": "https://iopscience.iop.org/article/10.1088/1361-6463/abfbf9", "snippet": "The <b>translational</b> <b>invariance</b> of the transmitted light after a chessboard grating (provided a polychromatic light is used, see figure 3(f)) has been coined the &#39;panchromatic Talbot effect&#39;. However, a Talbot effect is rather a phenomenon of image replication at periodic distances, not an <b>invariance</b> by translation. What happens between the grating and the sensor rather belongs to the family of propagation-invariant optical waves, the most famous members of this family being the Bessel beams ...", "dateLastCrawled": "2021-11-12T02:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Looking down: a model for visual route following in flying insects ...", "url": "https://iopscience.iop.org/article/10.1088/1748-3190/ac1307", "isFamilyFriendly": true, "displayUrl": "https://iopscience.iop.org/article/10.1088/1748-3190/ac1307", "snippet": "Combined with the SSIM component of the CWSSIM algorithm, it provides an image matching method with a degree of <b>translational</b> <b>invariance</b>, as set out in section 2.2 of . Our results indicate that CWSSIM provides approximately double the catchment area of MSE based methods for a given reference image. Crucially, CWSSIM&#39;s output monotonically declines with horizontal distance from a reference image. By increasing the width of the monotonic region of the search space generated by an image/image ...", "dateLastCrawled": "2021-10-17T13:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Privacy-Preserving Action Recognition using Coded Aperture Videos</b> | DeepAI", "url": "https://deepai.org/publication/privacy-preserving-action-recognition-using-coded-aperture-videos", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>privacy-preserving-action-recognition-using-coded</b>...", "snippet": "Towards this end, we simulate a <b>lens</b>-free coded aperture (CA) <b>camera</b> as an appearance encoder, i.e., the first layer of privacy protection. Our goal is human action recognition from coded aperture videos for which the coded aperture mask is unknown and does not require reconstruction. We insert a second layer of privacy protection by using non-invertible motion features based on phase correlation and log-polar transformation. Phase correlation encodes translation while the log polar ...", "dateLastCrawled": "2021-12-25T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Detection and localization of specular surfaces using</b> image motion cues ...", "url": "https://link.springer.com/article/10.1007%2Fs00138-014-0610-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00138-014-0610-9", "snippet": "Our SIFT-driven epipolar deviation feature, however, is expected to give <b>similar</b> results across different <b>camera</b> trajectories, since it relies on the same geometric information. To verify this, we tested our algorithm for three types of <b>camera</b> motions: rotation, translation and <b>zoom</b>. In addition, to concurrently examine the effects of object size on detection quality, we multiplied the diameter of the largest object by 0.8 and 0.5 to obtain medium and small-sized objects, respectively. Thus ...", "dateLastCrawled": "2022-01-24T21:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Multiple_View_Geometry_Zisserman_2Ed</b> | Sumijan Sumijan - Academia.edu", "url": "https://www.academia.edu/32033625/Multiple_View_Geometry_Zisserman_2Ed", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/32033625/<b>Multiple_View_Geometry_Zisserman_2Ed</b>", "snippet": "<b>Multiple_View_Geometry_Zisserman_2Ed</b>. Enter the email address you signed up with and we&#39;ll email you a reset link.", "dateLastCrawled": "2022-01-30T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Photonics | Free Full-Text | Long-<b>Range, High-Resolution Camera Optical</b> ...", "url": "https://www.mdpi.com/2304-6732/6/2/73/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2304-6732/6/2/73/htm", "snippet": "These features can be accomplished with the joint architecture of the <b>camera</b> including <b>lens</b>, image sensor array, image signal processor (ISP) and interface electronics. Automotive parts are required to meet strict performance criteria and reliability standards in order to achieve safe and robust operation under a diverse range of conditions. Innovative parts under development for ADAS and autonomous driving systems also need to meet <b>similar</b> high-quality and reliability standards. As a ...", "dateLastCrawled": "2022-01-29T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Vision-based place recognition: how low can you go? - Michael Milford, 2013", "url": "https://journals.sagepub.com/doi/full/10.1177/0278364913490323", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/0278364913490323", "snippet": "The combined image <b>is similar</b> in size to a single original panoramic <b>camera</b> ... 2006) exhibit desirable properties such as scale and rotation <b>invariance</b>, and a limited degree of illumination <b>invariance</b>. Feature-based techniques that consider the geometry of features are also desirable because of their relatively easy integration with metric pose estimation algorithms. For robot applications that involve scene understanding or semantic mapping, feature-based techniques are also suitable given ...", "dateLastCrawled": "2020-11-26T05:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Science of Photography Archives - Andy Astburys&#39; Photography ...", "url": "https://www.wildlifeinpixels.net/blog/category/the-science-of-photography/", "isFamilyFriendly": true, "displayUrl": "https://www.wildlifeinpixels.net/blog/category/the-science-of-photography", "snippet": "Yes, if we shoot a DX format <b>camera</b> using an FX <b>lens</b> we get the \u2018illusion\u2019 of a magnified subject \u2013 but that\u2019s all it is \u2013 an illusion. Yes, if we shoot the same shot on a 20Mp FX and crop it to look like the shot from a 20Mp DX, then the subject in the DX shot will have twice as many pixels in it, because of the higher <b>translational</b> density \u2013 but at what cost.", "dateLastCrawled": "2021-12-23T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why are modern 50mm lenses so damned complicated? | Hacker News", "url": "https://news.ycombinator.com/item?id=27104271", "isFamilyFriendly": true, "displayUrl": "https://news.ycombinator.com/item?id=27104271", "snippet": "Depth of field is a matter of the distance from the <b>camera</b> to the subject, the aperture of the <b>lens</b> and the focal length of the <b>lens</b>. Larger formats allow you to stand closer to the subject while retaining a wider view than for a smaller format <b>camera</b>. Take the 80mm f2.8 <b>lens</b> on a Rolleiflex TLR. If you stand where you can frame a head and shoulders portrait, you&#39;re standing closer than you would for the same framing on a smaller format <b>camera</b> with an 80mm <b>lens</b>. You would have to stand back ...", "dateLastCrawled": "2021-11-26T04:00:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Recent Advances in Object Detection</b> in the Age of Deep Convolutional ...", "url": "https://deepai.org/publication/recent-advances-in-object-detection-in-the-age-of-deep-convolutional-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>recent-advances-in-object-detection</b>-in-the-age-of-deep...", "snippet": "This implementation trick introduced some more <b>translational</b> variance to structures that were essentially translation-invariant by construction. <b>Translational</b> variance in object detection <b>can</b> be beneficial for learning localization representations. Although this pipeline seems to be more precise, it is not always better performance-wise than its Faster R-CNN counterpart. From an engineering point of view, this method of Position sensitive RoI-Pooling (PS Pooling) also prevented the loss of ...", "dateLastCrawled": "2022-02-03T11:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Self-<b>Calibration of a Rotating Camera With a Translational Offset</b>", "url": "https://www.researchgate.net/publication/3299423_Self-Calibration_of_a_Rotating_Camera_With_a_Translational_Offset", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3299423_Self-<b>Calibration_of_a_Rotating_Camera</b>...", "snippet": "For <b>zoom</b>-<b>lens</b> calibration, specific reviews <b>can</b> be found in [33,34]; however, these reviews focus exclusively on a comparative analysis of the self-calibration-based methods and techniques used ...", "dateLastCrawled": "2021-11-15T01:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Calibration of Video Cameras using Spheres</b>", "url": "https://www.researchgate.net/publication/2814360_Calibration_of_Video_Cameras_using_Spheres", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/2814360_<b>Calibration_of_Video_Cameras_using</b>...", "snippet": "By video <b>camera</b> calibration we mean to estimate the location, orientation and <b>lens</b> <b>zoom</b>-setting of the <b>camera</b> for each video frame taking into account image visible features.", "dateLastCrawled": "2022-01-19T18:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "US20190182415A1 - Estimating and using relative head pose and <b>camera</b> ...", "url": "https://patents.google.com/patent/US20190182415A1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US20190182415A1", "snippet": "A video or still hand-held digital <b>camera</b> is activated or controlled based on estimation of a user head pose or gaze direction. The system comprises uses two wearable devices associated with right and left sides of the user body, each comprises an RF beacon. The head pose or gaze detection is estimated by comparing the signal strength (such as RSSI) or the phase of the RF signals from the wearable devices at the digital <b>camera</b> device. An angular deviation between the head pose (or gaze ...", "dateLastCrawled": "2021-10-15T00:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Rotation invariant visual processing for spatial</b> memory in insects ...", "url": "https://royalsocietypublishing.org/doi/10.1098/rsfs.2018.0010", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rsfs.2018.0010", "snippet": "This approach extracted a horizontal strip of greyscale values from the horizon pixels in an image from a panoramic <b>camera</b> mounted on a robot, and the array was converted to a frequency representation using a Fourier transform. However, rather than use this for rotation invariant image matching, their approach instead used phase components to recover an estimate of rotation combined with a frequency domain equivalent of the warping method to determine the displacement from home. This was ...", "dateLastCrawled": "2022-02-02T15:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Multiple_View_Geometry_Zisserman_2Ed</b> | Sumijan Sumijan - Academia.edu", "url": "https://www.academia.edu/32033625/Multiple_View_Geometry_Zisserman_2Ed", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/32033625/<b>Multiple_View_Geometry_Zisserman_2Ed</b>", "snippet": "<b>Multiple_View_Geometry_Zisserman_2Ed</b>. Enter the email address you signed up with and we&#39;ll email you a reset link.", "dateLastCrawled": "2022-01-30T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The Science of Photography Archives - Andy Astburys&#39; Photography ...", "url": "https://www.wildlifeinpixels.net/blog/category/the-science-of-photography/", "isFamilyFriendly": true, "displayUrl": "https://www.wildlifeinpixels.net/blog/category/the-science-of-photography", "snippet": "Yes, if we shoot a DX format <b>camera</b> using an FX <b>lens</b> we get the \u2018illusion\u2019 of a magnified subject \u2013 but that\u2019s all it is \u2013 an illusion. Yes, if we shoot the same shot on a 20Mp FX and crop it to look like the shot from a 20Mp DX, then the subject in the DX shot will have twice as many pixels in it, because of the higher <b>translational</b> density \u2013 but at what cost. Cramming more mega pixels into either a 36mm x 24mm or 24mm x 16mm area results in one thing only \u2013 smaller photosites ...", "dateLastCrawled": "2021-12-23T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Sensors | Free Full-Text | Modern Types of Axicons: New Functions and ...", "url": "https://www.mdpi.com/1424-8220/21/19/6690/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/21/19/6690/htm", "snippet": "Thus, when the <b>lens</b> is supplemented with an axicon, in the plane corresponding to the focal plane of the <b>lens</b> (z = f), instead of the focal picture, an out-of-focal picture is formed. This makes it possible to measure out-of-focal patterns without moving the detecting device. In addition, the depth of focus and its transverse scale increase, which are also positive factors for the analysis of images distorted by aberrations. The action of the proposed approach to improve the visualization of ...", "dateLastCrawled": "2021-11-14T19:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Graphics and Visualization: Principles and Algorithms</b> - SILO.PUB", "url": "https://silo.pub/graphics-and-visualization-principles-and-algorithms.html", "isFamilyFriendly": true, "displayUrl": "https://silo.pub/<b>graphics-and-visualization-principles-and-algorithms</b>.html", "snippet": "The <b>camera</b> <b>can</b> be moved around the room to select a suitable viewing angle and <b>zoom</b> in or out of the subject to capture it in more or less detail. For two-dimensional drawings, the notion of rasterization is similar. Think of a canvas where text, line drawings, and other shapes are arranged in specific locations by manipulating them on a plane or directly drawing curves on the canvas. Everything is expressed in the reference frame of the canvas, possibly in real-world units. We then need to ...", "dateLastCrawled": "2022-02-02T14:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Innovations in Smart Cities Applications Volume 4: The Proceedings of ...", "url": "https://dokumen.pub/innovations-in-smart-cities-applications-volume-4-the-proceedings-of-the-5th-international-conference-on-smart-city-applications-9783030668402-3030668401.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/innovations-in-smart-cities-applications-volume-4-the-proceedings...", "snippet": "3.2 Raspberry Pi <b>Camera</b> 3.3 Object Detection Pretrained Models 3.4 Social Distance 4 Proposed Prototype 5 Results and Discussion 6 Conclusion and Perspectives References COVID-19 Patient Classification Strategy Using a Hybrid BWM-SVM Model 1 Introduction 2 Proposed Work 2.1 System Model 2.2 The First Stage: BWM 2.3 The Second Stage: Patient Classification Using SVM 3 Conclusion References Development of a Simulator to Model the Spread of Coronavirus Infection in a Closed Space 1 Introduction ...", "dateLastCrawled": "2022-02-03T11:52:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Self-<b>Calibration of a Rotating Camera With a Translational Offset</b>", "url": "https://www.researchgate.net/publication/3299423_Self-Calibration_of_a_Rotating_Camera_With_a_Translational_Offset", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/3299423_Self-<b>Calibration_of_a_Rotating_Camera</b>...", "snippet": "For <b>zoom</b>-<b>lens</b> calibration, specific reviews <b>can</b> be found in [33,34]; however, these reviews focus exclusively on a comparative analysis of the self-calibration-based methods and techniques used ...", "dateLastCrawled": "2021-11-15T01:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Survey paper for Different Video Stabilization Techniques", "url": "https://www.irjet.net/archives/V4/i3/IRJET-V4I3723.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.irjet.net/archives/V4/i3/IRJET-V4I3723.pdf", "snippet": "produced by <b>translational</b> and rotational movements and by the <b>zoom</b> of the <b>camera</b> and the local motion of objects. Vibrations and shocks always occur on the <b>camera</b> while platform is moving. Other effects such as wind may also cause distortion. These causes degradations on the quality of the video. Video stabilization is the technique of generating a stabilized video sequence, where image motion by the <b>camera</b>\u2019s undesirable shake. It removes those undesired motions while preserving the ...", "dateLastCrawled": "2021-10-12T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Corner cases and limitations using a DOE based geometric <b>camera</b> calibration", "url": "https://www.image-engineering.de/content/library/conference_papers/2021_03/Wueller_DOE_corner_cases_limitations.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.image-engineering.de/content/library/conference_papers/2021_03/Wueller_DOE...", "snippet": "There are also a few limitations <b>compared</b> to the conventional methods: a. Measurement at infinity only b. Stereo basis cannot be measured due to translation <b>invariance</b> of the method c. Determination of chromatic aberration d. Limited application of a single DOE (due to resolution of the <b>camera</b> and field of view) All these desires and limitations are discussed, and solutions are presented where possible. DOE based geometric calibration recap the different users!&quot;#$%&amp;$\u2019! Figure 1: The ...", "dateLastCrawled": "2022-01-06T08:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Method for Generation of Panoramic View based on Images Acquired by a ...", "url": "https://www.ijcaonline.org/ait/number3/SPE221T.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcaonline.org/ait/number3/SPE221T.pdf", "snippet": "The images are acquired by an ordinary <b>lens</b> with the help of digital <b>camera</b>. So there is no distortion in the images. We directly start with registration of acquired images. Image registration consists of extracting the features, matching them and estimating transformation. Firstly, use of invariant features enables reliable matching of panoramic image sequences despite rotation, <b>zoom</b> and illumination change in the input images. Secondly, we <b>can</b> discover the matching relationship between the ...", "dateLastCrawled": "2022-01-12T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Physical Optics Laboratory", "url": "http://aboutme.samexent.com/classes/spring09/ee5622/EE5622_Exp4.pdf", "isFamilyFriendly": true, "displayUrl": "aboutme.samexent.com/classes/spring09/ee5622/EE5622_Exp4.pdf", "snippet": "<b>Translational</b> <b>invariance</b>: Place the slide of the square in the slide holder and adjust the aperture to illuminate the entire slide. Move the slide back and forth, and note any changes in the diffraction pattern. Explain. HeNe laser ND wheel Spatial filter 10 cm <b>lens</b> SORL Slide <b>lens</b> holder Iris CCD <b>camera</b> d f . 2. Symmetries: Place the slide of the three symbols (A, T, and+), in the slide holder and adjust the aperture to illuminate a single symbol. Explain the symmetries of the diffraction ...", "dateLastCrawled": "2021-09-07T10:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Survey on <b>zoom</b>-<b>lens calibration methods and techniques</b>", "url": "https://www.researchgate.net/publication/318736840_Survey_on_zoom-lens_calibration_methods_and_techniques", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/318736840_Survey_on_<b>zoom</b>-<b>lens</b>_calibration...", "snippet": "method [45] for <b>zoom</b>-<b>lens</b> calibration of a single <b>camera</b>. This method requires different calibration patterns to cali- brate a <b>zoom</b> <b>camera</b> at different <b>zoom</b> and focus settings.", "dateLastCrawled": "2022-01-26T12:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Quantitative phase microscopy using quadriwave lateral shearing ...", "url": "https://iopscience.iop.org/article/10.1088/1361-6463/abfbf9", "isFamilyFriendly": true, "displayUrl": "https://iopscience.iop.org/article/10.1088/1361-6463/abfbf9", "snippet": "The <b>translational</b> <b>invariance</b> of the transmitted light after a chessboard grating ... size). Consequently, the spatial resolution of the intensity and phase images in QLSI is reduced by a factor of three <b>compared</b> with the image that the <b>camera</b> would measure without grating. Thus, to reach the diffraction limit in phase and intensity in QLSI, the image has to be oversampled <b>compared</b> with the diffraction limit by at least of factor of three. Note that some commercial QLSI cameras use of factor ...", "dateLastCrawled": "2021-11-12T02:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Privacy-Preserving Action Recognition using Coded Aperture Videos</b> - DeepAI", "url": "https://deepai.org/publication/privacy-preserving-action-recognition-using-coded-aperture-videos", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>privacy-preserving-action-recognition-using-coded</b>...", "snippet": "Towards this end, we simulate a <b>lens</b>-free coded aperture (CA) <b>camera</b> as an appearance encoder, i.e., the first layer of privacy protection. Our goal is human action recognition from coded aperture videos for which the coded aperture mask is unknown and does not require reconstruction. We insert a second layer of privacy protection by using non-invertible motion features based on phase correlation and log-polar transformation. Phase correlation encodes translation while the log polar ...", "dateLastCrawled": "2021-12-25T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Deep Burst Super-Resolution</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2101.10997/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2101.10997", "snippet": "We use a <b>zoom</b> <b>lens</b> with a focal length of 70mm to obtain images with \u2248 4 times higher spatial resolution <b>compared</b> to burst images captured from the phone <b>camera</b>. The images are taken using a smaller aperture size (F18) to have a wider depth of field. Other capture settings are automatically determined by the <b>camera</b>. We hold the phone <b>camera</b> just above the DSLR when taking bursts in order to minimize misalignments between the two images. Additionally, we use a timer on the DSLR to ...", "dateLastCrawled": "2021-12-22T01:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Speckle correlation resolution enhancement of wide</b>-field fluorescence ...", "url": "https://www.osapublishing.org/optica/fulltext.cfm?uri=optica-2-5-424&id=315725", "isFamilyFriendly": true, "displayUrl": "https://www.osapublishing.org/optica/fulltext.cfm?uri=optica-2-5-424&amp;id=315725", "snippet": "In case one <b>can</b> take pictures using a <b>camera</b> with a low-NA objective and wants pictures with higher resolution than the objective <b>can</b> achieve, the scattering environment <b>can</b> be used as a high-NA <b>lens</b> with our method as follows. The object of interest <b>can</b> be illuminated by low-intensity laser light that generates a speckle pattern reflected from a wall. The generated speckle pattern on the object <b>can</b> be translated by the optical memory effect. Taking several low-resolution pictures for a ...", "dateLastCrawled": "2022-01-24T18:32:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Translational Invariance</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/translational-invariance", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>translational-invariance</b>", "snippet": "In a sense, the <b>analogy</b> with translation <b>invariance</b> is limited to the principle of weight sharing, but in case of scale <b>invariance</b> one also needs to properly choose an appropriate value of the variance that depends on the scale. Of course, this is not gained if we use one single neuron for detecting a corresponding feature. In order to conquer scale <b>invariance</b>, one can think of using more filters for each single feature with different \u03c3, and let the <b>learning</b> of the \u03c9 i parameters detect ...", "dateLastCrawled": "2022-01-22T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Exploiting locality and <b>translational</b> <b>invariance</b> to design effective ...", "url": "https://aip.scitation.org/doi/10.1063/1.5132378", "isFamilyFriendly": true, "displayUrl": "https://aip.scitation.org/doi/10.1063/1.5132378", "snippet": "In addition, we introduce for the first time <b>translational</b> <b>invariance</b> in the architecture of the DRL agent, and we exploit locality of the control problem to define a dense reward function. This allows us to both speed up <b>learning</b> considerably and easily control an arbitrary large number of jets and overcome the curse of dimensionality on the control output size that would take place using a na\u00efve approach. This illustrates the importance of the architecture of the agent for successful DRL ...", "dateLastCrawled": "2022-02-01T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> Applications Journal", "url": "https://groups.google.com/g/dgknwthcx/c/KSHBxbBgxX4", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/dgknwthcx/c/KSHBxbBgxX4", "snippet": "Having an application to <b>machine</b> <b>learning</b> applications to the journal. Another interesting <b>analogy</b> with and a popular and refuters showed good results in. For document or <b>translational</b> <b>invariance</b> and analyzed and architecture utilizing telemedicine is <b>machine</b> <b>learning</b>. Not happened without prior section focused on a cookie does multiple loss ...", "dateLastCrawled": "2022-01-23T21:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Size\u2010Extensive <b>Molecular Machine Learning with Global Representations</b> ...", "url": "https://chemistry-europe.onlinelibrary.wiley.com/doi/full/10.1002/syst.201900052", "isFamilyFriendly": true, "displayUrl": "https://chemistry-europe.onlinelibrary.wiley.com/doi/full/10.1002/syst.201900052", "snippet": "In recent years, <b>machine</b>-<b>learning</b> (ML) ... In particular, several physically motivated criteria such as <b>translational</b>, permutational, and rotational <b>invariance</b> and uniqueness should be fulfilled. 5, 18. The Coulomb matrix (CM) developed by Rupp et al. 4 was one of the earliest (global) molecular representations used to this end (see below for a specification of global in contrast to local representations). However, it suffers from two notable limitations, namely that the size of v depends on ...", "dateLastCrawled": "2022-01-16T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Integrating <b>Machine Learning</b> with Physics-Based Modeling | DeepAI", "url": "https://deepai.org/publication/integrating-machine-learning-with-physics-based-modeling", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/integrating-<b>machine-learning</b>-with-physics-based-modeling", "snippet": "Instead, data generation and training is an interactive process: Data is generated and labeled on the fly as model training proceeds. In <b>analogy</b> with multi-scale modeling, we refer to the former class of problems \u201csequential <b>machine learning</b>\u201d problems and the latter kind \u201cconcurrent <b>machine learning</b>\u201d problems.", "dateLastCrawled": "2022-01-27T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Different scaling of linear models and deep <b>learning</b> in UKBiobank brain ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7447816/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7447816", "snippet": "In particular, an ingredient in the success of deep <b>learning</b> for image processing have been convolution operations, which introduce the additional assumption of <b>translational</b> <b>invariance</b> 11. To use a geography <b>analogy</b>, representational features of traffic jams could be detected from satellite images by convolution layers no matter in which city the traffic jams are located and irrespective of their extent and form. These traffic events can then be picked up by higher-level convolution layers ...", "dateLastCrawled": "2022-01-26T11:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Perspective: <b>Machine</b> <b>learning</b> potentials for atomistic simulations: The ...", "url": "https://aip.scitation.org/doi/10.1063/1.4966192", "isFamilyFriendly": true, "displayUrl": "https://aip.scitation.org/doi/10.1063/1.4966192", "snippet": "Recent advances in <b>machine</b> <b>learning</b> ... which maintain permutation <b>invariance</b>. For more accurate potentials employing ML, many-body descriptors are needed, that are much more complicated than additive low dimensional functions. It is of utmost importance that the descriptors do not contain any artificial symmetries because in this case two different structures would be mapped onto the same coordinates and become indistinguishable. Ideally there would be a one-to-one correspondence between ...", "dateLastCrawled": "2022-01-28T23:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Perceptual invariance</b> in <b>Humans and Machines</b> | The Center for Brains ...", "url": "https://cbmm.mit.edu/video/perceptual-invariance-humans-and-machines", "isFamilyFriendly": true, "displayUrl": "https://cbmm.mit.edu/video/<b>perceptual-invariance</b>-<b>humans-and-machines</b>", "snippet": "I&#39;d argue that adversarial images is not just probably one of the most important problems in current <b>machine</b> <b>learning</b> or computer vision, but probably vision science. I feel like-- and I&#39;m stepping aside from the whole theme of <b>perceptual invariance</b>, and metamers, and foveation, and vision-- but I think if you go back to how advances in vision have happened over the years, over the past maybe 50 years or 60, there&#39;s discoveries that have been made from single cell electrophysiology. For ...", "dateLastCrawled": "2021-12-15T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Fabian Fuchs</b>", "url": "https://fabianfuchsml.github.io/equivariance1of2/", "isFamilyFriendly": true, "displayUrl": "https://<b>fabianfuchs</b>ml.github.io/equivariance1of2", "snippet": "In <b>machine</b> <b>learning</b>, we\u2019re often concerned with the flexibility of our models. We\u2019d like to know that the model we choose is actually capable of the task that we want it to perform. For instance, the universal approximation theorem for neural networks gives us confidence that neural networks can approximate a very broad class of functions to any desired degree of accuracy 1. There is a downside to complete flexibility. While we know that we can learn our target function, there\u2019s also a ...", "dateLastCrawled": "2022-02-03T07:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Protein sequence\u2010to\u2010structure <b>learning</b>: Is this the end(\u2010to\u2010end ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1002/prot.26235", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1002/prot.26235", "snippet": "5 FROM <b>INVARIANCE</b> TO EQUIVARIANCE. Breakthrough applications of deep <b>learning</b> often have in common that the underlying methods cater to specific characteristics of the data domain, such as long-range dependencies in text and hierarchical features in images. Figure 4 considers relevant characteristics for macromolecular structure, namely <b>invariance</b> and equivariance with respect to translations and rotations in 3D. For illustration purposes, the figure includes a series of cat cartoons in 2D ...", "dateLastCrawled": "2022-01-09T07:18:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(translational invariance)  is like +(zoom lens on a camera)", "+(translational invariance) is similar to +(zoom lens on a camera)", "+(translational invariance) can be thought of as +(zoom lens on a camera)", "+(translational invariance) can be compared to +(zoom lens on a camera)", "machine learning +(translational invariance AND analogy)", "machine learning +(\"translational invariance is like\")", "machine learning +(\"translational invariance is similar\")", "machine learning +(\"just as translational invariance\")", "machine learning +(\"translational invariance can be thought of as\")", "machine learning +(\"translational invariance can be compared to\")"]}