{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Loss Functions in Machine Learning</b> | Working | Different Types", "url": "https://www.educba.com/loss-functions-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>loss-functions-in-machine-learning</b>", "snippet": "Types of <b>Loss Functions in Machine Learning</b>. Below are the different types of the <b>loss</b> function in <b>machine</b> <b>learning</b> which are as follows: 1. Regression <b>loss</b> functions. Linear regression is a fundamental concept of this function. Regression <b>loss</b> functions establish a linear relationship between a dependent variable (Y) and an independent ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Learning</b> <b>Rate</b> in <b>Machine</b> <b>Learning</b> - Deepchecks", "url": "https://deepchecks.com/glossary/learning-rate-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://deepchecks.com/g<b>loss</b>ary/<b>learning</b>-<b>rate</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "The <b>learning</b> <b>rate</b>, denoted by the symbol \u03b1, is a hyper-parameter used to govern the pace at which an <b>algorithm</b> updates or learns the values of a parameter estimate. In other words, the <b>learning</b> <b>rate</b> regulates the weights of our neural network concerning the <b>loss</b> gradient &gt;. It indicates how often the neural network refreshes the notions it has ...", "dateLastCrawled": "2022-01-30T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Tutorial: <b>Learning Curves for Machine Learning</b> in Python", "url": "https://www.dataquest.io/blog/learning-curves-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.dataquest.io/blog/<b>learning</b>-<b>curves</b>-<b>machine</b>-<b>learning</b>", "snippet": "If you\u2019re new to <b>machine</b> <b>learning</b> and have never tried scikit, a good place to start is this blog post. We begin with a brief introduction to bias and variance. The bias-variance trade-off. In supervised <b>learning</b>, we assume there\u2019s a real relationship between feature(s) and target and estimate this unknown relationship with a model. Provided the assumption is true, there really is a model, which we\u2019ll call \\(f\\), which describes perfectly the relationship between features and target ...", "dateLastCrawled": "2022-02-02T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to interpret <b>loss</b> and accuracy for a <b>machine</b> <b>learning</b> model", "url": "https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34518656", "snippet": "The lower the <b>loss</b>, the better a model (unless the model has over-fitted to the training data). The <b>loss</b> is calculated on training and validation and its interperation is how well the model is doing for these two sets. Unlike accuracy, <b>loss</b> is not a percentage. It is a summation of the errors made for each example in training or validation sets.", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "<b>Learning</b> Curves in <b>Machine Learning</b>. Generally, a <b>learning</b> <b>curve</b> is a plot that shows time or experience on the x-axis and <b>learning</b> or improvement on the y-axis. <b>Learning</b> curves (LCs) are deemed effective tools for monitoring the performance of workers exposed to a new task. LCs provide a mathematical representation of the <b>learning</b> process that takes place as task repetition occurs. \u2014 <b>Learning</b> <b>curve</b> models and applications: Literature review and research directions, 2011. For example, if ...", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning Error: Bias, Variance and Irreducible Error</b> with ...", "url": "https://www.machinecurve.com/index.php/2020/11/02/machine-learning-error-bias-variance-and-irreducible-error-with-python/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machinecurve</b>.com/index.php/2020/11/02/<b>machine-learning-error-bias-variance</b>...", "snippet": "If you choose a <b>machine</b> <b>learning</b> <b>algorithm</b> with more bias, it will often reduce variance, making it less sensitive to data. This can be good, unless the bias means that the model becomes too rigid. The opposite is also true: if you give up rigidity only to find the model show too much sensitivity, you\u2019ve crossed the balance between bias and variance in the wrong direction.", "dateLastCrawled": "2022-02-02T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning</b> <b>Rate</b> Hyperparameter Explained | by Swapnil Kangralkar | Medium", "url": "https://swapnilin.medium.com/learning-rate-hyperparameter-explained-2c1a619cbd33", "isFamilyFriendly": true, "displayUrl": "https://swapnilin.medium.com/<b>learning</b>-<b>rate</b>-hyperparameter-explained-2c1a619cbd33", "snippet": "Initially, the <b>machine</b> <b>learning</b> <b>algorithm</b> assumes random values for ... If we were to draw a plot of <b>loss</b> vs weights, we would get the <b>curve</b> shown in fig 4, and the point marked as the star is the only place where the slope is exactly 0. i.e. the point where the <b>loss</b> function converges. But calculating the <b>loss</b> function for every value of \u2018m\u2019 would be time-consuming. Therefore, a more efficient way of finding the convergence point is by gradient descent. Gradient descent helps find the ...", "dateLastCrawled": "2022-01-14T20:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b> | by Aditya Mishra ...", "url": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metrics-to-evaluate-your-<b>machine</b>-<b>learning</b>-<b>algorithm</b>-f10...", "snippet": "False Positive <b>Rate</b> and True Positive <b>Rate</b> both have values in the range [0, 1]. FPR and TPR both are computed at varying threshold values such as (0.00, 0.02, 0.04, \u2026., 1.00) and a graph is drawn. AUC is the area under the <b>curve</b> of plot False Positive <b>Rate</b> vs True Positive <b>Rate</b> at different points in [0, 1].", "dateLastCrawled": "2022-02-02T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Optimization in <b>Machine Learning</b> \u2014 Part 1 | by Abhishek Chatterjee ...", "url": "https://medium.com/swlh/optimization-in-machine-learning-part-1-e9da1aa1eedf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/optimization-in-<b>machine-learning</b>-part-1-e9da1aa1eedf", "snippet": "The optimizer is a function that optimizes <b>Machine Learning</b> models using training data. Optimizers use a <b>Loss</b> Function to calculate the <b>loss</b> of the model and then based on that tries to optimize ...", "dateLastCrawled": "2022-02-02T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning - Performance Metrics</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_algorithms_performance_metrics.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/.../<b>machine</b>_<b>learning</b>_<b>algorithms</b>_performance_metrics.htm", "snippet": "AUC (Area Under ROC <b>curve</b>) AUC (Area Under <b>Curve</b>)-ROC (Receiver Operating Characteristic) is a performance metric, based on varying threshold values, for classification problems. As name suggests, ROC is a probability <b>curve</b> and AUC measure the separability. In simple words, AUC-ROC metric will tell us about the capability of model in ...", "dateLastCrawled": "2022-02-02T08:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to <b>machine</b> <b>learning</b>: k-nearest neighbors", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4916348/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4916348", "snippet": "<b>Machine</b> <b>learning</b> techniques have been widely used in many scientific fields, but its use in medical literature is limited partly because of technical difficulties. k-nearest neighbors (kNN) is a simple method of <b>machine</b> <b>learning</b>. The article introduces some basic ideas underlying the kNN <b>algorithm</b>, and then focuses on how to perform kNN modeling with R. The dataset should be prepared before running the knn() function in R. After prediction of outcome with kNN <b>algorithm</b>, the diagnostic ...", "dateLastCrawled": "2022-01-20T02:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "A. <b>Machine</b> <b>Learning</b> (ML) is that field of computer science. B. ML is a type of artificial intelligence that extract patterns out of raw data by using an <b>algorithm</b> or method. C. The main focus of ML is to allow computer systems learn from experience without being explicitly programmed or human intervention. D.", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a plot of model <b>learning</b> performance over experience or time. <b>Learning</b> curves are a widely used diagnostic tool in <b>machine learning</b> for algorithms that learn from a training dataset incrementally. The model can be evaluated on the training dataset and on a hold out validation dataset after each update during training and plots of the measured performance", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Knowledge Informed <b>Machine</b> <b>Learning</b> using a Weibull-based <b>Loss</b> Function ...", "url": "https://deepai.org/publication/knowledge-informed-machine-learning-using-a-weibull-based-loss-function", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/knowledge-informed-<b>machine</b>-<b>learning</b>-using-a-weibull...", "snippet": "Finally, knowledge can be integrated in a <b>machine</b> learner via a <b>learning</b> <b>algorithm</b>. A common approach is to integrate the external knowledge into the <b>loss</b> function. The <b>loss</b> function is then used in the training of a neural network. The knowledge-based <b>loss</b> function acts as a constraint on the <b>machine</b> learner during its training. This method, and specifically, a Weibull-based <b>loss</b> function, is used in this research and described below. 1.3.1 Knowledge-based <b>Loss</b> Functions. The training of a ...", "dateLastCrawled": "2022-02-03T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "AUC <b>Optimization vs. Error Rate Minimization</b>", "url": "https://proceedings.neurips.cc/paper/2003/file/6ef80bb237adf4b6f77d0700e1255907-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2003/file/6ef80bb237adf4b6f77d0700e1255907-Paper.pdf", "snippet": "have found increased interest in the <b>machine</b> <b>learning</b> and data mining communities for model evaluation and selection [12, 10, 4, 9, 15, 2]. The ROC <b>curve</b> for a binary classi\ufb01cation problem plots the true positive <b>rate</b> as a function", "dateLastCrawled": "2022-02-03T09:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b> | by Aditya Mishra ...", "url": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metrics-to-evaluate-your-<b>machine</b>-<b>learning</b>-<b>algorithm</b>-f10...", "snippet": "False Positive <b>Rate</b> and True Positive <b>Rate</b> both have values in the range [0, 1]. FPR and TPR both are computed at varying threshold values such as (0.00, 0.02, 0.04, \u2026., 1.00) and a graph is drawn. AUC is the area under the <b>curve</b> of plot False Positive <b>Rate</b> vs True Positive <b>Rate</b> at different points in [0, 1].", "dateLastCrawled": "2022-02-02T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning Error: Bias, Variance and Irreducible Error</b> with ...", "url": "https://www.machinecurve.com/index.php/2020/11/02/machine-learning-error-bias-variance-and-irreducible-error-with-python/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machinecurve</b>.com/index.php/2020/11/02/<b>machine-learning-error-bias-variance</b>...", "snippet": "If you choose a <b>machine</b> <b>learning</b> <b>algorithm</b> with more bias, it will often reduce variance, making it less sensitive to data. This can be good, unless the bias means that the model becomes too rigid. The opposite is also true: if you give up rigidity only to find the model show too much sensitivity, you\u2019ve crossed the balance between bias and variance in the wrong direction.", "dateLastCrawled": "2022-02-02T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Comparing the performance of different machine learning algorithms</b> ...", "url": "https://dibyendudeb.com/comparing-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://dibyendudeb.com/comparing-<b>machine</b>-<b>learning</b>-<b>algorithms</b>", "snippet": "Comparing <b>Machine</b> <b>Learning</b> Algorithms (MLAs) are important to come out with the best-suited <b>algorithm</b> for a particular problem. This post discusses comparing different <b>machine</b> <b>learning</b> algorithms and how we can do this using scikit-learn package of python. You will learn how to compare multiple MLAs at a time using more than one fit statistics provided by scikit-learn and also creating plots to visualize the differences.", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "8 popular Evaluation Metrics for <b>Machine</b> <b>Learning</b> Models - Just into Data", "url": "https://www.justintodata.com/machine-learning-model-evaluation-metrics/", "isFamilyFriendly": true, "displayUrl": "https://www.justintodata.com/<b>machine</b>-<b>learning</b>-model-evaluation-metrics", "snippet": "Like the ROC <b>curve</b>, the precision-recall <b>curve</b> shows the trade-off between two metrics (precision and recall) among different thresholds. Similarly, we can also look at the Area Under the <b>Curve</b> (AUC) for the precision-recall <b>curve</b>. The Precision-Recall <b>curve</b> is more informative than the ROC when the classes are imbalanced.", "dateLastCrawled": "2022-02-03T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "5. <b>Model Metrics</b> \u2014 <b>Machine</b> <b>Learning</b> 101 documentation", "url": "https://machinelearning101.readthedocs.io/en/latest/_pages/05_model_metrics.html", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>101.readthedocs.io/en/latest/_pages/05_<b>model_metrics</b>.html", "snippet": "5. <b>Model Metrics</b>\u00b6. Evaluating your <b>machine</b> <b>learning</b> <b>algorithm</b> is an essential. Your model may give you satisfying results when evaluated using a metric say accuracy_score but may give poor results when evaluated against other metrics such as logarithmic_<b>loss</b> or any other such metric. Most of the times we use classification accuracy to measure the performance of our model, however it is not enough to truly judge our model.", "dateLastCrawled": "2022-01-29T19:57:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a plot of model <b>learning</b> performance over experience or time. <b>Learning</b> curves are a widely used diagnostic tool in <b>machine learning</b> for algorithms that learn from a training dataset incrementally. The model <b>can</b> be evaluated on the training dataset and on a hold out validation dataset after each update during training and plots of the measured performance", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Getting out of <b>Loss Plateaus by adjusting Learning Rates</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2020/02/26/getting-out-of-loss-plateaus-by-adjusting-learning-rates/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machinecurve</b>.com/.../getting-out-of-<b>loss-plateaus-by-adjusting-learning-rates</b>", "snippet": "Here\u2019s the answer: supervised <b>machine</b> <b>learning</b> models are optimized by means of the gradients. If they\u2019re zero, the model gets stuck. Contrary to local minima, which we will cover next, saddle points are extra problematic because they don\u2019t represent an extremum. Hence, for example, if you\u2019d go left and right, you\u2019d find a <b>loss</b> that increases \u2013 while it would decrease for the other two directions. This means that it\u2019s extra difficult to escape such points. Let\u2019s therefore ...", "dateLastCrawled": "2022-02-02T04:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to interpret <b>loss</b> and accuracy for a <b>machine</b> <b>learning</b> model", "url": "https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34518656", "snippet": "I\u2019m voting to close this question because <b>Machine</b> <b>learning</b> (ML) theory questions are off-topic on Stack Overflow - gift-wrap candidate for Cross-Validated \u2013 Daniel F. Feb 10 &#39;21 at 12:13. Add a comment | 3 Answers Active Oldest Score. 339 The lower the <b>loss</b>, the better a model (unless the model has over-fitted to the training data). The <b>loss</b> is calculated on training and validation and its interperation is how well the model is doing for these two sets. Unlike accuracy, <b>loss</b> is not a ...", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning Model Performance</b> and <b>Error</b> Analysis", "url": "https://www.linkedin.com/pulse/machine-learning-model-performance-error-analysis-payam-mokhtarian", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/<b>machine-learning-model-performance</b>-<b>error</b>-analysis-payam...", "snippet": "One of the most important part of <b>machine</b> <b>learning</b> analytics is to take a deeper dive into model evaluation and performance metrics, and potential prediction-related errors that one may encounter.", "dateLastCrawled": "2022-01-22T01:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How do I interpret my validation and training <b>loss</b> <b>curve</b> if there is a ...", "url": "https://stats.stackexchange.com/questions/335890/how-do-i-interpret-my-validation-and-training-loss-curve-if-there-is-a-large-dif", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/335890/how-do-i-interpret-my-validation-and...", "snippet": "I <b>thought</b> maybe its because my <b>learning</b> <b>rate</b> is too large, causing the training <b>loss</b> to plunge initially. I tried reducing <b>learning</b> <b>rate</b>. But doesn&#39;t change much. I <b>thought</b> maybe its due to initial overfitting and that I am \u201clucky\u201d to have the validation <b>loss</b> eventually find its way lower, so I tried adding dropouts to my model . I&#39;m still getting the same issue. I also tried changing the momentum from 0.5 to 0.9. What is causing the shape of my <b>loss</b> <b>curve</b> to be like that and how do I ...", "dateLastCrawled": "2022-01-22T00:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Overfitting</b> in Deep Neural Networks &amp; how to prevent it. | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/the-perfect-fit-for-a-dnn-596954c9ea39", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/the-perfect-fit-for-a-dnn-596954c9ea39", "snippet": "Measures to prevent <b>overfitting</b>. 1. Decrease the network complexity. Deep neural networks like CNN are prone to <b>overfitting</b> because of the millions or billions of parameters it encloses. A model ...", "dateLastCrawled": "2022-02-02T10:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[D] Why does L-BFGS have spikes in the <b>loss</b> <b>curve</b>? : MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/comments/hasc8r/d_why_does_lbfgs_have_spikes_in_the_loss_curve/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/hasc8r/d_why_does_lbfgs_have_spikes...", "snippet": "This spike occurs at all <b>learning</b> rates, and also occurs when using L2 regularization (I&#39;ve tried various L2 coefficients). I am admittedly new to quazi-newton methods, but I <b>thought</b> there was a line search step in BFGS that sort of guaranteed that the <b>loss</b> would be non-increasing. Why could this be happening? It is especially strange that this ...", "dateLastCrawled": "2022-01-29T13:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Learning</b> <b>Curve</b> Theory: Meaning, Formulas, Graphs", "url": "https://www.valamis.com/hub/learning-curve", "isFamilyFriendly": true, "displayUrl": "https://www.valamis.com/hub/<b>learning</b>-<b>curve</b>", "snippet": "An example of where a <b>learning</b> <b>curve</b> <b>can</b> be applied could be a measurable task like a factory worker <b>learning</b> to operate a new <b>machine</b> that requires specific, repeatable steps. As the worker learns to operate the <b>machine</b> following the procedural steps, he becomes faster and more proficient at using it. A <b>learning</b> <b>curve</b> would measure this <b>rate</b> of progression and mastery. The <b>learning</b> <b>curve</b> model is used most commonly in organizational or industrial management to improve output by way of ...", "dateLastCrawled": "2022-02-03T03:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How do you plot <b>learning</b> curves for <b>Random Forest</b> models? - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/36208300/how-do-you-plot-learning-curves-for-random-forest-models", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/36208300", "snippet": "Following Andrew Ng&#39;s <b>machine</b> <b>learning</b> course, I&#39;d like to try his method of plotting <b>learning</b> curves (cost versus number of samples) in order to evaluate the need for additional data samples. However, with Random Forests I&#39;m confused about how to plot a <b>learning</b> <b>curve</b>. Random Forests don&#39;t seem to have a basic cost function like, for example, linear regression so I&#39;m not sure what exactly to use on the y axis. <b>machine</b>-<b>learning</b> <b>random-forest</b>. Share. Improve this question. Follow asked Mar 24 ...", "dateLastCrawled": "2022-01-22T00:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>HarvardX-PH125.8x-Data-Science-Machine-Learning</b>/Data_Science_<b>Machine</b> ...", "url": "https://github.com/1965Eric/HarvardX-PH125.8x-Data-Science-Machine-Learning/blob/master/Data_Science_Machine_Learning.Rmd", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/1965Eric/HarvardX-PH125.8x-Data-Science-<b>Machine</b>-<b>Learning</b>/blob/...", "snippet": "* Linear regression <b>can</b> be considered a <b>machine</b> <b>learning</b> <b>algorithm</b>. Although it <b>can</b> be too rigid to be useful, it works rather well for some challenges. It also serves as a baseline approach: if you <b>can</b>\u2019t beat it with a more complex approach, you probably want to stick to linear regression. *Code*", "dateLastCrawled": "2022-01-29T20:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Loss Functions in Machine Learning</b> | Working | Different Types", "url": "https://www.educba.com/loss-functions-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>loss-functions-in-machine-learning</b>", "snippet": "Below are the different types of the <b>loss</b> function in <b>machine</b> <b>learning</b> which are as follows: 1. Regression <b>loss</b> functions. Linear regression is a fundamental concept of this function. Regression <b>loss</b> functions establish a linear relationship between a dependent variable (Y) and an independent variable (X); hence we try to fit the best line in ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to interpret \u201c<b>loss</b>\u201d and \u201c<b>accuracy</b>\u201d for a <b>machine</b> <b>learning</b> model ...", "url": "https://intellipaat.com/community/368/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/community/368/how-to-interpret-<b>loss</b>-and-<b>accuracy</b>-for-a-<b>machine</b>...", "snippet": "A <b>loss</b> function is used to optimize a <b>machine</b> <b>learning</b> <b>algorithm</b>. The <b>loss</b> is calculated on training and validation and its interpretation is based on how well the model is doing in these two sets. It is the sum of errors made for each example in training or validation sets. <b>Loss</b> value implies how poorly or well a model behaves after each iteration of optimization. An <b>accuracy</b> metric is used to measure the <b>algorithm</b>\u2019s performance in an interpretable way. The <b>accuracy</b> of a model is usually ...", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning Error: Bias, Variance and Irreducible Error</b> with ...", "url": "https://www.machinecurve.com/index.php/2020/11/02/machine-learning-error-bias-variance-and-irreducible-error-with-python/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machinecurve</b>.com/index.php/2020/11/02/<b>machine-learning-error-bias-variance</b>...", "snippet": "All predictions are <b>compared</b> to the labels, called the ground truth, and a <b>loss</b> value is output. Based on the <b>loss</b> value, the <b>loss</b> is computed backwards, to find the optimizations for the individual parts of the <b>machine</b> <b>learning</b> model. By means of some optimization mechanism (e.g. gradient descent or Adaptive optimization), the model is optimized. Above, we talked about the \u201cobserving how bad it performs\u201d part of training a supervised <b>machine</b> <b>learning</b> model. Note that \u201chow bad\u201d and ...", "dateLastCrawled": "2022-02-02T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Tutorial: <b>Learning Curves for Machine Learning</b> in Python", "url": "https://www.dataquest.io/blog/learning-curves-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.dataquest.io/blog/<b>learning</b>-<b>curves</b>-<b>machine</b>-<b>learning</b>", "snippet": "Training the current <b>learning</b> <b>algorithm</b> on more features (to avoid collecting new data, you <b>can</b> generate easily polynomial features). This should lower the bias by increasing the model\u2019s complexity. Decreasing the regularization of the current <b>learning</b> <b>algorithm</b>, if that\u2019s the case. In a nutshell, regularization prevents the <b>algorithm</b> from ...", "dateLastCrawled": "2022-02-02T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Diagnosing Model Performance with <b>Learning</b> Curves", "url": "https://rstudio-conf-2020.github.io/dl-keras-tf/notebooks/learning-curve-diagnostics.nb.html", "isFamilyFriendly": true, "displayUrl": "https://rstudio-conf-2020.github.io/dl-keras-tf/notebooks/<b>learning-curve</b>-diagnostics...", "snippet": "The shape and dynamics of a <b>learning curve</b> <b>can</b> be used to diagnose the behavior <b>of a machine</b> <b>learning</b> model and in turn perhaps suggest at the type of configuration changes that may be made to improve <b>learning</b> and/or performance. There are three common dynamics that you are likely to observe in <b>learning</b> curves: Underfit; Overfit; Optimal Fit; We will take a closer look at each with examples. The examples will assume that we are looking at a minimizing <b>loss</b> metric, meaning that smaller ...", "dateLastCrawled": "2022-01-29T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning</b> <b>Curve</b> to identify <b>Overfitting</b> and Underfitting in <b>Machine</b> ...", "url": "https://towardsdatascience.com/learning-curve-to-identify-overfitting-underfitting-problems-133177f38df5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>learning</b>-<b>curve</b>-to-identify-<b>overfitting</b>-underfitting...", "snippet": "Image by author Interpreting the validation <b>loss</b>. <b>Learning</b> <b>curve</b> of an underfit model has a high validation <b>loss</b> at the beginning which gradually lowers upon adding training examples and suddenly falls to an arbitrary minimum at the end (this sudden fall at the end may not always happen, but it may stay flat), indicating addition of more training examples <b>can</b>\u2019t improve the model performance on unseen data.", "dateLastCrawled": "2022-02-03T01:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a plot of model <b>learning</b> performance over experience or time. <b>Learning</b> curves are a widely used diagnostic tool in <b>machine learning</b> for algorithms that learn from a training dataset incrementally. The model <b>can</b> be evaluated on the training dataset and on a hold out validation dataset after each update during training and plots of the measured performance", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Knowledge Informed <b>Machine</b> <b>Learning</b> using a Weibull-based <b>Loss</b> Function ...", "url": "https://deepai.org/publication/knowledge-informed-machine-learning-using-a-weibull-based-loss-function", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/knowledge-informed-<b>machine</b>-<b>learning</b>-using-a-weibull...", "snippet": "Finally, knowledge <b>can</b> be integrated in a <b>machine</b> learner via a <b>learning</b> <b>algorithm</b>. A common approach is to integrate the external knowledge into the <b>loss</b> function. The <b>loss</b> function is then used in the training of a neural network. The knowledge-based <b>loss</b> function acts as a constraint on the <b>machine</b> learner during its training. This method, and specifically, a Weibull-based <b>loss</b> function, is used in this research and described below.", "dateLastCrawled": "2022-02-03T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to interpret <b>loss</b> and accuracy for a <b>machine</b> <b>learning</b> model", "url": "https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34518656", "snippet": "The lower the <b>loss</b>, the better a model (unless the model has over-fitted to the training data). The <b>loss</b> is calculated on training and validation and its interperation is how well the model is doing for these two sets. Unlike accuracy, <b>loss</b> is not a percentage. It is a summation of the errors made for each example in training or validation sets.", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - definition of <b>error rate</b> in classification and why ...", "url": "https://stackoverflow.com/questions/52865390/definition-of-error-rate-in-classification-and-why-some-researchers-use-error-ra", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/52865390", "snippet": "Thanks for contributing an answer to <b>Stack Overflow</b>! Please be sure to answer the question.Provide details and share your research! But avoid \u2026. Asking for help, clarification, or responding to other answers.", "dateLastCrawled": "2022-01-25T12:20:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding the 3 most common <b>loss</b> functions for <b>Machine</b> <b>Learning</b> ...", "url": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-the-3-most-common-<b>loss</b>-functions-for...", "snippet": "A <b>loss function</b> in <b>Machine</b> <b>Learning</b> is a measure of how accurately your ML model is able to predict the expected outcome i.e the ground truth. The <b>loss function</b> will take two items as input: the output value of our model and the ground truth expected value. The output of the <b>loss function</b> is called the <b>loss</b> which is a measure of how well our model did at predicting the outcome. A high value for the <b>loss</b> means our model performed very poorly. A low value for the <b>loss</b> means our model performed ...", "dateLastCrawled": "2022-02-02T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "Introduction Evaluating your <b>machine learning</b> model is a crucial part of any project. Your model may give satisfactory results when evaluated using metrics such as accuracy but may perform poorly when evaluated against other metrics such as <b>loss</b> or F1 score. In most cases, we use accuracy to measure the model performance, however, it is not enough to truly judge our model. Thus, let\u2019s take a look at different <b>evaluation metrics</b> available. Confusion Matrix Confusion Matrix is a performance ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Evaluating a <b>Machine</b> <b>Learning</b> Model: Regression and Classification ...", "url": "https://arnavbansal-8232.medium.com/evaluating-a-machine-learning-model-regression-and-classification-metrics-4f2316e180b4", "isFamilyFriendly": true, "displayUrl": "https://arnavbansal-8232.medium.com/evaluating-a-<b>machine</b>-<b>learning</b>-model-regression-and...", "snippet": "<b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> plays a vital role in all this. ... This <b>analogy</b> is true only when we have balanced data, meaning the number of rows for each class should be the same. Contradicting this <b>analogy</b> one can say that for a binary classification algorithm if we have 100 samples, where 90 denote one class, and the remaining 10 samples denote another class. In that case our <b>analogy</b> fails. (here, we can easily get 90% accuracy by just giving all samples to first class, which seems ...", "dateLastCrawled": "2022-01-05T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Learning to Teach with Dynamic Loss Functions</b>", "url": "https://proceedings.neurips.cc/paper/2018/file/8051a3c40561002834e59d566b7430cf-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2018/file/8051a3c40561002834e59d566b7430cf-Paper.pdf", "snippet": "<b>loss</b> function of a <b>machine</b> <b>learning</b> model (we call it student) is de\ufb01ned by another <b>machine</b> <b>learning</b> model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end, similar to human teaching, the teacher, a parametric model, dynamically outputs different <b>loss</b> functions that will be used and optimized by its student model at different training stages. We develop an ef\ufb01cient <b>learning</b> ...", "dateLastCrawled": "2022-01-26T01:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>learning</b> fundamentals (I): Cost functions and gradient descent ...", "url": "https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-fundamentals-via-linear-regression-41a...", "snippet": "In this post I\u2019ll use a simple linear regression model to explain two <b>machine</b> <b>learning</b> (ML) fundamentals; (1) cost functions and; (2) gradient descent. The linear regression isn\u2019t the most powerful model in the ML tool kit, but due to its familiarity and interpretability, it is still in widespread use in research and industry. Simply, linear regression is used to estimate linear relationships between continuous or/and categorical data and a continuous output variable \u2014 you can see an ...", "dateLastCrawled": "2022-01-30T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Measuring model loss</b> | <b>Machine</b> <b>Learning</b> for Finance", "url": "https://subscription.packtpub.com/book/data/9781789136364/1/ch01lvl1sec21/measuring-model-loss", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/.../9781789136364/1/ch01lvl1sec21/<b>measuring-model-loss</b>", "snippet": "In <b>machine</b> <b>learning</b>, a <b>loss</b> function measures how bad the model performs. A high <b>loss</b> function goes hand in hand with low accuracy, whereas if the function is low, then the model is doing well. In this case, our issue is a binary classification problem. Because of that, we will be using the binary cross-entropy <b>loss</b>, as we can see in the ...", "dateLastCrawled": "2021-12-21T06:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "PREDICTION OF RESEARCH TOPICS USING COMBINATION OF <b>MACHINE</b> <b>LEARNING</b> AND ...", "url": "http://www.jatit.org/volumes/Vol49No3/14Vol49No3.pdf", "isFamilyFriendly": true, "displayUrl": "www.jatit.org/volumes/Vol49No3/14Vol49No3.pdf", "snippet": "Extreme <b>Learning</b> <b>Machine</b> and Support Vector <b>Machine</b>. The prediction result is then finally refined by logistic <b>curve</b>. The dataset used in this study is a research report on Bioinformatics from Microsoft Research and NCBI (National Center for Biotechnology Information), over the past 30 years. Experimental result indicates that the combination of <b>machine</b> <b>learning</b> approaches and logistic-<b>curve</b> may improve the prediction accuracy. In addition, the emerging topic of the same dataset can be ...", "dateLastCrawled": "2021-11-21T16:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Has anyone experience val <b>loss</b> curves like this? : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/s2h03q/has_anyone_experience_val_loss_curves_like_this/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/s2h03q/has_anyone_experience...", "snippet": "\ud83c\udfc3 Although a relatively simple optimization algorithm, gradient descent (and its variants) has found an irreplaceable place in the heart of <b>machine</b> <b>learning</b>. This is majorly due to the fact that it has shown itself to be quite handy when optimizing deep neural networks and other models. The models behind the latest advances in ML and computer vision are majorly optimized using gradient descent and its variants like Adam and gradient descent with momentum.", "dateLastCrawled": "2022-01-13T05:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "B. <b>Analogy</b> C. Deduction D. Memorization Answer : A Explanation: Different <b>learning</b> methods does not include the introduction. 8. The model will be trained with data in one single batch is known as ? A. Batch <b>learning</b> B. Offline <b>learning</b> C. Both A and B D. None of the above Ans : C Explanation: we have end-to-end <b>Machine</b> <b>Learning</b> systems in which we need to train the model in one go by using whole available training data. Such kind of <b>learning</b> method or algorithm is called Batch or Offline ...", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "deep <b>learning</b> - How can both generator and discriminator losses ...", "url": "https://datascience.stackexchange.com/questions/32699/how-can-both-generator-and-discriminator-losses-decrease", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/32699", "snippet": "In the subsection of the figure, they compute the average <b>loss</b> across 100 iterations, which is why the <b>loss</b> is monotonically decreasing because on average the <b>loss</b> does decrease with the training. You are correct in inferring that if this was reported on an iteration to iteration basis, the <b>loss</b> would be a zig zag <b>curve</b>, which is less nice to look at than a smooth <b>curve</b>.", "dateLastCrawled": "2022-01-28T20:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "PINN deep <b>learning</b> method for the Chen\u2013Lee\u2013Liu equation: Rogue wave on ...", "url": "https://www.sciencedirect.com/science/article/pii/S1007570421003798", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1007570421003798", "snippet": "<b>Machine</b> <b>learning</b> with the neural network method ... Interestingly, from Fig. 5(d), we can observe that the <b>loss curve is like</b> \u201cstair\u201d, which does not exist in that one of periodic wave solution. 4.3. The data-driven soliton wave solution. As shown in Ref. , the expression (59) of Ref. will be the bright soliton solution with taking a = c = 1, \u03b2 = 0. 5, and be the dark soliton solution with taking a = c = 1, \u03b2 = \u2212 0. 5. Let [x 0, x 1] and [t 0, t 1] in Eq. as [\u2212 6. 0, 6. 0] and [\u2212 ...", "dateLastCrawled": "2022-01-17T00:12:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(loss curve)  is like +(error rate of a machine learning algorithm)", "+(loss curve) is similar to +(error rate of a machine learning algorithm)", "+(loss curve) can be thought of as +(error rate of a machine learning algorithm)", "+(loss curve) can be compared to +(error rate of a machine learning algorithm)", "machine learning +(loss curve AND analogy)", "machine learning +(\"loss curve is like\")", "machine learning +(\"loss curve is similar\")", "machine learning +(\"just as loss curve\")", "machine learning +(\"loss curve can be thought of as\")", "machine learning +(\"loss curve can be compared to\")"]}