{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Interpret the Confusion Matrix: Accuracy, <b>Sensitivity</b> ...", "url": "https://projects.uplevel.work/insights/confusion-matrix-accuracy-sensitivity-specificity-precision-f1-score-how-to-interpret", "isFamilyFriendly": true, "displayUrl": "https://projects.uplevel.work/insights/confusion-matrix-accuracy-<b>sensitivity</b>...", "snippet": "<b>True</b> Positives (<b>TP</b>) \u2013 Test result is +ve and patient is infected. (Correct assessment.) <b>True</b> Negative (TN) \u2013 Test result is -ve and patient is healthy. (Correct assessment.) False <b>Positive</b> (FP) \u2013 Test result is +ve but patient is healthy. (Incorrect assessment. This is a false alarm.) False Negative (FN) \u2013 Test result is -ve but patient is infected. (Incorrect assessment. We let the individual go and he proceeds to spread COVID-19 to others. Worst case scenario.) The same can be ...", "dateLastCrawled": "2022-02-02T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "AI-900: <b>Microsoft Azure AI Fundamentals Certification Exam Questions</b> ...", "url": "https://www.mytechmint.com/ai-900-microsoft-azure-ai-fundamentals-certification-exam-questions-and-answers/", "isFamilyFriendly": true, "displayUrl": "https://www.mytechmint.com/ai-900-<b>microsoft-azure-ai-fundamentals-certification</b>-exam...", "snippet": "Correct <b>Answer</b>: Box 1: 11 \u2013 <b>TP</b> = <b>True</b> <b>Positive</b>. The class labels in the training set can take on only two possible values, which we usually refer to as <b>positive</b> or negative. The <b>positive</b> and negative instances that a classifier predicts <b>correctly</b> are called <b>true</b> positives (<b>TP</b>) and <b>true</b> negatives (TN), respectively. Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN). Box 2: 1,033 \u2013 FN = False Negative \u2013 Reference: https://docs ...", "dateLastCrawled": "2022-01-31T14:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Understanding and using sensitivity, specificity and predictive values", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2636062", "snippet": "In cell \u2032a,\u2032 we enter those in whom the test in <b>question</b> <b>correctly</b> diagnosed the disease (as determined by the gold standard). In other words, the test is <b>positive</b>, as is the gold standard. These are the <b>true</b> positives (<b>TP</b>). In cell \u2032b,\u2032 we enter those who have <b>positive</b> results for the test in <b>question</b> but do not have disease according to the \u2032gold standard test.\u2032 The newer test has wrongly diagnosed the disease: These are false positives (FP). In cell \u2032c,\u2032 we enter those who ...", "dateLastCrawled": "2022-01-30T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Top 40 <b>Machine Learning Interview Questions</b> &amp; Answers 2022", "url": "https://intellipaat.com/blog/interview-question/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-<b>question</b>/<b>machine-learning-interview-questions</b>", "snippet": "16. Explain false negative, false <b>positive</b>, <b>true</b> negative, and <b>true</b> <b>positive</b> with a simple example. <b>True</b> <b>Positive</b> (<b>TP</b>): When the Machine Learning model <b>correctly</b> predicts the condition, it is said to have a <b>True</b> <b>Positive</b> value. <b>True</b> Negative (TN): When the Machine Learning model <b>correctly</b> predicts the negative condition or class, then it is ...", "dateLastCrawled": "2022-01-30T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is <b>Accuracy</b>, <b>Precision</b>, and Recall? And Why are they Important ...", "url": "https://shiffdag.medium.com/what-is-accuracy-precision-and-recall-and-why-are-they-important-ebfcb5a10df2", "isFamilyFriendly": true, "displayUrl": "https://shiffdag.medium.com/what-is-<b>accuracy</b>-<b>precision</b>-and-recall-and-why-are-they...", "snippet": "T (<b>True</b>) means that the model has <b>correctly</b> classified an observation. In other words, the predicted class and actual class coincide with one another. F (False) means that the model has incorrectly classified an observation by assigning it to the wrong class. <b>TP</b> ( <b>True</b> <b>Positive</b>) means the model was <b>correctly</b> classified in the <b>positive</b> class. TN ( <b>True</b> Negative) means the model <b>correctly</b> classified an observation in the negative class. FP (False <b>positive</b>) means the model classified an ...", "dateLastCrawled": "2022-02-02T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "image processing - how <b>to calculate accuracy in segmentation model</b> ...", "url": "https://stackoverflow.com/questions/64610214/how-to-calculate-accuracy-in-segmentation-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/<b>questions</b>/64610214/how-<b>to-calculate-accuracy-in-segmentation</b>...", "snippet": "<b>TP</b> : <b>True</b> <b>Positive</b> is the number of objects you <b>correctly</b> identified in image. FP : False <b>Positive</b> are objects you identified but actually that&#39;s a mistake because there is no such object in ground-truth. TN : <b>True</b> Negative is when algorithm doesn&#39;t identify any object and indeed that is the case with ground-truth. i.e. correct negative identification. FN : False Negative is when your algorithm failed to identify objects (i.e. the ground truth contains objects in the image(s), but it is ...", "dateLastCrawled": "2022-01-28T20:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Confusion Matrix in Machine Learning: Everything You Need to Know ...", "url": "https://hackernoon.com/confusion-matrix-in-machine-learning-everything-you-need-to-know", "isFamilyFriendly": true, "displayUrl": "https://hackernoon.com/confusion-matrix-in-machine-learning-everything-you-need-to-know", "snippet": "Notice how you\u2019re trying to <b>answer</b> the <b>question</b> \u201cWill the student default on the loan?\u201d\u2014and <b>the answer</b> is either a ... The number of times the classifier <b>correctly</b> predicted class 1, plus the number of times it <b>correctly</b> predicted class 0. Now, look up from the matrix above, it\u2019s the count of <b>True</b> <b>Positive</b> (<b>TP</b>) + <b>True</b> Negative (TN). And the total number of predictions is the sum of counts in all 4 quadrants. This this leads to the formula for accuracy as given below: Accuracy = <b>TP</b> ...", "dateLastCrawled": "2022-02-03T11:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to find <b>true</b> <b>positive</b>, <b>true</b> negative, false <b>positive</b>, false ...", "url": "https://stats.stackexchange.com/questions/187724/how-to-find-true-positive-true-negative-false-positive-false-negative-from-a", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/<b>question</b>s/187724", "snippet": "When I understand your <b>question</b> <b>correctly</b> you are asking which class is the <b>positive</b> one and which is the negative one. <b>The answer</b> is that this is to a certain extent arbitrary, so you have to decide that considering the problem at hand.. From &quot;Machine Learning with R&quot; by Brett Lantz, 2.nd edition, 2015, p. 318:. The most common performance measures consider the model&#39;s ability to discern one class versus all others.", "dateLastCrawled": "2022-01-24T14:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>True Position</b> | GD&amp;T Basics", "url": "https://www.gdandtbasics.com/true-position", "isFamilyFriendly": true, "displayUrl": "https://www.gdandtbasics.com/<b>true-position</b>", "snippet": "Ok, this may seem <b>like</b> a silly <b>question</b>. I have a <b>true position</b> callout, <b>TP</b>[0.5|X|Y|Z]. There is no diametric call out with the tolerance. We send the parts to be measured by CMM with a third party. The report the gave us shows the <b>true position</b> OOT, measuring 1.322, (<b>TP</b> RFS 1.322). The only way I can replicate this result is to either ...", "dateLastCrawled": "2022-02-03T06:51:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Logistic Regression</b> in Classification model using Python: Machine ...", "url": "https://towardsdatascience.com/logistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>logistic-regression</b>-in-classification-model-using...", "snippet": "Accuracy is the percentage of <b>correctly</b> predicted labels. The <b>correctly</b> predicted labels from the matrix would be: <b>True</b> <b>Positive</b>(<b>TP</b>): Churn customers are being predicted as churn; <b>True</b> Negative(TN): Non-churn customers are being predicted as non-churn. Accuracy = (<b>Correctly</b> predicted labels)/(Total number of labels) Accuracy = (TN+<b>TP</b> )/ (TN+FP+FN+<b>TP</b>) According to our model above, TN = 3270 FP = 365 FN = 579 <b>TP</b> = 708. The accuracy will be, acc = (3270+708)/(3270+365+579+708) = 0.808 = 80.8% ...", "dateLastCrawled": "2022-01-30T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding and using sensitivity, specificity and predictive values", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2636062", "snippet": "In cell \u2032a,\u2032 we enter those in whom the test in <b>question</b> <b>correctly</b> diagnosed the disease (as determined by the gold standard). In other words, the test is <b>positive</b>, as is the gold standard. These are the <b>true</b> positives (<b>TP</b>). In cell \u2032b,\u2032 we enter those who have <b>positive</b> results for the test in <b>question</b> but do not have disease according to the \u2032gold standard test.\u2032 The newer test has wrongly diagnosed the disease: These are false positives (FP). In cell \u2032c,\u2032 we enter those who ...", "dateLastCrawled": "2022-01-30T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Top 40 <b>Machine Learning Interview Questions</b> &amp; Answers 2022", "url": "https://intellipaat.com/blog/interview-question/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-<b>question</b>/<b>machine-learning-interview-questions</b>", "snippet": "16. Explain false negative, false <b>positive</b>, <b>true</b> negative, and <b>true</b> <b>positive</b> with a simple example. <b>True</b> <b>Positive</b> (<b>TP</b>): When the Machine Learning model <b>correctly</b> predicts the condition, it is said to have a <b>True</b> <b>Positive</b> value. <b>True</b> Negative (TN): When the Machine Learning model <b>correctly</b> predicts the negative condition or class, then it is ...", "dateLastCrawled": "2022-01-30T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Precision, Recall, Sensitivity and Specificity", "url": "https://iq.opengenus.org/precision-recall-sensitivity-specificity/", "isFamilyFriendly": true, "displayUrl": "https://iq.opengenus.org/precision-recall-sensitivity-specificity", "snippet": "Recall <b>answer</b> to this <b>question</b>, Of all the workers who are diabetic, how many of them did we properly predict? Recall Used Important; When : When the occurrence of false negatives is unacceptable. When we want to <b>identifying</b> the positives is crucial. Example: When predicting financial default or a deadly disease or Security checks in airports. More false positives than fewer false negatives. Specificity. Specificity is the Ratio of <b>true</b> negatives to total negatives in the data. Specificity ...", "dateLastCrawled": "2022-01-31T23:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evaluating a <b>Classification Model</b> | Machine Learning, Deep Learning ...", "url": "https://www.ritchieng.com/machine-learning-evaluate-classification-model/", "isFamilyFriendly": true, "displayUrl": "https://www.ritchieng.com/machine-learning-evaluate-<b>classification-model</b>", "snippet": "<b>True</b> Positives (<b>TP</b>): we <b>correctly</b> predicted that they do have diabetes. 15; <b>True</b> Negatives (TN): we <b>correctly</b> predicted that they don&#39;t have diabetes. 118; False Positives (FP): we incorrectly predicted that they do have diabetes (a &quot;Type I error&quot;) 12; Falsely predict <b>positive</b>; Type I error; False Negatives (FN): we incorrectly predicted that they don&#39;t have diabetes (a &quot;Type II error&quot;) 47; Falsely predict negative; Type II error; 0: negative class; 1: <b>positive</b> class; In [15]: # print the ...", "dateLastCrawled": "2022-02-03T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Metrics to measure the effectiveness of a diagnostic test</b> | by Ruchika ...", "url": "https://ruchikaverma.medium.com/metrics-to-measure-the-effectiveness-of-a-diagnostic-test-d3f3af3b8ed2", "isFamilyFriendly": true, "displayUrl": "https://ruchikaverma.medium.com/<b>metrics-to-measure-the-effectiveness-of-a-diagnostic</b>...", "snippet": "Sensitivity = <b>true</b> <b>positive</b> fraction (TPF): Sensitivity is the ratio of <b>TP</b> to the actual number of positives/diseased. It refers to the probability of a <b>positive</b> test result for patients with disease i.e. conditional probability of <b>correctly</b> <b>identifying</b> the diseased subjects by a diagnostic test. Sensitivity is used to determine whether the test is sufficiently sensitive to pick up the disease.", "dateLastCrawled": "2022-02-01T16:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Kaplan Quiz Review", "url": "http://www.kaplanquizzes.com/goto/kaplan/quizzes/review/biostatistics.php", "isFamilyFriendly": true, "displayUrl": "www.kaplanquizzes.com/goto/kaplan/quizzes/review/biostatistics.php", "snippet": "<b>TP</b> = <b>true</b> <b>positive</b>, an abnormal test result in an individual with disease ; FP = false <b>positive</b>, an abnormal test result in a healthy person ; Let&#39;s say that we are changing our cutoff from Line C (140 mg/dL) to Line B (126 mg/dL) in the graph below. From Line B, looking to the right, we do a much better job at labeling all of the diseased people. Therefore, we have really good sensitivity, <b>TP</b>/(<b>TP</b>-FN). Sensitivity is the probability of <b>correctly</b> <b>identifying</b> a case of disease. If you look to ...", "dateLastCrawled": "2022-01-26T11:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Free Download AI-900 Examp Dump: Microsoft Azure AI Fundamentals ...", "url": "https://www.exam-files.com/microsoft/ai-900/microsoft%20azure%20ai%20fundamentals.prepdumps.ai-900.2021-07-28.2e.73q.vcex/", "isFamilyFriendly": true, "displayUrl": "https://www.exam-files.com/microsoft/ai-900/microsoft azure ai fundamentals.prepdumps...", "snippet": "Use the drop-down menus to select <b>the answer</b> choice that completes each statement based on the information presented in the graphic. NOTE: Each correct selection is worth one point. Correct <b>Answer</b>: Exam simulator is required. Box 1: 11 - <b>TP</b> = <b>True</b> <b>Positive</b>. The class labels in the training set can take on only two possible values, which we usually refer to as <b>positive</b> or negative. The <b>positive</b> and negative instances that a classifier predicts <b>correctly</b> are called <b>true</b> positives (<b>TP</b>) and <b>true</b> ...", "dateLastCrawled": "2022-02-02T04:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>compute true positive, false positive, true negative</b> and false ...", "url": "https://www.researchgate.net/post/how_compute_true_positive_false_positive_true_negative_and_false_negative_in_searchable_encryption", "thumbnailUrl": "https://www.bing.com/th?id=OIP.wg_wWd9GLT4yhMwXSsOR1AHaHa&pid=Api", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/how_<b>compute_true_positive_false_positive</b>_<b>true</b>...", "snippet": "<b>True</b> <b>Positive</b>: Sensitivity (also called the <b>true</b> <b>positive</b> rate, the recall, or probability of detection in some fields) measures the proportion of actual positives that are <b>correctly</b> identified as ...", "dateLastCrawled": "2022-01-31T19:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Diagnostic <b>accuracy</b> \u2013 Part 1 Basic concepts: sensitivity and ...", "url": "https://acutecaretesting.org/en/articles/diagnostic-accuracy--part-1brbasic-concepts-sensitivity-and-specificity-roc-analysis-stard-statement", "isFamilyFriendly": true, "displayUrl": "https://acutecaretesting.org/en/articles/diagnostic-<b>accuracy</b>--part-1brbasic-concepts...", "snippet": "<b>True</b> <b>positive</b> (<b>TP</b>) \u2013 subjects having stroke and S-100B &gt; 0.5 \u00b5g/L; False <b>positive</b> (FP) \u2013 subjects without stroke and S-100B &gt; 0.5 \u00b5g/L ; <b>True</b> negative (TN) \u2013 subjects without stroke and S-100B ; 0.5 \u00b5g/L False negative (FN) \u2013 subjects having stroke and S-100B ; 0.5 \u00b5g/L The first step in calculating sensitivity and specificity is to make a 2 \u00d7 2 table with groups of subjects divided according to a gold standard or reference method (diagnostic criteria) in columns, and categories ...", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification: <b>Precision</b> and Recall | Machine Learning Crash Course ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/crash-course/classification/<b>precision</b>...", "snippet": "<b>Precision</b> = <b>T P</b> <b>T P</b> + F P = 8 8 + 2 = 0.8. Recall measures the percentage of actual spam emails that were <b>correctly</b> classified\u2014that is, the percentage of green dots that are to the right of the threshold line in Figure 1: Recall = <b>T P</b> <b>T P</b> + F N = 8 8 + 3 = 0.73. Figure 2 illustrates the effect of increasing the classification threshold. Figure 2.", "dateLastCrawled": "2022-01-30T23:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Receiver Operating Characteristic</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/engineering/receiver-operating-characteristic", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/engineering/<b>receiver-operating-characteristic</b>", "snippet": "On the other hand, the <b>true</b> <b>positive</b> (<b>TP</b>) detection rate is the probability of <b>correctly</b> classifying a target object as being indeed a target object. Both the <b>TP</b> and FP rates are specified in the interval from 0.0 to 1.0, inclusive. In medical imaging the <b>TP</b> rate is commonly referred to as sensitivity, and (1.0-FP rate) is called specificity.", "dateLastCrawled": "2022-02-02T22:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is <b>the difference between Precision, Specificity and Accuracy</b>? - Quora", "url": "https://www.quora.com/What-is-the-difference-between-Precision-Specificity-and-Accuracy", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-difference-between-Precision-Specificity-and-Accuracy</b>", "snippet": "<b>Answer</b> (1 of 4): Precision, Specificity and Accuracy are all measures of relevance for a binary classifier. For a binary classifier that classifies instances into <b>positive</b> (1) and negative (0) instances, any single prediction <b>can</b> fall into one of four buckets: 1. <b>True</b> <b>Positive</b> (<b>TP</b>): The <b>true</b> lab...", "dateLastCrawled": "2022-01-25T10:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Principles of Epidemiology: Lesson 6 Quiz|Self-Study Course SS1978|CDC", "url": "https://www.cdc.gov/csels/dsepd/ss1978/lesson6/quiz.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.cdc.gov</b>/csels/dsepd/ss1978/lesson6/quiz.html", "snippet": "This course covers basic epidemiology principles, concepts, and procedures useful in the surveillance and investigation of health-related states or events. It is designed for federal, state, and local government health professionals and private sector health professionals who are responsible for disease surveillance or investigation. A basic understanding of the practices of public health and biostatistics is recommended.", "dateLastCrawled": "2022-02-02T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Test 2 Questions - Richard - Rice University", "url": "http://www.owlnet.rice.edu/~bioe301/kortum/class/students/exams/Practice%20Exam%202%20with%20Answers.doc", "isFamilyFriendly": true, "displayUrl": "www.owlnet.rice.edu/~bioe301/kortum/class/students/exams/Practice Exam 2 with <b>Answer</b>s.doc", "snippet": "An antibody <b>can</b> <b>be thought</b> of as a bridge between a pathogen and the tool to kill it. Antibodies have two important regions: (1) Fab region: which binds free antigen or binds surface of virus infected cell (2) Fc region: which binds macrophages and neutrophils and induces phagocytosis or binds natural killer cell and induces killing . A screening test for a particular disease has a sensitivity of 96% and a specificity of 92%. You plan to screen a population in which the prevalence of the ...", "dateLastCrawled": "2022-01-30T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "False Positives and False Negatives", "url": "https://www.mathsisfun.com/data/probability-false-negatives-positives.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mathsisfun.com</b>/data/probability-false-negatives-<b>positives</b>.html", "snippet": "Airport Security: a &quot;false <b>positive</b>&quot; is when ordinary items such as keys or coins get mistaken for weapons (machine goes &quot;beep&quot;); Quality Control: a &quot;false <b>positive</b>&quot; is when a good quality item gets rejected, and a &quot;false negative&quot; is when a poor quality item gets accepted.(A &quot;<b>positive</b>&quot; result means there IS a defect.) Antivirus software: a &quot;false <b>positive</b>&quot; is when a normal file is <b>thought</b> to be a virus; Medical screening: low-cost tests given to a large group <b>can</b> give many false positives ...", "dateLastCrawled": "2022-02-02T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "machine learning - Calculating <b>F-Score</b>, which is the &quot;<b>positive</b>&quot; class ...", "url": "https://stats.stackexchange.com/questions/191645/calculating-f-score-which-is-the-positive-class-the-majority-or-minority-cla", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/<b>question</b>s/191645", "snippet": "If you take your case 1, &quot;# of predicted healthy patients over # of actual healthy patients&quot;, the &quot;<b>true</b> negatives&quot; are those who were <b>correctly</b> classified as having cancer yet that success in <b>identifying</b> patients with cancer doesn&#39;t enter into the <b>F-score</b>. If you take case 2, &quot;# of predicted cancer patients over # of actual cancer patients,&quot; then the number of patients <b>correctly</b> classified as not having cancer is ignored. Neither seems like a good choice in this situation.", "dateLastCrawled": "2022-01-24T21:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>True Position</b> | GD&amp;T Basics", "url": "https://www.gdandtbasics.com/true-position", "isFamilyFriendly": true, "displayUrl": "https://www.gdandtbasics.com/<b>true-position</b>", "snippet": "The only way I <b>can</b> replicate this result is to either calculate <b>TP</b> with X and Z coordinates and use diameter position tolerance, or spherical diameter <b>true position</b> with all X, Y, and Z. Mind you, I am rather lost in all of this and the nomenclature, but I <b>can</b> make the math work. My <b>question</b> is, is that the correct way to do it? The drawing does not call out the diameter symbol in the FCF. The feature being measured is a square hole dimensioned at 9mm by 9mm with a +/- 0.3mm. There is also ...", "dateLastCrawled": "2022-02-03T06:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Understanding Classifier Performance: A Primer - Apixio Blog", "url": "https://www.apixio.com/techblog/classifier-performance-primer/", "isFamilyFriendly": true, "displayUrl": "https://www.apixio.com/techblog/classifier-performance-primer", "snippet": "<b>The answer</b> to the latter <b>question</b> gives us <b>the answer</b> to the former. Take the case of credit card fraud. Somewhere close to 99.9% (maybe more) of credit card transactions are valid. If we are making a classifier to detect credit card fraud, we aren\u2019t as concerned with <b>correctly</b> <b>identifying</b> valid transactions\u2014we\u2019re interested in detecting ...", "dateLastCrawled": "2022-01-30T17:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification: <b>True</b> vs. False and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-false-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model <b>correctly</b> predicts the negative class.. A false <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a false negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding and using sensitivity, specificity and predictive values", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2636062", "snippet": "In cell \u2032a,\u2032 we enter those in whom the test in <b>question</b> <b>correctly</b> diagnosed the disease (as determined by the gold standard). In other words, the test is <b>positive</b>, as is the gold standard. These are the <b>true</b> positives (<b>TP</b>). In cell \u2032b,\u2032 we enter those who have <b>positive</b> results for the test in <b>question</b> but do not have disease according to the \u2032gold standard test.\u2032 The newer test has wrongly diagnosed the disease: These are false positives (FP). In cell \u2032c,\u2032 we enter those who ...", "dateLastCrawled": "2022-01-30T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Evaluation</b> Metrics for Machine Learning Models | by Bhajandeep Singh ...", "url": "https://heartbeat.comet.ml/evaluation-metrics-for-machine-learning-models-d42138496366", "isFamilyFriendly": true, "displayUrl": "https://heartbeat.comet.ml/<b>evaluation</b>-metrics-for-machine-learning-models-d42138496366", "snippet": "<b>True</b> <b>Positive</b> (<b>TP</b>) \u2014 A <b>true</b> <b>positive</b> is an outcome where the model <b>correctly</b> predicts the <b>positive</b> class. <b>True</b> Negative (TN) ... The AUC is one way to summarize the ROC curve into a single number so that it <b>can</b> <b>be compared</b> easily and automatically. A good ROC curve has a lot of space under it (because the <b>true</b> <b>positive</b> rate shoots up to 100% very quickly). A bad ROC curve covers very little area. So high AUC is good, and low AUC is not so good. One last important point to keep in mind ...", "dateLastCrawled": "2022-01-28T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Diagnostic <b>accuracy</b> \u2013 Part 1 Basic concepts: sensitivity and ...", "url": "https://acutecaretesting.org/en/articles/diagnostic-accuracy--part-1brbasic-concepts-sensitivity-and-specificity-roc-analysis-stard-statement", "isFamilyFriendly": true, "displayUrl": "https://acutecaretesting.org/en/articles/diagnostic-<b>accuracy</b>--part-1brbasic-concepts...", "snippet": "<b>True</b> <b>positive</b> (<b>TP</b>) \u2013 subjects having stroke and S-100B &gt; 0.5 \u00b5g/L; False <b>positive</b> (FP) \u2013 subjects without stroke and S-100B &gt; 0.5 \u00b5g/L ; <b>True</b> negative (TN) \u2013 subjects without stroke and S-100B ; 0.5 \u00b5g/L False negative (FN) \u2013 subjects having stroke and S-100B ; 0.5 \u00b5g/L The first step in calculating sensitivity and specificity is to make a 2 \u00d7 2 table with groups of subjects divided according to a gold standard or reference method (diagnostic criteria) in columns, and categories ...", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is <b>Accuracy</b>, <b>Precision</b>, and Recall? And Why are they Important ...", "url": "https://shiffdag.medium.com/what-is-accuracy-precision-and-recall-and-why-are-they-important-ebfcb5a10df2", "isFamilyFriendly": true, "displayUrl": "https://shiffdag.medium.com/what-is-<b>accuracy</b>-<b>precision</b>-and-recall-and-why-are-they...", "snippet": "T (<b>True</b>) means that the model has <b>correctly</b> classified an observation. In other words, the predicted class and actual class coincide with one another. F (False) means that the model has incorrectly classified an observation by assigning it to the wrong class. <b>TP</b> ( <b>True</b> <b>Positive</b>) means the model was <b>correctly</b> classified in the <b>positive</b> class. TN ( <b>True</b> Negative) means the model <b>correctly</b> classified an observation in the negative class. FP (False <b>positive</b>) means the model classified an ...", "dateLastCrawled": "2022-02-02T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Metrics to measure the effectiveness of a diagnostic test</b> | by Ruchika ...", "url": "https://ruchikaverma.medium.com/metrics-to-measure-the-effectiveness-of-a-diagnostic-test-d3f3af3b8ed2", "isFamilyFriendly": true, "displayUrl": "https://ruchikaverma.medium.com/<b>metrics-to-measure-the-effectiveness-of-a-diagnostic</b>...", "snippet": "Sensitivity = <b>true</b> <b>positive</b> fraction (TPF): Sensitivity is the ratio of <b>TP</b> to the actual number of positives/diseased. It refers to the probability of a <b>positive</b> test result for patients with disease i.e. conditional probability of <b>correctly</b> <b>identifying</b> the diseased subjects by a diagnostic test. Sensitivity is used to determine whether the test is sufficiently sensitive to pick up the disease.", "dateLastCrawled": "2022-02-01T16:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Performance Metrics for Classification problems in Machine Learning</b> ...", "url": "https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@MohammedS/<b>performance-metrics-for-classification-problems</b>-in...", "snippet": "<b>True</b> Positives (<b>TP</b>): ... comes under <b>True</b> <b>positive</b>. 2. <b>True</b> Negatives (TN): <b>True</b> negatives are the cases when the actual class of the data point was 0(False) and the predicted is also 0(False. Ex ...", "dateLastCrawled": "2022-02-02T11:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Classification: <b>Accuracy</b> | Machine Learning Crash Course | Google ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/accuracy", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/crash-course/classification/<b>accuracy</b>", "snippet": "Of the 100 tumor examples, 91 are benign (90 TNs and 1 FP) and 9 are malignant (1 <b>TP</b> and 8 FNs). Of the 91 benign tumors, the model <b>correctly</b> identifies 90 as benign. That&#39;s good. However, of the 9 malignant tumors, the model only <b>correctly</b> identifies 1 as malignant\u2014a terrible outcome, as 8 out of 9 malignancies go undiagnosed!", "dateLastCrawled": "2022-02-02T21:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Logistic Regression</b> in Classification model using Python: Machine ...", "url": "https://towardsdatascience.com/logistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>logistic-regression</b>-in-classification-model-using...", "snippet": "The variables having showing <b>True</b> are the ones we are interested in, and if we want to add more than 15 variables, we <b>can</b> add them one by one based on their respective ranks. Build the model using the above 15 variables Let\u2019s build our second model using the 15 variables we got from RFE.", "dateLastCrawled": "2022-01-30T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Imbalanced Data in <b>Classification</b>: General Solution &amp; Case Study | by ...", "url": "https://towardsdatascience.com/imbalanced-data-in-classification-general-solution-case-study-169f2e18b017", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/imbalanced-data-in-<b>classification</b>-general-solution-case...", "snippet": "The Receiver Operating Characteristic (ROC) curve is a graphical illustration of the <b>classification</b> model\u2019s performance in <b>identifying</b> the <b>positive</b> from the negative class as the discrimination threshold is varied (see below Figure 2). Additionally, it reflects the trade-off between type I and type II errors. As we successfully identify more <b>true</b> negative\u2019s (Fraud) in our data, it comes at the expense of misidentifying non-fraud records as fraud (committing false <b>positive</b>).", "dateLastCrawled": "2022-02-02T23:36:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Confusion Matrix in <b>Machine</b> <b>Learning</b> \u2013 Naukri <b>Learning</b>", "url": "https://www.naukri.com/learning/articles/confusion-matrix-in-machine-learning-naukri-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.naukri.com/<b>learning</b>/articles/confusion-matrix-in-<b>machine</b>-<b>learning</b>-naukri...", "snippet": "Let\u2019s understand <b>TP</b>, FP, FN, TN in terms of Coronavirus affected people <b>analogy</b>. <b>True</b> <b>Positive</b>: Interpretation: You predicted <b>positive</b> and it\u2019s <b>true</b>. You predicted that a person is Corona <b>positive</b> and he actually is having Corona. <b>True</b> Negative: Interpretation: You predicted negative and it\u2019s <b>true</b>.", "dateLastCrawled": "2022-02-07T08:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding Confusion Matrix in <b>Machine</b> <b>Learning</b>, Let\u2019s Study ...", "url": "https://ulimazzadaislamy.medium.com/understanding-confusion-matrix-in-machine-learning-lets-study-together-7521090aaaf2", "isFamilyFriendly": true, "displayUrl": "https://ulimazzadaislamy.medium.com/understanding-confusion-matrix-in-<b>machine</b>-<b>learning</b>...", "snippet": "Let\u2019s understand <b>TP</b>, FP, FN, TN in terms of pregnancy <b>analogy</b>: The <b>analogy</b> from the picture: <b>True</b> <b>Positive</b>: Interpretation: You predicted <b>positive</b> and it\u2019s <b>true</b>. You predicted that a woman is pregnant and she actually is. <b>True</b> Negative: Interpretation: You predicted negative and it\u2019s <b>true</b>. You predicted that a man is not pregnant and he actually is not. False <b>Positive</b>: (Type 1 Error) Interpretation: You predicted <b>positive</b> and it\u2019s false. You predicted that a man is pregnant but he ...", "dateLastCrawled": "2022-01-13T10:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning Accuracy</b>: <b>True</b> vs. False <b>Positive</b>/Negative", "url": "https://research.aimultiple.com/machine-learning-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://research.aimultiple.com/<b>machine-learning-accuracy</b>", "snippet": "There are various theoretical approaches to measuring accuracy* of competing <b>machine</b> <b>learning</b> models however, in most commercial applications, you simply need to assign a business value to 4 types of results: <b>true</b> positives, <b>true</b> negatives, false positives and false negatives.By multiplying number of results in each bucket with the associated business values, you will ensure that you use the best model available.", "dateLastCrawled": "2022-02-03T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "ROAL OF CONFUSION MATRIX IN CYBER CRIME | by HM | Medium", "url": "https://h17.medium.com/roal-of-confusion-matrix-in-cyber-crime-41e7c9c3f57b", "isFamilyFriendly": true, "displayUrl": "https://h17.medium.com/roal-of-confusion-matrix-in-cyber-crime-41e7c9c3f57b", "snippet": "Let\u2019s understand <b>TP</b>, FP, FN, TN in terms of pregnancy <b>analogy</b>. <b>True</b> <b>Positive</b>: Interpretation: You predicted <b>positive</b> and it\u2019s <b>true</b>. You predicted that a woman is pregnant and she actually is. <b>True</b> Negative: Interpretation: You predicted negative and it\u2019s <b>true</b>. You predi c ted that a man is not pregnant and he actually is not. False <b>Positive</b>: (Type 1 Error) Interpretation: You predicted <b>positive</b> and it\u2019s false. You predicted that a man is pregnant but he actually is not. False ...", "dateLastCrawled": "2022-01-10T21:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Evaluating a <b>Machine</b> <b>Learning</b> Model: Regression and Classification ...", "url": "https://arnavbansal-8232.medium.com/evaluating-a-machine-learning-model-regression-and-classification-metrics-4f2316e180b4", "isFamilyFriendly": true, "displayUrl": "https://arnavbansal-8232.medium.com/evaluating-a-<b>machine</b>-<b>learning</b>-model-regression-and...", "snippet": "<b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> plays a vital role in all this. ... <b>True</b> <b>positive</b> (<b>TP</b>) \u2014 actual = 1; predicted = 1 (11 = 1) False <b>positive</b> (FP) \u2014 actual = 0; predicted = 1 (01 = 0) False negative (FN) \u2014 actual = 1; predicted = 0 (10 = 0) <b>True</b> negative (TN) \u2014 actual = 0; predicted = 0 (00 = 1) \u201cXNOR gate\u201d produces this kind of output. Our objective is to train the model, so that our algorithm predicts the same as the <b>true</b> output. Hence, our algorithm should produce more outputs ...", "dateLastCrawled": "2022-01-05T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is <b>True</b> Negative, and a pregnant woman whose test results say \u201cPregnant\u201d is <b>True</b> <b>Positive</b>. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "Confusion Matrix Confusion Matrix is a performance measurement for a <b>machine learning</b> classification problem where output can be two or more classes. It is a table with 4 different combinations of predicted and actual values as shown below. It is very useful for measuring other <b>evaluation metrics</b> such as Recall, Precision, Specificity, Accuracy, and most importantly AUC-ROC Curve. Following is an example in terms of pregnancy <b>analogy</b> to help you better understand <b>TP</b>, TN, FP, and FN. <b>True</b> ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Model 1: accuracy = 92%. Model 2: accuracy = 95%. Model 2 has higher accuracy than model 1, but model 2 is useless. This is called accuracy paradox, which means the model with higher accuracy may not have better generalization power. In general, when <b>TP</b> &lt; FP, the accuracy will always increase when we change the classifier to always output &#39;negative&#39;.Conversely, when TN &lt; FN, the same will happen when we change the classifier to always output &#39;<b>positive</b>&#39; [1].. Recall@k", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Receiver Operating Curve (ROC) and The Scale \u2014 Understanding ROC ...", "url": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the-scale-understanding-roc-through-an-analogy-8b8f9d954f84", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the...", "snippet": "The Receiver Operating Curve (ROC) is used to evaluate and improve classification <b>Machine</b> <b>Learning</b> models. Who does not want an accurate classifier, that place observations where they actually\u2026", "dateLastCrawled": "2021-02-13T00:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - How to calculate precision and recall in a 3 x 3 ...", "url": "https://stats.stackexchange.com/questions/91044/how-to-calculate-precision-and-recall-in-a-3-x-3-confusion-matrix", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/91044/how-to-calculate-precision-and-recall...", "snippet": "We know Precision = <b>TP</b>/(<b>TP</b>+FP), so for Pa <b>true</b> <b>positive</b> will be Actual A predicted as A, i.e., 10, rest of the two cells in that column, whether it is B or C, make False <b>Positive</b>. So. Pa = 10/18 = 0.55 Ra = 10/17 = 0.59. Now precision and recall for class B are Pb and Rb. For class B, <b>true</b> <b>positive</b> is actual B predicted as B, that is the cell ...", "dateLastCrawled": "2022-01-30T05:56:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(true positive (tp))  is like +(correctly identifying the answer to a question)", "+(true positive (tp)) is similar to +(correctly identifying the answer to a question)", "+(true positive (tp)) can be thought of as +(correctly identifying the answer to a question)", "+(true positive (tp)) can be compared to +(correctly identifying the answer to a question)", "machine learning +(true positive (tp) AND analogy)", "machine learning +(\"true positive (tp) is like\")", "machine learning +(\"true positive (tp) is similar\")", "machine learning +(\"just as true positive (tp)\")", "machine learning +(\"true positive (tp) can be thought of as\")", "machine learning +(\"true positive (tp) can be compared to\")"]}