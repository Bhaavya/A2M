{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Feature</b> Selection Techniques in <b>Machine</b> <b>Learning</b> - <b>GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/feature-selection-techniques-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>feature</b>-selection-techniques-in-<b>machine</b>-<b>learning</b>", "snippet": "Even the saying \u201cSometimes less is better\u201d goes as well for the <b>machine</b> <b>learning</b> model. Hence, <b>feature</b> selection is one of the important steps while building <b>a machine</b> <b>learning</b> model. Its goal is to find the best possible set of features for building <b>a machine</b> <b>learning</b> model. Some popular techniques of <b>feature</b> selection in <b>machine</b> <b>learning</b> are: <b>Filter</b> methods; Wrapper methods; Embedded methods. <b>Filter</b> Methods. These methods are generally used while doing the pre-processing step. These ...", "dateLastCrawled": "2022-01-30T23:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Feature Selection</b>: <b>Filter</b> Methods | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/feature-selection-73bc12a9b39e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>feature-selection</b>-73bc12a9b39e", "snippet": "<b>Filter</b> Methods. A subset of features is selected based on their relationship to the target variable. The selection is not dependent of any <b>machine</b> <b>learning</b> algorithm. On the contrary, <b>filter</b> ...", "dateLastCrawled": "2022-01-26T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "11. <b>Feature Engineering For Machine Learning</b> | Data Science Beginners", "url": "https://datasciencebeginners.com/2018/11/26/11-feature-engineering-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://datasciencebeginners.com/2018/11/26/11-<b>feature-engineering-for-machine-learning</b>", "snippet": "<b>Filter</b> Methods. These methods mostly involve univariate analysis by considering one variable at a time or a bivariate analysis with regards to the dependent variable. For example \u2013 Using the correlation score, hypothesis testing and information gain are some of the methods which fall under the group of <b>filter</b> methods. Wrapper Methods. These methods are very popular but can be time-consuming. These methods work on the phenomena of adding and removing variables based upon their contribution ...", "dateLastCrawled": "2022-01-11T04:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Feature</b> Selection Techniques in <b>Machine</b> <b>Learning</b> - Javatpoint", "url": "https://www.javatpoint.com/feature-selection-techniques-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>feature</b>-selection-techniques-in-<b>machine</b>-<b>learning</b>", "snippet": "<b>Feature</b> Selection Techniques in <b>Machine</b> <b>Learning</b> <b>Feature</b> selection is a way of selecting the subset of the most relevant features from the original features set by removing the redundant, irrelevant, or noisy features. While developing the <b>machine</b> <b>learning</b> model, only a few variables in the dataset are useful for building the model, and the rest features are either redundant or irrelevant. If we input the dataset with all these redundant and irrelevant features, it may negatively impact and ...", "dateLastCrawled": "2022-01-28T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Choose a <b>Feature Selection</b> Method For <b>Machine</b> <b>Learning</b>", "url": "https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>feature-selection</b>-with-real-and-categorical-data", "snippet": "<b>Feature selection</b> is the process of reducing the number of input variables when developing a predictive model. It is desirable to reduce the number of input variables to both reduce the computational cost of modeling and, in some cases, to improve the performance of the model. Statistical-based <b>feature selection</b> methods involve evaluating the relationship between each input variable and the target variable", "dateLastCrawled": "2022-02-02T18:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Basic <b>Feature</b> Engineering to Reach More Efficient <b>Machine Learning</b> | by ...", "url": "https://towardsdatascience.com/basic-feature-engineering-to-reach-more-efficient-machine-learning-6294022e17a5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/basic-<b>feature</b>-engineering-to-reach-more-efficient...", "snippet": "If I ask you a question <b>like</b> does <b>machine learning</b> difficult, you might obviously say yes. But machi ... There are two types of string data as categorical data and <b>continuous</b> data. Categorical Features. Categorical data/ features are variables that have a finite number of labels or categories. Based on nature, categorical data can be classified into ordinal data and nominal data. An attribute is an ordinal attribute when there is a natural ordering of values. For example, the <b>feature</b> ...", "dateLastCrawled": "2022-02-02T16:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A guide for using <b>the Wavelet Transform in Machine Learning</b> \u2013 ML ...", "url": "https://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://ataspinar.com/.../21/a-guide-for-using-<b>the-wavelet-transform-in-machine-learning</b>", "snippet": "2.4 <b>Continuous</b> Wavelet Transform vs Discrete Wavelet Transform; 2.5 More on the Discrete Wavelet Transform: The DWT as a <b>filter</b>-bank. Practical Applications 3.1 Visualizing the State-Space using the <b>Continuous</b> Wavelet Transform; 3.2 Using the <b>Continuous</b> Wavelet Transform and a Convolutional Neural Network to classify signals 3.2.1 Loading the UCI-HAR time-series dataset; 3.2.2 Applying the CWT on the dataset and transforming the data to the right format; 3.2.3 Training the Convolutional ...", "dateLastCrawled": "2022-01-30T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Guide to Encoding <b>Categorical</b> Features Using Scikit-Learn For <b>Machine</b> ...", "url": "https://towardsdatascience.com/guide-to-encoding-categorical-features-using-scikit-learn-for-machine-learning-5048997a5c79", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/guide-to-encoding-<b>categorical</b>-<b>features</b>-using-scikit...", "snippet": "One of the most crucial preprocessing steps in any <b>machine</b> <b>learning</b> project is <b>feature</b> encoding. <b>Feature</b> encoding is the process of turning <b>categorical</b> data in a dataset into numerical data. It is essential that we perform <b>feature</b> encoding because most <b>machine</b> <b>learning</b> models can only interpret numerical data and not data in text form. In this article, we will learn: The difference between a nominal variable and an ordinal variable; How OneHotEncoder and OrdinalEncoder can be used to encode ...", "dateLastCrawled": "2022-02-03T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - <b>Publicly Available Spam Filter Training Set</b> - Stack ...", "url": "https://stackoverflow.com/questions/4743996/publicly-available-spam-filter-training-set", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/4743996", "snippet": "each data point is labelled &#39;spam&#39; or &#39;no spam&#39;. approx. 40% are labeled spam. of the features, all are <b>continuous</b> (vs. discrete) a representative <b>feature</b>: average <b>continuous</b> sequence of capital letters. Spambase is archived in the UCI <b>Machine</b> <b>Learning</b> Repository; in addition, it&#39;s also available on the Website for the excellent ML/Statistical ...", "dateLastCrawled": "2022-01-12T04:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "40 Questions to test a <b>Data Scientist on Machine Learning</b> Flashcards ...", "url": "https://quizlet.com/300350513/40-questions-to-test-a-data-scientist-on-machine-learning-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/300350513/40-questions-to-test-a-data-scientist-on-<b>machine</b>...", "snippet": "Cross-validation is an important step in <b>machine</b> <b>learning</b> for hyper parameter tuning. Let&#39;s say you are tuning a hyper-parameter &quot;max_depth&quot; for GBM by selecting it from 10 different depth values (values are greater than 2) for tree based model using 5-fold cross validation.", "dateLastCrawled": "2022-01-15T03:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Alternative <b>Feature</b> Selection Methods in <b>Machine</b> <b>Learning</b> - KDnuggets", "url": "https://www.kdnuggets.com/2021/12/alternative-feature-selection-methods-machine-learning.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/.../alternative-<b>feature</b>-selection-methods-<b>machine</b>-<b>learning</b>.html", "snippet": "For every <b>continuous</b> <b>feature</b>, it sorts the values into discrete intervals finding the limits using the train set. It determines the mean target value per interval (using a training set). It sorts variables in the test set into the intervals identified in 2. It replaces intervals with corresponding target mean values (using the test set). It determines a performance metric between the encoded <b>feature</b> and the target (on the test set). It selects features whose performance is above a threshold ...", "dateLastCrawled": "2022-01-29T04:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Feature</b> Selection Techniques in <b>Machine</b> <b>Learning</b> - <b>GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/feature-selection-techniques-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>feature</b>-selection-techniques-in-<b>machine</b>-<b>learning</b>", "snippet": "Even the saying \u201cSometimes less is better\u201d goes as well for the <b>machine</b> <b>learning</b> model. Hence, <b>feature</b> selection is one of the important steps while building a <b>machine</b> <b>learning</b> model. Its goal is to find the best possible set of features for building a <b>machine</b> <b>learning</b> model. Some popular techniques of <b>feature</b> selection in <b>machine</b> <b>learning</b> are: <b>Filter</b> methods; Wrapper methods; Embedded methods. <b>Filter</b> Methods. These methods are generally used while doing the pre-processing step. These ...", "dateLastCrawled": "2022-01-30T23:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Feature</b> Selection Techniques in <b>Machine</b> <b>Learning</b> - Javatpoint", "url": "https://www.javatpoint.com/feature-selection-techniques-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>feature</b>-selection-techniques-in-<b>machine</b>-<b>learning</b>", "snippet": "<b>Feature</b> Selection Techniques in <b>Machine</b> <b>Learning</b> <b>Feature</b> selection is a way of selecting the subset of the most relevant features from the original features set by removing the redundant, irrelevant, or noisy features. While developing the <b>machine</b> <b>learning</b> model, only a few variables in the dataset are useful for building the model, and the rest features are either redundant or irrelevant. If we input the dataset with all these redundant and irrelevant features, it may negatively impact and ...", "dateLastCrawled": "2022-01-28T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Study Notes on <b>Machine</b> <b>Learning</b> Pipeline \u2013 <b>Feature</b> Engineering, <b>Feature</b> ...", "url": "https://analyticsindiamag.com/study-notes-on-machine-learning-pipeline-feature-engineering-feature-selection-and-hyper-parameters-optimization/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/study-notes-on-<b>machine</b>-<b>learning</b>-pipeline-<b>feature</b>...", "snippet": "<b>Feature</b> selection is the process of selecting a subset of relevant features for use in <b>machine</b> <b>learning</b> model building. The following topics are covered in this section: <b>Filter</b> method ; Wrapper Method; Embedded Method; <b>Filter</b> Method ; <b>Filter</b> methods rely on the characteristics of data and are model agnostic. They tend to be less computationally ...", "dateLastCrawled": "2022-02-02T23:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Sigmis: A <b>Feature Selection</b> Algorithm Using Correlation Based Method", "url": "https://journals.sagepub.com/doi/pdf/10.1260/1748-3018.6.3.385", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/pdf/10.1260/1748-3018.6.3.385", "snippet": "<b>Feature Selection</b> is one of the preprocessing steps in <b>machine</b> <b>learning</b> tasks. <b>Feature Selection</b> is effective in reducing the dimensionality, removing irrelevant and redundant <b>feature</b>. In this paper, we propose a new <b>feature selection</b> algorithm (Sigmis) based on Correlation method for handling the <b>continuous</b> features and the missing data. Empirical comparison with three existing <b>feature selection</b> algorithms using UCI data sets shows that the proposed system is very effective and efficient in ...", "dateLastCrawled": "2022-01-30T05:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Beyond Correlation Filters: Learning Continuous</b> Convolution Operators ...", "url": "https://link.springer.com/chapter/10.1007/978-3-319-46454-1_29", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-319-46454-1_29", "snippet": "<b>Similar</b> to the periodic assumption in the conventional discrete DCF formulation, a ... (f^d \\in L^{2}(T)\\) is the <b>continuous</b> <b>filter</b> for <b>feature</b> channel d. We define the convolution operator as, $$\\begin{aligned} S_f\\{x\\} = \\sum _{d=1}^D f^d *J_d \\big \\{x^d\\big \\} \\,,\\quad x \\in \\mathcal {X} \\,. \\end{aligned}$$ (3) Here, each <b>feature</b> channel is first interpolated using and then convolved with its corresponding <b>filter</b>. Note that the convolutions are performed in the <b>continuous</b> domain, as ...", "dateLastCrawled": "2022-02-01T12:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Feature Selection in Python</b> Sklearn - DataCamp", "url": "https://www.datacamp.com/community/tutorials/feature-selection-python", "isFamilyFriendly": true, "displayUrl": "https://www.datacamp.com/community/tutorials/<b>feature</b>-selection-python", "snippet": "<b>Filter</b> methods do not incorporate a <b>machine</b> <b>learning</b> model in order to determine if a <b>feature</b> is good or bad whereas wrapper methods use a <b>machine</b> <b>learning</b> model and train it the <b>feature</b> to decide if it is essential or not. <b>Filter</b> methods are much faster compared to wrapper methods as they do not involve training the models. On the other hand ...", "dateLastCrawled": "2022-02-03T02:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Continuous</b> Numeric Data. Strategies for working with <b>continuous</b>\u2026 | by ...", "url": "https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-<b>feature-engineering</b>-part-1-<b>continuous</b>...", "snippet": "\u2018Applied <b>machine</b> <b>learning</b>\u2019 is basically <b>feature engineering</b>.\u201d \u2014 Prof. Andrew Ng. This basically reinforces what we mentioned earlier about data scientists spending close to 80% of their time in engineering features which is a difficult and time-consuming process, requiring both domain knowledge and mathematical computations. \u201c<b>Feature engineering</b> is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in ...", "dateLastCrawled": "2022-01-30T07:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>A Few Useful</b> Things to Know <b>About Machine Learning</b> | October 2012 ...", "url": "https://cacm.acm.org/magazines/2012/10/155531-a-few-useful-things-to-know-about-machine-learning/fulltext", "isFamilyFriendly": true, "displayUrl": "https://cacm.acm.org/magazines/2012/10/155531-<b>a-few-useful</b>-things-to-know-about-<b>machine</b>...", "snippet": "In fact, very general assumptionslike smoothness, <b>similar</b> examples having <b>similar</b> classes, limited dependences, or limited complexityare often enough to do very well, and this is a large part of why <b>machine</b> <b>learning</b> has been so successful. Like deduction, induction (what learners do) is a knowledge lever: it turns a small amount of input knowledge into a large amount of output knowledge. Induction is a vastly more powerful lever than deduction, requiring much less input knowledge to produce ...", "dateLastCrawled": "2022-02-02T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "3 Section 2 - <b>Machine</b> <b>Learning</b> Basics Overview | Data Science <b>Machine</b> ...", "url": "https://1965eric.github.io/Machine_Learning/section-2-machine-learning-basics-overview.html", "isFamilyFriendly": true, "displayUrl": "https://1965eric.github.io/<b>Machine</b>_<b>Learning</b>/section-2-<b>machine</b>-<b>learning</b>-basics-overview...", "snippet": "3.1 Caret package, training and test sets, and overall accuracy. There is a link to the relevant sections of the textbook: Training and test sets and Overall accuracy Key points. Note: the set.seed() function is used to obtain reproducible results. If you have R 3.6 or later, please use the sample.kind = &quot;Rounding&quot; argument whenever you set the seed for this course.; To mimic the ultimate evaluation process, we randomly split our data into two \u2014 a training set and a test set \u2014 and act as ...", "dateLastCrawled": "2022-01-31T13:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to <b>Machine</b> <b>Learning</b>, Neural Networks, and Deep <b>Learning</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7347027/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7347027", "snippet": "Semisupervised <b>learning</b> <b>can</b> <b>be thought</b> of as the \u201chappy medium\u201d between supervised and unsupervised <b>learning</b> and is particularly useful for datasets that contain both labeled and unlabeled data (i.e., all features are present, but not all features have associated targets).10 This situation typically arises when labeling images become time-intensive or cost-prohibitive. Semisupervised <b>learning</b> is often used for medical images, where a physician might label a small subset of images and use ...", "dateLastCrawled": "2022-02-02T05:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Continuous</b> Numeric Data. Strategies for working with <b>continuous</b>\u2026 | by ...", "url": "https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-<b>feature-engineering</b>-part-1-<b>continuous</b>...", "snippet": "Even though numeric data <b>can</b> be directly fed into <b>machine</b> <b>learning</b> models, you would still need to engineer features which are relevant to the scenario, problem and domain before building a model. Hence the need for <b>feature engineering</b> still remains. Let\u2019s leverage python and look at some strategies for <b>feature engineering</b> on numeric data. We load up the following necessary dependencies first (typically in a Jupyter notebook). import pandas as pd import matplotlib.pyplot as plt import ...", "dateLastCrawled": "2022-01-30T07:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Feature</b> Selection For <b>Machine Learning</b> in Python", "url": "https://machinelearningmastery.com/feature-selection-machine-learning-python/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>feature</b>-selection-<b>machine-learning</b>-python", "snippet": "The data features that you use to train your <b>machine learning</b> models have a huge influence on the performance you <b>can</b> achieve. Irrelevant or partially relevant features <b>can</b> negatively impact model performance. In this post you will discover automatic <b>feature</b> selection techniques that you <b>can</b> use to prepare your <b>machine learning</b> data in python with scikit-learn. Let&#39;s get started. Update Dec/2016: Fixed a", "dateLastCrawled": "2022-02-02T05:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Introduction to Artificial Intelligence &amp; <b>Machine</b> <b>Learning</b>", "url": "https://www.rebellionresearch.com/introduction-to-artificial-intelligence-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.rebellionresearch.com/introduction-to-artificial-intelligence-<b>machine</b>-<b>learning</b>", "snippet": "<b>Machine</b> <b>Learning</b> : Introduction to Artificial Intelligence &amp; <b>Machine</b> <b>Learning</b>. <b>Machine</b> <b>Learning</b> is a subdivision of AI. Which focuses on constructing machines that <b>can</b> improve upon themselves with only initial human intervention. As explained by Google at their \u201c<b>Machine</b> <b>Learning</b> 101\u201d event.", "dateLastCrawled": "2022-02-02T18:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "3 Section 2 - <b>Machine</b> <b>Learning</b> Basics Overview | Data Science <b>Machine</b> ...", "url": "https://1965eric.github.io/Machine_Learning/section-2-machine-learning-basics-overview.html", "isFamilyFriendly": true, "displayUrl": "https://1965eric.github.io/<b>Machine</b>_<b>Learning</b>/section-2-<b>machine</b>-<b>learning</b>-basics-overview...", "snippet": "3 Section 2 - <b>Machine</b> <b>Learning</b> Basics Overview. In the <b>Machine</b> <b>Learning</b> Basics section, you will learn the basics of <b>machine</b> <b>learning</b>.. After completing this section, you will be able to: Start to use the caret package.; Construct and interpret a confusion matrix.; Use conditional probabilities in the context of <b>machine</b> <b>learning</b>.; This section has two parts: basics of evaluating <b>machine</b> <b>learning</b> algorithms and conditional probabilities.", "dateLastCrawled": "2022-01-31T13:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Continuous motion recognition</b> - Edge Impulse Docs", "url": "https://docs.edgeimpulse.com/docs/continuous-motion-recognition", "isFamilyFriendly": true, "displayUrl": "https://docs.edgeimpulse.com/docs/<b>continuous-motion-recognition</b>", "snippet": "<b>Continuous motion recognition</b>. In this tutorial, you&#39;ll use <b>machine</b> <b>learning</b> to build a gesture recognition system that runs on a microcontroller. This is a hard task to solve using rule based programming, as people don&#39;t perform gestures in the exact same way every time. But <b>machine</b> <b>learning</b> <b>can</b> handle these variations with ease.", "dateLastCrawled": "2022-01-30T11:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "9 Real-World Problems that <b>can</b> be <b>Solved by Machine Learning</b>", "url": "https://marutitech.com/problems-solved-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://marutitech.com/problems-solve", "snippet": "If the data <b>can</b> be stored digitally, it <b>can</b> be fed into a <b>machine-learning</b> algorithm to solve specific problems. Types Of <b>Machine Learning</b>. Today, <b>Machine Learning</b> algorithms are primarily trained using three essential methods. These are categorized as three types of <b>machine learning</b>, as discussed below \u2013 1. Supervised <b>Learning</b>", "dateLastCrawled": "2022-02-03T01:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to apply <b>machine</b> <b>learning</b> and deep <b>learning</b> methods to audio ...", "url": "https://medium.com/comet-ml/applyingmachinelearningtoaudioanalysis-utm-source-kdnuggets11-19-e160b069e88", "isFamilyFriendly": true, "displayUrl": "https://<b>medium</b>.com/comet-ml/applying<b>machinelearning</b>toaudioanalysis-utm-source-kd...", "snippet": "Dataset preprocessing, <b>feature</b> extraction and <b>feature</b> engineering are steps we take to extract information from the underlying data, information that in a <b>machine</b> <b>learning</b> context should be useful ...", "dateLastCrawled": "2022-01-15T01:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A guide for using <b>the Wavelet Transform in Machine Learning</b> \u2013 ML ...", "url": "https://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://ataspinar.com/.../21/a-guide-for-using-<b>the-wavelet-transform-in-machine-learning</b>", "snippet": "The values of the scaling and translation factors are <b>continuous</b>, which means that there <b>can</b> be an infinite amount of wavelets. You <b>can</b> scale the mother wavelet with a factor of 1.3, or 1.31, and 1.311, and 1.3111 etc. When we are talking about the Discrete Wavelet Transform, the main difference is that the DWT uses discrete values for the scale and translation factor. The scale factor increases in powers of two, so and the translation factor increases integer values ( ). PS: The DWT is only ...", "dateLastCrawled": "2022-01-30T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Image Classification</b> using <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> | by ...", "url": "https://medium.com/swlh/image-classification-using-machine-learning-and-deep-learning-2b18bfe4693f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>image-classification</b>-using-<b>machine</b>-<b>learning</b>-and-deep-<b>learning</b>...", "snippet": "3 Literature review of relevant <b>machine</b> <b>learning</b> techniques . Before going through different techniques that <b>can</b> be used for <b>image classification</b>. Let\u2019s have an idea about some of the challenges ...", "dateLastCrawled": "2022-02-03T01:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Feature</b> Selection Techniques in <b>Machine</b> <b>Learning</b> - <b>GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/feature-selection-techniques-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/<b>feature</b>-selection-techniques-in-<b>machine</b>-<b>learning</b>", "snippet": "Even the saying \u201cSometimes less is better\u201d goes as well for the <b>machine</b> <b>learning</b> model. Hence, <b>feature</b> selection is one of the important steps while building a <b>machine</b> <b>learning</b> model. Its goal is to find the best possible set of features for building a <b>machine</b> <b>learning</b> model. Some popular techniques of <b>feature</b> selection in <b>machine</b> <b>learning</b> are: <b>Filter</b> methods; Wrapper methods; Embedded methods. <b>Filter</b> Methods. These methods are generally used while doing the pre-processing step. These ...", "dateLastCrawled": "2022-01-30T23:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Feature Selection</b>: <b>Filter</b> Methods | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/feature-selection-73bc12a9b39e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>feature-selection</b>-73bc12a9b39e", "snippet": "<b>Filter</b> Methods. A subset of features is selected based on their relationship to the target variable. The selection is not dependent of any <b>machine</b> <b>learning</b> algorithm. On the contrary, <b>filter</b> ...", "dateLastCrawled": "2022-01-26T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Feature</b> Selection Techniques in <b>Machine</b> <b>Learning</b> - Javatpoint", "url": "https://www.javatpoint.com/feature-selection-techniques-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>feature</b>-selection-techniques-in-<b>machine</b>-<b>learning</b>", "snippet": "<b>Feature</b> Selection Techniques in <b>Machine</b> <b>Learning</b> <b>Feature</b> selection is a way of selecting the subset of the most relevant features from the original features set by removing the redundant, irrelevant, or noisy features. While developing the <b>machine</b> <b>learning</b> model, only a few variables in the dataset are useful for building the model, and the rest features are either redundant or irrelevant. If we input the dataset with all these redundant and irrelevant features, it may negatively impact and ...", "dateLastCrawled": "2022-01-28T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>filter</b> approach for <b>feature selection in classification: application</b> ...", "url": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01427-8", "isFamilyFriendly": true, "displayUrl": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01427-8", "snippet": "In supervised <b>learning</b> (and especially in classification), the relevance of a <b>feature</b> is often assessed by quantifying its correlation with or dependence on a target <b>feature</b> Y, or by using consistency and separability indices or information theory-based metrics . The <b>feature</b> selection method tries to find the best combination of features according to an evaluation function that quantifies the relevance of all features. Evaluation functions <b>can</b> be divided into five categories", "dateLastCrawled": "2022-01-19T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "11. <b>Feature Engineering For Machine Learning</b> | Data Science Beginners", "url": "https://datasciencebeginners.com/2018/11/26/11-feature-engineering-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://datasciencebeginners.com/2018/11/26/11-<b>feature-engineering-for-machine-learning</b>", "snippet": "<b>Filter</b> Methods. These methods mostly involve univariate analysis by considering one variable at a time or a bivariate analysis with regards to the dependent variable. For example \u2013 Using the correlation score, hypothesis testing and information gain are some of the methods which fall under the group of <b>filter</b> methods. Wrapper Methods. These methods are very popular but <b>can</b> be time-consuming. These methods work on the phenomena of adding and removing variables based upon their contribution ...", "dateLastCrawled": "2022-01-11T04:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to Choose a <b>Feature Selection</b> Method For <b>Machine</b> <b>Learning</b>", "url": "https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>feature-selection</b>-with-real-and-categorical-data", "snippet": "<b>Feature selection</b> is the process of reducing the number of input variables when developing a predictive model. It is desirable to reduce the number of input variables to both reduce the computational cost of modeling and, in some cases, to improve the performance of the model. Statistical-based <b>feature selection</b> methods involve evaluating the relationship between each input variable and the target variable", "dateLastCrawled": "2022-02-02T18:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "SchNet: A <b>continuous</b>-<b>filter</b> <b>convolutional neural network for modeling</b> ...", "url": "https://proceedings.neurips.cc/paper/2017/file/303ed4c69846ab36c2904d3ba8573050-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2017/file/303ed4c69846ab36c2904d3ba8573050-Paper.pdf", "snippet": "SchNet: A <b>continuous</b>-\ufb01lter <b>convolutional neural network for modeling quantum interactions</b> K. T. Sch\u00fctt 1, P.-J. Kindermans , H. E. Sauceda2, S. Chmiela A. Tkatchenko3, K.-R. M\u00fcller1 ;4 5y 1 <b>Machine</b> <b>Learning</b> Group, Technische Universit\u00e4t Berlin, Germany 2 Theory Department, Fritz-Haber-Institut der Max-Planck-Gesellschaft, Berlin, Germany 3 Physics and Materials Science Research Unit, University of Luxembourg, Luxembourg 4 Max-Planck-Institut f\u00fcr Informatik, Saarbr\u00fccken, Germany 5 Dept ...", "dateLastCrawled": "2022-02-03T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "40 Questions to test a <b>Data Scientist on Machine Learning</b> Flashcards ...", "url": "https://quizlet.com/300350513/40-questions-to-test-a-data-scientist-on-machine-learning-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/300350513/40-questions-to-test-a-data-scientist-on-<b>machine</b>...", "snippet": "Cross-validation is an important step in <b>machine</b> <b>learning</b> for hyper parameter tuning. Let&#39;s say you are tuning a hyper-parameter &quot;max_depth&quot; for GBM by selecting it from 10 different depth values (values are greater than 2) for tree based model using 5-fold cross validation.", "dateLastCrawled": "2022-01-15T03:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Image Classification</b> using <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> | by ...", "url": "https://medium.com/swlh/image-classification-using-machine-learning-and-deep-learning-2b18bfe4693f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>image-classification</b>-using-<b>machine</b>-<b>learning</b>-and-deep-<b>learning</b>...", "snippet": "Although <b>machine</b> <b>learning</b> techniques like SVM didn\u2019t give us a good performance <b>compared</b> to a deep <b>learning</b> algorithm like Xception, it was a competitor to MLP in such a way that let us consider ...", "dateLastCrawled": "2022-02-03T01:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Choosing a <b>suitable Machine Learning algorithm - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/choosing-a-suitable-machine-learning-algorithm/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/choosing-a-suitable-<b>machine</b>-<b>learning</b>-algorithm", "snippet": "Linear Regression: It is essential in searching for the relationship between two <b>continuous</b> variables.One is an independent variable and other is the dependent variable. Logistic Regression: Logistic regression is one of the common methods to analyse the data and explain the relationship between one dependent binary variable and one or more independent variables of the nominal, ordinal, interval, or ratio level. KNN: KNN <b>can</b> be used for classification and regression predictive problems. K ...", "dateLastCrawled": "2022-02-02T15:13:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Types of Machine Learning</b> | Different Methods and Kinds of Model", "url": "https://www.educba.com/types-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>types-of-machine-learning</b>", "snippet": "Introduction to <b>Types of Machine Learning</b>. <b>Machine</b> <b>learning</b> is the subfield of AI that focuses on the development of the computer programs which have access to data by providing a system with the ability to learn and improve automatically. For example, finding patterns in the database without any human interventions or actions is based upon the ...", "dateLastCrawled": "2022-02-02T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Basic Introduction to <b>Machine</b> <b>Learning</b>: Types, Applications &amp; Examples ...", "url": "https://medium.com/@vishnuvijayanpv/basic-introduction-to-machine-learning-types-applications-examples-467a85a00ff5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@vishnuvijayanpv/basic-introduction-to-<b>machine</b>-<b>learning</b>-types...", "snippet": "<b>Machine</b> <b>Learning</b> is a large sub-field of AI dealing with the field of study that gives computers the ability to learn without being explicitly programmed. This means a single program, once created\u2026", "dateLastCrawled": "2022-02-03T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> Concepts for Revision | by Raunak Sarada | Medium", "url": "https://raunaksarada-cse21.medium.com/machine-learning-concepts-for-revision-491384952d27", "isFamilyFriendly": true, "displayUrl": "https://raunaksarada-cse21.medium.com/<b>machine</b>-<b>learning</b>-concepts-for-revision-491384952d27", "snippet": "ML Concepts. A.I \u2014 Intelligence showed by machines which is common for humans <b>Machine</b> <b>Learning</b>- Recognize the pattern in data and automatically learn and improve through experience without explicitly being programmed Deep <b>Learning</b>- branch of <b>machine</b> <b>learning</b>.We have to deal with lots of data so in that case problems can\u2019t be solved with simple ML algorithms.", "dateLastCrawled": "2022-01-25T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "What are the <b>basic concepts in machine learning</b>? I found that the best way to discover and get a handle on the <b>basic concepts in machine learning</b> is to review the introduction chapters to <b>machine learning</b> textbooks and to watch the videos from the first model in online courses. Pedro Domingos is a lecturer and professor on <b>machine learning</b> at the University of Washing and", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "<b>Machine Learning: Introduction and Unsupervised Learning</b> Chapter 18.1, 18.2, 18.8.1 and \u201cIntroduction to Statistical <b>Machine</b> <b>Learning</b>\u201d 1 What is <b>Learning</b>? \u2022\u201c<b>Learning</b> is making useful changes in our minds\u201d \u2013Marvin Minsky \u2022\u201c<b>Learning</b> is constructing or modifying representations of what is being experienced\u201c \u2013RyszardMichalski \u2022\u201c<b>Learning</b> denotes changes in a system that ... enable a system to do the same task more efficiently the next time\u201d \u2013Herbert Simon 3 Why do Mach", "dateLastCrawled": "2022-01-01T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Real-time <b>machine</b> <b>learning</b>: challenges and solutions", "url": "https://huyenchip.com/2022/01/02/real-time-machine-learning-challenges-and-solutions.html", "isFamilyFriendly": true, "displayUrl": "https://huyenchip.com/2022/01/02/real-time-<b>machine</b>-<b>learning</b>-challenges-and-solutions.html", "snippet": "Real-time <b>machine</b> <b>learning</b> is largely an infrastructure problem. Solving it will require the data science/ML team and the platform team to work together. Both online inference and continual <b>learning</b> require a mature streaming infrastructure. The training part of continual <b>learning</b> can be done in batch, but the online evaluation part requires streaming. Many engineers worry that streaming is hard and costly. It was true 3 years ago, but streaming technologies have matured significantly since ...", "dateLastCrawled": "2022-01-30T09:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Preliminary performance study of a brief review on <b>machine</b> <b>learning</b> ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "snippet": "<b>Analogy</b>-based effort estimation is the major task of software engineering which estimates the effort required for new software projects using existing histories for corresponding development and management. In general, the high accuracy of software effort estimation techniques can be a non-solvable problem we named as multi-objective problem. Recently, most of the authors have been used <b>machine</b> <b>learning</b> techniques for the same process however not possible to meet the higher performance ...", "dateLastCrawled": "2022-01-02T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "6 Modeling big data | Exploring, Visualizing, and Modeling Big Data with R", "url": "https://okanbulut.github.io/bigdata/modeling-big-data.html", "isFamilyFriendly": true, "displayUrl": "https://okanbulut.github.io/bigdata/modeling-big-data.html", "snippet": "Unsupervised <b>machine</b> <b>learning</b> is an approach to training ML in which the algorithm is given only input data, from which it identifies patterns on its own. The goal of unsupervised <b>learning</b> is for algorithms to identify underlying patterns or structures in data to better understand it. Unsupervised <b>learning</b> is closer to how humans learn most things in life: through observation, experience, and <b>analogy</b>. Unsupervised <b>learning</b> is best used for clustering problems \u2013 for example, grouping ...", "dateLastCrawled": "2022-02-02T18:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "11.2 <b>Universal Approximators</b> - GitHub Pages", "url": "https://jermwatt.github.io/machine_learning_refined/notes/11_Feature_learning/11_2_Universal.html", "isFamilyFriendly": true, "displayUrl": "https://jermwatt.github.io/<b>machine</b>_<b>learning</b>_refined/notes/11_<b>Feature</b>_<b>learning</b>/11_2...", "snippet": "* The following is part of an early draft of the second edition of <b>Machine</b> <b>Learning</b> Refined. The published text (with revised material) ... making the data appear as a <b>continuous</b> line (or hyperplane, in higher dimensions). In the bottom panels of Figure 11.3 we show a similar transition for a prototypical nonlinear regression dataset wherein the perfect data (shown in the right-most panel) carves out a <b>continuous</b> nonlinear curve (or surface, in higher dimensions). Figure: 11.3 (top left ...", "dateLastCrawled": "2022-02-03T14:44:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(continuous feature)  is like +(a machine learning filter)", "+(continuous feature) is similar to +(a machine learning filter)", "+(continuous feature) can be thought of as +(a machine learning filter)", "+(continuous feature) can be compared to +(a machine learning filter)", "machine learning +(continuous feature AND analogy)", "machine learning +(\"continuous feature is like\")", "machine learning +(\"continuous feature is similar\")", "machine learning +(\"just as continuous feature\")", "machine learning +(\"continuous feature can be thought of as\")", "machine learning +(\"continuous feature can be compared to\")"]}