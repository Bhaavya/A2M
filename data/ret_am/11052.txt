{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Continual Learning by Maximizing Transfer and Minimizing Interference</b>", "url": "https://mattriemer.files.wordpress.com/2018/12/continuallearningworkshop.pdf", "isFamilyFriendly": true, "displayUrl": "https://mattriemer.files.wordpress.com/2018/12/continual<b>learning</b>workshop.pdf", "snippet": "Our data is locally <b>i.i.d</b>. [2]: samples for a task are drawn from the ... NIPS 2017. I learned <b>a new</b> <b>skill</b>! I learned <b>a new</b> <b>skill</b>! Aargh I forgot it all! Disclaimer Many relevant approaches to this setting and our work have been explored over the years (see our paper for more details)! I learned <b>a new</b> <b>skill</b>! Stability \u2013 Plasticity Dilemma Stability \u2013 Plasticity Dilemma A. Transfer \u2013 Interference Trade-o\ufb00 Transfer Old <b>Learning</b> Current <b>Learning</b> Future <b>Learning</b> Sharing Sharing B ...", "dateLastCrawled": "2021-11-22T12:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Broad and Practical Exposition of Online <b>Learning</b> Techniques | by ...", "url": "https://towardsdatascience.com/a-broad-and-practical-exposition-of-online-learning-techniques-a4cbc300dcd4", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-broad-and-practical-exposition-of-online-<b>learning</b>...", "snippet": "In the online <b>learning</b> community, the main issue that has been identified for training models in an online fashion over non-<b>i.i.d</b>. data streams is catastrophic forgetting [11, 12]. Catastrophic forgetting is a property of online <b>learning</b> models in which the model forgets how to classify previous data as it is exposed to <b>new</b> data. For example, consider a dataset with 10 classes (e.g., CIFAR10), and assume that the online <b>learning</b> model has already been trained on classes one and two. Then ...", "dateLastCrawled": "2022-01-06T15:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Relative Hidden Markov Models for Evaluating Motion <b>Skill</b>", "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zhang_Relative_Hidden_Markov_2013_CVPR_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zhang_Relative...", "snippet": "where X is the set of <b>i.i.d</b>. training sequences. One ef\ufb01cient solution to the above problem is the well-known Baum-Welch algorithm [2]. Another scheme, namely the segmental K-means algorithm [5], may also be used to seek a solution, and it has been shown that the <b>like</b>-lihoods under models estimated by either of the two algo-rithms are very ...", "dateLastCrawled": "2021-12-22T11:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Corticostriatal dynamics encode the refinement</b> of specific ... - <b>eLife</b>", "url": "https://elifesciences.org/articles/09423", "isFamilyFriendly": true, "displayUrl": "https://<b>elife</b>sciences.org/articles/09423", "snippet": "If the IPI in the sequences is drawn (<b>i.i.d</b>.) from a distribution with some fixed (\u03bc) mean, it follows that the distribution of the press rate in some duration has a related mean (1/\u03bc) but also, due to the central limit theorem, that the variance will decrease with the duration. Therefore, the authors need to find a controlled way to demonstrate that the behavior is indeed refined and not that the animals simply make longer pressing sequences and hit their targets by chance.", "dateLastCrawled": "2022-02-01T14:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "100+ Important MCQ on Flow of Control in Python - CS-IP-<b>Learning</b>-Hub", "url": "https://csiplearninghub.com/flow-of-control-in-python-mcq/", "isFamilyFriendly": true, "displayUrl": "https://csip<b>learning</b>hub.com/flow-of-control-in-python-mcq", "snippet": "c. i <b>i i. d</b>. i i Here i. Show Answer. Q95. Which of the following is an empty statement in python? a. Pass. b. Continue. c. Break . d. Exit ... Enter your email address to subscribe to this blog and receive notifications of <b>new</b> posts by email. Join 330 other subscribers Email Address . Subscribe . About me. I am a teacher with more than 17 years of experience in education field. You can contact me at csiplearninghub@gmail.com. <b>Like</b> For Update. Recently Added. Best Computer Network Notes ...", "dateLastCrawled": "2022-01-30T23:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning 10-601/10</b>-301", "url": "https://www.cs.cmu.edu/~mgormley/courses/10601/slides/lecture1-overview.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~mgormley/courses/10601/slides/lecture1-overview.pdf", "snippet": "<b>Learning</b> Objectives You should be able to\u2026 1. Formulate a well-posed <b>learning</b> problem for a real-world task by identifying the task, performance measure, and training experience 2.Describe common <b>learning</b> paradigms in terms of the type of data available, when it\u2019s available, the form of prediction, and the structure of the output prediction", "dateLastCrawled": "2022-01-30T01:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Transfer Learning</b> \u2014 part 1. Introduction | by Ilya Prokin | dataswati ...", "url": "https://medium.com/dataswati-garage/transfer-learning-part-1-c2f87de8df38", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dataswati-garage/<b>transfer-learning</b>-part-1-c2f87de8df38", "snippet": "Ben-David, Shai, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. 2010. \u201cA Theory of <b>Learning</b> from Different Domains.\u201d Machine <b>Learning</b> 79 (1\u20132): 151 ...", "dateLastCrawled": "2022-01-20T20:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "HIMANSHU GUPTA - Sales - Aditya Birla Capital | LinkedIn", "url": "https://in.linkedin.com/in/himanshu-gupta-21ba13104", "isFamilyFriendly": true, "displayUrl": "https://in.linkedin.com/in/himanshu-gupta-21ba13104", "snippet": "Keep <b>Learning</b> #mahindrarise Liked by HIMANSHU GUPTA. Join now to see all activity Experience Sales ... Decided to teach myself <b>a new</b> <b>skill</b> during this lockdown. In a time where #digitalmarketing is more crucial than ever before, I took up this course\u2026 Decided to teach myself <b>a new</b> <b>skill</b> during this lockdown. In a time where #digitalmarketing is more crucial than ever before, I took up this course\u2026 Liked by HIMANSHU GUPTA. <b>Like</b> all <b>New</b> Yorkers, PepsiCo lives and breathes the memories made ...", "dateLastCrawled": "2022-01-28T09:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Exploration</b> Strategies in Deep Reinforcement <b>Learning</b>", "url": "https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html", "isFamilyFriendly": true, "displayUrl": "https://lilianweng.github.io/lil-log/2020/06/07/<b>exploration</b>-strategies-in-deep...", "snippet": "Exploitation versus <b>exploration</b> is a critical topic in Reinforcement <b>Learning</b>. We\u2019d <b>like</b> the RL agent to find the best solution as fast as possible. However, in the meantime, committing to solutions too quickly without enough <b>exploration</b> sounds pretty bad, as it could lead to local minima or total failure. Modern RL algorithms that optimize for the best returns can achieve good exploitation quite efficiently, while <b>exploration</b> remains more <b>like</b> an open topic. I would <b>like</b> to discuss ...", "dateLastCrawled": "2022-01-27T16:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Talking points: If I could change one thing about myself, what would it ...", "url": "https://www.scmp.com/yp/discover/your-voice/opinion/article/3064289/talking-points-if-i-could-change-one-thing-about", "isFamilyFriendly": true, "displayUrl": "https://<b>www.scmp.com</b>/yp/discover/your-voice/opinion/article/3064289/talking-points-if...", "snippet": "I <b>like</b> getting up really late whenever I can, so I end up not utilising my morning fully. I also should spend more time studying or revising than I do at the moment. It takes me some time to get ...", "dateLastCrawled": "2022-01-30T22:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Broad and Practical Exposition of Online <b>Learning</b> Techniques | by ...", "url": "https://towardsdatascience.com/a-broad-and-practical-exposition-of-online-learning-techniques-a4cbc300dcd4", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-broad-and-practical-exposition-of-online-<b>learning</b>...", "snippet": "For example, two separate networks could be maintained, where one network is solely devoted <b>to learning</b> <b>new</b> data and the other tries to solve the overall <b>learning</b> problem (i.e., both old and <b>new</b> data) [12]. [35] proposes a <b>similar</b> approach that maintains two separate models: a probabilistic model for short-term memory and an autoencoder for long-term memory. Somewhat differently, highly-uncertain examples could be stored within a separate memory buffer that is later incorperated into the ...", "dateLastCrawled": "2022-01-06T15:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Corticostriatal dynamics encode the refinement</b> of specific ... - <b>eLife</b>", "url": "https://elifesciences.org/articles/09423", "isFamilyFriendly": true, "displayUrl": "https://<b>elife</b>sciences.org/articles/09423", "snippet": "If the IPI in the sequences is drawn (<b>i.i.d</b>.) from a distribution with some fixed (\u03bc) mean, it follows that the distribution of the press rate in some duration has a related mean (1/\u03bc) but also, due to the central limit theorem, that the variance will decrease with the duration. Therefore, the authors need to find a controlled way to demonstrate that the behavior is indeed refined and not that the animals simply make longer pressing sequences and hit their targets by chance.", "dateLastCrawled": "2022-02-01T14:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Stochastic\u2010Deep <b>Learning</b> Parameterization of Ocean Momentum Forcing ...", "url": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021MS002534", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021MS002534", "snippet": "where the are sampled according to <b>i.i.d</b>. standard normal distributions, and is the number of points of the low-resolution grid along the and axes respectively. The field is then interpolated back to the and grid for the and components, respectively, and used as the value of the subgrid momentum forcing in the shallow water model.", "dateLastCrawled": "2022-01-29T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "INTERPRETABLE CONTINUAL <b>LEARNING</b> - OpenReview", "url": "https://openreview.net/pdf?id=S1g9N2A5FX", "isFamilyFriendly": true, "displayUrl": "https://openreview.net/pdf?id=S1g9N2A5FX", "snippet": "Data belonging to different tasks might be non <b>i.i.d</b>. (Nguyen et al., 2018; Ring, 1997; Schmidhuber, 2013; Schlimmer &amp; Fisher, 1986; Sutton &amp; Whitehead, 1993). Crucially, a continual learner must be able to learn <b>a new</b> task without forgetting how to perform previous tasks (Ring, 1995; Schwarz et al., 2018). Continual <b>learning</b> frameworks need to continually adapt to the domain shift occurring across tasks, without revisiting data from previous tasks. An appropriate balance is required between ...", "dateLastCrawled": "2022-01-25T00:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Meta-<b>Learning</b>: from Few-<b>Shot Learning to Rapid Reinforcement Learning</b>", "url": "https://icml.cc/media/Slides/icml/2019/halla(10-09-15)-10-13-00-4340-meta-learning_.pdf", "isFamilyFriendly": true, "displayUrl": "https://icml.cc/media/Slides/icml/2019/halla(10-09-15)-10-13-00-4340-meta-<b>learning</b>_.pdf", "snippet": "<b>new</b> datapoints Training this network uses a meta-dataset, which itself consists of many datasets, each for a different task This view makes it easier to implement meta-<b>learning</b> algorithms Probabilistic view Extract prior information from a set of (meta-training) tasks that allows efficient <b>learning</b> of <b>new</b> tasks", "dateLastCrawled": "2022-01-29T15:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Transfer Learning</b> \u2014 part 1. Introduction | by Ilya Prokin | dataswati ...", "url": "https://medium.com/dataswati-garage/transfer-learning-part-1-c2f87de8df38", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dataswati-garage/<b>transfer-learning</b>-part-1-c2f87de8df38", "snippet": "Ben-David, Shai, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. 2010. \u201cA Theory of <b>Learning</b> from Different Domains.\u201d Machine <b>Learning</b> 79 (1\u20132): 151 ...", "dateLastCrawled": "2022-01-20T20:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Robust learning in expert networks: a comparative analysis</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10844-018-0515-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10844-018-0515-6", "snippet": "An extremely skilled expert but who \u2013 perhaps by virtue of her <b>skill</b> \u2013 gets too busy to answer would also require fallback options. Also, experts previously dismissed as weak can improve their <b>skill</b> level, a fact the referral <b>learning</b> algorithms will only be alerted to when using a balanced re-sampling and re-estimation approach. Many such considerations are often swept under the proverbial rug of Active <b>Learning</b> assumptions. In this article, we do take a closer look at these factors ...", "dateLastCrawled": "2021-12-10T01:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) SPEAKING PROBLEMS FACED BY THE ENGLISH DEPARTMENT STUDENTS OF ...", "url": "https://www.researchgate.net/publication/324195076_SPEAKING_PROBLEMS_FACED_BY_THE_ENGLISH_DEPARTMENT_STUDENTS_OF_SYIAH_KUALA_UNIVERSITY", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324195076_SPEAKING_PROBLEMS_FACED_BY_THE...", "snippet": "A <b>similar</b> study also investigated speaking obstacles faced by the students [8]. The study focused on the difficulties and affected factors faced by <b>English department students of Syiah Kuala</b> ...", "dateLastCrawled": "2022-02-03T07:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Exploration</b> Strategies in Deep Reinforcement <b>Learning</b>", "url": "https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html", "isFamilyFriendly": true, "displayUrl": "https://lilianweng.github.io/lil-log/2020/06/07/<b>exploration</b>-strategies-in-deep...", "snippet": "Fig. 14. Algorithm of DTSIL (Diverse Trajectory-conditioned Self-Imitation <b>Learning</b>). (Image source: Yijie Guo, et al. 2019) The <b>similar</b> approach is also seen in Guo, et al. (2019). The main idea is to store goals with high uncertainty in memory so that later the agent can revisit these goal states with a goal-conditioned policy repeatedly. In ...", "dateLastCrawled": "2022-01-27T16:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "K-12 <b>Module in TLE - ICT Grade 9 [All Gradings</b>]", "url": "https://www.slideshare.net/danielmanaog14/k12-module-in-tle-ict-grade-9-all-gradings", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/danielmanaog14/k12-<b>module-in-tle-ict-grade-9-all-gradings</b>", "snippet": "In addition, you introduce <b>new</b> ways of using the product, making it more useful and adaptable to the customers\u2019 many needs. When you are improving the product or enhancing it, you are doing an innovation. You can also do an invention by introducing an entirely <b>new</b> product to replace the old one. Business ideas may also be generated by examining what goods and services are sold outside by the community. Very often, these products are sold in a form that can still be enhanced or improved. 2 ...", "dateLastCrawled": "2022-02-02T08:34:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Anatomy of Learning-from-Exporting</b>", "url": "https://www.rieti.go.jp/jp/publications/dp/10e053.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.rieti.go.jp/jp/publications/dp/10e053.pdf", "snippet": "The essence of <b>learning</b>-from-exporting <b>can</b> <b>be thought</b> of as a process in which exporters absorb international knowledge spillovers and feed it back to their innovation efforts. <b>Learning</b>-from- exporting is often difficult to observe because it is conditional on at least two efforts: information gathering from foreign markets and zealous R&amp;D. We exploit unique survey data to explicitly analyze the contribution of these activities to exporters\u2019 innovation. We find that gathering information ...", "dateLastCrawled": "2022-02-02T15:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bayesian nonparametric learning of how skill</b> is distributed across the ...", "url": "https://www.sciencedirect.com/science/article/pii/S0304407621001147", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0304407621001147", "snippet": "According to the percentiles in Table 1, the probability of <b>a new</b>, or unknown fund, being extraordinarily skilled is higher than previously <b>thought</b> since the nonparametric population distribution\u2019s 99 th-percentile is an alpha of 11.48%, and the 99 th-percentile for the parametric distribution is only 4.87%. Our flexible, nonparametric, population distribution is also more fat-tailed, with a kurtosis of 101.49, and more skewed towards finding <b>skill</b> in the industry with a skewness of 4.31 ...", "dateLastCrawled": "2021-11-07T19:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Career Development Theories</b> - SlideShare", "url": "https://www.slideshare.net/Krishnanhr/career-development-theories", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/Krishnanhr/<b>career-development-theories</b>", "snippet": "<b>Learning</b> experiences, especially observational <b>learning</b> stemming from significant role models (e.g., parents, teachers, heroes), have a f f powerful influence on career decisions, making some occupations more attractive than others. Positive modeling, reward and reinforcement will likely lead to the development of appropriate career planning skills and career behavior.", "dateLastCrawled": "2022-01-28T23:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Independent And Dependent Clauses Exercises Pdf - Worksheet Student", "url": "https://worksheetstudent.com/independent-and-dependent-clauses-exercises-pdf/", "isFamilyFriendly": true, "displayUrl": "https://worksheetstudent.com/independent-and-dependent-clauses-exercises-pdf", "snippet": "Independent A clause that expresses a complete <b>thought</b> and <b>can</b> stand alone AKA A SENTENCE 4. Say a dependent clause after we eat dinner before we leave home when we go to the store. By using either highlighters or pens highlight or underline the dependent clause with one color and the independent clause with another in each sentence. Sandy likes to read mysteries because she wants to be a detective. A clause is part of the sentence. If only we finished our papers on time. In the following ...", "dateLastCrawled": "2022-02-03T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Time Series Forecasting as Supervised Learning</b>", "url": "https://machinelearningmastery.com/time-series-forecasting-supervised-learning/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/time-series-forecasting-su", "snippet": "It is called supervised <b>learning</b> because the process of an algorithm <b>learning</b> from the training dataset <b>can</b> <b>be thought</b> of as a teacher supervising the <b>learning</b> process. We know the correct answers; the algorithm iteratively makes predictions on the training data and is corrected by making updates. <b>Learning</b> stops when the algorithm achieves an acceptable level of performance. Supervised <b>learning</b> problems <b>can</b> be further grouped into regression and classification problems. Classification: A ...", "dateLastCrawled": "2022-02-02T19:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Frontiers | Assisting Movement Training and Execution With Visual and ...", "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2018.00024/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fnbot.2018.00024", "snippet": "In the absence of an instructor, errors in the execution of movements by a person trying to learn <b>a new</b> motor <b>skill</b>, such as calligraphy, for example, may go unnoticed. To counter this problem, we propose recording demonstrations of a motor <b>skill</b> provided by an instructor and processing them such that someone practicing that motor <b>skill</b> in the absence of the instructor <b>can</b> have the correctness of his/her trials automatically assessed and receive feedback based on the demonstrations.", "dateLastCrawled": "2022-02-03T13:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Exploration</b> Strategies in Deep Reinforcement <b>Learning</b>", "url": "https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html", "isFamilyFriendly": true, "displayUrl": "https://lilianweng.github.io/lil-log/2020/06/07/<b>exploration</b>-strategies-in-deep...", "snippet": "The following strategies could be used for better <b>exploration</b> in deep RL training when neural networks are used for function approximation: Entropy loss term: Add an entropy term H(\u03c0(a | s)) into the loss function, encouraging the policy to take diverse actions. Noise-based <b>Exploration</b>: Add noise into the observation, action or even parameter ...", "dateLastCrawled": "2022-01-27T16:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Optimizing Quantum Error Correction Codes with</b> Reinforcement <b>Learning</b>", "url": "https://quantum-journal.org/papers/q-2019-12-16-215/pdf/", "isFamilyFriendly": true, "displayUrl": "https://quantum-journal.org/papers/q-2019-12-16-215/pdf", "snippet": "ferent, physical setups. This transfer <b>learning</b> <b>skill</b> is both remarkable and extremely useful: Maintaining the option to switch from one scenario to another, we <b>can</b> train a <b>learning</b> algorithm on fast simulations with modeled environments before optimizing the QEC code under real conditions. Transfer <b>learning</b> thus o ers the ability to bootstrap the optimization of the actual quantum device via simulations. These simula-tions are comparably cheap since resources are much more limited under ...", "dateLastCrawled": "2022-01-29T16:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "#182: Making Better Decisions and Being Useful with Cassie Kozyrkov ...", "url": "https://analyticshour.io/2021/12/14/182-making-better-decisions-and-being-useful-with-cassie-kozyrkov/", "isFamilyFriendly": true, "displayUrl": "https://analyticshour.io/2021/12/14/182-making-better-decisions-and-being-useful-with...", "snippet": "Some would say that, given the breadth and depth of data that is available to businesses these days, a surefire path to business value is to load up a department with smart data scientists, task them with developing a solid machine <b>learning</b> strategy, and then execute that strategy. The people who\u2019ve said that might take issue with this episode. Cassie Kozyrkov joined the show to discuss decision making: what it is, how we often frame decisions too narrowly, and the different roles data <b>can</b> ...", "dateLastCrawled": "2022-01-29T14:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to <b>Remove Trends and Seasonality with a Difference Transform</b> in Python", "url": "https://machinelearningmastery.com/remove-trends-seasonality-difference-transform-python/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/remove-trends-seasonality-difference-transform-python", "snippet": "Time series datasets may contain trends and seasonality, which may need to be removed prior to modeling. Trends <b>can</b> result in a varying mean over time, whereas seasonality <b>can</b> result in a changing variance over time, both which define a time series as being non-stationary. Stationary datasets are those that have a stable mean and variance, and are in turn much", "dateLastCrawled": "2022-02-02T22:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Corticostriatal dynamics encode the refinement</b> of specific ... - <b>eLife</b>", "url": "https://elifesciences.org/articles/09423", "isFamilyFriendly": true, "displayUrl": "https://<b>elife</b>sciences.org/articles/09423", "snippet": "If the IPI in the sequences is drawn (<b>i.i.d</b>.) from a distribution with some fixed (\u03bc) mean, it follows that the distribution of the press rate in some duration has a related mean (1/\u03bc) but also, due to the central limit theorem, that the variance will decrease with the duration. Therefore, the authors need to find a controlled way to demonstrate that the behavior is indeed refined and not that the animals simply make longer pressing sequences and hit their targets by chance.", "dateLastCrawled": "2022-02-01T14:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Stochastic\u2010Deep <b>Learning</b> Parameterization of Ocean Momentum Forcing ...", "url": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021MS002534", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021MS002534", "snippet": "where the are sampled according to <b>i.i.d</b>. standard normal distributions, and is the number of points of the low-resolution grid along the and axes respectively. The field is then interpolated back to the and grid for the and components, respectively, and used as the value of the subgrid momentum forcing in the shallow water model.", "dateLastCrawled": "2022-01-29T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> by Doing vs. <b>Learning</b> About Match Quality: <b>Can</b> We Tell Them ...", "url": "https://academic.oup.com/restud/article-abstract/74/2/537/1576231", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/restud/article-abstract/74/2/537/1576231", "snippet": "One important source of match-specific capital is <b>learning</b> on the job, which <b>can</b> take on two distinct forms: <b>learning</b> by doing and <b>learning</b> about match quality. While these are conceptually distinct processes, distinguishing between them empirically has not been achieved in past work. This study does so by building on the insight that the two explanations have different implications for how firm-specific shocks affect the distribution of tenure among a firm&#39;s displaced workers. The ...", "dateLastCrawled": "2022-01-30T14:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Robust learning in expert networks: a comparative analysis</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10844-018-0515-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10844-018-0515-6", "snippet": "Human experts as well as autonomous agents in a referral network must decide whether to accept a task or refer to a more appropriate expert, and if so to whom. In order for the referral network to improve over time, the experts must learn to estimate the topical expertise of other experts. This article extends concepts from Multi-agent Reinforcement <b>Learning</b> and Active <b>Learning</b> to referral networks for distributed <b>learning</b> in referral networks. Among a wide array of algorithms evaluated ...", "dateLastCrawled": "2021-12-10T01:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Piecewise power laws in individual learning curves</b> | SpringerLink", "url": "https://link.springer.com/article/10.3758/s13423-015-0811-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.3758/s13423-015-0811-x", "snippet": "Here, we analyzed <b>a new</b> data set from human <b>learning</b> in cognitive tasks (Hardy, Farzin, &amp; Scanlon, 2013) that is much larger than the data sets previously used in <b>learning</b> curve analyses. Using <b>new</b> procedures for fitting and model selection, we demonstrate that shifts between PLs occur in individual <b>learning</b> curves, and we describe a global, two-process view of improvement on a task.", "dateLastCrawled": "2021-11-14T11:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Transfer Learning</b> \u2014 part 1. Introduction | by Ilya Prokin | dataswati ...", "url": "https://medium.com/dataswati-garage/transfer-learning-part-1-c2f87de8df38", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dataswati-garage/<b>transfer-learning</b>-part-1-c2f87de8df38", "snippet": "When enough data are available, one <b>can</b> simply retrain a model on the <b>new</b> data and discard old data altogether. This is not always possible. However, there is a way to improve. If it is known that ...", "dateLastCrawled": "2022-01-20T20:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Lifelong Machine Learning: Outlook and Direction</b>", "url": "https://www.researchgate.net/publication/330371588_Lifelong_Machine_Learning_Outlook_and_Direction", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330371588_<b>Lifelong_Machine_Learning_Outlook</b>...", "snippet": "<b>Skill</b> <b>learning</b> and retention is <b>a new</b> design proposed . by this paper an d should be added to the design of t he lifelong . <b>learning</b>. 9. ACKNOWLEDGMENTS . This research is sup ported by the Re ...", "dateLastCrawled": "2022-01-12T17:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) SPEAKING PROBLEMS FACED BY THE ENGLISH DEPARTMENT STUDENTS OF ...", "url": "https://www.researchgate.net/publication/324195076_SPEAKING_PROBLEMS_FACED_BY_THE_ENGLISH_DEPARTMENT_STUDENTS_OF_SYIAH_KUALA_UNIVERSITY", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324195076_SPEAKING_PROBLEMS_FACED_BY_THE...", "snippet": "Self-confidence is the main nonlinguistic factor that influences someone&#39;s speaking <b>skill</b>. On the other side, it is also the problem most commonly faced by people in speaking foreign language ...", "dateLastCrawled": "2022-02-03T07:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Exploration</b> Strategies in Deep Reinforcement <b>Learning</b>", "url": "https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html", "isFamilyFriendly": true, "displayUrl": "https://lilianweng.github.io/lil-log/2020/06/07/<b>exploration</b>-strategies-in-deep...", "snippet": "<b>A new</b> observation will <b>be compared</b> with existing state embeddings via \\(C\\) and the results are aggregated (e.g. max, 90th percentile) to provide a reachability score \\(C^M(\\phi(s_t))\\). The <b>exploration</b> bonus is \\(r^i_t = \\big(C&#39; - C^M(f(s_t))\\big)\\), where \\(C&#39;\\) is a predefined threshold for determining the sign of the reward (e.g. \\(C&#39;=0.5\\) works well for fixed-duration episodes). High bonus is awarded to <b>new</b> states when they are not easily reachable from states in the memory buffer.", "dateLastCrawled": "2022-01-27T16:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "RTI \u2018Tune-U\u2019 Up\u2019: Tiers 1, 2 &amp; 3 - RTI | RTI Resources", "url": "http://www.jimwrightonline.com/mixed_files/warwick/wright_RTI_Overview_WVCSD_17_Jan_2013_PPT.pdf", "isFamilyFriendly": true, "displayUrl": "www.jimwrightonline.com/mixed_files/warwick/wright_RTI_Overview_WVCSD_17_Jan_2013_PPT.pdf", "snippet": "Fl fi tFluency, a first-grad td t t th h l Cli de student <b>new</b> to the school, Colin, was found have moderate delays when <b>compared</b> to peers. In his school Colin fell below the 25school, Colin fell below the 25th percentile <b>compared</b> with peers (AIMSweb norms). According to the benchmark norms, a", "dateLastCrawled": "2021-12-16T03:14:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Learning</b>? <b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "<b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b> Chapter 18.1, 18.2, 18.8.1 and \u201cIntroduction to Statistical <b>Machine</b> <b>Learning</b>\u201d 1 What is <b>Learning</b>? \u2022\u201c<b>Learning</b> is making useful changes in our minds\u201d \u2013Marvin Minsky \u2022\u201c<b>Learning</b> is constructing or modifying representations of what is being experienced\u201c \u2013RyszardMichalski \u2022\u201c<b>Learning</b> denotes changes in a system that ... enable a system to do the same task more efficiently the next time\u201d \u2013Herbert Simon 3 Why do Mach", "dateLastCrawled": "2022-02-03T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~bgibson/cs540/handouts/learning_intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~bgibson/cs540/handouts/<b>learning</b>_intro.pdf", "snippet": "<b>learning</b> process \u2022x i = (x i1, . . . , x iD) \u2022Assume these instances are sampled independently from an unknown (population) distribution, P(x) \u2022We denote this by x i \u223c P(x), where <b>i.i.d</b>. stands for independent and identically distributed <b>i.i.d</b>. Training Sample \u2022A training sample is the \u201cexperience\u201d given to a <b>learning</b> algorithm", "dateLastCrawled": "2021-08-25T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "11._Intro_to_<b>Machine</b>_<b>Learning</b>.pdf - CMPSC 442 Artificial Intelligence ...", "url": "https://www.coursehero.com/file/121916721/11-Intro-to-Machine-Learningpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/121916721/11-Intro-to-<b>Machine</b>-<b>Learning</b>pdf", "snippet": "Outline Data-Driven Problem Solving Types of <b>Machine</b> <b>Learning</b> <b>I.I.D</b> Assumption and Generalization The Fundamental Tradeoff between Bias and Variance Bias and Variance Overfitting and Underfitting Regularization Hyperparameters, Three-fold split, Cross-Validation Example of Polynomial Regression 2. Minimum Spanning Tree A classical problem in algorithm design: Minimum Spanning Tree Input: A graph with cost for edges Output: A spanning tree with minimum cost Prim&#39;s algorithm, Kruskal&#39;s ...", "dateLastCrawled": "2022-01-15T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> for Drug <b>Discovery</b> in a Nutshell \u2014 Part I | by Stefan ...", "url": "https://medium.com/atomwise/machine-learning-for-drug-discovery-in-a-nutshell-part-i-24ae3f65c135", "isFamilyFriendly": true, "displayUrl": "https://medium.com/atomwise/<b>machine</b>-<b>learning</b>-for-drug-<b>discovery</b>-in-a-nutshell-part-i...", "snippet": "Classical <b>machine</b> <b>learning</b> literature spends little attention to this aspect. Most often, the underlying assumption is that training and test examples are drawn <b>i.i.d</b>. from the same distribution ...", "dateLastCrawled": "2022-01-26T14:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning for Market Microstructure and</b> High Frequency Trading", "url": "https://www.cis.upenn.edu/~mkearns/papers/KearnsNevmyvakaHFTRiskBooks.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cis.upenn.edu/~mkearns/papers/KearnsNevmyvakaHFTRiskBooks.pdf", "snippet": "<b>Machine</b> <b>learning</b> is a vibrant sub\ufb01eld of computer science that draws on models and methods from statistics, algorithms, computational complexity, arti\ufb01cial intelli- gence, control theory, and a variety of other disciplines. Its primary focus is on computationally and informationally ef\ufb01cient algorithms for inferring good predictive models from large data sets, and thus is a natural candidate for application to problems arising in HFT, both for trade execution and the generation of ...", "dateLastCrawled": "2022-02-01T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Shortcut <b>learning</b> in deep neural networks | Nature <b>Machine</b> Intelligence", "url": "https://www.nature.com/articles/s42256-020-00257-z", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42256-020-00257-z", "snippet": "In <b>analogy</b> to <b>machine</b> <b>learning</b>, we have a striking discrepancy between intended and actual <b>learning</b> outcome. Shortcut <b>learning</b> in education (surface <b>learning</b>) Alice loves history\u2014but at this ...", "dateLastCrawled": "2022-02-03T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Time Series Forecasting as Supervised Learning</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/time-series-forecasting-supervised-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/time-series-forecasting-su", "snippet": "Time series forecasting can be framed as a supervised <b>learning</b> problem. This re-framing of your time series data allows you access to the suite of standard linear and nonlinear <b>machine</b> <b>learning</b> algorithms on your problem. In this post, you will discover how you can re-frame your time series problem as a supervised <b>learning</b> problem for <b>machine</b> <b>learning</b>. After reading this post, you", "dateLastCrawled": "2022-02-02T19:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Overcoming Forgetting in Federated <b>Learning</b> on Non-<b>IID</b> Data - <b>NASA/ADS</b>", "url": "https://ui.adsabs.harvard.edu/abs/2019arXiv191007796S/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2019arXiv191007796S/abstract", "snippet": "We tackle the problem of Federated <b>Learning</b> in the non <b>i.i.d</b>. case, in which local models drift apart, inhibiting <b>learning</b>. Building on an <b>analogy</b> with Lifelong <b>Learning</b>, we adapt a solution for catastrophic forgetting to Federated <b>Learning</b>. We add a penalty term to the loss function, compelling all local models to converge to a shared optimum. We show that this can be done efficiently for communication (adding no further privacy risks), scaling with the number of nodes in the distributed ...", "dateLastCrawled": "2022-01-03T20:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - Can a model of P(Y|X) be trained via stochastic ...", "url": "https://stats.stackexchange.com/questions/34807/can-a-model-of-pyx-be-trained-via-stochastic-gradient-descent-from-non-i-i-d", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/34807", "snippet": "When training a parameterized model (e.g. to maximize likelihood) via stochastic gradient descent on some data set, it is commonly assumed that the training samples are drawn <b>i.i.d</b>. from the training", "dateLastCrawled": "2022-02-03T14:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[1910.07796] Overcoming Forgetting in <b>Federated Learning</b> on Non-<b>IID</b> Data", "url": "https://arxiv.org/abs/1910.07796", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1910.07796", "snippet": "We tackle the problem of <b>Federated Learning</b> in the non <b>i.i.d</b>. case, in which local models drift apart, inhibiting <b>learning</b>. Building on an <b>analogy</b> with Lifelong <b>Learning</b>, we adapt a solution for catastrophic forgetting to <b>Federated Learning</b>. We add a penalty term to the loss function, compelling all local models to converge to a shared optimum. We show that this can be done efficiently for communication (adding no further privacy risks), scaling with the number of nodes in the distributed ...", "dateLastCrawled": "2022-01-28T12:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Pearson\u2019s Correlation, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black-swans-in-your-market-neutral-portfolios-part-1-e17fc18a42a7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum ...", "dateLastCrawled": "2021-05-27T10:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Pearson\u2019s <b>Correlation</b>, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part-i-7521683a7317", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum-entropy problem , which aims at finding among all probability distributions that are consistent with observed empirical evidence, the one the is the most ignorant about everything else.", "dateLastCrawled": "2022-02-02T09:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(i.i.d.)  is like +(learning a new skill)", "+(i.i.d.) is similar to +(learning a new skill)", "+(i.i.d.) can be thought of as +(learning a new skill)", "+(i.i.d.) can be compared to +(learning a new skill)", "machine learning +(i.i.d. AND analogy)", "machine learning +(\"i.i.d. is like\")", "machine learning +(\"i.i.d. is similar\")", "machine learning +(\"just as i.i.d.\")", "machine learning +(\"i.i.d. can be thought of as\")", "machine learning +(\"i.i.d. can be compared to\")"]}