{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Unlabeled</b> <b>Example</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/unlabeled-example", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>unlabeled</b>-<b>example</b>", "snippet": "A hypothesis is induced from the <b>learning</b> set and used to label <b>a new</b> <b>example</b>. The newly labelled <b>example</b> is included in the <b>learning</b> set, and another, transduced hypothesis is induced. It is used to label the <b>new</b> <b>example</b> with the transduced label. The difference (distance) between induced and transduced labels (or probability distributions, if available) is evaluated as a quality estimation (or reliability of the original prediction). Different distance metrics can be used in classification ...", "dateLastCrawled": "2022-01-07T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Machine <b>Learning</b> with <b>Unlabeled</b> Training Data | iMerit", "url": "https://imerit.net/blog/machine-learning-with-unlabeled-training-data-all-pbm/", "isFamilyFriendly": true, "displayUrl": "https://imerit.net/blog/machine-<b>learning</b>-with-<b>unlabeled</b>-training-data-all-pbm", "snippet": "Post Machine <b>Learning</b> with <b>Unlabeled</b> Training Data. June 01, 2021. Machine <b>learning</b> relies on supervised <b>learning</b>, which uses labeled training data. However unsupervised <b>learning</b>, which uses <b>unlabeled</b> training data, can supplement supervised <b>learning</b>, and improve ML system performance.. Unsupervised <b>learning</b> uses <b>unlabeled</b> training samples to model basic characteristics of an ML system\u2019s input data.", "dateLastCrawled": "2022-01-28T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Positive and Unlabeled Learning</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2021/03/26/positive-and-unlabeled-learning/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/03/26/<b>positive-and-unlabeled-learning</b>", "snippet": "A <b>positive and unlabeled learning</b> problem is one where you want to make a binary classification model. In a regular binary classification problem you have training data that\u2019s labeled positive (class 1) and negative (class 0). But in a PUL problem you only have training data that labeled positive and <b>unlabeled</b> data. For <b>example</b>, suppose you have a dataset of people who have a disease (class 1) or don\u2019t have the disease (class 0). Your training data might look <b>like</b>:", "dateLastCrawled": "2022-01-17T14:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Positive and Unlabeled Learning (PUL) Using PyTorch</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2021/05/27/positive-and-unlabeled-learning-pul-using-pytorch/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/05/27/<b>positive-and-unlabeled-learning-pul</b>...", "snippet": "A <b>positive and unlabeled learning (PUL</b>) problem occurs when a machine <b>learning</b> set of training data has only a few positive labeled items and many <b>unlabeled</b> items. For <b>example</b>, suppose you want to train a machine <b>learning</b> model to predict if a hospital patient has a disease or not, based on predictor variables such as age, blood pressure, and so on. The training data might have a few dozen instances of items that are positive (class 1 = patient has disease) and many hundreds or thousands of ...", "dateLastCrawled": "2022-01-01T10:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Label <b>Unlabeled</b> Tweets. Unsupervised <b>Learning</b> | by Huda | Geek ...", "url": "https://medium.com/geekculture/how-to-label-unlabeled-tweets-fb701b97ebf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/how-to-label-<b>unlabeled</b>-tweets-fb701b97ebf", "snippet": "While <b>learning</b> data science, we mostly get a well-labeled dataset to build our models on. However, in a real-world scenario, seldom do we get good labeled datasets. Many data science problems ...", "dateLastCrawled": "2022-01-27T11:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>A new</b> dictionary-based <b>positive and unlabeled learning</b> method ...", "url": "https://link.springer.com/article/10.1007/s10489-021-02344-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10489-021-02344-z", "snippet": "<b>Positive and unlabeled learning</b> (PU <b>learning</b>) is designed to solve the problem that we only utilize the labeled positive examples and the <b>unlabeled</b> examples to train a classifier. A variety of methods have been proposed to solve this problem by incorporating <b>unlabeled</b> examples into <b>learning</b>. However, many methods treat the original features as input in the training stage and then build the classifier. In this paper, by use of two-step strategy, a novel method with dictionary <b>learning</b> is ...", "dateLastCrawled": "2022-01-24T21:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Top 10 Machine <b>Learning</b> Examples in Real Life", "url": "https://omdena.com/blog/machine-learning-examples/", "isFamilyFriendly": true, "displayUrl": "https://omdena.com/blog/machine-<b>learning</b>-<b>examples</b>", "snippet": "Semi-supervised <b>learning</b> uses a combination of a small amount of labeled data and a large amount of <b>unlabeled</b> data to train models. Here the approach involves supervised machine <b>learning</b> using labeled training data, and unsupervised <b>learning</b>, that uses <b>unlabeled</b> training data. Unsupervised <b>learning</b>. Image Source. The unsupervised <b>learning</b> approach is fantastic for uncovering relationships and insights in <b>unlabeled</b> datasets. Models feed input data with unknown desirable outcomes. So ...", "dateLastCrawled": "2022-01-31T13:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Positive and <b>Unlabeled</b> Materials Machine <b>Learning</b> | by Nathan C. Frey ...", "url": "https://towardsdatascience.com/positive-and-unlabeled-materials-machine-learning-8b216edea899", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/positive-and-<b>unlabeled</b>-materials-machine-<b>learning</b>-8b216...", "snippet": "In simple terms, with PU <b>learning</b> some <b>unlabeled</b> examples will randomly be labeled \u201cnegative.\u201d Then a machine <b>learning</b> model \u2014 a ... There are <b>example</b> Jupyter notebooks in the pumml repository for exploring more features, <b>like</b> building your own models using <b>new</b> data. What\u2019s Next? This is just the beginning and there\u2019s a lot to do. We looked at one family of 2D materials but there are many, many more out there. The Materials Project <b>example</b> shows how pumml can be used to predict the ...", "dateLastCrawled": "2022-02-03T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Active <b>Learning</b> by Acquiring Contrastive Examples", "url": "https://aclanthology.org/2021.emnlp-main.51.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.emnlp-main.51.pdf", "snippet": "trastive Active <b>Learning</b> (CAL) selects <b>unlabeled</b>. 651 data points from the pool, whose predictive <b>like</b>-lihoods diverge the most from their neighbors in the training set. This way, C AL shares similarities with diversity sampling, but instead of performing clustering it uses the feature space to create neigh-borhoods. CAL also leverages uncertainty, by using predictive likelihoods to rank the <b>unlabeled</b> data. We evaluate our approach in seven datasets from four tasks including sentiment ...", "dateLastCrawled": "2022-01-30T21:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "CLIP: Mining the treasure trove of <b>unlabeled</b> image data | by Fabian ...", "url": "https://medium.com/dida-machine-learning/clip-mining-the-treasure-trove-of-unlabeled-image-data-48d373d09dd5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dida-machine-<b>learning</b>/clip-mining-the-treasure-trove-of-<b>unlabeled</b>...", "snippet": "In the context of natural <b>language</b> processing tasks, it is already common to take advantage of the masses of (<b>unlabeled</b>!) textual data that is available in digitized form (e.g. Wikipedia articles ...", "dateLastCrawled": "2022-01-05T02:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Unlabeled</b> <b>Example</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/unlabeled-example", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>unlabeled</b>-<b>example</b>", "snippet": "Transduction <b>is similar</b> to instance-based <b>learning</b>, a family of algorithms that compares <b>new</b> problem instances with training instances\u2014K-means clustering is an <b>example</b> (Section 5.3). If some labels are available, transductive <b>learning</b> <b>is similar</b> to semisupervised <b>learning</b>. Yet, transduction is different from all the <b>learning</b> approaches mentioned thus far. Instance-based <b>learning</b> can be inductive, and semisupervised <b>learning</b> is inductive, whereas transductive <b>learning</b> avoids inductive ...", "dateLastCrawled": "2022-01-07T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Positive and Unlabeled Learning</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2021/03/26/positive-and-unlabeled-learning/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/03/26/<b>positive-and-unlabeled-learning</b>", "snippet": "A <b>positive and unlabeled learning</b> problem is one where you want to make a binary classification model. In a regular binary classification problem you have training data that\u2019s labeled positive (class 1) and negative (class 0). But in a PUL problem you only have training data that labeled positive and <b>unlabeled</b> data. For <b>example</b>, suppose you have a dataset of people who have a disease (class 1) or don\u2019t have the disease (class 0). Your training data might look like:", "dateLastCrawled": "2022-01-17T14:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to Label <b>Unlabeled</b> Tweets. Unsupervised <b>Learning</b> | by Huda | Geek ...", "url": "https://medium.com/geekculture/how-to-label-unlabeled-tweets-fb701b97ebf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/how-to-label-<b>unlabeled</b>-tweets-fb701b97ebf", "snippet": "A prime <b>example</b> of <b>unlabeled</b> data is the tweets! I\u2019ll try to unbundle this enigma of <b>unlabeled</b> data by analyzing all the tweets related to Electric Cars! Why Electric Cars? Electric cars are the ...", "dateLastCrawled": "2022-01-27T11:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Learning</b> an enriched representation from <b>unlabeled</b> data for protein ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3166043/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3166043", "snippet": "The experimental analysis shows that FCG can utilize well the sparse features which have little effect in supervised <b>learning</b>. The <b>new</b> features perform better in non-linear classifiers than linear ones. We combine the <b>new</b> features with local lexical features, obtaining an F-score of 63.5 on AIMED corpus, which is comparable with the current state-of-the-art results. We also find that simple Boolean lexical features derived only from local contexts are able to achieve competitive results ...", "dateLastCrawled": "2021-07-16T05:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning the language of proteins</b> - GitHub Pages", "url": "https://yangkky.github.io/2018/03/26/learning-the-language-of-proteins.html", "isFamilyFriendly": true, "displayUrl": "https://yangkky.github.io/2018/03/26/<b>learning-the-language-of-proteins</b>.html", "snippet": "<b>Learning the language of proteins</b>. Mar 26, 2018 Amino acids in a protein are analogous to letters in an alphabet, short subsequences of amino acids are analogous to words in an unknown <b>language</b>, and a protein\u2019s entire amino-acid sequence to a document encoding its structure and function. Therefore, I applied techniques from natural <b>language</b> processing to learn the <b>language</b> of proteins. Given a large collection of <b>unlabeled</b> texts, word2vec and doc2vec are well-established methods that learn ...", "dateLastCrawled": "2021-12-31T04:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning</b> to Classify Texts Using Positive and <b>Unlabeled</b> Data", "url": "https://www.cs.uic.edu/~liub/publications/ijcai03-textClass.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.uic.edu/~liub/publications/ijcai03-textClass.pdf", "snippet": "results show that the <b>new</b> method outperforms ex-isting methods significantly. 1 Introduction Text classification is an important problem and has been studied extensively in information retrieval and machine <b>learning</b>. To build a text classifier, the user first collects a set of training examples, which are labeled with pre-defined classes (labeling is often done manually). A classification algorithm is then applied to the training data to build a classifier. This approach to building ...", "dateLastCrawled": "2022-01-31T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Language</b> Model like Pre-Training for Acoustic Data | by Sundar V ...", "url": "https://towardsdatascience.com/language-model-like-pre-training-for-acoustic-data-f6057b3701ca", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>language</b>-model-like-pre-training-for-acoustic-data-f...", "snippet": "<b>Language</b> Model Pre-Training. Transfer <b>learning</b> is considerably popular these days, where a model trained for one task is re-purposed for another target task. In Computer Vision (CV), transfer <b>learning</b> is widespread; for <b>example</b>, it is prevalent to fine-tune a model pre-trained on ImageNet dataset for a target task to get reliable performance. But the problem here is it is hard to find ImageNet like massive labelled dataset for NLP or acoustic time-series data. To make use of the massive free ...", "dateLastCrawled": "2022-01-30T17:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Positive <b>Unlabeled</b> <b>Learning</b> for Deceptive Reviews Detection", "url": "https://aclanthology.org/D14-1055.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/D14-1055.pdf", "snippet": "Proceedings of the 2014 Conference on Empirical Methods in Natural <b>Language</b> Processing (EMNLP), pages 488\u2013498, October 25-29, 2014, Doha, Qatar. c 2014 Association for Computational Linguistics Positive <b>Unlabeled</b> <b>Learning</b> for Deceptive Reviews Detection Yafeng Ren Donghong Ji Hongbin Zhang Computer School Wuhan University Wuhan 430072, China frenyafeng,dhji,zhanghongbin g@whu.edu.cn Abstract Deceptive reviews detection has attract-ed signicant attention from both business and research ...", "dateLastCrawled": "2021-11-24T12:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "CLIP: Mining the treasure trove of <b>unlabeled</b> image data | by Fabian ...", "url": "https://medium.com/dida-machine-learning/clip-mining-the-treasure-trove-of-unlabeled-image-data-48d373d09dd5?source=post_internal_links---------5----------------------------", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dida-machine-<b>learning</b>/clip-mining-the-treasure-trove-of-<b>unlabeled</b>...", "snippet": "Zero-shot <b>learning</b> refers to the ability of a pretrained model to perform tasks it was not trained on without seeing any examples for the <b>new</b> tasks beforehand (seeing zero examples, hence the name).", "dateLastCrawled": "2021-11-28T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Positive and <b>Unlabeled</b> Materials Machine <b>Learning</b> | by Nathan C. Frey ...", "url": "https://towardsdatascience.com/positive-and-unlabeled-materials-machine-learning-8b216edea899", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/positive-and-<b>unlabeled</b>-materials-machine-<b>learning</b>-8b216...", "snippet": "Image by author. We calculated a bunch of properties for all the materials we were interested in, built and trained a positive and <b>unlabeled</b> machine <b>learning</b> model to recognize what is special about the synthesized materials, and then predicted which <b>new</b> materials should be synthesizable. Our model learned to use some information that we already know is a good indicator of synthesizability, like how much the atoms want to be bonded together.", "dateLastCrawled": "2022-02-03T00:08:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Positive and Unlabeled Learning</b> | James D. McCaffrey", "url": "https://jamesmccaffrey.wordpress.com/2021/03/26/positive-and-unlabeled-learning/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/03/26/<b>positive-and-unlabeled-learning</b>", "snippet": "A <b>positive and unlabeled learning</b> problem is one where you want to make a binary classification model. In a regular binary classification problem you have training data that\u2019s labeled positive (class 1) and negative (class 0). But in a PUL problem you only have training data that labeled positive and <b>unlabeled</b> data. For <b>example</b>, suppose you have a dataset of people who have a disease (class 1) or don\u2019t have the disease (class 0). Your training data might look like:", "dateLastCrawled": "2022-01-17T14:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Positive and <b>Unlabeled</b> <b>Learning</b>: How Complex is Too Complex? | James D ...", "url": "https://jamesmccaffrey.wordpress.com/2021/11/11/positive-and-unlabeled-learning-how-complex-is-too-complex/", "isFamilyFriendly": true, "displayUrl": "https://jamesmccaffrey.wordpress.com/2021/11/11/positive-and-<b>unlabeled</b>-<b>learning</b>-how...", "snippet": "The output of the system is a pair of probabilities for each <b>unlabeled</b> data item, for <b>example</b> [0.123, 0.877], where the first value is probability of class 0, and second value is probability of class 1. The system uses a delta threshold where only those items where the difference between the prob(0) and prob(1) is greater than the delta, are used to make predictions. For <b>example</b>, if the threshold is 0.50 then a result like [0.20, 0.80] is used (prediction is class 1) but a result like [0.45 ...", "dateLastCrawled": "2022-01-11T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is Data Labeling? | IBM", "url": "https://www.ibm.com/cloud/learn/data-labeling", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ibm.com</b>/cloud/learn/data-labeling", "snippet": "Labeled data is used in supervised <b>learning</b>, whereas <b>unlabeled</b> data is used in unsupervised <b>learning</b>. Labeled data is more difficult to acquire and store (i.e. time consuming and expensive), whereas <b>unlabeled</b> data is easier to acquire and store. Labeled data <b>can</b> be used to determine actionable insights (e.g. forecasting tasks), whereas <b>unlabeled</b> data is more limited in its usefulness. Unsupervised <b>learning</b> methods <b>can</b> help discover <b>new</b> clusters of data, allowing for <b>new</b> categorizations when ...", "dateLastCrawled": "2022-02-02T06:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is <b>Deep Learning</b> and How Does It Work?", "url": "https://www.techtarget.com/searchenterpriseai/definition/deep-learning-deep-neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.techtarget.com/searchenterpriseai/definition/<b>deep-learning</b>-deep-neural-network", "snippet": "At its simplest, <b>deep learning</b> <b>can</b> <b>be thought</b> of as a way to automate predictive analytics. ... This means, for <b>example</b>, a facial recognition model might make determinations about people&#39;s characteristics based on things like race or gender without the programmer being aware. The <b>learning</b> rate <b>can</b> also become a major challenge to <b>deep learning</b> models. If the rate is too high, then the model will converge too quickly, producing a less-than-optimal solution. If the rate is too low, then the ...", "dateLastCrawled": "2022-01-29T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Statistical Learning vs Machine Learning</b> | A Thorough Guide", "url": "https://onlinecoursescertifications.com/statistical-learning-vs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://onlinecoursescertifications.com/<b>statistical-learning-vs-machine-learning</b>", "snippet": "Statistical <b>learning</b> is often <b>thought</b> of as being a subcategory of machine <b>learning</b>. Typically, the <b>learning</b> process in machine <b>learning</b> goes as follows: Making observations of the phenomenon; Creating a model that represents this phenomenon; Making predictions based on this model; So, how do things differ in statistical modelling? Well, for starters, the <b>learning</b> process must be automated to allow the machine to absorb it and construct a statistical model. The statistical model&#39;s ...", "dateLastCrawled": "2022-02-02T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Can</b> someone help with <b>building sub-labels for unlabeled and labeled</b> ...", "url": "https://www.researchgate.net/post/Can-someone-help-with-building-sub-labels-for-unlabeled-and-labeled-documents", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/<b>Can</b>-someone-help-with-building-sub-labels-for...", "snippet": "Machine <b>learning</b> plays a key role in a wide range of applications such as data mining, natural <b>language</b> processing and expert systems. It provides a solution in all domains for further development ...", "dateLastCrawled": "2022-01-15T01:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "CLIP: Mining the treasure trove of <b>unlabeled</b> image data | by Fabian ...", "url": "https://medium.com/dida-machine-learning/clip-mining-the-treasure-trove-of-unlabeled-image-data-48d373d09dd5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dida-machine-<b>learning</b>/clip-mining-the-treasure-trove-of-<b>unlabeled</b>...", "snippet": "In the context of natural <b>language</b> processing tasks, it is already common to take advantage of the masses of (<b>unlabeled</b>!) textual data that is available in digitized form (e.g. Wikipedia articles ...", "dateLastCrawled": "2022-01-05T02:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How <b>words anchor categorization: conceptual flexibility with labeled</b> ...", "url": "https://www.cambridge.org/core/journals/language-and-cognition/article/how-words-anchor-categorization-conceptual-flexibility-with-labeled-and-unlabeled-categories/8A97991E4AA3FECA4DCF39EC97705C85", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/<b>language</b>-and-cognition/article/how-words...", "snippet": "How <b>words anchor categorization: conceptual flexibility with labeled</b> and <b>unlabeled</b> categories*\u2021 - Volume 7 Issue 2", "dateLastCrawled": "2022-01-25T04:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Data Mining MCQ</b> (Multiple Choice Questions) - Javatpoint", "url": "https://www.javatpoint.com/data-mining-mcq", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>data-mining-mcq</b>", "snippet": "Answer: d Explanation: Data cleaning is a kind of process that is applied to data set to remove the noise from the data (or noisy data), inconsistent data from the given data. It also involves the process of transformation where wrong data is transformed into the correct data as well. In other words, we <b>can</b> also say that data cleaning is a kind of pre-process in which the given set of data is prepared for the data warehouse.", "dateLastCrawled": "2022-02-02T21:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Language doesn&#39;t influence our thoughts ... except when</b> it does ...", "url": "https://scienceblogs.com/cognitivedaily/2008/01/07/language-doesnt-influence-our", "isFamilyFriendly": true, "displayUrl": "https://<b>scienceblogs.com</b>/cognitivedaily/2008/01/07/<b>language-doesnt-influence-our</b>", "snippet": "Just as we <b>can</b> learn <b>a new</b> <b>language</b>, we <b>can</b> learn to have thoughts that aren&#39;t expressible in any <b>language</b>. Lupyan, G., Rakison, D.H., McClelland, J.L. (2007). <b>Language</b> Is Not Just for Talking ...", "dateLastCrawled": "2022-02-02T13:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Positive and <b>Unlabeled</b> Materials Machine <b>Learning</b> | by Nathan C. Frey ...", "url": "https://towardsdatascience.com/positive-and-unlabeled-materials-machine-learning-8b216edea899", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/positive-and-<b>unlabeled</b>-materials-machine-<b>learning</b>-8b216...", "snippet": "To deal with all these positive and <b>unlabeled</b> examples, we adapted a framework that is unsurprisingly called \u201cpositive and <b>unlabeled</b> <b>learning</b>\u201d (PU <b>learning</b>) [1]. This sort of approach is more useful than you might think \u2014 it turns out lots of problems <b>can</b> be framed this way. Imagine you\u2019re a data scientist and you have a list of customers who have bought your product (positive examples) and a list of potential customers who might or might not buy your product (<b>unlabeled</b> examples). Or ...", "dateLastCrawled": "2022-02-03T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to Label <b>Unlabeled</b> Tweets. Unsupervised <b>Learning</b> | by Huda | Geek ...", "url": "https://medium.com/geekculture/how-to-label-unlabeled-tweets-fb701b97ebf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/how-to-label-<b>unlabeled</b>-tweets-fb701b97ebf", "snippet": "While <b>learning</b> data science, we mostly get a well-labeled dataset to build our models on. However, in a real-world scenario, seldom do we get good labeled datasets. Many data science problems ...", "dateLastCrawled": "2022-01-27T11:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>A new</b> dictionary-based <b>positive and unlabeled learning</b> method ...", "url": "https://link.springer.com/article/10.1007/s10489-021-02344-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10489-021-02344-z", "snippet": "<b>Positive and unlabeled learning</b> (PU <b>learning</b>) is designed to solve the problem that we only utilize the labeled positive examples and the <b>unlabeled</b> examples to train a classifier. A variety of methods have been proposed to solve this problem by incorporating <b>unlabeled</b> examples into <b>learning</b>. However, many methods treat the original features as input in the training stage and then build the classifier. In this paper, by use of two-step strategy, a novel method with dictionary <b>learning</b> is ...", "dateLastCrawled": "2022-01-24T21:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Not All <b>Unlabeled</b> Data are Equal: <b>Learning</b> to Weight Data in Semi ...", "url": "https://papers.nips.cc/paper/2020/file/f7ac67a9aa8d255282de7d11391e1b69-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2020/file/f7ac67a9aa8d255282de7d11391e1b69-Paper.pdf", "snippet": "Not All <b>Unlabeled</b> Data are Equal: <b>Learning</b> to Weight Data in Semi-supervised <b>Learning</b> Zhongzheng Ren \u21e4, Raymond A. Yeh \u21e4, Alexander G. Schwing University of Illinois at Urbana-Champaign {zr5, yeh17, aschwing}@illinois.edu Abstract Existing semi-supervised <b>learning</b> (SSL) algorithms use a single weight to balance the loss of labeled and <b>unlabeled</b> examples, i.e., all <b>unlabeled</b> examples are equally weighted. But not all <b>unlabeled</b> data are equal. In this paper we study how to use a different ...", "dateLastCrawled": "2022-02-02T23:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning from positive</b> and <b>unlabeled</b> data: a survey | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "<b>Learning from positive</b> and <b>unlabeled</b> data or PU <b>learning</b> is a variant of this classical set up where the training data consists of positive and <b>unlabeled</b> examples. The assumption is that each <b>unlabeled</b> <b>example</b> could belong to either the positive or negative class. The term PU <b>learning</b> first began to appear in the early 2000s and there has been a surge of interest in this setting in recent years (Liu et al.", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Positive and <b>Unlabeled Learning for Graph Classification</b>", "url": "https://www.researchgate.net/publication/220766180_Positive_and_Unlabeled_Learning_for_Graph_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220766180_Positive_and_<b>Unlabeled</b>_<b>Learning</b>_for...", "snippet": "<b>new</b> drugs for cancers or chronic diseases [2], [3]. ... <b>unlabeled</b> <b>learning</b> is particularly challenging on graph data. Conventional PU <b>learning</b> approaches <b>can</b> identify a group. of reliable negative ...", "dateLastCrawled": "2021-09-28T23:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Improving <b>Neural Relation Extraction with Positive and Unlabeled</b> <b>Learning</b>", "url": "https://deepai.org/publication/improving-neural-relation-extraction-with-positive-and-unlabeled-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/improving-<b>neural-relation-extraction-with-positive-and</b>...", "snippet": "Classical PU <b>learning</b> methods, either selecting negative data points from the <b>unlabeled</b> collection, or simply assuming all <b>unlabeled</b> data points are negative [Li and Liu2005, Sechidis, Calvo, and Brown2014], are not suitable for our task as we mention above. Thus we propose <b>a new</b> method to exploit both positive and <b>unlabeled</b> data. That is, we first build two representations for positive and <b>unlabeled</b> sentences respectively, and then the two representations are combined into one as a", "dateLastCrawled": "2021-12-23T03:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Incremental Learning with Unlabeled Data</b> in the Wild | DeepAI", "url": "https://deepai.org/publication/incremental-learning-with-unlabeled-data-in-the-wild", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>incremental-learning-with-unlabeled-data</b>-in-the-wild", "snippet": "Prior works in class-incremental <b>learning</b> focused on <b>learning</b> in a closed environment, i.e., a model <b>can</b> only see the given labeled training dataset during training [2, 10, 20, 21, 28]. However, in the real world, as we live with a continuous and large stream of data, a number of <b>unlabeled</b> data is easily obtainable on the fly or transiently, for <b>example</b>, by data mining on social media [ 23 ] and web data [ 14 ] .", "dateLastCrawled": "2021-12-22T04:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Self-<b>Learning</b> AI Explained | Udacity", "url": "https://www.udacity.com/blog/2021/08/self-learning-ai-explained.html", "isFamilyFriendly": true, "displayUrl": "https://www.udacity.com/blog/2021/08/self-<b>learning</b>-ai-explained.html", "snippet": "Self-<b>learning</b> AI is artificial intelligence that <b>can</b> train itself using <b>unlabeled</b> data. On a high level, it works by analyzing a dataset and looking for patterns that it <b>can</b> draw conclusions from. It essentially learns to \u201cfill in the blanks.\u201d A recent Wired article <b>compared</b> it to teaching someone to speak another <b>language</b> in a structured educational setting versus immersing them in the <b>language</b> in real life. While a person who learns Spanish for five years in school might have a solid ...", "dateLastCrawled": "2022-01-29T04:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Explanation of BERT Model - NLP - <b>GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/explanation-of-bert-model-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/explanation-of-bert-model-nlp", "snippet": "This is convenient because we have vast amounts of text data that such a model <b>can</b> learn from without labels <b>can</b> be trained. ULM-Fit: Transfer <b>Learning</b> In NLP: ULM-Fit introduces <b>a new</b> <b>language</b> model and process to effectively fine-tuned that <b>language</b> model for the specific task. This enables NLP architecture to perform transfer <b>learning</b> on a pre-trained model similar to that is performed in many Computer vision tasks. Open AI Transformer: Pre-training: The above Transformer architecture pre ...", "dateLastCrawled": "2022-02-02T20:41:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>The Types Of Machine Learning | Let\u2019s Understand Part</b> 2. \u2013 ML for Lazy", "url": "https://mlforlazy.in/the-types-of-machine-learning-lets-understand-part-2/", "isFamilyFriendly": true, "displayUrl": "https://mlforlazy.in/<b>the-types-of-machine-learning-lets-understand-part</b>-2", "snippet": "The <b>analogy</b>. In layman\u2019s language or in words that are easy to understand, semi-supervised <b>learning</b> is like supervising a student for a short amount of time and then letting him go and wander the field independently. It solves classification problems. That means that you will need some supervised parts. Then at the same time, you have to train the model on large datasets of unlabelled data, for which you need the unsupervised part of <b>machine</b> <b>learning</b>. The central concept is to cluster ...", "dateLastCrawled": "2022-01-09T08:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Types of <b>Machine</b> <b>Learning</b>. How do machines learn? There are many\u2026 | by ...", "url": "https://medium.com/@sameerkhan9/types-of-machine-learning-b046528d65f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@sameerkhan9/types-of-<b>machine</b>-<b>learning</b>-b046528d65f3", "snippet": "Unsupervised <b>learning</b> is a type of <b>learning</b> in which the <b>machine</b> must infer the function of input and outputs with <b>unlabeled</b> data. It is given data but the job of the <b>machine</b> is to figure out some ...", "dateLastCrawled": "2021-11-23T16:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Unsupervised <b>Machine</b> <b>Learning</b>: Examples and Use Cases | <b>AltexSoft</b>", "url": "https://www.altexsoft.com/blog/unsupervised-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>altexsoft</b>.com/blog/unsupervised-<b>machine</b>-<b>learning</b>", "snippet": "Unsupervised <b>machine</b> <b>learning</b> is the process of inferring underlying hidden patterns from historical data. Within such an approach, a <b>machine</b> <b>learning</b> model tries to find any similarities, differences, patterns, and structure in data by itself. No prior human intervention is needed. Let\u2019s get back to our <b>example</b> of a child\u2019s experiential <b>learning</b>. Picture a toddler. The child knows what the family cat looks like (provided they have one) but has no idea that there are a lot of other cats ...", "dateLastCrawled": "2022-02-03T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Learning from positive</b> and <b>unlabeled</b> data: a survey - <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "<b>Learning from positive</b> and <b>unlabeled</b> data or PU <b>learning</b> is the setting where a learner only has access to positive examples and <b>unlabeled</b> data. The assumption is that the <b>unlabeled</b> data can contain both positive and negative examples. This setting has attracted increasing interest within the <b>machine</b> <b>learning</b> literature as this type of data naturally arises in applications such as medical diagnosis and knowledge base completion. This article provides a survey of the current state of the art ...", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How does <b>Machine Learning</b> work?. What? Is that Wall-E? I guess you ...", "url": "https://medium.datadriveninvestor.com/what-is-machine-learning-and-how-does-it-work-ea4b2a6b1d32", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/what-is-<b>machine-learning</b>-and-how-does-it-work-ea...", "snippet": "Time for a bizarre attempt at an <b>analogy</b> for <b>machine learning</b> methods\u2026 There are three main methods of <b>machine learning</b>. Supervised <b>Learning</b>; Unsupervised <b>Learning</b>; Reinforcement <b>Learning</b>; For simplicity\u2019s sake, let\u2019s think of each of these methods as students at a school. And if we were to be considered a coder trying to code an ML program to tackle a certain problem, we could call ourselves teachers, in charge of teaching these students how to succeed at solving some problems. \ud83d\udc68 ...", "dateLastCrawled": "2022-01-28T02:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is <b>Learning</b>? <b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "\u2022Transfer <b>Learning</b> \u2022<b>Learning</b> by <b>Analogy</b> \u2022Multi-task <b>Learning</b> 5. 2 Inductive <b>Learning</b> \u2022Generalize from a given set of (training) examples so that accurate predictions can be made about futureexamples \u2022Learn unknown function:f(x)=y \u2013x: an input <b>example</b>(aka instance) \u2013y: the desired output \u2022Discrete or continuous scalar value \u2013h(hypothesis) function is learned that approximates f 6 Representing \u201cThings\u201d in <b>Machine</b> <b>Learning</b> \u2022An exampleor instance,x,represents a specific ...", "dateLastCrawled": "2022-02-03T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is <b>Machine</b> <b>Learning</b>? \u2014 Learned from K-Drama Start-Up | by Richardy ...", "url": "https://richardylobosapan.medium.com/what-is-machine-learning-learned-from-k-drama-start-up-a1328882808d", "isFamilyFriendly": true, "displayUrl": "https://richardylobosapan.medium.com/what-is-<b>machine</b>-<b>learning</b>-learned-from-k-drama...", "snippet": "<b>Machi n e</b> <b>learning</b> is just like Tarzan in Do-San\u2019s <b>analogy</b>. The process of <b>learning</b> of Tarzan begins with observations of data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that provided. The primary aim is to allow the computers, in this case Tarzan, to learn automatically without human intervention or assistance and adjust actions accordingly. A question then arises, why is <b>machine</b> ...", "dateLastCrawled": "2022-01-07T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Detecting Textual Analogies Using Semi-Supervised <b>Learning</b>", "url": "https://portfolios.cs.earlham.edu/wp-content/uploads/2018/12/Detecting-textual-analogies-Rei.pdf", "isFamilyFriendly": true, "displayUrl": "https://portfolios.cs.earlham.edu/wp-content/uploads/2018/12/Detecting-textual...", "snippet": "other <b>machine</b> <b>learning</b> techniques. <b>Analogy</b> is an essential aspect of human communication, understanding, and knowledge sharing. However, strategies for detecting textual analogies using machines are largely unexplored. There is also no standard corpus of textual analogies. This paper presents a system for detecting analogies in a given text using two semi supervised <b>learning</b> techniques; trans-ductive support vector machines (TSVMs) and label propagation. Count vectorization, tf-idf, and hash ...", "dateLastCrawled": "2021-10-17T14:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Starting Your Journey to Master <b>Machine Learning</b> with Python | by ...", "url": "https://towardsdatascience.com/starting-your-journey-to-master-machine-learning-with-python-d0bd47ebada9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/starting-your-journey-to-master-<b>machine-learning</b>-with...", "snippet": "What is <b>Machine Learning</b>? <b>Machine Learning</b> is the ability of a program to learn and improve its efficiency automatically without being explicitly programmed to do so. This means that given a training set you can train the <b>machine learning</b> model and it will understand how a model exactly works. Upon being tested on a test set, validation set, or any other unseen data, the model will still be able to evaluate the particular task. Let us understand this with a simple <b>example</b>. Assume we have a ...", "dateLastCrawled": "2022-01-25T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine learning MCQs</b> | T4Tutorials.com", "url": "https://t4tutorials.com/machine-learning-mcqs/", "isFamilyFriendly": true, "displayUrl": "https://t4tutorials.com/<b>machine-learning-mcqs</b>", "snippet": "<b>Machine learning MCQs</b>. 1. The general concept and process of forming definitions from examples of concepts to be learned. E. All of these. F. None of these. 2. The computer is the best <b>learning</b> for.", "dateLastCrawled": "2022-01-30T16:47:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "2148 IEEE TRANSACTIONS ON NEURAL NETWORKS AND <b>LEARNING</b> SYSTEMS, VOL. 26 ...", "url": "http://www.kerenfu.top/sources/FLAP2015.pdf", "isFamilyFriendly": true, "displayUrl": "www.kerenfu.top/sources/FLAP2015.pdf", "snippet": "conventional <b>machine</b> <b>learning</b> algorithms. As a kind of iteration-based algorithm, it is proven that FLAP can converge more quickly than other iterative methods by analyzing the relationship between the convergence rate and the eigenvalues of the iteration matrix. We show that eigenvalues of the iteration matrix in FLAP are close to 1, while those in other methods may scatter in a wide range. This difference makes FLAP is superior to other iterative methods in terms of convergence speed. We ...", "dateLastCrawled": "2021-11-19T02:43:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(unlabeled example)  is like +(learning a new language)", "+(unlabeled example) is similar to +(learning a new language)", "+(unlabeled example) can be thought of as +(learning a new language)", "+(unlabeled example) can be compared to +(learning a new language)", "machine learning +(unlabeled example AND analogy)", "machine learning +(\"unlabeled example is like\")", "machine learning +(\"unlabeled example is similar\")", "machine learning +(\"just as unlabeled example\")", "machine learning +(\"unlabeled example can be thought of as\")", "machine learning +(\"unlabeled example can be compared to\")"]}