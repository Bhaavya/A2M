{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "6 Types of AI <b>Bias</b> Everyone Should Know - Seldon", "url": "https://www.seldon.io/6-types-of-ai-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.seldon.io/6-types-of-ai-<b>bias</b>", "snippet": "<b>Confirmation</b> <b>bias</b> is particularly prevalent in applications of <b>machine</b> <b>learning</b> where human review is required before any action is taken. The use of AI in healthcare has seen doctors be dismissive of algorithmic diagnosis because it doesn\u2019t match their own experience or understanding. Often when investigated, it turns out that the doctors haven\u2019t read the most recent research literature which points to slightly different symptoms, techniques or diagnosis outcomes. Ultimately, there are ...", "dateLastCrawled": "2022-02-03T01:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Machine</b> <b>Learning</b> <b>Bias</b> (AI <b>Bias</b>)?", "url": "https://www.techtarget.com/searchenterpriseai/definition/machine-learning-bias-algorithm-bias-or-AI-bias", "isFamilyFriendly": true, "displayUrl": "https://www.techtarget.com/.../definition/<b>machine</b>-<b>learning</b>-<b>bias</b>-<b>algorithm</b>-<b>bias</b>-or-AI-<b>bias</b>", "snippet": "<b>Machine</b> <b>learning</b> <b>bias</b>, also sometimes called <b>algorithm</b> <b>bias</b> or AI <b>bias</b>, is a phenomenon that occurs when an <b>algorithm</b> produces results that are systemically prejudiced due to erroneous assumptions in the <b>machine</b> <b>learning</b> process.. <b>Machine</b> <b>learning</b>, a subset of artificial intelligence (), depends on the quality, objectivity and size of training data used to teach it.Faulty, poor or incomplete data will result in inaccurate predictions, reflecting the &quot;garbage in, garbage out&quot; admonishment ...", "dateLastCrawled": "2022-01-28T17:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Controlling <b>machine</b>-<b>learning</b> algorithms and their biases", "url": "https://www.mckinsey.com/~/media/McKinsey/Business%20Functions/Risk/Our%20Insights/Controlling%20machine%20learning%20algorithms%20and%20their%20biases/Controlling-machine-learning-algorithms-and-their-biases.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mckinsey.com</b>/~/media/<b>McKinsey</b>/Business Functions/Risk/Our Insights...", "snippet": "<b>Confirmation</b> <b>bias</b> is the tendency to select evidence that supports preconceived beliefs, while loss-aversion <b>bias</b> imposes undue conservatism on decision-making processes. <b>Machine</b> <b>learning</b> is being used in many decisions with business implications, such as loan approvals in banking, and with personal implications, such as diagnostic decisions in hospital emergency rooms. The benefits of removing harmful biases from such decisions are obvious and highly desirable, whether they come in ...", "dateLastCrawled": "2022-01-27T20:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Controlling machine-learning algorithms</b> and their biases | McKinsey", "url": "https://www.mckinsey.com/business-functions/risk-and-resilience/our-insights/controlling-machine-learning-algorithms-and-their-biases", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mckinsey.com</b>/.../<b>controlling-machine-learning-algorithms</b>-and-their-<b>bias</b>es", "snippet": "First, users of <b>machine</b>-<b>learning</b> algorithms need to understand an <b>algorithm</b>\u2019s shortcomings and refrain from asking questions whose answers will be invalidated by algorithmic <b>bias</b>. Using a <b>machine</b>-<b>learning</b> model is more <b>like</b> driving a car than riding an elevator. To get from point A to point B, users cannot simply push a button; they must first learn operating procedures, rules of the road, and safety practices.", "dateLastCrawled": "2022-02-01T23:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Youtube\u2019s Recommendation System and Impact of <b>Confirmation</b> <b>Bias</b> | by ...", "url": "https://medium.com/analytics-vidhya/youtubes-recommendation-system-and-confirmation-bias-c81ae7481dec", "isFamilyFriendly": true, "displayUrl": "https://medium.com/.../youtubes-recommendation-system-and-<b>confirmation</b>-<b>bias</b>-c81ae7481dec", "snippet": "<b>Confirmation</b> <b>bias</b> can lead to echo chambers and extreme polarization of social groups, as seen below. The Pew Research Center conducts a study of American Polarization every ten years. This study ...", "dateLastCrawled": "2022-01-25T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Cognitive <b>Bias</b> in <b>Machine Learning</b> | by Maureen McElaney | Center for ...", "url": "https://medium.com/codait/cognitive-bias-in-machine-learning-d287838eeb4b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/codait/cognitive-<b>bias</b>-in-<b>machine-learning</b>-d287838eeb4b", "snippet": "<b>Machine learning</b> algorithms make decisions <b>like</b> who gets a bonus, a job interview, whether or not your credit card limit (or interest) is raised, and who gets into a clinical trial. <b>Machine</b> ...", "dateLastCrawled": "2022-02-03T10:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "9 Types of <b>Data Bias in Machine Learning</b> - TAUS", "url": "https://blog.taus.net/9-types-of-data-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://blog.taus.net/9-types-of-<b>data-bias-in-machine-learning</b>", "snippet": "In <b>machine</b> <b>learning</b>, recall is defined as the rate of how many unseen points a model labeled accurately over the total number of observations. Let\u2019s say a group of test subjects share how many calories they consumed per day over the last week. As they cannot recall the precise amount, they will provide an estimation. These estimates take away from the true values, resulting in a recall <b>bias</b>. Observer <b>Bias</b>. Observer <b>bias</b>, or <b>confirmation</b> <b>bias</b>, occurs when the conductor of the experiment ...", "dateLastCrawled": "2022-02-01T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Biases in <b>Machine</b> <b>Learning</b> | Baeldung on Computer Science", "url": "https://www.baeldung.com/cs/machine-learning-biases", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/cs/<b>machine</b>-<b>learning</b>-<b>bias</b>es", "snippet": "<b>Algorithm</b> <b>Bias</b>: The next step is choosing an <b>algorithm</b> that we\u2019ll use to create the model to train. As we\u2019ve previously seen, there are several algorithms to choose from, <b>like</b> linear regression, support vector machines, decision trees, etc. Although these algorithms have broad applications, there are certainly use cases that fit an <b>algorithm</b> better. The wrong choice of <b>algorithm</b> can also lead to <b>bias</b> in predictions.", "dateLastCrawled": "2022-01-30T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> <b>Learning</b> Fairness: Types of <b>Bias</b> | by Svs Nagesh | Medium", "url": "https://nageshsomayajula.medium.com/machine-learning-fairness-types-of-bias-82bcf3df2d47", "isFamilyFriendly": true, "displayUrl": "https://nageshsomayajula.medium.com/<b>machine</b>-<b>learning</b>-fairness-types-of-<b>bias</b>-82bcf3df2d47", "snippet": "AI a p plications are <b>like</b> a small kid, we must train with the right data otherwise they can be misguided, and correcting machines or AI applications will be big challenging, for kids also (pun intended). The AI systems themselves will construct models that will explain how it works and follow anti-<b>bias</b> rules. In the <b>machine</b>, <b>learning</b> <b>bias</b> is one of the most common problems and every <b>algorithm</b> falls trap on this various kind of <b>bias</b>, let\u2019s discuss in detail various types of <b>bias</b> and how to ...", "dateLastCrawled": "2022-01-30T12:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Is this a <b>wolf? Understanding bias in machine learning</b> | KDE", "url": "https://kde.mitre.org/blog/2018/10/28/is-this-a-wolf-understanding-bias-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://kde.mitre.org/.../2018/10/28/is-this-a-<b>wolf-understanding-bias-in-machine-learning</b>", "snippet": "But as <b>machine</b> <b>learning</b> matures, we are coming to appreciate how limited our understanding is of how these tools come to conclusions. MITRE in the mix! This is where MITRE comes in. Through MITRE research, we are taking steps to assess new ways for algorithms to give us feedback. <b>Machine</b> <b>learning</b> is a valuable tool, but its black box nature can make it difficult to rely on in the real world. Photo courtesy of Pixabay. For instance, imagine I took our <b>algorithm</b>, and showed it the new image of ...", "dateLastCrawled": "2022-02-01T23:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Controlling machine-learning algorithms</b> and their biases | McKinsey", "url": "https://www.mckinsey.com/business-functions/risk-and-resilience/our-insights/controlling-machine-learning-algorithms-and-their-biases", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mckinsey.com</b>/.../<b>controlling-machine-learning-algorithms</b>-and-their-<b>bias</b>es", "snippet": "Another basic <b>bias</b>-generating factor is incomplete data. Every <b>machine</b>-<b>learning</b> <b>algorithm</b> operates wholly within the world defined by the data that were used to calibrate it. Limitations in the data set will <b>bias</b> outcomes, sometimes severely. Predicting behavior: \u2018Winner takes all\u2019 <b>Machine</b> <b>learning</b> can perpetuate and even amplify behavioral biases. By design, a social-media site filtering news based on user preferences reinforces natural <b>confirmation</b> <b>bias</b> in readers. The site may even be ...", "dateLastCrawled": "2022-02-01T23:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Data <b>Bias</b> and What it <b>Means for Your Machine Learning Models</b> - Explorium", "url": "https://www.explorium.ai/blog/data-bias-and-what-it-means-for-your-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://www.explorium.ai/blog/data-<b>bias</b>-and-what-it-<b>means-for-your-machine-learning-models</b>", "snippet": "<b>Confirmation</b> <b>bias</b>. An incredibly pervasive problem is people\u2019s reluctance to question findings that support what they already believe. In other words, patterns and outcomes that confirm your assumptions or prejudices. This is especially problematic with <b>machine</b> <b>learning</b> because the model is continually trying to refine itself based on your reactions to its results. If you ignore certain outcomes and privilege others \u2013 the ones that confirm what you already believe \u2013 the system takes ...", "dateLastCrawled": "2022-02-03T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Seven Types Of Data <b>Bias</b> In <b>Machine</b> <b>Learning</b>", "url": "https://www.telusinternational.com/articles/7-types-of-data-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.telusinternational.com/articles/7-types-of-data-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "How do I avoid data <b>bias</b> in <b>machine</b> <b>learning</b> projects? The prevention of data <b>bias</b> in <b>machine</b> <b>learning</b> projects is an ongoing process. Though it is sometimes difficult to know when your <b>machine</b> <b>learning</b> <b>algorithm</b>, data or model is biased, there are a number of steps you can take to help prevent <b>bias</b> or catch it early. Though far from a comprehensive list, the bullet points below provide an entry-level guide for thinking about data <b>bias</b> for <b>machine</b> <b>learning</b> projects.", "dateLastCrawled": "2022-02-03T11:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Controlling <b>machine</b>-<b>learning</b> algorithms and their biases", "url": "https://www.mckinsey.com/~/media/McKinsey/Business%20Functions/Risk/Our%20Insights/Controlling%20machine%20learning%20algorithms%20and%20their%20biases/Controlling-machine-learning-algorithms-and-their-biases.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mckinsey.com</b>/~/media/<b>McKinsey</b>/Business Functions/Risk/Our Insights...", "snippet": "<b>Confirmation</b> <b>bias</b> is the tendency to select evidence that supports preconceived beliefs, while loss-aversion <b>bias</b> imposes undue conservatism on decision-making processes. <b>Machine</b> <b>learning</b> is being used in many decisions with business implications, such as loan approvals in banking, and with personal implications, such as diagnostic decisions in hospital emergency rooms. The benefits of removing harmful biases from such decisions are obvious and highly desirable, whether they come in ...", "dateLastCrawled": "2022-01-27T20:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "9 Types of <b>Data Bias in Machine Learning</b> - TAUS", "url": "https://blog.taus.net/9-types-of-data-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://blog.taus.net/9-types-of-<b>data-bias-in-machine-learning</b>", "snippet": "In <b>machine</b> <b>learning</b>, recall is defined as the rate of how many unseen points a model labeled accurately over the total number of observations. Let\u2019s say a group of test subjects share how many calories they consumed per day over the last week. As they cannot recall the precise amount, they will provide an estimation. These estimates take away from the true values, resulting in a recall <b>bias</b>. Observer <b>Bias</b>. Observer <b>bias</b>, or <b>confirmation</b> <b>bias</b>, occurs when the conductor of the experiment ...", "dateLastCrawled": "2022-02-01T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "6 Ways to Reduce Different Types of <b>Bias</b> in <b>Machine Learning</b>", "url": "https://www.techtarget.com/searchenterpriseai/feature/6-ways-to-reduce-different-types-of-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.techtarget.com/searchenterpriseai/feature/6-ways-to-reduce-different-types...", "snippet": "However, <b>machine learning</b>-based systems are only as good as the data that&#39;s used to train them. If there are inherent biases in the data used to feed a <b>machine learning</b> <b>algorithm</b>, the result could be systems that are untrustworthy and potentially harmful.. In this article, you&#39;ll learn why <b>bias</b> in AI systems is a cause for concern, how to identify different types of biases and six effective methods for reducing <b>bias</b> in <b>machine learning</b>.. Why is eliminating <b>bias</b> important?", "dateLastCrawled": "2022-01-30T19:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Cognitive <b>Bias</b> in <b>Machine Learning</b> | by Maureen McElaney | Center for ...", "url": "https://medium.com/codait/cognitive-bias-in-machine-learning-d287838eeb4b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/codait/cognitive-<b>bias</b>-in-<b>machine-learning</b>-d287838eeb4b", "snippet": "Cognitive <b>Bias</b> in <b>Machine Learning</b>. The High Stakes Game of Digital Discrimination . Companies from a wide range of industries use <b>machine learning</b> data to do everyday business. From consumer ...", "dateLastCrawled": "2022-02-03T10:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is <b>Bias in Machine Learning</b> &amp; Deep <b>Learning</b>?", "url": "https://www.foreseemed.com/blog/bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.foreseemed.com/blog/<b>bias-in-machine-learning</b>", "snippet": "<b>Similar</b> to observational studies, how the deep <b>learning</b> and <b>machine</b> <b>learning</b> models are planned, developed, tested, analyzed, and deployed can lead to removing <b>bias</b> inherent in all systems. At ForeSee Medical , we have a dedicated team of clinicians, medical NLP linguists and <b>machine</b> <b>learning</b> experts focused on understanding, tracking and mitigating <b>bias</b> within our HCC risk adjustment coding data models.", "dateLastCrawled": "2022-02-02T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Youtube\u2019s Recommendation System and Impact of <b>Confirmation</b> <b>Bias</b> | by ...", "url": "https://medium.com/analytics-vidhya/youtubes-recommendation-system-and-confirmation-bias-c81ae7481dec", "isFamilyFriendly": true, "displayUrl": "https://medium.com/.../youtubes-recommendation-system-and-<b>confirmation</b>-<b>bias</b>-c81ae7481dec", "snippet": "Big Data + <b>Machine</b> <b>Learning</b> + Human Computer Interaction. YouTube\u2019s industrial recommendation system is dealing with one of the largest and fastest growing datasets in the world. The system\u2019s ...", "dateLastCrawled": "2022-01-25T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Confidence drives a neural <b>confirmation</b> <b>bias</b> | Nature Communications", "url": "https://www.nature.com/articles/s41467-020-16278-6", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-020-16278-6", "snippet": "a We trained a <b>machine</b>-<b>learning</b> classification <b>algorithm</b> on the pre-decision phase using MEG activity to predict left vs. right choices, and reapplied this classifier to the corresponding time ...", "dateLastCrawled": "2022-01-28T14:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Data <b>Bias</b> and What it <b>Means for Your Machine Learning Models</b> - Explorium", "url": "https://www.explorium.ai/blog/data-bias-and-what-it-means-for-your-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://www.explorium.ai/blog/data-<b>bias</b>-and-what-it-<b>means-for-your-machine-learning-models</b>", "snippet": "<b>Confirmation</b> <b>bias</b>. An incredibly pervasive problem is people\u2019s reluctance to question findings that support what they already believe. In other words, patterns and outcomes that confirm your assumptions or prejudices. This is especially problematic with <b>machine</b> <b>learning</b> because the model is continually trying to refine itself based on your reactions to its results. If you ignore certain outcomes and privilege others \u2013 the ones that confirm what you already believe \u2013 the system takes ...", "dateLastCrawled": "2022-02-03T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 Types of AI <b>Bias</b> Everyone Should Know - Seldon", "url": "https://www.seldon.io/6-types-of-ai-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.seldon.io/6-types-of-ai-<b>bias</b>", "snippet": "<b>Confirmation</b> <b>bias</b> is particularly prevalent in applications of <b>machine</b> <b>learning</b> where human review is required before any action is taken. The use of AI in healthcare has seen doctors be dismissive of algorithmic diagnosis because it doesn\u2019t match their own experience or understanding. Often when investigated, it turns out that the doctors haven\u2019t read the most recent research literature which points to slightly different symptoms, techniques or diagnosis outcomes. Ultimately, there are ...", "dateLastCrawled": "2022-02-03T01:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Seven Types Of Data <b>Bias</b> In <b>Machine</b> <b>Learning</b>", "url": "http://telusinternational.com/articles/7-types-of-data-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "telusinternational.com/articles/7-types-of-data-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "How do I avoid data <b>bias</b> in <b>machine</b> <b>learning</b> projects? The prevention of data <b>bias</b> in <b>machine</b> <b>learning</b> projects is an ongoing process. Though it is sometimes difficult to know when your <b>machine</b> <b>learning</b> <b>algorithm</b>, data or model is biased, there are a number of steps you <b>can</b> take to help prevent <b>bias</b> or catch it early. Though far from a comprehensive list, the bullet points below provide an entry-level guide for thinking about data <b>bias</b> for <b>machine</b> <b>learning</b> projects.", "dateLastCrawled": "2022-02-01T01:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Controlling machine-learning algorithms</b> and their biases | McKinsey", "url": "https://www.mckinsey.com/business-functions/risk-and-resilience/our-insights/controlling-machine-learning-algorithms-and-their-biases", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mckinsey.com</b>/.../<b>controlling-machine-learning-algorithms</b>-and-their-<b>bias</b>es", "snippet": "This cannot be done automatically, even by advanced <b>machine</b>-<b>learning</b> algorithms such as boosting (an <b>algorithm</b> designed to reduce algorithmic <b>bias</b>). Advanced algorithms <b>can</b> correct for a statistically defined concept of error, but they cannot distinguish errors with high business impact from those of negligible importance. Another example of the many statistical techniques data scientists <b>can</b> deploy to protect algorithms from biases is the careful analysis of missing values. By determining ...", "dateLastCrawled": "2022-02-01T23:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Controlling <b>machine</b>-<b>learning</b> algorithms and their biases", "url": "https://www.mckinsey.com/~/media/McKinsey/Business%20Functions/Risk/Our%20Insights/Controlling%20machine%20learning%20algorithms%20and%20their%20biases/Controlling-machine-learning-algorithms-and-their-biases.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mckinsey.com</b>/~/media/<b>McKinsey</b>/Business Functions/Risk/Our Insights...", "snippet": "The severity of this <b>bias</b> <b>can</b> be magnified by <b>machine</b>-<b>learning</b> algorithms that must assume things will more or less continue as before in order to operate. Another basic <b>bias</b>- generating factor is incomplete data. Every <b>machine</b>-<b>learning</b> <b>algorithm</b> operates wholly within the world defined by the data that were used to calibrate it. Limitations in the data set will <b>bias</b> outcomes, sometimes severely. Predicting behavior: \u2018Winner takes all\u2019 <b>Machine</b> <b>learning</b> <b>can</b> perpetuate and even amplify ...", "dateLastCrawled": "2022-01-27T20:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>How to reduce machine learning bias</b> | by Raghav Vashisht | atoti | Medium", "url": "https://medium.com/atoti/how-to-reduce-machine-learning-bias-eb24923dd18e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/atoti/<b>how-to-reduce-machine-learning-bias</b>-eb24923dd18e", "snippet": "T here could be other types of <b>machine</b> <b>learning</b> <b>bias</b> whose origins are NOT in data. Examples of such <b>machine</b> <b>learning</b> <b>bias</b> include: 1. <b>Algorithm</b> <b>bias</b>: when there\u2019s a problem within the <b>algorithm</b> ...", "dateLastCrawled": "2022-01-27T01:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>How to reduce machine learning bias</b> - atoti", "url": "https://www.atoti.io/how-to-reduce-machine-learning-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.atoti.io/<b>how-to-reduce-machine-learning-bias</b>", "snippet": "There could be other types of <b>machine</b> <b>learning</b> <b>bias</b> whose origins are NOT in data. Examples of such <b>machine</b> <b>learning</b> <b>bias</b> include: 1. <b>Algorithm</b> <b>bias</b>: when there\u2019s a problem within the <b>algorithm</b> that performs the calculations that power the <b>machine</b> <b>learning</b> computations.Either the <b>algorithm</b> favors or unnecessarily opposes a certain section of the population.", "dateLastCrawled": "2022-01-29T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "5 Types of <b>bias</b> &amp; how to eliminate them in your <b>machine</b> <b>learning</b> ...", "url": "https://towardsdatascience.com/5-types-of-bias-how-to-eliminate-them-in-your-machine-learning-project-75959af9d3a0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/5-types-of-<b>bias</b>-how-to-eliminate-them-in-your-<b>machine</b>...", "snippet": "Compas is a <b>machine</b> <b>learning</b> <b>algorithm</b> that predicts the defendant\u2019s likelihoods to commit crimes, it has been shown that it makes biased predictions about who is more likely to recommit crimes. Research from ProPublica found that the tool was 2 times more likely to incorrectly cite black defendants as being high risk for recommitting crimes, it was also 2 times more likely to incorrectly predict that white defendants were low risk to recommitting crimes. Find the complete analysis by ...", "dateLastCrawled": "2022-01-26T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Confirmation Bias</b> | SpringerLink", "url": "https://link.springer.com/chapter/10.1007%2F978-1-4757-2901-6_9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-1-4757-2901-6_9", "snippet": "These keywords were added by <b>machine</b> and not by the authors. This process is experimental and the keywords may be updated as the <b>learning</b> <b>algorithm</b> improves. This is a preview of subscription content, log in to check access. Preview. Unable to display preview. Download preview PDF. Unable to display preview. Download preview PDF. References. Anderson, J. R. (1990). The adaptive character of <b>thought</b>. Hillsdale, NJ: Lawrence Erlbaum. Google Scholar. Beckmann, J., &amp; Irle, M. (1985). Dissonance ...", "dateLastCrawled": "2022-01-23T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Bias in Artificial Intelligence</b>. How <b>bias</b> <b>can</b> explode our AI models ...", "url": "https://adabhishekdabas.medium.com/bias-in-artificial-intelligence-d2ccec3abb2b", "isFamilyFriendly": true, "displayUrl": "https://adabhishekdabas.medium.com/<b>bias-in-artificial-intelligence</b>-d2ccec3abb2b", "snippet": "Example: Optimism/Pessimism <b>bias</b>, <b>Confirmation</b> <b>Bias</b>, Self-serving <b>Bias</b>, Negativity <b>Bias</b>. <b>Algorithm</b> <b>Bias</b>: The Unjust, prejudicial treatment which is shown within the algorithmic decision-making system. In most cases when we are concerned about <b>bias</b>, we mean \u201cAlgorithmic <b>bias</b>\u201d. The Algorithms picks up this <b>bias</b> from the data, which is created by humans and includes these human biases. Now, Why is this a problem if our model picks up the <b>bias</b> which was there in the data or examples from the ...", "dateLastCrawled": "2022-01-30T19:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "9 Types of <b>Data Bias in Machine Learning</b> - TAUS", "url": "https://blog.taus.net/9-types-of-data-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://blog.taus.net/9-types-of-<b>data-bias-in-machine-learning</b>", "snippet": "The introduction of the term <b>bias</b> in the <b>Machine</b> <b>Learning</b> space goes back to the paper written by Tom Mitchell in 1980, ... Observer <b>bias</b>, or <b>confirmation</b> <b>bias</b>, occurs when the conductor of the experiment integrates their expected outcome into the study. It <b>can</b> happen if a researcher starts on a project with subjective thoughts about their study, knowingly or unconsciously. An example <b>can</b> be seen in data labeling tasks where one data worker chooses a different label based on their subjective ...", "dateLastCrawled": "2022-02-01T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "5 Types of <b>bias</b> &amp; how to eliminate them in your <b>machine</b> <b>learning</b> ...", "url": "https://towardsdatascience.com/5-types-of-bias-how-to-eliminate-them-in-your-machine-learning-project-75959af9d3a0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/5-types-of-<b>bias</b>-how-to-eliminate-them-in-your-<b>machine</b>...", "snippet": "Compas is a <b>machine</b> <b>learning</b> <b>algorithm</b> that predicts the defendant\u2019s likelihoods to commit crimes, it has been shown that it makes biased predictions about who is more likely to recommit crimes. Research from ProPublica found that the tool was 2 times more likely to incorrectly cite black defendants as being high risk for recommitting crimes, it was also 2 times more likely to incorrectly predict that white defendants were low risk to recommitting crimes. Find the complete analysis by ...", "dateLastCrawled": "2022-01-26T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Evolution and impact of <b>bias</b> in human and <b>machine learning</b> <b>algorithm</b> ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235502", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235502", "snippet": "Traditionally, <b>machine learning</b> algorithms relied on reliable labels from experts to build predictions. More recently however, algorithms have been receiving data from the general population in the form of labeling, annotations, etc. The result is that algorithms are subject to <b>bias</b> that is born from ingesting unchecked information, such as biased samples and biased labels. Furthermore, people and algorithms are increasingly engaged in interactive processes wherein neither the human nor the ...", "dateLastCrawled": "2021-11-15T00:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Reducing Sanger <b>confirmation</b> testing through false positive prediction ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8257489/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8257489", "snippet": "Similarly, true positive variant calls passed to the <b>machine</b> <b>learning</b> <b>algorithm</b> are labeled as negatives (binary label \u201c0\u201d). The goal of <b>machine</b> <b>learning</b> in this application is to create a model with high \u201ccapture rate\u201d (sensitivity in our <b>machine</b> <b>learning</b> context), meaning that few or no false positive variant calls will be missed by the model and allowed onto the final patient report. The model should also have a low true positive flagging rate (\u201cTP flag rate,\u201d false positive ...", "dateLastCrawled": "2021-08-26T10:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Confidence drives a neural <b>confirmation</b> <b>bias</b> | Nature Communications", "url": "https://www.nature.com/articles/s41467-020-16278-6", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-020-16278-6", "snippet": "a We trained a <b>machine</b>-<b>learning</b> classification <b>algorithm</b> on the pre-decision phase using MEG activity to predict left vs. right choices, and reapplied this classifier to the corresponding time ...", "dateLastCrawled": "2022-01-28T14:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A review of <b>possible effects of cognitive biases on interpretation of</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0004370221000096", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0004370221000096", "snippet": "Implications for rule <b>learning</b> This <b>bias</b> <b>can</b> have a significant impact depending on the purpose for which the rule <b>learning</b> results are used. If the analyst has some prior hypothesis before obtaining the rule <b>learning</b> results, according to the <b>confirmation</b> <b>bias</b> the analyst will tend to \u201ccherry pick\u201d rules confirming this prior hypothesis and disregard rules that contradict it. Given that some rule learners may output contradicting rules, the analyst may tend to select only the rules ...", "dateLastCrawled": "2021-10-30T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A <b>confirmation</b> <b>bias</b> in perceptual decision-making due to hierarchical ...", "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009517", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009517", "snippet": "Author summary When humans and animals accumulate evidence over time, they are often biased. Identifying the mechanisms underlying these biases <b>can</b> lead to new insights into principles of neural computation. The <b>confirmation</b> <b>bias</b>, in which new evidence is given more weight when it agrees with existing beliefs, is a ubiquitous yet poorly understood example of such biases. Here we report that a <b>confirmation</b> <b>bias</b> arises even during perceptual decision-making, and propose an approximate ...", "dateLastCrawled": "2022-01-18T06:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Reducing Sanger confirmation testing through false positive prediction</b> ...", "url": "https://www.nature.com/articles/s41436-021-01148-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41436-021-01148-3", "snippet": "Similarly, true positive variant calls passed to the <b>machine</b> <b>learning</b> <b>algorithm</b> are labeled as negatives (binary label \u201c0\u201d). The goal of <b>machine</b> <b>learning</b> in this application is to create a ...", "dateLastCrawled": "2021-12-31T01:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>How Algorithms Can Fight Bias Instead of Entrench</b> It - By Tobias Baer ...", "url": "https://behavioralscientist.org/how-algorithms-can-fight-bias-instead-of-entrench-it/", "isFamilyFriendly": true, "displayUrl": "https://behavioralscientist.org/<b>how-algorithms-can-fight-bias-instead-of-entrench</b>-it", "snippet": "Human decision-makers often are more expensive than a <b>machine</b>, especially when thousands or millions of similar decisions need to be made, and we\u2019re notoriously fickle, inconsistent deciders. To achieve this efficiency and consistency, algorithms are designed to remove many human cognitive biases, such as <b>confirmation</b> <b>bias</b>, overconfidence, anchoring on irrelevant reference points (which mislead our conscious reasoning), and social and interest biases (which cause us to override proper ...", "dateLastCrawled": "2022-01-29T20:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Are <b>CNN</b> and <b>Fox News</b> Really Biased? A <b>Machine</b> <b>Learning</b> Study. | by ...", "url": "https://medium.com/swlh/are-cnn-and-fox-news-really-biased-3ab3ef34bd28", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/are-<b>cnn</b>-and-<b>fox-news</b>-really-<b>bias</b>ed-3ab3ef34bd28", "snippet": "A Look at the BLUFFNet <b>Algorithm</b>. Before I go into my results, I want to give you a sense of how they were created. At the core of any <b>machine</b> <b>learning</b> <b>algorithm</b> or statistical analysis is data ...", "dateLastCrawled": "2022-02-02T06:38:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "<b>Confirmation</b> <b>bias</b> is a form of implicit <b>bias</b>. ... addition and subtraction of embeddings can solve word <b>analogy</b> tasks. The dot product of two embeddings is a measure of their similarity. empirical risk minimization (ERM) Choosing the function that minimizes loss on the training set. Contrast with structural risk minimization. encoder . #language. In general, any ML system that converts from a raw, sparse, or external representation into a more processed, denser, or more internal ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understand Cognitive Biases for Penetration Testers", "url": "https://jeremyharbinger.com/cognitive-biases-and-hacking-1", "isFamilyFriendly": true, "displayUrl": "https://jeremyharbinger.com/cognitive-<b>bias</b>es-and-hacking-1", "snippet": "According to The Decision Lab, &quot;<b>Confirmation</b> <b>bias</b> is a cognitive shortcut we use when gathering and interpreting information&quot;. Since generating new hypotheses that explain events is cognitively expensive, it&#39;s often easier to use the shortcut of relying on hypotheses we already know of rather than spend time on generating new ones. While this might be a good survival instinct, it hardly helps us understand and attack a computer or network efficiently.", "dateLastCrawled": "2022-01-31T09:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Preliminary performance study of a brief review on <b>machine</b> <b>learning</b> ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "snippet": "<b>Analogy</b>-based effort estimation is the major task of software engineering which estimates the effort required for new software projects using existing histories for corresponding development and management. In general, the high accuracy of software effort estimation techniques can be a non-solvable problem we named as multi-objective problem. Recently, most of the authors have been used <b>machine</b> <b>learning</b> techniques for the same process however not possible to meet the higher performance ...", "dateLastCrawled": "2022-01-02T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Top <b>50+ Machine Learning Interview Questions and Answers</b> [Updated]", "url": "https://www.techgeekbuzz.com/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.techgeekbuzz.com/<b>machine</b>-<b>learning</b>-interview-questions", "snippet": "Answer: Following are the most common forms of <b>bias</b> in <b>machine</b> <b>learning</b>: <b>Confirmation</b> <b>bias</b> \u2013 It happens when the person analyzing the data has some assumptions about the data. To prove the same, they exclude certain variables from the analysis itself. Selection <b>bias</b> \u2013 This happens when the sample doesn\u2019t represent the entire population of data. Outliers \u2013 Data points that are predominantly different from other values. For example, a value with an age of 35 years in the dataset ...", "dateLastCrawled": "2022-01-20T21:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Six useful metaphors for thinking about artificial intelligence ...", "url": "https://hackernoon.com/six-useful-metaphors-for-thinking-about-artificial-intelligence-c7468b1551fa", "isFamilyFriendly": true, "displayUrl": "https://hackernoon.com/six-useful-<b>metaphor</b>s-for-thinking-about-artificial-intelligence...", "snippet": "<b>Machine</b> <b>learning</b> will replace all labeling work inte the same way. No more need to manually and repeatedly identifying, categorizing and sorting things. We can expect to uptake of this technology happen rapidly because most human don\u2019t prefer to do repetitive work. A Japanese farmer took 7000 pictures of cucumbers that his mother had manually sorted and built and trained a <b>machine</b> to sort them automatically based on this technology. And Island of drunk people. Because we rarely understand ...", "dateLastCrawled": "2022-01-30T10:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Ethical Issues in <b>Machine</b> <b>Learning</b> Algorithms (Part 2)", "url": "https://www.slideshare.net/vladimirkanchev/ethical-issues-in-machine-learning-algorithms-part-2-140369359", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/vladimirkanchev/ethical-issues-in-<b>machine</b>-<b>learning</b>...", "snippet": "Data <b>bias</b> Now data <b>bias</b>: is the most important component of the <b>bias</b> of the whole AI system now; comes from data sampling. is a responsibility of the designer of the AI/ML system to deal with it. is due to various standards for datasets; no strict requirements for data content; each dataset is biased to some extent. What if the world itself is biased \u2013 gender equality is a recent social norm, for example. 11", "dateLastCrawled": "2022-01-08T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning Analogy for Meditation (illustrated</b>) - LessWrong 2.0 ...", "url": "https://www.greaterwrong.com/posts/chHhuCvmZqYLM32gz/machine-learning-analogy-for-meditation-illustrated", "isFamilyFriendly": true, "displayUrl": "https://www.greaterwrong.com/posts/chHhuCvmZqYLM32gz/<b>machine</b>-<b>learning</b>-<b>analogy</b>-for...", "snippet": "<b>Machine Learning Analogy for Meditation (illustrated</b>) abramdemski 28 Jun 2018 22:51 UTC. 87 points. 48 comments LW link. Meditation <b>Machine</b> <b>Learning</b> World Modeling Post permalink Link without comments Link without top nav bars Link without comments or top nav bars. Here\u2019s an illustrated rendition of a semiformal explanation of certain effects of meditation. It was inspired by, but differs significantly from, Kaj\u2019s post on meditation. Some people appreciated gjm\u2019s transcription for ...", "dateLastCrawled": "2022-01-17T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Examples and Observations of a <b>Confirmation Bias</b> | <b>Simply Psychology</b>", "url": "https://www.simplypsychology.org/confirmation-bias.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.simplypsychology.org</b>/<b>confirmation-bias</b>", "snippet": "<b>Confirmation bias</b> also affects employment diversity because preconceived ideas about different social groups can introduce discrimination (though it might be unconscious) and impact the recruitment process (Agarwal, 2018). Existing beliefs of a certain group being more competent than the other is the reason why particular races and gender are represented the most in companies today. This <b>bias</b> can hamper the company\u2019s attempt at diversifying their employees. Mitigating <b>Confirmation Bias</b> ...", "dateLastCrawled": "2022-02-02T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Human, Model and <b>Machine</b>: A Complementary Approach to Big Data", "url": "https://www.researchgate.net/publication/266659176_Human_Model_and_Machine_A_Complementary_Approach_to_Big_Data", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/266659176_Human_Model_and_<b>Machine</b>_A...", "snippet": "another <b>analogy</b> from ... environment for cognitive biases such as <b>confirmation</b> <b>bias</b> and the . availability heuristic. In each case, the inability of human working . memory to maintain a sufficient ...", "dateLastCrawled": "2022-01-09T09:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Learning</b> in an instructionless environment: Observation and analysis", "url": "https://www.researchgate.net/publication/234808939_Learning_in_an_instructionless_environment_Observation_and_analysis", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/234808939_<b>Learning</b>_in_an_instructionless...", "snippet": "However, recent empirical work (Wason and Johnson-Laird, 1972) suggests the existence of a <b>confirmation</b> <b>bias</b>, at least on abstract problems. Using a more realistic, computer controlled environment ...", "dateLastCrawled": "2022-01-07T23:21:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(confirmation bias)  is like +(machine learning algorithm)", "+(confirmation bias) is similar to +(machine learning algorithm)", "+(confirmation bias) can be thought of as +(machine learning algorithm)", "+(confirmation bias) can be compared to +(machine learning algorithm)", "machine learning +(confirmation bias AND analogy)", "machine learning +(\"confirmation bias is like\")", "machine learning +(\"confirmation bias is similar\")", "machine learning +(\"just as confirmation bias\")", "machine learning +(\"confirmation bias can be thought of as\")", "machine learning +(\"confirmation bias can be compared to\")"]}