{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "r - <b>Randomly</b> <b>subsampling</b> seurat object - Stack Overflow", "url": "https://stackoverflow.com/questions/70160160/randomly-subsampling-seurat-object", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/70160160/<b>randomly</b>-<b>subsampling</b>-seurat-object", "snippet": "I&#39;ve been trying to <b>randomly</b> subsample my seurat object. I&#39;m interested in <b>subsampling</b> based on 2 columns: condition and cell type. I have 5 conditions and 5 cell types. Main goal is to have 1000 c...", "dateLastCrawled": "2022-01-15T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Subsetting <b>data</b> in SAS | SAS Learning Modules", "url": "https://stats.oarc.ucla.edu/sas/modules/ubsetting-data-in-sas/", "isFamilyFriendly": true, "displayUrl": "https://stats.oarc.ucla.edu/sas/modules/ub<b>set</b>ting-<b>data</b>-in-sas", "snippet": "<b>Selecting</b> variables: The SAS file structure is similar to a spreadsheet. <b>Data</b> values are stored as variables, which are <b>like</b> fields or columns on a spreadsheet. Sometimes <b>data</b> files contain information that is superfluous to a particular analysis, in which case we might want to change the <b>data</b> file to contain only variables of interest. Programs will run more quickly and occupy less storage space if files contain only necessary variables. The following program builds a SAS file called auto ...", "dateLastCrawled": "2022-02-02T03:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Chapter 10 <b>Subsampling</b> | From Scratch", "url": "https://www.paltmeyer.com/fromScratch/subsample.html", "isFamilyFriendly": true, "displayUrl": "https://www.paltmeyer.com/fromScratch/subsample.html", "snippet": "Chapter 10 <b>Subsampling</b>. When working with very large sample <b>data</b>, even the estimation of ordinary least-squares can be computationally prohibitive. Since we increasingly find ourselves in situations where the sample size \\(n\\) is extremely high, a body of literature concerned with optimal <b>subsampling</b> has recently emerged. This post summarises some of the main ideas and methodologies that have emerged from that literature.", "dateLastCrawled": "2022-01-20T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Selecting Random Samples in R: Sample() Function</b> - <b>ProgrammingR</b>", "url": "https://www.programmingr.com/examples/neat-tricks/sample-r-function/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>programmingr</b>.com/examples/neat-tricks/sample-r-function", "snippet": "R Sample Dataframe: <b>Randomly</b> Select Rows In R Dataframes. Up till now, our examples have dealt with using the sample function in R to select a random <b>subset</b> of the values in a vector. It is more likely you will be called upon to generate a random sample in R from an existing <b>data</b> frames, <b>randomly</b> <b>selecting</b> rows from the larger <b>set</b> of ...", "dateLastCrawled": "2022-02-02T08:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Handling noisy <b>data</b> in sparse model identification using <b>subsampling</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0098135421004063", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0098135421004063", "snippet": "<b>Subsampling</b> is a statistical technique where <b>a subset</b> of the entire <b>data</b> <b>set</b> is <b>randomly</b> selected for analysis instead of the entire <b>data</b> <b>set</b>. While the method is typically employed to estimate statistical metrics ( Efron and Stein, 1981 ) or speed up an algorithm ( Rudy et al., 2017 ), the objective of <b>subsampling</b> in this paper is to increase the modeling accuracy in the presence of high levels of sensor noise.", "dateLastCrawled": "2022-01-27T06:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to match the distribution of one dataset when <b>subsampling</b> from another?", "url": "https://stats.stackexchange.com/questions/519296/how-to-match-the-distribution-of-one-dataset-when-subsampling-from-another", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/519296/how-to-match-the-distribution-of-one...", "snippet": "This is a standard matching problem equivalent to the problem of <b>selecting</b> a comparable comparison group from a pool of potential controls when assessing the effect of a treatment in an observational study. The goal of matching is to select <b>a subset</b> of the control pool to resemble the treated units. Instead of sampling, you should use matching. 1:1 optimal matching will work well in this case.", "dateLastCrawled": "2022-01-06T13:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is <b>subsampling</b> machine learning? - Quora", "url": "https://www.quora.com/What-is-subsampling-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>subsampling</b>-machine-learning", "snippet": "Answer: Running algorithms which require the full <b>data</b> <b>set</b> for each update can be expensive when the <b>data</b> is large. In order to scale inferences, we can do <b>data</b> <b>subsampling</b>, i.e., update inference using only a subsample of <b>data</b> at a time. (Note that only certain algorithms support <b>data</b> subsampli...", "dateLastCrawled": "2022-01-03T14:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Different ways to get random <b>data</b> for SQL Server <b>data</b> sampling", "url": "https://www.mssqltips.com/sqlservertip/3157/different-ways-to-get-random-data-for-sql-server-data-sampling/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mssqltips.com</b>/sqlservertip/3157/different-ways-to-get-random-<b>data</b>-for-sql...", "snippet": "For this tip, I will be using a <b>data</b> <b>set</b> containing an identity INT column (to establish the degree of randomness when <b>selecting</b> rows) and other columns filled with pseudo-random <b>data</b> of different <b>data</b> types, to (vaguely) simulate real <b>data</b> in a table. You can use the T-SQL code below to <b>set</b> this up. It should take only a couple of minutes to run and is tested on SQL Server 2012 Developer Edition. I will also be using the AdventureWorks 2012 (non-DW) database, available here: http ...", "dateLastCrawled": "2022-02-02T23:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>python</b> - How to split <b>data</b> into trainset and testset <b>randomly</b>? - Stack ...", "url": "https://stackoverflow.com/questions/17412439/how-to-split-data-into-trainset-and-testset-randomly", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/17412439", "snippet": "How to split <b>data</b> into trainset and testset <b>randomly</b>? Ask Question Asked 8 years, 7 months ago. ... delimiter)) file.close() random.shuffle(<b>data</b>) train_<b>data</b> = <b>data</b>[:int((len(<b>data</b>)+1)*.80)] #Remaining 80% to training <b>set</b> test_<b>data</b> = <b>data</b>[int((len(<b>data</b>)+1)*.80):] #Splits 20% <b>data</b> to test <b>set</b> The code splits the entire dataset to 80% train and 20% test <b>data</b> . Share. Improve this answer. Follow edited Jun 11 &#39;20 at 13:43. Community Bot. 1 1 1 silver badge. answered Feb 2 &#39;17 at 3:55. subin ...", "dateLastCrawled": "2022-01-28T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Random Sampling a Dataset in R \u2013 DECISION STATS", "url": "https://decisionstats.com/2012/03/22/random-sampling-a-dataset-in-r/", "isFamilyFriendly": true, "displayUrl": "https://decisionstats.com/2012/03/22/random-sampling-a-<b>dataset</b>-in-r", "snippet": "[1] 10. This is a typical business <b>data</b> scenario when we want to select only a few records to do our analysis (or test our code), but have all the columns for those records.Let us assume we want to sample only 5% of the whole <b>data</b> so we can run our code on it. Then the number of rows in the new object will be 0.05*nrow(ajay).That will be the size of the sample.", "dateLastCrawled": "2022-01-26T01:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Subsetting <b>data</b> in SAS | SAS Learning Modules", "url": "https://stats.oarc.ucla.edu/sas/modules/ubsetting-data-in-sas/", "isFamilyFriendly": true, "displayUrl": "https://stats.oarc.ucla.edu/sas/modules/ub<b>set</b>ting-<b>data</b>-in-sas", "snippet": "<b>Selecting</b> variables: The SAS file structure <b>is similar</b> to a spreadsheet. <b>Data</b> values are stored as variables, which are like fields or columns on a spreadsheet. Sometimes <b>data</b> files contain information that is superfluous to a particular analysis, in which case we might want to change the <b>data</b> file to contain only variables of interest. Programs will run more quickly and occupy less storage space if files contain only necessary variables. The following program builds a SAS file called auto ...", "dateLastCrawled": "2022-02-02T03:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "COMPARISON OF <b>SUBSAMPLING</b> TECHNIQUES FOR RANDOM SUBSPACE ENSEMBLES", "url": "https://www.eng.utoledo.edu/~gserpen/Publications/ICMLC%202010%20Manuscript.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.eng.utoledo.edu/~gserpen/Publications/ICMLC 2010 Manuscript.pdf", "snippet": "dimensional feature space is projected onto a <b>set</b> of lower dimensions by <b>selecting</b> random feature subsets or subsamples from the original <b>set</b>. The lower-dimensional projections can be generated using a variety of techniques based on random <b>subsampling</b>. The three such specific methods used for the generation of the random subsamples of the original feature space, as presented in this paper, are: (1) random sampling without replacement, (2) random sampling with replacement, prediction. and (3 ...", "dateLastCrawled": "2022-01-23T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Chapter 10 <b>Subsampling</b> | From Scratch", "url": "https://www.paltmeyer.com/fromScratch/subsample.html", "isFamilyFriendly": true, "displayUrl": "https://www.paltmeyer.com/fromScratch/subsample.html", "snippet": "Chapter 10 <b>Subsampling</b>. When working with very large sample <b>data</b>, even the estimation of ordinary least-squares can be computationally prohibitive. Since we increasingly find ourselves in situations where the sample size \\(n\\) is extremely high, a body of literature concerned with optimal <b>subsampling</b> has recently emerged. This post summarises some of the main ideas and methodologies that have emerged from that literature.", "dateLastCrawled": "2022-01-20T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Phylogenomic <b>Subsampling</b> and the Search for Phylogenetically Reliable Loci", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8382905/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8382905", "snippet": "Five extra matrices were built by <b>selecting</b> loci at random, for a total of 23 matrices per phylogenomic <b>data</b> <b>set</b> and <b>subsampling</b> size. It should be noted that some low occupancy taxa had no <b>data</b> in the subsampled matrices and had to be removed. In conditions of extremely uneven occupancy, these protocols should be paired with additional steps to ensure key taxa are represented in the final <b>data</b> sets. Tree inference was performed in IQ-TREE 1.6.3", "dateLastCrawled": "2022-01-22T11:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Handling noisy <b>data</b> in sparse model identification using <b>subsampling</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0098135421004063", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0098135421004063", "snippet": "<b>Subsampling</b> is a statistical technique where <b>a subset</b> of the entire <b>data</b> <b>set</b> is <b>randomly</b> selected for analysis instead of the entire <b>data</b> <b>set</b>. While the method is typically employed to estimate statistical metrics ( Efron and Stein, 1981 ) or speed up an algorithm ( Rudy et al., 2017 ), the objective of <b>subsampling</b> in this paper is to increase the modeling accuracy in the presence of high levels of sensor noise.", "dateLastCrawled": "2022-01-27T06:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Selecting Random Samples in R: Sample() Function</b> - <b>ProgrammingR</b>", "url": "https://www.programmingr.com/examples/neat-tricks/sample-r-function/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>programmingr</b>.com/examples/neat-tricks/sample-r-function", "snippet": "R Sample Dataframe: <b>Randomly</b> Select Rows In R Dataframes. Up till now, our examples have dealt with using the sample function in R to select a random <b>subset</b> of the values in a vector. It is more likely you will be called upon to generate a random sample in R from an existing <b>data</b> frames, <b>randomly</b> <b>selecting</b> rows from the larger <b>set</b> of ...", "dateLastCrawled": "2022-02-02T08:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to match the distribution of one dataset when <b>subsampling</b> from another?", "url": "https://stats.stackexchange.com/questions/519296/how-to-match-the-distribution-of-one-dataset-when-subsampling-from-another", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/519296/how-to-match-the-distribution-of-one...", "snippet": "This is a standard matching problem equivalent to the problem of <b>selecting</b> a comparable comparison group from a pool of potential controls when assessing the effect of a treatment in an observational study. The goal of matching is to select <b>a subset</b> of the control pool to resemble the treated units. Instead of sampling, you should use matching. 1:1 optimal matching will work well in this case.", "dateLastCrawled": "2022-01-06T13:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Chapter 3 Optimal subsampling</b> | From Scratch", "url": "https://www.paltmeyer.com/fromScratch/optimal-subsampling.html", "isFamilyFriendly": true, "displayUrl": "https://www.paltmeyer.com/fromScratch/optimal-<b>subsampling</b>.html", "snippet": "<b>Chapter 3 Optimal subsampling</b>. This note investigates if and how systematic <b>subsampling</b> can be applied to imbalanced learning. The structure is as follows: to <b>set</b> the stage for the remainder of the analysis the first section briefly introduces the bias-variance trade-off. The following section then introduces various <b>subsampling</b> methods. Section 3.3 illustrates the improvements associated with non-uniform <b>subsampling</b>. The final two sections apply the developed ideas to binary classification ...", "dateLastCrawled": "2022-01-18T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is <b>subsampling</b> machine learning? - Quora", "url": "https://www.quora.com/What-is-subsampling-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>subsampling</b>-machine-learning", "snippet": "Answer: Running algorithms which require the full <b>data</b> <b>set</b> for each update can be expensive when the <b>data</b> is large. In order to scale inferences, we can do <b>data</b> <b>subsampling</b>, i.e., update inference using only a subsample of <b>data</b> at a time. (Note that only certain algorithms support <b>data</b> subsampli...", "dateLastCrawled": "2022-01-03T14:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Chapter 6- Sampling</b> Flashcards - <b>Quizlet</b>", "url": "https://quizlet.com/162184081/chapter-6-sampling-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/162184081/<b>chapter-6-sampling</b>-flash-cards", "snippet": "-researcher can find <b>similar</b> studies and use their sample size as a guide-used when budgetary constraints dictate the size of a sample. Simple random sampling -A sample selected by assigning a number to every element of the population and then using some method for <b>randomly</b> <b>selecting</b> elements to be in the sample such a random digit dialing - probability of selection = sample size/ population size. Systematic sampling-a sample in which the entire population is numbered and elements are ...", "dateLastCrawled": "2019-08-19T20:11:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "An analysis of the impact of <b>subsampling</b> on the neural network error ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231221013813", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231221013813", "snippet": "This suggests that, for at least some problems, different subsets of <b>data</b> will produce minima at different locations, and that the minima of a random <b>subset</b> <b>of the data</b> does not reliably predict the location of true minima. This observation held for aggregate estimates as well, which use all available <b>data</b> by evaluating different weight vectors using different subsets of examples. It is concluded from the findings that training on changing subsamples of the available <b>data</b> is a dynamic ...", "dateLastCrawled": "2021-11-24T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Selecting</b> single cell clustering parameter values using <b>subsampling</b> ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7852188/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7852188", "snippet": "Application of chooseR to additional clustering parameters and effect of repetitions and <b>subsampling</b> on chooseR results. a ... Here, the cluster robustness stabilizes after <b>selecting</b> more than 20 PCs for this <b>data</b> <b>set</b>. d Same as b, but for the near-optimal value of the number of PCs used for clustering. e Silhouette distribution plot over different values of the resolution parameter when using only 20% of the total cells in each iteration. The near-optimal parameter value for the resolution ...", "dateLastCrawled": "2021-12-22T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Variable selection with error control: another look at ... - JSTOR", "url": "https://www.jstor.org/stable/23361014", "isFamilyFriendly": true, "displayUrl": "https://www.jstor.org/stable/23361014", "snippet": "In fact, taking subsamples of size [n/2J <b>can</b> <b>be thought</b> of as the <b>subsampling</b> scheme that most closely mimics the bootstrap (e.g. D\u00fcmbgen et al. (2012)). It is convenient at this stage to define another related selection procedure based on sample splitting. Definition 2 (simultaneous selection). Let {(A2j-\\, Ajj) : j = 1,..., B} be <b>randomly</b> chosen", "dateLastCrawled": "2021-11-30T12:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Types of Sampling: Sampling Methods with Examples | QuestionPro", "url": "https://www.questionpro.com/blog/types-of-sampling-for-social-research/", "isFamilyFriendly": true, "displayUrl": "https://www.questionpro.com/blog/types-of-sampling-for-social-research", "snippet": "Sampling is a technique of <b>selecting</b> individual members or <b>a subset</b> of the population to make statistical inferences from ... is a sampling technique where a researcher sets a selection of a few criteria and chooses members of a population <b>randomly</b>. All the members have an equal opportunity to be a part of the sample with this selection parameter. Non-probability sampling: In non-probability sampling, the researcher chooses members for research at random. This sampling method is not a fixed ...", "dateLastCrawled": "2022-02-02T06:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Variable selection with error control: Another look at Stability Selection", "url": "http://www.statslab.cam.ac.uk/~rjs57/SSFinal.pdf", "isFamilyFriendly": true, "displayUrl": "www.statslab.cam.ac.uk/~rjs57/SSFinal.pdf", "snippet": "exception in this regard). In fact, taking subsamples of size \u230an/2\u230b <b>can</b> <b>be thought</b> of as the <b>subsampling</b> scheme that most closely mimics the bootstrap (e.g. Du\u00a8mbgen, Samworth and Schuhmacher, 2012). It is convenient at this stage to de\ufb01ne another related selection procedure based on sample splitting. Definition 2 (Simultaneous Selection).", "dateLastCrawled": "2021-11-06T15:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Subsampling large graphs and invariance in networks</b> | DeepAI", "url": "https://deepai.org/publication/subsampling-large-graphs-and-invariance-in-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>subsampling-large-graphs-and-invariance-in-networks</b>", "snippet": "The algorithm <b>can</b> be understood as a model of an experimental design\u2014a protocol used to collect <b>data</b> in a survey, or to sample <b>data</b> from a network\u2014or as an actual program extracting <b>data</b> from a <b>data</b> base. Use the algorithm to extract a sample graph, small relative to input size. What information <b>can</b> be obtained from a single such sample? Certainly, that should depend on the algorithm. We approach the problem starting from a simple observation: Fix a sequence", "dateLastCrawled": "2021-12-26T18:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The 5 <b>Sampling</b> Algorithms every <b>Data</b> Scientist need to know | by Rahul ...", "url": "https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/the-5-<b>sampling</b>-algorithms-every-<b>data</b>-scientist-need-to...", "snippet": "This post is about some of the most common <b>sampling</b> techniques one <b>can</b> use while working with <b>data</b>. Simple Random <b>Sampling</b>. Say you want to select <b>a subset</b> of a population in which each member of the <b>subset</b> has an equal probability of being chosen. Below we select 100 sample points from a dataset. sample_df = df.sample(100) Stratified <b>Sampling</b>. Assum e that we need to estimate the average number of votes for each candidate in an election. Assume that the country has 3 towns: Town A has 1 ...", "dateLastCrawled": "2022-02-03T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Different ways to get random <b>data</b> for SQL Server <b>data</b> sampling", "url": "https://www.mssqltips.com/sqlservertip/3157/different-ways-to-get-random-data-for-sql-server-data-sampling/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mssqltips.com</b>/sqlservertip/3157/different-ways-to-get-random-<b>data</b>-for-sql...", "snippet": "For this tip, I will be using a <b>data</b> <b>set</b> containing an identity INT column (to establish the degree of randomness when <b>selecting</b> rows) and other columns filled with pseudo-random <b>data</b> of different <b>data</b> types, to (vaguely) simulate real <b>data</b> in a table. You <b>can</b> use the T-SQL code below to <b>set</b> this up. It should take only a couple of minutes to run and is tested on SQL Server 2012 Developer Edition. I will also be using the AdventureWorks 2012 (non-DW) database, available here: http ...", "dateLastCrawled": "2022-02-02T23:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Preparing your</b> <b>data</b> \u2014 SARS-CoV-2 Workflow documentation", "url": "https://docs.nextstrain.org/en/update-install-docs/tutorials/SARS-CoV-2/steps/data-prep.html", "isFamilyFriendly": true, "displayUrl": "https://docs.nextstrain.org/en/update-install-docs/tutorials/SARS-CoV-2/steps/<b>data</b>...", "snippet": "Note that \u201cstrain\u201d here carries no biological or functional significance and should largely <b>be thought</b> of as synonymous with \u201csample.\u201d The sequence itself is a consensus genome. By default, sequences less than 27,000 bases in length or with more than 3,000 N (unknown) bases are omitted from the analysis. For a basic QC and preliminary analysis of your sequence <b>data</b>, you <b>can</b> use clades.nextstrain.org. This tool will check your sequences for excess divergence, clustered differences ...", "dateLastCrawled": "2021-12-19T08:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "3.3. The <b>MNIST Dataset</b> \u2014 conx 3.7.9 documentation", "url": "https://conx.readthedocs.io/en/latest/MNIST.html", "isFamilyFriendly": true, "displayUrl": "https://conx.readthedocs.io/en/latest/MNIST.html", "snippet": "During training, a <b>randomly</b> chosen <b>subset</b> of units in a dropout layer (here, 20% of the units) will be turned off (<b>set</b> to zero activation) on each training cycle, with different random subsets being chosen on each cycle. Dropout only occurs during training; after the network has learned, all units participate in the classification of input <b>data</b>.", "dateLastCrawled": "2022-01-31T00:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "COMPARISON OF <b>SUBSAMPLING</b> TECHNIQUES FOR RANDOM SUBSPACE ENSEMBLES", "url": "https://www.eng.utoledo.edu/~gserpen/Publications/ICMLC%202010%20Manuscript.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.eng.utoledo.edu/~gserpen/Publications/ICMLC 2010 Manuscript.pdf", "snippet": "dimensional feature space is projected onto a <b>set</b> of lower dimensions by <b>selecting</b> random feature subsets or subsamples from the original <b>set</b>. The lower-dimensional projections <b>can</b> be generated using a variety of techniques based on random <b>subsampling</b>. The three such specific methods used for the generation of the random subsamples of the original feature space, as presented in this paper, are: (1) random sampling without replacement, (2) random sampling with replacement, prediction. and (3 ...", "dateLastCrawled": "2022-01-23T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Ultimate Guide to <b>AdaBoost</b>, random forests ... - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/the-ultimate-guide-to-adaboost-random-forests-and-xgboost-7f9327061c4f", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/the-ultimate-guide-to-<b>adaboost</b>-random-forests-and-xg...", "snippet": "<b>Compared</b> to random forests and XGBoost, ... Chen &amp; Guestrin introduce shrinkage (i.e. a learning rate) and column <b>subsampling</b> (<b>randomly</b> <b>selecting</b> <b>a subset</b> of features) to this gradient tree boosting algorithm which allows further reduction of overfitting. It therefore adds the methods to handle overfitting introduced in <b>AdaBoost</b> (the learning rate) and random forests (column or feature <b>subsampling</b>) to the regularization parameter found in stochastic gradient descent models. Overview of the ...", "dateLastCrawled": "2022-01-31T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Quality Assurance Techniques in <b>Data</b> Annotation - Ango AI", "url": "https://ango.ai/quality-assurance-techniques-in-data-annotation/", "isFamilyFriendly": true, "displayUrl": "https://ango.ai/quality-assurance-techniques-in-<b>data</b>-annotation", "snippet": "<b>Subsampling</b>: A common statistical technique used to determine the distribution of <b>data</b>, this refers <b>to randomly</b> <b>selecting</b> and keenly observing <b>a subset</b> of the annotated <b>data</b> to check for possible errors. If the sample is random and representative <b>of the data</b>, this <b>can</b> give a good indication of where errors are prone to occur.", "dateLastCrawled": "2022-01-29T07:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 10 <b>Subsampling</b> | From Scratch", "url": "https://www.paltmeyer.com/fromScratch/subsample.html", "isFamilyFriendly": true, "displayUrl": "https://www.paltmeyer.com/fromScratch/subsample.html", "snippet": "Chapter 10 <b>Subsampling</b>. When working with very large sample <b>data</b>, even the estimation of ordinary least-squares <b>can</b> be computationally prohibitive. Since we increasingly find ourselves in situations where the sample size \\(n\\) is extremely high, a body of literature concerned with optimal <b>subsampling</b> has recently emerged. This post summarises some of the main ideas and methodologies that have emerged from that literature.", "dateLastCrawled": "2022-01-20T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A subsampled double bootstrap for massive <b>data</b>", "url": "https://publish.illinois.edu/xshao/files/2015/08/SDB.pdf", "isFamilyFriendly": true, "displayUrl": "https://publish.illinois.edu/xshao/files/2015/08/SDB.pdf", "snippet": "procedure consists of <b>randomly</b> <b>selecting</b> small subsets <b>of the data</b>, and then performing a bootstrap on each <b>subset</b>, by constructing weighted resamples of the <b>subset</b> such that the resample size equals the size of the original <b>data</b>. The estimator is calculated on these resamples in the same manner as bootstrap. It is worth noting that this method bears some resemblance to the traditional <b>subsampling</b> (Politis and Romano (1994a)) or mout of nbootstrap (Bickel, G otze, and van Zwet (1997)), which ...", "dateLastCrawled": "2022-02-02T20:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Information-based Optimal Subdata Selection for Big <b>Data</b> Logistic ...", "url": "https://ossifragus.github.io/pdfs/IBOSS_Logistic.pdf", "isFamilyFriendly": true, "displayUrl": "https://ossifragus.github.io/pdfs/IBOSS_Logistic.pdf", "snippet": "framework of <b>selecting</b> subsets of <b>data</b> for logistic regression models. We show that, while the information contained in the subdata based on random sampling approaches is limited by the size of the <b>subset</b>, the information contained in the subdata based on the new framework increases as the size of the full <b>data</b> <b>set</b> increases. Performances of the proposed approach and that of other existing methods are <b>compared</b> under various criteria via extensive simulation studies. Keywords: D-Optimality ...", "dateLastCrawled": "2022-01-21T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Data</b> <b>quality assessment and subsampling strategies</b> to correct ...", "url": "https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01277-y", "isFamilyFriendly": true, "displayUrl": "https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01277-y", "snippet": "The procedures selected hospitals with higher <b>data</b> quality, especially the Probability procedure (lower QS in 100% of bootstrap simulations). The Distance procedure produced lower HAI prevalence estimates (6.98% <b>compared</b> to 7.44% in the convenience sample), more in line with the European median. The QS and the <b>subsampling</b> procedures proposed in ...", "dateLastCrawled": "2022-01-23T02:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "An analysis of the impact of <b>subsampling</b> on the neural network error ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231221013813", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231221013813", "snippet": "Fig. 8 presents a critical difference plot illustrating significant differences in Skew between partial estimates, and the fully informed estimated. From Fig. 8 it <b>can</b> be seen that Skew tended to increase as training examples were added, with the Skew of partial estimates 10, 9, 1, 6, and the fully informed estimate being significantly higher than the Skew of partial estimate 2. This suggests that the quality of weight vectors tended to improve as the size of the training <b>set</b> increased when ...", "dateLastCrawled": "2021-11-24T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Prediction settings \u2014 <b>Dataiku</b> DSS 10.0 documentation", "url": "https://doc.dataiku.com/dss/latest/machine-learning/supervised/settings.html", "isFamilyFriendly": true, "displayUrl": "https://doc.<b>dataiku</b>.com/dss/latest/machine-learning/supervised/<b>set</b>tings.html", "snippet": "By default, DSS <b>randomly</b> splits the input dataset into a training and a test <b>set</b>. The fraction of <b>data</b> used for training <b>can</b> be specified in DSS. 80% is a standard fraction of <b>data</b> to use for training. By enabling the \u201cTime-based ordering\u201d option you will ensure that this split is done according to the order induced by a variable to specify, instead of <b>randomly</b>. <b>Subsampling</b> \u00b6 Furthermore, depending on the engine DSS <b>can</b> perform this split, random or sorted, from a subsample of the ...", "dateLastCrawled": "2022-01-29T13:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>subsampling</b> machine learning? - Quora", "url": "https://www.quora.com/What-is-subsampling-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>subsampling</b>-machine-learning", "snippet": "Answer: Running algorithms which require the full <b>data</b> <b>set</b> for each update <b>can</b> be expensive when the <b>data</b> is large. In order to scale inferences, we <b>can</b> do <b>data</b> <b>subsampling</b>, i.e., update inference using only a subsample of <b>data</b> at a time. (Note that only certain algorithms support <b>data</b> subsampli...", "dateLastCrawled": "2022-01-03T14:41:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classifying and completing word analogies by <b>machine</b> <b>learning</b> | Request PDF", "url": "https://www.researchgate.net/publication/349152012_Classifying_and_completing_word_analogies_by_machine_learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/349152012_Classifying_and_completing_word...", "snippet": "Viewing words as vectors in a multi-dimensional space, we depart from the traditional parallelogram view of <b>analogy</b> to adopt a purely <b>machine</b>-<b>learning</b> approach. In some sense, we learn a ...", "dateLastCrawled": "2021-11-11T17:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Solving Word <b>Analogies: A Machine Learning Perspective</b> | Request PDF", "url": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_Machine_Learning_Perspective", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_<b>Machine</b>...", "snippet": "We introduce a supervised corpus-based <b>machine</b> <b>learning</b> algorithm for classifying analogous word pairs, and we show that it can solve multiple-choice SAT <b>analogy</b> questions, TOEFL synonym questions ...", "dateLastCrawled": "2021-10-16T21:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>learning</b>: Trends, perspectives, and prospects", "url": "https://www.science.org/doi/10.1126/science.aaa8415", "isFamilyFriendly": true, "displayUrl": "https://www.science.org/doi/10.1126/science.aaa8415", "snippet": "A diverse array of <b>machine</b>-<b>learning</b> algorithms has been developed to cover the wide variety of data and problem types exhibited across different <b>machine</b>-<b>learning</b> problems (1, 2). Conceptually, <b>machine</b>-<b>learning</b> algorithms can be viewed as searching through a large space of candidate programs, guided by training experience, to find a program that optimizes the performance metric. <b>Machine</b>-<b>learning</b> algorithms vary greatly, in part by the way in which they represent candidate programs (e.g ...", "dateLastCrawled": "2022-01-30T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Swamping and <b>Masking</b> in Anomaly detection: How <b>Subsampling</b> in Isolation ...", "url": "https://medium.com/walmartglobaltech/swamping-and-masking-in-anomaly-detection-how-subsampling-in-isolation-forests-helps-mitigate-bb192a8f8dd5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/walmartglobaltech/swamping-and-<b>masking</b>-in-anomaly-detection-how...", "snippet": "Isolation Forests achieve high anomaly detection performance with high efficiency with a very small <b>subsampling</b> size unlike most of the anomaly detection algorithms in which larger the sampling ...", "dateLastCrawled": "2022-01-30T21:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Word2Vec in Gensim Explained for Creating Word Embedding Models ...", "url": "https://machinelearningknowledge.ai/word2vec-in-gensim-explained-for-creating-word-embedding-models-pretrained-and-custom/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>knowledge.ai/word2vec-in-gensim-explained-for-creating-word...", "snippet": "<b>Machine</b> <b>learning</b> and ... This is another way putting that word2vec can draw the <b>analogy</b> that if Man is to Woman then Kind is to Queen! The publicly released model of word2vec by Google consists of 300 features and the model is trained in the Google news dataset. The vocabulary size of the model is around 1.6 billion words. However, this might have taken a huge time for the model to be trained on but they have applied a method of simple <b>subsampling</b> approach to optimize the time. Word2Vec ...", "dateLastCrawled": "2022-02-02T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "CPSC 540: <b>Machine</b> <b>Learning</b>", "url": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/L12.5.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/L12.5.pdf", "snippet": "CPSC 540: <b>Machine</b> <b>Learning</b> Fenchel Duality and Large-Scale Kernel Methods Mark Schmidt University of British Columbia Winter 2018. Fenchel Duality Large-Scale Kernel Methods Outline 1 Fenchel Duality 2 Large-Scale Kernel Methods. Fenchel Duality Large-Scale Kernel Methods Motvation: Getting Rid of the Step-Size SVMsare a widely-used model but objective isnon-di erentiable. We can\u2019t apply coordinate optimization or proximal-gradient or SAG. The non-di erentiable part is the loss, which isn ...", "dateLastCrawled": "2021-12-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning and Computer Vision Group</b>", "url": "https://cvml.ist.ac.at/courses/DLWT_W18/material/word2vec.pdf", "isFamilyFriendly": true, "displayUrl": "https://cvml.ist.ac.at/courses/DLWT_W18/material/word2vec.pdf", "snippet": "In <b>machine</b> <b>learning</b>, we usually represent quantities as vectors (or tensors). Strings are difficult to operate on. How can we have a vector for each word? One - Hot vectors Only one entry is 1, rest are all 0s. Vector length = size of vocabulary (can be ~1,000,000 !) They are all orthogonal, no measure of similarity Can we do better? Vocabulary size (|V|) The Idea Represent words as dense vectors that capture semantic and syntactic similarity. That is, similar words should have similar ...", "dateLastCrawled": "2021-08-10T23:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Neural Networks &amp; Word Embeddings | by Nwamaka Imasogie | Nwamaka ...", "url": "https://medium.com/nwamaka-imasogie/neural-networks-word-embeddings-8ec8b3845b2e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/nwamaka-imasogie/neural-networks-word-embeddings-8ec8b3845b2e", "snippet": "In this Google paper they found that by <b>subsampling</b> of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to t", "dateLastCrawled": "2022-01-20T20:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Stochastic Gradient Descent</b> \u2014 Clearly Explained !! | by Aishwarya V ...", "url": "https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>stochastic-gradient-descent</b>-clearly-explained-53d239905d31", "snippet": "<b>Stochastic gradient descent</b> is a very popular and common algorithm used in various <b>Machine</b> <b>Learning</b> algorithms, most importantly forms the basis of Neural Networks. In this article, I have tried my best to explain it in detail, yet in simple terms. I highly recommend going through linear regression before proceeding with this article. What is the objective of <b>Gradient Descent</b>? Gradient, in plain terms means slope or slant of a surface. So <b>gradient descent</b> literally means descending a slope ...", "dateLastCrawled": "2022-02-02T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "classification - Extending the idea of Bootstrapping to Train Test ...", "url": "https://stats.stackexchange.com/questions/296493/extending-the-idea-of-bootstrapping-to-train-test-splits-of-a-dataset-used-to-le", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/296493/extending-the-idea-of-bootstrapping...", "snippet": "In <b>Machine</b> <b>Learning</b> the standard practice for <b>learning</b> a Classifier --e.g. fitting a Logistic Regression model-- and then validating its performance is to split the original/available Dataset into a train and test dataset randomly --typically 70% of the data used for training and 30% for validation. Using the training dataset you fit a model -- possibly using k-fold cross-validation on the training dataset -- and then make predictions on the Test (Unseen / Out of Sample) dataset. You measure ...", "dateLastCrawled": "2022-01-19T13:38:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Gradient Boosting</b> - Overview, Tree Sizes, Regularization", "url": "https://corporatefinanceinstitute.com/resources/knowledge/other/gradient-boosting/", "isFamilyFriendly": true, "displayUrl": "https://corporatefinanceinstitute.com/resources/knowledge/other/<b>gradient-boosting</b>", "snippet": "<b>Subsampling is similar</b> to bagging, where they allow the definition of out-of-bag errors in the improvement of prediction performance. By evaluating previous predictions, the base learners can correct the shortcomings to improve on the prediction at hand. Estimating the out-of-bag errors helps in avoiding the validation of data sets independently. Tree Complexity Penalization. Another <b>gradient boosting</b> regularization method is to penalize the complexity of trees. The complexity of a model can ...", "dateLastCrawled": "2022-02-02T06:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>A hybrid deep learning CNN\u2013ELM for age and gender classification</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231217314923", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231217314923", "snippet": "<b>Subsampling is similar</b> to a fuzzy filter which is primary to re-extract features from the convolutional layers. With the local correlation principle, the operations of subsampling not only eliminate non-maximal values and reduce computations for previous layer, but also improve the ability of distortion tolerance of the networks and provide additional robustness to position. These features will be encoded into a 1-D vectors in the full connection layer. After that, these vectors will be ...", "dateLastCrawled": "2022-01-24T05:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Example of How to Construct 1D Convolutional Net on Text \u00b7 Issue #233 ...", "url": "https://github.com/keras-team/keras/issues/233", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/keras-team/keras/issues/233", "snippet": "Also there is a subsample_length (1d) and subsample (2d) in the cnn layers, i have read that <b>subsampling is similar</b> to pooling. If i added the subsample option to my cnn layer would i skip pooling? Sorry about all the questions, i&#39;ve spent hours looking for examples and trying to understand CNN&#39;s. I have a good concept of what they are, whats ...", "dateLastCrawled": "2022-01-19T15:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Histograms of Motion Gradients for Real-time Video Classification</b>", "url": "https://www.researchgate.net/publication/304149735_Histograms_of_Motion_Gradients_for_Real-time_Video_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/304149735_<b>Histograms_of_Motion_Gradients_for</b>...", "snippet": "The modality of frame <b>subsampling is similar</b> as . in the work [25]. For a fair comparison, the descriptors describe. the same video volume for the process of subsampling frames. For instance, if ...", "dateLastCrawled": "2022-01-02T08:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Statistical tests and identifiability conditions for pooling and</b> ...", "url": "https://www.pnas.org/content/115/7/1481", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/115/7/1481", "snippet": "These issues are not restricted to biomedical studies, and variously manifest in <b>machine</b> <b>learning</b> and computer vision, where distinct datasets must be pooled (e.g., for training a statistical model). While the literature on addressing sample selection bias and compensating for population characteristics differences is sizable 12, 13), statistical frameworks for resolving distributional shift to facilitate pooled analysis, essential in various applications, are less developed in comparison ...", "dateLastCrawled": "2021-08-21T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "It is common to use the softmax to yield probabilistic predictions of ...", "url": "https://www.coursehero.com/file/p50078l7/It-is-common-to-use-the-softmax-to-yield-probabilistic-predictions-of-discrete/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p50078l7/It-is-common-to-use-the-softmax-to-yield...", "snippet": "Pages 512 ; Ratings 100% (1) 1 out of 1 people found this document helpful; This preview shows page 205 - 207 out of 512 pages.preview shows page 205 - 207 out of 512 pages.", "dateLastCrawled": "2021-11-13T16:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Charu C. Aggarwal - Machine Learning For Text</b> (2018, Springer ...", "url": "https://www.scribd.com/document/401620463/Charu-C-Aggarwal-Machine-Learning-for-Text-2018-Springer-pdf", "isFamilyFriendly": true, "displayUrl": "https://www.<b>scribd</b>.com/document/401620463/<b>Charu-C-Aggarwal-Machine-Learning-for-Text</b>...", "snippet": "Most <b>machine</b> <b>learning</b> applications in the text domain work with the bag-of-words repre-sentation in which the words are treated as dimensions with values corresponding to word frequencies. A data set corresponds to a collection of documents, which is also referred to as a corpus. The complete and distinct set of words used to de\ufb01ne the corpus is also referred to as the lexicon. Dimensions are also referred to as terms or features. Some applications of text work with a binary representation ...", "dateLastCrawled": "2022-01-01T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Neural Networks and <b>Deep Learning: A Textbook 9783319944630, 3319944630</b> ...", "url": "https://dokumen.pub/neural-networks-and-deep-learning-a-textbook-9783319944630-3319944630.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/neural-networks-and-<b>deep-learning-a-textbook-9783319944630</b>...", "snippet": "The performance of traditional <b>machine</b> <b>learning</b> remains better at times for smaller data sets because of more choices, greater ease of model interpretation, and the tendency to hand-craft interpretable features that incorporate domain-speci\ufb01c insights. With limited data, the best of a very wide diversity of models in <b>machine</b> <b>learning</b> will usually perform better than a single class of models (like neural networks). This is one reason why the potential of neural networks was not realized in ...", "dateLastCrawled": "2022-01-28T02:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Not Too Hot, <b>Not Too Cold: The Bundled-SVM is Just Right</b>!", "url": "https://www.researchgate.net/publication/2945326_Not_Too_Hot_Not_Too_Cold_The_Bundled-SVM_is_Just_Right", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/2945326_Not_Too_Hot_<b>Not_Too_Cold_The_Bundled</b>...", "snippet": "The Support Vector <b>Machine</b> (SVM) typically outperforms other algorithms on text classification problems, but requires training time roughly quadratic in the number of training documents.", "dateLastCrawled": "2021-11-10T06:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Handbook of Integration of <b>Cloud Computing, Cyber Physical Systems</b> and ...", "url": "https://dokumen.pub/handbook-of-integration-of-cloud-computing-cyber-physical-systems-and-internet-of-things-9783030437947-9783030437954.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/handbook-of-integration-of-<b>cloud-computing-cyber-physical-systems</b>...", "snippet": "6 <b>Machine</b> <b>Learning</b> Based Modeling 7 Real-World Data Proxy Examples 7.1 Proxy Model 7.2 Costs 7.3 Objectives &amp; Constraints 7.4 Results 8 Conclusions 8.1 Future References A Multi-level Monitoring Framework for Containerized Self-Adaptive Early Warning Applications 1 Introduction 2 Basic Framework of an Early Warning System 3 Monitoring Requirements 3.1 VM-Level Monitoring 3.2 P2P Link Quality Monitoring 3.3 Container-Level Monitoring 3.4 Application-Level Monitoring 4 Architecture of our ...", "dateLastCrawled": "2022-01-04T04:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "US6535819B1 - Optimal dissimilarity method for choosing distinctive ...", "url": "https://patents.google.com/patent/US6535819B1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US6535819B1/en", "snippet": "The method of this invention identifies distinctive items of information from a larger body of information on the basis of similarities or dissimilarities among the items and achieves a significant increase in speed as well as the ability to balance the representativeness and diversity among the identified items by applying selection criteria to randomly chosen subsamples of all the information. The method is illustrated with reference to the compound selection requirements of medicinal ...", "dateLastCrawled": "2022-01-13T10:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Using natural language processing techniques to extract information on ...", "url": "https://deepai.org/publication/using-natural-language-processing-techniques-to-extract-information-on-the-properties-and-functionalities-of-energetic-materials-from-large-text-corpora", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/using-natural-language-processing-techniques-to-extract...", "snippet": "<b>Subsampling can be thought of as</b> a probabilistic variant of stop word removal. 2.2 GloVe. The GloVe (\u201cGlobal Vector\u201d) word embedding, introduced by Pennington et al. in 2014, takes a very different approach to generating word embeddings RN327 . In GloVe, word vectors are used to reproduce the co-occurrence matrix X i j as faithfully as possible. Each element in the co-occurrence matrix tabulates the probability (inverse frequency) with which word i appears in the context of word j, where ...", "dateLastCrawled": "2021-12-27T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "An <b>Investigation of Newton-Sketch and Subsampled Newton Methods</b> | DeepAI", "url": "https://deepai.org/publication/an-investigation-of-newton-sketch-and-subsampled-newton-methods", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/an-<b>investigation-of-newton-sketch-and-subsampled-newton</b>...", "snippet": "The Newton-Sketch method is a randomized approximation of Newton\u2019s method. It solves an approximate version of the Newton equations using an unbiased estimator of the true Hessian (Hessian Sketch; see [18, 22]), based on a decomposition of reduced dimension that takes into account all n components of (1.1).The Newton-Sketch method has been tested only on a few synthetic problems and its efficiency on practical problems has not yet been explored, to the best of our knowledge.", "dateLastCrawled": "2022-01-01T17:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Using natural language processing techniques</b> to extract ...", "url": "https://www.researchgate.net/publication/331485271_Using_natural_language_processing_techniques_to_extract_information_on_the_properties_and_functionalities_of_energetic_materials_from_large_text_corpora", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/331485271_Using_natural_language_processing...", "snippet": "<b>Subsampling can be thought of as</b> a probabilistic variant of stop word removal. 2.2 GloV e. The GloV e (\u201cGlobal V ector\u201d) word embedding, introduced by Pennington et al. in 2014, takes a very ...", "dateLastCrawled": "2021-11-04T00:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "An Investigation of Newton-Sketch and Subsampled Newton Methods", "url": "http://www.optimization-online.org/DB_FILE/2017/05/6013.pdf", "isFamilyFriendly": true, "displayUrl": "www.optimization-online.org/DB_FILE/2017/05/6013.pdf", "snippet": "Keywords: sketching, subsampling, Newton\u2019s method, <b>machine</b> <b>learning</b>, stochastic optimization 1 Introduction In this paper, we consider second order methods for solving the nite sum problem, min w2Rd F(w) = 1 n Xn i=1 Fi(w); (1.1) \u2217Department of Industrial and Systems Engineering, Lehigh University. albertberahas@gmail.com This author was supported by the Defense Advanced Research Projects Agency (DARPA). \u2020Department of Industrial Engineering and Management Sciences, Northwestern ...", "dateLastCrawled": "2021-11-04T08:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "An Investigation of Newton-Sketch and Subsampled Newton Methods \u2013 arXiv ...", "url": "https://www.arxiv-vanity.com/papers/1705.06211/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1705.06211", "snippet": "The concepts of sketching and subsampling have recently received much attention by the optimization and statistics communities. In this paper, we study Newton-Sketch and Subsampled Newton (SSN) methods for the finite-sum optimization problem. We consider practical versions of the two methods in which the Newton equations are solved approximately using the conjugate gradient (CG) method or a stochastic gradient iteration. We establish new complexity results for the SSN-CG method that exploit ...", "dateLastCrawled": "2022-02-02T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "USING NATURAL LANGUAGE PROCESSING TECHNIQUES TO EXTRACT INFORMATION ON ...", "url": "https://ideal.umd.edu/assets/pdfs/2019_nlp_for_extracting_info_on_chemicals_NTREM.pdf", "isFamilyFriendly": true, "displayUrl": "https://ideal.umd.edu/assets/pdfs/2019_nlp_for_extracting_info_on_chemicals_NTREM.pdf", "snippet": "techniques from natural language processing and <b>machine</b> <b>learning</b> can be used to automatically extract chemical insights from large collections of documents. We \ufb01rst describe how to download and process documents from a variety of sources - journal articles, conference proceedings (including NTREM), the US Patent &amp; Trademark Of\ufb01ce, and the Defense Technical Information Center archive on archive.org. We present a custom NLP pipeline which uses open source NLP tools to identify the names of ...", "dateLastCrawled": "2022-01-23T11:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Using natural language processing techniques to extract ...", "url": "https://www.academia.edu/38684545/Using_natural_language_processing_techniques_to_extract_information_on_the_properties_and_functionalities_of_energetic_materials_from_large_text_corpora", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/38684545", "snippet": "The number of scientific journal articles and reports being published about energetic materials every year is growing exponentially, and therefore extracting relevant information and actionable insights from the latest research is becoming a", "dateLastCrawled": "2021-12-28T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Convergence rates of sub-sampled Newton methods</b>", "url": "https://www.researchgate.net/publication/280970229_Convergence_rates_of_sub-sampled_Newton_methods", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/280970229_<b>Convergence_rates_of_sub-sampled</b>...", "snippet": "Several variants <b>of subsampled Newton methods</b> have been proposed and analyzed for solving (strongly) convex formulations of problem (11) [68,69, 25, 9,87]. All of these methods use B k = \u2207 2 S k ...", "dateLastCrawled": "2021-12-24T09:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "WO2004036461A2 - Information reservoir - Google Patents", "url": "https://patents.google.com/patent/WO2004036461A2/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/WO2004036461A2/en", "snippet": "Approximate answers to queries are provided by executing queries against a representation of a data source in addition to, or in lieu of accessing the source data itself. A repres", "dateLastCrawled": "2021-12-20T19:51:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(subsampling)  is like +(randomly selecting a subset of the data set)", "+(subsampling) is similar to +(randomly selecting a subset of the data set)", "+(subsampling) can be thought of as +(randomly selecting a subset of the data set)", "+(subsampling) can be compared to +(randomly selecting a subset of the data set)", "machine learning +(subsampling AND analogy)", "machine learning +(\"subsampling is like\")", "machine learning +(\"subsampling is similar\")", "machine learning +(\"just as subsampling\")", "machine learning +(\"subsampling can be thought of as\")", "machine learning +(\"subsampling can be compared to\")"]}