{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Tutorial on <b>Fairness</b> in Machine Learning | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-machine-learning-3ff8ba1040cb", "snippet": "Any <b>two</b> of the three group <b>fairness</b> definitions demographic <b>parity</b>, equalized odds, and <b>predictive</b> <b>rate</b> <b>parity</b> cannot be achieved at <b>the same</b> time except in degenerate cases. Trade-off between accuracy and <b>fairness</b> usually exists.", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Machine Learning Glossary: <b>Fairness</b> | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/fairness", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/glossary/<b>fairness</b>", "snippet": "For example, a model that predicts college acceptance would satisfy <b>predictive</b> <b>parity</b> for nationality if its precision <b>rate</b> is <b>the same</b> for Lilliputians and Brobdingnagians. <b>Predictive</b> <b>parity</b> is sometime also called <b>predictive</b> <b>rate</b> <b>parity</b>. See &quot;<b>Fairness</b> Definitions Explained&quot; (section 3.2.1) for a more detailed discussion of <b>predictive</b> <b>parity</b>.", "dateLastCrawled": "2022-02-02T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Measuring <b>Fairness</b> in Machine Learning Models", "url": "https://blog.dataiku.com/measuring-fairness-in-machine-learning-models", "isFamilyFriendly": true, "displayUrl": "https://blog.dataiku.com/measuring-<b>fairness</b>-in-machine-learning-models", "snippet": "<b>Predictive</b> <b>Rate</b> <b>Parity</b>. A slightly similar <b>fairness</b> definition is <b>predictive</b> <b>rate</b> <b>parity</b> and was introduced by Dieterich, Mendoza and Brennan. A model satisfies <b>predictive</b> <b>rate</b> <b>parity</b> if the likelihood of the positive observation of the target variable among <b>people</b> predicted with the positive outcome is independent from the subpopulation.", "dateLastCrawled": "2022-01-25T22:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The Myth of the <b>Impartial Machine</b> - parametric.press", "url": "https://parametric.press/issue-01/the-myth-of-the-impartial-machine/", "isFamilyFriendly": true, "displayUrl": "https://parametric.press/issue-01/the-myth-of-the-<b>impartial-machine</b>", "snippet": "In the simplified recidivism model below, the <b>predictive</b> <b>parity</b> rule has been imposed such that for both groups, 67% of <b>people</b> that are labeled as \u201chigh risk\u201d indeed get rearrested. Play with the model by setting the total number of <b>people</b> in Group A that are labeled as \u201chigh risk\u201d. Can you set this number such that the model achieves equal false negative rates in addition to <b>predictive</b> <b>parity</b>? Is there a value that allows the model to achieve equal false positive and false negative ...", "dateLastCrawled": "2022-02-03T05:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Interest <b>Rate</b> <b>Parity</b> (IRP) Definition", "url": "https://www.investopedia.com/terms/i/interestrateparity.asp", "isFamilyFriendly": true, "displayUrl": "https://<b>www.investopedia.com</b>/terms/i/interest<b>rateparity</b>.asp", "snippet": "Interest <b>rate</b> <b>parity</b> is the fundamental equation that governs the relationship between interest rates and currency exchange rates. The basic premise of interest <b>rate</b> <b>parity</b> is that hedged returns ...", "dateLastCrawled": "2022-02-02T23:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "Heidari et al. <b>have</b> written a paper comparing the three criteria \u2013 demographic <b>parity</b>, equality of opportunity, and <b>predictive</b> <b>parity</b> \u2013 to egalitarianism, equality of opportunity (EOP) in the Rawlsian sense, and EOP seen through the glass of luck egalitarianism, respectively. While the analogy is fascinating, it too assumes that we may take what is in the data at face value. In their likening <b>predictive</b> <b>parity</b> to luck egalitarianism, they <b>have</b> to go to especially great lengths, in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Fairness Definitions Explained (Research Summary) | Montreal AI Ethics ...", "url": "https://montrealethics.ai/fairness-definitions-explained-research-summary/", "isFamilyFriendly": true, "displayUrl": "https://montrealethics.ai/fairness-definitions-explained-research-summary", "snippet": "False Discovery <b>Rate</b> (FDR) : This is the probability of false (or wrong) acceptance. ... Members from both the protected and unprotected group <b>have</b> <b>the same</b> probability of being assigned to the positive predicted class. In the case of the credit example, this means that regardless of gender, you <b>have</b> an equal probability of being assigned a good credit score. Note that the above is also called equal acceptance <b>rate</b>, benchmarking, and statistical <b>parity</b> (not to be confused with the following ...", "dateLastCrawled": "2022-01-20T19:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is <b>Sensitivity, Specificity, False positive, False negative</b>?", "url": "https://microbenotes.com/sensitivity-specificity-false-positive-false-negative/", "isFamilyFriendly": true, "displayUrl": "https://microbenotes.com/<b>sensitivity-specificity-false-positive-false-negative</b>", "snippet": "It is also known as the True Negative <b>Rate</b> ... You <b>have</b> a sample size of 600 <b>people</b> and by validity, there are samples that you know definitely <b>have</b> the disease (480) and/or healthy individual samples from the disease in question (120). After running the test, then you compare the results to their know disease staus and find that: True positive (test positive and are correctly positive) = 480; False-positive (test positive but are actually negative) = 15; True negative (test negative and are ...", "dateLastCrawled": "2022-02-02T20:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Bias in <b>predictive</b> models \u2014 part 1/2 | by Stas Cherkassky | Towards ...", "url": "https://towardsdatascience.com/bias-in-predictive-models-part-1-2-ebba5c9ab94b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/bias-in-<b>predictive</b>-models-part-1-2-ebba5c9ab94b", "snippet": "There are problems <b>like</b> medical diagnosis where chances to <b>have</b> some condition may directly depend on sex. In other problems, the meaning of some parameters may depend on gender indirectly. For example, in CV analysis, certain gaps in employment for women may indicate maternity leave which has different meaning compared to employment gaps when a person couldn\u2019t or wouldn\u2019t get a job. In summary, sometimes it\u2019s ok, or even desirable to refer to protected variables, and not referring to ...", "dateLastCrawled": "2022-01-22T01:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>MKT 310 Exam 3 SG</b> Flashcards | Quizlet", "url": "https://quizlet.com/538816028/mkt-310-exam-3-sg-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/538816028/<b>mkt-310-exam-3-sg</b>-flash-cards", "snippet": "Inflation occurs when incomes are reduced and <b>people</b> <b>have</b> less money to purchase goods and services. c. Inflation occurs when the money supply in a country out paces the level of production of goods and services. When the growth in a country&#39;s money supply is faster than the growth in its output of goods, _____ tends to increase. a. the exchange <b>rate</b> b. price inflation c. direct investment d. trade exports. b. price inflation. The failure to find a link between which <b>two</b> of the following ...", "dateLastCrawled": "2022-01-12T18:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Machine Learning Glossary: <b>Fairness</b> | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/fairness", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/glossary/<b>fairness</b>", "snippet": "For example, a model that predicts college acceptance would satisfy <b>predictive</b> <b>parity</b> for nationality if its precision <b>rate</b> is <b>the same</b> for Lilliputians and Brobdingnagians. <b>Predictive</b> <b>parity</b> is sometime also called <b>predictive</b> <b>rate</b> <b>parity</b>. See &quot;<b>Fairness</b> Definitions Explained&quot; (section 3.2.1) for a more detailed discussion of <b>predictive</b> <b>parity</b>.", "dateLastCrawled": "2022-02-02T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Tutorial on <b>Fairness</b> in Machine Learning | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-machine-learning-3ff8ba1040cb", "snippet": "Any <b>two</b> of the three group <b>fairness</b> definitions demographic <b>parity</b>, equalized odds, and <b>predictive</b> <b>rate</b> <b>parity</b> cannot be achieved at <b>the same</b> time except in degenerate cases. Trade-off between accuracy and <b>fairness</b> usually exists.", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "<b>Predictive</b> <b>parity</b> suggests that <b>people</b> classified similarly (\\(\\hat{Y}\\) ... demand that these metrics be <b>the same</b> across groups, we arrive at corresponding fairness criteria: equal false positive <b>rate</b>, equal positive <b>predictive</b> value, etc. In the inter-group setting, the <b>two</b> types of metrics may be arranged under headings \u201cequality of opportunity\u201d and \u201c<b>predictive</b> <b>parity</b>.\u201d You\u2019ll encounter these as actual headers in the summary table at the end of this text. Said table organizes ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Measuring <b>Fairness</b> in Machine Learning Models", "url": "https://blog.dataiku.com/measuring-fairness-in-machine-learning-models", "isFamilyFriendly": true, "displayUrl": "https://blog.dataiku.com/measuring-<b>fairness</b>-in-machine-learning-models", "snippet": "<b>Predictive</b> <b>Rate</b> <b>Parity</b>. A slightly <b>similar</b> <b>fairness</b> definition is <b>predictive</b> <b>rate</b> <b>parity</b> and was introduced by Dieterich, Mendoza and Brennan. A model satisfies <b>predictive</b> <b>rate</b> <b>parity</b> if the likelihood of the positive observation of the target variable among <b>people</b> predicted with the positive outcome is independent from the subpopulation.", "dateLastCrawled": "2022-01-25T22:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is fair machine learning? Depends on your definition of fair ...", "url": "https://blogs.ischool.berkeley.edu/w231/2021/07/09/what-is-fair-machine-learning-depends-on-your-definition-of-fair/", "isFamilyFriendly": true, "displayUrl": "https://blogs.ischool.berkeley.edu/w231/2021/07/09/what-is-fair-machine-learning...", "snippet": "Another definition known as <b>predictive</b> <b>parity</b> would ensure <b>similar</b> fractions of ... In fact, because the base recidivism <b>rate</b> for both groups was not <b>the same</b>, researchers proved that it wasn\u2019t possible for the tool to satisfy both definitions at once. This led to disagreement over whether or not the algorithm could be considered fair. Fairness can depend on the context. With multiple (and sometimes mutually exclusive) ways to measure fairness, choosing which one to apply requires ...", "dateLastCrawled": "2021-12-27T02:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Equality <b>and fairness measures in classification models</b> | Auditing ...", "url": "https://www.auditingalgorithms.net/EqualityAndFairness.html", "isFamilyFriendly": true, "displayUrl": "https://www.auditingalgorithms.net/EqualityAndFairness.html", "snippet": "Sufficiency (also called <b>predictive</b> <b>rate</b> <b>parity</b>): <b>Same</b> PPV and <b>same</b> NPV - that is the probability of a real positive or negative given a predicted positive or negative is equal It is important for auditors to understand that in the common case of different prevalence in different groups, no imperfect model can satisfy any <b>two</b> of the three fairness metrics at <b>the same</b> time.", "dateLastCrawled": "2022-01-21T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The accuracy, fairness, and limits of predicting recidivism", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5777393/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5777393", "snippet": "This subset yielded <b>similar</b> overall COMPAS accuracy, false-positive <b>rate</b>, and false-negative <b>rate</b> as the complete database (a positive prediction is one in which a defendant is predicted to recidivate; a negative prediction is one in which they are predicted to not recidivate). The COMPAS accuracy for this subset of 1000 defendants was 65.2%. The average COMPAS accuracy on 10,000 random subsets of size 1000 each was 65.4% with a 95% confidence interval of (62.6, 68.1).", "dateLastCrawled": "2022-02-02T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fairness Definitions Explained (Research Summary) | Montreal AI Ethics ...", "url": "https://montrealethics.ai/fairness-definitions-explained-research-summary/", "isFamilyFriendly": true, "displayUrl": "https://montrealethics.ai/fairness-definitions-explained-research-summary", "snippet": "Note that the above is also called equal acceptance <b>rate</b>, benchmarking, and statistical <b>parity</b> (not to be confused with the following definition) Conditional Statistical <b>Parity</b> : Extending the previous definitions, this definition allows for the inclusion of a group of legitimate factors that won\u2019t be considered discriminatory when included in the decision making process. So, controlling for these factors, the groups should <b>have</b> equal probabilities of landing with positive predicted values ...", "dateLastCrawled": "2022-01-20T19:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Bias in <b>predictive</b> models \u2014 part 1/2 | by Stas Cherkassky | Towards ...", "url": "https://towardsdatascience.com/bias-in-predictive-models-part-1-2-ebba5c9ab94b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/bias-in-<b>predictive</b>-models-part-1-2-ebba5c9ab94b", "snippet": "The naive application of the \u201cDemographic <b>Parity</b>\u201d would, of course, fail because 27% is far less than the <b>rate</b> of females in the general population. Intel could make this claim because they used as reference only females that were the graduates of relevant college degrees, as only them, according to Intel, constitute the pool of qualified female candidates.", "dateLastCrawled": "2022-01-22T01:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Myth of the <b>Impartial Machine</b> - parametric.press", "url": "https://parametric.press/issue-01/the-myth-of-the-impartial-machine/", "isFamilyFriendly": true, "displayUrl": "https://parametric.press/issue-01/the-myth-of-the-<b>impartial-machine</b>", "snippet": "Even when sub-groups are statistically <b>similar</b>, feedback loops can still lead to noisy and less accurate predictions. Algorithms where the <b>predictive</b> outcome determines what feedback the algorithm receives\u2014e.g. recidivism prediction, language translation, and social media news feeds\u2014should always be diligently monitored for the presence of feedback loops bias. Bias in data and in algorithms are interrelated. It should be clear by this point that bias in data and algorithms are ...", "dateLastCrawled": "2022-02-03T05:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Bias in Criminal Risk Scores Is Mathematically Inevitable, Researchers Say", "url": "https://www.courts.wa.gov/content/publicupload/eclips/2017%2001%2012%20Bias%20in%20Criminal%20Risk%20Scores%20Is%20Mathematically%20Inevitable%20Researchers%20Say.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.courts.wa.gov</b>/content/publicupload/eclips/2017 01 12 Bias in Criminal Risk...", "snippet": "\u201c<b>predictive</b> <b>parity</b>,\u201d inevitably leads to disparities in what sorts of <b>people</b> are incorrectly classified as high risk when <b>two</b> groups <b>have</b> different arrest rates. \u201c\u2019<b>Predictive</b> <b>parity</b>\u2019 actually corresponds to \u2018optimal discrimination,\u2019\u201d said Nathan Srebro, associate professor of computer science at the University of Chicago and the Toyota Technological Institute at Chicago. That\u2019s because <b>predictive</b> <b>parity</b> results in a higher proportion of black defendants being wrongly rated ...", "dateLastCrawled": "2022-01-20T18:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Algorithmic Fairness: Contemporary Ideas in the Insurance Context", "url": "https://www.actuaries.org.uk/system/files/field/document/B9_Chris%20Dolman.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.actuaries.org.uk/system/files/field/document/B9_Chris Dolman.pdf", "snippet": "\u2022 Argued that \u201c<b>predictive</b> <b>parity</b>\u201d ought to be the way we judge the fairness of the algorithm: \u2013 Of those <b>people</b> who were scored as \u201chigh risk\u201d, blacks did not recidivate at a <b>rate</b> of 37%, versus 41% for whites \u2013 Similarly, for those scored as \u201clow risk\u201d, the recidivism <b>rate</b> was 35% for blacks and 29% for whites", "dateLastCrawled": "2022-02-02T19:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding and Identifying Unfairness in Machine Learning | by ...", "url": "https://cannon-m-bray.medium.com/understanding-and-identifying-unfairness-in-machine-learning-80178a16357c", "isFamilyFriendly": true, "displayUrl": "https://<b>can</b>non-m-bray.medium.com/understanding-and-identifying-unfairness-in-machine...", "snippet": "<b>Predictive</b> <b>Parity</b>. Next, let\u2019s look at <b>predictive</b> <b>parity</b>, also known as the outcome test. Unlike group fairness, this metric takes into account the predicted outcomes and the actual outcomes. According to <b>predictive</b> <b>parity</b>, a classifier is considered fair if each level of a protected class has <b>the same</b> PPV, also known as precision.", "dateLastCrawled": "2022-01-21T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Framing the AI Fairness Question? | Bipartisan Policy Center", "url": "https://bipartisanpolicy.org/explainer/framing-the-ai-fairness-question/", "isFamilyFriendly": true, "displayUrl": "https://bipartisanpolicy.org/explainer/framing-the-ai-fairness-question", "snippet": "The university <b>can</b>, however, ensure <b>predictive</b> <b>parity</b> by making sure the students predicted to graduate end up graduating at similar rates across groups. A model with equal precision between groups will achieve \u2018<b>predictive</b> <b>parity</b>\u2019 for those predicted to graduate. Equal opportunity more closely resembles the idea of fairness from the students and society more broadly \u2013 ensuring those who would go on to graduate are given similar risk classifications. Violating this would mean that among ...", "dateLastCrawled": "2022-01-20T08:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Urbanization and Fertility: An Event-History Analysis of Coastal Ghana", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2834382/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2834382", "snippet": "The 2000 Ghana census recorded a national population of 18.9 million <b>people</b>, representing a 54% increase from the population of 12.3 million in 1984, the year of the previous census, as well as an intercensal growth <b>rate</b> of 2.7% (GSS 2002:1). The 2000 population of the Central Region was recorded to be about 1.6 million. The coastal Central Region was chosen because of our concern for urbanization in ecologically sensitive coastal zones in developing countries. The Central Region contains a ...", "dateLastCrawled": "2022-01-22T01:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "3 Common Ways to Forecast Currency Exchange Rates", "url": "https://www.investopedia.com/articles/forex/11/4-ways-to-forecast-exchange-rates.asp", "isFamilyFriendly": true, "displayUrl": "https://<b>www.investopedia.com</b>/articles/forex/11/4-ways-to-forecast-exchange-<b>rates</b>.asp", "snippet": "Many methods of forecasting currency exchange rates exist. Here, we&#39;ll look at a few of the most popular methods: purchasing power <b>parity</b>, relative economic strength, and econometric models. 1:47.", "dateLastCrawled": "2022-02-03T02:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Reprogramming Fairness: Affirmative Action in Algorithmic Criminal</b> ...", "url": "http://hrlr.law.columbia.edu/hrlr-online/reprogramming-fairness-affirmative-action-in-algorithmic-criminal-sentencing/", "isFamilyFriendly": true, "displayUrl": "hrlr.law.columbia.edu/hrlr-online/<b>reprogramming-fairness-affirmative-action-in</b>...", "snippet": "If the recidivism <b>rate</b> for white and black defendants is <b>the same</b> within each risk category, and if black defendants <b>have</b> a higher overall recidivism <b>rate</b>, then a greater share of black defendants will be classified as high risk. And if a greater share of black defendants are classified as high risk, then . . . a greater share of black defendants who do not reoffend will also be classified as high risk.", "dateLastCrawled": "2022-02-01T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Pay <b>parity</b>: What is it <b>and how does an employer get there</b>? | HR Dive", "url": "https://www.hrdive.com/news/pay-parity-what-is-it-and-how-does-an-employer-get-there/580504/", "isFamilyFriendly": true, "displayUrl": "https://www.hrdive.com/news/pay-<b>parity</b>-what-is-it-<b>and-how-does-an-employer-get-there</b>/...", "snippet": "The Institute for Women&#39;s Policy Research found that working women&#39;s poverty <b>rate</b> would be cut in half if women were paid <b>the same</b> as men. The study said that change would decrease the number of ...", "dateLastCrawled": "2022-02-01T06:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Defining fairness</b>. For our upcoming ethics book club on\u2026 | by DataKind ...", "url": "https://medium.com/datakinduk/defining-fairness-1e12586d4b36", "isFamilyFriendly": true, "displayUrl": "https://medium.com/datakinduk/<b>defining-fairness</b>-1e12586d4b36", "snippet": "Jul 1, 2019 \u00b7 5 min read. By Giselle Cory, Executive Director at DataKind UK. For our upcoming ethics book club on fairness in AI, we are \u2018reading\u2019 Arvind Narayanan\u2019s 21 definitions of ...", "dateLastCrawled": "2022-01-25T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Coronavirus\u2019 business impact: Evolving perspective | McKinsey", "url": "https://www.mckinsey.com/business-functions/risk-and-resilience/our-insights/covid-19-implications-for-business", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mckinsey.com</b>/business-functions/risk-and-resilience/our-insights/covid-19...", "snippet": "<b>Two</b> big lessons: if you <b>have</b> to choose between a great idea and a great team of <b>people</b>, pick the <b>people</b>, because ultimately talent rules outcomes. Her second takeaway: <b>people</b> who <b>have</b> been successful in other roles at Goldman Sachs are not always <b>the same</b> <b>people</b> who will succeed at building a new business. Entrepreneurship often requires a separate set of skills.", "dateLastCrawled": "2022-02-03T06:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The accuracy, fairness, and limits of predicting recidivism", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5777393/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5777393", "snippet": "Specifically, it is argued that the COMPAS score is not biased against blacks because the likelihood of recidivism among high-risk offenders is <b>the same</b> regardless of race (<b>predictive</b> <b>parity</b>), it <b>can</b> discriminate between recidivists and nonrecidivists equally well for white and black defendants as measured with the area under the curve of the receiver operating characteristic, AUC-ROC (accuracy equity), and the likelihood of recidivism for any given score is <b>the same</b> regardless of race ...", "dateLastCrawled": "2022-02-02T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Place Matters: Variation in the Black/White Very Preterm Birth <b>Rate</b> ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2496930/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2496930", "snippet": "The threefold disparity in mean <b>rate</b>, and <b>two</b>- to threefold increased variation as indicated by standard deviation, was maintained in all subanalyses. Conclusion. <b>Compared</b> with white women, black women <b>have</b> three times the mean VPT birth risk, as well as three times the variance in city-level rates. The racial disparity in VPT birth rates was composed of characteristics that were constant across MSAs, as well as factors that varied by MSA. The increased sensitivity to place for black women ...", "dateLastCrawled": "2021-12-01T07:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Algorithmic Fairness: Contemporary Ideas in the Insurance Context", "url": "https://www.actuaries.org.uk/system/files/field/document/B9_Chris%20Dolman.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.actuaries.org.uk/system/files/field/document/B9_Chris Dolman.pdf", "snippet": "\u2022 Argued that \u201c<b>predictive</b> <b>parity</b>\u201d ought to be the way we judge the fairness of the algorithm: \u2013 Of those <b>people</b> who were scored as \u201chigh risk\u201d, blacks did not recidivate at a <b>rate</b> of 37%, versus 41% for whites \u2013 Similarly, for those scored as \u201clow risk\u201d, the recidivism <b>rate</b> was 35% for blacks and 29% for whites", "dateLastCrawled": "2022-02-02T19:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Understanding and Identifying Unfairness in Machine Learning | by ...", "url": "https://cannon-m-bray.medium.com/understanding-and-identifying-unfairness-in-machine-learning-80178a16357c", "isFamilyFriendly": true, "displayUrl": "https://<b>can</b>non-m-bray.medium.com/understanding-and-identifying-unfairness-in-machine...", "snippet": "<b>Predictive</b> <b>Parity</b>. Next, let\u2019s look at <b>predictive</b> <b>parity</b>, also known as the outcome test. Unlike group fairness, this metric takes into account the predicted outcomes and the actual outcomes. According to <b>predictive</b> <b>parity</b>, a classifier is considered fair if each level of a protected class has <b>the same</b> PPV, also known as precision.", "dateLastCrawled": "2022-01-21T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Can</b> We <b>Automate Fairness? Professor Alexandra Chouldechova on Machine</b> ...", "url": "https://www.heinz.cmu.edu/media/2017/january/automate-fairness-machine-learning-discrimination", "isFamilyFriendly": true, "displayUrl": "https://www.heinz.cmu.edu/media/2017/january/automate-fairness-machine-learning...", "snippet": "Chouldechova says risk assessments are traditionally held to <b>the same</b> standards of bias as psychological and educational tests, something called \u201c<b>predictive</b> <b>parity</b>.\u201d While that may seem reasonable, she says it\u2019s not adequate in all contexts. Following the ProPublica-Northpointe feud, Chouldechova performed her own analysis, which she presented at the Fairness, Accountability, and Transparency in Machine Learning", "dateLastCrawled": "2021-12-21T01:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What Is <b>Purchasing Power Parity</b>? - Admiral Markets - Admirals", "url": "https://admiralmarkets.com/education/articles/forex-basics/understanding-the-meaning-of-purchasing-power-parity", "isFamilyFriendly": true, "displayUrl": "https://admiralmarkets.com/.../understanding-the-meaning-of-<b>purchasing-power-parity</b>", "snippet": "This is the relative <b>purchasing power parity</b> definition: The exchange <b>rate</b> between <b>two</b> countries will adjust in response to a difference in the <b>two</b> national inflation rates. To go into the specifics of the relative <b>purchasing power parity</b> equation is beyond the requirements of this discussion. Put simply though, relative PPP suggests that the exchange <b>rate</b> will change by a percentage that equals the difference in the inflation rates.", "dateLastCrawled": "2022-01-30T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The accuracy, fairness, and limits of predicting recidivism", "url": "https://www.science.org/doi/pdf/10.1126/sciadv.aao5580", "isFamilyFriendly": true, "displayUrl": "https://www.science.org/doi/pdf/10.1126/sciadv.aao5580", "snippet": "tions made by <b>people</b> with little or no criminal justice expertise. In addition, despite COMPAS\u2019scollectionof137 features, <b>the same</b> accuracy <b>can</b> be achieved with a simple linear predictor with only <b>two</b> features. INTRODUCTION We are the frequent subjects of <b>predictive</b> algorithms that determine music recommendations, product advertising, university admission, job placement, and bank loan qualific ation. In the criminal justice sys-tem, <b>predictive</b> algorithms <b>have</b> been used to predict where ...", "dateLastCrawled": "2022-01-29T23:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Risk <b>parity</b> \u2013 <b>the benefits of a conditional approach</b> - Top1000funds.com", "url": "https://www.top1000funds.com/2014/07/risk-parity-the-benefits-of-a-conditional-approach/", "isFamilyFriendly": true, "displayUrl": "https://www.top1000funds.com/2014/07/risk-<b>parity</b>-<b>the-benefits-of-a-conditional-approach</b>", "snippet": "The concordance <b>rate</b> is defined as the percentage of months in the sample in which the yield and the bond weight moved in <b>the same</b> direction. URP-VOL-RW is the standard risk <b>parity</b> strategy that relies on historical volatilities; CRP-VOL-DUR is a risk <b>parity</b> strategy that uses duration-based volatility as the bond volatility measure; CRP-NGVAR99 is a strategy that equates the contributions of constituents to non-Gaussian VaR at 99%; MSR-<b>SAME</b>-SR is a maximum Sharpe ratio strategy that uses ...", "dateLastCrawled": "2022-01-21T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Reprogramming Fairness: Affirmative Action in Algorithmic Criminal</b> ...", "url": "http://hrlr.law.columbia.edu/hrlr-online/reprogramming-fairness-affirmative-action-in-algorithmic-criminal-sentencing/", "isFamilyFriendly": true, "displayUrl": "hrlr.law.columbia.edu/hrlr-online/<b>reprogramming-fairness-affirmative-action-in</b>...", "snippet": "If the recidivism <b>rate</b> for white and black defendants is <b>the same</b> within each risk category, and if black defendants <b>have</b> a higher overall recidivism <b>rate</b>, then a greater share of black defendants will be classified as high risk. And if a greater share of black defendants are classified as high risk, then . . . a greater share of black defendants who do not reoffend will also be classified as high risk.", "dateLastCrawled": "2022-02-01T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Pay <b>parity</b>: What is it <b>and how does an employer get there</b>? | HR Dive", "url": "https://www.hrdive.com/news/pay-parity-what-is-it-and-how-does-an-employer-get-there/580504/", "isFamilyFriendly": true, "displayUrl": "https://www.hrdive.com/news/pay-<b>parity</b>-what-is-it-<b>and-how-does-an-employer-get-there</b>/...", "snippet": "PayScale indicated that over a 40-year career, a <b>two</b> cent disparity costs women $80,000. Pay <b>parity</b> is a term used to signify the lack of a pay gap, Holloway said. &quot;A lot of organizations seek to ...", "dateLastCrawled": "2022-02-01T06:34:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "Heidari et al. have written a paper comparing the three criteria \u2013 demographic <b>parity</b>, equality of opportunity, and <b>predictive</b> <b>parity</b> \u2013 to egalitarianism, equality of opportunity (EOP) in the Rawlsian sense, and EOP seen through the glass of luck egalitarianism, respectively. While the <b>analogy</b> is fascinating, it too assumes that we may take what is in the data at face value. In their likening <b>predictive</b> <b>parity</b> to luck egalitarianism, they have to go to especially great lengths, in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A <b>Machine</b> <b>Learning</b> Approach for Prediction of <b>Rate</b> Constants | Request PDF", "url": "https://www.researchgate.net/publication/343294287_A_Machine_Learning_Approach_for_Prediction_of_Rate_Constants", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343294287_A_<b>Machine</b>_<b>Learning</b>_Approach_for...", "snippet": "More recently, novel methods based on <b>machine</b> <b>learning</b> are actively being developed to interpolate cross sections and <b>rate</b> coefficients as functions of energy and temperature. 5,[18][19][20] [21 ...", "dateLastCrawled": "2022-01-30T10:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Starting to think about AI Fairness - Adolfo Eliaz\u00e0t - Artificial ...", "url": "https://adolfoeliazat.com/2022/01/01/starting-to-think-about-ai-fairness-2/", "isFamilyFriendly": true, "displayUrl": "https://adolfoeliazat.com/2022/01/01/starting-to-think-about-ai-fairness-2", "snippet": "() have written a paper comparing the three criteria \u2013 demographic <b>parity</b>, equality of opportunity, and <b>predictive</b> <b>parity</b> \u2013 to egalitarianism, equality of opportunity (EOP) in the Rawlsian sense, and EOP seen through the glass of luck egalitarianism, respectively. While the <b>analogy</b> is fascinating, it too assumes that we may take what is in the data at face value. In their likening <b>predictive</b> <b>parity</b> to luck egalitarianism, they have to go to especially great lengths, in assuming that the", "dateLastCrawled": "2022-02-01T05:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Multi-fidelity machine learning models for accurate bandgap predictions</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0927025616306188", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0927025616306188", "snippet": "To demonstrate the efficacy of the multi-fidelity bandgap <b>learning</b> model, we use a materials dataset of 640 double perovskite halides (or elpasolites) of A 2 BB\u2032X 6-type (cf. Fig. 2a) employed in a recent study that was focused on identifying novel and improved scintillators \u2013 an application where the electronic bandgap is an important criterion for optimal performance .This materials database features halide compounds (X = F, Cl, Br and I) with the A- and B- sites occupied by alkali ...", "dateLastCrawled": "2022-01-17T11:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "Simply put, the goal of classification is to determine a plausible value for an unknown variable Y given an observed variable X.For example, we might try to predict whether a loan applicant will pay back her loan by looking at various characteristics such as credit history, income, and net worth. Classification also applies in situations where the variable Y does not refer to an event that lies in the future. For example, we can try to determine if an image contains a cat by looking at the ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Survey on Bias and Fairness in <b>Machine</b> <b>Learning</b> | Request PDF", "url": "https://www.researchgate.net/publication/353229162_A_Survey_on_Bias_and_Fairness_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353229162_A_Survey_on_Bias_and_Fairness_in...", "snippet": "Our attacking framework can target fair <b>machine</b> <b>learning</b> models trained with a variety of group based fairness notions such as demographic <b>parity</b> and equalized odds. We develop three online ...", "dateLastCrawled": "2021-12-14T03:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>A Few Useful</b> Things to Know <b>About Machine Learning</b> | October 2012 ...", "url": "https://cacm.acm.org/magazines/2012/10/155531-a-few-useful-things-to-know-about-machine-learning/fulltext", "isFamilyFriendly": true, "displayUrl": "https://cacm.acm.org/magazines/2012/10/155531-<b>a-few-useful</b>-things-to-know-about-<b>machine</b>...", "snippet": "A recent report from the McKinsey Global Institute asserts that <b>machine</b> <b>learning</b> (a.k.a. data mining or <b>predictive</b> analytics) will be the driver of the next big wave of innovation. 15 Several fine textbooks are available to interested practitioners and researchers (for example, Mitchell 16 and Witten et al. 24). However, much of the &quot;folk knowledge&quot; that is needed to successfully develop <b>machine</b> <b>learning</b> applications is not readily available in them. As a result, many <b>machine</b> <b>learning</b> ...", "dateLastCrawled": "2022-02-02T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>All Unit MCQ questions of ML</b> \u2013 TheCodingShef", "url": "https://thecodingshef.com/all-unit-mcq-questions-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://thecodingshef.com/<b>all-unit-mcq-questions-of</b>-<b>machine</b>-<b>learning</b>", "snippet": "Correct option is C. Choose the correct option regarding <b>machine</b> <b>learning</b> (ML) and artificial intelligence (AI) ML is a set of techniques that turns a dataset into a software. AI is a software that can emulate the human mind. ML is an alternate way of programming intelligent machines. All of the above. Correct option is D.", "dateLastCrawled": "2022-01-30T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "On the integration of molecular dynamics, data science, and experiments ...", "url": "https://www.sciencedirect.com/science/article/pii/S2211339822000065", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2211339822000065", "snippet": "<b>Machine</b> <b>learning</b> (ML) models have been used for efficiently identifying ternary platinum alloys ... Here, reactivity was quantified by the so-called kinetic solvent parameter, which measures the relative <b>rate</b> of a reaction in a solvent mixture normalized by the <b>rate</b> in pure water. In our first DC approach, we sought to predict this output by training <b>predictive</b> models (regression and feedforward NNs) that used MD-derived descriptors of the solvent environment to predict experimental ...", "dateLastCrawled": "2022-02-03T03:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Predicting the pandemic: sentiment evaluation and <b>predictive</b> analysis ...", "url": "https://link.springer.com/article/10.1007/s12065-021-00598-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12065-021-00598-7", "snippet": "While the problem with classic rule-based <b>machine</b> <b>learning</b> algorithms is, though they are faster to learn , they are shallow, hence the ... We keep the <b>learning</b> <b>rate</b> of the optimizer as 0.01. The dropout <b>rate</b> for avoiding overfitting is kept at 0.6 for the vectorization layer. We fit the model within the padded vector\u2013matrix in the x-axis and y-axis consecutively. The verbose information is kept as 1 for word (vector) to training logs. Finally, we print the collective outcome as the model ...", "dateLastCrawled": "2021-12-30T06:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(predictive rate parity)  is like +(two people have the same predictive rate)", "+(predictive rate parity) is similar to +(two people have the same predictive rate)", "+(predictive rate parity) can be thought of as +(two people have the same predictive rate)", "+(predictive rate parity) can be compared to +(two people have the same predictive rate)", "machine learning +(predictive rate parity AND analogy)", "machine learning +(\"predictive rate parity is like\")", "machine learning +(\"predictive rate parity is similar\")", "machine learning +(\"just as predictive rate parity\")", "machine learning +(\"predictive rate parity can be thought of as\")", "machine learning +(\"predictive rate parity can be compared to\")"]}