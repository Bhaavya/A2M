{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Learning Automata Clustering</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "snippet": "<b>Centroid-based</b> <b>clustering</b> where each cluster is represented using a cluster center which may not belong to the data points. K-means, K ... Artificial <b>fish</b> swarm algorithm is another evolutionary algorithm derived from the movement of herd <b>of fish</b>. In , the initial solutions for the artificial <b>fish</b> swarm algorithm are initialized using K-means algorithm and then the algorithm carries out the <b>clustering</b> task. In order to achieve the <b>clustering</b> goal, a new fitness function is used which ...", "dateLastCrawled": "2021-12-04T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Cooperative Swarm based Evolutionary Approach to find optimal cluster ...", "url": "http://ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "isFamilyFriendly": true, "displayUrl": "ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "snippet": "<b>Centroid-based</b> <b>clustering</b> is a NP-hard optimization problem, and thus the common approach is to search for cluster centers only for approximate solutions. Well-known <b>centroid-based</b> <b>clustering</b> methods are k-means, k-medoids and fuzzy c-means. In this paper we proposed swarm intelligence based nature-inspired center-based <b>clustering</b> method using PSO optimization. PSO searches the optimized solution from available solutions in multidimensional search space. So PSO is capable to search best ...", "dateLastCrawled": "2021-09-15T23:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "The ACO for <b>clustering</b> (ACOC), which is an optimization algorithm for <b>clustering</b> proposed by Kao and Cheng (2006), entails <b>centroid-based</b> <b>clustering</b>, in which the problem of <b>clustering</b> is ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Using cluster edge counting to aggregate iterations of centroid-linkage ...", "url": "https://europepmc.org/article/MED/31453226", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/31453226", "snippet": "The USEARCH \u201c-cluster_fast\u201d command utilizes <b>centroid-based</b> <b>clustering</b> and avoids creating computationally costly distance matrices at the cost of being input-order dependent. To mitigate the effects of input-order dependence, the sequence FASTA-formatted input file is first reordered randomly prior to <b>clustering</b> and downstream edge counting for each iteration. The Sequence Numerical Identifiers created in step 1 are not altered by the randomization process. Depending on the dataset, a ...", "dateLastCrawled": "2021-12-18T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Diatom (Bacillariophyceae) assemblages in tidal environments of ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/pre.12470", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/pre.12470", "snippet": "Another <b>clustering</b> model, k-means <b>clustering</b> (<b>centroid-based</b> <b>clustering</b>), segregates samples more objectively than the hierarchical approach. However, it requires users to decide the specific number of clusters to partition the assemblages before running the cluster analysis (e.g. Kaufman &amp; Rousseeuw, 1990; Everitt et al. 2011).", "dateLastCrawled": "2022-01-24T08:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A New Soft Computing Method for <b>K-Harmonic Means Clustering</b>", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "snippet": "The <b>K-harmonic means clustering</b> algorithm (KHM) is a new <b>clustering</b> method used to group data such that the sum of the harmonic averages of the distances between each entity and all cluster centroids is minimized. Because it is less sensitive to initialization than K-means (KM), many researchers have recently been attracted to studying KHM. In this study, the proposed iSSO-KHM is based on an improved simplified swarm optimization (iSSO) and integrates a variable neighborhood search (VNS) for ...", "dateLastCrawled": "2021-02-15T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>lec27 - Lecture 27 The Story of the Ne2lix Prize Lester</b> ... - Course Hero", "url": "https://www.coursehero.com/file/14936346/lec27/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/14936346/lec27", "snippet": "<b>Clustering</b> with Missing Data \u2022 <b>Centroid-based</b> <b>clustering</b> \u2013 Represent user by incomplete raJngs vector, \u2013 Represent cluster by centroid vector, \u2022 Typically, is average of user vectors in cluster \u2013 Minimize (esJmated) distance between users and their cluster centers \u2022 Result: r u = (1, 5,?,?, 3,?, 4) c k c k r u k-0.3% improvement over Cinematch. Matching Cinematch \u2022 Incorporate prior informaJon \u2013 PosiJve raJngs {3,4,5} vs. negaJve raJngs {1,2} \u2022 EsJmate and combine ...", "dateLastCrawled": "2021-12-08T17:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Image quantization using improved artificial <b>fish</b> swarm algorithm ...", "url": "https://link.springer.com/article/10.1007/s00500-014-1436-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00500-014-1436-0", "snippet": "One of the applied approaches for producing codebook based on the color distribution is using <b>clustering</b> algorithms <b>like</b> k-means (Celebi 2011) and Fuzzy C-means (FCM) (Schaefer and Zhou 2009). In <b>clustering</b> CQ algorithms, the color histogram is produced from the original image and after that, <b>clustering</b> according to the color distribution among pixels is done. The number of cluster centers in <b>clustering</b> algorithms is determined equal to the number of decreased colors in the codebook. In ...", "dateLastCrawled": "2021-12-10T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "testing k means <b>clustering</b>", "url": "https://sukin.com/ulsyn/testing-k-means-clustering.html", "isFamilyFriendly": true, "displayUrl": "https://sukin.com/ulsyn/testing-k-means-<b>clustering</b>.html", "snippet": "K Means algorithm is a <b>centroid-based</b> <b>clustering</b> (unsupervised) technique. K-Means is a very popular <b>clustering</b> technique. The number of centroids represents the number of output classes. The most common <b>clustering</b> covered in machine learning for beginners is K-Means. Two points are assigned as centroids. <b>Clustering</b> outliers. We repeat the process for a given number of iterations and at the end, we have our clusters. Objective The objective of this hands on is to let you reason about the ...", "dateLastCrawled": "2022-01-27T09:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Differences Between Classification and Clustering</b> | Baeldung on ...", "url": "https://www.baeldung.com/cs/ml-classification-vs-clustering", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/cs/ml-classification-vs-<b>clustering</b>", "snippet": "Ironically, it\u2019s frequently used for features <b>like</b> texts that certainly have a strong linear dependence. ... Another <b>centroid-based</b> algorithm is the mean shift, which works by iteratively attempting to identify cluster centroids that are placed as close as possible to the ideal mean of the points in a region. This takes place by first placing the centroids randomly, and then updating their position so that they shift towards the mean: The algorithm identifies as clusters all observations ...", "dateLastCrawled": "2022-01-21T10:50:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Cooperative Swarm based Evolutionary Approach to find optimal cluster ...", "url": "http://ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "isFamilyFriendly": true, "displayUrl": "ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "snippet": "<b>Centroid-based</b> <b>clustering</b> is a NP-hard optimization problem, and thus the common approach is to search for cluster centers only for approximate solutions. Well-known <b>centroid-based</b> <b>clustering</b> methods are k-means, k-medoids and fuzzy c-means. In this paper we proposed swarm intelligence based nature-inspired center-based <b>clustering</b> method using PSO optimization. PSO searches the optimized solution from available solutions in multidimensional search space. So PSO is capable to search best ...", "dateLastCrawled": "2021-09-15T23:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Using cluster edge counting to aggregate iterations of centroid-linkage ...", "url": "https://europepmc.org/article/MED/31453226", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/31453226", "snippet": "The procedure outlined here includes the use of specific <b>clustering</b> and scripting programs but <b>similar</b> programs should work just as well. The choice of which programs is determined by user preference. The important details are to use a program that performs <b>centroid-based</b> <b>clustering</b>, or some other distance-matrix independent algorithm, and use a scripting language to perform the following aggregation procedure with the resulting clusters. The annotated Perl script used by the authors is ...", "dateLastCrawled": "2021-12-18T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A New Soft Computing Method for <b>K-Harmonic Means Clustering</b>", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "snippet": "The former builds a hierarchy tree of data that successively merges <b>similar</b> clusters, ... The most popular class of partition <b>clustering</b> is the <b>centroid-based</b> <b>clustering</b> algorithm. Among all <b>clustering</b> methods, with an extensive history dating back to 1972, K-means (KM) is one of the most well-known center-based partition <b>clustering</b> techniques [4\u201317]. KM is implemented by first randomly selecting K initial centroids and then trying to minimize heuristically the sum of the squares of ...", "dateLastCrawled": "2021-02-15T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Differences Between Classification and Clustering</b> | Baeldung on ...", "url": "https://www.baeldung.com/cs/ml-classification-vs-clustering", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/cs/ml-classification-vs-<b>clustering</b>", "snippet": "Another <b>centroid-based</b> algorithm is the mean shift, which works by iteratively attempting to identify cluster centroids that are placed as close as possible to the ideal mean of the points in a region. This takes place by first placing the centroids randomly, and then updating their position so that they shift towards the mean: The algorithm identifies as clusters all observations that comprise a region of smooth density around the centroids. Those observations that lie outside of all ...", "dateLastCrawled": "2022-01-21T10:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Learning Automata Clustering</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "snippet": "Comparing the proposed algorithm with four <b>centroid based</b> <b>clustering</b> algorithms, the proposed algorithm achieves a decent accuracy and comparable Silhouette coefficient on 14 real world datasets. Abstract . <b>Clustering</b> of data points has been a profound research avenue in the history of machine learning algorithms. Using learning automata which are autonomous decision making entities, in this paper, the <b>learning automata clustering</b> algorithm is proposed. In <b>learning automata clustering</b>, each ...", "dateLastCrawled": "2021-12-04T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>New Soft Computing Method for K-Harmonic Means Clustering</b>", "url": "https://www.researchgate.net/publication/310433557_A_New_Soft_Computing_Method_for_K-Harmonic_Means_Clustering/fulltext/582d1a1908ae004f74b94a1c/A-New-Soft-Computing-Method-for-K-Harmonic-Means-Clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/310433557_A_<b>New_Soft_Computing_Method_for</b>_K...", "snippet": "successively merges <b>similar</b> clusters, while the latter begins with a random partition and refines it iteratively [3]. The most popular class of partition <b>clustering</b> is the <b>centroid-based</b> ...", "dateLastCrawled": "2021-12-22T00:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "The ACO for <b>clustering</b> (ACOC), which is an optimization algorithm for <b>clustering</b> proposed by Kao and Cheng (2006), entails <b>centroid-based</b> <b>clustering</b>, in which the problem of <b>clustering</b> is ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Meal Pattern Analysis</b> in Nutritional Science: Recent Methods and ...", "url": "https://academic.oup.com/advances/article-abstract/12/4/1365/6103933", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/advances/article-abstract/12/4/1365/6103933", "snippet": "Finally, K-means <b>clustering</b> is a <b>similar</b> approach to PAM, with the <b>centroid (based</b> on the mean of the variables in the cluster) being used in place of the medoid to minimize variation within clusters. Both approaches are limited to identifying clusters that can be separated by a straight line. One of the decisions required when <b>clustering</b> is choosing the number of clusters to represent the data. Different approaches were taken in the studies reviewed here. Chau et al. selected 5 clusters to ...", "dateLastCrawled": "2022-01-21T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>lec27 - Lecture 27 The Story of the Ne2lix Prize Lester</b> ... - Course Hero", "url": "https://www.coursehero.com/file/14936346/lec27/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/14936346/lec27", "snippet": "<b>Clustering</b> with Missing Data \u2022 <b>Centroid-based</b> <b>clustering</b> \u2013 Represent user by incomplete raJngs vector, \u2013 Represent cluster by centroid vector, \u2022 Typically, is average of user vectors in cluster \u2013 Minimize (esJmated) distance between users and their cluster centers \u2022 Result: r u = (1, 5,?,?, 3,?, 4) c k c k r u k-0.3% improvement over Cinematch. Matching Cinematch \u2022 Incorporate prior informaJon \u2013 PosiJve raJngs {3,4,5} vs. negaJve raJngs {1,2} \u2022 EsJmate and combine ...", "dateLastCrawled": "2021-12-08T17:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "testing k means <b>clustering</b>", "url": "https://sukin.com/ulsyn/testing-k-means-clustering.html", "isFamilyFriendly": true, "displayUrl": "https://sukin.com/ulsyn/testing-k-means-<b>clustering</b>.html", "snippet": "K Means algorithm is a <b>centroid-based</b> <b>clustering</b> (unsupervised) technique. K-Means is a very popular <b>clustering</b> technique. The number of centroids represents the number of output classes. The most common <b>clustering</b> covered in machine learning for beginners is K-Means. Two points are assigned as centroids. <b>Clustering</b> outliers. We repeat the process for a given number of iterations and at the end, we have our clusters. Objective The objective of this hands on is to let you reason about the ...", "dateLastCrawled": "2022-01-27T09:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Using cluster edge counting to aggregate iterations of centroid-linkage ...", "url": "https://europepmc.org/article/MED/31453226", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/31453226", "snippet": "<b>School</b> of Earth and Space Exploration, Arizona State University, Tempe, AZ 85287-6004 USA. ... capacity beyond what is typically <b>thought</b> of for a standard computer. By eliminating the need for a distance matrix, the number of sequences that the centroid-linkage algorithm is able to process is only limited by the size of the file that <b>can</b> be read into memory (&gt; 1000000 for our 120 GB RAM computer). Importantly, these results do become input-order dependent. By avoiding distance matrices and ...", "dateLastCrawled": "2021-12-18T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Efficient <b>Clustering</b> of Emails Into Spam and Ham: The ...", "url": "https://www.researchgate.net/publication/343709430_Efficient_Clustering_of_Emails_Into_Spam_and_Ham_The_Foundational_Study_of_a_Comprehensive_Unsupervised_Framework", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343709430_Efficient_<b>Clustering</b>_of_Emails_Into...", "snippet": "ferred over <b>centroid-based</b> <b>clustering</b> as in K-means. Density. based <b>clustering</b> is an unsupervised learning technique that . recognises distinctive clusters in the data, on the assumption. that a ...", "dateLastCrawled": "2022-01-28T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) A Hybrid Sequential Approach for Data <b>Clustering</b> Using K-Means ...", "url": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_Clustering_Using_K_Means_and_Particle_Swarm_Optimization_Algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_<b>Clustering</b>...", "snippet": "However, if good initial <b>clustering</b> centroids <b>can</b> be obtained using any of the other techniques, the K-Means would work well in refining the <b>clustering</b> centroids to find the optimal <b>clustering</b> centers. The same idea is proposed in this paper to determine initial points for K-Means algorithm by some other global optimization search algorithms. Evolutionary and bio-inspired algorithms eradicate some of the above mentioned difficulties and are quickly replacing the classical methods in solving ...", "dateLastCrawled": "2022-01-18T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Kao and Cheng (2006) designed a <b>centroid-based</b> ACO <b>clustering</b> algorithm, where ants assign each data instance to one of the available clusters and cluster centroids are adjusted based on this ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Differential Threshold of Breakfast, Caffeine and Food Groups May Be ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8288514/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8288514", "snippet": "Using chi-square analysis, the significant variables in Cluster 1 for men included breakfast, <b>fish</b> and supplements use pattern (vitamins and <b>fish</b> oil), which represent a healthy dietary practice. Cluster 2 encompassed a spectrum of nutrient-dense food groups, which represents a healthy dietary pattern. Cluster 3 consists of fast-food, which represents an unhealthy dietary pattern. As for women, Cluster 1 comprised fast-food and meat, which represent an unhealthy dietary pattern. Cluster 2 ...", "dateLastCrawled": "2021-11-16T19:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Using Dendritic Heat Maps to Simultaneously Display Genotype Divergence ...", "url": "https://europepmc.org/article/PMC/PMC4990276", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC4990276", "snippet": "Since the USEARCH command \u201c-cluster_fast\u201d performs <b>centroid-based</b> <b>clustering</b> in the order of the input FASTA file, input sequences were first multiple aligned using Clustal Omega (described later) and arranged to ensure that the most distantly related and potentially cluster splitting \u201ccentroid\u201d sequences were listed first in a staggered order (conceptualized in Fig 1). This ordering process was performed by a script that reads from opposite ends of the multiple alignment and is ...", "dateLastCrawled": "2021-09-12T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "MS153 - jbmethods.org", "url": "https://jbmethods.org/jbm/article/download/153/160?inline=1", "isFamilyFriendly": true, "displayUrl": "https://jbmethods.org/jbm/article/download/153/160?inline=1", "snippet": "<b>School</b> of Earth and Space Exploration, Arizona State University, Tempe, AZ 85287-6004 USA *Corresponding author: Matthew Kellom, Email: matthewkellom@gmail.com. Competing interests: The authors have declared that no competing interests exist. Abbreviations used: GB: gigabyte; KS, Kolmogorov-Smirnov; RAM, random-access memory. Received August 19, 2016; Revision received January 20, 2017; Accepted January 22, 2017; Published March 16, 2017. Abstract. Sequence <b>clustering</b> is a fundamental tool ...", "dateLastCrawled": "2021-11-20T03:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Comprehensive Survey <b>on Particle Swarm Optimization Algorithm and</b> Its ...", "url": "https://www.hindawi.com/journals/mpe/2015/931256/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/mpe/2015/931256", "snippet": "Particle swarm optimization (PSO) is a heuristic global optimization method, proposed originally by Kennedy and Eberhart in 1995. It is now one of the most commonly used optimization techniques. This survey presented a comprehensive investigation of PSO. On one hand, we provided advances with PSO, including its modifications (including quantum-behaved PSO, bare-bones PSO, chaotic PSO, and fuzzy PSO), population topology (as fully connected, von Neumann, ring, star, random, etc ...", "dateLastCrawled": "2022-02-02T04:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A <b>Machine Learning</b> Tutorial with Examples | Toptal", "url": "https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer", "isFamilyFriendly": true, "displayUrl": "https://www.toptal.com/<b>machine-learning</b>/<b>machine-learning</b>-theory-an-introductory-primer", "snippet": "We <b>can</b> then tweak h(x) ... However, for something to chew on in the meantime, take a look at <b>clustering</b> algorithms such as k-means, and also look into dimensionality reduction systems such as principle component analysis. Our prior post on big data discusses a number of these topics in more detail as well. Conclusion. We\u2019ve covered much of the basic theory underlying the field of <b>Machine Learning</b> here, but of course, we have only barely scratched the surface. Keep in mind that to really ...", "dateLastCrawled": "2022-02-02T23:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>regional structure of</b> spawning phenology and the potential consequences ...", "url": "https://academic.oup.com/icesjms/article/74/3/613/2734755", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/icesjms/article/74/3/613/2734755", "snippet": "Although coral larvae have low swimming capabilities in comparison to <b>fish</b> larvae (Leichter et al., 2013), ... and polyp <b>clustering</b> (Mizrahi et al., 2014) <b>can</b> increase the dispersal potential of corals. In the ETP, little is known about coral dispersal due to the difficulty in collecting empirical information in the field. For the major reef builders as Pocilloporids or P. lobata, there are no records of direct spawning observations either in the field or in controlled settings. Therefore ...", "dateLastCrawled": "2022-01-19T09:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Medoid-based <b>clustering</b> methods are helpful\u2014<b>compared</b> to classical <b>centroid-based</b> techniques\u2014when centroids cannot be easily defined. This paper proposes two medoid-based ACO <b>clustering</b> ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Diatom (Bacillariophyceae) assemblages in tidal environments of ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/pre.12470", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/pre.12470", "snippet": "Another <b>clustering</b> model, k-means <b>clustering</b> (<b>centroid-based</b> <b>clustering</b>), segregates samples more objectively than the hierarchical approach. However, it requires users to decide the specific number of clusters to partition the assemblages before running the cluster analysis (e.g. Kaufman &amp; Rousseeuw, 1990; Everitt et al. 2011).", "dateLastCrawled": "2022-01-24T08:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) A Hybrid Sequential Approach for Data <b>Clustering</b> Using K-Means ...", "url": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_Clustering_Using_K_Means_and_Particle_Swarm_Optimization_Algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_<b>Clustering</b>...", "snippet": "However, if good initial <b>clustering</b> centroids <b>can</b> be obtained using any of the other techniques, the K-Means would work well in refining the <b>clustering</b> centroids to find the optimal <b>clustering</b> centers. The same idea is proposed in this paper to determine initial points for K-Means algorithm by some other global optimization search algorithms. Evolutionary and bio-inspired algorithms eradicate some of the above mentioned difficulties and are quickly replacing the classical methods in solving ...", "dateLastCrawled": "2022-01-18T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Centroid-Based</b> Particle Swarm Optimization Variant for Data ...", "url": "https://www.researchgate.net/publication/330937798_Centroid-Based_Particle_Swarm_Optimization_Variant_for_Data_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330937798_<b>Centroid-Based</b>_Particle_Swarm...", "snippet": "Request PDF | <b>Centroid-Based</b> Particle Swarm Optimization Variant for Data Classification | Recently, data mining has become more attractive for researchers as a technique to analyze and transform ...", "dateLastCrawled": "2022-02-03T08:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A New Soft Computing Method for <b>K-Harmonic Means Clustering</b>", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0164754", "snippet": "The <b>K-harmonic means clustering</b> algorithm (KHM) is a new <b>clustering</b> method used to group data such that the sum of the harmonic averages of the distances between each entity and all cluster centroids is minimized. Because it is less sensitive to initialization than K-means (KM), many researchers have recently been attracted to studying KHM. In this study, the proposed iSSO-KHM is based on an improved simplified swarm optimization (iSSO) and integrates a variable neighborhood search (VNS) for ...", "dateLastCrawled": "2021-02-15T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning Automata Clustering</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877750317302247", "snippet": "It <b>can</b> be divided into two approaches: Agglomerative <b>clustering</b> which puts each data point in a cluster and merges the clusters on the way up to the tip of hierarchy, and divisive <b>clustering</b> which starts with one cluster for the entire dataset and splits it recursively in the way down the hierarchy. Generally, the result of a hierarchical <b>clustering</b> algorithm is a dendogram showing the configuration of clusters.", "dateLastCrawled": "2021-12-04T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Meal Pattern Analysis</b> in Nutritional Science: Recent Methods and ...", "url": "https://academic.oup.com/advances/article-abstract/12/4/1365/6103933", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/advances/article-abstract/12/4/1365/6103933", "snippet": "<b>Clustering</b> <b>can</b> identify groups of individuals who eat meals at similar times over the course of a day and in a similar context Chau et al. ; Khanna et al. ; Riou et al. Latent class analysis Groups of observations are identified that have similar probabilities of belonging to the same categories in the variables of interest Study participants <b>can</b> be grouped based on having high probabilities for eating during the same time periods of the day or consuming the same combinations of meals over a ...", "dateLastCrawled": "2022-01-21T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Image quantization using improved artificial <b>fish</b> swarm algorithm ...", "url": "https://link.springer.com/article/10.1007/s00500-014-1436-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00500-014-1436-0", "snippet": "In this section, a stable and accurate color quantization algorithm framework based on an efficient extension of FCM <b>clustering</b> (Ozdemir and Akarun 1999; Yu and Yang 2005) and an improved artificial <b>fish</b> swarm optimization (He et al. 2009) algorithms is proposed. The color image usually represents each color component with an 8-bit integer, and each pixel requires 24 bits to completely and accurately specify its color. Of the many color spaces in existence RGB, CMY, YIQ, YUV, CIE Lab, HSV ...", "dateLastCrawled": "2021-12-10T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Density-based particle swarm optimization algorithm for data clustering</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417417305912", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417417305912", "snippet": "<b>Clustering</b> algorithms <b>can</b> be classified broadly into different categories, namely, partitional, hierarchical, and density-based algorithms. Each category has its own working mechanism, capability to deal with certain types of data, advantages, and drawbacks Saraswathi &amp; Sheela, 2014). One of the most widely used partitional <b>clustering</b> algorithms is the K-means (Hartigan &amp; Wong, 1979), a <b>centroid-based</b> <b>clustering</b> technique, where objects in a cluster are centered around its nearest ...", "dateLastCrawled": "2021-12-14T01:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "JPM | Free Full-Text | Customization of Diet May Promote Exercise and ...", "url": "https://www.mdpi.com/2075-4426/11/5/435/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2075-4426/11/5/435/htm", "snippet": "It included exercise, breakfast, whole grain, dairy, caffeine, fruits, nuts, HGI food, meat, DGLV, beans, <b>fish</b>, <b>fish</b> oil and an inverse association with mental distress (mean value = \u22120.11843). Cluster 2 was a Western diet pattern and consisted of HGI food, meat and mental distress (mean value = 0.64137). Cluster 3 included mostly dietary practices, such as breakfast, <b>fish</b>, MV and <b>fish</b> oil, exercise and mental wellbeing (mean value = \u22120.31067). Among men, Cluster 1 included fast food and ...", "dateLastCrawled": "2022-02-03T03:05:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~bgibson/cs540/handouts/learning_intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~bgibson/cs540/handouts/<b>learning</b>_intro.pdf", "snippet": "human <b>learning</b> (e.g., Computer-Aided Instruction (CAI)) \u2022Discover new things or structures that are unknown to humans (\u201cdata mining\u201d) \u2022Fill in skeletal or incomplete specifications about a domain Major Paradigms of <b>Machine</b> <b>Learning</b> \u2022Rote <b>Learning</b> \u2022Induction \u2022<b>Clustering</b> \u2022<b>Analogy</b> \u2022Discovery \u2022Genetic Algorithms \u2022Reinforcement", "dateLastCrawled": "2021-08-25T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Unsupervised Learning</b> and Data <b>Clustering</b> | by Sanatan Mishra | Towards ...", "url": "https://towardsdatascience.com/unsupervised-learning-and-data-clustering-eeecb78b422a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>unsupervised-learning</b>-and-data-<b>clustering</b>-eeecb78b422a", "snippet": "<b>Unsupervised Learning</b> and Data <b>Clustering</b>. Sanatan Mishra. May 19, 2017 \u00b7 15 min read. A task involving <b>machine</b> <b>learning</b> may not be linear, but it has a number of well known steps: Problem definition. Preparation of Data. Learn an underlying model. Improve the underlying model by quantitative and qualitative evaluations. Present the model. One good way to come to terms with a new problem is to work through identifying and defining the problem in the best possible way and learn a model that ...", "dateLastCrawled": "2022-02-02T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "MaxMin <b>clustering</b> for <b>historical analogy</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s42452-020-03202-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42452-020-03202-2", "snippet": "In natural language processing and <b>machine</b> <b>learning</b> studies, <b>clustering</b> algorithms are widely used; therefore, several types of <b>clustering</b> algorithms have been developed. The key purpose of a <b>clustering</b> algorithm is to identify similarities between data and to cluster them into groups 1, 19]. As several surveys presenting a broad overview of <b>clustering</b> have been published, e.g., [17, 59, 60], this study compares previously proposed partitioning-, hierarchy-, distribution- and graph-based ...", "dateLastCrawled": "2021-12-27T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Determination of miscible CO2 flooding analogue projects with <b>machine</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0920410521014455", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0920410521014455", "snippet": "We use <b>machine</b> <b>learning</b> <b>clustering</b> methods to group successfully executed miscible CO 2 flooding projects into clusters of projects with similar fluid/reservoir characteristics and to identify analogues for new target projects. Porosity, permeability, oil gravity and viscosity, reservoir pressure and temperature, minimum miscibility pressure (MMP), and depth were all input parameters. Data from nearly 200 miscible CO 2 EOR projects around the world were clustered using the Agglomerative ...", "dateLastCrawled": "2022-01-24T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Artificial Neural Networks - unit 3", "url": "https://www.slideshare.net/PVidyasri/artificial-neural-networks-unit-3", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/PVidyasri/artificial-neural-networks-unit-3", "snippet": "<b>Clustering</b>: \u2022 <b>Clustering</b> is a method of grouping the objects into clusters such that objects with most similarities remains into a group and has less or no similarities with the objects of another group. \u2022 Cluster analysis finds the commonalities between the data objects and categorizes them as per the presence and absence of those commonalities. \u2022 Below are some popular <b>Clustering</b> algorithms which come under unsupervised <b>learning</b>: \u2022 <b>Centroid-based</b> <b>Clustering</b> \u2022 Density-based ...", "dateLastCrawled": "2022-01-29T21:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Density-Based <b>Clustering</b>", "url": "https://blog.dominodatalab.com/topology-and-density-based-clustering", "isFamilyFriendly": true, "displayUrl": "https://blog.dominodatalab.com/topology-and-density-based-<b>clustering</b>", "snippet": "Compared to <b>centroid-based</b> <b>clustering</b> like k-means, density-based <b>clustering</b> works by identifying \u201cdense\u201d clusters of points, allowing it to learn clusters of arbitrary shape and identify outliers in the data. In particular, I will: Discuss the highly popular DBSCAN algorithm. Use the denpro R package.", "dateLastCrawled": "2022-02-02T08:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Tour of the <b>Most Popular Machine Learning Algorithms</b> | by Athreya ...", "url": "https://towardsdatascience.com/a-tour-of-the-most-popular-machine-learning-algorithms-b57d50c2eb51", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tour-of-the-<b>most-popular-machine-learning-algorithms</b>...", "snippet": "In <b>machine</b> <b>learning</b>, it is tradition to categorize algorithms by their <b>learning</b> style. In general, <b>learning</b> style is just a fancy way of saying what data you have readily available to train your algorithm. Let\u2019s look at some! 1. Supervised <b>Learning</b>. In supervised <b>learning</b>, input data is called training data and has a known label/result. An example of an input could be a picture of an animal and a label could be the name of it (i.e. elephant, cat, etc.). Another example can be emails as ...", "dateLastCrawled": "2022-01-29T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deep <b>Clustering</b> with a Dynamic Autoencoder - deepai.org", "url": "https://deepai.org/publication/deep-clustering-with-a-dynamic-autoencoder", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/deep-<b>clustering</b>-with-a-dynamic-autoencoder", "snippet": "4 Experiments. 4.1 Datasets. We compare DynAE with five of the state-of-the-art autoencoder-based deep <b>clustering</b> algorithms on four image datasets: MNIST-full ( 30), MNIST-test, USPS ( 41) and Fashion-MNIST ( 42). MNIST-full ( 30): a dataset that consists of 70000, 28\u00d728 grayscale images of handwritten digits.", "dateLastCrawled": "2021-12-29T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) EM-<b>algorithm and Clustering: a Tutorial</b> | Su WANG - Academia.edu", "url": "https://www.academia.edu/33573441/EM_algorithm_and_Clustering_a_Tutorial", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/33573441/EM_<b>algorithm_and_Clustering_a_Tutorial</b>", "snippet": "The EM-algorithm \\citep{Dempster:77} applies widely in unsupervised <b>learning</b>, in particular <b>clustering</b> models, e.g. K-means \\citep{Kanungo:02} and Bernoulli Mixture models \\citep{Juan:04}. Many, however, have treated the algorithm as a pure blackbox", "dateLastCrawled": "2022-01-21T06:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>Machine Learning</b> enhances <b>Personalization</b> at scale? | Opensense Labs", "url": "https://opensenselabs.com/blog/articles/machine-learning-enhances-personalization", "isFamilyFriendly": true, "displayUrl": "https://opensenselabs.com/blog/articles/<b>machine-learning</b>-enhances-<b>personalization</b>", "snippet": "If you want to learn about the miracles of the technological marvel of the 21st century, then this article is no less than a treat for you. In today\u2019s era, digital marketing may sound like a messy environment filled with constant change and complex systems. With the buzzword like <b>Machine Learning</b> (ML) that has penetrated into various aspects of our everyday life, human inputs are reduced to minimal. In other words, more freedom falls in the lap of a <b>machine</b> wherein the <b>machine</b> acts on its ...", "dateLastCrawled": "2022-01-17T11:15:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(centroid-based clustering)  is like +(school of fish)", "+(centroid-based clustering) is similar to +(school of fish)", "+(centroid-based clustering) can be thought of as +(school of fish)", "+(centroid-based clustering) can be compared to +(school of fish)", "machine learning +(centroid-based clustering AND analogy)", "machine learning +(\"centroid-based clustering is like\")", "machine learning +(\"centroid-based clustering is similar\")", "machine learning +(\"just as centroid-based clustering\")", "machine learning +(\"centroid-based clustering can be thought of as\")", "machine learning +(\"centroid-based clustering can be compared to\")"]}