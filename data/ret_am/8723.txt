{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "DPIR-Net: Direct PET Image Reconstruction Based on the <b>Wasserstein</b> ...", "url": "https://www.researchgate.net/publication/341498644_DPIR-Net_Direct_PET_Image_Reconstruction_Based_on_the_Wasserstein_Generative_Adversarial_Network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341498644_DPIR-Net_Direct_PET_Image...", "snippet": "<b>These</b> methods use trusted models of the imaging physics and noise distribution, while relying on <b>training</b> data <b>examples</b> to learn deep mappings for regularisation and resolution recovery. After ...", "dateLastCrawled": "2022-01-18T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "GANs for Simulation, Representation and Inference | by Ari Heljakka ...", "url": "https://becominghuman.ai/gans-for-simulation-representation-and-inference-d215c251ed12", "isFamilyFriendly": true, "displayUrl": "https://becominghuman.ai/gans-for-simulation-representation-and-inference-d215c251ed12", "snippet": "trains a <b>separate</b> <b>Wasserstein</b> critic with <b>validation</b> data, uses it for the evaluation of the trained GAN, and could further use it to compare different GAN architectures. In addition, Classifier 2-sample testing (C2ST) [13] and a <b>separate</b> MMD estimator [12] can serve as fairly advanced sample quality evaluation approaches that also promise human-interpretability.", "dateLastCrawled": "2022-01-20T18:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>How to Develop a Conditional</b> GAN (cGAN) From Scratch", "url": "https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>how-to-develop-a-conditional</b>-generative-adversarial...", "snippet": "Generative Adversarial Networks, or GANs, are an architecture for <b>training</b> generative models, such as deep convolutional neural networks for generating images. Although GAN models are capable of generating new random plausible <b>examples</b> for a given dataset, there is no way to control the types of images that are generated other than <b>trying</b> to figure out the complex relationship <b>between</b> the latent", "dateLastCrawled": "2022-02-03T03:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "KDD &#39;21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge ...", "url": "https://kdd.org/kdd2021/accepted-papers/toc", "isFamilyFriendly": true, "displayUrl": "https://kdd.org/kdd2021/accepted-papers/toc", "snippet": "Partial label <b>learning</b> deals with <b>training</b> <b>examples</b> each associated with <b>a set</b> of candidate labels, among which only one is valid. Most existing works focus on manipulating the label space by estimating the labeling confidences of candidate labels, while the task of manipulating the feature space by dimensionality reduction has been rarely investigated. In this paper, a novel partial label dimensionality reduction approach named CENDA is proposed via confidence-based dependence maximization ...", "dateLastCrawled": "2022-01-26T18:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Develop a 1D Generative Adversarial Network From Scratch in Keras", "url": "https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/how-to-develop-a-generative-adversarial-network-for...", "snippet": "Generative Adversarial Networks, or GANs for short, are a deep <b>learning</b> architecture for <b>training</b> powerful generator models. A generator model is capable of generating new artificial samples that plausibly could have come from an existing distribution of samples. GANs are comprised of both generator and discriminator models. The generator is responsible for generating new samples from the domain, and the discriminator is", "dateLastCrawled": "2022-02-02T01:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "With <b>machine</b> <b>learning</b>, to perform <b>any</b> task, we need to design the right <b>set</b> of features and feed those features to the <b>machine</b> <b>learning</b> model. Feature engineering is a vital task for the success of <b>any</b> <b>machine</b> <b>learning</b> model. But it is hard to engineer the right <b>set</b> of features when dealing with unstructured data <b>like</b> text and images. In those cases, we can use deep <b>learning</b>. With deep <b>learning</b>, we are not required to engineer the features since the deep neural network consists of several ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>VICTORIA&#39;s MACHINE LEARNING NOTES</b> - Persagen Consulting", "url": "https://persagen.com/files/ml.html", "isFamilyFriendly": true, "displayUrl": "https://persagen.com/files/ml.html", "snippet": "The idea is that with sufficient <b>training</b> data (corresponding pairs of low and high resolution images) we can learn <b>set</b> of filters (i.e. a mapping) that when applied to given image that is not in the <b>training</b> <b>set</b>, will produce a higher resolution version of it, where the <b>learning</b> is preferably low complexity. In <b>our</b> proposed approach, the run-time is more than one to two orders of magnitude faster than the best competing methods currently available, while producing results comparable or ...", "dateLastCrawled": "2022-02-01T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>GitHub</b> - borisbanushev/stockpredictionai: In this noteboook I will ...", "url": "https://github.com/borisbanushev/stockpredictionai", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/borisbanushev/<b>stock</b>predictionai", "snippet": "Rainbow is a Q <b>learning</b> based off-policy deep reinforcement <b>learning</b> <b>algorithm</b> combining seven <b>algorithm</b> together: DQN. DQN is an extension of Q <b>learning</b> <b>algorithm</b> that uses a neural network to represent the Q value. Similar to supervised (deep) <b>learning</b>, in DQN we train a neural network and try to <b>minimize</b> a <b>loss</b> function. We train the network ...", "dateLastCrawled": "2022-01-30T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Python <b>Machine</b> <b>Learning</b>: <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-<b>machine</b>-<b>learning</b>-<b>machine</b>-<b>learning</b>-and-deep-<b>learning</b>-with...", "snippet": "In addition to offering hands-on experience with <b>machine</b> <b>learning</b> using the Python programming language and Python-based <b>machine</b> <b>learning</b> libraries, this book introduces the mathematical concepts behind <b>machine</b> <b>learning</b> algorithms, which are essential for using <b>machine</b> <b>learning</b> successfully. Thus, this book is different from a purely practical book; this is a book that discusses the necessary details regarding <b>machine</b> <b>learning</b> concepts and offers intuitive, yet informative, explanations on ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Mastering <b>Machine</b> <b>Learning</b> Algorithms - Second Edition | <b>Packt</b>", "url": "https://www.packtpub.com/product/mastering-machine-learning-algorithms-second-edition/9781838820299", "isFamilyFriendly": true, "displayUrl": "https://www.<b>packt</b>pub.com/product/mastering-<b>machine</b>-<b>learning</b>-<b>algorithms</b>-second-edition/...", "snippet": "The task of a parametric <b>learning</b> process is <b>to find</b> the best parameter <b>set</b> that maximizes a target function, the value of which is proportional to the accuracy of the model, given specific input X and output Y datasets (or proportional to the error, if we&#39;re <b>trying</b> to <b>minimize</b> the error). This definition isn&#39;t very rigorous, and we&#39;ll improve it in the following sections; however, it&#39;s useful as a way to introduce the structure and the properties of the data we&#39;re using, in the context of ...", "dateLastCrawled": "2022-01-31T18:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Correcting Nuisance Variation using Wasserstein Distance</b>", "url": "https://www.researchgate.net/publication/320867145_Correcting_Nuisance_Variation_using_Wasserstein_Distance", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320867145_Correcting_Nuisance_Variation_using...", "snippet": "PDF | Profiling cellular phenotypes from microscopic imaging can provide meaningful biological information resulting from various factors affecting the... | <b>Find</b>, read and cite all the research ...", "dateLastCrawled": "2021-10-13T03:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/g<b>loss</b>ary", "snippet": "A distributed <b>machine learning</b> approach that trains <b>machine learning</b> models using decentralized <b>examples</b> residing on devices such as smartphones. In federated <b>learning</b>, a subset of devices downloads the current model from a central coordinating server. The devices use the <b>examples</b> stored on the devices to make improvements to the model. The devices then upload the model improvements (but not the <b>training</b> <b>examples</b>) to the coordinating server, where they are aggregated with other updates to ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Deep <b>Learning for NLP and Speech Recognition</b> | William Jacome ...", "url": "https://www.academia.edu/43190210/Deep_Learning_for_NLP_and_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43190210/Deep_<b>Learning_for_NLP_and_Speech_Recognition</b>", "snippet": "Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome. Download PDF. Download Full PDF Package. This paper. A short summary of this paper. 37 Full PDFs related to this paper. READ PAPER. Deep <b>Learning for NLP and Speech Recognition</b> . Download. Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "GANs for Simulation, Representation and Inference | by Ari Heljakka ...", "url": "https://becominghuman.ai/gans-for-simulation-representation-and-inference-d215c251ed12", "isFamilyFriendly": true, "displayUrl": "https://becominghuman.ai/gans-for-simulation-representation-and-inference-d215c251ed12", "snippet": "Alternatively, we can make <b>any</b> f-divergence <b>our</b> explicit <b>loss</b> measure by divergence minimization, ... Next, we will see <b>examples</b> of all of <b>these</b>! Simulator <b>Learning</b> \u2014 <b>Loss</b> Function Perspective. The <b>loss</b> function formulation of the original GAN has been found challenging to work with. It was supported later by the <b>set</b> of Improved GAN Techniques that provided generic tools for GAN <b>training</b> while also showing good results in semi-supervised scenarios. Still, problems remained. At least one ...", "dateLastCrawled": "2022-01-20T18:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Develop a 1D Generative Adversarial Network From Scratch in Keras", "url": "https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/how-to-develop-a-generative-adversarial-network-for...", "snippet": "Generative Adversarial Networks, or GANs for short, are a deep <b>learning</b> architecture for <b>training</b> powerful generator models. A generator model is capable of generating new artificial samples that plausibly could have come from an existing distribution of samples. GANs are comprised of both generator and discriminator models. The generator is responsible for generating new samples from the domain, and the discriminator is", "dateLastCrawled": "2022-02-02T01:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>GitHub</b> - borisbanushev/stockpredictionai: In this noteboook I will ...", "url": "https://github.com/borisbanushev/stockpredictionai", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/borisbanushev/<b>stock</b>predictionai", "snippet": "Rainbow is a Q <b>learning</b> based off-policy deep reinforcement <b>learning</b> <b>algorithm</b> combining seven <b>algorithm</b> together: DQN. DQN is an extension of Q <b>learning</b> <b>algorithm</b> that uses a neural network to represent the Q value. <b>Similar</b> to supervised (deep) <b>learning</b>, in DQN we train a neural network and try to <b>minimize</b> a <b>loss</b> function. We train the network ...", "dateLastCrawled": "2022-01-30T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "New submissions for Tue, 14 Dec 21 \u00b7 Issue #153 \u00b7 DongZhouGu/arxiv ...", "url": "https://github.com/DongZhouGu/arxiv-daily/issues/153", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/DongZhouGu/arxiv-daily/issues/153", "snippet": "Keyword: human object interaction There is no result Keyword: visual relation detection There is no result Keyword: object detection Guided Generative Models using Weak Supervision for Detecting Object Spatial Arrangement in Overhead Ima...", "dateLastCrawled": "2021-12-28T18:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Mastering <b>Machine</b> <b>Learning</b> Algorithms - Second Edition | <b>Packt</b>", "url": "https://www.packtpub.com/product/mastering-machine-learning-algorithms-second-edition/9781838820299", "isFamilyFriendly": true, "displayUrl": "https://www.<b>packt</b>pub.com/product/mastering-<b>machine</b>-<b>learning</b>-<b>algorithms</b>-second-edition/...", "snippet": "The task of a parametric <b>learning</b> process is <b>to find</b> the best parameter <b>set</b> that maximizes a target function, the value of which is proportional to the accuracy of the model, given specific input X and output Y datasets (or proportional to the error, if we&#39;re <b>trying</b> to <b>minimize</b> the error). This definition isn&#39;t very rigorous, and we&#39;ll improve it in the following sections; however, it&#39;s useful as a way to introduce the structure and the properties of the data we&#39;re using, in the context of ...", "dateLastCrawled": "2022-01-31T18:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "With <b>machine</b> <b>learning</b>, to perform <b>any</b> task, we need to design the right <b>set</b> of features and feed those features to the <b>machine</b> <b>learning</b> model. Feature engineering is a vital task for the success of <b>any</b> <b>machine</b> <b>learning</b> model. But it is hard to engineer the right <b>set</b> of features when dealing with unstructured data like text and images. In those cases, we can use deep <b>learning</b>. With deep <b>learning</b>, we are not required to engineer the features since the deep neural network consists of several ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Python <b>Machine</b> <b>Learning</b>: <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-<b>machine</b>-<b>learning</b>-<b>machine</b>-<b>learning</b>-and-deep-<b>learning</b>-with...", "snippet": "In addition to offering hands-on experience with <b>machine</b> <b>learning</b> using the Python programming language and Python-based <b>machine</b> <b>learning</b> libraries, this book introduces the mathematical concepts behind <b>machine</b> <b>learning</b> algorithms, which are essential for using <b>machine</b> <b>learning</b> successfully. Thus, this book is different from a purely practical book; this is a book that discusses the necessary details regarding <b>machine</b> <b>learning</b> concepts and offers intuitive, yet informative, explanations on ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Correcting Nuisance Variation using Wasserstein Distance</b>", "url": "https://www.researchgate.net/publication/320867145_Correcting_Nuisance_Variation_using_Wasserstein_Distance", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320867145_Correcting_Nuisance_Variation_using...", "snippet": "PDF | Profiling cellular phenotypes from microscopic imaging <b>can</b> provide meaningful biological information resulting from various factors affecting the... | <b>Find</b>, read and cite all the research ...", "dateLastCrawled": "2021-10-13T03:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A survey of bias in <b>Machine Learning through the prism of Statistical</b> ...", "url": "https://deepai.org/publication/a-survey-of-bias-in-machine-learning-through-the-prism-of-statistical-parity-for-the-adult-data-set", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-survey-of-bias-in-<b>machine-learning-through-the-prism</b>...", "snippet": "A survey of bias in <b>Machine Learning through the prism of Statistical Parity for the Adult</b> Data <b>Set</b>. 03/31/2020 \u2219 by Philippe Besse, et al. \u2219 0 \u2219 share . Applications based on <b>Machine</b> <b>Learning</b> models have now become an indispensable part of the everyday life and the professional world. A critical question then recently arised among the population: Do algorithmic decisions convey <b>any</b> type of discrimination against specific groups of population or minorities?", "dateLastCrawled": "2021-12-05T13:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Deep <b>Learning for NLP and Speech Recognition</b> | William Jacome ...", "url": "https://www.academia.edu/43190210/Deep_Learning_for_NLP_and_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43190210/Deep_<b>Learning_for_NLP_and_Speech_Recognition</b>", "snippet": "Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome. Download PDF. Download Full PDF Package. This paper. A short summary of this paper. 37 Full PDFs related to this paper. READ PAPER. Deep <b>Learning for NLP and Speech Recognition</b> . Download. Deep <b>Learning for NLP and Speech Recognition</b>. William Jacome ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to Develop a 1D Generative Adversarial Network From Scratch in Keras", "url": "https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/how-to-develop-a-generative-adversarial-network-for...", "snippet": "Generative Adversarial Networks, or GANs for short, are a deep <b>learning</b> architecture for <b>training</b> powerful generator models. A generator model is capable of generating new artificial samples that plausibly could have come from an existing distribution of samples. GANs are comprised of both generator and discriminator models. The generator is responsible for generating new samples from the domain, and the discriminator is", "dateLastCrawled": "2022-02-02T01:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Develop a Pix2Pix GAN <b>for Image-to-Image Translation</b>", "url": "https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/how-to-develop-a-pix2pix-gan-for-image-to-ima", "snippet": "The Pix2Pix Generative Adversarial Network, or GAN, is an approach to <b>training</b> a deep convolutional neural network <b>for image-to-image translation</b> tasks. The careful configuration of architecture as a type of image-conditional GAN allows for both the generation of large images compared to prior GAN models (e.g. such as 256x256 pixels) and the capability of performing well on a variety of different", "dateLastCrawled": "2022-02-02T18:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Data science applications to string theory</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0370157319303072", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0370157319303072", "snippet": "Many concepts, such as the generation <b>of training</b> sets as explained in Section 3.2, the definition of different <b>loss</b> functions introduced in Section 3.5, the problem of over- and underfitting examined in Section 3.6, and methods of <b>performance</b> evaluation detailed in Section 3.8, are not specific to NNs and <b>can</b> be applied to other <b>machine</b> <b>learning</b> techniques as well.", "dateLastCrawled": "2022-01-28T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Proceedings of the 2020 Conference on Empirical Methods in Natural ...", "url": "https://aclanthology.org/volumes/2020.emnlp-main/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/volumes/2020.emnlp-main", "snippet": "Data efficiency <b>can</b> be improved by optimizing pre-<b>training</b> directly for future fine-tuning with few <b>examples</b>; this <b>can</b> be treated as a meta-<b>learning</b> problem. However, standard meta-<b>learning</b> techniques require many <b>training</b> tasks in order to generalize; unfortunately, finding a diverse <b>set</b> of such supervised tasks is usually difficult. This paper proposes a self-supervised approach to generate a large, rich, meta-<b>learning</b> task distribution from unlabeled text. This is achieved using a cloze ...", "dateLastCrawled": "2022-02-02T12:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "With <b>machine</b> <b>learning</b>, to perform <b>any</b> task, we need to design the right <b>set</b> of features and feed those features to the <b>machine</b> <b>learning</b> model. Feature engineering is a vital task for the success of <b>any</b> <b>machine</b> <b>learning</b> model. But it is hard to engineer the right <b>set</b> of features when dealing with unstructured data like text and images. In those cases, we <b>can</b> use deep <b>learning</b>. With deep <b>learning</b>, we are not required to engineer the features since the deep neural network consists of several ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Python <b>Machine</b> <b>Learning</b>: <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-<b>machine</b>-<b>learning</b>-<b>machine</b>-<b>learning</b>-and-deep-<b>learning</b>-with...", "snippet": "Here, the term &quot;supervised&quot; refers to <b>a set</b> <b>of training</b> <b>examples</b> (data inputs) where the desired output signals (labels) are already known. The following figure summarizes a typical supervised <b>learning</b> workflow, where the labeled <b>training</b> data is passed to a <b>machine</b> <b>learning</b> <b>algorithm</b> for fitting a predictive model that <b>can</b> make predictions on new, unlabeled data inputs: Considering the example of email spam filtering, we <b>can</b> train a model using a supervised <b>machine</b> <b>learning</b> <b>algorithm</b> on a ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>VICTORIA&#39;s MACHINE LEARNING NOTES</b> - Persagen Consulting", "url": "https://persagen.com/files/ml.html", "isFamilyFriendly": true, "displayUrl": "https://persagen.com/files/ml.html", "snippet": "Here, we develop <b>our</b> understanding of GANs with the aim of forming a rich view of this growing area of <b>machine</b> <b>learning</b> -- to build connections to the diverse <b>set</b> of statistical thinking on this topic, of which much <b>can</b> be gained by a mutual exchange of ideas. We frame GANs within the wider landscape of algorithms for <b>learning</b> in implicit generative models--models that only specify a stochastic procedure with which to generate data--and relate <b>these</b> ideas to modelling problems in related ...", "dateLastCrawled": "2022-02-01T17:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "DPIR-Net: Direct PET Image Reconstruction Based on the <b>Wasserstein</b> ...", "url": "https://www.researchgate.net/publication/341498644_DPIR-Net_Direct_PET_Image_Reconstruction_Based_on_the_Wasserstein_Generative_Adversarial_Network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341498644_DPIR-Net_Direct_PET_Image...", "snippet": "This hybrid approach produces reconstruction results using a <b>training</b> <b>set</b> of reduced size, <b>compared</b> to pure DLbased methods proposed for tomographic image recon- struction in different studies [12 ...", "dateLastCrawled": "2022-01-18T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Cramer Distance as a Solution to Biased <b>Wasserstein</b> Gradients ...", "url": "https://www.researchgate.net/publication/317248418_The_Cramer_Distance_as_a_Solution_to_Biased_Wasserstein_Gradients", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/317248418_The_Cramer_Distance_as_a_Solution...", "snippet": "<b>Wasserstein</b>-inspired gradient regularization approaches <b>can</b> be used on the MMD critic when <b>learning</b> <b>these</b> features: uses weight clipping , and [Bi\u0144kowski* et al., 2018, Bellemare et al., 2017 use ...", "dateLastCrawled": "2022-01-26T17:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Generative Adversarial Networks in Digital Pathology and ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8609288/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8609288", "snippet": "Deep <b>learning</b> methods are used in digital pathology in many tasks including image preprocessing, segmentation and detection of histologic primitives,[13,14] and grading and prognosis.[15,16] In 2014, Goodfellow et al. introduced the generative adversarial networks (GANs) as a deep <b>learning</b> concept capable of <b>learning</b> representative distributions of data and generating new, synthetic data that <b>can</b> be used as real data substitutes or complements.", "dateLastCrawled": "2022-01-04T17:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to Develop a 1D Generative Adversarial Network From Scratch in Keras", "url": "https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/how-to-develop-a-generative-adversarial-network-for...", "snippet": "Generative Adversarial Networks, or GANs for short, are a deep <b>learning</b> architecture for <b>training</b> powerful generator models. A generator model is capable of generating new artificial samples that plausibly could have come from an existing distribution of samples. GANs are comprised of both generator and discriminator models. The generator is responsible for generating new samples from the domain, and the discriminator is", "dateLastCrawled": "2022-02-02T01:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>How to Develop a Conditional</b> GAN (cGAN) From Scratch", "url": "https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>how-to-develop-a-conditional</b>-generative-adversarial...", "snippet": "Generative Adversarial Networks, or GANs, are an architecture for <b>training</b> generative models, such as deep convolutional neural networks for generating images. Although GAN models are capable of generating new random plausible <b>examples</b> for a given dataset, there is no way to control the types of images that are generated other than <b>trying</b> to figure out the complex relationship <b>between</b> the latent", "dateLastCrawled": "2022-02-03T03:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Synthetic flow-based cryptomining attack generation through Generative ...", "url": "https://deepai.org/publication/synthetic-flow-based-cryptomining-attack-generation-through-generative-adversarial-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/synthetic-flow-based-cryptomining-attack-generation...", "snippet": "The main <b>differences</b> of the previous proposals and <b>our</b> work are: (i) Unlike the prevailing existing data augmentation solutions, we obtain synthetic flow-based traffic that <b>can</b> fully replace real data and therefore, this solution <b>can</b> be applied in scenarios where data privacy must be guaranteed, (ii) existing metrics measure the <b>differences</b> of synthetic and real data independently for each each variable, but we propose <b>a set</b> of new metrics to measure more realistically the similarity of the ...", "dateLastCrawled": "2021-12-25T07:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Python <b>Machine</b> <b>Learning</b>: <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-<b>machine</b>-<b>learning</b>-<b>machine</b>-<b>learning</b>-and-deep-<b>learning</b>-with...", "snippet": "Here, the term &quot;supervised&quot; refers to <b>a set</b> <b>of training</b> <b>examples</b> (data inputs) where the desired output signals (labels) are already known. The following figure summarizes a typical supervised <b>learning</b> workflow, where the labeled <b>training</b> data is passed to a <b>machine</b> <b>learning</b> <b>algorithm</b> for fitting a predictive model that <b>can</b> make predictions on new, unlabeled data inputs: Considering the example of email spam filtering, we <b>can</b> train a model using a supervised <b>machine</b> <b>learning</b> <b>algorithm</b> on a ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A survey of bias in <b>Machine Learning through the prism of Statistical</b> ...", "url": "https://deepai.org/publication/a-survey-of-bias-in-machine-learning-through-the-prism-of-statistical-parity-for-the-adult-data-set", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-survey-of-bias-in-<b>machine-learning-through-the-prism</b>...", "snippet": "A survey of bias in <b>Machine Learning through the prism of Statistical Parity for the Adult</b> Data <b>Set</b>. 03/31/2020 \u2219 by Philippe Besse, et al. \u2219 0 \u2219 share . Applications based on <b>Machine</b> <b>Learning</b> models have now become an indispensable part of the everyday life and the professional world. A critical question then recently arised among the population: Do algorithmic decisions convey <b>any</b> type of discrimination against specific groups of population or minorities?", "dateLastCrawled": "2021-12-05T13:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "With <b>machine</b> <b>learning</b>, to perform <b>any</b> task, we need to design the right <b>set</b> of features and feed those features to the <b>machine</b> <b>learning</b> model. Feature engineering is a vital task for the success of <b>any</b> <b>machine</b> <b>learning</b> model. But it is hard to engineer the right <b>set</b> of features when dealing with unstructured data like text and images. In those cases, we <b>can</b> use deep <b>learning</b>. With deep <b>learning</b>, we are not required to engineer the features since the deep neural network consists of several ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Mastering <b>Machine</b> <b>Learning</b> Algorithms - Second Edition | <b>Packt</b>", "url": "https://www.packtpub.com/product/mastering-machine-learning-algorithms-second-edition/9781838820299", "isFamilyFriendly": true, "displayUrl": "https://www.<b>packt</b>pub.com/product/mastering-<b>machine</b>-<b>learning</b>-<b>algorithms</b>-second-edition/...", "snippet": "In all <b>these</b> cases, a standard <b>training</b>-test <b>set</b> decomposition will be used, assuming that for both sets the numerosity is large enough to guarantee full coverage of the underlying data generating process. Characteristics of a <b>machine</b> <b>learning</b> model. In this section, we&#39;re mainly going to consider supervised models, even though the concepts we&#39;ll discuss are valid in general. We&#39;ll try to determine how it&#39;s possible to measure the theoretical potential accuracy of a model, and a model&#39;s ...", "dateLastCrawled": "2022-01-31T18:58:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to stabilize GAN training. Understand <b>Wasserstein</b> distance and ...", "url": "https://towardsdatascience.com/wasserstein-distance-gan-began-and-progressively-growing-gan-7e099f38da96", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>wasserstein</b>-distance-gan-began-and-progressively...", "snippet": "<b>Wasserstein</b> <b>loss</b> leads to a higher quality of the gradients to train G. ... Finally, one intuitive way to understand this paper is to make an <b>analogy</b> with the gradients on the history of in-layer activation functions. Specifically, the gradients of sigmoid and tanh activations that disappeared in favor of ReLUs, because of the improved gradients in the whole range of values. BEGAN (Boundary Equilibrium Generative Adversarial Networks 2017) We often see that the discriminator progresses too ...", "dateLastCrawled": "2022-01-25T18:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning Wasserstein Embeddings</b> | DeepAI", "url": "https://deepai.org/publication/learning-wasserstein-embeddings", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>learning-wasserstein-embeddings</b>", "snippet": "The <b>Wasserstein</b> distance received a lot of attention recently in the community of <b>machine</b> <b>learning</b>, especially for its principled way of comparing distributions. It has found numerous applications in several hard problems, such as domain adaptation, dimensionality reduction or generative models. However, its use is still limited by a heavy ...", "dateLastCrawled": "2022-01-05T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Learning</b> <b>Wasserstein</b> Embeddings - ResearchGate", "url": "https://www.researchgate.net/publication/320564581_Learning_Wasserstein_Embeddings", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320564581_<b>Learning</b>_<b>Wasserstein</b>_Embeddings", "snippet": "Designed through an <b>analogy</b> with ... Fast dictionary <b>learning</b> with a smoothed <b>wasserstein</b> <b>loss</b>. In AISTA TS, pages 630\u2013638, 2016. [32] F. Santambrogio. Introduction to optimal transport theory ...", "dateLastCrawled": "2021-12-13T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "deep <b>learning</b> - How can both generator and discriminator losses ...", "url": "https://datascience.stackexchange.com/questions/32699/how-can-both-generator-and-discriminator-losses-decrease", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/32699", "snippet": "In the widely used <b>analogy</b>: ... despite the WGAN having a different <b>loss</b> function, namely the <b>Wasserstein</b> distance, one should still not expect that the discriminator and generator simultaneously monotonically increase -- generally one of them &quot;wins&quot; the round and receives a lower portion of the <b>loss</b>. $\\endgroup$ \u2013 PSub. Mar 13 &#39;21 at 6:07 $\\begingroup$ @PSub You are completely misunderstanding the question. It&#39;s not a question about the small scale changes of the <b>loss</b> values. OP is asking ...", "dateLastCrawled": "2022-01-28T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Manifold-Valued Image Generation with <b>Wasserstein</b> Generative ...", "url": "https://ojs.aaai.org/index.php/AAAI/article/download/4277/4155", "isFamilyFriendly": true, "displayUrl": "https://ojs.aaai.org/index.php/AAAI/article/download/4277/4155", "snippet": "fundamental <b>machine</b> <b>learning</b> problems. However, few mod-ern generative models, including <b>Wasserstein</b> Generative Ad-versarial Nets (WGANs), are studied on manifold-valued im- ages that are frequently encountered in real-world applica-tions. To \ufb01ll the gap, this paper \ufb01rst formulates the problem of generating manifold-valued images and exploits three typical instances: hue-saturation-value (HSV) color image genera-tion, chromaticity-brightness (CB) color image generation, and diffusion ...", "dateLastCrawled": "2022-01-29T09:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Advanced <b>Machine</b> <b>Learning</b> - Computer Vision", "url": "https://www.vision.rwth-aachen.de/media/course/SS/2019/advanced-machine-learning/ml2_19-part17-gans-6on1.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.vision.rwth-aachen.de/media/course/SS/2019/advanced-<b>machine</b>-<b>learning</b>/ml2...", "snippet": "<b>Analogy</b>: police investigator \u2022Both generator and discriminator are deep networks We can train them with backprop. Image sources: www.bundesbank.de, weclipart.com, Kevin McGuiness 15 Advanced <b>Machine</b> <b>Learning</b> Part 17 \u2013Generative Adversarial Networks Training the Discriminator \u2022Procedure Fix generator weights Train discriminator to distinguish between real and generated images Image credit: Kevin McGuiness 16 Visual Computing Institute | Prof. Dr . Bastian Leibe Advanced <b>Machine</b> <b>Learning</b> ...", "dateLastCrawled": "2021-10-25T15:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[D] Is the <b>Wasserstein</b> distance really what we optimize in WGAN ...", "url": "https://www.reddit.com/r/MachineLearning/comments/ew2lzs/d_is_the_wasserstein_distance_really_what_we/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/ew2lzs/d_is_the_<b>wasserstein</b>_distance...", "snippet": "The &quot;genuine&quot; <b>Wasserstein</b> <b>loss</b> relies on optimal transport, a generalization of sorting to high-dimensional feature spaces. In a nutshell: OT relies on the matrix of distances between samples to define a &quot;least action&quot; matching between any two distributions. Now, unfortunately, in spaces of images, the L2 distance is (essentially) meaningless: natural images should not be compared with each other pixel-wise. As a consequence, the baseline <b>Wasserstein</b> distance between two batches of images is ...", "dateLastCrawled": "2021-09-30T11:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A <b>Tour of Generative Adversarial Network Models</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/tour-of-generative-adversarial-network-models/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>tour-of-generative-adversarial-network-models</b>", "snippet": "By <b>analogy</b> with auto-encoders, we propose Context Encoders \u2013 a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. \u2014 Context Encoders: Feature <b>Learning</b> by Inpainting, 2016. Example of the Context Encoders Encoder-Decoder Model Architecture. Taken from: Context Encoders: Feature <b>Learning</b> by Inpainting. The model is trained with a joint-<b>loss</b> that combines both the adversarial <b>loss</b> of generator and discriminator models ...", "dateLastCrawled": "2022-02-03T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "SpringerLink - <b>Machine Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05924-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05924-1", "snippet": "Here, we aim to minimize this <b>loss</b> for a given value of \\xi and show that domain shift robustness can be achieved to first order with the population C o R e estimator using the conditional-standard-deviation-of-<b>loss</b> penalty, i.e., Eq. ( 10) with \\nu = 1/2, by choosing an appropriate value of the penalty \\lambda.", "dateLastCrawled": "2022-01-15T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>Gentle Introduction to Pix2Pix Generative</b> Adversarial Network", "url": "https://machinelearningmastery.com/a-gentle-introduction-to-pix2pix-generative-adversarial-network/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/a-<b>gentle-introduction-to-pix2pix-generative</b>...", "snippet": "Image-to-image translation is the controlled conversion of a given source image to a target image. An example might be the conversion of black and white photographs to color photographs. Image-to-image translation is a challenging problem and often requires specialized models and <b>loss</b> functions for a given translation task or dataset. The Pix2Pix GAN is a general approach for image-to-image translation. It is based", "dateLastCrawled": "2022-02-02T13:26:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(wasserstein loss)  is like +(trying to find a set of training examples that minimize any differences between the performance of our machine learning algorithm on these training examples and on a separate set of validation examples)", "+(wasserstein loss) is similar to +(trying to find a set of training examples that minimize any differences between the performance of our machine learning algorithm on these training examples and on a separate set of validation examples)", "+(wasserstein loss) can be thought of as +(trying to find a set of training examples that minimize any differences between the performance of our machine learning algorithm on these training examples and on a separate set of validation examples)", "+(wasserstein loss) can be compared to +(trying to find a set of training examples that minimize any differences between the performance of our machine learning algorithm on these training examples and on a separate set of validation examples)", "machine learning +(wasserstein loss AND analogy)", "machine learning +(\"wasserstein loss is like\")", "machine learning +(\"wasserstein loss is similar\")", "machine learning +(\"just as wasserstein loss\")", "machine learning +(\"wasserstein loss can be thought of as\")", "machine learning +(\"wasserstein loss can be compared to\")"]}