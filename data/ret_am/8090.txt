{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Masked</b> education? The benefits and burdens of wearing face masks in ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7417296/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7417296", "snippet": "When strangers meet, who speak <b>two</b> <b>different</b> <b>languages</b> which they do not mutually understand, they <b>can</b> still interpret facial expressions such as smiles and frowns with ease and thereby communicate. In fact, the most basic form of communication between humans is by facial expressions. This is because facial expressions are a simple universal <b>language</b> that we instinctively understand . It may be for this reason, that many people do not <b>like</b> the wearing masks at all in the first place. Because ...", "dateLastCrawled": "2022-02-02T09:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Types of Figurative Language</b> (With Examples) | <b>Indeed.com</b>", "url": "https://www.indeed.com/career-advice/career-development/figurative-language-examples", "isFamilyFriendly": true, "displayUrl": "https://<b>www.indeed.com</b>/career-advice/career-development/figurative-<b>language</b>-examples", "snippet": "Figurative <b>language</b> is used to: Compare <b>two</b> unlike ideas to increase understanding of one. Describe ideas sometimes difficult to understand . Show a deeper emotion or connection. Influence the audience. Help make connections. Make descriptions easier to visualize. Elicit an emotion. Related: 4 Types of Communication (with Examples) <b>Types of figurative language</b> with examples. Figurative <b>language</b> is used in literature <b>like</b> poetry, drama, prose and even speeches. Figures of speech are literary ...", "dateLastCrawled": "2022-02-03T06:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>NLP Language Models BERT, GPT2</b>/3, T-NLG: <b>Changing the rules of the</b> game ...", "url": "https://medium.com/analytics-vidhya/nlp-language-models-bert-gpt2-t-nlg-changing-the-rules-of-the-game-3334b23020a9", "isFamilyFriendly": true, "displayUrl": "https://<b>medium</b>.com/analytics-vidhya/<b>nlp-language-models-bert-gpt2</b>-t-nlg-changing-the...", "snippet": "Our conventional NLP <b>language</b> <b>model</b> was similar <b>like</b> this only, everyone needs to develop their own <b>language</b> understanding using some technique but no one <b>can</b> leverage others work. The computer ...", "dateLastCrawled": "2022-01-30T00:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "READING and FEELING: the effects of a literature-based intervention ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4267422/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4267422", "snippet": "2. Reading unit: The difference between true and <b>masked</b> feelings: Work out the <b>different</b> emotional motivations of the <b>two</b> protagonists for the example of the emotion \u201cjoy\u201d: The sheep shows emotions directly/the wolf hides his intention. Work on the connection between the valence of emotions and the showing of emotions directly or masking them.", "dateLastCrawled": "2022-02-03T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to <b>Develop Word-Based Neural Language Models in Python</b> with Keras", "url": "https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>develop-word-based-neural-language-models</b>-python-keras", "snippet": "<b>Language</b> models are a key component in larger models for challenging natural <b>language</b> processing problems, <b>like</b> machine translation and speech recognition. They <b>can</b> also be developed as standalone models and used for generating new sequences that have the same statistical properties as the source text. <b>Language</b> models both learn and predict one word at a time. The training of the network involves providing sequences of words as input that are processed one at a time where a prediction <b>can</b> be ...", "dateLastCrawled": "2022-02-02T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Direct and Indirect Communication Styles</b>", "url": "https://www.linkedin.com/pulse/direct-indirect-communication-styles-marjorie-friesen", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/direct-indirect-communication-styles-marjorie-friesen", "snippet": "Try a slightly <b>different</b> approach \u2013 for example, use less \u201cassertive\u201d <b>language</b> with an indirect communicator.\u201d OR use less \u201csubtle\u201d <b>language</b> with a direct communicator. It\u2019s a 2 ways ...", "dateLastCrawled": "2022-02-03T06:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Quanta Magazine", "url": "https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/", "isFamilyFriendly": true, "displayUrl": "https://www.quantamagazine.org/machines-beat-humans-on-a-<b>read</b>ing-test-but-do-they...", "snippet": "\u201cThe simplest kind of <b>language</b> <b>model</b> is: I\u2019m going to <b>read</b> a bunch of words and then try to predict the next word ,\u201d explained Myle Ott, a research scientist at Facebook. \u201cIf I say, \u2018George Bush was born in,\u2019 the <b>model</b> now has to predict the next word in that sentence.\u201d These deep pretrained <b>language</b> models could be produced relatively efficiently. Researchers simply fed their neural networks massive amounts of written text copied from freely available sources <b>like</b> Wikipedia ...", "dateLastCrawled": "2022-01-30T07:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Emotive</b> <b>Language</b>: Definition, Example and Features | Total Assignment Help", "url": "https://www.totalassignmenthelp.com/blog/emotive-language/", "isFamilyFriendly": true, "displayUrl": "https://www.totalassignmenthelp.com/blog/<b>emotive</b>-<b>language</b>", "snippet": "Also <b>Read</b>: <b>Language</b> Analysis Techniques: Strategies to Master Linguistic Analysis. <b>Emotive</b> <b>Language</b> . <b>Emotive</b> <b>Language</b> is the type of <b>language</b> which conveys or evokes an emotion in the mind of the reader. It requires choosing the words carefully which best convey the emotions and phrase them in such a way that it has the most impact on the audience. <b>Emotive</b> <b>language</b> is the best form of <b>language</b> to connect with the audiences, be it through written medium or verbal. For Example: Non-<b>Emotive</b> ...", "dateLastCrawled": "2022-02-02T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Guide to Text Preprocessing Using BERT", "url": "https://analyticsindiamag.com/a-guide-to-text-preprocessing-using-bert/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/a-guide-to-text-preprocessing-using-bert", "snippet": "Various state-of-the-art NLP applications <b>like</b> sentiment analysis, question answering, smart assistance, etc. require a tremendous amount of data.This large amount of data <b>can</b> be directly fed to the machine learning <b>model</b>. Almost all the text-based applications require a lot of pre-processing with the textual data such as creating the embedding vectors from scratch using the word frequency counter.", "dateLastCrawled": "2022-02-03T04:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "THE <b>STORAGE AND PROCESSING OF MORPHOLOGICALLY COMPLEX WORDS</b> IN L2 ...", "url": "https://www.cambridge.org/core/journals/studies-in-second-language-acquisition/article/storage-and-processing-of-morphologically-complex-words-in-l2-spanish/B4DE248B29A09210B851513FA2E6A332", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/studies-in-second-<b>language</b>-acquisition/article/...", "snippet": "According to this <b>model</b>, native speakers of a <b>language</b> use <b>two</b> distinct memory systems for <b>language</b> processing and production. The declarative memory system serves memorized, form-based lexical knowledge, while the grammar or rules of the <b>language</b> are served by the procedural memory system. In L2 acquisition that occurs postpuberty, learners begin with both types of knowledge being dependent upon the declarative system, so that the combinatorial rules present in native speaker grammars ...", "dateLastCrawled": "2021-12-16T02:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Masked</b> education? The benefits and burdens of wearing face masks in ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7417296/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7417296", "snippet": "When strangers meet, who speak <b>two</b> <b>different</b> <b>languages</b> which they do not mutually understand, they <b>can</b> still interpret facial expressions such as smiles and frowns with ease and thereby communicate. In fact, the most basic form of communication between humans is by facial expressions. This is because facial expressions are a simple universal <b>language</b> that we instinctively understand . It may be for this reason, that many people do not like the wearing masks at all in the first place. Because ...", "dateLastCrawled": "2022-02-02T09:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>NLP Language Models BERT, GPT2</b>/3, T-NLG: <b>Changing the rules of the</b> game ...", "url": "https://medium.com/analytics-vidhya/nlp-language-models-bert-gpt2-t-nlg-changing-the-rules-of-the-game-3334b23020a9", "isFamilyFriendly": true, "displayUrl": "https://<b>medium</b>.com/analytics-vidhya/<b>nlp-language-models-bert-gpt2</b>-t-nlg-changing-the...", "snippet": "Our conventional NLP <b>language</b> <b>model</b> was <b>similar</b> like this only, everyone needs to develop their own <b>language</b> understanding using some technique but no one <b>can</b> leverage others work. The computer ...", "dateLastCrawled": "2022-01-30T00:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "12.5 <b>Different</b> Types of <b>Communication</b> \u2013 Principles of Management", "url": "https://open.lib.umn.edu/principlesmanagement/chapter/12-5-different-types-of-communication/", "isFamilyFriendly": true, "displayUrl": "https://open.lib.umn.edu/principlesmanagement/chapter/12-5-", "snippet": "Written <b>communication</b> is often asynchronous (occurring at <b>different</b> times). That is, the Sender <b>can</b> <b>write</b> a Message that the Receiver <b>can</b> <b>read</b> at any time, unlike a conversation that is carried on in real time. A written <b>communication</b> <b>can</b> also be <b>read</b> by many people (such as all employees in a department or all customers). It\u2019s a \u201cone-to-many\u201d <b>communication</b>, as opposed to a one-to-one verbal conversation. There are exceptions, of course: a voicemail is an oral Message that is ...", "dateLastCrawled": "2022-02-02T04:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to <b>Develop Word-Based Neural Language Models in Python</b> with Keras", "url": "https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>develop-word-based-neural-language-models</b>-python-keras", "snippet": "<b>Language</b> modeling involves predicting the next word in a sequence given the sequence of words already present. A <b>language</b> <b>model</b> is a key element in many natural <b>language</b> processing models such as machine translation and speech recognition. The choice of how the <b>language</b> <b>model</b> is framed must match how the <b>language</b> <b>model</b> is intended to be used. In this tutorial, you will", "dateLastCrawled": "2022-02-02T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "NLP Research: Top Papers from 2021 So Far - <b>Read</b> More Here", "url": "https://opendatascience.com/top-recent-nlp-research/", "isFamilyFriendly": true, "displayUrl": "https://opendatascience.com/top-recent-nlp-research", "snippet": "Subnetworks found on the <b>masked</b> <b>language</b> modeling task (the same task used to pre-train the <b>model</b>) transfer universally; those found on other tasks transfer in a limited fashion if at all. As large-scale pre-training becomes an increasingly central paradigm in deep learning, the results demonstrate that the main lottery ticket observations remain relevant in this context. The GitHub repo associated with this paper <b>can</b> be found HERE. BERT Loses Patience: Fast and Robust Inference with Early ...", "dateLastCrawled": "2022-02-03T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Emotive</b> <b>Language</b>: Definition, Example and Features | Total Assignment Help", "url": "https://www.totalassignmenthelp.com/blog/emotive-language/", "isFamilyFriendly": true, "displayUrl": "https://www.totalassignmenthelp.com/blog/<b>emotive</b>-<b>language</b>", "snippet": "Also <b>Read</b>: <b>Language</b> Analysis Techniques: Strategies to Master Linguistic Analysis. <b>Emotive</b> <b>Language</b> . <b>Emotive</b> <b>Language</b> is the type of <b>language</b> which conveys or evokes an emotion in the mind of the reader. It requires choosing the words carefully which best convey the emotions and phrase them in such a way that it has the most impact on the audience. <b>Emotive</b> <b>language</b> is the best form of <b>language</b> to connect with the audiences, be it through written medium or verbal. For Example: Non-<b>Emotive</b> ...", "dateLastCrawled": "2022-02-02T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Datasets for Natural <b>Language</b> Processing", "url": "https://machinelearningmastery.com/datasets-natural-language-processing/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/datasets-natural-<b>language</b>-processing", "snippet": "You <b>can</b> join to the project and help to build the biggest voice datasets for many <b>languages</b>. More details you <b>can</b> reach here: https: ... <b>masked</b> <b>language</b> modeling and machine translation. Under <b>language</b> modeling, you have mentioned that \u201cIt is a pre-cursor task in tasks like speech recognition and machine translation\u201d Does that mean you <b>can</b> pre-train and <b>model</b> on a <b>language</b> modeling learning objective and fine tune it using a parallel corpus or something <b>similar</b>? Although I\u2019m not sure ...", "dateLastCrawled": "2022-02-02T05:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Guide to Text Preprocessing Using BERT", "url": "https://analyticsindiamag.com/a-guide-to-text-preprocessing-using-bert/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/a-guide-to-text-preprocessing-using-bert", "snippet": "The <b>model</b> then makes an attempt to forecast the original value of the <b>masked</b> words using the context provided by the other, non-<b>masked</b> phrases in the sequence. It is necessary to add a classification layer on top of the encoder output in order to predict the output words. This is followed by multiplying the encoder output vectors by the embedding matrix, transforming them into the vocabulary dimension, and computing the probability of each word in the vocabulary using softmax.", "dateLastCrawled": "2022-02-03T04:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "THE <b>STORAGE AND PROCESSING OF MORPHOLOGICALLY COMPLEX WORDS</b> IN L2 ...", "url": "https://www.cambridge.org/core/journals/studies-in-second-language-acquisition/article/storage-and-processing-of-morphologically-complex-words-in-l2-spanish/B4DE248B29A09210B851513FA2E6A332", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/studies-in-second-<b>language</b>-acquisition/article/...", "snippet": "According to this <b>model</b>, native speakers of a <b>language</b> use <b>two</b> distinct memory systems for <b>language</b> processing and production. The declarative memory system serves memorized, form-based lexical knowledge, while the grammar or rules of the <b>language</b> are served by the procedural memory system. In L2 acquisition that occurs postpuberty, learners begin with both types of knowledge being dependent upon the declarative system, so that the combinatorial rules present in native speaker grammars ...", "dateLastCrawled": "2021-12-16T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 9, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>List of narrative techniques</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/List_of_narrative_techniques", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>List_of_narrative_techniques</b>", "snippet": "A narrative technique (known for literary fictional narratives as a literary technique, literary device, or fictional device) is any of several specific methods the creator of a narrative uses to convey what they want \u2014in other words, a strategy used in the making of a narrative to relay information to the audience and particularly to develop the narrative, usually in order to make it more complete, complex, or interesting. Literary techniques are distinguished from literary elements ...", "dateLastCrawled": "2022-01-30T03:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Word-finding difficulty: a clinical analysis of the progressive aphasias", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2373641/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2373641", "snippet": "All propositional speech <b>can</b> be considered as an attempt to convey a <b>thought</b> or \u2018message\u2019 in verbal form, and the operational stages involved in this process (Fig. 1) suggest a broad classification of clinical deficits, according to whether the patient has difficulty initiating conversation, difficulty in conveying the sense of the message (a disturbance of speech content such that <b>thought</b> <b>can</b> no longer be conveyed coherently) or with message structure (a disturbance of word formation or ...", "dateLastCrawled": "2022-02-03T00:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Types of Figurative Language</b> (With Examples) | <b>Indeed.com</b>", "url": "https://www.indeed.com/career-advice/career-development/figurative-language-examples", "isFamilyFriendly": true, "displayUrl": "https://<b>www.indeed.com</b>/career-advice/career-development/figurative-<b>language</b>-examples", "snippet": "Also referred to as &quot;figures of speech,&quot; figurative <b>language</b> <b>can</b> be utilized to persuade, engage and connect with an audience and amplify your intended message. Implementing figurative <b>language</b> takes some careful <b>thought</b> and close observations to successfully convey your intended meaning. In this article, we review some common <b>types of figurative language</b> and evaluate some examples to deepen your understanding. What is figurative <b>language</b>? Figurative <b>language</b> is the use of descriptive words ...", "dateLastCrawled": "2022-02-03T06:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to <b>Develop Word-Based Neural Language Models in Python</b> with Keras", "url": "https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>develop-word-based-neural-language-models</b>-python-keras", "snippet": "<b>Language</b> modeling involves predicting the next word in a sequence given the sequence of words already present. A <b>language</b> <b>model</b> is a key element in many natural <b>language</b> processing models such as machine translation and speech recognition. The choice of how the <b>language</b> <b>model</b> is framed must match how the <b>language</b> <b>model</b> is intended to be used. In this tutorial, you will", "dateLastCrawled": "2022-02-02T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Emotive</b> <b>Language</b>: Definition, Example and Features | Total Assignment Help", "url": "https://www.totalassignmenthelp.com/blog/emotive-language/", "isFamilyFriendly": true, "displayUrl": "https://www.totalassignmenthelp.com/blog/<b>emotive</b>-<b>language</b>", "snippet": "Also <b>Read</b>: <b>Language</b> Analysis Techniques: Strategies to Master Linguistic Analysis. <b>Emotive</b> <b>Language</b> . <b>Emotive</b> <b>Language</b> is the type of <b>language</b> which conveys or evokes an emotion in the mind of the reader. It requires choosing the words carefully which best convey the emotions and phrase them in such a way that it has the most impact on the audience. <b>Emotive</b> <b>language</b> is the best form of <b>language</b> to connect with the audiences, be it through written medium or verbal. For Example: Non-<b>Emotive</b> ...", "dateLastCrawled": "2022-02-02T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Quanta Magazine", "url": "https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/", "isFamilyFriendly": true, "displayUrl": "https://www.quantamagazine.org/machines-beat-humans-on-a-<b>read</b>ing-test-but-do-they...", "snippet": "\u201cThe simplest kind of <b>language</b> <b>model</b> is: I\u2019m going to <b>read</b> a bunch of words and then try to predict the next word,\u201d explained Myle Ott, a research scientist at Facebook. \u201cIf I say, \u2018George Bush was born in,\u2019 the <b>model</b> now has to predict the next word in that sentence.\u201d These deep pretrained <b>language</b> models could be produced relatively efficiently. Researchers simply fed their neural networks massive amounts of written text copied from freely available sources like Wikipedia ...", "dateLastCrawled": "2022-01-30T07:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Frontiers | Complexity and Simplification in <b>Language</b> Shift | Communication", "url": "https://www.frontiersin.org/articles/10.3389/fcomm.2021.638118/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fcomm.2021.638118", "snippet": "This paper examines the question of linguistic complexity <b>in two</b> shift ecologies in northeastern Russia. It is frequently claimed that <b>language</b> shift results in linguistic simplification across a range of domains in the grammars of shifting speakers (Campbell and Muntzel 1989; Dorian 1989; O\u2019Shannessy 2011). We challenge the breadth of this claim, showing that while there are undoubtedly patterns that <b>can</b> be described as a simplification of some grammatical domain, the overall grammars of ...", "dateLastCrawled": "2021-12-06T13:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "THE <b>STORAGE AND PROCESSING OF MORPHOLOGICALLY COMPLEX WORDS</b> IN L2 ...", "url": "https://www.cambridge.org/core/journals/studies-in-second-language-acquisition/article/storage-and-processing-of-morphologically-complex-words-in-l2-spanish/B4DE248B29A09210B851513FA2E6A332", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/studies-in-second-<b>language</b>-acquisition/article/...", "snippet": "According to this <b>model</b>, native speakers of a <b>language</b> use <b>two</b> distinct memory systems for <b>language</b> processing and production. The declarative memory system serves memorized, form-based lexical knowledge, while the grammar or rules of the <b>language</b> are served by the procedural memory system. In L2 acquisition that occurs postpuberty, learners begin with both types of knowledge being dependent upon the declarative system, so that the combinatorial rules present in native speaker grammars ...", "dateLastCrawled": "2021-12-16T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fallacies</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/fallacies/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/<b>fallacies</b>", "snippet": "The kinds of mistakes one <b>can</b> make in reasoning are generally <b>thought</b> to be beyond enumeration and, hence, it has been maintained that there <b>can</b> be no complete stock of <b>fallacies</b> that will guard against every kind of mistake. Johnson and Blair\u2019s approach is responsive to this problem in that it allows the names of the classes of <b>fallacies</b> \u2014 \u2018unacceptable premise,\u2019 \u2018irrelevant reason\u2019 and \u2018hasty conclusion\u2019 \u2014 to stand for <b>fallacies</b> themselves, <b>fallacies</b> broad-in-scope; i.e ...", "dateLastCrawled": "2022-02-02T08:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A <b>Complete Learning Path To Transformers</b> (Guide To 23 Architectures)", "url": "https://analyticsindiamag.com/a-complete-learning-path-to-transformers/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/a-<b>complete-learning-path-to-transformers</b>", "snippet": "When building an end-to-end <b>language</b> <b>model</b> is costly because of numerous parameters that take several hours to train, BERT was developed by Google to be used as a pre-trained base for <b>language</b> modeling. BERT still remains one of the preferred pre-trained models though many variants and extensions have been developed after BERT. <b>Read</b> more about BERT here. 2| Transformer XL. Transformer XL is a large size transformer developed to address a few issues faced by BERT. BERT <b>can</b> handle only a fixed ...", "dateLastCrawled": "2022-01-26T10:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Logic Puzzles</b> (with Answers)\u2014Best Logic Problems", "url": "https://parade.com/970343/parade/logic-puzzles/", "isFamilyFriendly": true, "displayUrl": "https://parade.com/970343/parade/<b>logic-puzzles</b>", "snippet": "Test your logic with 25 <b>logic puzzles</b>, including easy word <b>logic puzzles</b> for kids, and hard <b>logic puzzles</b> for adults. Solve these word problems, with answers included.", "dateLastCrawled": "2022-02-03T07:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Masked</b> education? The benefits and burdens of wearing face masks in ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7417296/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7417296", "snippet": "<b>Compared</b> to adults, children are less likely to fall ill, and if so, their illness is usually mild . ... When strangers meet, who speak <b>two</b> <b>different</b> <b>languages</b> which they do not mutually understand, they <b>can</b> still interpret facial expressions such as smiles and frowns with ease and thereby communicate. In fact, the most basic form of communication between humans is by facial expressions. This is because facial expressions are a simple universal <b>language</b> that we instinctively understand . It ...", "dateLastCrawled": "2022-02-02T09:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "READING and FEELING: the effects of a literature-based intervention ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4267422/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4267422", "snippet": "After being asked Please name all of the <b>different</b> feelings you <b>can</b> think of, children should list all the feelings they could think of (see also Kusche et al., unpublished). Children received one point for each correctly stated feeling but none for an incorrect response (e.g., the description of the behavior). The target variable was the number of correctly listed feelings (open\u2013ended response format). Explicit emotional knowledge. In response to a short sample situation (e.g., \u201cImagine ...", "dateLastCrawled": "2022-02-03T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Direct and Indirect Communication Styles</b>", "url": "https://www.linkedin.com/pulse/direct-indirect-communication-styles-marjorie-friesen", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/direct-indirect-communication-styles-marjorie-friesen", "snippet": "Try a slightly <b>different</b> approach \u2013 for example, use less \u201cassertive\u201d <b>language</b> with an indirect communicator.\u201d OR use less \u201csubtle\u201d <b>language</b> with a direct communicator. It\u2019s a 2 ways ...", "dateLastCrawled": "2022-02-03T06:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Types of Figurative Language</b> (With Examples) | <b>Indeed.com</b>", "url": "https://www.indeed.com/career-advice/career-development/figurative-language-examples", "isFamilyFriendly": true, "displayUrl": "https://<b>www.indeed.com</b>/career-advice/career-development/figurative-<b>language</b>-examples", "snippet": "Figurative <b>language</b> is used to: Compare <b>two</b> unlike ideas to increase understanding of one. Describe ideas sometimes difficult to understand. Show a deeper emotion or connection . Influence the audience. Help make connections. Make descriptions easier to visualize. Elicit an emotion. Related: 4 Types of Communication (with Examples) <b>Types of figurative language</b> with examples. Figurative <b>language</b> is used in literature like poetry, drama, prose and even speeches. Figures of speech are literary ...", "dateLastCrawled": "2022-02-03T06:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "NLP Research: Top Papers from 2021 So Far - <b>Read</b> More Here", "url": "https://opendatascience.com/top-recent-nlp-research/", "isFamilyFriendly": true, "displayUrl": "https://opendatascience.com/top-recent-nlp-research", "snippet": "Subnetworks found on the <b>masked</b> <b>language</b> modeling task (the same task used to pre-train the <b>model</b>) transfer universally; those found on other tasks transfer in a limited fashion if at all. As large-scale pre-training becomes an increasingly central paradigm in deep learning, the results demonstrate that the main lottery ticket observations remain relevant in this context. The GitHub repo associated with this paper <b>can</b> be found HERE. BERT Loses Patience: Fast and Robust Inference with Early ...", "dateLastCrawled": "2022-02-03T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Masked</b> education? The benefits and burdens of wearing face masks in ...", "url": "https://europepmc.org/articles/PMC7417296/", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/articles/PMC7417296", "snippet": "1. Introduction. A new coronavirus, SARS-CoV-2, has caused a global pandemic of the disease Covid-19, with \u2013 as of July 31st \u2013 almost 300.000 new cases within a single day, more than 17 million confirmed infections, and more than 670.000 deaths [16].", "dateLastCrawled": "2021-03-14T03:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Quanta Magazine", "url": "https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017/", "isFamilyFriendly": true, "displayUrl": "https://www.quantamagazine.org/machines-beat-humans-on-a-<b>read</b>ing-test-but-do-they...", "snippet": "\u201cThe simplest kind of <b>language</b> <b>model</b> is: I\u2019m going to <b>read</b> a bunch of words and then try to predict the next word,\u201d explained Myle Ott, a research scientist at Facebook. \u201cIf I say, \u2018George Bush was born in,\u2019 the <b>model</b> now has to predict the next word in that sentence.\u201d These deep pretrained <b>language</b> models could be produced relatively efficiently. Researchers simply fed their neural networks massive amounts of written text copied from freely available sources like Wikipedia ...", "dateLastCrawled": "2022-01-30T07:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "FAQs - Unique Identification Authority of India", "url": "https://uidai.gov.in/277-faqs.html", "isFamilyFriendly": true, "displayUrl": "https://<b>uidai</b>.gov.in/277-faqs.html", "snippet": "2. Chatbot (Ask Aadhaar) \u2013 https://<b>uidai</b>.gov.in. <b>UIDAI</b> Chatbot is an automated chat platform available on <b>UIDAI</b> official website ( <b>uidai</b>.gov.in) for quick automated response related to Aadhaar and its services. It is available on the main page of <b>UIDAI</b> website and Resident portal at right bottom.", "dateLastCrawled": "2022-02-02T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 8, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Priming (psychology</b>) - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Priming_(psychology)", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Priming_(psychology</b>)", "snippet": "The <b>masked</b> priming paradigm has been widely used in the last <b>two</b> decades in order to investigate both orthographic and phonological activations during visual word recognition. The term &quot;<b>masked</b>&quot; refers to the fact that the prime word or pseudoword is <b>masked</b> by symbols such as ##### that <b>can</b> be presented in a forward manner (before the prime) or a backward manner (after the prime). These masks enable to diminish the visibility of the prime. The prime is usually presented less than 80 ms (but ...", "dateLastCrawled": "2022-02-02T15:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>R - Quick Guide</b>", "url": "https://www.tutorialspoint.com/r/r_quick_guide.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/r/<b>r_quick_guide</b>.htm", "snippet": "R <b>can</b> <b>read</b> <b>and write</b> into various file formats like csv, excel, xml etc. In this chapter we will learn to <b>read</b> data from a csv file and then <b>write</b> data into a csv file. The file should be present in current working directory so that R <b>can</b> <b>read</b> it. Of course we <b>can</b> also set our own directory and <b>read</b> files from there.", "dateLastCrawled": "2022-02-02T21:43:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> Glossary: <b>Language</b> Evaluation | Google Developers", "url": "https://developers.google.com/machine-learning/glossary/language", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/glossary/<b>language</b>", "snippet": "For instance, a <b>masked</b> <b>language</b> <b>model</b> can calculate probabilities for candidate word(s) to replace the underline in the following sentence: The ____ in the hat came back. The literature typically uses the string &quot;MASK&quot; instead of an underline. For example: The &quot;MASK&quot; in the hat came back. Most modern <b>masked</b> <b>language</b> models are bidirectional.", "dateLastCrawled": "2022-01-29T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Illustrated GPT-2 (Visualizing Transformer <b>Language</b> Models) \u2013 Jay ...", "url": "http://jalammar.github.io/illustrated-gpt2/", "isFamilyFriendly": true, "displayUrl": "jalammar.github.io/illustrated-gpt2", "snippet": "GPT-2 <b>Masked</b> Self-Attention; Beyond <b>Language</b> modeling; You\u2019ve Made it! Part 3: Beyond <b>Language</b> Modeling. <b>Machine</b> Translation; Summarization ; Transfer <b>Learning</b>; Music Generation; Part #1: GPT2 And <b>Language</b> Modeling # So what exactly is a <b>language</b> <b>model</b>? What is a <b>Language</b> <b>Model</b>. In The Illustrated Word2vec, we\u2019ve looked at what a <b>language</b> <b>model</b> is \u2013 basically a <b>machine</b> <b>learning</b> <b>model</b> that is able to look at part of a sentence and predict the next word. The most famous <b>language</b> models ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The <b>language</b> of <b>proteins: NLP, machine learning &amp; protein sequences</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S2001037021000945", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2001037021000945", "snippet": "For example, in the <b>masked</b> <b>language</b> task, some fraction of the tokens in the original text are <b>masked</b> at random, and the <b>language</b> <b>model</b> attempts to predict the original text. (B) (Pre-)trained <b>language</b> models are commonly fine-tuned on downstream tasks over labeled text, through a standard supervised-<b>learning</b> approach. Fine-tuning is typically much faster and provides superior performance than training a <b>model</b> from scratch, especially when labeled data is scarce.", "dateLastCrawled": "2022-02-03T02:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Word Embeddings, WordPiece and Language-Agnostic BERT</b> (LaBSE) | by ...", "url": "https://medium.com/mlearning-ai/word-embeddings-wordpiece-and-language-agnostic-bert-labse-98c7626878c7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/m<b>learning</b>-ai/<b>word-embeddings-wordpiece-and-language-agnostic-bert</b>...", "snippet": "LaBSE <b>model</b> combines <b>masked</b> <b>language</b> <b>model</b> (MLM) and translation <b>language</b> <b>model</b> (TLM) pretraining with a translation ranking task using bi-directional dual encoders.", "dateLastCrawled": "2022-02-03T17:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Natrual <b>language</b> processing basic concepts - <b>language</b> <b>model</b> - word ...", "url": "https://shuffleai.blog/blog/nlp_concepts_part_1.html", "isFamilyFriendly": true, "displayUrl": "https://shuffleai.blog/blog/nlp_concepts_part_1.html", "snippet": "Before deep <b>learning</b>&#39;s domination in natural <b>language</b> processing, a <b>language</b> <b>model</b> is basically a large lookup table, recording frequencies of different combinations of words&#39; occurrences in a large corpus. Now it&#39;s a neural network trained on a corpus or dataset. In addition, a causal <b>language</b> <b>model</b>(e.g., GPT) predicts the next word, and a <b>masked</b> <b>language</b> <b>model</b>(e.g., BERT) fills the blank given the rest of a sentence. If you input &quot;The man ____ to the store&quot; to BERT, it will predict the ...", "dateLastCrawled": "2021-12-24T07:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "An introduction to Deep <b>Learning</b> in Natural <b>Language</b> Processing: Models ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231221010997", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231221010997", "snippet": "The pre-training was driven by two <b>language</b> <b>model</b> objectives, i.e. <b>Masked</b> <b>Language</b> <b>Model</b> (MLM) and Next Sentence Prediction (NSP). In MLM, showed in Fig. 8 , the network masks a small number of words of the input sequence and it tries to predict them in output, whereas in NSP the network tries to understand the relations between sentences by means of a binary loss.", "dateLastCrawled": "2022-01-04T17:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>GitHub</b> - <b>rosinality/ml-papers</b>: My collection of <b>machine</b> <b>learning</b> papers", "url": "https://github.com/rosinality/ml-papers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/rosinality/ml-papers", "snippet": "210413 <b>Masked</b> <b>Language</b> Modeling and the Distributional Hypothesis #<b>language</b>_<b>model</b> #mlm; 210417 mT6 #<b>language</b>_<b>model</b>; 210418 Data-Efficient <b>Language</b>-Supervised Zero-Shot <b>Learning</b> with #multimodal; 210422 ImageNet-21K Pretraining for the Masses #backbone; 210510 Are Pre-trained Convolutions Better than Pre-trained Transformers #nlp #convolution # ...", "dateLastCrawled": "2022-01-31T15:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The 5 <b>Components Towards Building Production-Ready Machine Learning Systems</b>", "url": "https://www.topbots.com/building-production-ready-machine-learning-systems/", "isFamilyFriendly": true, "displayUrl": "https://www.topbots.com/<b>building-production-ready-machine-learning-systems</b>", "snippet": "A well-known recent case study of applying knowledge distillation in practice is Hugging Face\u2019s DistilBERT, which is a smaller <b>language</b> <b>model</b> derived from the supervision of the popular BERT <b>language</b> <b>model</b>. DistilBERT removed the toke-type embeddings and the pooler (used for the next sentence classification task) from BERT while keeping the rest of the architecture identical and reducing the number of layers by a factor of two. Overall, DistilBERT has about half the total number of ...", "dateLastCrawled": "2022-01-25T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "SpringerLink - International Journal of <b>Machine</b> <b>Learning</b> and Cybernetics", "url": "https://link.springer.com/article/10.1007/s13042-020-01069-8", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13042-020-01069-8", "snippet": "The Neural Network <b>Language</b> <b>Model</b> (NNLM) is a pioneering work which introduces the idea of deep <b>learning</b> into <b>language</b> modeling and successfully mitigates the curse of dimensionality (i.e. Sequences in the test set is likely to have not been observed in the training data) by <b>learning</b> a distributed representation of words. The goal of <b>language</b> modeling is to learn a <b>model</b> that predicts the next word given previous ones. Practically, we assume the", "dateLastCrawled": "2022-01-29T10:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Intuitive Introduction to BERT \u2013 MachineCurve</b>", "url": "https://www.machinecurve.com/index.php/2021/01/04/intuitive-introduction-to-bert/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2021/01/04/<b>intuitive-introduction-to-bert</b>", "snippet": "We do however often want to create a <b>machine</b> <b>learning</b> <b>model</b> that can perform one task really well. This is where finetuning comes in: using a labeled corpus, which is often smaller, we can then train the pretrained <b>model</b> further, with an additional or replacing NLP task. The end result is a <b>model</b> that has been pretrained on the large unlabeled corpus and which is finetuned to a specific <b>language</b> task, such as summarization, text generation in a particular domain, or translation.", "dateLastCrawled": "2022-01-30T22:30:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Improving Text Generation with Dynamic Masking and Recovering", "url": "https://www.ijcai.org/proceedings/2021/0534.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/proceedings/2021/0534.pdf", "snippet": "tokens, <b>just as masked language model</b> does. Therefore, our approach jointly maximizes both the likelihoods of both sen-tence generation and prediction of masked tokens. We verify the effectiveness and generality of our ap-proach on three types of text generation tasks which use var-ious forms of input data including text, graph, and image. For sequence-to-sequence (seq2seq) generation task (specif-ically, <b>machine</b> translation), our model obtains signi\ufb01cant improvement of 1.01 and 0.90 BLEU ...", "dateLastCrawled": "2022-01-29T07:50:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(masked language model)  is like +(person who can read and write in two different languages)", "+(masked language model) is similar to +(person who can read and write in two different languages)", "+(masked language model) can be thought of as +(person who can read and write in two different languages)", "+(masked language model) can be compared to +(person who can read and write in two different languages)", "machine learning +(masked language model AND analogy)", "machine learning +(\"masked language model is like\")", "machine learning +(\"masked language model is similar\")", "machine learning +(\"just as masked language model\")", "machine learning +(\"masked language model can be thought of as\")", "machine learning +(\"masked language model can be compared to\")"]}