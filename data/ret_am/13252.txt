{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>convex</b> <b>function</b> in <b>Machine</b> <b>Learning</b> | Data Modelling", "url": "https://datamodelling.org/what-is-convex-function-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://datamodelling.org/what-is-<b>convex</b>-<b>function</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "What is <b>convex</b> <b>function</b> in <b>Machine</b> <b>Learning</b>. Data Science PR. December 29, 2020. Add comment. 1 min read. A <b>function</b> in which the region above the graph of the <b>function</b> is a <b>convex</b> set. The prototypical <b>convex</b> <b>function</b> is shaped something <b>like</b> the letter U. For example, the following are all <b>convex</b> functions: By contrast, the following <b>function</b> is not <b>convex</b>. Notice how the region above the graph is not a <b>convex</b> set: A strictly <b>convex</b> <b>function</b> has exactly one local minimum point, which is ...", "dateLastCrawled": "2022-01-26T23:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>convex</b> <b>function</b> in <b>Machine</b> <b>Learning</b> | Big Data PR", "url": "https://bigdatapr.com/what-is-convex-function-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://bigdatapr.com/what-is-<b>convex</b>-<b>function</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "What is <b>convex</b> <b>function</b> in <b>Machine</b> <b>Learning</b>. A <b>function</b> in which the region above the graph of the <b>function</b> is a <b>convex</b> set. The prototypical <b>convex</b> <b>function</b> is shaped something <b>like</b> the letter U. For example, the following are all <b>convex</b> functions: By contrast, the following <b>function</b> is not <b>convex</b>. Notice how the region above the graph is not ...", "dateLastCrawled": "2022-01-17T23:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Introduction to <b>Convex Optimization</b> for <b>Machine</b> <b>Learning</b>", "url": "https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/optimization/slides.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/optimization/...", "snippet": "Norms (<b>like</b> \u21131 or \u21132 for ... Duchi (UC Berkeley) <b>Convex Optimization</b> for <b>Machine</b> <b>Learning</b> Fall 2009 21 / 53. <b>Convex</b> Functions Examples Important examples in <b>Machine</b> <b>Learning</b> SVM loss: f(w) = 1\u2212yixT i w + Binary logistic loss: f(w) = log 1+exp(\u2212yixT i w) \u22122 3 0 3 [1 - x]+ log(1+ex) Duchi (UC Berkeley) <b>Convex Optimization</b> for <b>Machine</b> <b>Learning</b> Fall 2009 22 / 53. <b>Convex Optimization</b> Problems <b>Convex Optimization</b> Problems De\ufb01nition An optimization problem is <b>convex</b> if its objective is ...", "dateLastCrawled": "2022-02-03T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Why the <b>Convex</b> <b>Function</b>?. Gradient Descent 101: Basics of\u2026 | by Pavan ...", "url": "https://medium.com/@pavantejanagisetti/why-the-convex-function-2f52cc080418", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@pavantejanagisetti/why-the-<b>convex</b>-<b>function</b>-2f52cc080418", "snippet": "\u201c<b>Machine</b> <b>Learning</b> at its crux is an Optimization problem\u201d I think I\u2019ve read the above line somewhere on Quora. Any <b>function</b> (with how many ever parameters/variables) if it has a minima, it ...", "dateLastCrawled": "2021-12-26T09:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Report for CS229: <b>Convex</b> Optimization For <b>Machine</b> <b>Learning</b> (cvx4ml)", "url": "http://cs229.stanford.edu/proj2017/final-reports/5242031.pdf", "isFamilyFriendly": true, "displayUrl": "cs229.stanford.edu/proj2017/final-reports/5242031.pdf", "snippet": "Report for CS229: <b>Convex</b> Optimization For <b>Machine</b> <b>Learning</b> (cvx4ml) Abstract \u201cHumanity is a wandering fires in the fog. The appearance of breakthroughs through the fog from one flame to another can be called a miracle - A.N. Kolmogorov\u201d. <b>Machine</b> <b>Learning</b> connects engineering fields with usual people life. But I believe that <b>Machine</b> <b>Learning</b> can be improved by mathematical optimization, which has already become an important tool in many areas. Very important that there are effective ...", "dateLastCrawled": "2022-01-11T23:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Why study <b>convex optimization</b> for theoretical <b>machine</b> <b>learning</b>? - Cross ...", "url": "https://stats.stackexchange.com/questions/324981/why-study-convex-optimization-for-theoretical-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/324981", "snippet": "$\\begingroup$ <b>Machine</b> <b>Learning</b> is about building <b>function</b> approximation <b>like</b> couning methods, ... The big problem is that many problems in the <b>machine</b> <b>learning</b> are non-<b>convex</b>. $\\endgroup$ \u2013 Jan Kukacka. Feb 4 &#39;18 at 21:56. Add a comment | 1 $\\begingroup$ If your interests lie in (<b>convex</b>) optimisation applied to deep <b>learning</b> (you mention transfer <b>learning</b>, which is widely used in practice with neural networks) applications, I strongly encourage you to consider reading chapter 8 ...", "dateLastCrawled": "2022-01-25T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Why is Convex Optimization such a big</b> deal in <b>Machine</b> <b>Learning</b>? - Quora", "url": "https://www.quora.com/Why-is-Convex-Optimization-such-a-big-deal-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Why-is-Convex-Optimization-such-a-big</b>-deal-in-<b>Machine</b>-<b>Learning</b>", "snippet": "Answer (1 of 10): <b>Convex</b> optimization is the core of most <b>machine</b> <b>learning</b> methods Some key concepts here: - <b>Convex</b> functions are those for which it&#39;s possible to draw a line segment from any two points on the graph and this line will always be inside the graph (except at the endpoints). This m...", "dateLastCrawled": "2022-01-17T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "8. <b>Gradient descent</b> \u2014 <b>Machine</b> <b>Learning</b> 101 documentation", "url": "https://machinelearning101.readthedocs.io/en/latest/_pages/08_gradient_decent.html", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>101.readthedocs.io/en/latest/_pages/08_gradient_decent.html", "snippet": "<b>Gradient Descent</b> is a method used while training a <b>machine</b> <b>learning</b> model. It is an optimization algorithm, based on a <b>convex</b> <b>function</b>, that tweaks it\u2019s parameters iteratively to minimize a given <b>function</b> to its local minimum. It is simply used to find the values of a functions parameters (coefficients) that minimize a cost <b>function</b> as far as possible. You start by defining the initial parameters values and from there on <b>Gradient Descent</b> iteratively adjusts the values, using calculus, so ...", "dateLastCrawled": "2022-01-30T07:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Why are most of the <b>machine learning algorithms a convex optimization</b> ...", "url": "https://www.quora.com/Why-are-most-of-the-machine-learning-algorithms-a-convex-optimization-problem", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-are-most-of-the-<b>machine-learning-algorithms-a-convex</b>...", "snippet": "Answer: Thanks for the A2A , I really <b>like</b> Avinash\u2019s answer - My answer too is that they Are Not ! but we need them to be :) The next question is do we always or can we make do sometimes ? The most important thing is to get a model which is generalized (works well on unseen data). A <b>Convex</b> Funct...", "dateLastCrawled": "2022-01-24T22:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - Cost <b>function</b> of neural network is non-<b>convex</b> ...", "url": "https://stats.stackexchange.com/questions/106334/cost-function-of-neural-network-is-non-convex", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/106334", "snippet": "The cost <b>function</b> of a neural network is in general neither <b>convex</b> nor concave. This means that the matrix of all second partial derivatives (the Hessian) is neither positive semidefinite, nor negative semidefinite. Since the second derivative is a matrix, it&#39;s possible that it&#39;s neither one or the other. To make this analogous to one-variable ...", "dateLastCrawled": "2022-02-03T01:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning Note - Convex Optimization</b> | Xiaowen Ying", "url": "https://www.xiaowenying.com/machine-learning/2019/11/11/Convex-Optimization.html", "isFamilyFriendly": true, "displayUrl": "https://www.xiaowenying.com/<b>machine</b>-<b>learning</b>/2019/11/11/<b>Convex</b>-Optimization.html", "snippet": "<b>Machine Learning Note - Convex Optimization</b>. 11 November 2019. Introduction . I\u2019ve been taking an online <b>Machine</b> <b>Learning</b> class recently. This post is my note on <b>convex</b> optimization part. Contents. Optimization. 1. Overview; 2. Standard Form; 3. Categories; <b>Convex</b> Optimization. 1. <b>Convex</b> Set: 2. <b>Convex</b> <b>Function</b>. 2.1 Definition; 2.2 First Order Convexity Condition; 2.3 Second Order Convexity Condtion; 3. Proof of Convexity; Optimization 1. Overview. AI problem = Model + Optimization ...", "dateLastCrawled": "2022-01-01T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimization Algorithms for <b>Machine</b> <b>Learning</b> | by Aviejay Paul ...", "url": "https://towardsdatascience.com/optimization-algorithms-for-machine-learning-d98d0feef53e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/optimization-algorithms-for-<b>machine</b>-<b>learning</b>-d98d0feef53e", "snippet": "Every local minimum of a <b>convex</b> <b>function</b> f on a <b>convex</b> set S\u2286\u211d is a global minimum. Let us first try and understand what exactly local minimum and global minimum is. Consider any <b>convex</b> <b>function</b> f with domain of S. So, local minima of f(x) at a point in the domain of f(x) would mean:", "dateLastCrawled": "2022-02-02T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Convex Optimization &amp; Machine Learning Convex Functions</b>", "url": "http://marcocuturi.net/Teaching/KU/2011/COML/Lec2-COML.pdf", "isFamilyFriendly": true, "displayUrl": "marcocuturi.net/Teaching/KU/2011/COML/Lec2-COML.pdf", "snippet": "<b>Convex Optimization &amp; Machine Learning Convex Functions</b> mcuturi@i.kyoto-u.ac.jp Most slides in this lecture are taken from CO&amp;ML 1. Quizz if C and C\u2032 are two <b>convex</b> sets, then C \u222aC\u2032 is <b>convex</b>? 1. Yes 2. No CO&amp;ML 2. Quizz if C and C\u2032 are two <b>convex</b> sets, then C \u222aC\u2032 is <b>convex</b>? 1. Yes 2. No if Ci is a family of <b>convex</b> sets, then T i\u2208I Ci is <b>convex</b> CO&amp;ML 3. Quizz The matrix M = 3 2 1 2 5 3 1 2 8 is positive de\ufb01nite? 1. Yes 2. No CO&amp;ML 4. Quizz The matrix M = 3 2 1 2 5 3 1 2 8 is ...", "dateLastCrawled": "2021-09-20T11:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Why is Convex Optimization such a big</b> deal in <b>Machine</b> <b>Learning</b>? - Quora", "url": "https://www.quora.com/Why-is-Convex-Optimization-such-a-big-deal-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Why-is-Convex-Optimization-such-a-big</b>-deal-in-<b>Machine</b>-<b>Learning</b>", "snippet": "Answer (1 of 10): <b>Convex</b> optimization is the core of most <b>machine</b> <b>learning</b> methods Some key concepts here: - <b>Convex</b> functions are those for which it&#39;s possible to draw a line segment from any two points on the graph and this line will always be inside the graph (except at the endpoints). This m...", "dateLastCrawled": "2022-01-17T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Optimization for <b>Machine</b> <b>Learning</b> From <b>Convex</b> to Non-<b>convex</b>", "url": "https://project.inria.fr/paiss/files/2021/07/bach21_PAISS_with_video.pdf", "isFamilyFriendly": true, "displayUrl": "https://project.inria.fr/paiss/files/2021/07/bach21_PAISS_with_video.pdf", "snippet": "<b>Convex</b> optimization problems min \u03b8\u2208Rd 1 n Xn i=1 n \u2113 yi,h(xi,\u03b8) + \u03bb\u03a9(\u03b8) o \u2022 Conditions: <b>Convex</b> loss and linear predictions h(x,\u03b8) = \u03b8\u22a4\u03a6(x) \u2022 Consequences \u2013 E\ufb03cient algorithms (typically gradient-based) \u2013 Quantitative runtime and prediction performance guarantees - Golden years of convexity in <b>machine</b> <b>learning</b> (1995 to 2020)", "dateLastCrawled": "2022-01-28T05:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Why study <b>convex optimization</b> for theoretical <b>machine</b> <b>learning</b>? - Cross ...", "url": "https://stats.stackexchange.com/questions/324981/why-study-convex-optimization-for-theoretical-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/324981", "snippet": "$\\begingroup$ <b>Machine</b> <b>Learning</b> is about building <b>function</b> approximation like couning methods, ... and I work a <b>similar</b> problem with <b>convex optimization</b> and take my answer and find a solution to the non-<b>convex</b> problem that costs 2 million dollars, I&#39;ve found a better answer. $\\endgroup$ \u2013 prosfilaes. Jan 27 &#39;18 at 16:14 $\\begingroup$ This answer is flawed on so many levels. Comparing <b>convex</b> analysis to the streetlight effect is just wrong. I would advise you to refer to the introductory ...", "dateLastCrawled": "2022-01-25T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What are <b>convex</b> and non-<b>convex</b> functions, and how are they used in ...", "url": "https://www.quora.com/What-are-convex-and-non-convex-functions-and-how-are-they-used-in-Machine-Learning-optimization-problems-such-as-gradient-descent", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>convex</b>-and-non-<b>convex</b>-<b>functions</b>-and-how-are-they-used...", "snippet": "Answer: For <b>convex</b> and non-<b>convex</b> functions, you can look on Wikipedia. The prototype of a <b>convex</b> <b>function</b> is a (piece-wise) linear <b>function</b> f(x)=ax+b or a parabola f(x)=x^2. For a non-<b>convex</b> <b>function</b>, you can look for example f(x)=x^3. The key word is that of semi-positivity of the Hessian of th...", "dateLastCrawled": "2022-01-21T09:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Price Optimisation with <b>convex</b> and non-<b>convex</b> loss functions | by ...", "url": "https://towardsdatascience.com/convex-and-non-convex-optimisation-899174802b60", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>convex</b>-and-non-<b>convex</b>-optimisation-899174802b60", "snippet": "A <b>convex</b> optimisat i on problem is a problem where all of the constraints are <b>convex</b> functions, and the objective is a <b>convex</b> <b>function</b> if minimising, or a concave <b>function</b> if maximising. A <b>convex</b> <b>function</b> can be described as a smooth surface with a single global minimum. Example of a <b>convex</b> <b>function</b> is as below: F(x,y) = x2 + xy + y2.", "dateLastCrawled": "2022-01-30T23:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - Example of <b>convex</b> activation <b>function</b> - Data Science ...", "url": "https://datascience.stackexchange.com/questions/73718/example-of-convex-activation-function", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/.../73718/example-of-<b>convex</b>-activation-<b>function</b>", "snippet": "Bookmark this question. Show activity on this post. For a particular task, I need a <b>convex</b> activation <b>function</b> with the following properties: f&#39;&#39; (x) &gt; 0. 0 &lt;= f (x) &lt;= 1. f (x) is monotonic. f (x) is not &quot;exploding&quot; i.e. avoiding functions such as f (x) = x\u00b2. The only example I have in mind for this is the softplus activation <b>function</b>.", "dateLastCrawled": "2022-01-12T07:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - <b>Non-Convex</b> Loss <b>Function</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/279292/non-convex-loss-function", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/279292/<b>non-convex</b>-loss-<b>function</b>", "snippet": "We know &quot;if a <b>function</b> is a <b>non-convex</b> loss <b>function</b> without plotting the graph&quot; by using Calculus.To quote Wikipedia&#39;s <b>convex</b> <b>function</b> article: &quot;If the <b>function</b> is twice differentiable, and the second derivative is always greater than or equal to zero for its entire domain, then the <b>function</b> is <b>convex</b>.&quot; If the second derivative is always greater than zero then it is strictly <b>convex</b>. Therefore if we can prove that the second derivatives of our selected cost <b>function</b> are always positive the ...", "dateLastCrawled": "2022-01-24T08:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Convex Optimization with Submodular Functions</b> \u2013 Optimization in <b>Machine</b> ...", "url": "https://wordpress.cs.vt.edu/optml/2018/03/20/convex-optimization-with-submodular-functions/", "isFamilyFriendly": true, "displayUrl": "https://wordpress.cs.vt.edu/optml/2018/03/20/<b>convex-optimization-with-submodular-functions</b>", "snippet": "The base polyhedra, B(F), <b>can</b> <b>be thought</b> of as the hollow outer shell of the set <b>function</b> formed by the intersecting constraint hyperplanes and the submodular polyhedra, P(F), <b>can</b> <b>be thought</b> of as the base polyhdra and the discrete, encapsulated, non-empty interior space encompassed by the base polyhedra. What we found confusing was whether Figure 2.1 below was representing just the domain of the set <b>function</b>, F, or if it was also representing the <b>function</b> values. We agreed that we <b>thought</b> ...", "dateLastCrawled": "2022-01-23T15:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Generalization of <b>Convex</b> Sets and <b>Convex</b> Functions | Mathematics ...", "url": "https://mathematics-tech.org/mathematics/a-generalization-of-convex-sets-and-convex-functions-with-machine-learning-applications/", "isFamilyFriendly": true, "displayUrl": "https://mathematics-tech.org/mathematics/a-generalization-of-<b>convex</b>-sets-and-<b>convex</b>...", "snippet": "A <b>Convex</b> set is the same as an order-<b>convex</b> set; A <b>convex</b> <b>function</b> defined in terms of a <b>convex</b> set; A <b>convex</b> <b>function</b> in terms of order-convexity ; <b>Convex</b> sets and <b>convex</b> functions in <b>machine</b> <b>learning</b>. <b>Convex</b> Optimization; Software Libraries . SUMMARY: We define a <b>convex</b> set in a general framework of a vector space over a field with a partial order, and we show how the general notion is related to the usual notion of a <b>convex</b> set. Then we define a <b>convex</b> <b>function</b> in terms of that general ...", "dateLastCrawled": "2021-12-03T16:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Why is Convex Optimization such a big</b> deal in <b>Machine</b> <b>Learning</b>? - Quora", "url": "https://www.quora.com/Why-is-Convex-Optimization-such-a-big-deal-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Why-is-Convex-Optimization-such-a-big</b>-deal-in-<b>Machine</b>-<b>Learning</b>", "snippet": "Answer (1 of 10): <b>Convex</b> optimization is the core of most <b>machine</b> <b>learning</b> methods Some key concepts here: - <b>Convex</b> functions are those for which it&#39;s possible to draw a line segment from any two points on the graph and this line will always be inside the graph (except at the endpoints). This m...", "dateLastCrawled": "2022-01-17T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Convex</b> Optimization Overview", "url": "https://cs229.stanford.edu/section/cs229-cvxopt.pdf", "isFamilyFriendly": true, "displayUrl": "https://cs229.stanford.edu/section/cs229-cvxopt.pdf", "snippet": "Many situations arise in <b>machine</b> <b>learning</b> where we would like to optimize the value of some <b>function</b>. That is, given a <b>function</b> f : Rn \u2192 R, we want to \ufb01nd x \u2208 Rn that minimizes (or maximizes) f(x). We have already seen several examples of optimization problems in class: least-squares, logistic regression, and support vector machines <b>can</b> all be framed as optimization problems. It turns out that, in the general case, \ufb01nding the global optimum of a <b>function</b> <b>can</b> be a very di\ufb03cult task ...", "dateLastCrawled": "2022-01-30T03:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Theory <b>of Convex Optimization for Machine Learning</b>", "url": "https://www.researchgate.net/publication/262489426_Theory_of_Convex_Optimization_for_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/262489426_Theory_of_<b>Convex</b>_Optimization_for...", "snippet": "A central object of study in this area is the notion of acceleration -an algorithmic technique that <b>can</b> be deployed when minimizing a smooth <b>convex</b> <b>function</b> f (\u00b7) via queries to a first-order ...", "dateLastCrawled": "2021-11-07T19:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Norms and <b>machine</b> <b>learning</b> | A blog on science", "url": "https://ekamperi.github.io/machine%20learning/2019/10/19/norms-in-machine-learning.html", "isFamilyFriendly": true, "displayUrl": "https://ekamperi.github.io/<b>machine</b> <b>learning</b>/2019/10/19/norms-in-<b>machine</b>-<b>learning</b>.html", "snippet": "So, by using a cost <b>function</b> that happens to be the norm of a vector space, we end up with a <b>convex</b> optimization <b>function</b> that behaves very well. Also, adding a penalty term from, say, \\(\\ell_p\\) norm preserves the convexity of the cost <b>function</b> (assuming it was <b>convex</b> before, obviously). Because the sum of two <b>convex</b> functions is also a <b>convex</b> ...", "dateLastCrawled": "2022-02-03T02:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - Explanation of why Neural Networks are non <b>convex</b> ...", "url": "https://datascience.stackexchange.com/questions/87961/explanation-of-why-neural-networks-are-non-convex", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/87961/explanation-of-why-neural...", "snippet": "where g ( x) is a subgradient at x the <b>function</b> is non-<b>convex</b>. This is pretty simple to follow from the Mid-point value theorem and the definition of convexity. Consider a neural network F ( \u22c5) with a few layers and name three layers L 1, L 2 and L 3 Consider nodes a and b in L 1 and c and d in L 2 .Let the parameters connecting node i to j ...", "dateLastCrawled": "2022-01-24T10:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[D] <b>Can</b> Stochastic Gradient Descent Converge on Non-<b>Convex</b> Functions ...", "url": "https://www.reddit.com/r/MachineLearning/comments/slnvzw/d_can_stochastic_gradient_descent_converge_on/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/slnvzw/d_<b>can</b>_stochastic_gradient...", "snippet": "For instance, in <b>Machine</b> <b>Learning</b> applications with Neural Networks in the real world - Loss Functions almost always tend to be Non-<b>Convex</b>. Seeing as Non-<b>Convex</b> Functions usually have Saddle Points (i.e. point where the first derivatives of the Loss <b>Function</b> is 0), these usually &quot;trap&quot; and prevent the Gradient Descent from reaching the optimal point, since Gradient Descent <b>can</b> not move forward when the derivative is 0. I am aware of famous adaptions of Gradient Descent and Stochastic ...", "dateLastCrawled": "2022-02-07T14:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Cs229-cvxopt 2 - <b>Machine</b> <b>learning</b> by andrew - <b>Convex</b> Optimization ...", "url": "https://www.studocu.com/en-us/document/stanford-university/machine-learning/cs229-cvxopt-2-machine-learning-by-andrew/1403931", "isFamilyFriendly": true, "displayUrl": "https://www.studocu.com/en-us/document/stanford-university/<b>machine</b>-<b>learning</b>/cs229...", "snippet": "Intuitively, the Lagrangian <b>can</b> <b>be thought</b> of as a modified version of the objective <b>function</b> to the original <b>convex</b> optimization problem (OPT) which accounts for each of the constraints. The Lagrange multipliers\u03b1iand\u03b2ican <b>be thought</b> of \u201ccosts\u201d associated with violating different constraints. The key intuition behind the theory of Lagrangeduality is the following:", "dateLastCrawled": "2022-02-02T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Mathematics of Machine Learning</b> - University of Cambridge", "url": "http://www.statslab.cam.ac.uk/~rds37/teaching/machine_learning/notes.pdf", "isFamilyFriendly": true, "displayUrl": "www.statslab.cam.ac.uk/~rds37/teaching/<b>machine</b>_<b>learning</b>/notes.pdf", "snippet": "<b>Mathematics of Machine Learning</b> Rajen D. Shah r.shah@statslab.cam.ac.uk 1 Introduction Consider a pair of random variables (X;Y) 2XY with joint distribution P 0, where X is to <b>be thought</b> of as an input or vector of predictors, and Y as an output or response. For instance Xmay represent a collection of disease risk factors (e.g. BMI, age, genetic indicators etc.) for a subject randomly selected from a population and Y may represent their disease status; or Xcould represent the number or ...", "dateLastCrawled": "2022-02-03T05:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Why is Convex Optimization such a big</b> deal in <b>Machine</b> <b>Learning</b>? - Quora", "url": "https://www.quora.com/Why-is-Convex-Optimization-such-a-big-deal-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Why-is-Convex-Optimization-such-a-big</b>-deal-in-<b>Machine</b>-<b>Learning</b>", "snippet": "Answer (1 of 10): <b>Convex</b> optimization is the core of most <b>machine</b> <b>learning</b> methods Some key concepts here: - <b>Convex</b> functions are those for which it&#39;s possible to draw a line segment from any two points on the graph and this line will always be inside the graph (except at the endpoints). This m...", "dateLastCrawled": "2022-01-17T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>machine</b> <b>learning</b> - Why do we want an objective <b>function</b> to be a <b>convex</b> ...", "url": "https://stats.stackexchange.com/questions/219899/why-do-we-want-an-objective-function-to-be-a-convex-function", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/219899", "snippet": "Show activity on this post. I understand that a <b>convex</b> <b>function</b> is a great object <b>function</b> since a local minimum is the global minimum. However, there are non-<b>convex</b> functions that also carry this property. For example, this figure shows a non-<b>convex</b> <b>function</b> that carries the above property. It seems to me that, as long as the local minimum is ...", "dateLastCrawled": "2022-01-14T20:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Convex Optimization in R</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/convex-optimization-in-r/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>convex-optimization-in-r</b>", "snippet": "<b>Convex Optimization in R</b>. By Jason Brownlee on August 29, 2014 in R <b>Machine</b> <b>Learning</b>. Last Updated on August 22, 2019. Optimization is a big part of <b>machine</b> <b>learning</b>. It is the core of most popular methods, from least squares regression to artificial neural networks. In this post you will discover recipes for 5 optimization algorithms in R.", "dateLastCrawled": "2022-02-03T13:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "2 <b>Convex</b> Variational Formulations for <b>Learning</b> Problems", "url": "http://www.optimization-online.org/DB_FILE/2016/08/5586.pdf", "isFamilyFriendly": true, "displayUrl": "www.optimization-online.org/DB_FILE/2016/08/5586.pdf", "snippet": "Quadratic Programming, <b>Machine</b> <b>Learning</b> I. INTRODUCTION The regression problem has been studied for centuries and recently gained renewed attention due to the huge variety of applications it has in <b>machine</b> <b>learning</b> problems. When the <b>function</b> generating the data is linear, least squares is the most effective technique. On the other hand, when the <b>function</b> generating the data is nonlinear there are several computational techniques available to solve the problem. The most important ones are ...", "dateLastCrawled": "2022-01-31T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>learning</b> algorithm based on <b>convex</b> hull analysis - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1877050921009911", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050921009911", "snippet": "In this paper <b>machine</b> <b>learning</b> methods for automatic classification problems using computational geometry are considered. Classes are defined with <b>convex</b> hulls of points sets in a multidimensional feature space. Classification algorithms based on the estimation of the proximity of the test point to <b>convex</b> class shells are considered. Several ways of such estimation are suggested when the test point is located both outside the <b>convex</b> hull and inside it. A new method for estimating proximity ...", "dateLastCrawled": "2022-02-02T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Theory <b>of Convex Optimization for Machine Learning</b>", "url": "https://www.researchgate.net/publication/262489426_Theory_of_Convex_Optimization_for_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/262489426_Theory_of_<b>Convex</b>_Optimization_for...", "snippet": "A central object of study in this area is the notion of acceleration -an algorithmic technique that <b>can</b> be deployed when minimizing a smooth <b>convex</b> <b>function</b> f (\u00b7) via queries to a first-order ...", "dateLastCrawled": "2021-11-07T19:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b>: Algorithms, Real-World Applications and Research ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7983091/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7983091", "snippet": "Supervised: Supervised <b>learning</b> is typically the task of <b>machine</b> <b>learning</b> to learn a <b>function</b> that maps an input to an output based on sample input-output pairs [].It uses labeled training data and a collection of training examples to infer a <b>function</b>. Supervised <b>learning</b> is carried out when certain goals are identified to be accomplished from a certain set of inputs [], i.e., a task-driven approach.The most common supervised tasks are \u201cclassification\u201d that separates the data, and ...", "dateLastCrawled": "2022-01-27T01:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Convolutional Neural Network and Convex Optimization</b>", "url": "https://acsweb.ucsd.edu/~yuw176/report/ECE273.pdf", "isFamilyFriendly": true, "displayUrl": "https://acsweb.ucsd.edu/~yuw176/report/ECE273.pdf", "snippet": "This report shows that the performance of deep convolutional neural network <b>can</b> be improved by incorporating <b>convex</b> optimization techniques. First, we \ufb01nd that the sub-models learned by dropout <b>can</b> be more e ectively combined by solving a <b>convex</b> problem. Also, we generalize this idea to models that are not trained by dropout. <b>Compared</b> to traditional methods, we get an improvement of 0.22% and 0.76% test accuracy on CIFAR10 dataset. Second, we investigate the performance for di erent loss ...", "dateLastCrawled": "2022-01-27T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Understanding Non-convex Optimization</b>", "url": "https://praneethnetrapalli.org/UnderstandingNonconvexOptimization-V5.pdf", "isFamilyFriendly": true, "displayUrl": "https://praneethnetrapalli.org/<b>UnderstandingNonconvexOptimization</b>-V5.pdf", "snippet": "\u2022<b>Convex</b> optimization ()is a <b>convex</b> <b>function</b>, \ud835\udc9eis <b>convex</b> set \u2022ut \u201ctoday\u2019s problems\u201d, and this tutorial, are non-<b>convex</b> \u2022Our focus: non-<b>convex</b> problems that arise in <b>machine</b> <b>learning</b> Variable, in \ud835\udc51 <b>function</b> feasible set. Outline of Tutorial Part I (algorithms &amp; background) \u2022<b>Convex</b> optimization (brief overview) \u2022Nonconvex optimization Part II \u2022Example applications of nonconvex optimization \u2022Open directions. <b>Convex</b> Functions onvex functions \u201clie below the line\u201d \ud835\udf40 ...", "dateLastCrawled": "2022-01-30T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[D] <b>Can</b> Stochastic Gradient Descent Converge on Non-<b>Convex</b> Functions ...", "url": "https://www.reddit.com/r/MachineLearning/comments/slnvzw/d_can_stochastic_gradient_descent_converge_on/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/slnvzw/d_<b>can</b>_stochastic_gradient...", "snippet": "For instance, in <b>Machine</b> <b>Learning</b> applications with Neural Networks in the real world - Loss Functions almost always tend to be Non-<b>Convex</b>. Seeing as Non-<b>Convex</b> Functions usually have Saddle Points (i.e. point where the first derivatives of the Loss <b>Function</b> is 0), these usually &quot;trap&quot; and prevent the Gradient Descent from reaching the optimal point, since Gradient Descent <b>can</b> not move forward when the derivative is 0. I am aware of famous adaptions of Gradient Descent and Stochastic ...", "dateLastCrawled": "2022-02-07T14:27:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "11.2. <b>Convexity</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_optimization/convexity.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_optimization/<b>convexity</b>.html", "snippet": "A twice-differentiable <b>function</b> is <b>convex</b> if and only if its Hessian (a matrix of second derivatives) is positive semidefinite. <b>Convex</b> constraints can be added via the Lagrangian. In practice we may simply add them with a penalty to the objective <b>function</b>. Projections map to points in the <b>convex</b> set closest to the original points.", "dateLastCrawled": "2022-01-30T21:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "<b>Machine</b> <b>learning</b> terminology for model building and validation There seems to be an <b>analogy</b> between statistical modeling and <b>machine</b> <b>learning</b> that we will cover in subsequent chapters in depth. However, a quick view has been provided as follows: in statistical modeling, linear regression with two independent variables is trying to fit the best plane with\u2026", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Gradient</b> Descent: A Quick, Simple Introduction | Built In", "url": "https://builtin.com/data-science/gradient-descent", "isFamilyFriendly": true, "displayUrl": "https://builtin.com/data-science/<b>gradient</b>-descent", "snippet": "<b>Gradient</b> descent is an optimization algorithm that&#39;s used when training a <b>machine</b> <b>learning</b> model. It&#39;s based on a <b>convex</b> <b>function</b> and tweaks its parameters iteratively to minimize a given <b>function</b> to its local minimum.", "dateLastCrawled": "2022-02-02T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Introduction to <b>Machine</b> <b>Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-machine-learning-3/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-<b>machine</b>-<b>learning</b>-3", "snippet": "The loss <b>function</b> or cost <b>function</b> in <b>machine</b> <b>learning</b> is a <b>function</b> that maps the values of variables onto a real number intuitively representing some cost associated with the variable values. Optimization methods are applied to minimize the loss <b>function</b> by changing the parameter values, which is the central theme of <b>machine</b> <b>learning</b>.", "dateLastCrawled": "2022-01-28T18:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "Probability Estimation: when the output of the <b>function</b> is a probability. <b>Machine Learning</b> in Practice. <b>Machine learning</b> algorithms are only a very small part of using <b>machine learning</b> in practice as a data analyst or data scientist. In practice, the process often looks like: Start Loop Understand the domain, prior knowledge and goals. Talk to ...", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How the good old sorting algorithm helps a great <b>machine learning</b> ...", "url": "https://towardsdatascience.com/how-the-good-old-sorting-algorithm-helps-a-great-machine-learning-technique-9e744020254b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-the-good-old-sorting-algorithm-helps-a-great...", "snippet": "A geometric explanation of how the SVM works: <b>Convex</b> Hull. The formal mathematics behind the SVM algorithm is fairly complex but intuitively it can be understood by considering a special geometric construct called <b>convex</b> hull. What is <b>Convex</b> Hull? Formally a <b>convex</b> hull or <b>convex</b> envelope or <b>convex</b> closure of a set X of points in the Euclidean plane or in a Euclidean space is the smallest <b>convex</b> set that contains X. However it is easiest to visualize using the rubber band <b>analogy</b>. Imagine ...", "dateLastCrawled": "2022-01-31T15:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Solving Word <b>Analogies: A Machine Learning Perspective</b> | Request PDF", "url": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_Machine_Learning_Perspective", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335597029_Solving_Word_Analogies_A_<b>Machine</b>...", "snippet": "We introduce a supervised corpus-based <b>machine</b> <b>learning</b> algorithm for classifying analogous word pairs, and we show that it can solve multiple-choice SAT <b>analogy</b> questions, TOEFL synonym questions ...", "dateLastCrawled": "2021-10-16T21:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>machine</b> <b>learning</b> - How does Gradient Descent work? - Data Science Stack ...", "url": "https://datascience.stackexchange.com/questions/102509/how-does-gradient-descent-work", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/102509/how-does-gradient-descent-work", "snippet": "If the <b>function</b> we minimize was <b>convex</b>, it would not matter what we choose for initial values, as gradient descent would get us to the minimum no matter what. But as the dimensions of the model increase, it is extremely unlikely that we have a <b>convex</b> loss <b>function</b>. And in this case, initialization of the weight depends on the activation functions used in the model. As discussed in", "dateLastCrawled": "2022-01-16T12:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Regularization : What? Why? and How? (Part -1) | by Siddhant Rai ...", "url": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "isFamilyFriendly": true, "displayUrl": "https://medium.com/m<b>learning</b>-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "snippet": "In general <b>machine</b> <b>learning</b> sense, it is solving an objective <b>function</b> to perform maximum or minimum evaluation. In reality, optimization is lot more profound in usage. Then we have two terms ...", "dateLastCrawled": "2022-01-28T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - Cost <b>function</b> of neural network is non-<b>convex</b> ...", "url": "https://stats.stackexchange.com/questions/106334/cost-function-of-neural-network-is-non-convex", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/106334", "snippet": "$\\begingroup$ I mean, this is how it should be interpreted, not just an <b>analogy</b>. $\\endgroup$ \u2013 avocado. May 23 &#39;16 at 12:27 . 5 $\\begingroup$ @loganecolss You are correct that this is not the only reason why cost functions are non-<b>convex</b>, but one of the most obvious reasons. Depdending on the network and the training set, there might be other reasons why there are multiple minima. But the bottom line is: The permuation alone creates non-convexity, regardless of other effects. $\\endgroup ...", "dateLastCrawled": "2022-02-03T01:18:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(convex function)  is like +(machine learning)", "+(convex function) is similar to +(machine learning)", "+(convex function) can be thought of as +(machine learning)", "+(convex function) can be compared to +(machine learning)", "machine learning +(convex function AND analogy)", "machine learning +(\"convex function is like\")", "machine learning +(\"convex function is similar\")", "machine learning +(\"just as convex function\")", "machine learning +(\"convex function can be thought of as\")", "machine learning +(\"convex function can be compared to\")"]}