{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>sparse</b>(1) - Linux manual page", "url": "https://www.man7.org/linux/man-pages/man1/sparse.1.html", "isFamilyFriendly": true, "displayUrl": "https://www.man7.org/linux/man-pages/man1/<b>sparse</b>.1.html", "snippet": "<b>Sparse</b> does not issue these warnings by default, processing &#39;{ 0 }&#39; the same as &#39;{ }&#39;. -Wunion-cast Warn on casts to union types. <b>Sparse</b> does not issues these warnings by default. MISC OPTIONS top--<b>arch</b>=<b>ARCH</b> Specify the target architecture.", "dateLastCrawled": "2022-01-29T21:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Sparse</b> <b>Representation for Different Animal Vertebra</b> Classification ...", "url": "https://www.hindawi.com/journals/jspec/2020/2521696/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/jspec/2020/2521696", "snippet": "The ideal position is approached by that the screw is placed through the <b>arch</b> of the cancellous bone till the tip arrives at the cortical bone. In the previous study, the method based on optical spectrum and needle-<b>like</b> probe presented a new way to overcome the two problems to the most extent, which was working on the principle of the local bone reflectance spectrum. In this study, different animal bones were used in the experiment, including porcine vertebra, bovine vertebra, and ovine ...", "dateLastCrawled": "2022-01-02T01:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A NOVEL SELF-TAUGHT <b>LEARNING FRAMEWORK USING SPATIAL PYRAMID MATCHING</b> ...", "url": "https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/725/2020/isprs-archives-XLIII-B2-2020-725-2020.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.int-<b>arch</b>-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/725/2020/...", "snippet": "dictionary learning, <b>sparse</b> <b>representation</b> and classi\ufb01cation. It is generally believed that in the dictionary learning stage, although unsupervised, one should use the same data set as classi\ufb01cation stage to get good results. However, recent studies in transfer learning suggest that it might be a better strategy to train the dictionary on a larger data set different from the one to classify. In our work, we propose an algorithm that combines ScSPM with self-taught learning, a transfer ...", "dateLastCrawled": "2021-09-01T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "High-dimensional penalized <b>ARCH</b> processes", "url": "http://www.crest.fr/ckfinder/userfiles/files/Pageperso/fermania/Sparse_ARCH_Fermanian_Poignard.pdf", "isFamilyFriendly": true, "displayUrl": "www.crest.fr/ckfinder/userfiles/files/Pageperso/fermania/<b>Sparse</b>_<b>ARCH</b>_Fermanian...", "snippet": "multivariate <b>ARCH</b> models admit a linear <b>representation</b> with respect to the pa-3. rameters, contrary to GARCH ones. Note that any \\invertible&quot; GARCH process may be written as an in nite order <b>ARCH</b> model, under some conditions on its coe cients. Therefore, we argue that highly parameterized <b>ARCH</b> models (with numerous lags) should behave at least as well as more usual GARCH models, in terms of realism and exibility. Nonetheless, for the purpose of parsimony and to avoid over tting, we have to ...", "dateLastCrawled": "2022-02-02T09:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "SCENE CLASSFICATION BASED ON THE SEMANTIC-FEATURE FUSION FULLY <b>SPARSE</b> ...", "url": "https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLI-B7/451/2016/isprs-archives-XLI-B7-451-2016.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.int-<b>arch</b>-photogramm-remote-sens-spatial-inf-sci.net/XLI-B7/451/2016/isprs...", "snippet": "multiple semantic-feature fusion strategy and <b>sparse</b> <b>representation</b> based FSTM is able to trade off sparsity and the quality of <b>sparse</b> inferred semantic information as well as inferring time, and presents a comparable performance with the existed relevant method. The rest of the paper is organized as follows. The next section details the procedure of the proposed SFF-FSTM for HSR image scene classification. A description of the experimental datasets and an analysis of the experimental ...", "dateLastCrawled": "2022-01-25T22:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>New Architecture for Optimization Modeling Frameworks</b>", "url": "https://stanford.edu/~boyd/papers/pdf/new_arch_opt_model.pdf", "isFamilyFriendly": true, "displayUrl": "https://stanford.edu/~boyd/papers/pdf/new_<b>arch</b>_opt_model.pdf", "snippet": "LAPACK [28] for basic operations and libraries <b>like</b> SuiteSparse [29] for <b>sparse</b> matrix factorization. Existing cone solvers are almost exclusively restricted to CPU implementations; an exception is SCS which provides GPU support using the cuBLAS library [30]. D. Drawbacks The traditional approach to optimization modeling frameworks has been enormously successful, allowing modeling languages and solver implementations to be developed independently in the programming languages best suited to ...", "dateLastCrawled": "2021-09-19T20:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Face Image Retrieval of Efficient <b>Sparse</b> Code words and Multiple ...", "url": "https://www.scielo.br/j/babt/a/c74TJf3DZkCKn5Tz9VGVsDf/?format=pdf", "isFamilyFriendly": true, "displayUrl": "https://www.scielo.br/j/babt/a/c74TJf3DZkCKn5Tz9VGVsDf/?format=pdf", "snippet": "with <b>sparse</b> code. Experimental results with Pubfig dataset shows that the proposed LOP along with <b>sparse</b> codewords able to provide matching results with increased accuracy of 90%. Key words: Face Retrieval, LOP, Multiple face attribute, <b>sparse</b> <b>representation</b>, indexing * Author for correspondence: suchitraprofphd@gmail.com", "dateLastCrawled": "2021-07-10T05:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Recognizing <b>architecture</b> styles by hierarchical <b>sparse</b> coding of ...", "url": "https://www.sciencedirect.com/science/article/pii/S002002551300580X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S002002551300580X", "snippet": "Further, Yu et al. proposed a two-layer <b>sparse</b> coding to learn an image <b>representation</b> from raw pixels. The first layer encodes image patches while the second layer encodes the spatial relations of blocks from the neighboring regions. Unfortunately, the experimental results failed to demonstrate that the performance of Yu et al.\u2019s approach is as good as the approaches based on SIFT descriptors. In", "dateLastCrawled": "2021-11-27T13:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "GAN Compression: Efficient Architectures for Interactive Conditional GANs", "url": "https://tinyml.mit.edu/projects/gancompression/resources/546-slides.pdf", "isFamilyFriendly": true, "displayUrl": "https://tinyml.mit.edu/projects/gancompression/resources/546-slides.pdf", "snippet": "complexity arrays. After that, I\u2019d <b>like</b> to implement this architecture in FPGA or ASIC, then integrate the HW primitive into TACO. Then, I want to co-design the machine learning models that are not only pruned to be <b>sparse</b>, but also with the optimal granularity of sparsity that \ufb01ts the accelerator. Lastly, I\u2019ll demonstrate a few machine learning applications accelerated with such <b>sparse</b> primitives: machine translation, speech recognition, image classi\ufb01cation, and Progressive GAN ...", "dateLastCrawled": "2022-01-22T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "cuda - Converting a dense matrix to <b>sparse</b> CSR format with cuSPARSE ...", "url": "https://stackoverflow.com/questions/23993014/converting-a-dense-matrix-to-sparse-csr-format-with-cusparse", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/23993014", "snippet": "You can convert a dense matrix to <b>sparse</b> with code you write yourself. For the CSR (compressed-<b>sparse</b>-row) formulation, you could also use the CUSPARSE function for this. The general format of a CSR <b>sparse</b> matrix <b>representation</b> is documented in many places, including the CUSPARSE manual. Show activity on this post.", "dateLastCrawled": "2022-01-28T05:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "An Introduction to <b>Sparse</b> Representations and Compressive Sensing [4mm ...", "url": "https://perso.ens-lyon.fr/paulo.goncalves/education/SparseReps-PG.pdf", "isFamilyFriendly": true, "displayUrl": "https://perso.ens-lyon.fr/paulo.goncalves/education/<b>Sparse</b>Reps-PG.pdf", "snippet": "<b>Sparse</b> transform coding is asymptotically optimal Donoho, Cohen, Daubechies, DeVore, Vetterli, and others ::: The statement \\transform coding in a <b>sparse</b> basis is a smart thing to do&quot; can be made mathematically precise Class of images C <b>Representation</b> f ig (orthobasis) such that j j(n ). n r for all f 2 C (j j(n ) is the n th largest transform ...", "dateLastCrawled": "2021-11-06T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Sparse</b> Multivariate <b>ARCH</b> Models: Finite Sample Properties - <b>NASA</b>/ADS", "url": "https://ui.adsabs.harvard.edu/abs/2018arXiv180805352P/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2018arXiv180805352P/abstract", "snippet": "We provide finite sample properties of <b>sparse</b> multivariate <b>ARCH</b> processes, where the linear <b>representation</b> of <b>ARCH</b> models allows for an ordinary least squares estimation. Under the restricted strong convexity of the unpenalized loss function, regularity conditions on the penalty function, strict stationary and beta-mixing process, we prove non ...", "dateLastCrawled": "2020-05-20T15:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Sparse</b> Component Analysis Using Time-Frequency Representations for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4435134/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4435134", "snippet": "First, the measurements from the sensors are transformed to the TF domain to get a <b>sparse</b> <b>representation</b>. Then, single-source-points (SSPs) are detected to better reveal the hyperlines which correspond to the columns of the mixing matrix. The K-hyperline clustering algorithm is used to identify the direction vectors of the hyperlines and then the mixing matrix is calculated. Finally, basis pursuit de-noising technique is used to recover the modal responses, from which the modal parameters ...", "dateLastCrawled": "2021-08-26T20:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Segmentation and Enhancement of Latent Fingerprints: A Coarse to Fine ...", "url": "https://www.cse.msu.edu/~cse902/S14/ppt/Latent%20segmentation%20and%20enhancement.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cse.msu.edu/~cse902/S14/ppt/Latent segmentation and enhancement.pdf", "snippet": "<b>Sparse</b> Coding Orthogonal Matching Pursuit Each example has a Update Dictionary One atom at a time \u2022Learning algorithm: K-SVD[1] \u2022Database: High quality patches in NIST DB 4 [1] M. Aharon, M. Elad and A. Bruchstein, \u201cK-SVD: An Algorithm for Designing Overcomplete Dictionaries for <b>Sparse</b> <b>Representation</b>\u201d, IEEE TSP, 54(11): 4311-4322, 2006. 11", "dateLastCrawled": "2022-01-14T02:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Multi-Scale Dictionary Learning via Cross-Scale Cooperative Learning ...", "url": "https://personal.ntu.edu.sg/elpchau/pdf/Multiscale%20Sparse%20Representation.pdf", "isFamilyFriendly": true, "displayUrl": "https://personal.ntu.edu.sg/elpchau/pdf/Multiscale <b>Sparse</b> <b>Representation</b>.pdf", "snippet": "Abstract\u2014For <b>sparse</b> signal <b>representation</b>, the sparsity across the scales is a promising yet under investigated direction. In this work, we aim at designing a multi-scale <b>sparse</b> <b>representation</b> scheme to explore such potential. A multi-scale dictionary (MD) structure is designed. A Cross-scale Matching Pursuit (CMP) al-gorithm is proposed for multi-scale <b>sparse</b> coding. Two dictionary learning methods: Cross-scale Cooperative Learning MD/CCL), and Cross-scale Atom Clustering (MD/CAC) are ...", "dateLastCrawled": "2021-09-07T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Sparse</b> <b>Representation for Different Animal Vertebra</b> Classification ...", "url": "https://www.hindawi.com/journals/jspec/2020/2521696/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/jspec/2020/2521696", "snippet": "Along the fixation trajectory of PS, the classification method based on the <b>sparse</b> <b>representation</b>-based classifier (SRC) was applied to different vertebral tissues (cortical bones and cancellous bones). Considering the large amount of spectral data, <b>sparse</b> preserving projection (SPP) was applied to improve the performance of SRC. The proposed method based on the SPP method for dimensionality reduction and the SRC method for tissue recognition was first used in vertebrae classification and ...", "dateLastCrawled": "2022-01-02T01:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>SpArch: Efficient Architecture for Sparse Matrix Multiplication</b>", "url": "https://deepai.org/publication/sparch-efficient-architecture-for-sparse-matrix-multiplication", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>sparch-efficient-architecture-for-sparse-matrix</b>...", "snippet": "We then propose a condensed matrix <b>representation</b> that reduces the number of partial matrices by three orders of magnitude and thus reduces DRAM access by 5.4x. We further develop a Huffman tree scheduler to improve the scalability of the merger for larger <b>sparse</b> matrices, which reduces the DRAM access by another 1.8x. We also resolve the increased input matrix read induced by the new <b>representation</b> using a row prefetcher with near-optimal buffer replacement policy, further reducing the DRAM ...", "dateLastCrawled": "2022-01-13T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>sparse</b>(1) - Linux manual page", "url": "https://www.man7.org/linux/man-pages/man1/sparse.1.html", "isFamilyFriendly": true, "displayUrl": "https://www.man7.org/linux/man-pages/man1/<b>sparse</b>.1.html", "snippet": "<b>sparse</b>(1) General Commands Manual <b>sparse</b>(1) NAME top <b>sparse</b> - Semantic Parser for C SYNOPSIS top <b>sparse</b> [WARNING ... This <b>is similar</b> to -Waddress-space but will also warn on casts to unsigned long. <b>Sparse</b> does not issues these warnings by default. -Wcast-to-as Warn about casts which add an address space to a pointer type. A cast that includes __attribute__((force)) will suppress this warning. No warning is generated if the original type is uintptr_t (or unsigned long). <b>Sparse</b> does not issue ...", "dateLastCrawled": "2022-01-29T21:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "COUPLE GRAPH BASED <b>LABEL PROPAGATION METHOD FOR HYPERSPECTRAL REMOTE</b> ...", "url": "https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-3/1795/2018/isprs-archives-XLII-3-1795-2018.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.int-<b>arch</b>-photogramm-remote-sens-spatial-inf-sci.net/XLII-3/1795/2018/isprs...", "snippet": "the <b>similar</b> graph. The main question is to find the <b>similar</b> data pairs and calculate the edge weight. We try to choose the <b>similar</b> data pairs, by solving an . l. 1. optimization problem on <b>sparse</b> <b>representation</b> (SR): NSRC. Firstly, calculate the class-probability of each unlabeled data by. 0. T 0 (( ) )= \u00d6 P XY iL a, where (X) i is an ...", "dateLastCrawled": "2022-02-03T05:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "R: <b>Cross Tabulation</b> - MIT", "url": "https://web.mit.edu/~r/current/arch/i386_linux26/lib/R/library/stats/html/xtabs.html", "isFamilyFriendly": true, "displayUrl": "https://<b>web.mit.edu</b>/~r/current/<b>arch</b>/i386_linux26/lib/R/library/stats/html/xtabs.html", "snippet": "Details. There is a summary method for contingency table objects created by table or xtabs(*, <b>sparse</b> = FALSE), which gives basic information and performs a chi-squared test for independence of factors (note that the function chisq.test currently only handles 2-d tables).. If a left hand side is given in formula, its entries are simply summed over the cells corresponding to the right hand side; this also works if the lhs does not give counts.. For variables in formula which are factors ...", "dateLastCrawled": "2022-01-30T08:03:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The Neurobiology of <b>Thought</b>: The Groundbreaking Discoveries of Patricia ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3767966/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3767966", "snippet": "Patricia S. Goldman-Rakic (1937\u20132003) transformed the study of the prefrontal cortex (PFC) and the neural basis of mental <b>representation</b>, the basic building block of abstract <b>thought</b>. Her pioneering research first identified the dorsolateral PFC (dlPFC) region essential for spatial working memory, and the extensive circuits of spatial cognition. She discovered the cellular basis of working memory, illuminating the dlPFC microcircuitry underlying spatially tuned, persistent firing, whereby ...", "dateLastCrawled": "2022-01-28T06:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Learning a hierarchical <b>representation</b> of the yeast transcriptomic ...", "url": "https://europepmc.org/article/MED/26818848", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/26818848", "snippet": "The NMF <b>can</b> <b>be thought</b> of as a model consisting of an observed layer (gene expression) and a single hidden layer ... the <b>sparse</b> encoder <b>can</b> concisely learn and represent the information of biological entities, in this case the TFs. Latent variables <b>can</b> capture the information of signaling pathways. We further investigated whether certain hidden nodes <b>can</b> represent the states of well-known yeast signaling pathways, i.e., whether the state of a hidden node <b>can</b> be mapped to the state of a ...", "dateLastCrawled": "2021-09-17T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Odor Representations in Olfactory Cortex: \u201cSparse</b>\u201d Coding, Global ...", "url": "https://www.cell.com/neuron/fulltext/S0896-6273(09)00397-3", "isFamilyFriendly": true, "displayUrl": "https://www.cell.com/neuron/fulltext/S0896-6273(09)00397-3", "snippet": "<b>Sparse</b> <b>representation</b> of sounds in the unanesthetized auditory cortex. PLoS Biol. 2008; 6: e16. Crossref; PubMed; Scopus (356) Google Scholar, Margrie et al., 2002. Margrie T.W. Brecht M. Sakmann B. In vivo, low-resistance, whole-cell recordings from neurons in the anaesthetized and awake mammalian brain. Pflugers <b>Arch</b>. 2002; 444: 491-498. Crossref; PubMed; Scopus (407) Google Scholar). Cell-attached recordings revealed low spontaneous firing rates of L2/3 cells (Figures 1B and 1C 1; median ...", "dateLastCrawled": "2022-01-21T15:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Fingerprint Classification Based on Depth Neural Network | DeepAI", "url": "https://deepai.org/publication/fingerprint-classification-based-on-depth-neural-network", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/fingerprint-classification-based-on-depth-neural-network", "snippet": "All of the machine-learning algorithms need to have the characteristics as the input, a good feature <b>representation</b> <b>can</b> <b>be thought</b> as a key to an algorithm. The traditional definition and selection of feature are often completed by artificial. But the manual features selection is often time-consuming, and the feature usually has certain subjectivity, but also requires some prior knowledge. However, by constructing a depth neural network which imitates the cognitive process from observation ...", "dateLastCrawled": "2021-12-21T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) An MVPA Method Based on <b>Sparse</b> <b>Representation</b> for Pattern ...", "url": "https://www.researchgate.net/publication/317322628_An_MVPA_Method_Based_on_Sparse_Representation_for_Pattern_Localization_in_fMRI_Data_Analysis", "isFamilyFriendly": true, "displayUrl": "https://www.rese<b>arch</b>gate.net/publication/317322628_An_MVPA_Method_Based_on_<b>Sparse</b>...", "snippet": "The <b>sparse</b> <b>representation</b> of signal <b>can</b> be described with the. following equation: y = A w. (1) where, y \u2208 N is a given label vector for training, with 1 indicates a. class and \u2212 1 indicates ...", "dateLastCrawled": "2021-10-31T21:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Statistics stats</b> \u2014 statsmodels", "url": "https://www.statsmodels.org/stable/stats.html", "isFamilyFriendly": true, "displayUrl": "https://www.statsmodels.org/stable/stats.html", "snippet": "het_<b>arch</b> (resid[, nlags, autolag, store, ddof]) Engle&#39;s Test for Autoregressive Conditional Heteroscedasticity (<b>ARCH</b>). ... Construct a <b>sparse</b> matrix containing the thresholded row-wise correlation matrix from a data array. cov_nearest (cov[, method, threshold, ...]) Find the nearest covariance matrix that is positive (semi-) definite. cov_nearest_factor_homog (cov, rank) Approximate an arbitrary square matrix with a factor-structured matrix of the form k*I + XX&#39;. FactoredPSDMatrix (diag ...", "dateLastCrawled": "2022-01-26T05:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "mkfs.<b>btrfs</b>(8) \u2014 <b>Arch</b> manual pages", "url": "https://man.archlinux.org/man/mkfs.btrfs.8", "isFamilyFriendly": true, "displayUrl": "https://man.<b>arch</b>linux.org/man/mkfs.<b>btrfs</b>.8", "snippet": "improved <b>representation</b> of file extents where holes are not explicitly stored as an extent, saves a few percent of metadata if <b>sparse</b> files are used . zoned (kernel support since 5.12) zoned mode, data allocation and write friendly to zoned/SMR/ZBC/ZNS devices, see ZONED MODE in <b>btrfs</b>(5), the mode is automatically selected when a zoned device is detected. RUNTIME FEATURES. Features that are typically enabled on a mounted filesystem, eg. by a mount option or by an ioctl. Some of them <b>can</b> be ...", "dateLastCrawled": "2022-02-01T18:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Ahmad Badary", "url": "https://ahmedbadary.github.io/work_files/research/dl/archits/convnets", "isFamilyFriendly": true, "displayUrl": "https://ahmedbadary.github.io/work_files/rese<b>arch</b>/dl/<b>arch</b>its/convnets", "snippet": "The convolution could <b>be thought</b> of as a weighting function ... Convolution usually corresponds to a very <b>sparse</b> matrix (a matrix whose entries are mostly equal to zero). This is because the kernel is usually much smaller than the input image. Any neural network algorithm that works with matrix multiplication and does not depend on specific properties of the matrix structure should work with convolution, without requiring any further changes to the neural network. Typical convolutional ...", "dateLastCrawled": "2021-06-22T22:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Creating <b>Life: Or, Does Architecture Determine Anything</b>?", "url": "https://www.epfl.ch/labs/lasur/wp-content/uploads/2018/05/HILLIER_-BURDETT_PEPONISandPENN.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.epfl.ch/labs/lasur/wp-content/uploads/2018/05/HILLIER_-BURDETT...", "snippet": "The model of measures <b>can</b> be set out in a diagram: state connectivity integration dynamlc control choice Fig. 1 Model of the fundamental measures of the axial <b>representation</b> of urban form. An urban system has both static and dynamic properties. This is one dimension of the model. The other is the relation between local and global", "dateLastCrawled": "2021-12-07T23:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A Theory of <b>Architecture Part 3: Why Primitive Form Languages Spread</b> ...", "url": "https://www.archdaily.com/493458/a-theory-of-architecture-part-3-why-primitive-form-languages-spread", "isFamilyFriendly": true, "displayUrl": "https://<b>www.archdaily.com</b>/493458", "snippet": "A primitive language or non-language, by contrast, is characterized by the reduction or absence of such internal complexity and structure. The complexity of human <b>thought</b> sets a rather high ...", "dateLastCrawled": "2022-02-01T08:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse</b> Component Analysis Using Time-Frequency Representations for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4435134/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4435134", "snippet": "developed a high-resolution time-frequency <b>representation</b> to achieve robust estimation of multiple frequency hopping signals based on <b>sparse</b> Bayesian method. The source signals in OMA are exponentially-decaying sinusoids. Thus, the time resolution is not so important and we <b>can</b> select a wide window. Meanwhile, the overlap is set at 75% of the window length to obtain adequate single source points. In practice, the minimal natural frequency is another factor that should be considered in ...", "dateLastCrawled": "2021-08-26T20:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Sparse</b> <b>Representation for Different Animal Vertebra</b> Classification ...", "url": "https://www.hindawi.com/journals/jspec/2020/2521696/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/jspec/2020/2521696", "snippet": "Pedicle screw (PS) implantation is an ideal method for the treatment of severe multilevel vertebral instability. The key problem is the accuracy of PS fixation. In this paper, the spectrum of different tissues along the fixation trajectory of PS is studied to tackle the accuracy problem. Fresh porcine vertebrae, bovine vertebrae, and ovine vertebrae were measured by using the near-infrared spectrum (NIRs) device to obtain the reflected spectrum from these vertebrae. Along the fixation ...", "dateLastCrawled": "2022-01-02T01:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) An Image <b>Reconstruction Algorithm based on Sparse</b> <b>Representation</b> ...", "url": "https://www.researchgate.net/publication/352141099_An_Image_Reconstruction_Algorithm_based_on_Sparse_Representation_for_Image_Compressed_Sensing", "isFamilyFriendly": true, "displayUrl": "https://www.rese<b>arch</b>gate.net/publication/352141099_An_Image_Reconstruction_Algorithm...", "snippet": "<b>sparse</b> <b>representation</b> in the iterative process, the improved algorithm <b>can</b> not o nly reconstruct the image with u nknown sparsity, but also has advantages over other algorit hms in", "dateLastCrawled": "2022-01-04T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Sparse</b> <b>Representation</b> of Brain Aging: Extracting Covariance Patterns ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3348167/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3348167", "snippet": "The <b>sparse</b> <b>representation</b> algorithm <b>can</b> effectively solve the over-fitting problem, but it presents the additional challenge of over-pruning, which occurs when the <b>representation</b> algorithm selects only several representative voxels from each discriminative cluster. The representative voxels may be different when the algorithm reruns on the same data. Because the basic brain function units are voxel clusters, the voxels selected by <b>sparse</b> <b>representation</b> cannot effectively reflect the stable ...", "dateLastCrawled": "2016-12-25T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Models</b> \u2014 SparseZoo 0.9.0.20211204 documentation", "url": "https://docs.neuralmagic.com/sparsezoo/source/models.html", "isFamilyFriendly": true, "displayUrl": "https://docs.neuralmagic.com/<b>sparse</b>zoo/source/<b>models</b>.html", "snippet": "base, pruned, quant (quantized), pruned_quant, <b>arch</b> (architecture modified) <b>SPARSE</b>_CATEGORY Descriptor on the degree to which the model is sparsified as <b>compared</b> with the baseline metric none, conservative (100% baseline), moderate (&gt;= 99% baseline), aggressive (&lt; 99%) <b>SPARSE</b>_TARGET (optional) Descriptor for the target environment the model was sparsified for ...", "dateLastCrawled": "2022-01-22T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "NEW SAR INTERFEROGRAM DENOISING METHOD VIA <b>SPARSE</b> RECOVERY BASED ON L NORM", "url": "https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XL-7/37/2014/isprsarchives-XL-7-37-2014.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.int-<b>arch</b>-photogramm-remote-sens-spatial-inf-sci.net/XL-7/37/2014/isprs...", "snippet": "The new <b>sparse</b> <b>representation</b> of the interferometric phase image allows to transform the denoising problem to an optimization one. So the estimated interferogram is achieved using the approximate message passing algorithm. The proposed approach is validated on different cases of simulated and real interferograms. 1. INTRODUCTION The SAR interferogram (InSAR) ltering is a fundamental step before phase unwrapping process. Several lters have been pro-posed last decades, many of them are spatial ...", "dateLastCrawled": "2022-01-22T16:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "sparsezoo/models.md at main \u00b7 neuralmagic/sparsezoo \u00b7 <b>GitHub</b>", "url": "https://github.com/neuralmagic/sparsezoo/blob/main/docs/source/models.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/neuralmagic/<b>sparse</b>zoo/blob/main/docs/source/models.md", "snippet": "<b>SPARSE</b>_NAME. An overview of what was done to sparsify the model. base, pruned, quant (quantized), pruned_quant, <b>arch</b> (architecture modified) <b>SPARSE</b>_CATEGORY. Descriptor on the degree to which the model is sparsified as <b>compared</b> with the baseline metric. none, conservative (100% baseline), moderate (&gt;= 99% baseline), aggressive (&lt; 99%) <b>SPARSE</b> ...", "dateLastCrawled": "2021-12-20T12:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Improved Image Generation via Sparse Modeling</b> | DeepAI", "url": "https://deepai.org/publication/improved-image-generation-via-sparse-modeling", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>improved-image-generation-via-sparse-modeling</b>", "snippet": "<b>Improved Image Generation via Sparse Modeling</b>. 04/01/2021 \u2219 by Roy Ganz, et al. \u2219 Technion \u2219 0 \u2219 share . The interest of the deep learning community in image synthesis has grown massively in recent years. Nowadays, deep generative methods, and especially Generative Adversarial Networks (GANs), are leading to state-of-the-art performance, capable of synthesizing images that appear realistic.", "dateLastCrawled": "2021-11-28T16:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "GF-3 SAR IMAGE DESPECKLING BASED ON THE IMPROVED NON-LOCAL MEANS USING ...", "url": "https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-3/1547/2018/isprs-archives-XLII-3-1547-2018.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.int-<b>arch</b>-photogramm-remote-sens-spatial-inf-sci.net/XLII-3/1547/2018/isprs...", "snippet": "The optimal <b>sparse</b> <b>representation</b> of the Shearlet . Denoting . f as the function that the direction is . C2 except a curve that is piecewise continuous respectively. S Nf is the approximation of the maximum Shearlet coefficient that the count is N of . The relationship between them is: 22 3 2 S log f f CN N N d (5) The approximation order of the Shearlet <b>can</b> be reached . N 2 g and the Shearlet <b>can</b> present the images that have rich information optimally. Non-Subsampled Shearlet Transform ...", "dateLastCrawled": "2022-01-11T23:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "High-dimensional penalized <b>ARCH</b> processes", "url": "http://www.crest.fr/ckfinder/userfiles/files/Pageperso/fermania/Sparse_ARCH_Fermanian_Poignard.pdf", "isFamilyFriendly": true, "displayUrl": "www.crest.fr/ckfinder/userfiles/files/Pageperso/fermania/<b>Sparse</b>_<b>ARCH</b>_Fermanian...", "snippet": "forecasting performances of our models are <b>compared</b> through the management of nancial portfolios. JEL classi cation: C13, C32, G17. Keywords: Multivariate <b>ARCH</b>, Positive de niteness, <b>Sparse</b> group lasso, Station- arity. 1 Introduction Modellingthe joint behavior of several nancial assets has become a key challenge for academics and practitioners. Indeed, it is not easy to build a realistic model that is statistically relevant and consistent with some well-known stylized features of nancial ...", "dateLastCrawled": "2022-02-02T09:43:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Neural Networks: Analogies. When our brains form analogies, they\u2026 | by ...", "url": "https://towardsdatascience.com/neural-networks-analogies-7ebeb3ac5d5e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-networks-analogies-7ebeb3ac5d5e", "snippet": "I\u2019ll outline a potential route to artificial neural networks which exhibit transfer <b>learning</b>: First, <b>Sparse</b> Distributed Representations. Numenta\u2019s Hierarchical Te m poral Memory, along with other techniques, relies upon a <b>sparse</b> distributed <b>representation</b>. An example of this is a very long string of ones and zeroes, where almost all the values are zero \u2014 there is a <b>sparse</b> distribution of the ones. If each digit represented a different thing, like \u2018pointy ears\u2019, \u2018tail ...", "dateLastCrawled": "2022-01-28T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Compressed Sensing Meets <b>Machine</b> <b>Learning</b>: Classification via <b>Sparse</b> ...", "url": "https://nuit-blanche.blogspot.com/2008/05/cs-mini-course-classification-via.html", "isFamilyFriendly": true, "displayUrl": "https://nuit-blanche.blogspot.com/2008/05/cs-mini-course-classification-via.html", "snippet": "Compressed Sensing Meets <b>Machine</b> <b>Learning</b>: Classification via <b>Sparse</b> <b>Representation</b> and Distributed Pattern Recognition This Spring, Allen Yang has given a mini course at Berkeley entitled Compressed Sensing Meets <b>Machine</b> <b>Learning</b>. The three lectures are listed here (it includes accompanying code): lecture 1: Classification via <b>Sparse</b> <b>Representation</b>; lecture 2: Classification of Mixture Subspace Models via <b>Sparse</b> <b>Representation</b>, lecture 3: Distributed Pattern Recognition; The third lecture ...", "dateLastCrawled": "2022-01-25T10:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Conceptualization as a Basis for Cognition \u2014 Human and <b>Machine</b> | by ...", "url": "https://towardsdatascience.com/conceptualization-as-a-basis-for-cognition-human-and-machine-345d9e687e3c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/conceptualization-as-a-basis-for-cognition-human-and...", "snippet": "Abstraction and <b>analogy</b> allow concepts to be re-applied in new domains. There are many, often conflicting, ... <b>Machine</b>-<b>learning</b> systems must learn to conceptualize to reach the goal of creating machines with higher intelligence. To substantiate this claim, let\u2019s first examine what generalization in artificial intelligence means specifically in the context of artificial intelligence/<b>machine</b> <b>learning</b> (as opposed to the layman\u2019s use of the term), and then explore how that differs from ...", "dateLastCrawled": "2022-01-20T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Word Embedding: Syntactics or Semantics</b> \u00b7 Shengbin&#39;s Studio", "url": "https://wushbin.github.io/2017/10/09/Word-Embedding-Syntactics-or-Semantics/", "isFamilyFriendly": true, "displayUrl": "https://wushbin.github.io/2017/10/09/<b>Word-Embedding-Syntactics-or-Semantics</b>", "snippet": "<b>Sparse</b> Vector <b>Representation</b>. The co-occurrence matrix in represented each cell by the raw frequency of the co-occurrence of two words. The raw frequency in a matrix may be skewed. Pointwise mutual information PPMI is a good measure for association between words which can tell us how much often the two words occur. The pointwise mutual information is a measure of how often two events x and y occur, compared with what we would expect if they were independent: PMI between two words is ...", "dateLastCrawled": "2022-01-09T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What Are Word Embeddings</b> for Text? - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/what-are-word-embeddings/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>what-are-word-embeddings</b>", "snippet": "Word embeddings are a type of word <b>representation</b> that allows words with similar meaning to have a similar <b>representation</b>. They are a distributed <b>representation</b> for text that is perhaps one of the key breakthroughs for the impressive performance of deep <b>learning</b> methods on challenging natural language processing problems. In this post, you will discover the word embedding approach for representing text data. After", "dateLastCrawled": "2022-01-30T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Word Embeddings in NLP - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/word-embeddings-in-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/word-embeddings-in-nlp", "snippet": "Word Embeddings are a method of extracting features out of text so that we can input those features into a <b>machine</b> <b>learning</b> model to work with text data. They try to preserve syntactical and semantic information. The methods such as Bag of Words(BOW), CountVectorizer and TFIDF rely on the word count in a sentence but do not save any syntactical or semantic information. In these algorithms, the size of the vector is the number of elements in the vocabulary. We can get a <b>sparse</b> matrix if most ...", "dateLastCrawled": "2022-01-30T08:38:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse Adaptive Local Machine Learning</b> Algorithms for Sensing and Analytics", "url": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1000&context=mcecs_mentoring", "isFamilyFriendly": true, "displayUrl": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1000&amp;context=mcecs...", "snippet": "Fig. 2: A <b>sparse representation can be thought of as</b> the dot product of a dictionary vector and a sparse code vector. Given a . dictionary . of general components, we can use a . sparse code. to select as few of them as possible to reconstruct an image of interest (Fig. 2). This reconstruction is called a . sparse representation. Sparse Coding. Image processing is expensive. Instead of working with the original image, we can identify its most relevant components and discard the rest. This ...", "dateLastCrawled": "2021-08-31T12:20:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(sparse representation)  is like +(an arch)", "+(sparse representation) is similar to +(an arch)", "+(sparse representation) can be thought of as +(an arch)", "+(sparse representation) can be compared to +(an arch)", "machine learning +(sparse representation AND analogy)", "machine learning +(\"sparse representation is like\")", "machine learning +(\"sparse representation is similar\")", "machine learning +(\"just as sparse representation\")", "machine learning +(\"sparse representation can be thought of as\")", "machine learning +(\"sparse representation can be compared to\")"]}