{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "The adjustment of the predicted scores and thus the specific type of <b>bias</b> mitigation <b>depends</b> on the targeted fairness <b>metric</b>, similar to the mitigation strategies developed for <b>machine</b> <b>learning</b> classification. The <b>algorithm</b> can be applied both as an in-processing approach by <b>learning</b> the adjustments during training procedure and applying them on the separate test data, or as post-processing approach which directly calculates the necessary adjustments on the test data itself (similar to post ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias</b> and Discrimination in AI: A Cross-Disciplinary Perspective - IEEE ...", "url": "https://technologyandsociety.org/bias-and-discrimination-in-ai-a-cross-disciplinary-perspective/", "isFamilyFriendly": true, "displayUrl": "https://technologyandsociety.org/<b>bias</b>-and-discrimination-in-ai-a-cross-disciplinary...", "snippet": "We can distinguish between two general approaches to measure <b>bias</b>: 1) procedural approaches, which focus on identifying biases in the decision-making the process of an <b>algorithm</b> [6] and 2) relational approaches, which focus on identifying (and preventing) biased decisions in the data set or algorithmic <b>output</b>. Although ensuring unbiased outcomes is useful to attest whether a specific <b>algorithm</b> has a discriminatory impact on a population, focusing on the algorithmic process itself can help ...", "dateLastCrawled": "2022-01-30T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Tutorial on <b>Fairness</b> in <b>Machine</b> <b>Learning</b> | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-<b>machine</b>-<b>learning</b>-3ff8ba1040cb", "snippet": "<b>Machine</b> <b>Learning</b>, the most widely used AI techniques, relies heavily on data. It is a common misconception that AI is absolutely objective. AI is objective only in the sense of <b>learning</b> what human teaches. The data provided by human can be highly-biased. It has been found in 2016 that COMPAS, the <b>algorithm</b> used for recidivism prediction produces <b>much</b> higher false positive rate for black people than white people(see Fig2, Larson et al. ProPublica, 2016). Fig2: The <b>bias</b> in COMPAS. (from Larson ...", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Evolution and impact of <b>bias</b> in human and <b>machine learning</b> <b>algorithm</b> ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235502", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235502", "snippet": "Traditionally, <b>machine learning</b> algorithms relied on reliable labels from experts to build predictions. More recently however, algorithms have been receiving data from the general population in the form of labeling, annotations, etc. The result is that algorithms are subject to <b>bias</b> that is born from ingesting unchecked information, such as biased samples and biased labels. Furthermore, people and algorithms are increasingly engaged in interactive processes wherein neither the human nor the ...", "dateLastCrawled": "2021-11-15T00:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "170 <b>Machine</b> <b>Learning</b> Interview Question and Answers in 2022", "url": "https://www.mygreatlearning.com/blog/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>machine-learning-interview-questions</b>", "snippet": "<b>Machine</b> <b>Learning</b> <b>algorithm</b> to be used purely <b>depends</b> on the type of data in a given dataset. If data is linear then, we use linear regression. If data shows non-linearity then, the bagging <b>algorithm</b> would do better. If the data is to be analyzed/interpreted for some business purposes then we can use decision trees or SVM. If the dataset consists of images, videos, audios then, neural networks would be helpful to get the solution accurately. So, there is no certain <b>metric</b> to decide which ...", "dateLastCrawled": "2022-02-03T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evaluating a <b>machine</b> <b>learning</b> model. - Jeremy Jordan", "url": "https://www.jeremyjordan.me/evaluating-a-machine-learning-model/", "isFamilyFriendly": true, "displayUrl": "https://www.jeremyjordan.me/evaluating-a-<b>machine</b>-<b>learning</b>-model", "snippet": "Some <b>machine</b> <b>learning</b> models provide the framework for generalization by suggesting the underlying structure of that knowledge. For example, a linear regression model imposes a framework to learn linear relationships between the information we feed it. However, sometimes we provide a model with too <b>much</b> pre-built structure that we limit the model&#39;s ability to learn from the examples - such as the case where we train a linear model on a exponential dataset. In this case, our model is", "dateLastCrawled": "2022-01-22T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Regression Metrics for Machine Learning</b>", "url": "https://machinelearningmastery.com/regression-metrics-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>regression-metrics-for-machine-learning</b>", "snippet": "For more on approximating functions in applied <b>machine</b> <b>learning</b>, see the post: How <b>Machine</b> <b>Learning</b> Algorithms Work; Regression predictive modeling is the task of approximating a mapping function (f) from <b>input</b> variables (X) to a continuous <b>output</b> variable (y).", "dateLastCrawled": "2022-02-03T02:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Tutorial: Understanding Linear Regression and <b>Regression Error Metrics</b>", "url": "https://www.dataquest.io/blog/understanding-regression-error-metrics/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>dataquest</b>.io/blog/<b>understanding-regression-error-metrics</b>", "snippet": "Since our model will produce an <b>output</b> given any <b>input</b> or set of inputs, we can then check these estimated outputs against the actual values that we tried to predict. We call the difference between the actual value and the model\u2019s estimate a residual. We can calculate the residual for every point in our data set, and each of these residuals will be of use in assessment. These residuals will play a significant role in judging the usefulness of a model. If our collection of residuals are ...", "dateLastCrawled": "2022-02-02T22:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "K-Nearest Neighbor(KNN) <b>Algorithm</b> for <b>Machine</b> <b>Learning</b> - Javatpoint", "url": "https://www.javatpoint.com/k-nearest-neighbor-algorithm-for-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/k-nearest-neighbor-<b>algorithm</b>-for-<b>machine</b>-<b>learning</b>", "snippet": "The K-NN working can be explained on the basis of the below <b>algorithm</b>: Step-1: Select the number K of the neighbors. Step-2: Calculate the Euclidean distance of K number of neighbors. Step-3: Take the K nearest neighbors as per the calculated Euclidean distance. Step-4: Among these k neighbors, count the number of the data points in each category.", "dateLastCrawled": "2022-02-02T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>GitHub</b> - dontless/<b>Machine-Learning-Foundations-A-Case-Study-Approach</b> ...", "url": "https://github.com/dontless/Machine-Learning-Foundations-A-Case-Study-Approach", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/dontless/<b>Machine-Learning-Foundations-A-Case-Study-Approach</b>", "snippet": "1). <b>Features</b> in computer vision act <b>like</b> local detectors. 2).Deep <b>learning</b> has had impact in computer vision, because it\u2019s used to combine all the different hand-created <b>features</b> that already exist. 3). By <b>learning</b> non-linear <b>features</b>, neural networks have allowed us to automatically learn detectors for computer vision. 4).none of the above", "dateLastCrawled": "2022-01-30T23:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "The adjustment of the predicted scores and thus the specific type of <b>bias</b> mitigation <b>depends</b> on the targeted fairness <b>metric</b>, <b>similar</b> to the mitigation strategies developed for <b>machine</b> <b>learning</b> classification. The <b>algorithm</b> can be applied both as an in-processing approach by <b>learning</b> the adjustments during training procedure and applying them on the separate test data, or as post-processing approach which directly calculates the necessary adjustments on the test data itself (<b>similar</b> to post ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Tutorial on <b>Fairness</b> in <b>Machine</b> <b>Learning</b> | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-<b>machine</b>-<b>learning</b>-3ff8ba1040cb", "snippet": "<b>Machine</b> <b>Learning</b>, the most widely used AI techniques, relies heavily on data. It is a common misconception that AI is absolutely objective. AI is objective only in the sense of <b>learning</b> what human teaches. The data provided by human can be highly-biased. It has been found in 2016 that COMPAS, the <b>algorithm</b> used for recidivism prediction produces <b>much</b> higher false positive rate for black people than white people(see Fig2, Larson et al. ProPublica, 2016). Fig2: The <b>bias</b> in COMPAS. (from Larson ...", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Tutorial: Understanding Linear Regression and <b>Regression Error Metrics</b>", "url": "https://www.dataquest.io/blog/understanding-regression-error-metrics/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>dataquest</b>.io/blog/<b>understanding-regression-error-metrics</b>", "snippet": "Since our model will produce an <b>output</b> given any <b>input</b> or set of inputs, we can then check these estimated outputs against the actual values that we tried to predict. We call the difference between the actual value and the model\u2019s estimate a residual. We can calculate the residual for every point in our data set, and each of these residuals will be of use in assessment. These residuals will play a significant role in judging the usefulness of a model. If our collection of residuals are ...", "dateLastCrawled": "2022-02-02T22:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "K-Nearest Neighbor(KNN) <b>Algorithm</b> for <b>Machine</b> <b>Learning</b> - Javatpoint", "url": "https://www.javatpoint.com/k-nearest-neighbor-algorithm-for-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/k-nearest-neighbor-<b>algorithm</b>-for-<b>machine</b>-<b>learning</b>", "snippet": "The K-NN working can be explained on the basis of the below <b>algorithm</b>: Step-1: Select the number K of the neighbors. Step-2: Calculate the Euclidean distance of K number of neighbors. Step-3: Take the K nearest neighbors as per the calculated Euclidean distance. Step-4: Among these k neighbors, count the number of the data points in each category.", "dateLastCrawled": "2022-02-02T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Demystifying Gradient Descent and</b> Backpropagation via Logistic ...", "url": "https://www.freecodecamp.org/news/demystifying-gradient-descent-and-backpropagation-via-logistic-regression-based-image-classification-9b5526c2ed46/", "isFamilyFriendly": true, "displayUrl": "https://www.freecodecamp.org/news/<b>demystifying-gradient-descent-and</b>-backpropagation...", "snippet": "The Age old <b>Machine</b> <b>Learning</b> <b>Algorithm</b>. Let\u2019s start off with a very brief (well, too brief) an introduction to what one of the oldest algorithms in <b>Machine</b> <b>Learning</b> essentially does. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of <b>input</b> values (x) and <b>output</b> values (y) to a general function that can map any <b>input</b> value to an <b>output</b> value. This is known as linear regression, and it is a ...", "dateLastCrawled": "2022-02-01T05:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evaluating a <b>machine</b> <b>learning</b> model. - Jeremy Jordan", "url": "https://www.jeremyjordan.me/evaluating-a-machine-learning-model/", "isFamilyFriendly": true, "displayUrl": "https://www.jeremyjordan.me/evaluating-a-<b>machine</b>-<b>learning</b>-model", "snippet": "Some <b>machine</b> <b>learning</b> models provide the framework for generalization by suggesting the underlying structure of that knowledge. For example, a linear regression model imposes a framework to learn linear relationships between the information we feed it. However, sometimes we provide a model with too <b>much</b> pre-built structure that we limit the model&#39;s ability to learn from the examples - such as the case where we train a linear model on a exponential dataset. In this case, our model is biased ...", "dateLastCrawled": "2022-01-22T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Chapter 4 Linear Regression</b> | Hands-On <b>Machine</b> <b>Learning</b> with R", "url": "https://bradleyboehmke.github.io/HOML/linear-regression.html", "isFamilyFriendly": true, "displayUrl": "https://bradleyboehmke.github.io/HOML/linear-regression.html", "snippet": "A <b>Machine</b> <b>Learning</b> Algorithmic Deep Dive Using R. Most statistical software, including R, will include estimated standard errors, t-statistics, etc. as part of its regression <b>output</b>.However, it is important to remember that such quantities depend on three major assumptions of the linear regression model:", "dateLastCrawled": "2022-02-02T06:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fairlearn</b>: The secret to teaching your models to play fair | by Willem ...", "url": "https://medium.com/microsoftazure/fairlearn-the-secret-to-teaching-your-models-to-play-fair-1dfe8a42ed9f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/microsoftazure/<b>fairlearn</b>-the-secret-to-teaching-your-models-to-play...", "snippet": "When we train <b>machine</b> <b>learning</b> models, we want them to behave fairly. But despite our best efforts, we may harm people. There\u2019s two ways in which we can talk about fairness: Fairness towards an ...", "dateLastCrawled": "2022-01-29T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>How to Normalize or Standardize a Dataset in Python</b>? \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2020/11/19/how-to-normalize-or-standardize-a-dataset-in-python/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2020/11/19/<b>how-to-normalize-or-standardize</b>-a...", "snippet": "If the model <b>depends</b> on <b>measuring</b> distance (think SVM), the distances are comparable after the dataset was scaled. ... Some <b>features</b> (columns) contribute to <b>the output</b> less significantly than others. It could be that when removed, the model will still be able to perform, but at a significantly lower computational cost. We therefore want to be able to select the <b>features</b> that contribute most significantly. In <b>machine</b> <b>learning</b> problems that involve <b>learning</b> a \u201cstate-of-nature\u201d from a ...", "dateLastCrawled": "2022-02-03T12:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>GitHub</b> - dontless/<b>Machine-Learning-Foundations-A-Case-Study-Approach</b> ...", "url": "https://github.com/dontless/Machine-Learning-Foundations-A-Case-Study-Approach", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/dontless/<b>Machine-Learning-Foundations-A-Case-Study-Approach</b>", "snippet": "<b>Features</b> in computer vision act like local detectors. 2).Deep <b>learning</b> has had impact in computer vision, because it\u2019s used to combine all the different hand-created <b>features</b> that already exist. 3). By <b>learning</b> non-linear <b>features</b>, neural networks have allowed us to automatically learn detectors for computer vision. 4).none of the above", "dateLastCrawled": "2022-01-30T23:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "The first step in the process was to formulate a research question to define the aim of the study and map answers from the literature. The research question that this semi-systematic literature review address is the RQ1, presented in Section 1.It aims to determine what concepts from classification-based fair <b>machine</b> <b>learning</b> <b>can</b> be mapped to fairness metrics in rating-based recommender system settings.", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Comments Received on A Proposal for Identifying and Managing <b>Bias</b> in ...", "url": "https://www.nist.gov/artificial-intelligence/comments-received-proposal-identifying-and-managing-bias-artificial", "isFamilyFriendly": true, "displayUrl": "https://<b>www.nist.gov</b>/artificial-intelligence/comments-received-proposal-identifying...", "snippet": "In this document, about 30 biases are listed up and classified into 4 categories such as human cognitive <b>bias</b>, data <b>bias</b>, <b>machine</b> <b>learning</b> model architecture <b>bias</b>, <b>bias</b> in rule-based system design and requirement <b>bias</b>. This report also classifies biases based on AI system life cycle. We also understand the intention is to leverage key locations within stages of the AI lifecycle for optimally identifying and managing <b>bias</b>.", "dateLastCrawled": "2022-01-28T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "It\u2019s Too Easy to <b>Hide Bias in Deep-Learning Systems</b> - IEEE Spectrum", "url": "https://spectrum.ieee.org/its-too-easy-to-hide-bias-in-deeplearning-systems", "isFamilyFriendly": true, "displayUrl": "https://spectrum.ieee.org/its-too-easy-to-<b>hide-bias-in-deeplearning-systems</b>", "snippet": "They used an <b>algorithm</b> they called (appropriately enough for such fairwashing) LaundryML to examine a <b>machine</b>-<b>learning</b> system whose inner workings were too intricate for a person to readily ...", "dateLastCrawled": "2022-01-30T06:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Review of Challenges and Opportunities in <b>Machine</b> <b>Learning</b> for Health", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233077/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7233077", "snippet": "While exploiting such relationships between <b>features</b> and targets is a goal of <b>learning</b>, information leakage <b>can</b> render a prediction meaningless. Consider predicting mortality of hospital patients using all available data up until their time of death. Such a task could lead to a pathological prediction rule\u2014\u201dif the ventilator is turned off in the preceding hour, predict death.\u201d This commonly happens when patients and their families decide to withdraw care at a terminal stage of illness ...", "dateLastCrawled": "2022-01-25T00:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Classification: <b>Precision</b> and Recall | <b>Machine</b> <b>Learning</b> Crash Course ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/crash-course/classification/<b>precision</b>...", "snippet": "<b>Precision</b> = T P T P + F P = 8 8 + 2 = 0.8. Recall measures the percentage of actual spam emails that were correctly classified\u2014that is, the percentage of green dots that are to the right of the threshold line in Figure 1: Recall = T P T P + F N = 8 8 + 3 = 0.73. Figure 2 illustrates the effect of increasing the classification threshold. Figure 2.", "dateLastCrawled": "2022-01-30T23:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evolution and impact of <b>bias</b> in human and <b>machine learning</b> <b>algorithm</b> ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235502", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235502", "snippet": "Traditionally, <b>machine learning</b> algorithms relied on reliable labels from experts to build predictions. More recently however, algorithms have been receiving data from the general population in the form of labeling, annotations, etc. The result is that algorithms are subject to <b>bias</b> that is born from ingesting unchecked information, such as biased samples and biased labels. Furthermore, people and algorithms are increasingly engaged in interactive processes wherein neither the human nor the ...", "dateLastCrawled": "2021-11-15T00:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Classification Accuracy is Not Enough: More Performance Measures You ...", "url": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/classification-accuracy-is-not-enough-", "snippet": "Precision <b>can</b> <b>be thought</b> of as a measure of a classifiers exactness. A low precision <b>can</b> also indicate a large number of False Positives. The precision of the All No Recurrence model is 0/(0+0) or not a number, or 0. The precision of the All Recurrence model is 85/(85+201) or 0.30. The precision of the CART model is 10/(10+13) or 0.43. The precision suggests CART is a better model and that the All Recurrence is more useful than the All No Recurrence model even though it has a lower accuracy ...", "dateLastCrawled": "2022-02-03T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Sharpness: What is it and How it is Measured | imatest", "url": "https://www.imatest.com/docs/sharpness/", "isFamilyFriendly": true, "displayUrl": "https://www.imatest.com/docs/sharpness", "snippet": "Sharpness is most visible on <b>features</b> like image edges (Figure 2) and <b>can</b> be measured by the edge (step) response. Several methods are used for <b>measuring</b> sharpness that include the 10-90% rise distance technique, modulation transfer function (MTF), special and frequency domains, and slanted-edge <b>algorithm</b>. Rise Distance and Frequency Domain. Image sharpness <b>can</b> be measured by the \u201crise distance\u201d of an edge within the image. With this technique, sharpness <b>can</b> be determined by the distance ...", "dateLastCrawled": "2022-01-30T19:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "An overview of model <b>explainability</b> in modern <b>machine</b> <b>learning</b> | by Rui ...", "url": "https://towardsdatascience.com/an-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-overview-of-model-<b>explainability</b>-in-modern-<b>machine</b>...", "snippet": "Partial dependence works by marginalizing the <b>machine</b> <b>learning</b> model <b>output</b> over the distribution of the <b>features</b> we are not interested in (denoted by <b>features</b> in set C). This makes it such that the partial dependence function shows the relationship between the <b>features</b> we do care about (which we denote by buying in set S) and the predicted outcome. By marginalizing over the other <b>features</b>, we get a function that <b>depends</b> only on <b>features</b> in S. This makes it easy to understand how varying a ...", "dateLastCrawled": "2022-01-31T22:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A theory and methodology to quantify knowledge | Royal Society Open Science", "url": "https://royalsocietypublishing.org/doi/10.1098/rsos.181055", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rsos.181055", "snippet": "This is defined as the shortest program that, if fed into a universal Turing <b>machine</b>, would <b>output</b> the \u03c4 and then halt. Mathematical theorems prove that this quantity cannot be computed directly\u2014at least in the sense that one <b>can</b> never be sure to have found the shortest possible program. In practice, however, the Kolmogorov complexity of an object is approximated, by excess, by any information compression <b>algorithm</b> and is independent of the encoding language used, up to a constant. This ...", "dateLastCrawled": "2022-01-29T07:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "The first step in the process was to formulate a research question to define the aim of the study and map answers from the literature. The research question that this semi-systematic literature review address is the RQ1, presented in Section 1.It aims to determine what concepts from classification-based fair <b>machine</b> <b>learning</b> <b>can</b> be mapped to fairness metrics in rating-based recommender system settings.", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias</b> and Discrimination in AI: A Cross-Disciplinary Perspective - IEEE ...", "url": "https://technologyandsociety.org/bias-and-discrimination-in-ai-a-cross-disciplinary-perspective/", "isFamilyFriendly": true, "displayUrl": "https://technologyandsociety.org/<b>bias</b>-and-discrimination-in-ai-a-cross-disciplinary...", "snippet": "We <b>can</b> distinguish between two general approaches to measure <b>bias</b>: 1) procedural approaches, which focus on identifying biases in the decision-making the process of an <b>algorithm</b> [6] and 2) relational approaches, which focus on identifying (and preventing) biased decisions in the data set or algorithmic <b>output</b>. Although ensuring unbiased outcomes is useful to attest whether a specific <b>algorithm</b> has a discriminatory impact on a population, focusing on the algorithmic process itself <b>can</b> help ...", "dateLastCrawled": "2022-01-30T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Comments Received on A Proposal for Identifying and Managing <b>Bias</b> in ...", "url": "https://www.nist.gov/artificial-intelligence/comments-received-proposal-identifying-and-managing-bias-artificial", "isFamilyFriendly": true, "displayUrl": "https://<b>www.nist.gov</b>/artificial-intelligence/comments-received-proposal-identifying...", "snippet": "In this document, about 30 biases are listed up and classified into 4 categories such as human cognitive <b>bias</b>, data <b>bias</b>, <b>machine</b> <b>learning</b> model architecture <b>bias</b>, <b>bias</b> in rule-based system design and requirement <b>bias</b>. This report also classifies biases based on AI system life cycle. We also understand the intention is to leverage key locations within stages of the AI lifecycle for optimally identifying and managing <b>bias</b>.", "dateLastCrawled": "2022-01-28T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Correcting Coarse\u2010Grid Weather and Climate Models by <b>Machine</b> <b>Learning</b> ...", "url": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021MS002794", "isFamilyFriendly": true, "displayUrl": "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021MS002794", "snippet": "The coarse-grid model without <b>machine</b> <b>learning</b> corrections has too few clouds, causing too <b>much</b> daytime heating of land surfaces that creates excessive surface latent heat flux and rainfall. This <b>bias</b> is avoided by <b>learning</b> downwelling radiative flux from the fine-grid model. The best configuration uses learned nudging tendencies for temperature and humidity but not winds. Neural nets slightly outperform random forests. Forecasts of 850 hPa temperature gain 18 hr of skill at 3\u20137 days leads ...", "dateLastCrawled": "2022-02-05T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Tutorial: Understanding Linear Regression and <b>Regression Error Metrics</b>", "url": "https://www.dataquest.io/blog/understanding-regression-error-metrics/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>dataquest</b>.io/blog/<b>understanding-regression-error-metrics</b>", "snippet": "Since our model will produce an <b>output</b> given any <b>input</b> or set of inputs, we <b>can</b> then check these estimated outputs against the actual values that we tried to predict. We call the difference between the actual value and the model\u2019s estimate a residual. We <b>can</b> calculate the residual for every point in our data set, and each of these residuals will be of use in assessment. These residuals will play a significant role in judging the usefulness of a model. If our collection of residuals are ...", "dateLastCrawled": "2022-02-02T22:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evolution and impact of <b>bias</b> in human and <b>machine learning</b> <b>algorithm</b> ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235502", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235502", "snippet": "Traditionally, <b>machine learning</b> algorithms relied on reliable labels from experts to build predictions. More recently however, algorithms have been receiving data from the general population in the form of labeling, annotations, etc. The result is that algorithms are subject to <b>bias</b> that is born from ingesting unchecked information, such as biased samples and biased labels. Furthermore, people and algorithms are increasingly engaged in interactive processes wherein neither the human nor the ...", "dateLastCrawled": "2021-11-15T00:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Regression Metrics for Machine Learning</b>", "url": "https://machinelearningmastery.com/regression-metrics-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>regression-metrics-for-machine-learning</b>", "snippet": "For more on approximating functions in applied <b>machine</b> <b>learning</b>, see the post: How <b>Machine</b> <b>Learning</b> Algorithms Work; Regression predictive modeling is the task of approximating a mapping function (f) from <b>input</b> variables (X) to a continuous <b>output</b> variable (y).", "dateLastCrawled": "2022-02-03T02:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Evaluating a <b>machine</b> <b>learning</b> model. - Jeremy Jordan", "url": "https://www.jeremyjordan.me/evaluating-a-machine-learning-model/", "isFamilyFriendly": true, "displayUrl": "https://www.jeremyjordan.me/evaluating-a-<b>machine</b>-<b>learning</b>-model", "snippet": "Some <b>machine</b> <b>learning</b> models provide the framework for generalization by suggesting the underlying structure of that knowledge. For example, a linear regression model imposes a framework to learn linear relationships between the information we feed it. However, sometimes we provide a model with too <b>much</b> pre-built structure that we limit the model&#39;s ability to learn from the examples - such as the case where we train a linear model on a exponential dataset. In this case, our model is biased ...", "dateLastCrawled": "2022-01-22T19:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "170 <b>Machine</b> <b>Learning</b> Interview Question and Answers in 2022", "url": "https://www.mygreatlearning.com/blog/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>machine-learning-interview-questions</b>", "snippet": "<b>Machine</b> <b>Learning</b> <b>algorithm</b> to be used purely <b>depends</b> on the type of data in a given dataset. If data is linear then, we use linear regression. If data shows non-linearity then, the bagging <b>algorithm</b> would do better. If the data is to be analyzed/interpreted for some business purposes then we <b>can</b> use decision trees or SVM. If the dataset consists of images, videos, audios then, neural networks would be helpful to get the solution accurately. So, there is no certain <b>metric</b> to decide which ...", "dateLastCrawled": "2022-02-03T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "AUC: A Better Measure <b>than Accuracy in Comparing Learning Algorithms</b> ...", "url": "https://www.researchgate.net/publication/221442229_AUC_A_Better_Measure_than_Accuracy_in_Comparing_Learning_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221442229_AUC_A_Better_Measure_than_Accuracy...", "snippet": "This diagnostic tool <b>can</b> be developed using <b>machine</b> <b>learning</b> as a classification problem. The performance of the classifier <b>depends</b> on the interrelationship between sample sizes, some <b>features</b> ...", "dateLastCrawled": "2022-02-03T03:31:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b>, Variance, and <b>Overfitting</b> Explained, Step by Step", "url": "https://machinelearningcompass.com/model_optimization/bias_and_variance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>compass.com/model_optimization/<b>bias</b>_and_variance", "snippet": "The <b>bias</b> of a specific <b>machine learning</b> model trained on a specific dataset describes how well this <b>machine learning</b> model can capture the relationship between the features and the targets. So for our example, the <b>bias</b> of any one model would tell us how well this particular model can predict the exam points received for any number of hours studied in our specific dataset. That seems like a reasonable definition. Practical Examples (<b>Bias</b>) Let\u2019s take a look at three of the above models and ...", "dateLastCrawled": "2022-01-31T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Short Discussion On <b>Bias</b> In <b>Machine</b> <b>Learning</b>", "url": "https://www.encora.com/insights/a-short-discussion-on-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.encora.com/insights/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "A typical <b>machine</b> <b>learning</b> lifecycle might start with a Scoping stage. At this point, an important decision to be made by the analysts regards the level of performance the <b>machine</b> <b>learning</b> system should have. The <b>machine</b> <b>learning</b> team, along with the stakeholders involved, should decide on a <b>metric</b> to be used as a measure of success. This ...", "dateLastCrawled": "2022-02-03T02:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Short Discussion on <b>Bias</b> in <b>Machine</b> <b>Learning</b> | by Daitan | Daitan ...", "url": "https://medium.com/daitan-tech/a-short-discussion-on-bias-in-machine-learning-5bb2066afabc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/daitan-tech/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>-5bb2066afabc", "snippet": "The problem of <b>bias</b> in <b>machine</b> <b>learning</b> is very serious. Moreover, though it seems to be a \u201cdata related\u201d problem, one might think that it can be solved by simply curating datasets so that ...", "dateLastCrawled": "2021-08-05T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Short Discussion on <b>Bias</b> in <b>Machine</b> <b>Learning</b> - Adolfo Eliaz\u00e0t ...", "url": "https://adolfoeliazat.com/2021/06/16/a-short-discussion-on-bias-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://adolfoeliazat.com/2021/06/16/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "The problem of <b>bias</b> in <b>machine</b> <b>learning</b> is very serious. Moreover, though it seems to be a \u201cdata related\u201d problem, one might think that it can be solved by simply curating datasets so that classes and ethical groups are well represented. This line of thinking is a trap and must be avoided. Overall, <b>bias</b> in technology can happen anywhere or anytime a decision must be taken by a human. In such situations, it is very common to consider aspects that make sense from a marketing or profit ...", "dateLastCrawled": "2022-01-16T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A New <b>Metric for Quantifying Machine Learning Fairness in</b> Healthcare ...", "url": "https://towardsdatascience.com/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare-closedloop-ai-fc07b9c83487?source=post_internal_links---------3----------------------------", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-new-<b>metric-for-quantifying-machine-learning-fairness</b>...", "snippet": "The <b>analogy</b> would be the difference between a Pearson correlation or a residual sum of squared errors in regression. While both quantify the models performance, the former is significantly easier to understand and explain; unsurprisingly, it is the <b>metric</b> most individuals use to describe a regression model. In order to achieve this effect, many fairness metrics are presented as the quotient of a protected subgroup to a base subgroup[2]. As the goal of healthcare is to deliver interventions ...", "dateLastCrawled": "2022-01-19T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "CS 540 Lecture Notes: <b>Machine</b> <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/learning.html", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/<b>learning</b>.html", "snippet": "Inductive <b>Bias</b>. Inductive <b>learning</b> is an inherently conjectural process because any knowledge created by generalization from specific facts cannot be proven true; it can only be proven false. Hence, inductive inference is falsity preserving, not truth preserving. To generalize beyond the specific training examples, we need constraints or biases on what f is best. That is, <b>learning</b> can be viewed as searching the Hypothesis Space H of possible f functions. A <b>bias</b> allows us to choose one f over ...", "dateLastCrawled": "2022-02-03T15:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Fairness Metrics - Data Analytics - Data Science, <b>Machine</b> <b>Learning</b>, AI", "url": "https://vitalflux.com/fairness-metrics-ml-model-sensitivity-bias-detection/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>fairness-metrics-ml-model-sensitivity</b>-<b>bias</b>-detection", "snippet": "There are many different ways in which <b>machine</b> <b>learning</b> (ML) models\u2019 fairness could be determined. Some of them are statistical parity, the relative significance of features, model sensitivity etc. In this post, you would learn about how model sensitivity could be used to determine model fairness or <b>bias</b> of model towards the privileged or unprivileged group.The following are some of the topics covered in this post:", "dateLastCrawled": "2022-01-20T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Bias</b> -Variance &amp; <b>Precision</b>-Recall Trade-offs: How to aim for the sweet ...", "url": "https://towardsdatascience.com/tradeoffs-how-to-aim-for-the-sweet-spot-c20b40d5e6b6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/tradeoffs-how-to-aim-for-the-sweet-spot-c20b40d5e6b6", "snippet": "Enoug h with the \u2018Bookish\u2019 definition, let us understand it by more relatable <b>analogy</b> with the real world. \u2192 In simple English, \u201cThe inability of <b>machine</b> <b>learning</b> techniques to capture the true relationship is <b>Bias</b>\u201d. Low <b>Bias</b>: Predicted data points are close to the target. Also, the model suggests less assumptions about the form of the target function. High-<b>Bias</b>: Predicted data points are far from the target. Also, the model suggests more assumptions about the form of the target ...", "dateLastCrawled": "2022-01-30T08:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A New <b>Metric</b> for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare", "url": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/a-new-<b>metric</b>-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "A New <b>Metric</b> for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare. Joseph Gartner. March 2, 2020. Background. Several recent, high profile cases of unfair AI algorithms have highlighted the vital need to address <b>bias</b> early in the development of any AI system. For the most part, <b>bias</b> does not come into algorithms due to malicious intent by the individual creating the algorithm. <b>Bias</b> comes from a lack of diligence in ensuring that the AI system is fair for everyone. In order to combat <b>bias</b> ...", "dateLastCrawled": "2022-02-01T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Solutions to the exercises for <b>Machine</b> <b>Learning</b>", "url": "http://www.perfmath.com/ml/ml_liu_text_solutions.pdf", "isFamilyFriendly": true, "displayUrl": "www.perfmath.com/ml/ml_liu_text_solutions.pdf", "snippet": "2 <b>Machine</b> <b>Learning</b> Fundamentals Illustrated with Regression 2.1 Try to find a publicly available <b>machine</b> <b>learning</b> dataset and apply an end-to-end procedure similar to the one we used with the fuel economy dataset to come up with your own first linear regression <b>machine</b> <b>learning</b> project. Summarize how you explored the data, pre-processed the", "dateLastCrawled": "2022-01-18T07:21:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bias metric)  is like +(measuring how much the output of a machine learning algorithm depends on the input features)", "+(bias metric) is similar to +(measuring how much the output of a machine learning algorithm depends on the input features)", "+(bias metric) can be thought of as +(measuring how much the output of a machine learning algorithm depends on the input features)", "+(bias metric) can be compared to +(measuring how much the output of a machine learning algorithm depends on the input features)", "machine learning +(bias metric AND analogy)", "machine learning +(\"bias metric is like\")", "machine learning +(\"bias metric is similar\")", "machine learning +(\"just as bias metric\")", "machine learning +(\"bias metric can be thought of as\")", "machine learning +(\"bias metric can be compared to\")"]}