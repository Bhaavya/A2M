{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Learning Sparse Representation</b> - SlideShare", "url": "https://www.slideshare.net/gpeyre/learning-sparse-representation", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/gpeyre/<b>learning-sparse-representation</b>", "snippet": "In <b>our</b> <b>work</b> we pro- compares the various methods and discusses similarities and compares the various methods and discusses similarities and pose to replace the coding stage from VQ to <b>sparse</b> and redundant pose to replace the coding stage from VQ to <b>sparse</b> and redundant differences between them. Therefore, rather than repeating such differences between them. Therefore, rather than repeating such representations\u2014this leads us to the next subsection, were we de- representations\u2014this leads ...", "dateLastCrawled": "2022-01-30T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Smooth non-negative <b>sparse</b> <b>representation</b> for face and handwritten ...", "url": "https://www.sciencedirect.com/science/article/pii/S156849462100644X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S156849462100644X", "snippet": "<b>Sparse</b> <b>representation</b> problem is one of the most attractive and demanding topics in signal processing, ... parts of a face image (e.g. <b>eyes</b>, eyebrows, lips) can be represented only by applying addition operator on a selection of pixels and hence the non-negativity condition is preserved. In this paper, we propose a novel approach to solve <b>sparse</b> recovery problem with additive non-negative penalty. Motivated by the effectiveness of non-negativity constraint in learning parts of objects ...", "dateLastCrawled": "2021-10-11T23:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Manifold based <b>sparse</b> <b>representation</b> for facial understanding in ...", "url": "https://www.sciencedirect.com/science/article/pii/S0262885613000486", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0262885613000486", "snippet": "As such, the top features for <b>our</b> Manifold based <b>Sparse</b> <b>Representation</b> (MSR) method are the extended face (extface) and face regions. Surprisingly, for the CK dataset, using only the mouth and mustache regions sacrifice only 10\u201315 percentage points of accuracy. This is followed by the nose and eyereg which sacrifice 20 and 30 percentage points respectively. The forehead, <b>eyes</b>, eyebrows, chin, and cheek regions were found to be less valuable.", "dateLastCrawled": "2022-02-03T03:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Discriminative sparse representation for face recognition</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007%2Fs11042-015-3136-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11042-015-3136-x", "snippet": "Recently <b>Sparse</b> <b>Representation</b> (or coding) based Classification (SRC) has gained great success in face recognition. In SRC, the testing image is expected to be best represented as a <b>sparse</b> linear combination of training images from the same class, and the <b>representation</b> fidelity is measured by the \u2113 2-norm or \u2113 1-norm of the coding residual. However, SRC emphasizes the sparsity too much and overlooks the spatial information during local feature encoding process which has been ...", "dateLastCrawled": "2022-01-24T13:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Saliency Detection Using <b>Sparse</b> and Nonlinear Feature <b>Representation</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4034579/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4034579", "snippet": "In <b>our</b> <b>work</b>, we combine the two methods and propose a scheme that takes advantage of both <b>sparse</b> and nonlinear feature <b>representation</b>. To this end, we use independent component analysis (ICA) and covariant matrices, respectively. To compute saliency, we use a biologically plausible center surround difference (CSD) mechanism. <b>Our</b> <b>sparse</b> features are adaptive in nature; the ICA basis function are learnt at every image <b>representation</b>, rather than being fixed. We show that Adaptive <b>Sparse</b> ...", "dateLastCrawled": "2021-09-17T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Sparse Representation Approach to Face Matching across Plastic Surgery</b>", "url": "https://www3.nd.edu/~kwb/Aggarwal_Biswas_Flynn_Bowyer_WACV_2012.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www3.nd.edu</b>/~kwb/Aggarwal_Biswas_Flynn_Bowyer_WACV_2012.pdf", "snippet": "used in <b>our</b> <b>work</b> consists of only one pre-surgery and one post-surgery image per subject making it dif\ufb01cult to di-rectly apply sparsity framework to this task. To this end, we propose a part-wise <b>sparse</b> <b>representation</b> approach that chooses similar images from sequestered training data in a part-wise fashion to ful\ufb01ll the requirement of ...", "dateLastCrawled": "2021-09-07T23:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Saliency Detection Using <b>Sparse and Nonlinear Feature Representation</b>", "url": "https://www.hindawi.com/journals/tswj/2014/137349/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/j<b>our</b>nals/tswj/2014/137349", "snippet": "In <b>our</b> <b>work</b>, we combine the two methods and propose a scheme that takes advantage of both <b>sparse and nonlinear feature representation</b>. To this end, we use independent component analysis (ICA) and covariant matrices, respectively. To compute saliency, we use a biologically plausible center surround difference (CSD) mechanism. <b>Our</b> <b>sparse</b> features are adaptive in nature; the ICA basis function are learnt at every image <b>representation</b>, rather than being fixed. We show that Adaptive <b>Sparse</b> ...", "dateLastCrawled": "2022-01-15T20:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Image colorization using sparse representation</b>", "url": "https://www.researchgate.net/publication/261282221_Image_colorization_using_sparse_representation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../261282221_<b>Image_colorization_using_sparse_representation</b>", "snippet": "In this <b>work</b>, we present a novel method to perform <b>image colorization using sparse representation</b>. <b>Our</b> method first trains an over-complete dictionary in YUV color space. Then taking a grayscale ...", "dateLastCrawled": "2022-01-20T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Face Image Retrieval from <b>Sparse</b> Codeword\u2019s", "url": "https://www.ijsr.net/archive/v4i7/SUB156350.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijsr.net/archive/v4i7/SUB156350.pdf", "snippet": "<b>Sparse</b> coding is one of the approaches for face image retrieval. In <b>our</b> proposed <b>work</b>, we used an attribute-enhanced <b>sparse</b> coding applied to all the patches of a single image. The codeword\u2019s are then combined together for representing a single image. Let us discuss the process of <b>sparse</b> coding for image retrieval. 5.", "dateLastCrawled": "2021-11-24T11:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Nuit Blanche: CS: <b>Replica Method for Sparse Representation</b> of White ...", "url": "https://nuit-blanche.blogspot.com/2011/04/cs-replica-method-for-sparse.html", "isFamilyFriendly": true, "displayUrl": "https://nuit-blanche.blogspot.com/2011/04/cs-replica-method-for-<b>sparse</b>.html", "snippet": "<b>Our</b> <b>work</b> provides an ef\ufb01cient analytical solution to estimate, from few measurements, the diffusion propagator at any radius. We also provide a new analytical solution to extract an important feature characterising the tissue microstructure: the Orientation Distribution Function (ODF). We illustrate and prove the effectiveness of <b>our</b> method in reconstructing the propagator and the ODF on both noisy multiple q-shell synthetic and phantom data.", "dateLastCrawled": "2022-01-17T17:24:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Saliency Detection Using <b>Sparse</b> and Nonlinear Feature <b>Representation</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4034579/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4034579", "snippet": "A popular theory supports <b>sparse</b> feature <b>representation</b>, an image being represented with a basis dictionary having <b>sparse</b> weighting coefficient. Another method uses a nonlinear combination of image features for <b>representation</b>. In <b>our</b> <b>work</b>, we combine the two methods and propose a scheme that takes advantage of both <b>sparse</b> and nonlinear feature <b>representation</b>. To this end, we use independent component analysis (ICA) and covariant matrices, respectively. To compute saliency, we use a ...", "dateLastCrawled": "2021-09-17T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Use of \u21132/3-norm <b>Sparse</b> <b>Representation</b> for Facial Expression Recognition", "url": "https://www.ijsr.net/archive/v3i11/T0NUMTQ4Mjg=.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijsr.net/archive/v3i11/T0NUMTQ4Mjg=.pdf", "snippet": "2/3-norm <b>Sparse</b> <b>Representation</b> for Facial Expression Recognition Sandeep Rangari1, Sandeep Gonnade2 1MATS University, ... In this category, we launch <b>our</b> latest model of <b>sparse</b> <b>representation</b> via \u2113 2/3-norm minimization. After that we represent an active-set based iterative reweighted algorithm to resolve the \u2113 2/3-norm minimization problem, and review the classification procedure of \u2113 2/3-SRC. A. <b>Sparse</b> <b>Representation</b> via \u2113 2/3-norm Minimization The \u2113 2/3-norm minimization is ...", "dateLastCrawled": "2022-02-01T00:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Sparse</b> <b>Representation</b>-based Super-Resolution for Face Recognition At a ...", "url": "http://www.bmva.org/bmvc/2011/proceedings/paper52/paper52.pdf", "isFamilyFriendly": true, "displayUrl": "www.bmva.org/bmvc/2011/proceedings/paper52/paper52.pdf", "snippet": "<b>sparse</b> <b>representation</b> of images that have smooth regions with isolated abrupt changes [15]. In <b>our</b> method, we propose to take advantage of the wavelet decomposition-based rules in conjunction with <b>sparse</b> <b>representation</b> and dictionary learning techniques to improve face recognition rates. Unlike the other methods [2,12,21], the performance of ...", "dateLastCrawled": "2021-12-13T02:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Learning Sparse Representation</b> - SlideShare", "url": "https://www.slideshare.net/gpeyre/learning-sparse-representation", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/gpeyre/<b>learning-sparse-representation</b>", "snippet": "In <b>our</b> <b>work</b> we pro- compares the various methods and discusses similarities and compares the various methods and discusses similarities and pose to replace the coding stage from VQ to <b>sparse</b> and redundant pose to replace the coding stage from VQ to <b>sparse</b> and redundant differences between them. Therefore, rather than repeating such differences between them. Therefore, rather than repeating such representations\u2014this leads us to the next subsection, were we de- representations\u2014this leads ...", "dateLastCrawled": "2022-01-30T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>SPARSE</b> VOLUMETRIC <b>REPRESENTATION</b> OF TIME-LAPSE POINT CLOUD", "url": "https://on-demand.gputechconf.com/gtc/2017/presentation/s7108-innfarn-yoo-sparse-volumetric-representation-of-time-lapse.pdf", "isFamilyFriendly": true, "displayUrl": "https://on-demand.gputechconf.com/gtc/2017/presentation/s7108-innfarn-yoo-<b>sparse</b>...", "snippet": "<b>SPARSE</b> VOLUMETRIC <b>REPRESENTATION</b> OF TIME-LAPSE POINT CLOUD. 2 AGENDA Introduction Previous <b>Work</b> Method Result Future <b>Work</b>. 3 INTRODUCTION Captured external point cloud data by captured Kespry-Drone Captured Photogrammetric Point Cloud - Captured every 2-3 days-235 captures, 190 GB (avg. 810 MB) - Each capture has 300 MB ~ 1.9 GB - 10 ~ 50 million points - Resolution is 10 ~ 20 cm - Some noise Time-lapse Point Cloud Dataset. 4. 5 INTRODUCTION Capturing internal point cloud data-Laser Scan ...", "dateLastCrawled": "2021-12-28T12:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Constrained L1-<b>optimal sparse representation technique for face</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0030399219301045", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0030399219301045", "snippet": "On this basis, <b>similar</b> methodology is adopted in this <b>work</b> and loads of simulations are carried with slight variations in the value of control parameter. Mathematical Compilation of Cuckoo-Search. The cuckoo bird species lay eggs in other bird\u2019s nest where the host bird either throw away the identified foreign eggs or abandon their own nest, shifting to a new location. The algorithm symbolizes each host nest to a capable solution for this design problem and assigns it a fitness value, as ...", "dateLastCrawled": "2022-01-01T20:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Image colorization using sparse representation</b>", "url": "https://www.researchgate.net/publication/261282221_Image_colorization_using_sparse_representation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../261282221_<b>Image_colorization_using_sparse_representation</b>", "snippet": "In this <b>work</b>, we present a novel method to perform <b>image colorization using sparse representation</b>. <b>Our</b> method first trains an over-complete dictionary in YUV color space. Then taking a grayscale ...", "dateLastCrawled": "2022-01-20T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Sparsity analysis versus <b>sparse</b> <b>representation</b> classifier - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S092523121500898X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S092523121500898X", "snippet": "<b>Our</b> use of the <b>sparse</b> <b>representation</b> for classification differs from the other related feature <b>representation</b> techniques. Instead of using the sparsity to identify a relevant model or classifier that can later be used for classifying test samples, we use the <b>sparse</b> regression coefficients of each individual test sample directly for classification, adaptively selecting the training samples that give the most compact <b>representation</b>. The proposed feature extraction can be easily combined with ...", "dateLastCrawled": "2021-12-12T05:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Sparse</b> Graphical <b>Representation</b> based Discriminant Analysis for ...", "url": "https://deepai.org/publication/sparse-graphical-representation-based-discriminant-analysis-for-heterogeneous-face-recognition", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>sparse</b>-graphical-<b>representation</b>-based-discriminant...", "snippet": "<b>Sparse</b> Graphical <b>Representation</b> based Discriminant Analysis for Heterogeneous Face Recognition. ... In <b>our</b> <b>work</b>, we simply sum the similarity scores of different spatial partition strategies after a min-max score normalization. Iii-C SGR-DA Method for HFR. In order to better illustrate the proposed approach, the whole approach is outlined in Fig. 3. Firstly, the face images are divided into patches, and common feature descriptors (SIFT, for example) are used to represent each image patch ...", "dateLastCrawled": "2021-12-10T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "ACCEPTED VERSION", "url": "https://www.researchgate.net/profile/Chunhua-Shen/publication/221210054_Robust_Face_Recognition_via_Accurate_Face_Alignment_and_Sparse_Representation/links/004635302b5d555afd000000/Robust-Face-Recognition-via-Accurate-Face-Alignment-and-Sparse-Representation.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/profile/Chunhua-Shen/publication/221210054_Robust_Face...", "snippet": "termed <b>Sparse</b> <b>Representation</b>-based Classi\ufb01cation (SRC) for the face recognition component. Experiments demonstrate that the whole system is highly quali\ufb01ed for ef\ufb01ciency as well as accuracy ...", "dateLastCrawled": "2021-12-02T01:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Supervised Discriminative Group <b>Sparse</b> <b>Representation</b> for Mild ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4469635/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4469635", "snippet": "To <b>our</b> best knowledge, there has been no <b>work</b> on brain disease diagnosis and/or medical image analysis with the application of the <b>sparse</b> modeling that explicitly incorporates the discriminative approach into the regression model. We also show that the proposed optimization algorithm finds the group-consistent topological network as the conventional group lasso does and further jointly makes the connectivity coefficients to be similar within a class and distinct between classes. Therefore ...", "dateLastCrawled": "2016-11-10T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Non-negative Matrix Factorization with Sparseness Constraints", "url": "https://jmlr.csail.mit.edu/papers/volume5/hoyer04a/hoyer04a.pdf", "isFamilyFriendly": true, "displayUrl": "https://jmlr.csail.mit.edu/papers/volume5/hoyer04a/hoyer04a.pdf", "snippet": "One of the most useful properties of NMF is that it usually produces a <b>sparse</b> <b>representation</b> of the data. Such a <b>representation</b> encodes much of the data using few \u2018active\u2019 components, which makes the encoding easy to interpret. <b>Sparse</b> coding (Field, 1994) has also, on theoretical grounds, been shown to be a useful middle ground between completely distributed representations, on the one hand, and unary representations (grandmother cells) on the other (F\u00a8oldi \u00b4ak and Young, 1995; Thorpe ...", "dateLastCrawled": "2022-02-03T11:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Sparse</b> Coding Using Biologically Plausible Local Learning Rules ...", "url": "https://fenrirllc.com/2021/09/17/sparse-coding-using-biologically-plausible-local-learning-rules/", "isFamilyFriendly": true, "displayUrl": "https://fenrirllc.com/2021/09/17/<b>sparse</b>-coding-using-biologically-plausible-local...", "snippet": "Despite the apparent limitations of biological networks, <b>our</b> brains are capable of interpreting the complex scenes presented to <b>our</b> <b>eyes</b>. Previous studies have shown that <b>sparse</b> coding algorithms trained on natural images <b>can</b> accurately predict the features that excite visual cortical neurons, but it was not known whether such codes could be learned using biologically realistic plasticity rules.", "dateLastCrawled": "2022-01-02T16:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Facial Expression Recognition &amp; Comparative Study on Densenet161 and ...", "url": "https://medium.com/analytics-vidhya/facial-expression-recognition-comparative-study-on-densenet161-and-resnet152-e88ee02b6734", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/facial-expression-recognition-comparative-study-on...", "snippet": "Facial Expression Recognition <b>can</b> be featured as one of the classification jobs people might like to include in the set of computer vision. The job of <b>our</b> project will be to look through a camera\u2026", "dateLastCrawled": "2022-01-23T09:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Forming cooperative representations via solipsistic synaptic plasticity ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3240538/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3240538", "snippet": "In that case, the value \u03c8 ij <b>can</b> <b>be thought</b> of as the strength of the synaptic connection between input pixel value X j, and neuron i. With that interpretation in mind, it is clear that the canonical learning rule \u0394\u03c8 ij = \u03b1 b i (X j - \u2211 i b i \u03c8 ij), used by most previous <b>work</b> in this field [1,2], fails to be biologically realistic because the rule for updating one synaptic strength \u03c8 ij requires knowledge of the strengths of many synaptic connections, all on different neurons (with ...", "dateLastCrawled": "2017-01-23T03:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Lecture 14: Learning: Sparse Spaces, Phonology</b> | Lecture Videos ...", "url": "https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/lecture-14-learning-sparse-spaces-phonology/", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/.../lecture-videos/<b>lecture-14-learning-sparse-spaces-phonology</b>", "snippet": "Well, it&#39;s a pretty <b>sparse</b> space out there. ... If you have a <b>representation</b> in which you <b>can</b> see the right answer by looking at descriptions through soda straw, that&#39;s probably a better <b>representation</b> than one that&#39;s all spread out. It&#39;s true with programs, right? If you <b>can</b> see how they <b>work</b> by looking through a soda straw, you&#39;re in much better situation to understand something if you have to look here and there and on the next page and in the next file. So all this is basically common ...", "dateLastCrawled": "2022-02-02T16:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Image Denoising Via Learned Dictionaries and <b>Sparse</b> <b>representation</b> ...", "url": "https://www.researchgate.net/publication/4246192_Image_Denoising_Via_Learned_Dictionaries_and_Sparse_representation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/4246192_Image_Denoising_Via_Learned...", "snippet": "<b>Sparse</b> <b>representation</b> <b>can</b> simplify learning tasks and reduce model complexity. <b>Sparse</b> <b>representation</b> has a large number of applications in the fields of signal acquisition, denoising, and image ...", "dateLastCrawled": "2022-01-27T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Do Neural Networks Learn Shearlets</b>?", "url": "https://elybrand.github.io/sparse_net/", "isFamilyFriendly": true, "displayUrl": "https://elybrand.github.io/<b>sparse</b>_net", "snippet": "Each sub-network <b>can</b> <b>be thought</b> of as a function in a <b>representation</b> system which the aggregate network will learn. The network is trained with stochastic gradient descent with the usual backpropagation and \\(\\ell^2\\) loss. All weights except those in the second layer are trainable. The reason for fixing the weights in the second layer is to encourage the first two layers to learn something like a bump function. See the paragraph below Figure 3 for a more complete explanation.", "dateLastCrawled": "2022-01-31T22:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "\u201cAn Efficient <b>Representation</b> for <b>Sparse</b> Sets\u201d | MetaFilter", "url": "https://www.metafilter.com/69932/An-Efficient-Representation-for-Sparse-Sets", "isFamilyFriendly": true, "displayUrl": "https://www.metafilter.com/69932", "snippet": "I <b>thought</b> that what the point of this scheme. What you want to store is used as an index into <b>sparse</b>. No, it&#39;s more general than that--the interface is the same as any array. The example given uses the same values as both the index and the stored value, but that&#39;s not required. <b>Sparse</b> could be indexed by employee number, for example, and each ...", "dateLastCrawled": "2022-01-26T12:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to start to learn <b>sparse</b> coding or dictionary learning, such that I ...", "url": "https://www.quora.com/How-do-I-start-to-learn-sparse-coding-or-dictionary-learning-such-that-I-can-write-my-own-optimization-equations", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-do-I-start-to-learn-<b>sparse</b>-coding-or-dictionary-learning...", "snippet": "Answer: I think it depends on you. The <b>sparse</b> <b>representation</b> has huge literature. If we just restrict <b>our</b> discussion on learning based methods, you will need to have a good understanding of optimization and linear algebra. You need to have experience with some of the well-known optimization appro...", "dateLastCrawled": "2022-01-11T05:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse</b> <b>representation</b> for face recognition: A review paper | Request PDF", "url": "https://www.researchgate.net/publication/349865972_Sparse_representation_for_face_recognition_A_review_paper", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/349865972_<b>Sparse</b>_<b>representation</b>_for_face...", "snippet": "The taxonomy of <b>sparse</b> <b>representation</b> methods <b>can</b> be studied from various viewpoints. For example, in terms of different norm minimizations used in sparsity constraints, the methods <b>can</b> be roughly ...", "dateLastCrawled": "2022-01-04T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Effective two\u2010step method for face hallucination based on <b>sparse</b> ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2012.0554", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2012.0554", "snippet": "3.2 Local face model <b>representation</b> (<b>sparse</b> residual compensation) The reason to choose the <b>sparse</b> <b>representation</b> for <b>our</b> <b>work</b> is that, the principle of compressed sensing ensures that under mild conditions, the <b>sparse</b> <b>representation</b> <b>can</b> be correctly recovered from the down-sampled signals [].We have two dictionaries d l and d h that are obtained from training sample low- and high-resolution face images and these two dictionaries contain low- and high-resolution residual face images.", "dateLastCrawled": "2022-01-13T11:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Low-Rank and Eigenface Based <b>Sparse</b> <b>Representation</b> for Face Recognition", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4204857/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4204857", "snippet": "Introduction. <b>Sparse</b> <b>representation</b> algorithm has been successfully applied in image restoration and compressed sensing in the past several years. Recently, it has also led to promising results in image classification such as face recognition \u2013 and texture recognition .For face recognition, given an over-complete dictionary, a testing face image <b>can</b> be linearly represented as a <b>sparse</b> coefficient vector.", "dateLastCrawled": "2016-12-31T23:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A VISUAL SURFACE DEFECT DETECTION METHOD BASED ON LOW RANK AND <b>SPARSE</b> ...", "url": "http://www.ijicic.org/ijicic-160104.pdf", "isFamilyFriendly": true, "displayUrl": "www.ijicic.org/ijicic-160104.pdf", "snippet": "low rank and <b>sparse</b> <b>representation</b> is proposed. The main contribution of <b>our</b> <b>work</b> <b>can</b> be summarized as follows. Firstly, a noise term is added to reduce the e\ufb00ect of noise and uneven illumination based on RPCA. Secondly, a Laplacian regularization term is applied to constrain the spatial relationship of superpixels, which is bene\ufb01cial to detect", "dateLastCrawled": "2021-08-11T09:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A New Approach for Clustered MCs Classification with <b>Sparse</b> Features ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3934082/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3934082", "snippet": "In <b>our</b> experiments, they are designed to quantitatively verify the performance of <b>sparse</b> <b>representation</b> based methods for MCs detection and classification by using mammograms. To get an accurate performance measure in this study, a stratified 5-fold cross validation method is employed. We also <b>compared</b> <b>our</b> approaches with the state-of-the-art algorithm, SVMs, which have been successfully applied in MCs detection.", "dateLastCrawled": "2017-02-03T16:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Sparse</b> <b>representation</b> for pose invariant face recognition", "url": "https://hrcak.srce.hr/file/296932", "isFamilyFriendly": true, "displayUrl": "https://hrcak.srce.hr/file/296932", "snippet": "that <b>sparse</b> <b>representation</b> <b>can</b> estimate pose angle accurately, synthesize near frontal faces very well and significantly improve the recognition rate for large pose angles. KEY WORDS: face pose estimation, <b>sparse</b> <b>representation</b>, face synthesis, face recognition. 1. INTRODUCTION As a research hotspot of pattern recognition and computer vision, face recognition has attracted more and more attention from researchers [1, 2]. <b>Compared</b> with other biometric identification techniques, face ...", "dateLastCrawled": "2021-02-05T23:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Smooth non-negative <b>sparse</b> <b>representation</b> for face and handwritten ...", "url": "https://www.sciencedirect.com/science/article/pii/S156849462100644X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S156849462100644X", "snippet": "1. Introduction. <b>Sparse</b> <b>representation</b> problem is one of the most attractive and demanding topics in signal processing, image processing, computer vision and pattern classification research , , .It is now explicitly observed that one <b>can</b> represent variety of signals, images, or patterns with only few non-zero samples using an overcomplete matrix, the so-called dictionary.", "dateLastCrawled": "2021-10-11T23:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Saliency Detection Using <b>Sparse and Nonlinear Feature Representation</b>", "url": "https://www.hindawi.com/journals/tswj/2014/137349/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/j<b>our</b>nals/tswj/2014/137349", "snippet": "In <b>our</b> <b>work</b>, we combine the two methods and propose a scheme that takes advantage of both <b>sparse and nonlinear feature representation</b>. To this end, we use independent component analysis (ICA) and covariant matrices, respectively. To compute saliency, we use a biologically plausible center surround difference (CSD) mechanism. <b>Our</b> <b>sparse</b> features are adaptive in nature; the ICA basis function are learnt at every image <b>representation</b>, rather than being fixed. We show that Adaptive <b>Sparse</b> ...", "dateLastCrawled": "2022-01-15T20:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep Learning of Part-based <b>Representation</b> of Data Using <b>Sparse</b> ...", "url": "https://deepai.org/publication/deep-learning-of-part-based-representation-of-data-using-sparse-autoencoders-with-nonnegativity-constraints", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/deep-learning-of-part-based-<b>representation</b>-of-data...", "snippet": "The key difference <b>compared</b> <b>to our</b> network is that we use a general autoencoder with trainable weights for both the hidden and the output layers. We also use a nonlinear function for the nodes in each layer which makes <b>our</b> model more flexible. The other related <b>work</b> is by Chorowski et al. , who demonstrated that a multilayer perceptron network with softmax output nodes trained with nonnegative weights, was capable of extracting understandable latent features, which consist of part-based ...", "dateLastCrawled": "2021-12-06T16:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "IEEE TRANSACTIONS ON MULTIMEDIA 1 Image Quality Assessment Using Kernel ...", "url": "https://csyhquan.github.io/manuscript/21-tmm-Image%20Quality%20Assessment%20Using%20Kernel%20Sparse%20Coding.pdf", "isFamilyFriendly": true, "displayUrl": "https://csyhquan.github.io/manuscript/21-tmm-Image Quality Assessment Using Kernel...", "snippet": "in this <b>work</b>, we introduce nonlinear <b>sparse</b> coding to IQA. Motivated by the recent advances of kernel <b>sparse</b> coding beyond conventional <b>sparse</b> coding in analyzing non-linear data [22], [24], we develop some effective kernel <b>sparse</b> coding models on image patches, together with a kernel dictionary construction scheme designed for the IQA task. Based on the coding coef\ufb01cients and reconstruction errors from <b>our</b> models, we propose an effective <b>sparse</b>-coding-based IQA method which <b>can</b> exploit ...", "dateLastCrawled": "2022-01-29T04:37:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Neural Networks: Analogies. When our brains form analogies, they\u2026 | by ...", "url": "https://towardsdatascience.com/neural-networks-analogies-7ebeb3ac5d5e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-networks-analogies-7ebeb3ac5d5e", "snippet": "I\u2019ll outline a potential route to artificial neural networks which exhibit transfer <b>learning</b>: First, <b>Sparse</b> Distributed Representations. Numenta\u2019s Hierarchical Te m poral Memory, along with other techniques, relies upon a <b>sparse</b> distributed <b>representation</b>. An example of this is a very long string of ones and zeroes, where almost all the values are zero \u2014 there is a <b>sparse</b> distribution of the ones. If each digit represented a different thing, like \u2018pointy ears\u2019, \u2018tail ...", "dateLastCrawled": "2022-01-28T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "On <b>Machine</b> <b>Learning</b> \u2014 Data, ML &amp; Leadership", "url": "https://bugra.github.io/posts/2014/8/23/on-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://bugra.github.io/posts/2014/8/23/on-<b>machine</b>-<b>learning</b>", "snippet": "<b>Sparse</b> Colorful Filters. Recently, I wrote how we do classification at CB Insights.The post outlines some of the things that I have been thinking about how to apply <b>machine</b> <b>learning</b> for a given problem along with the process that we adopted for the classification problem at CB Insights, but also gave me a good opportunity to reflect even further about the <b>machine</b> <b>learning</b> process; shortcomings of papers, books and even traditional education system when it comes to teach the <b>machine</b> <b>learning</b>.", "dateLastCrawled": "2021-12-10T17:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Compressed Sensing Meets <b>Machine</b> <b>Learning</b>: Classification via <b>Sparse</b> ...", "url": "https://nuit-blanche.blogspot.com/2008/05/cs-mini-course-classification-via.html", "isFamilyFriendly": true, "displayUrl": "https://nuit-blanche.blogspot.com/2008/05/cs-mini-course-classification-via.html", "snippet": "Compressed Sensing Meets <b>Machine</b> <b>Learning</b>: Classification via <b>Sparse</b> <b>Representation</b> and Distributed Pattern Recognition This Spring, Allen Yang has given a mini course at Berkeley entitled Compressed Sensing Meets <b>Machine</b> <b>Learning</b>. The three lectures are listed here (it includes accompanying code): lecture 1: Classification via <b>Sparse</b> <b>Representation</b>; lecture 2: Classification of Mixture Subspace Models via <b>Sparse</b> <b>Representation</b>, lecture 3: Distributed Pattern Recognition; The third lecture ...", "dateLastCrawled": "2022-01-25T10:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Word Embedding: Syntactics or Semantics</b> \u00b7 Shengbin&#39;s Studio", "url": "https://wushbin.github.io/2017/10/09/Word-Embedding-Syntactics-or-Semantics/", "isFamilyFriendly": true, "displayUrl": "https://wushbin.github.io/2017/10/09/<b>Word-Embedding-Syntactics-or-Semantics</b>", "snippet": "<b>Sparse</b> Vector <b>Representation</b>. The co-occurrence matrix in represented each cell by the raw frequency of the co-occurrence of two words. The raw frequency in a matrix may be skewed. Pointwise mutual information PPMI is a good measure for association between words which can tell us how much often the two words occur. The pointwise mutual information is a measure of how often two events x and y occur, compared with what we would expect if they were independent: PMI between two words is ...", "dateLastCrawled": "2022-01-09T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What Are Word Embeddings</b> for Text? - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/what-are-word-embeddings/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>what-are-word-embeddings</b>", "snippet": "Word embeddings are a type of word <b>representation</b> that allows words with similar meaning to have a similar <b>representation</b>. They are a distributed <b>representation</b> for text that is perhaps one of the key breakthroughs for the impressive performance of deep <b>learning</b> methods on challenging natural language processing problems. In this post, you will discover the word embedding approach for representing text data. After", "dateLastCrawled": "2022-01-30T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Accelerating Innovation Through <b>Analogy</b> Mining", "url": "http://hyadatalab.com/papers/analogy-kdd17.pdf", "isFamilyFriendly": true, "displayUrl": "hyadatalab.com/papers/<b>analogy</b>-kdd17.pdf", "snippet": "<b>machine</b> <b>learning</b> models that develop similarity metrics suited for <b>analogy</b> mining. We demonstrate that <b>learning</b> purpose and mechanism representations allows us to \u2022nd analogies with higher precision and recall than traditional information-retrieval methods based on TF-IDF, LSA, LDA and GlOVe, in challenging noisy set-tings. Furthermore, we ...", "dateLastCrawled": "2022-01-29T02:29:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse Adaptive Local Machine Learning</b> Algorithms for Sensing and Analytics", "url": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1000&context=mcecs_mentoring", "isFamilyFriendly": true, "displayUrl": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1000&amp;context=mcecs...", "snippet": "Fig. 2: A <b>sparse representation can be thought of as</b> the dot product of a dictionary vector and a sparse code vector. Given a . dictionary . of general components, we can use a . sparse code. to select as few of them as possible to reconstruct an image of interest (Fig. 2). This reconstruction is called a . sparse representation. Sparse Coding. Image processing is expensive. Instead of working with the original image, we can identify its most relevant components and discard the rest. This ...", "dateLastCrawled": "2021-08-31T12:20:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(sparse representation)  is like +(our eyes work)", "+(sparse representation) is similar to +(our eyes work)", "+(sparse representation) can be thought of as +(our eyes work)", "+(sparse representation) can be compared to +(our eyes work)", "machine learning +(sparse representation AND analogy)", "machine learning +(\"sparse representation is like\")", "machine learning +(\"sparse representation is similar\")", "machine learning +(\"just as sparse representation\")", "machine learning +(\"sparse representation can be thought of as\")", "machine learning +(\"sparse representation can be compared to\")"]}