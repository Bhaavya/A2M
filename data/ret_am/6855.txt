{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "Contrast with <b>equalized</b> <b>odds</b> and equality of opportunity, ... (also abbreviated as separable convolution) factors a standard 3-D convolution <b>into</b> <b>two</b> separate convolution operations that are more computationally efficient: first, a depthwise convolution, with a depth of 1 (n n 1), and then second, a pointwise convolution, with length and width of 1 (1 1 n). To learn more, see Xception: Deep Learning with Depthwise Separable Convolutions. device. #TensorFlow. A category of hardware that can ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A survey on providing customer and public administration based services ...", "url": "https://europepmc.org/article/PMC/PMC8721490", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC8721490", "snippet": "It creates precise definitions of equality of opportunity and <b>equalized</b> <b>odds</b>. This indicates that there exists an immense potential for the unbiased and transparent solution of the citizen centric services to be adopted at the local administration using AI. In 2017, Georgios N. Kouziokas et al. has developed an Artificial Neural Network (ANN) model for unemployment rates forecasting in public administration. The ANN topologies were examined regarding the number of the neurons and the ...", "dateLastCrawled": "2022-01-19T19:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Explainable AI: A Review of Machine Learning Interpretability Methods", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7824368/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7824368", "snippet": "In , Microsoft presented <b>two</b> case studies on real medical <b>data</b>, where naturally interpretable generalized additive models with pairwise interactions (GA 2 Ms), as originally proposed in , achieved state-of-the-art accuracy, showing that GA 2 Ms are the first step towards deploying interpretable high-accuracy models in applications <b>like</b> healthcare, where interpretability is of utmost importance.", "dateLastCrawled": "2022-01-29T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Uncertainty as a <b>Form of Transparency: Measuring, Communicating</b>, and ...", "url": "https://deepai.org/publication/uncertainty-as-a-form-of-transparency-measuring-communicating-and-using-uncertainty", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/uncertainty-as-a-form-of-transparency-measuring...", "snippet": "The <b>equalized</b> <b>odds</b> post-processing method of hardt2016equality is guaranteed to reduce the bias of the classifier under an assumption on the noise in the sensitive attributes, namely the independence of the classifier prediction and the observed attribute, conditional on both the outcome and the true sensitive attribute (awasthi2020equalized).", "dateLastCrawled": "2021-12-01T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Fairness in Machine Learning: A Survey</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-a-survey</b>", "snippet": "There is a recognition in the literature that often <b>data</b> is the problem, i.e. intrinsic biases in the sample will manifest themselves in any model built on the <b>data</b> [boyd2012critical, binns2017], inappropriate uses of <b>data</b> leading to (un)conscious bias(es) [boyd2011six, boyd2012critical], <b>data</b> veracity and quality [zwitter2014big], <b>data</b> relativity and context shifts [boyd2012critical, rost2013representation, gonzalez2014assessing], and subjectivity filters [boyd2011six]. Even for skilled ml ...", "dateLastCrawled": "2022-01-18T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Ultimate <b>Data</b> Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-<b>data</b>-science-flash-cards", "snippet": "Contrast with <b>equalized</b> <b>odds</b> and equality of opportunity, which permit classification results in aggregate to depend on sensitive attributes, but do not permit classification results for certain specified ground-truth labels to depend on sensitive attributes. See &quot;Attacking discrimination with smarter machine learning&quot; for a visualization exploring the tradeoffs when optimizing for demographic parity. Dense Feature. A feature in which most values are non-zero, typically a Tensor of floating ...", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[Solved] [urgent] I NEED LIVE HELP ON Fundamentals of Quantitative ...", "url": "https://www.coursehero.com/tutors-problems/Statistics-and-Probability/9403040-urgent-I-NEED-LIVE-HELP-ON-Fundamentals-of-Quantitative-Methods-MAT/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/tutors-problems/Statistics-and-Probability/9403040-urgent-I...", "snippet": "[urgent] I NEED LIVE HELP ON Fundamentals of Quantitative Methods (MATHS) - Statistics and Probability. plz leave ur kik or Skype, i&#39;ll add you and choose u the best when u helped me!", "dateLastCrawled": "2022-01-31T03:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Education Crisis: Being in School Is Not the Same as ... - <b>World Bank</b>", "url": "https://www.worldbank.org/en/news/immersive-story/2019/01/22/pass-or-fail-how-can-the-world-do-its-homework", "isFamilyFriendly": true, "displayUrl": "https://<b>www.worldbank.org</b>/en/news/immersive-story/2019/01/22/pass-or-fail-how-can-the...", "snippet": "In rural India, nearly three-quarters of third graders cannot solve a <b>two</b>-digit subtraction problem such as 46 minus 17, and by grade five \u2014 half still cannot do so. The world is facing a learning crisis. While countries have significantly increased access to education, being in school isn\u2019t the same thing as learning.", "dateLastCrawled": "2022-02-02T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>08 Stats</b> Flashcards | Quizlet", "url": "https://quizlet.com/9721630/08-stats-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/9721630/<b>08-stats</b>-flash-cards", "snippet": "The _____ is determined by <b>dividing</b> the sum of all values by the number of cases/scores (or N), providing the most useful measure of central tendency (MCT) for normal distributions; the _____ is the middle value when <b>data</b> is ordered from lowest to highest, making it less sensitive to extreme scores than the prior MCT and thus more useful with skewed distributions; the _____ is the most frequent value in a <b>data</b> <b>set</b> (can have more than one). Mean; median; mode. How is the median calculated ...", "dateLastCrawled": "2022-02-02T06:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Bias In, Bias Out</b>. - Free Online Library", "url": "https://www.thefreelibrary.com/Bias+In%2c+Bias+Out.-a0594620991", "isFamilyFriendly": true, "displayUrl": "https://www.thefreelibrary.com/Bias+In,+Bias+Out.-a0594620991", "snippet": "Melissa Hamilton has recently shown that the very same prediction <b>data</b> <b>set</b> that ProPublica analyzed for black/white disparities manifests even greater disparities between Hispanic and white defendants. (27) As the debate on equality in algorithmic prediction evolves, the analysis here is meant to serve as a template with broader applications. The Article proceeds in four <b>Parts</b>. Part I chronicles the recent scholarly and public debate over risk assessment and racial inequality, using the ...", "dateLastCrawled": "2021-11-09T17:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Explaining the Sex Difference in Dyslexia", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5438271/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5438271", "snippet": "It is now clear that we can divide the over-representation of males with dyslexia <b>into</b> <b>two</b> <b>parts</b>: one invalid part explained by referral bias ... 95% CI = 0.74 \u2013 1.58. Results were <b>similar</b> using a <b>two</b> standard deviation cutoff. Open in a separate window. Figure 2. Reading skill distributions by sex. X-axis values are mean z-scores for the reading composite. Measurement Invariance. As illustrated in Figure 1, an early step in determining whether a sex difference is due to valid ...", "dateLastCrawled": "2022-01-24T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "Contrast with <b>equalized</b> <b>odds</b> and equality of opportunity, ... (also abbreviated as separable convolution) factors a standard 3-D convolution <b>into</b> <b>two</b> separate convolution operations that are more computationally efficient: first, a depthwise convolution, with a depth of 1 (n n 1), and then second, a pointwise convolution, with length and width of 1 (1 1 n). To learn more, see Xception: Deep Learning with Depthwise Separable Convolutions. device. #TensorFlow. A category of hardware that can ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Uncertainty as a <b>Form of Transparency: Measuring, Communicating</b>, and ...", "url": "https://deepai.org/publication/uncertainty-as-a-form-of-transparency-measuring-communicating-and-using-uncertainty", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/uncertainty-as-a-form-of-transparency-measuring...", "snippet": "The <b>equalized</b> <b>odds</b> post-processing method of ... This method translates the abstract concept of probability distribution <b>into</b> a <b>set</b> of discrete outcomes, which are more familiar concepts to people who have not been trained in statistics. kay_when_2016 \u2019s study showed that people could more accurately derive probability estimates from quantile dot plots than from density plots. One very different approach to conveying uncertainty is to individually show random draws from the probability ...", "dateLastCrawled": "2021-12-01T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A survey on providing customer and public administration based services ...", "url": "https://europepmc.org/article/PMC/PMC8721490", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC8721490", "snippet": "It has <b>two</b> <b>parts</b>, chatbot engine and language module. Language model is in AIML (Artificial Intelligence Mark-up Language) files which consist of patterns and templates. Pattern is used for matching the user query whereas the response will be provided in the template. User sentences given as input in AIML are stored in category which consists of a response template and context. Context is conditional <b>set</b> to provide meaning to the sentence. Input is then pre-processed and matched against ...", "dateLastCrawled": "2022-01-19T19:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Explaining the sex difference in dyslexia. - Abstract - Europe PMC", "url": "https://europepmc.org/article/MED/28176347", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/MED/28176347", "snippet": "<b>Data</b> <b>Similar</b> Articles Funding Explaining the sex difference in dyslexia. ... It is now clear that we can divide the over-representation of males with dyslexia <b>into</b> <b>two</b> <b>parts</b>: one invalid part explained by referral bias, and one potentially valid residual part found in epidemiological samples (Rutter et al., 2004; Shaywitz, Shaywitz, Fletcher, &amp; Escobar, 1990). The male : female sex ratio in referred samples ranges from about 3:1 to 5:1, whereas the sex ratio in epidemiological samples ranges ...", "dateLastCrawled": "2021-08-16T05:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Fairness in Machine Learning: A Survey</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-a-survey</b>", "snippet": "Specifically, there is a rich <b>set</b> of fairness-related work in a variety of disciplines, often with concepts that are <b>similar</b> or equal to current ml fairness research [Hutchinson2019a]. For example, discrimination in hiring decisions has been examined since the 1960s [guion1966employment]. Research <b>into</b> (un)fairness, discrimination, and bias ...", "dateLastCrawled": "2022-01-18T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Ultimate <b>Data</b> Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-<b>data</b>-science-flash-cards", "snippet": "Contrast with <b>equalized</b> <b>odds</b> and equality of opportunity, which permit classification results in aggregate to depend on sensitive attributes, but do not permit classification results for certain specified ground-truth labels to depend on sensitive attributes. See &quot;Attacking discrimination with smarter machine learning&quot; for a visualization exploring the tradeoffs when optimizing for demographic parity. Dense Feature. A feature in which most values are non-zero, typically a Tensor of floating ...", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Controlling Attribute Effect in Linear Regression</b>", "url": "https://www.researchgate.net/publication/261637367_Controlling_Attribute_Effect_in_Linear_Regression", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/261637367_Controlling_Attribute_Effect_in...", "snippet": "In this section, we introduce the task of controlling the. effect of an attribute in a regression model and we de\ufb01ne. different measures of model unbiasedness. We consider a dataset D = { x i ,t ...", "dateLastCrawled": "2021-12-16T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Education Crisis: Being in School Is Not the Same as ... - <b>World Bank</b>", "url": "https://www.worldbank.org/en/news/immersive-story/2019/01/22/pass-or-fail-how-can-the-world-do-its-homework", "isFamilyFriendly": true, "displayUrl": "https://<b>www.worldbank.org</b>/en/news/immersive-story/2019/01/22/pass-or-fail-how-can-the...", "snippet": "In rural India, nearly three-quarters of third graders cannot solve a <b>two</b>-digit subtraction problem such as 46 minus 17, and by grade five \u2014 half still cannot do so. The world is facing a learning crisis. While countries have significantly increased access to education, being in school isn\u2019t the same thing as learning.", "dateLastCrawled": "2022-02-02T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Bias In, Bias Out</b>. - Free Online Library", "url": "https://www.thefreelibrary.com/Bias+In%2c+Bias+Out.-a0594620991", "isFamilyFriendly": true, "displayUrl": "https://www.thefreelibrary.com/Bias+In,+Bias+Out.-a0594620991", "snippet": "Melissa Hamilton has recently shown that the very same prediction <b>data</b> <b>set</b> that ProPublica analyzed for black/white disparities manifests even greater disparities between Hispanic and white defendants. (27) As the debate on equality in algorithmic prediction evolves, the analysis here is meant to serve as a template with broader applications. The Article proceeds in four <b>Parts</b>. Part I chronicles the recent scholarly and public debate over risk assessment and racial inequality, using the ...", "dateLastCrawled": "2021-11-09T17:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Explaining the Sex Difference in Dyslexia", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5438271/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5438271", "snippet": "It is now clear that we <b>can</b> divide the over-representation of males with dyslexia <b>into</b> <b>two</b> <b>parts</b>: one invalid part explained by referral bias ... (VDM) attributes the sex difference to greater variance in males\u2019 reading performance. To test this model, we <b>equalized</b> the variance by <b>dividing</b> males\u2019 and females\u2019 reading scores by their respective standard deviations so that each group had a standard deviation of one. If the observed sex differences are due to a variance difference, then ...", "dateLastCrawled": "2022-01-24T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Uncertainty as a <b>Form of Transparency: Measuring, Communicating</b>, and ...", "url": "https://deepai.org/publication/uncertainty-as-a-form-of-transparency-measuring-communicating-and-using-uncertainty", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/uncertainty-as-a-form-of-transparency-measuring...", "snippet": "These methods <b>can</b> be broadly classified <b>into</b> <b>two</b> categories: Bayesian approaches (welling2011bayesian; graves2011practical; ... the measures of demographic parity and <b>equalized</b> <b>odds</b> computed on the observed <b>data</b> are equal to the true metrics up to a scaling factor, which is proportional to the value of the noise (lamy2019noise); if the noise rates are known, then the true metrics <b>can</b> be directly estimated. When information on the protected class is unavailable, but it <b>can</b> be predicted from ...", "dateLastCrawled": "2021-12-01T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Genome Wide Association Scan of Bovine Tuberculosis Susceptibility in ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/3280253/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/3280253", "snippet": "If only the samples with EBVs are included in the MDS analysis and then the samples are objectively divided <b>into</b> <b>two</b> clusters one contains 253 sires (average 97.8% Holstein, 2.2% Friesian) and 54 sires (average 24% Holstein and 76% Friesian). (DOCX) pone.0030545.s001.docx (42K) GUID: A280DB89-13EB-411E-A006-6265710BF6D0. Figure S2: EBV distributions in all samples and in the <b>two</b> clusters identified by <b>dividing</b> an MDS analysis of an Identical by State matrix. None of the pairwise comparisons ...", "dateLastCrawled": "2021-09-02T16:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Equality of Opportunity</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/equal-opportunity/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/equal-opportunity", "snippet": "This line of <b>thought</b> is discernible in chapter <b>two</b> of John Rawls&#39;s classic treatise on justice (Rawls 1999; see also Barry 1989: chapter 6). If we accept that people ought to enjoy formal <b>equality of opportunity</b> or careers open to talents, we should be concerned that morally arbitrary good and bad fortune <b>can</b> determine whether individuals have the opportunity to develop their potential talents and become qualified for positions that confer special advantages and favorable life prospects. If ...", "dateLastCrawled": "2022-01-31T06:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Genetics Exam 2</b> Flashcards | Quizlet", "url": "https://quizlet.com/101652833/genetics-exam-2-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/101652833/<b>genetics-exam-2</b>-flash-cards", "snippet": "In a balanced inversion, one or both breakpoints <b>can</b> fall inside a gene&#39;s sequence, resulting in the gene&#39;s sequence being broken <b>into</b> <b>two</b> <b>parts</b>, and the <b>parts</b> being separated from each other They <b>can</b> also cause the &quot;position effect.&quot; For either a balanced or unbalanced reciprocal translocation there may be a position effect:", "dateLastCrawled": "2020-09-26T21:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Fairness in Machine Learning: A Survey</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-a-survey</b>", "snippet": "There is a recognition in the literature that often <b>data</b> is the problem, i.e. intrinsic biases in the sample will manifest themselves in any model built on the <b>data</b> [boyd2012critical, binns2017], inappropriate uses of <b>data</b> leading to (un)conscious bias(es) [boyd2011six, boyd2012critical], <b>data</b> veracity and quality [zwitter2014big], <b>data</b> relativity and context shifts [boyd2012critical, rost2013representation, gonzalez2014assessing], and subjectivity filters [boyd2011six]. Even for skilled ml ...", "dateLastCrawled": "2022-01-18T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Controlling Attribute Effect in Linear Regression</b>", "url": "https://www.researchgate.net/publication/261637367_Controlling_Attribute_Effect_in_Linear_Regression", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/261637367_Controlling_Attribute_Effect_in...", "snippet": "<b>data</b> <b>into</b> strata such that within the stratum none of the bias. <b>can</b> be justi\ufb01ed by the explanatory attributes. Once the explanatory part of the bias has been removed. by <b>dividing</b> <b>into</b> strata, we ...", "dateLastCrawled": "2021-12-16T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Smart Alex</b> Answers - Milton Rocks", "url": "http://milton-the-cat.rocks/home/dsus_alex.html", "isFamilyFriendly": true, "displayUrl": "milton-the-cat.rocks/home/dsus_alex.html", "snippet": "Generate hypotheses: break your theory down <b>into</b> a <b>set</b> of testable predictions. Collect <b>data</b> to test the theory: decide on what variables you need to measure to test your predictions and how best to measure or manipulate those variables. Analyse the <b>data</b>: look at the <b>data</b> visually and by fitting a statistical model to see if it supports your predictions (and therefore your theory). At this point you should return to your theory and revise it if necessary. Task 1.2. What is the fundamental ...", "dateLastCrawled": "2022-01-30T11:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Education Crisis: Being in School Is Not the Same as ... - <b>World Bank</b>", "url": "https://www.worldbank.org/en/news/immersive-story/2019/01/22/pass-or-fail-how-can-the-world-do-its-homework", "isFamilyFriendly": true, "displayUrl": "https://<b>www.worldbank.org</b>/en/news/immersive-story/2019/01/22/pass-or-fail-how-<b>can</b>-the...", "snippet": "In rural India, nearly three-quarters of third graders cannot solve a <b>two</b>-digit subtraction problem such as 46 minus 17, and by grade five \u2014 half still cannot do so. The world is facing a learning crisis. While countries have significantly increased access to education, being in school isn\u2019t the same thing as learning.", "dateLastCrawled": "2022-02-02T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Research Methods and Statistical Terms Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/3176831/research-methods-and-statistical-terms-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/3176831/research-methods-and-statistical-terms-flash-cards", "snippet": "measure of variability that is the average difference between each score and the mean of the <b>data</b> <b>set</b> (demonstrates consistency) correlation. the degree to which one variable is related to another. correlation coefficient . a statistic (r) that summarizes the strength and direction of a relationship between <b>two</b> variables. statistical significance. a term used to describe research results that have been shown by a statistical test to be UNLIKELY to be due to random chance. ethics. code used ...", "dateLastCrawled": "2020-10-23T22:57:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Explaining the Sex Difference in Dyslexia", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5438271/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5438271", "snippet": "It is now clear that we <b>can</b> divide the over-representation of males with dyslexia <b>into</b> <b>two</b> <b>parts</b>: one invalid part explained by referral bias ... (VDM) attributes the sex difference to greater variance in males\u2019 reading performance. To test this model, we <b>equalized</b> the variance by <b>dividing</b> males\u2019 and females\u2019 reading scores by their respective standard deviations so that each group had a standard deviation of one. If the observed sex differences are due to a variance difference, then ...", "dateLastCrawled": "2022-01-24T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "Contrast with <b>equalized</b> <b>odds</b> and equality of opportunity, ... (also abbreviated as separable convolution) factors a standard 3-D convolution <b>into</b> <b>two</b> separate convolution operations that are more computationally efficient: first, a depthwise convolution, with a depth of 1 (n n 1), and then second, a pointwise convolution, with length and width of 1 (1 1 n). To learn more, see Xception: Deep Learning with Depthwise Separable Convolutions. device. #TensorFlow. A category of hardware that <b>can</b> ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Uncertainty as a <b>Form of Transparency: Measuring, Communicating</b>, and ...", "url": "https://deepai.org/publication/uncertainty-as-a-form-of-transparency-measuring-communicating-and-using-uncertainty", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/uncertainty-as-a-form-of-transparency-measuring...", "snippet": "These methods <b>can</b> be broadly classified <b>into</b> <b>two</b> categories: Bayesian approaches (welling2011bayesian; ... the measures of demographic parity and <b>equalized</b> <b>odds</b> computed on the observed <b>data</b> are equal to the true metrics up to a scaling factor, which is proportional to the value of the noise (lamy2019noise); if the noise rates are known, then the true metrics <b>can</b> be directly estimated. When information on the protected class is unavailable, but it <b>can</b> be predicted from an auxiliary dataset ...", "dateLastCrawled": "2021-12-01T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Mapping and validating stem rust resistance genes directly in self ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8263455/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8263455", "snippet": "Similar infection types <b>can</b> be achieved on the detached leaves <b>compared</b> to whole-plant seedling tests (K. Flath, unpublished <b>data</b>) that are commonly applied to characterize (stem) rust resistance genes in wheat (McIntosh et al. 1995). Further, as the seedling plants remain unaffected and healthy, DNA <b>can</b> be extracted after performing the test from newly emerging leaves. Representative rust isolates were chosen from previous collections (Miedaner et al.", "dateLastCrawled": "2022-01-26T22:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Fairness in Machine Learning: A Survey</b> | DeepAI", "url": "https://deepai.org/publication/fairness-in-machine-learning-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>fairness-in-machine-learning-a-survey</b>", "snippet": "There is a recognition in the literature that often <b>data</b> is the problem, i.e. intrinsic biases in the sample will manifest themselves in any model built on the <b>data</b> [boyd2012critical, binns2017], inappropriate uses of <b>data</b> leading to (un)conscious bias(es) [boyd2011six, boyd2012critical], <b>data</b> veracity and quality [zwitter2014big], <b>data</b> relativity and context shifts [boyd2012critical, rost2013representation, gonzalez2014assessing], and subjectivity filters [boyd2011six]. Even for skilled ml ...", "dateLastCrawled": "2022-01-18T13:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Global Economic <b>Inequality</b> - Our World in <b>Data</b>", "url": "https://ourworldindata.org/global-economic-inequality", "isFamilyFriendly": true, "displayUrl": "https://ourworldin<b>data</b>.org/global-economic-<b>inequality</b>", "snippet": "He wrote a book about it with this title in which he chronicles how some <b>parts</b> of the world escaped the worst poverty and disease, ... Whilst enormous income differences remain, the world no longer neatly divides <b>into</b> the <b>two</b> groups of \u2018developed\u2019 and \u2018developing\u2019 countries. We have moved from a <b>two</b>-hump to a one-hump world. And at the same time, the distribution has also shifted to the right\u2014the incomes of many of the world\u2019s poorest citizens have increased and extreme poverty ...", "dateLastCrawled": "2022-02-03T00:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Statistical Modeling, Causal Inference, and Social Science ...", "url": "http://www.stat.columbia.edu/~cook/movabletype/archives/miscellaneous_statistics/", "isFamilyFriendly": true, "displayUrl": "www.stat.columbia.edu/~cook/movabletype/archives/miscellaneous_statistics", "snippet": "OK, fine. I see his points. But let&#39;s go out <b>into</b> the real world, where people load <b>data</b> <b>into</b> the computer and fit models straight out of the box. (That&#39;s &quot;out of the box,&quot; not &quot;outside the box.&quot;) Here&#39;s something I saw recently, coefficients (and standard errors) from a fitted regression model: coefficient for &quot;per-capita GDP&quot;: -.079 (.170)", "dateLastCrawled": "2022-02-01T23:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Ultimate <b>Data</b> Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-<b>data</b>-science-flash-cards", "snippet": "Contrast with <b>equalized</b> <b>odds</b> and equality of opportunity, which permit classification results in aggregate to depend on sensitive attributes, but do not permit classification results for certain specified ground-truth labels to depend on sensitive attributes. See &quot;Attacking discrimination with smarter machine learning&quot; for a visualization exploring the tradeoffs when optimizing for demographic parity. Dense Feature. A feature in which most values are non-zero, typically a Tensor of floating ...", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>08 Stats</b> Flashcards | Quizlet", "url": "https://quizlet.com/9721630/08-stats-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/9721630/<b>08-stats</b>-flash-cards", "snippet": "<b>Two</b> tests used when <b>data</b> is rank-ordered (i.e., ordinal) include the _____, used when a study involves 2 independent groups, and the _____, used when correlated groups are <b>compared</b>; both <b>can</b> also be used when interval or ratio <b>data</b> does not meet the assumptions of parametric tests (i.e., normal distribution, homogeneity of variance), in which case <b>data</b> would be converted to ranks.", "dateLastCrawled": "2022-02-02T06:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Bias In, Bias Out</b>. - Free Online Library", "url": "https://www.thefreelibrary.com/Bias+In%2c+Bias+Out.-a0594620991", "isFamilyFriendly": true, "displayUrl": "https://www.thefreelibrary.com/Bias+In,+Bias+Out.-a0594620991", "snippet": "Melissa Hamilton has recently shown that the very same prediction <b>data</b> <b>set</b> that ProPublica analyzed for black/white disparities manifests even greater disparities between Hispanic and white defendants. (27) As the debate on equality in algorithmic prediction evolves, the analysis here is meant to serve as a template with broader applications. The Article proceeds in four <b>Parts</b>. Part I chronicles the recent scholarly and public debate over risk assessment and racial inequality, using the ...", "dateLastCrawled": "2021-11-09T17:13:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "A <b>machine learning</b> technique that iteratively combines a set of simple and not very accurate classifiers ... Contrast with <b>equalized</b> <b>odds</b> and equality of opportunity, which permit classification results in aggregate to depend on sensitive attributes, but do not permit classification results for certain specified ground-truth labels to depend on sensitive attributes. See &quot;Attacking discrimination with smarter <b>machine learning</b>&quot; for a visualization exploring the tradeoffs when optimizing for ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Human-centric Approach to Fairness in AI", "url": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "isFamilyFriendly": true, "displayUrl": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "snippet": "We embed the evaluation of AI fairness within the best practices of <b>machine</b> <b>learning</b> development and operations such as version control, ... This includes measures such as Demographic Parity / Statistical Parity (Dwork et al., 2012), <b>Equalized</b> <b>Odds</b> Metric (Hardt et al., 2016) and Calibration within Groups (Chouldechova, 2017). They are all statistical measures derived from the predictions of a classification model and differ in terms of which element(s) of the confusion matrix they are ...", "dateLastCrawled": "2022-02-03T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Residual Unfairness in Fair <b>Machine</b> <b>Learning</b> from Prejudiced Data", "url": "http://proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "snippet": "chine <b>learning</b> has considered some subcomponents of the overall problem we study of <b>learning</b> fair policies from bi-ased datasets. Hardt et al. (2016) formalize the criteria of equal opportunity and <b>equalized</b> <b>odds</b>. Lum &amp; Isaac (2016) show that a predictive policing algorithm for drug enforce-ment in Oakland, trained on police records, will ...", "dateLastCrawled": "2022-01-31T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Survey on Bias and Fairness in <b>Machine</b> <b>Learning</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1908.09635/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1908.09635", "snippet": "With the widespread use of AI systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in <b>machine</b> <b>learning</b>, natural language ...", "dateLastCrawled": "2021-11-15T17:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "Papers on fairness in <b>machine</b> <b>learning</b>, as is common in fields like computer science, abound with formulae. Even the papers referenced here, though selected not for their theorems and proofs but for the ideas they harbor, are no exception. But to start thinking about fairness as it might apply to an ML process at hand, common language \u2013 and common sense \u2013 will do just fine. If, after analyzing your use case, you judge that the more technical results are relevant to the process in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Mitigating Unwanted Biases with Adversarial Learning</b>", "url": "https://www.aies-conference.com/2018/contents/papers/main/AIES_2018_paper_162.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aies-conference.com/2018/contents/papers/main/AIES_2018_paper_162.pdf", "snippet": "<b>Machine</b> <b>learning</b> is a tool for building models that accurately represent input training data. When undesired biases concern- ing demographic groups are in the training data, well-trained models will re\ufb02ect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously <b>learning</b> a predictor and an ad-versary. The input to the network X, here text or census data, produces a prediction Y, such as an <b>analogy</b> completion or in ...", "dateLastCrawled": "2021-12-17T22:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Mitigating Unwanted Biases with Adversarial Learning</b> | DeepAI", "url": "https://deepai.org/publication/mitigating-unwanted-biases-with-adversarial-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>mitigating-unwanted-biases-with-adversarial-learning</b>", "snippet": "<b>Mitigating Unwanted Biases with Adversarial Learning</b>. 01/22/2018 \u2219 by Brian Hu Zhang, et al. \u2219 Google \u2219 Stanford University \u2219 0 \u2219 share . <b>Machine</b> <b>learning</b> is a tool for building models that accurately represent input training data. When undesired biases concerning demographic groups are in the training data, well-trained models will reflect those biases.", "dateLastCrawled": "2021-12-10T20:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "Simply put, the goal of classification is to determine a plausible value for an unknown variable Y given an observed variable X.For example, we might try to predict whether a loan applicant will pay back her loan by looking at various characteristics such as credit history, income, and net worth. Classification also applies in situations where the variable Y does not refer to an event that lies in the future. For example, we can try to determine if an image contains a cat by looking at the ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Measuring discrimination in algorithmic <b>decision making</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10618-017-0506-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10618-017-0506-1", "snippet": "A <b>machine</b> <b>learning</b> algorithm is a procedure used for producing a predictive model from historical data. A model is a collection of decision rules used for <b>decision making</b> for new incoming data. The model would take personal characteristics as inputs (for example, income, credit history, employment status), and produce a prediction (for example, credit risk level). Fig. 1. A typical <b>machine</b> <b>learning</b> setting. Full size image. <b>Learning</b> algorithms as such cannot discriminate, because they are ...", "dateLastCrawled": "2022-01-29T20:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "On Predicting Recidivism: Epistemic Risk, Tradeoffs, and Values in ...", "url": "https://www.cambridge.org/core/journals/canadian-journal-of-philosophy/article/on-predicting-recidivism-epistemic-risk-tradeoffs-and-values-in-machine-learning/7E541FA03E78C3141A65EA99A0CA6E9A", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/canadian-journal-of-philosophy/article/on...", "snippet": "This paper examines the role of value judgments in the design of <b>machine</b>-<b>learning</b> (ML) systems generally and in recidivism-prediction algorithms specifically. Drawing on work on inductive and epistemic risk, the paper argues that ML systems are value laden in ways similar to human decision making, because the development and design of ML systems requires human decisions that involve tradeoffs that reflect values. In many cases, these decisions have significant\u2014and, in some cases, disparate ...", "dateLastCrawled": "2022-01-26T20:57:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(equalized odds)  is like +(dividing data set into two parts)", "+(equalized odds) is similar to +(dividing data set into two parts)", "+(equalized odds) can be thought of as +(dividing data set into two parts)", "+(equalized odds) can be compared to +(dividing data set into two parts)", "machine learning +(equalized odds AND analogy)", "machine learning +(\"equalized odds is like\")", "machine learning +(\"equalized odds is similar\")", "machine learning +(\"just as equalized odds\")", "machine learning +(\"equalized odds can be thought of as\")", "machine learning +(\"equalized odds can be compared to\")"]}