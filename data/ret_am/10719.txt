{"src_spec_res": [[], [], [], []], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Gentle Introduction to Vectors for <b>Machine</b> <b>Learning</b>", "url": "https://machinelearningmastery.com/gentle-introduction-vectors-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>vectors</b>-<b>machine</b>-<b>learning</b>", "snippet": "It is common to introduce vectors using a geometric <b>analogy</b>, where a <b>vector</b> represents a point or coordinate in an n-dimensional space, where n is the number of dimensions, such as 2. The <b>vector</b> can also be thought of as a line from the origin of the <b>vector</b> space with a direction and a magnitude. These analogies are good as a starting point, but should not be held too tightly as we often consider very high dimensional vectors in <b>machine</b> <b>learning</b>. I find the <b>vector</b>-as-coordinate the most ...", "dateLastCrawled": "2022-02-01T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Word Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond king - man ...", "url": "https://aclanthology.org/C16-1332.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/C16-1332.pdf", "snippet": "Word Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond King - Man + Woman = Queen Aleksandr Drozd y, Anna Gladkova z, Satoshi Matsuoka y yTokyo Institute of Technology, Meguro-ku, Tokyo 152-8550, Japan alex@smg.is.titech.ac.jp, matsu@is.titech.ac.jp z The University of Tokyo, Meguro-ku, Tokyo 153-8902 Japan gladkova@phiz.c.u-tokyo.ac.jp Abstract Solving word analogies became one of the most popular benchmarks for word embeddings on the assumption that linear relations between word pairs ...", "dateLastCrawled": "2022-01-20T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Introduction to Matrices and Matrix Arithmetic for <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/introduction-matrices-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/introduction-matrices-<b>machine-learning</b>", "snippet": "The geometric <b>analogy</b> used to help understand vectors and some of their operations does not hold with matrices. Further, a <b>vector</b> itself may be considered a matrix with one column and multiple rows. Often the dimensions of the matrix are denoted as m and n for the number of rows and the number of columns. Now that we know what a matrix is, let\u2019s look at defining one in Python. Defining a Matrix. We can represent a matrix in Python using a two-dimensional NumPy array. A NumPy array can be ...", "dateLastCrawled": "2022-02-02T11:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning :: Cosine Similarity for Vector</b> Space Models (Part III ...", "url": "https://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/", "isFamilyFriendly": true, "displayUrl": "https://blog.christianperone.com/2013/09/<b>machine</b>-<b>learning</b>-", "snippet": "<b>Machine Learning :: Cosine Similarity for Vector</b> Space Models (Part III) 12/09/2013 19/01/2020 Christian S. Perone <b>Machine</b> <b>Learning</b> , Programming , Python * It has been a long time since I wrote the TF-IDF tutorial ( Part I and Part II ) and as I promissed, here is the continuation of the tutorial.", "dateLastCrawled": "2022-01-29T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Word Embedding: Syntactics or Semantics</b> \u00b7 Shengbin&#39;s Studio", "url": "https://wushbin.github.io/2017/10/09/Word-Embedding-Syntactics-or-Semantics/", "isFamilyFriendly": true, "displayUrl": "https://wushbin.github.io/2017/10/09/<b>Word-Embedding-Syntactics-or-Semantics</b>", "snippet": "From all the result of the two method, we know that the dense <b>vector</b> method get a better result than the <b>sparse</b> PPMI method in <b>analogy</b> analysis and similar word search. In addition, the computational efficiency of the dense <b>vector</b> is also better than the PPMI. Short vectors may be easier to use as features in <b>machine</b> <b>learning</b>. Dense vectors may generalize better than storing explicit counts. In addition, dense vectors may perform better in capturing synonymy than <b>sparse</b> vectors.", "dateLastCrawled": "2022-01-09T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Word Embeddings in NLP - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/word-embeddings-in-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/word-embeddings-in-nlp", "snippet": "Word Embeddings are a method of extracting features out of text so that we can input those features into a <b>machine</b> <b>learning</b> model to work with text data. They try to preserve syntactical and semantic information. The methods such as Bag of Words(BOW), CountVectorizer and TFIDF rely on the word count in a sentence but do not save any syntactical or semantic information. In these algorithms, the size of the <b>vector</b> is the number of elements in the vocabulary. We can get a <b>sparse</b> matrix if most ...", "dateLastCrawled": "2022-01-30T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the difference between a <b>Vector</b> and a Tensor in <b>Machine</b> <b>Learning</b>?", "url": "https://www.quora.com/What-is-the-difference-between-a-Vector-and-a-Tensor-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-a-<b>Vector</b>-and-a-Tensor-in-<b>Machine</b>...", "snippet": "Answer (1 of 2): A <b>vector</b> is a tensor of rank 1, a matrix is a tensor of rank 2. For a tensor with more than 2 dimensions, we refer to it as a tensor. Note that, rank of a matrix [1] from linear algebra is not the same as tensor rank [2] 1. Rank (linear algebra) - Wikipedia 2. Tensor - Wikipedia", "dateLastCrawled": "2022-01-13T06:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(sparse vector)  is like +(a set of frequencites)", "+(sparse vector) is similar to +(a set of frequencites)", "+(sparse vector) can be thought of as +(a set of frequencites)", "+(sparse vector) can be compared to +(a set of frequencites)", "machine learning +(sparse vector AND analogy)", "machine learning +(\"sparse vector is like\")", "machine learning +(\"sparse vector is similar\")", "machine learning +(\"just as sparse vector\")", "machine learning +(\"sparse vector can be thought of as\")", "machine learning +(\"sparse vector can be compared to\")"]}