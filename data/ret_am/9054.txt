{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Recommender Systems- BigBasket Case.docx - What is the difference in ...", "url": "https://www.coursehero.com/file/61459139/Recommender-Systems-BigBasket-Casedocx/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/61459139/Recommender-Systems-BigBasket-Casedocx", "snippet": "<b>Grocery</b> <b>store</b>; Safeway Inc; GOA INSTITUTE OF MANAGEMENT; 6 pages. Group 6_Big Basket CASE STUDY.docx. Goa Institute Of Management. HR 13. View more . CaseAssignment3Solution.docx. Indian School of Business. ASC CBA. Indian School of Business \u2022 ASC CBA. CaseAssignment3Solution.docx. homework. 6. Bigbasket Case.pdf. Symbiosis Centre for Information Technology. IT 143. Jaccard index; Cold start; Dice Coefficient; Symbiosis Centre for Information Technology \u2022 IT 143. Bigbasket Case.pdf. 7 ...", "dateLastCrawled": "2022-01-30T20:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Data <b>sparsity</b> most n grams never appear in the corpus even if they are ...", "url": "https://www.coursehero.com/file/p3if9dj/Data-sparsity-most-n-grams-never-appear-in-the-corpus-even-if-they-are-possible/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p3if9dj/Data-<b>sparsity</b>-most-n-grams-never-appear-in-the...", "snippet": "Data <b>sparsity</b>: most n-grams never appear in the corpus, even if they are possible. Traditional ways to deal with data <b>sparsity</b> Use a short context (but this means the model is less powerful) Smooth the probabilities, e.g. by adding imaginary counts Make predictions using an ensemble of n-gram models with different n Richard Zemel COMS 4995 Lecture 3: Automatic Differentiation 30 / 48", "dateLastCrawled": "2022-02-03T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "R <b>Market Basket Analysis</b> using Apriori Examples - DataCamp", "url": "https://www.datacamp.com/community/tutorials/market-basket-analysis-r", "isFamilyFriendly": true, "displayUrl": "https://www.datacamp.com/community/tutorials/<b>market-basket-analysis</b>-r", "snippet": "Next, <b>you</b> have to <b>store</b> this transaction data into a .csv (Comma Separated Values) file. For this, ... The number of zero-valued elements divided by the total number of elements is called the <b>sparsity</b> of the matrix (which is equal to 1 minus the density of the matrix). Summary can also tell <b>you</b> most frequent items. Element (itemset/transaction) length distribution: This is telling <b>you</b> how many transactions are there for 1-itemset, for 2-itemset and so on. The first row is telling <b>you</b> a ...", "dateLastCrawled": "2022-02-02T06:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Missing and Grieving - The Seminarian&#39;s Wife", "url": "https://thepastorwife.com/missing-and-grieving/", "isFamilyFriendly": true, "displayUrl": "https://thepastorwife.com/missing-and-grieving", "snippet": "I enjoy the <b>sparsity</b> of cars on the road and the smaller crowds in the <b>grocery</b> stores as of late. Sometimes I drive to work or <b>go</b> to the <b>store</b> and think this must be what it was <b>like</b> in the 1940\u2019s or the 1950\u2019s. When there were not as many people on the road and in the stores. A time when traffic was not a daily occurrence and <b>you</b> could walk down a shopping aisle without bumping into someone. Days when the neighborhood wasn\u2019t so congested. But I feel guilty for my thoughts and guilty ...", "dateLastCrawled": "2021-11-19T16:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Types of <b>Data</b> Sets in <b>Data</b> Science, <b>Data</b> Mining &amp; Machine Learning | by ...", "url": "https://towardsdatascience.com/types-of-data-sets-in-data-science-data-mining-machine-learning-eb47c80af7a", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/types-of-<b>data</b>-sets-in-<b>data</b>-science-<b>data</b>-mining-machine...", "snippet": "In one of my previous posts, I talked about what <b>Data</b> is and what does <b>Data</b> Attributes mean. This will continue on that, if <b>you</b> haven\u2019t read it, read it here in order to have a proper grasp of the topics and concepts I am going to talk about in the article.. Please bear with me for the conceptual part, I know it can be a bit boring but if <b>you</b> have strong fundamentals, then nothing can stop <b>you</b> from being a great <b>Data</b> Scientist or Machine Learning Engineer.", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Data Similarity</b> - Data Understanding | Coursera", "url": "https://www.coursera.org/lecture/data-mining-pipeline/data-similarity-WxoZS", "isFamilyFriendly": true, "displayUrl": "https://<b>www.coursera.org</b>/lecture/data-mining-pipeline/<b>data-similarity</b>-WxoZS", "snippet": "If <b>you</b> <b>go</b> through <b>like</b> say here <b>you</b> have d and i,j, so d i,j should be always be smaller or not to exceed the distance if <b>you</b> have to <b>go</b> through i to k and k to j as illustrated in our example here. Another way to calculate a similarity, particularly used for this text documents is referred to as this a cosine similarity. With text document so here what <b>you</b> have is that <b>you</b> have the individual keywords and then <b>you</b> would have a way of representing that by the number of occurrences of those ...", "dateLastCrawled": "2022-01-09T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Why are deep neural networks so bad with</b> sparse data? - Quora", "url": "https://www.quora.com/Why-are-deep-neural-networks-so-bad-with-sparse-data", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Why-are-deep-neural-networks-so-bad-with</b>-sparse-data", "snippet": "Answer (1 of 4): The answer lies in the universal approximation theorem (UAT). I\u2019ll try a simple explanation. The UAT states that any function of N-variables can be ...", "dateLastCrawled": "2022-01-26T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "CS <b>6841 - End-Semester TODO: Name TODO: Roll</b>", "url": "https://rakri.github.io/2018spring/hws/endsem.pdf", "isFamilyFriendly": true, "displayUrl": "https://rakri.github.io/2018spring/hws/endsem.pdf", "snippet": "1. (15 points) (<b>Grocery</b> <b>Store</b> Packing) <b>You</b> are given nitems each with some known weight 0 w i 1, and a bunch of bags. Each bag has a weight tolerance of 1 kg beyond which it will break. The goal is to put the items into bags to minimize the number of bags used. Give a simple 2-approximation to this problem, i.e., come up with an algorithm", "dateLastCrawled": "2021-09-15T16:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How We Increased Market Research Speed By 88% \u00bb Opinosis Analytics", "url": "https://www.opinosis-analytics.com/case-study/ai-in-market-research/", "isFamilyFriendly": true, "displayUrl": "https://www.opinosis-analytics.com/case-study/ai-in-market-research", "snippet": "For example, if Safeway (a <b>grocery</b> <b>store</b>) was a topic of analysis, they also wanted to analyze other <b>grocery</b> stores <b>like</b> HEB and Smiths as well as concepts related to <b>grocery</b> stores such as farmers market and grocers .Another example is to be able to surface products that are used in conjunction with other products. For example, peanut butter is often used in conjunction with jelly. While it\u2019s easy for a human to enumerate related concepts for a handful of topics, scaling this up to ...", "dateLastCrawled": "2022-01-24T11:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>the most awkward thing you have ever</b> said to someone? - Quora", "url": "https://www.quora.com/What-is-the-most-awkward-thing-you-have-ever-said-to-someone", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-most-awkward-thing-you-have-ever</b>-said-to-someone", "snippet": "Answer (1 of 12): Something <b>like</b> this just happened to me! I am on a plane (as I write this) flying from San Francisco to Washington DC, currently in snowy Chicago awaiting the connecting flight. I\u2019m wearing a shirt that on the front says \u201cMIT\u201d, but on the back it says, \u201cbecause not everyone can...", "dateLastCrawled": "2022-01-21T05:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Using Content Based Filtering For Recommendation", "url": "https://groups.google.com/g/eydxg5g/c/g7BXHcv1zOw", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/eydxg5g/c/g7BXHcv1zOw", "snippet": "An interesting example is when <b>you</b> <b>go</b> <b>to the grocery</b> <b>store</b> to typically buy food. TF is the frequency of a word in a document. How services like Netflix, Amazon, and Youtube recommend items to the users? Where N is the bag of items, M is passage number of users and d is the legacy or size of target feature vector. Collaborative filtering based on content based on. These methods can also be used to overcome some of the common problems in recommender systems such as cold start and the <b>sparsity</b> ...", "dateLastCrawled": "2022-01-17T21:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Types of <b>Data</b> Sets in <b>Data</b> Science, <b>Data</b> Mining &amp; Machine Learning | by ...", "url": "https://towardsdatascience.com/types-of-data-sets-in-data-science-data-mining-machine-learning-eb47c80af7a", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/types-of-<b>data</b>-sets-in-<b>data</b>-science-<b>data</b>-mining-machine...", "snippet": "In one of my previous posts, I talked about what <b>Data</b> is and what does <b>Data</b> Attributes mean. This will continue on that, if <b>you</b> haven\u2019t read it, read it here in order to have a proper grasp of the topics and concepts I am going to talk about in the article.. Please bear with me for the conceptual part, I know it can be a bit boring but if <b>you</b> have strong fundamentals, then nothing can stop <b>you</b> from being a great <b>Data</b> Scientist or Machine Learning Engineer.", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Data Similarity</b> - Data Understanding | Coursera", "url": "https://www.coursera.org/lecture/data-mining-pipeline/data-similarity-WxoZS", "isFamilyFriendly": true, "displayUrl": "https://<b>www.coursera.org</b>/lecture/data-mining-pipeline/<b>data-similarity</b>-WxoZS", "snippet": "If <b>you</b> think about it, <b>you</b> <b>go</b> to a <b>grocery</b> <b>store</b>, there are certain items <b>you</b>&#39;ve purchased, but the chance of <b>you</b> purchasing one item versus another purchase to the item, they are usually not equal, so usually have a much lower chance of purchasing certain item versus the possible items versus also medical simple tons. If <b>you</b> think about it, your general population, the likelihood that somebody&#39;s coughing or had a fever, that&#39;s usually much smaller compared to a healthy population. People ...", "dateLastCrawled": "2022-01-09T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Cosine Similarity Recommender Systems", "url": "https://groups.google.com/g/uno40lrry/c/DZlM6nUSdXk", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/uno40lrry/c/DZlM6nUSdXk", "snippet": "When customers <b>go</b> into a restaurant or into a <b>grocery</b> <b>store</b>, or it is a similarity between users. As seen in the sorted_<b>similar</b>_movies list, and then decide what items to recommend based on this comparison. Generally, watch and buy proved to be good not only for the business but for the users as well. In practice, a system that can recommend songs based on artists who are related to one another is generated. Similarity Measures for Recommender Systems: A Comparative Study Mr. Not only in the ...", "dateLastCrawled": "2022-01-27T04:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Recommender Systems- BigBasket Case.docx - What is the difference in ...", "url": "https://www.coursehero.com/file/61459139/Recommender-Systems-BigBasket-Casedocx/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/61459139/Recommender-Systems-BigBasket-Casedocx", "snippet": "This way, <b>you</b> can minimize the <b>sparsity</b> of the rating matrix of user items. 7. Grey-Sheep Issues Grey-sheep hints at those who have very inconsistent opinions and unpredictable behaviors. But, this issue is also solvable, and hence, <b>you</b> need not stress out too much! <b>You</b> should know that pure collaborative filtering may not succeed in fixing ...", "dateLastCrawled": "2022-01-30T20:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "CS <b>6841 - End-Semester TODO: Name TODO: Roll</b>", "url": "https://rakri.github.io/2018spring/hws/endsem.pdf", "isFamilyFriendly": true, "displayUrl": "https://rakri.github.io/2018spring/hws/endsem.pdf", "snippet": "1. (15 points) (<b>Grocery</b> <b>Store</b> Packing) <b>You</b> are given nitems each with some known weight 0 w i 1, and a bunch of bags. Each bag has a weight tolerance of 1 kg beyond which it will break. The goal is to put the items into bags to minimize the number of bags used. Give a simple 2-approximation to this problem, i.e., come up with an algorithm", "dateLastCrawled": "2021-09-15T16:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Introduction to Association Rule Mining</b> in R | Jan Kirenz", "url": "https://www.kirenz.com/post/2020-05-14-r-association-rule-mining/", "isFamilyFriendly": true, "displayUrl": "https://www.kirenz.com/post/2020-05-14-r-association-rule-mining", "snippet": "Now imagine a <b>grocery</b> <b>store</b> with tens of thousands of different products. We wouldn\u2019t want to calculate all associations between every possible combination of products. Instead, we would want to select only potentially \u201crelevant\u201d rules from the set of all possible rules. Therefore, we use the measures support, confidence and lift to reduce the number of relationships we need to analyze: Support is an indication of how frequently a set of items appear in baskets. Confidence is an ...", "dateLastCrawled": "2022-02-02T11:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Boosting Product Categorization with Machine Learning</b> | by Amadeus ...", "url": "https://techblog.commercetools.com/boosting-product-categorization-with-machine-learning-ad4dbd30b0e8", "isFamilyFriendly": true, "displayUrl": "https://techblog.commercetools.com/<b>boosting-product-categorization-with-machine</b>...", "snippet": "Like the class probabilities, category similarities are also scaled to the range between 0 and 1, and we count every value above 0.6 as \u201c<b>similar</b> enough\u201d to match a model category to a <b>store</b>-specific category. To account for the variance in the similarities between matches, we multiply the probabilities of our class predictions with these similarity scores to quantify our confidence in the final category predictions.", "dateLastCrawled": "2022-02-02T15:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Answers to Selected Questions and Problems", "url": "https://media.lanecc.edu/users/loftl/CS275/TextReferenceMaterial/SelectedProblemSolutions/Answers%20to%20Selected%20Questions%20and%20Problems-Edition9.doc", "isFamilyFriendly": true, "displayUrl": "https://media.lanecc.edu/users/loftl/CS275/TextReferenceMaterial...", "snippet": "(The proj_emp data file would <b>store</b> the hours that an employee worked on a project.) 9. The file structure in Figure P1.9 contains redundant data (teacher last name, first name, and initial). That data duplication could lead to data anomalies. It would be preferable to use a teacher ID or a teacher number column to relate the schedule data to a Teacher data file. Chapter 2 Data Models. Answers to Selected Review Questions. 2. A business rule is a brief, precise, and unambiguous description ...", "dateLastCrawled": "2022-02-02T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why No Upscale <b>Grocery</b> Stores in Burke? (Alexandria, Dale City: real ...", "url": "https://www.city-data.com/forum/northern-virginia/622759-why-no-upscale-grocery-stores-burke-2.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.city-data.com</b>/forum/northern-virginia/622759-why-no-upscale-<b>grocery</b>-<b>stores</b>...", "snippet": "I&#39;m disappointed with the <b>Grocery</b> <b>Store</b> options, and so now I might have to drive 10 miles to <b>go</b> to ... too. But I&#39;m with <b>you</b> on the lack of <b>grocery</b> stores. I&#39;ve never lived in an area with such a <b>sparsity</b> of <b>grocery</b> stores. And there aren&#39;t even any Super Wal-Marts or Super Targets to theoretically compete them away. Unfortunately, I think this is the consequence of out-of-control suburban sprawl coupled with out-of-control real estate prices. It makes <b>grocery</b> stores not all that ...", "dateLastCrawled": "2022-01-17T19:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Data <b>sparsity</b> most n grams never appear in the corpus even if they are ...", "url": "https://www.coursehero.com/file/p3if9dj/Data-sparsity-most-n-grams-never-appear-in-the-corpus-even-if-they-are-possible/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p3if9dj/Data-<b>sparsity</b>-most-n-grams-never-appear-in-the...", "snippet": "Traditional ways to deal with data <b>sparsity</b> Use a short context (but this means the model is less powerful) ... the first layer <b>can</b> <b>be thought</b> of as a linear layer with tied weights. The weight matrix basically acts like a lookup table. Each column is the representation of a word, also called an embedding, feature vector, or encoding. \u201cEmbedding\u201d emphasizes that it\u2019s a location in a high-dimensonal space; words that are closer together are more semantically similar \u201cFeature vector ...", "dateLastCrawled": "2022-02-03T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Types of <b>Data</b> Sets in <b>Data</b> Science, <b>Data</b> Mining &amp; Machine Learning | by ...", "url": "https://towardsdatascience.com/types-of-data-sets-in-data-science-data-mining-machine-learning-eb47c80af7a", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/types-of-<b>data</b>-sets-in-<b>data</b>-science-<b>data</b>-mining-machine...", "snippet": "For some types of <b>data</b>, the attributes have relationships that involve order in time or space. As <b>you</b> <b>can</b> see in the picture above, it <b>can</b> be segregated into four types:. Sequential <b>Data</b>: Also referred to as temporal <b>data</b>, <b>can</b> <b>be thought</b> of as an extension of record <b>data</b>, where each record has a time associated with it. Consider a retail transaction <b>data</b> set that also stores the time at which the transaction took place", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Recommender Systems- BigBasket Case.docx - What is the difference in ...", "url": "https://www.coursehero.com/file/61459139/Recommender-Systems-BigBasket-Casedocx/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/61459139/Recommender-Systems-BigBasket-Casedocx", "snippet": "This way, <b>you</b> <b>can</b> minimize the <b>sparsity</b> of the rating matrix of user items. 7. Grey-Sheep Issues Grey-sheep hints at those who have very inconsistent opinions and unpredictable behaviors. But, this issue is also solvable, and hence, <b>you</b> need not stress out too much! <b>You</b> should know that pure collaborative filtering may not succeed in fixing ...", "dateLastCrawled": "2022-01-30T20:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Missing and Grieving - The Seminarian&#39;s Wife", "url": "https://thepastorwife.com/missing-and-grieving/", "isFamilyFriendly": true, "displayUrl": "https://thepastorwife.com/missing-and-grieving", "snippet": "I enjoy the <b>sparsity</b> of cars on the road and the smaller crowds in the <b>grocery</b> stores as of late. Sometimes I drive to work or <b>go</b> to the <b>store</b> and think this must be what it was like in the 1940\u2019s or the 1950\u2019s. When there were not as many people on the road and in the stores. A time when traffic was not a daily occurrence and <b>you</b> could walk down a shopping aisle without bumping into someone. Days when the neighborhood wasn\u2019t so congested. But I feel guilty for my thoughts and guilty ...", "dateLastCrawled": "2021-11-19T16:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Retailing in the \u2018New Normal\u2019 \u2013 is Omnichannel still key? - TruRating ...", "url": "https://trurating.com/blog/retailing-in-the-new-normal-is-omnichannel-still-key/", "isFamilyFriendly": true, "displayUrl": "https://trurating.com/blog/retailing-in-the-new-normal-is-omnichannel-still-key", "snippet": "Ricardo Belmar, Retail Transformation <b>Thought</b> Leader &amp; Founder, ... Target issued a press release saying that in 4Q 2020, fully 95% of orders were fulfilled through the <b>store</b>. Retailers who <b>can</b>\u2019t build out this capability will be at a distinct disadvantage. Cathy Hotka, Principal, Cathy Hotka &amp; Associates. It\u2019s simple, shoppers <b>go</b> online to buy to replace or get a specific item, but they <b>go</b> to stores to discover. The importance is in having a dynamic experience to help them discover more ...", "dateLastCrawled": "2021-12-28T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "1.Data Mining - <b>Go</b>_To_NewPostPage", "url": "https://yimsuson.github.io/datamining/Datamining/", "isFamilyFriendly": true, "displayUrl": "https://yimsuson.github.io/datamining/Datamining", "snippet": "1: For the kth attribute, compute a similarity, sk (x, y), in the range [0, 1]. 2: Define an indicator variable, \u03b4k, for the kth attribute as follows: \u03b4k = 0 if the kth attribute is an asymmetric attribute and both objects have a value of 0, or if one of the objects has a missing value for the kth attribute.", "dateLastCrawled": "2021-12-04T11:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Forecasting hierarchical time series using deep learning in a ...", "url": "https://reddspark.blog/2021/11/26/forecasting-hierarchical-time-series-using-deep-learning-in-a-commercial-setting/", "isFamilyFriendly": true, "displayUrl": "https://reddspark.blog/2021/11/26/forecasting-hierarchical-time-series-using-deep...", "snippet": "The result is a forecasting method that <b>can</b> generate a high-level forecast of <b>store</b> sales based on the last 30 days and variables such as day of the week and item level promotions; and then break that forecast down to the brand and item level. To train the model the researchers started with a training dataset spanning 3 years of daily sales data, and then iteratively included an additional week of data into the training set to simulate real world scenarios till they had spanned 4 years ...", "dateLastCrawled": "2022-01-02T01:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>XGBoost: A Deep Dive Into Boosting</b> - DZone AI", "url": "https://dzone.com/articles/xgboost-a-deep-dive-into-boosting", "isFamilyFriendly": true, "displayUrl": "https://dzone.com/articles/<b>xgboost-a-deep-dive-into-boosting</b>", "snippet": "Think of it as organizing efficient routes to your work/college/or <b>grocery</b> stores. As <b>you</b> <b>can</b> use multiple routes to reach your destination, <b>you</b> tend to learn the traffic and the delay it might ...", "dateLastCrawled": "2022-01-31T13:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is <b>the most awkward thing you have ever</b> said to someone? - Quora", "url": "https://www.quora.com/What-is-the-most-awkward-thing-you-have-ever-said-to-someone", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-most-awkward-thing-you-have-ever</b>-said-to-someone", "snippet": "Answer (1 of 12): Something like this just happened to me! I am on a plane (as I write this) flying from San Francisco to Washington DC, currently in snowy Chicago awaiting the connecting flight. I\u2019m wearing a shirt that on the front says \u201cMIT\u201d, but on the back it says, \u201cbecause not everyone <b>can</b>...", "dateLastCrawled": "2022-01-21T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "All Categories", "url": "https://www.sacredchickens.com/sacred-chickens-blog/category/all/5", "isFamilyFriendly": true, "displayUrl": "https://www.sacredchickens.com/sacred-chickens-blog/category/all/5", "snippet": "It meant deciding to stay or <b>go</b>.\u201d First novels are, by and large, a toss up. Some authors are most known for their first novels. Some authors prefer not to talk about them. They <b>can</b> be revelatory or they <b>can</b> fall short of the expectations for that genre. After reading Conjure Women, I <b>can</b> definitively say that Afia Atakora should be proud of her first novel. Read More. 0 Comments Shiverwood: Nick Dunkenstein. 12/4/2020 0 Comments Shiverwood by Nick Dunkenstein. Cain could feel his insides ...", "dateLastCrawled": "2022-01-13T13:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Data <b>sparsity</b> most n grams never appear in the corpus even if they are ...", "url": "https://www.coursehero.com/file/p3if9dj/Data-sparsity-most-n-grams-never-appear-in-the-corpus-even-if-they-are-possible/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p3if9dj/Data-<b>sparsity</b>-most-n-grams-never-appear-in-the...", "snippet": "Data <b>sparsity</b>: most n-grams never appear in the corpus, even if they are possible. Traditional ways to deal with data <b>sparsity</b> Use a short context (but this means the model is less powerful) Smooth the probabilities, e.g. by adding imaginary counts Make predictions using an ensemble of n-gram models with different n Richard Zemel COMS 4995 Lecture 3: Automatic Differentiation 30 / 48", "dateLastCrawled": "2022-02-03T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Pareto Chart and Analysis</b> - What is Six Sigma", "url": "https://www.whatissixsigma.net/pareto-chart-and-analysis/", "isFamilyFriendly": true, "displayUrl": "https://www.whatissixsigma.net/<b>pareto-chart-and-analysis</b>", "snippet": "The conclusion from this example is that the <b>store</b> <b>can</b> focus its scarce resources in addressing the top four reasons for dissatisfaction which are: \u201cFood Presentation\u201d \u2013 25% \u201cQuality of Service\u201d \u2013 24% \u201cCleanliness\u201d \u2013 15%, and \u201cOverall Taste\u201d \u2013 12%; and effectively resolves 80% of the problem of dissatisfied customers. Without the Pareto, the business entity might be spreading out their resources in trying to address all of the reasons of dissatisfaction. Or they might ...", "dateLastCrawled": "2022-02-02T19:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Data Similarity</b> - Data Understanding | Coursera", "url": "https://www.coursera.org/lecture/data-mining-pipeline/data-similarity-WxoZS", "isFamilyFriendly": true, "displayUrl": "https://<b>www.coursera.org</b>/lecture/data-mining-pipeline/<b>data-similarity</b>-WxoZS", "snippet": "If <b>you</b> think about it, <b>you</b> <b>go</b> to a <b>grocery</b> <b>store</b>, there are certain items <b>you</b>&#39;ve purchased, but the chance of <b>you</b> purchasing one item versus another purchase to the item, they are usually not equal, so usually have a much lower chance of purchasing certain item versus the possible items versus also medical simple tons. If <b>you</b> think about it, your general population, the likelihood that somebody&#39;s coughing or had a fever, that&#39;s usually much smaller <b>compared</b> to a healthy population. People ...", "dateLastCrawled": "2022-01-09T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is the essential difference between queries run in an operational ...", "url": "https://www.coursehero.com/file/p7fksf2l/What-is-the-essential-difference-between-queries-run-in-an-operational-system/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p7fksf2l/What-is-the-essential-difference-between...", "snippet": "Effect of <b>Sparsity</b> on Aggregation Consider the case of the <b>grocery</b> chain with 300 stores, 40,000 products in each <b>store</b>, but only 4000 selling in each <b>store</b> in a day. As discussed earlier, assuming that <b>you</b> keep records for 5 years or 1825 days, the maximum number of base fact table rows is calculated as follows: Product \u00bc 40,000", "dateLastCrawled": "2022-01-03T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Why are deep neural networks so bad with</b> sparse data? - Quora", "url": "https://www.quora.com/Why-are-deep-neural-networks-so-bad-with-sparse-data", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Why-are-deep-neural-networks-so-bad-with</b>-sparse-data", "snippet": "Answer (1 of 4): The answer lies in the universal approximation theorem (UAT). I\u2019ll try a simple explanation. The UAT states that any function of N-variables <b>can</b> be ...", "dateLastCrawled": "2022-01-26T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Google Translate</b>", "url": "https://translate.google.gr/?hl=en&tab=wT", "isFamilyFriendly": true, "displayUrl": "https://translate.google.gr/?hl=en&amp;tab=wT", "snippet": "Google&#39;s free service instantly translates words, phrases, and web pages between English and over 100 other languages.", "dateLastCrawled": "2022-02-02T06:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "R <b>Market Basket Analysis</b> using Apriori Examples - DataCamp", "url": "https://www.datacamp.com/community/tutorials/market-basket-analysis-r", "isFamilyFriendly": true, "displayUrl": "https://www.datacamp.com/community/tutorials/<b>market-basket-analysis</b>-r", "snippet": "It <b>can</b> tell <b>you</b> what items do customers frequently buy together by generating a set of rules called Association Rules. In simple words, it gives <b>you</b> output as rules in form if this then that. Clients <b>can</b> use those rules for numerous marketing strategies: Changing the <b>store</b> layout according to trends; Customer behavior analysis ; Catalogue design; Cross marketing on online stores; What are the trending items customers buy; Customized emails with add-on sales; Consider the following example ...", "dateLastCrawled": "2022-02-02T06:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deconstructing XGBoost (Part 2). Welcome back to the Part 2 of\u2026 | by ...", "url": "https://medium.com/@sathuraju/deconstructing-xgboost-part-2-69f13113cca8", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@sathuraju/deconstructing-xgboost-part-2-69f13113cca8", "snippet": "Xgboost <b>can</b> handle missing values as seen from the <b>Sparsity</b> aware algorithm. This brings us to the end of the post. I hope <b>you</b> all now have a brief understanding behind the popular machine ...", "dateLastCrawled": "2021-10-01T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Discussion on Data Mining - <b>Assignment Den</b>", "url": "https://www.assignmentden.com/discussion-on-data-mining/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>assignmentden</b>.com/discussion-on-data-mining", "snippet": "<b>Compared</b> to more traditional research in social science, which is often based on surveys, this analysis requires a broader range of skills and tools, and involves far larger amounts of data. Thus, data science is, by necessity, a highly interdisciplinary field that builds on the continuing work of many fields. The data-driven approach of data science emphasizes the direct discovery of patterns and relationships from data, especially in large quantities of data, often without the need for ...", "dateLastCrawled": "2022-02-03T12:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "If my motorcycle starts to tip over with me on it, what&#39;s the best way ...", "url": "https://www.quora.com/If-my-motorcycle-starts-to-tip-over-with-me-on-it-whats-the-best-way-to-stop-it-from-falling", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/If-my-motorcycle-starts-to-tip-over-with-me-on-it-whats-the-best...", "snippet": "Answer (1 of 9): I will answer the question assuming <b>you</b> are referring to low-speed parking lot maneuvers. At any speed above a slow jog, the bike will stay up easily due to the physics at play in a two-wheeled vehicle. Using the following technique <b>you</b> <b>can</b> change that speed to a slow walk. It&#39;s ...", "dateLastCrawled": "2022-01-12T06:45:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Sparsity</b> is an essential feature of many contemporary data problems. Remote sensing, various forms of automated screening and other high throughput measurement devices collect a large amount of ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Regularization \u2014 Understanding L1 and L2 regularization for Deep <b>Learning</b>", "url": "https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2-regularization-for-deep-learning-a7b9e4a409bf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2...", "snippet": "The <b>sparsity</b> feature used in L1 regularization has been used extensively as a feature selection mechanism in <b>machine</b> <b>learning</b>. Feature selection is a mechanism which inherently simplifies a ...", "dateLastCrawled": "2022-02-01T00:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "An E\ufb03cient Sparse Metric <b>Learning</b> in High ... - <b>Machine</b> <b>Learning</b>", "url": "http://machinelearning.org/archive/icml2009/papers/46.pdf", "isFamilyFriendly": true, "displayUrl": "<b>machinelearning</b>.org/archive/icml2009/papers/46.pdf", "snippet": "This <b>sparsity</b> prior of <b>learning</b> distance metric serves to regularize the com-plexity of the distance model especially in the \u201cless example number p and high dimension d\u201d setting. Theoretically, by <b>analogy</b> to the covariance estimation problem, we \ufb01nd the proposed distance <b>learning</b> algorithm has a consistent result at rate O!&quot;# m2 logd $% n &amp; to the target distance matrix with at most m nonzeros per row. Moreover, from the imple-mentation perspective, this! 1-penalized log-determinant ...", "dateLastCrawled": "2021-11-19T11:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Discovering governing equations from data</b> by sparse identification of ...", "url": "https://www.pnas.org/content/pnas/113/15/3932.full.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/<b>pnas</b>/113/15/3932.full.pdf", "snippet": "examples. In this work, we combin e <b>sparsity</b>-promoting techniques and <b>machine</b> <b>learning</b> with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only as-sumption about the structureof the model is that there are onlya few important terms that govern the dy namics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to ...", "dateLastCrawled": "2022-01-20T20:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> in Medical Imaging", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4220564/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4220564", "snippet": "SUPERVISED <b>LEARNING</b>. In <b>machine</b> <b>learning</b>, one often seeks to predict an output variable y based on a vector x of input variables. To accomplish this, it is assumed that the input and output approximately obey a functional relationship y=f (x), called the predictive model, as shown in Figure 1.In supervised <b>learning</b>, the predictive model is discovered with the benefit of training data consisting of examples for which both x and y are known. We will denote these available pairs of examples as ...", "dateLastCrawled": "2022-02-03T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "What are the <b>basic concepts in machine learning</b>? I found that the best way to discover and get a handle on the <b>basic concepts in machine learning</b> is to review the introduction chapters to <b>machine learning</b> textbooks and to watch the videos from the first model in online courses. Pedro Domingos is a lecturer and professor on <b>machine learning</b> at the University of Washing and", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Dynamical <b>machine</b> <b>learning</b> volumetric reconstruction of objects ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8027224/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8027224", "snippet": "The sequence index in the angle of illumination plays the role of discrete time in the dynamical system <b>analogy</b>. Thus, the imaging problem turns into a problem of nonlinear system identification, which also suggests dynamical <b>learning</b> as a better fit to regularize the reconstructions. We devised a Recurrent Neural Network (RNN) architecture with a novel Separable-Convolution Gated Recurrent Unit (SC-GRU) as the fundamental building block. Through a comprehensive comparison of several ...", "dateLastCrawled": "2022-01-08T19:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Dynamical machine learning volumetric reconstruction of</b> objects ...", "url": "https://www.nature.com/articles/s41377-021-00512-x", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41377-021-00512-x", "snippet": "Recently, thanks to a ground-breaking observation from 2010 that <b>sparsity</b> can be learnt by a deep neural network 48, the idea of using <b>machine</b> <b>learning</b> to approximate solutions to inverse problems ...", "dateLastCrawled": "2022-02-02T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "regression - Why L1 norm for sparse models - Cross Validated", "url": "https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/45643", "snippet": "There are many norms that lead to <b>sparsity</b> (e.g., as you mentioned, any Lp norm with p &lt;= 1). In general, any norm with a sharp corner at zero induces <b>sparsity</b>. So, going back to the original question - the L1 norm induces <b>sparsity</b> by having a discontinuous gradient at zero (and any other penalty with this property will do so too). $\\endgroup$", "dateLastCrawled": "2022-01-26T23:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>What Are Word Embeddings</b> for Text? - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/what-are-word-embeddings/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>what-are-word-embeddings</b>", "snippet": "The result is a <b>learning</b> model that may result in generally better word embeddings. GloVe, is a new global log-bilinear regression model for the unsupervised <b>learning</b> of word representations that outperforms other models on word <b>analogy</b>, word similarity, and named entity recognition tasks. \u2014 GloVe: Global Vectors for Word Representation, 2014.", "dateLastCrawled": "2022-01-30T18:50:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Learning Neural Representations for Network Anomaly Detection</b>", "url": "https://www.researchgate.net/publication/325797465_Learning_Neural_Representations_for_Network_Anomaly_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/325797465_<b>Learning</b>_Neural_Representations_for...", "snippet": "Many <b>machine</b> <b>learning</b> algorithms have been. Manuscript received December 22, 2017; revised March 13, 2018. This. work is funded by Vietnam International Education De velopment (VIED) and. by ...", "dateLastCrawled": "2021-12-06T22:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Self-representation based dual-graph regularized <b>feature selection</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231215010759", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231215010759", "snippet": "<b>Just as sparsity</b> leads to sparse representation, self-similarity results in self-representation ... Her current research interests include pattern recognition and <b>machine</b> <b>learning</b>. Licheng Jiao (SM\u05f389) received the B.S. degree from Shanghai Jiaotong University, Shanghai, China, in 1982, the M.S. and Ph.D. degrees from Xi\u05f3an Jiaotong University, Xi\u05f3an, China, in 1984 and 1990, respectively. From 1990 to 1991, he was a postdoctoral Fellow in the National Key Laboratory for Radar Signal ...", "dateLastCrawled": "2021-11-22T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Self-representation based dual-graph regularized feature selection ...", "url": "https://web.xidian.edu.cn/rhshang/files/20160516_172953.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.xidian.edu.cn/rhshang/files/20160516_172953.pdf", "snippet": "<b>machine</b> <b>learning</b> and computer vision \ufb01elds [41]. <b>Just as sparsity</b> leads to sparse representation, self-similarity results in self-representation [41]. Taking into account of manifold <b>learning</b> and feature selection, and inspired by the self-representation property and the idea of dual-regularization <b>learning</b> [44,45], we propose a novel feature selection algorithm for clustering, named self-representation based dual-graph regularized feature selection clustering (DFSC). This algorithm ...", "dateLastCrawled": "2022-02-02T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Unsupervised feature selection</b> by <b>regularized self-representation</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0031320314002970", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320314002970", "snippet": "<b>Just as sparsity</b> leads to sparse representation, self-similarity results in self-representation. With the above considerations, in this paper we propose a simple yet very effective <b>unsupervised feature selection</b> method by exploiting the self-representation ability of features. The feature matrix is represented over itself to find the representative feature components. The representation residual is minimized by L 2, 1-norm loss to reduce the effect of outlier samples. Different from the ...", "dateLastCrawled": "2022-01-24T12:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Talk <b>Archive</b> - Research on Algorithms and Incentives in Networks", "url": "https://rain.stanford.edu/schedule/archive.shtml", "isFamilyFriendly": true, "displayUrl": "https://rain.stanford.edu/schedule/<b>archive</b>.shtml", "snippet": "McFowland\u2019s research interests\u2014which lie at the intersection of Information Systems, <b>Machine</b> <b>Learning</b>, and Public Policy\u2014include the development of computationally efficient algorithms for large-scale statistical <b>machine</b> <b>learning</b> and \u201cbig data\u201d analytics. More specifically, his research seeks to demonstrate that many real-world problems faced by organizations, and society more broadly, can be reduced to the tasks of anomalous pattern detection and discovery. As a data and ...", "dateLastCrawled": "2022-01-20T11:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Talks - <b>sites.google.com</b>", "url": "https://sites.google.com/view/dssseminarseries/talks", "isFamilyFriendly": true, "displayUrl": "https://<b>sites.google.com</b>/view/dssseminarseries/talks", "snippet": "Abstracts &amp; Bios for upcoming talks", "dateLastCrawled": "2022-01-27T14:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Sparse representations for text categorization</b>", "url": "https://www.researchgate.net/publication/221479613_Sparse_representations_for_text_categorization", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221479613_Sparse_representations_for_text...", "snippet": "<b>Machine</b> <b>learning</b> for text classification is the cornerstone of document categorization, news filtering, document routing, and personalization. In text domains, effective feature selection is ...", "dateLastCrawled": "2021-12-10T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Continual Learning via Neural Pruning</b> | DeepAI", "url": "https://deepai.org/publication/continual-learning-via-neural-pruning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>continual-learning-via-neural-pruning</b>", "snippet": "Continual <b>learning</b>, the ability of models to learn to solve new tasks beyond what has previously been trained, has garnered much attention from the <b>machine</b> <b>learning</b> community in recent years. This is driven in part by the practical advantages promised by continual <b>learning</b> schemes such as improved performance on subsequent tasks as well as a more efficient use of resources in machines with memory constraints.", "dateLastCrawled": "2021-12-30T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Sparse Representations for Text Categorization</b> | Dimitri Kanevsky ...", "url": "https://www.academia.edu/2738730/Sparse_Representations_for_Text_Categorization", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2738730/<b>Sparse_Representations_for_Text_Categorization</b>", "snippet": "A Comparative Study of <b>Machine</b> <b>Learning</b> Methods for Verbal Autopsy Text Classification. By Eric S Atwell and Samuel Danso. CSC435 book proposal. By Russell Frith. Higher-Order Smoothing: A Novel Semantic Smoothing Method for Text Classification. By Murat C Ganiz, Mitat Poyraz, and Zeynep Kilimci. INFORMATION RETRIEVAL. By febi k. Introduction to information retrieval. By Valeria Mesi. Download pdf. \u00d7 Close Log In. Log In with Facebook Log In with Google. Sign Up with Apple. or. Email ...", "dateLastCrawled": "2021-10-13T23:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Non-negative data-<b>driven mapping of structural connections</b> with ...", "url": "https://www.sciencedirect.com/science/article/pii/S105381192030759X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S105381192030759X", "snippet": "For ICA, <b>sparsity can be thought of as</b> a proxy for independence. 3.5. In-vivo data decompositions. For real data, we decomposed group-average tractography matrices, using independent component analysis (ICA) and non-negative matrix factorisation (NMF), with a range of model orders K. ICA was initialised with regular PCA, in which the first 500 components were retained (explaining 97% of the total variance). ICA was applied to the reduced dataset using the FastICA algorithm (Hyv\u00e4rinen and ...", "dateLastCrawled": "2021-10-11T05:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Continual <b>Learning</b> via Neural Pruning \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1903.04476/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1903.04476", "snippet": "We introduce Continual <b>Learning</b> via Neural Pruning (CLNP), a new method aimed at lifelong <b>learning</b> in fixed capacity models based on neuronal model sparsification. In this method, subsequent tasks are trained using the inactive neurons and filters of the sparsified network and cause zero deterioration to the performance of previous tasks. In order to deal with the possible compromise between model sparsity and performance, we formalize and incorporate the concept of graceful forgetting: the ...", "dateLastCrawled": "2021-11-07T10:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Abstract - arXiv", "url": "https://arxiv.org/pdf/1903.04476.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/1903.04476.pdf", "snippet": "Continual <b>learning</b>, the ability of models to learn to solve new tasks beyond what has previously been trained, has garnered much attention from the <b>machine</b> <b>learning</b> community in recent years. This is driven in part by the practical advantages promised by continual <b>learning</b> schemes such as improved performance on subsequent tasks as well as a more ef\ufb01cient use of resources in machines with memory constraints. There is also great interest in continual <b>learning</b> from a more long term ...", "dateLastCrawled": "2021-06-03T00:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Continual <b>Learning</b> via Neural Pruning", "url": "https://openreview.net/pdf?id=Hyl_XXYLIB", "isFamilyFriendly": true, "displayUrl": "https://openreview.net/pdf?id=Hyl_XXYLIB", "snippet": "Continual <b>learning</b>, the ability of models to learn to solve new tasks beyond what has previously been trained, has garnered much at-tention from the <b>machine</b> <b>learning</b> community in recent years. The main obstacle for effective continual <b>learning</b> is the problem of cata-strophic forgetting: machines trained on new problems forget about", "dateLastCrawled": "2022-01-05T02:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Introduction to compressed sensing</b>", "url": "https://www.researchgate.net/publication/220043734_Introduction_to_compressed_sensing", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220043734_<b>Introduction_to_compressed_sensing</b>", "snippet": "systems control, clustering, and <b>machine</b> <b>learning</b> [14, 15, 58, 61, 89, 193, 217, 240, 244]. Low-dimensional manifolds hav e also been prop osed as approximate mod-", "dateLastCrawled": "2022-01-14T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Introduction to compressed sensing</b> | Marco Duarte - Academia.edu", "url": "https://www.academia.edu/1443164/Introduction_to_compressed_sensing", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/1443164/<b>Introduction_to_compressed_sensing</b>", "snippet": "<b>Introduction to Compressed Sensing</b> For any x \u2208 \u03a3k , we can associate a k-face of C n with the support and sign pattern of x. One can show that the number of k-faces of AC n is precisely the number of index sets of size k for which signals supported on them can be recovered by (1.12) with B (y) = {z : Az = y}.", "dateLastCrawled": "2022-01-21T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Non-negative data-driven mapping of structural connections with ...", "url": "https://europepmc.org/article/PMC/PMC7116021", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC7116021", "snippet": "Europe PMC is an archive of life sciences journal literature.", "dateLastCrawled": "2021-01-10T00:07:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(sparsity)  is like +(when you go to the grocery store)", "+(sparsity) is similar to +(when you go to the grocery store)", "+(sparsity) can be thought of as +(when you go to the grocery store)", "+(sparsity) can be compared to +(when you go to the grocery store)", "machine learning +(sparsity AND analogy)", "machine learning +(\"sparsity is like\")", "machine learning +(\"sparsity is similar\")", "machine learning +(\"just as sparsity\")", "machine learning +(\"sparsity can be thought of as\")", "machine learning +(\"sparsity can be compared to\")"]}