{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "9 Essential Features for a <b>Bounding</b> <b>Box</b> Annotation Tool", "url": "https://www.v7labs.com/blog/bounding-box-annotation-tool-features", "isFamilyFriendly": true, "displayUrl": "https://www.v7labs.com/blog/<b>bounding</b>-<b>box</b>-annotation-tool-features", "snippet": "There are plenty of <b>image</b> annotation platforms out there, and a <b>bounding</b> <b>box</b> tool seems <b>like</b> a simple enough functionality. But here\u2019s the thing\u2014 The accuracy and quality of your <b>bounding</b> boxes define your model performance, and you may need millions of these to build the most accurate model to market within your use case. Have you taken the time to consider every feature that will help you achieve this? We spoke to hundreds of teams labeling data with <b>bounding</b> boxes and listed (plus ...", "dateLastCrawled": "2022-02-03T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bounding Box</b> Prediction from Scratch using PyTorch | by Aakanksha NS ...", "url": "https://towardsdatascience.com/bounding-box-prediction-from-scratch-using-pytorch-a8525da51ddc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bounding-box</b>-prediction-from-scratch-using-pytorch-a...", "snippet": "Here\u2019s how resizing a <b>bounding box</b> works: Convert the <b>bounding box</b> into <b>an image</b> (called mask) of the same size as the <b>image</b> it corresponds to. This mask would just have 0 for background and 1 for the area covered by the <b>bounding box</b>. Original <b>Image</b>. Mask of the <b>bounding box</b>. Resize the mask to the required dimensions.", "dateLastCrawled": "2022-02-03T07:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Resizing <b>bounding box</b> without scaling <b>image</b> - Adobe Support Community ...", "url": "https://community.adobe.com/t5/illustrator-discussions/resizing-bounding-box-without-scaling-image/m-p/8321443", "isFamilyFriendly": true, "displayUrl": "https://community.adobe.com/.../resizing-<b>bounding-box</b>-without-scaling-<b>image</b>/m-p/8321443", "snippet": "I had placed <b>image</b> files from Photoshop into Illustrator (on the same layer) and most of them had huge <b>bounding</b> boxes <b>surrounding</b> a smaller <b>image</b>. It was awkward to try and select a particular <b>image</b> with another <b>image</b>&#39;s <b>bounding box</b> getting in the way. So, I first placed each seperate <b>image</b> on its own layer, then locked and hid all the layers except the top one. Working on the top layer, I placed a rectangle over the <b>image</b> at the size I wanted the <b>bounding box</b> to be. I then Selected All on ...", "dateLastCrawled": "2022-02-02T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Red &quot;transform&quot; <b>box around image</b> - Adobe Support Community - 9898808", "url": "https://community.adobe.com/t5/illustrator-discussions/red-quot-transform-quot-box-around-image/m-p/9898808", "isFamilyFriendly": true, "displayUrl": "https://community.adobe.com/.../red-quot-transform-quot-<b>box-around-image</b>/m-p/9898808", "snippet": "Does anyone know how I can simply drop <b>an image</b> into a layer rezise it then get rid of the red transform style grid <b>surrounding</b> my <b>image</b> and then be able to freely move my <b>image</b> around? Thank you. Views. 4.1K Likes. <b>Like</b> Translate. Translate. Report. Report. Follow; Report; More. Reply. Reply. Community guidelines. Be kind and respectful, give credit to the original source of content, and search for duplicates before posting. Learn more. 12 Replies 12. Jump to latest reply. Monika Gause ...", "dateLastCrawled": "2022-02-02T08:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Top 5 <b>Image Processing Projects Ideas &amp; Topics [For Beginners</b>] | upGrad ...", "url": "https://www.upgrad.com/blog/image-processing-projects-ideas-topics/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/<b>image-processing-projects-ideas-topics</b>", "snippet": "The red <b>bounding</b> <b>box</b> would mean people in the <b>frame</b> are very close together and therefore at maximum risk. The yellow <b>box</b> would mean that the people are at a considerable distance and the risk is medium. The green boxes would mean people are following the norms and they are safe. Integrating this system with an alerting mechanism (Loudspeakers)could be a great way to alert the pedestrians violating the COVID-19 norms!", "dateLastCrawled": "2022-01-30T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Image</b> Processing with <b>Python</b>: Connected Components and Region Labeling ...", "url": "https://medium.com/swlh/image-processing-with-python-connected-components-and-region-labeling-3eef1864b951", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>image</b>-processing-with-<b>python</b>-connected-components-and-region...", "snippet": "To extract the <b>image</b> within each region, we can use the <b>bounding</b> <b>box</b> attribute of region_props to determine each region\u2019s exact coordinates in the <b>image</b>. From there, we would only need to slice ...", "dateLastCrawled": "2022-01-30T19:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Gentle Introduction to Object Recognition With Deep Learning", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/object-recognition-with-deep-learnin", "snippet": "<b>Image</b> classification involves assigning a class label to <b>an image</b>, whereas object localization involves drawing a <b>bounding</b> <b>box</b> around one or more objects in <b>an image</b>. Object detection is more challenging and combines these two tasks and draws a <b>bounding</b> <b>box</b> around each object of interest in the <b>image</b> and assigns them a class label. Together, all of these problems are referred to as object recognition.", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[<b>boundingBox</b>] opencv example python - Contours \u2013 <b>bounding box</b>, minimum ...", "url": "https://gist.github.com/bigsnarfdude/d811e31ee17495f82f10db12651ae82d", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/bigsnarfdude/d811e31ee17495f82f10db12651ae82d", "snippet": "hi i was using the code to get a <b>bounding box</b> over shaded objects in a picture.for eg, in the pic included, the car is shaded in red and i&#39;d just <b>like</b> the <b>bounding box</b> to be over the car. however with this code the <b>bounding box</b> is generated over everything. how do i tweak it to get what i want, which is just a <b>bounding box</b> over the objects in the pic that is shaded?.", "dateLastCrawled": "2022-02-02T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "c++ - How to put text into a <b>bounding</b> <b>box</b> in OpenCV? - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/32755439/how-to-put-text-into-a-bounding-box-in-opencv", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/32755439", "snippet": "There is a sample code in the description of the function but it only renders some text, the tight <b>box</b> (<b>surrounding</b> the text), and the baseline of it. If you&#39;d <b>like</b> to render the text in an arbitrary ROI of <b>an image</b> then you first need to render it into another <b>image</b> (which fits to the text size), resize it to the ROI desired and then put it over the <b>image</b>, such as below:", "dateLastCrawled": "2022-01-17T13:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Drawing a <b>rectangle</b> around all contours in OpenCV Python - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/40203932/drawing-a-rectangle-around-all-contours-in-opencv-python", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/40203932", "snippet": "i have a code which identifies contours after applying filters on video frames. Now in my case i get 3 contours and i show them by drawing rectangles around them, what i want to do is drawing a <b>rectangle</b> around all these 3 contour rectangles. <b>like</b> it will be a larger <b>rectangle</b>, containing 3 detected rectangles.", "dateLastCrawled": "2022-01-24T20:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Resizing <b>bounding box</b> without scaling <b>image</b> - Adobe Support Community ...", "url": "https://community.adobe.com/t5/illustrator-discussions/resizing-bounding-box-without-scaling-image/m-p/8321443", "isFamilyFriendly": true, "displayUrl": "https://community.adobe.com/.../resizing-<b>bounding-box</b>-without-scaling-<b>image</b>/m-p/8321443", "snippet": "I had placed <b>image</b> files from Photoshop into Illustrator (on the same layer) and most of them had huge <b>bounding</b> boxes <b>surrounding</b> a smaller <b>image</b>. It was awkward to try and select a particular <b>image</b> with another <b>image</b>&#39;s <b>bounding box</b> getting in the way. So, I first placed each seperate <b>image</b> on its own layer, then locked and hid all the layers except the top one. Working on the top layer, I placed a rectangle over the <b>image</b> at the size I wanted the <b>bounding box</b> to be. I then Selected All on ...", "dateLastCrawled": "2022-02-02T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "9 Essential Features for a <b>Bounding</b> <b>Box</b> Annotation Tool", "url": "https://www.v7labs.com/blog/bounding-box-annotation-tool-features", "isFamilyFriendly": true, "displayUrl": "https://www.v7labs.com/blog/<b>bounding</b>-<b>box</b>-annotation-tool-features", "snippet": "There are plenty of <b>image</b> annotation platforms out there, and a <b>bounding</b> <b>box</b> tool seems like a simple enough functionality. But here\u2019s the thing\u2014 The accuracy and quality of your <b>bounding</b> boxes define your model performance, and you may need millions of these to build the most accurate model to market within your use case. Have you taken the time to consider every feature that will help you achieve this? We spoke to hundreds of teams labeling data with <b>bounding</b> boxes and listed (plus ...", "dateLastCrawled": "2022-02-03T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Using <b>Bounding</b>-<b>Surrounding</b> Boxes Method for Fish Tracking in Real World ...", "url": "https://journals.sagepub.com/doi/pdf/10.5772/56631", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/pdf/10.5772/56631", "snippet": "Using <b>Bounding</b>-<b>Surrounding</b> Boxes Method for Fish Tracking in Real World Underwater Observation Regular Paper Yi-Haur Shiau1,*, ... to update this model <b>frame</b> by <b>frame</b>. It can be updated and restructured by spatial variation of successive images. Each pixel is modelled by a mixture of G Gaussian distributions. The history of a pixel is defined as a time series {X1, \u2026, Xt}. The probability function of the pixel value in <b>frame</b> t is: \u03a3 , ,\u03a3 (1) Where is the weight, is the mean value, \u03a3 is ...", "dateLastCrawled": "2021-12-11T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bounding Box</b> Prediction from Scratch using PyTorch | by Aakanksha NS ...", "url": "https://towardsdatascience.com/bounding-box-prediction-from-scratch-using-pytorch-a8525da51ddc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bounding-box</b>-prediction-from-scratch-using-pytorch-a...", "snippet": "Here\u2019s how resizing a <b>bounding box</b> works: Convert the <b>bounding box</b> into <b>an image</b> (called mask) of the same size as the <b>image</b> it corresponds to. This mask would just have 0 for background and 1 for the area covered by the <b>bounding box</b>. Original <b>Image</b>. Mask of the <b>bounding box</b>. Resize the mask to the required dimensions.", "dateLastCrawled": "2022-02-03T07:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Geometric <b>bounding</b> <b>box</b> interpolation: an alternative for efficient ...", "url": "https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-016-0108-7", "isFamilyFriendly": true, "displayUrl": "https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-016-0108-7", "snippet": "This approach enables the annotation of large <b>image</b> databases at the <b>bounding</b> <b>box</b> level in a short time. <b>Video annotation</b> can also be done at different levels. For instance, ANVIL is a free tool that allows video annotations at the <b>frame</b> level, that is, without any spatial information. However, when object location is required, the temporal evolution of the annotated objects must also be provided. Manually annotating the object location for all the frames in the video sequence is a tedious ...", "dateLastCrawled": "2022-01-17T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "3D <b>Bounding Box Estimation Using Deep Learning and</b> Geometry | DeepAI", "url": "https://deepai.org/publication/3d-bounding-box-estimation-using-deep-learning-and-geometry", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/3d-<b>bounding-box-estimation-using-deep-learning-and</b>-geometry", "snippet": "In this work, we propose a method that estimates the pose (R, T) \u2208 S E (3) and the dimensions of an object\u2019s 3D <b>bounding</b> <b>box</b> from a 2D <b>bounding</b> <b>box</b> and the <b>surrounding</b> <b>image</b> pixels. Our simple and efficient method is suitable for many real world applications including self-driving vehicles. The main contribution of our approach is in the choice of the regression parameters and the associated objective functions for the problem. We first regress the orientation and object dimensions ...", "dateLastCrawled": "2022-01-16T08:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Gentle Introduction to Object Recognition With Deep Learning", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/object-recognition-with-deep-learnin", "snippet": "<b>Image</b> classification involves assigning a class label to <b>an image</b>, whereas object localization involves drawing a <b>bounding</b> <b>box</b> around one or more objects in <b>an image</b>. Object detection is more challenging and combines these two tasks and draws a <b>bounding</b> <b>box</b> around each object of interest in the <b>image</b> and assigns them a class label. Together, all of these problems are referred to as object recognition.", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Bounding</b> <b>box</b> annotations and object orientation : computervision", "url": "https://www.reddit.com/r/computervision/comments/pcb4h8/bounding_box_annotations_and_object_orientation/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/computervision/comments/pcb4h8/<b>bounding</b>_<b>box</b>_annotations_and...", "snippet": "The baseball bats within the <b>image</b> <b>frame</b> on the left are oriented at perfect right angles to fit tightly within a <b>bounding</b> <b>box</b>. The baseball bats within the <b>image</b> <b>frame</b> on the right exist at non-orthogonal angles and force the <b>bounding</b> boxes to cover a substantial number of pixels that are not meant to be passed to the model as &quot;baseball bat.&quot; Thus my question: will this severely impact the performance of the object detection algorithm? It seems that the case on the right will erroneously be ...", "dateLastCrawled": "2021-12-15T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "c++ - OpenCV <b>Bounding Box</b> - Stack Overflow", "url": "https://stackoverflow.com/questions/14733042/opencv-bounding-box", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/14733042", "snippet": "You currently draw a <b>bounding box</b> around each contour, and findContour will find a contour around each connected white or black component, of which there are many in your picture. So the first thing I would do is filter all that noise with some morphological operations on the thresholded <b>image</b>: do some opening and closing , both of which are combinations of dilation and erosion .", "dateLastCrawled": "2022-01-22T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Turning any CNN <b>image</b> <b>classifier into an object detector</b> with Keras ...", "url": "https://www.pyimagesearch.com/2020/06/22/turning-any-cnn-image-classifier-into-an-object-detector-with-keras-tensorflow-and-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2020/06/22/turning-any-cnn-<b>image</b>-classifier-into-an...", "snippet": "Object detection, on the other hand, not only tells us what is in the <b>image</b> (i.e., class label) but also where in the <b>image</b> the object is via <b>bounding</b> <b>box</b> (x, y)-coordinates (Figure 1, right). Therefore, object detection algorithms allow us to: Input one <b>image</b>; Obtain multiple <b>bounding</b> boxes and class labels as output", "dateLastCrawled": "2022-02-02T14:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Resizing <b>bounding box</b> without scaling <b>image</b> - Adobe Support Community ...", "url": "https://community.adobe.com/t5/illustrator-discussions/resizing-bounding-box-without-scaling-image/m-p/8321443", "isFamilyFriendly": true, "displayUrl": "https://community.adobe.com/.../resizing-<b>bounding-box</b>-without-scaling-<b>image</b>/m-p/8321443", "snippet": "I had placed <b>image</b> files from Photoshop into Illustrator (on the same layer) and most of them had huge <b>bounding</b> boxes <b>surrounding</b> a smaller <b>image</b>. It was awkward to try and select a particular <b>image</b> with another <b>image</b>&#39;s <b>bounding box</b> getting in the way. So, I first placed each seperate <b>image</b> on its own layer, then locked and hid all the layers except the top one. Working on the top layer, I placed a rectangle over the <b>image</b> at the size I wanted the <b>bounding box</b> to be. I then Selected All on ...", "dateLastCrawled": "2022-02-02T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Complete Review of the OpenCV Object Tracking Algorithms", "url": "https://broutonlab.com/blog/opencv-object-tracking", "isFamilyFriendly": true, "displayUrl": "https://broutonlab.com/blog/opencv-object-tracking", "snippet": "The tracking process <b>can</b> <b>be thought</b> of as a combination of two models: the motion model and the appearance model. The motion model tracks the speed and direction of the object&#39;s movement, which allows it to predict a new position of the object based on the received data. At the same time, the appearance model is responsible for determining if the object we have selected is inside the <b>frame</b>. In the case of using pre-trained classifiers, the coordinates of the <b>bounding</b> <b>box</b> containing the ...", "dateLastCrawled": "2022-01-30T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Object Detection - Atmosera", "url": "https://www.atmosera.com/blog/object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.atmosera.com/blog/object-detection", "snippet": "decode_predictions requires the width and height of the original <b>image</b> as input so it <b>can</b> scale the <b>bounding</b> boxes to match the original <b>image</b> dimensions. The return value is a list of BoundingBox objects, each containing the pixel coordinates of a <b>box</b> <b>surrounding</b> an object detected in the scene, along with a label identifying the object and a confidence value from 0.0 to 1.0.", "dateLastCrawled": "2022-01-29T14:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What&#39;s the role of <b>bounding boxes in object detection</b>? - Quora", "url": "https://www.quora.com/Whats-the-role-of-bounding-boxes-in-object-detection", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Whats-the-role-of-<b>bounding-boxes-in-object-detection</b>", "snippet": "Answer (1 of 3): To be sure that your model <b>can</b> classify your target object and know where it is. So if you have a classification code without <b>bounding</b> <b>box</b>, you don`t know that your model is successfully classified your target object or not. but if you do <b>bounding</b> <b>box</b> around your target object, y...", "dateLastCrawled": "2022-01-22T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Gentle Introduction to Object Recognition With Deep Learning", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/object-recognition-with-deep-learnin", "snippet": "For example, <b>an image</b> may be divided into a 7\u00d77 grid and each cell in the grid may predict 2 <b>bounding</b> boxes, resulting in 94 proposed <b>bounding</b> <b>box</b> predictions. The class probabilities map and the <b>bounding</b> boxes with confidences are then combined into a final set of <b>bounding</b> boxes and class labels. The <b>image</b> taken from the paper below summarizes the two outputs of the model.", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>OpenCV OCR and text recognition with Tesseract</b> - You <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2018/09/17/opencv-ocr-and-text-recognition-with-tesseract/", "isFamilyFriendly": true, "displayUrl": "https://www.py<b>image</b>search.com/2018/09/17/<b>opencv-ocr-and-text-recognition-with-tesseract</b>", "snippet": "In this tutorial, you will learn how to apply OpenCV OCR (Optical Character Recognition). We will perform both (1) text detection and (2) text recognition using OpenCV, Python, and Tesseract.. A few weeks ago I showed you how to perform text detection using OpenCV\u2019s EAST deep learning model.Using this model we were able to detect and localize the <b>bounding</b> <b>box</b> coordinates of text contained in <b>an image</b>.", "dateLastCrawled": "2022-02-02T17:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bounding</b> <b>box</b> annotations and object orientation : computervision", "url": "https://www.reddit.com/r/computervision/comments/pcb4h8/bounding_box_annotations_and_object_orientation/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/computervision/comments/pcb4h8/<b>bounding</b>_<b>box</b>_annotations_and...", "snippet": "I define &quot;nicely&quot; as the target existing relatively orthogonal to the <b>image</b>, allowing for a <b>bounding</b> <b>box</b> to tightly fit the target and include little to no pixels that don&#39;t belong to the target. Instead in my dataset, each <b>image</b> may contain a dozen instances of the target all at various rotations (i.e. not fitting well within a <b>box</b>). Below is a visual example: Targets fitting tightly with a <b>bounding</b> <b>box</b> (L) and not tightly with a <b>bounding</b> <b>box</b> (R) The baseball bats within the <b>image</b> <b>frame</b> on ...", "dateLastCrawled": "2021-12-15T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Measuring size of objects in <b>an image</b> with OpenCV - You <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2016/03/28/measuring-size-of-objects-in-<b>an-image</b>-with-opencv", "snippet": "Measuring the size of an object (or objects) in <b>an image</b> has been a heavily requested tutorial on the <b>PyImageSearch</b> blog for some time now \u2014 and it feels great to get this post online and share it with you. Today\u2019s post is the second in a three part series on measuring the size of objects in <b>an image</b> and computing the distances between them.. Last week, we learned an important technique: how reliably order a set of rotated <b>bounding</b> <b>box</b> coordinates in a top-left, top-right, bottom-right ...", "dateLastCrawled": "2022-02-02T15:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>image</b> processing - Crop <b>black</b> edges with OpenCV - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/13538748/crop-black-edges-with-opencv", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/13538748", "snippet": "There will be only one object, so find <b>bounding</b> rectangle for it. contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE) cnt = contours[0] x,y,w,h = cv2.boundingRect(cnt) Now crop the <b>image</b>, and save it into another file. crop = img[y:y+h,x:x+w] cv2.imwrite(&#39;sofwinres.png&#39;,crop) Below is the result : Share. Improve this answer. Follow answered Nov 24 &#39;12 at 7:17. Abid Rahman K Abid Rahman K. 49.7k 28 28 gold badges 142 142 silver badges 154 154 bronze badges ...", "dateLastCrawled": "2022-01-27T19:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to <b>create a bounding box around 2d drawings</b> : AutoCAD", "url": "https://www.reddit.com/r/AutoCAD/comments/b3bqld/how_to_create_a_bounding_box_around_2d_drawings/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/AutoCAD/comments/b3bqld/how_to_<b>create_a_bounding_box_around</b>_2...", "snippet": "I need to update/add a <b>bounding</b> <b>box</b> to ~2500 2d drawings all of different sizes. I would like to do this via a macro if possible. In case im using the wrong word, when i say <b>bounding</b> <b>box</b> a <b>box</b> with minimum dimentions so its sides are touching the outside perimeter of the 2d drawing. Edit: sorry i just couldn&#39;t get the wording right this morning ...", "dateLastCrawled": "2021-10-05T22:34:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Image</b> Processing with <b>Python</b>: Connected Components and Region Labeling ...", "url": "https://medium.com/swlh/image-processing-with-python-connected-components-and-region-labeling-3eef1864b951", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>image</b>-processing-with-<b>python</b>-connected-components-and-region...", "snippet": "To extract the <b>image</b> within each region, we <b>can</b> use the <b>bounding</b> <b>box</b> attribute of region_props to determine each region\u2019s exact coordinates in the <b>image</b>. From there, we would only need to slice ...", "dateLastCrawled": "2022-01-30T19:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Bioptic Color Camera SDK for Linux - <b>Bounding Box</b> Detection - Zebra ...", "url": "https://techdocs.zebra.com/dcs/scanners/camera-sdk-linux/bounding-box/", "isFamilyFriendly": true, "displayUrl": "https://techdocs.zebra.com/dcs/s<b>can</b>ners/camera-sdk-linux/<b>bounding-box</b>", "snippet": "This <b>image</b> is considered as the Background <b>frame</b> that gets <b>compared</b> with every <b>frame</b> that comes next to check if a movement has occurred. If a movement is detected, the object that caused the movement is identified and a rectangle is drawn <b>surrounding</b> it. The method \u2018SetBackgroundFrame\u2019 should be called to set the Background for comparison. Before passing parameters to \u2018SetBackgroundFrame\u2019, the <b>image</b> that is displayed in the GUI needs to be converted to either a BMP or a JPG <b>image</b> ...", "dateLastCrawled": "2022-01-07T08:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Geometric <b>bounding</b> <b>box</b> interpolation: an alternative for efficient ...", "url": "https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-016-0108-7", "isFamilyFriendly": true, "displayUrl": "https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-016-0108-7", "snippet": "In <b>video annotation</b>, instead of annotating every <b>frame</b> of a trajectory, usually only a sparse set of annotations is provided by the user: typically its endpoints plus some key intermediate frames, interpolating the remaining annotations between these key frames in order to reduce the cost of the video labeling. While a number of <b>video annotation</b> tools have been proposed, some of which are freely available, and <b>bounding</b> <b>box</b> interpolation is mainly based on <b>image</b> processing techniques whose ...", "dateLastCrawled": "2022-01-17T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Intro to Computer Graphics: <b>Visible Surface Determination</b>", "url": "https://www.cs.uic.edu/~jbell/CourseNotes/ComputerGraphics/VisibleSurfaces.html", "isFamilyFriendly": true, "displayUrl": "https://www.cs.uic.edu/~jbell/CourseNotes/ComputerGraphics/VisibleSurfaces.html", "snippet": "<b>image</b> space (<b>image</b> precision in our text) ... Every part of the object is guaranteed to fall within the <b>bounding</b> <b>box</b>. Checks <b>can</b> then be made on the <b>bounding</b> <b>box</b> to make quick decisions (ie does a ray pass through the <b>box</b>.) For more detail, checks would then be made on the object in the <b>box</b>. There are many ways to define the <b>bounding</b> <b>box</b>. The simplest way is to take the minimum and maximum X, Y, and Z values to create a <b>box</b>. You <b>can</b> also have <b>bounding</b> boxes that rotate with the object ...", "dateLastCrawled": "2022-01-23T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Automate <b>Image</b> <b>Annotation</b> on a Small Budget - Bitsy.ai", "url": "https://www.bitsy.ai/automate-bounding-box-annotation-with-tensorflow-and-automl/", "isFamilyFriendly": true, "displayUrl": "https://www.bitsy.ai/automate-<b>bounding</b>-<b>box</b>-<b>annotation</b>-with-tensorflow-and-automl", "snippet": "With a bit of elbow grease, you <b>can</b> automate <b>bounding</b> <b>box</b> <b>annotation</b> for yourself or a small team. In this blog post, I will show you the automation technique I used to quickly prototype a 3D print failure detection model. You&#39;ll learn how to: Create detailed instructions for human labelers ; Train a guidance model ; Automate <b>bounding</b> <b>box</b> <b>annotation</b> with Microsoft VoTT (Visual Object Tagging Tool) and TensorFlow.js; Pictured: Custom TensorFlow model automatically annotates a video <b>frame</b> in ...", "dateLastCrawled": "2022-02-03T09:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Gentle Introduction to Object Recognition With Deep Learning", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/object-recognition-with-deep-learnin", "snippet": "<b>Image</b> classification involves assigning a class label to <b>an image</b>, whereas object localization involves drawing a <b>bounding</b> <b>box</b> around one or more objects in <b>an image</b>. Object detection is more challenging and combines these two tasks and draws a <b>bounding</b> <b>box</b> around each object of interest in the <b>image</b> and assigns them a class label. Together, all of these problems are referred to as object recognition.", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "3D <b>Bounding Box Estimation Using Deep Learning and</b> Geometry | DeepAI", "url": "https://deepai.org/publication/3d-bounding-box-estimation-using-deep-learning-and-geometry", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/3d-<b>bounding-box-estimation-using-deep-learning-and</b>-geometry", "snippet": "In this work, we propose a method that estimates the pose (R, T) \u2208 S E (3) and the dimensions of an object\u2019s 3D <b>bounding</b> <b>box</b> from a 2D <b>bounding</b> <b>box</b> and the <b>surrounding</b> <b>image</b> pixels. Our simple and efficient method is suitable for many real world applications including self-driving vehicles. The main contribution of our approach is in the choice of the regression parameters and the associated objective functions for the problem. We first regress the orientation and object dimensions ...", "dateLastCrawled": "2022-01-16T08:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Complete Review of the OpenCV Object Tracking Algorithms", "url": "https://broutonlab.com/blog/opencv-object-tracking", "isFamilyFriendly": true, "displayUrl": "https://broutonlab.com/blog/opencv-object-tracking", "snippet": "In the case of using pre-trained classifiers, the coordinates of the <b>bounding</b> <b>box</b> containing the object would be determined automatically, whereas by using \u201conline\u201d training, we specify the <b>bounding</b> <b>box</b> manually and the classifier does not have training data, except for those that it <b>can</b> receive while tracking the object. It is worth noting that tracking algorithms <b>can</b> be divided into two groups: single-object tracking and multi-object tracking algorithms, we will consider the former.", "dateLastCrawled": "2022-01-30T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How <b>can</b> I find <b>bounding</b> boxes of objects (object detection and ...", "url": "https://www.quora.com/How-can-I-find-bounding-boxes-of-objects-object-detection-and-localization-with-Keras", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>can</b>-I-find-<b>bounding</b>-<b>box</b>es-of-objects-object-detection-and...", "snippet": "Answer (1 of 3): A simple network <b>can</b> be like, in the VGG16, GooLeNet, or another CNN network, create a second set of FC (Fully Connected) network along side the existing one that does the classification. This second set of FC will be use for predicting a set of four numbers (hence it will do reg...", "dateLastCrawled": "2022-01-13T13:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "matlab - <b>extraction of minimal bounding box</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/28927613/extraction-of-minimal-bounding-box", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/28927613", "snippet": "So that I get a <b>bounding</b> <b>box</b> which looks like this. Now, I want to create a new volume from the MBB. In other words, I want to map every point within the MBB to a new <b>box</b> which is axis-parallel. I <b>can</b> get the dimensions of the new <b>box</b> from the corner points", "dateLastCrawled": "2022-01-10T02:40:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "13.3. Object Detection and <b>Bounding</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0 ...", "url": "http://d2l.ai/chapter_computer-vision/bounding-box.html", "isFamilyFriendly": true, "displayUrl": "d2l.ai/chapter_computer-vision/<b>bounding</b>-<b>box</b>.html", "snippet": "13.3.1. <b>Bounding</b> Boxes\u00b6. In object detection, we usually use a <b>bounding</b> <b>box</b> to describe the spatial location of an object. The <b>bounding</b> <b>box</b> is rectangular, which is determined by the \\(x\\) and \\(y\\) coordinates of the upper-left corner of the rectangle and the such coordinates of the lower-right corner. Another commonly used <b>bounding</b> <b>box</b> representation is the \\((x, y)\\)-axis coordinates of the <b>bounding</b> <b>box</b> center, and the width and height of the <b>box</b>. Here we define functions to convert ...", "dateLastCrawled": "2022-02-02T00:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "5 Main Types of <b>Machine</b> <b>Learning</b> Systems | by Jean de Dieu Nyandwi | Medium", "url": "https://jeande.medium.com/5-main-types-of-machine-learning-systems-fb07b0cc3d35", "isFamilyFriendly": true, "displayUrl": "https://jeande.medium.com/5-main-types-of-<b>machine</b>-<b>learning</b>-systems-fb07b0cc3d35", "snippet": "Semi-supervised <b>learning</b> is most notable in problems that involve working with massive datasets like internet image searches, image and audio recognition, and webpages classification. 4. Self-supervised <b>learning</b>. Self-supervised <b>learning</b> is one of the most exciting types of <b>machine</b> <b>learning</b> that is most applicable in computer vision and robotics.", "dateLastCrawled": "2022-01-25T04:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "In <b>machine-learning</b> image-detection tasks, IoU is used to measure the accuracy of the model\u2019s predicted <b>bounding</b> <b>box</b> with respect to the ground-truth <b>bounding</b> <b>box</b>. In this case, the IoU for the two boxes is the ratio between the overlapping area and the total area, and its value ranges from 0 (no overlap of predicted <b>bounding</b> <b>box</b> and ground-truth <b>bounding</b> <b>box</b>) to 1 (predicted <b>bounding</b> <b>box</b> and ground-truth <b>bounding</b> <b>box</b> have the exact same coordinates).", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> in <b>Computer Vision</b> - Princeton University", "url": "https://www.cs.princeton.edu/courses/archive/spring07/cos424/lectures/li-guest-lecture.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.princeton.edu/courses/archive/spring07/cos424/lectures/li-guest-lecture.pdf", "snippet": "<b>Machine</b> <b>learning</b> Speech Information retrieval Maths Computer Science Information Engineering Physics Biology Robotics Cognitive sciences Psychology. Quiz? What about this? A picture is worth a thousand words.--- Confucius or Printers\u2019 Ink Ad (1921) horizontal lines vertical blue on the top porous oblique white shadow to the left textured large green patches A picture is worth a thousand words.--- Confucius or Printers\u2019 Ink Ad (1921) A picture is worth a thousand words.--- Confucius or ...", "dateLastCrawled": "2022-01-29T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "13.4. <b>Anchor</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/anchor.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>anchor</b>.html", "snippet": "In order to train an object detection model, we need class and offset labels for each <b>anchor</b> <b>box</b>, where the former is the class of the object relevant to the <b>anchor</b> <b>box</b> and the latter is the offset of the ground-truth <b>bounding</b> <b>box</b> relative to the <b>anchor</b> <b>box</b>. During the prediction, for each image we generate multiple <b>anchor</b> boxes, predict classes and offsets for all the <b>anchor</b> boxes, adjust their positions according to the predicted offsets to obtain the predicted <b>bounding</b> boxes, and finally ...", "dateLastCrawled": "2022-01-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Why <b>Deep Learning</b> over Traditional <b>Machine</b> <b>Learning</b>? | by Sambit ...", "url": "https://towardsdatascience.com/why-deep-learning-is-needed-over-traditional-machine-learning-1b6a99177063", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/why-<b>deep-learning</b>-is-needed-over-traditional-<b>machine</b>...", "snippet": "In a simpler way, <b>Machine</b> <b>Learning</b> is set of algorithms that parse data, learn from them, and then apply what they\u2019ve learned to make ... \u201cThe <b>analogy</b> to <b>deep learning</b> is that the rocket engine is the <b>deep learning</b> models and the fuel is the huge amounts of data we can feed to these algorithms.\u201d <b>Deep Learning</b> requires high-end machines contrary to traditional <b>Machine</b> <b>Learning</b> algorithms. GPU has become a integral part now to execute any <b>Deep Learning</b> algorithm. In traditional <b>Machine</b> ...", "dateLastCrawled": "2022-01-30T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning and its Applications</b> - SlideShare", "url": "https://www.slideshare.net/ganeshn9/machine-learning-and-its-applications-138639251", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ganeshn9/<b>machine-learning-and-its-applications</b>-138639251", "snippet": "Problem Solving Approach - Example \u2022 In a <b>machine</b> <b>learning</b> approach, we will divide problem in to two parts \u2013 object detection and object recognition \u2022 We will use an algorithm like <b>bounding</b> <b>box</b> detection as an example to scan through image and detect all objects then use object recognition algorithm to recognize relevant objects \u2022 When ...", "dateLastCrawled": "2022-01-30T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ODAM: Object Detection, Association, and Mapping Using Posed RGB Video", "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Li_ODAM_Object_Detection_Association_and_Mapping_Using_Posed_RGB_Video_ICCV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021/papers/Li_ODAM_Object_Detection...", "snippet": "<b>analogy</b> to the use of 2D <b>bounding</b> boxes (BBs) in images, a 3D <b>bounding</b> volume presents a valuable abstraction of location and space, enabling for example, object-level plan- ningforrobots[13,15],learningscene-levelpriorsoverob-jects [55], or anchoring information on object instances. A robust way of inferring <b>bounding</b> volumes and associated views of individual objects in a scene is a stepping stone to-ward reconstructing, embedding and describing the objects with advanced state-of-the-art ...", "dateLastCrawled": "2022-02-01T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Deep-<b>Learning</b> Model with <b>Task-Specific Bounding Box Regressors</b> and ...", "url": "https://www.mdpi.com/1424-8220/20/18/5269/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/20/18/5269/htm", "snippet": "This paper proposes a deep-<b>learning</b> model with <b>task-specific bounding box regressors</b> (TSBBRs) and conditional back-propagation mechanisms for detection of objects in motion for advanced driver assistance system (ADAS) applications. The proposed model separates the object detection networks for objects of different sizes and applies the proposed algorithm to achieve better detection results for both larger and tinier objects. For larger objects, a neural network with a larger visual receptive ...", "dateLastCrawled": "2022-01-01T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A comprehensive guide to OCR with <b>Tesseract</b>, OpenCV and Python | by ...", "url": "https://medium.com/nanonets/a-comprehensive-guide-to-ocr-with-tesseract-opencv-and-python-fd42f69e8ca8", "isFamilyFriendly": true, "displayUrl": "https://medium.com/nanonets/a-comprehensive-guide-to-ocr-with-<b>tesseract</b>-opencv-and...", "snippet": "Deep <b>learning</b> based models (such as named entity recognition) have managed to obtain unprecedented text recognition accuracy, far beyond traditional feature extraction and <b>machine</b> <b>learning</b> approaches.", "dateLastCrawled": "2022-02-02T15:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Solved: <b>Checking in features</b> - <b>Autodesk</b> Community", "url": "https://forums.autodesk.com/t5/autocad-map-3d-forum/checking-in-features/td-p/6270481", "isFamilyFriendly": true, "displayUrl": "https://<b>forums.autodesk.com</b>/t5/autocad-map-3d-forum/<b>checking-in-features</b>/td-p/6270481", "snippet": "The &quot;<b>bounding box&quot; is like</b> a spatial filter defining the lef bottom and the right upper corner for legal objects. Are you working with UTM coordinates without zone information e.g. 32(N) and inside the shape it is define with 32(N)? 32(N) means a addition of 32000000 to the x-value. When that is true you are out of the bounding box and your ...", "dateLastCrawled": "2022-01-25T23:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "arXiv:2007.04499v1 [cs.RO] 9 Jul 2020", "url": "https://arxiv.org/pdf/2007.04499.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/2007.04499.pdf", "snippet": "contains the observed object, and the <b>bounding box is similar</b> for each valid object detected. However, for robotic grasping, there may be several methods to grasp an object. But it is essential to pick the one with the highest grasp success or with the most stable grasp, thus relying on <b>machine</b> <b>learning</b> techniques to \ufb01nd the best possible grasp. The use of convolutional neural networks is a popular technique used for <b>learning</b> features and visual models that uses a sliding window detection ...", "dateLastCrawled": "2020-07-12T09:31:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "YOLOv3 Tutorial: Understanding What is YOLOv3 and How it works?", "url": "https://bestinau.com.au/yolov3-architecture-best-model-in-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://bestinau.com.au/<b>yolov3-architecture-best-model-in-object-detection</b>", "snippet": "In many <b>machine</b> <b>learning</b> models (Logistic Regression, SVMs), in loss functions we have loss as well as a regularizer multiplied by. The job of this is to make a choice between minimizing loss and regularizing the model. Because of the scale of these two numbers being different, it is sensible to actually weigh them differently. Initially, they didn\u2019t do it and weren\u2019t getting good performance, but later thought that if they could create a weighted model, that might do the trick. These ...", "dateLastCrawled": "2022-02-02T01:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Using AI to Detect Social Distancing Violations - <b>Deep Learning Analytics</b>", "url": "https://deeplearninganalytics.org/using-ai-to-detect-social-distancing-violations/", "isFamilyFriendly": true, "displayUrl": "https://<b>deeplearninganalytics</b>.org/using-ai-to-detect-social-distancing-violations", "snippet": "Each track is basically a bounding box with an ID. So a <b>bounding box can be compared to</b> another bounding using the euclidean distance between them. Now we start our modeling. The code for that is shared below. This is the same code as in my Github. Modeling Social Distancing. The main steps that are run for every frame are: Compare the pixel distance between each track and every other track; If distance &lt; proximity threshold then, two people are too close to each other. So put safe =1 in the ...", "dateLastCrawled": "2022-01-31T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Using AI to Detect <b>Social Distancing</b> Violations | by Priya Dwivedi ...", "url": "https://medium.com/swlh/using-ai-to-detect-social-distancing-violations-4707301844be", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/using-ai-to-detect-<b>social-distancing</b>-violations-4707301844be", "snippet": "<b>Social Distancing</b> Violations Detection and Counting. At Deep <b>Learning</b> Analytics, we are very passionate about using data science and <b>machine</b> <b>learning</b> to solve problems.Please reach out to us if ...", "dateLastCrawled": "2022-01-28T16:11:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(bounding box)  is like +(frame surrounding an image)", "+(bounding box) is similar to +(frame surrounding an image)", "+(bounding box) can be thought of as +(frame surrounding an image)", "+(bounding box) can be compared to +(frame surrounding an image)", "machine learning +(bounding box AND analogy)", "machine learning +(\"bounding box is like\")", "machine learning +(\"bounding box is similar\")", "machine learning +(\"just as bounding box\")", "machine learning +(\"bounding box can be thought of as\")", "machine learning +(\"bounding box can be compared to\")"]}