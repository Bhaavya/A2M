{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Regional <b>Probabilistic</b> Fertility Forecasting by Modeling Between ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4169201/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4169201", "snippet": "The effect of the correlation <b>model</b> on the variance of the regional <b>weighted</b> <b>average</b> TFRs. The ratio of the dependence factor to the independence factor (DF/IF) indicates the multiplicative increase in the variance of the regional TFR when using the correlation <b>model</b> compared to the current <b>model</b> where forecast errors are assumed independent. The \u201cmax proportion\u201d column shows the largest proportion of the current region female population that is attributed to a single country and N is ...", "dateLastCrawled": "2021-12-23T05:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Probabilistic</b> <b>regression</b> with Tensorflow | A blog on science", "url": "https://ekamperi.github.io/machine%20learning/2021/01/07/probabilistic-regression-with-tensorflow.html", "isFamilyFriendly": true, "displayUrl": "https://ekamperi.github.io/machine learning/2021/01/07/<b>probabilistic</b>-<b>regression</b>-with...", "snippet": "The probability of predicting y given an input x and the training data D is: P ( y \u2223 x, D) = \u222b P ( y \u2223 x, w) P ( w \u2223 D) d w. This is equivalent to having an ensemble of models with different parameters w, and taking their <b>average</b> <b>weighted</b> by the posterior probabilities of their parameters, P ( w \u2223 D).", "dateLastCrawled": "2022-01-29T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Approximating Probabilistic Models as Weighted</b> Finite Automata ...", "url": "https://direct.mit.edu/coli/article/47/2/221/98517/Approximating-Probabilistic-Models-as-Weighted", "isFamilyFriendly": true, "displayUrl": "https://direct.mit.edu/.../47/2/221/98517/<b>Approximating-Probabilistic-Models-as-Weighted</b>", "snippet": "Abstract. <b>Weighted</b> finite automata (WFAs) are often used to represent <b>probabilistic</b> models, such as n-gram language models, because among other things, they are efficient for recognition tasks in time and space. The <b>probabilistic</b> source to be represented as a WFA, however, may come in many forms. Given a generic <b>probabilistic</b> <b>model</b> over sequences, we propose an algorithm to approximate it as a WFA such that the Kullback-Leibler divergence between the source <b>model</b> and the WFA target <b>model</b> is ...", "dateLastCrawled": "2022-02-02T01:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Notes On Probabilistic Perspective Part 3</b>", "url": "http://wuciawe.github.io/math/2018/04/16/notes-on-probabilistic-perspective-part-3.html", "isFamilyFriendly": true, "displayUrl": "wuciawe.github.io/math/2018/04/16/<b>notes-on-probabilistic-perspective-part-3</b>.html", "snippet": "Intuitively, perplexity measures the <b>weighted</b> <b>average</b> branching factor of the <b>model</b>\u2019s predictive distribution. Suppose the <b>model</b> predicts that each sysmbol (letter, word, whatever) is equally likely, so \\(p(y_i|y_{1:i-1})=\\frac{1}{K}\\). Then the preplexity is \\(((\\frac{1}{K})^N)^{-\\frac{1}{N}}=K\\). If some symbols are more likely than others, and the <b>model</b> correctly relects this, its perplexity will be lower than \\(K\\). Of course, \\(\\mathbb{H}(p,p)=\\mathbb{H}(p)\\leq\\mathbb{H}(p,q)\\), so we ...", "dateLastCrawled": "2021-12-23T19:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A novel <b>probabilistic</b> <b>regression</b> <b>model</b> for electrical peak demand ...", "url": "https://www.sciencedirect.com/science/article/pii/S2210670721008106", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2210670721008106", "snippet": "<b>Probabilistic</b> <b>regression</b>. A <b>regression</b> <b>model</b> refers to a mathematical expression that connects one or more quantities of interest, such as the electrical demand value in a near future, to a collection of measurable factors. The <b>model</b>\u2019s primary objective is to offer a method for forecasting the quantities of interest given deterministic or <b>probabilistic</b> values for the inputs. When just one quantity is to be predicted, the <b>model</b> is said to be univariate; when several quantities are to be ...", "dateLastCrawled": "2021-12-12T11:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Mixture Density Networks: Probabilistic Regression for Uncertainty</b> ...", "url": "https://deep-and-shallow.com/2021/03/20/mixture-density-networks-probabilistic-regression-for-uncertainty-estimation/", "isFamilyFriendly": true, "displayUrl": "https://deep-and-shallow.com/2021/03/20/mixture-density-networks-<b>probabilistic</b>...", "snippet": "Now, let\u2019s take a look at the Mixture <b>Model</b>. The Mixture <b>Model</b>, <b>like</b> we discussed before, is a <b>model</b> of probability distributions built up with a <b>weighted</b> sum of more simple distributions. More formally, it models a probability density function(pdf) as a mixture of m pdfs indexed by j, with weights by the following equation:", "dateLastCrawled": "2022-02-02T22:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "13.1 - <b>Weighted Least Squares</b> | STAT 501", "url": "https://online.stat.psu.edu/stat501/lesson/13/13.1", "isFamilyFriendly": true, "displayUrl": "https://online.stat.psu.edu/stat501/lesson/13/13.1", "snippet": "These standard deviations reflect the information in the response Y values (remember these are averages) and so in estimating a <b>regression</b> <b>model</b> we should downweight the obervations with a large standard deviation and upweight the observations with a small standard deviation. In other words we should use <b>weighted least squares</b> with weights equal to \\(1/SD^{2}\\). The resulting fitted equation from Minitab for this <b>model</b> is:", "dateLastCrawled": "2022-02-02T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>regression</b> - <b>Gaussian Processes as weighted averages</b>? - Cross Validated", "url": "https://stats.stackexchange.com/questions/504761/gaussian-processes-as-weighted-averages", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/504761/<b>gaussian-processes-as-weighted-averages</b>", "snippet": "I&#39;ve been wondering if a &quot;<b>weighted</b> <b>average</b>&quot; is a valid means to consider the Gaussian Process, specifically in the context of GP <b>Regression</b>. The kernel (I&#39;ll be referring to the common Radial Basis Function (RBF) Kernel) plays an extremely important role, which determines how similar any pair of $(x_i, x_j)$ are based on their distance from one another.. Background", "dateLastCrawled": "2022-01-21T04:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Weighted Least Squares</b> - McMaster University", "url": "https://ms.mcmaster.ca/canty/teaching/stat3a03/Lectures7.pdf", "isFamilyFriendly": true, "displayUrl": "https://ms.mcmaster.ca/canty/teaching/stat3a03/Lectures7.pdf", "snippet": "To apply <b>weighted least squares</b>, we need to know the weights w1;:::;wn. There are some instances where this is true. We may have a <b>probabilistic</b> <b>model</b> for Var(Y jX= xi) in which case we would use this <b>model</b> to nd the wi. For example, with Poisson data we may use wi= 1=xi if we expect an increasing relationship between Var(Y jX = x) and x. 7-11", "dateLastCrawled": "2022-02-03T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Lecture 2 Recap - Linear <b>Regression</b> | CS181", "url": "https://harvard-ml-courses.github.io/cs181-web/recaps/lec2", "isFamilyFriendly": true, "displayUrl": "https://harvard-ml-courses.github.io/cs181-web/recaps/lec2", "snippet": "A key extension of this is basis <b>regression</b>. Basically, convert an input \\mathbf x to another vector \\phi (\\mathbf x) where \\phi : \\mathbb R^D \\to \\mathbb R^ {D&#39;} is a basis function. Then we use \\phi (\\mathbf x) we perform linear <b>regression</b> in the new input space \\mathbb R^ {D&#39;}. To <b>model</b> a parabolic curve, therefore, we can use the transform ...", "dateLastCrawled": "2022-02-02T20:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Comparing quantile <b>regression</b> methods for <b>probabilistic</b> forecasting of ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8173015/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8173015", "snippet": "By combining a linear <b>model</b> with nonlinear <b>probabilistic</b> modelling of its residuals we obtain optimized versions of the standard models. <b>Probabilistic</b> forecasting with quantile <b>regression</b> The prediction from most <b>regression</b> models is a point estimate of the conditional mean of a dependent variable, or response, given a set of independent variables or predictors.", "dateLastCrawled": "2021-12-22T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Approximating Probabilistic Models as Weighted</b> Finite Automata ...", "url": "https://direct.mit.edu/coli/article/47/2/221/98517/Approximating-Probabilistic-Models-as-Weighted", "isFamilyFriendly": true, "displayUrl": "https://direct.mit.edu/.../47/2/221/98517/<b>Approximating-Probabilistic-Models-as-Weighted</b>", "snippet": "Abstract. <b>Weighted</b> finite automata (WFAs) are often used to represent <b>probabilistic</b> models, such as n-gram language models, because among other things, they are efficient for recognition tasks in time and space. The <b>probabilistic</b> source to be represented as a WFA, however, may come in many forms. Given a generic <b>probabilistic</b> <b>model</b> over sequences, we propose an algorithm to approximate it as a WFA such that the Kullback-Leibler divergence between the source <b>model</b> and the WFA target <b>model</b> is ...", "dateLastCrawled": "2022-02-02T01:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>The probabilistic weighted average and its</b> application in ...", "url": "https://www.academia.edu/12496290/The_probabilistic_weighted_average_and_its_application_in_multiperson_decision_making", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/12496290/<b>The_probabilistic_weighted_average_and_its</b>...", "snippet": "<b>The Probabilistic Weighted Average and Its</b> <b>Application in Multiperson Decision Making</b> Jose\u00b4 M. Merigo\u00b4 \u2217 Department of Business Administration, University of Barcelona, 08034 Barcelona, Spain We present the <b>probabilistic</b> <b>weighted</b> <b>average</b> (PWA). It is an aggregation operator that unifies the probability and the <b>weighted</b> <b>average</b> in the same formulation. Its main advantage is that it provides a formulation that it is able to deal with probabilities and <b>weighted</b> averages in the same ...", "dateLastCrawled": "2022-01-16T02:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Regional <b>Probabilistic</b> Fertility Forecasting by Modeling Between ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4169201/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4169201", "snippet": "The effect of the correlation <b>model</b> on the variance of the regional <b>weighted</b> <b>average</b> TFRs. The ratio of the dependence factor to the independence factor (DF/IF) indicates the multiplicative increase in the variance of the regional TFR when using the correlation <b>model</b> compared to the current <b>model</b> where forecast errors are assumed independent. The \u201cmax proportion\u201d column shows the largest proportion of the current region female population that is attributed to a single country and N is ...", "dateLastCrawled": "2021-12-23T05:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "13.1 - <b>Weighted Least Squares</b> | STAT 501", "url": "https://online.stat.psu.edu/stat501/lesson/13/13.1", "isFamilyFriendly": true, "displayUrl": "https://online.stat.psu.edu/stat501/lesson/13/13.1", "snippet": "These standard deviations reflect the information in the response Y values (remember these are averages) and so in estimating a <b>regression</b> <b>model</b> we should downweight the obervations with a large standard deviation and upweight the observations with a small standard deviation. In other words we should use <b>weighted least squares</b> with weights equal to \\(1/SD^{2}\\). The resulting fitted equation from Minitab for this <b>model</b> is:", "dateLastCrawled": "2022-02-02T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>regression</b> - <b>Gaussian Processes as weighted averages</b>? - Cross Validated", "url": "https://stats.stackexchange.com/questions/504761/gaussian-processes-as-weighted-averages", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/504761/<b>gaussian-processes-as-weighted-averages</b>", "snippet": "I&#39;ve been wondering if a &quot;<b>weighted</b> <b>average</b>&quot; is a valid means to consider the Gaussian Process, specifically in the context of GP <b>Regression</b>. The kernel (I&#39;ll be referring to the common Radial Basis Function (RBF) Kernel) plays an extremely important role, which determines how <b>similar</b> any pair of $(x_i, x_j)$ are based on their distance from one another.. Background", "dateLastCrawled": "2022-01-21T04:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Bonferroni <b>Probabilistic</b> Ordered <b>Weighted</b> Averaging Operators Applied ...", "url": "https://res.mdpi.com/d_attachment/mathematics/mathematics-08-01350/article_deploy/mathematics-08-01350-v2.pdf", "isFamilyFriendly": true, "displayUrl": "https://res.mdpi.com/d_attachment/mathematics/mathematics-08-01350/article_deploy/...", "snippet": "(OWA) operator called the Bonferroni <b>probabilistic</b> ordered <b>weighted</b> <b>average</b> (B-POWA) operator. This operator is designed to unify in a single formulation the interrelation of the values given in a data set by the Bonferroni means and a <b>weighted</b> and <b>probabilistic</b> vector that models the attitudinal character, expectations, and knowledge of the decision-maker of a problem. The paper also studies the main characteristics and some families of the B-POWA operator. An illustrative example is also ...", "dateLastCrawled": "2022-01-31T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The <b>probabilistic weighted average and its</b> application in multiperson ...", "url": "https://www.researchgate.net/publication/263193544_The_probabilistic_weighted_average_and_its_application_in_multiperson_decision_making", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/263193544_The_<b>probabilistic</b>_<b>weighted</b>_<b>average</b>...", "snippet": "Moreover, other authors have developed <b>similar</b> approaches by using the <b>weighted</b> <b>average</b> including the <b>probabilistic</b> <b>weighted</b> <b>average</b> [25], the <b>weighted</b> OWA (WOWA) operator [26], the hybrid <b>average</b> ...", "dateLastCrawled": "2021-12-18T01:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Comparing quantile <b>regression</b> methods for <b>probabilistic</b> forecasting of ...", "url": "https://www.nature.com/articles/s41598-021-90063-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-90063-3", "snippet": "The prediction from most <b>regression</b> models is a point estimate of the conditional mean of a dependent variable, or response, given a set of independent variables or predictors.", "dateLastCrawled": "2022-02-01T02:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Lecture 4: Logistic <b>Regression</b> - Shuai Li", "url": "https://shuaili8.github.io/Teaching/VE445/L4_logistic%20regression.pdf", "isFamilyFriendly": true, "displayUrl": "https://shuaili8.github.io/Teaching/VE445/L4_logistic <b>regression</b>.pdf", "snippet": "\u2022<b>Probabilistic</b>: \u2022Directly <b>model</b> the dependence for label prediction \u2022Easy to define dependence on specific features and models \u2022Practically yielding higher prediction performance \u2022E.g. linear <b>regression</b>, logistic <b>regression</b>, k nearest neighbor, SVMs, (multi-layer) perceptrons, decision trees, random forest 6. Generative Models \u2022Generative models \u2022Modeling the joint <b>probabilistic</b> distribution of data \u2022Given some hidden parameters or variables \u2022Then do the conditional ...", "dateLastCrawled": "2022-02-03T01:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>regression</b> - <b>Gaussian Processes as weighted averages</b>? - Cross Validated", "url": "https://stats.stackexchange.com/questions/504761/gaussian-processes-as-weighted-averages", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/504761/<b>gaussian-processes-as-weighted-averages</b>", "snippet": "$\\begingroup$ @jbuddy_13 I almost always prefer GP <b>regression</b> over NW kernel <b>regression</b>. For example: 1) NW <b>can</b> be badly biased at the edges of the data, where the weight function falls off the end. 2) GP <b>regression</b> is a <b>probabilistic</b> method that gives uncertainty estimates over predictions, whereas NW only gives point estimates.", "dateLastCrawled": "2022-01-21T04:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "NOTES AND CORRESPONDENCE Calibration of <b>Probabilistic</b> Forecasts of ...", "url": "https://empslocal.ex.ac.uk/people/staff/dbs202/publications/2009/primo.pdf", "isFamilyFriendly": true, "displayUrl": "https://empslocal.ex.ac.uk/people/staff/dbs202/publications/2009/primo.pdf", "snippet": "<b>weighted</b> <b>average</b> of the relative frequencies and the prior mean a/(a 1 b) withrelative weights proportional to sample size m and what <b>can</b> <b>be thought</b> of as the \u2018\u2018effective\u2019\u2019 prior sample size (a 1 b). Since the parameters that <b>model</b> our prior belief (a and b) are constants, the beta-binomial approach leads", "dateLastCrawled": "2022-01-31T13:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Bayesian non-parametrics and the <b>probabilistic</b> approach to modelling ...", "url": "https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0553", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0553", "snippet": "A linear <b>regression</b> <b>model</b> that states that the slope <b>can</b> take values between \u22121 and +1 is a very different <b>model</b> from one that specifies that the slope <b>can</b> take values between \u2212100 and +100. In fact, to fully specify a <b>model</b>, we need to do a bit more than specify the range of parameters, we need to define a distribution over this range. Only then will our <b>model</b>", "dateLastCrawled": "2021-12-31T19:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "12 <b>Regression</b>\u2019", "url": "https://www.colorado.edu/amath/sites/default/files/attached-files/ch12_0.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.colorado.edu</b>/amath/sites/default/files/attached-files/ch12_0.pdf", "snippet": "8 ALinear)<b>Probabilistic</b>)<b>Model</b> The)points(x1, y 1),)\u2026,)(x n, y n))resulting)from)n independent) observationswill)then)be)scattered)about)the)true) <b>regression</b>)line: This image cannot currently be displayed.", "dateLastCrawled": "2022-01-30T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Regression</b> \u2013 Yet Another ML Blog \u2013 data science and ML theory", "url": "https://bllguo.github.io/Regression/", "isFamilyFriendly": true, "displayUrl": "https://bllguo.github.io/<b>Regression</b>", "snippet": "<b>Regression</b> \u2013 Yet Another ML Blog \u2013 data science and ML theory. Let\u2019s do a quick review of basic <b>regression</b>, to lay the framework for future posts. The goal of <b>regression</b>, one of the principal problems in supervised learning, is to predict the value (s) of one or more continuous target variables , given a corresponding vector of input ...", "dateLastCrawled": "2022-01-31T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "probability - <b>Model</b> ensembling - averaging of <b>probabilities</b> - Cross ...", "url": "https://stats.stackexchange.com/questions/405712/model-ensembling-averaging-of-probabilities", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/405712", "snippet": "Your question asks about taking averages of multiple <b>probabilistic</b> forecasts to take pooled forecast, so it is closely resorted to linear opinion ... p.20. Somehow, a simple <b>average</b> of multiple models appears to outperform single <b>model</b> forecast and <b>weighted</b> <b>average</b> forecasts in practice. There are many hypotheses of why this happens, but there is no consensus in forecasting literature. This could be because an optimal weight in a <b>weighted</b> <b>average</b> combination has too much noise, so in the end ...", "dateLastCrawled": "2022-01-12T23:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The <b>probabilistic weighted average and its</b> application in multiperson ...", "url": "https://www.researchgate.net/publication/263193544_The_probabilistic_weighted_average_and_its_application_in_multiperson_decision_making", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/263193544_The_<b>probabilistic</b>_<b>weighted</b>_<b>average</b>...", "snippet": "Recently, new concepts about moving <b>average</b> and OWA operators have been introduced, such as moving <b>average</b> with <b>probabilistic</b> <b>weighted</b> <b>average</b> [33], generalized moving <b>average</b>, distance measures ...", "dateLastCrawled": "2021-12-18T01:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Probabilistic Quantitative Precipitation Forecasting Using Bayesian</b> ...", "url": "https://www.stat.washington.edu/raftery/Research/PDF/Sloughter2007.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.stat.washington.edu/raftery/Research/PDF/Sloughter2007.pdf", "snippet": "<b>Probabilistic Quantitative Precipitation Forecasting Using Bayesian</b> <b>Model</b> Averaging ... a <b>weighted</b> <b>average</b> of PDFs centered on the individual bias-corrected forecasts, where the weights are posterior probabilities of the models generating the forecasts and reflect the forecasts\u2019 relative contributions to predictive skill over a training period. It was developed initially for quantities whose PDFs <b>can</b> be approximated by normal distributions, such as temperature and sea level pressure. BMA ...", "dateLastCrawled": "2021-12-27T20:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Football Analysis: Attempt to improve upon the current Expected Goals ...", "url": "https://medium.com/geekculture/football-analysis-attempt-to-improve-upon-the-current-expected-goals-metric-using-probabilistic-7372dbed7649", "isFamilyFriendly": true, "displayUrl": "https://medium.com/geekculture/football-analysis-attempt-to-improve-upon-the-current...", "snippet": "As <b>can</b> be seen in Table 4, the Bayesian Network <b>model</b> works much better than the given data and the logistic <b>regression</b> classifier grossly overestimates the xG. In fact, given the constraints of ...", "dateLastCrawled": "2022-01-13T05:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to understand <b>weight</b> variables in statistical analyses - The DO Loop", "url": "https://blogs.sas.com/content/iml/2017/10/02/weight-variables-in-statistics-sas.html", "isFamilyFriendly": true, "displayUrl": "https://blogs.sas.com/content/iml/2017/10/02/<b>weight</b>-variables-in-statistics-sas.html", "snippet": "You <b>can</b> &quot;manually&quot; reproduce a lot of formulas for <b>weighted</b> multivariate statistics by multiplying each row of the data matrix (and the response vector) by the square root of the appropriate <b>weight</b>. In particular, if you use a <b>weight</b> variable in a <b>regression</b> procedure, you get a <b>weighted</b> <b>regression</b> analysis. For <b>regression</b>, the right side of ...", "dateLastCrawled": "2022-02-02T07:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Comparing quantile <b>regression</b> methods for <b>probabilistic</b> forecasting of ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8173015/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8173015", "snippet": "In this work, we thoroughly <b>compared</b> 10 state of the art quantile <b>regression</b> models, using them to predict the distribution of NO 2 concentrations in a urban location for a set of forecasting horizons (up to 60 hours into the future). Instead of using directly the quantiles, we derived from them the parameters of a predicted distribution, rendering this method semi-parametric. Amongst the models tested, quantile gradient boosted trees show the best performance, yielding the best results for ...", "dateLastCrawled": "2021-12-22T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Approximating Probabilistic Models as Weighted</b> Finite Automata ...", "url": "https://direct.mit.edu/coli/article/47/2/221/98517/Approximating-Probabilistic-Models-as-Weighted", "isFamilyFriendly": true, "displayUrl": "https://direct.mit.edu/.../47/2/221/98517/<b>Approximating-Probabilistic-Models-as-Weighted</b>", "snippet": "Abstract. <b>Weighted</b> finite automata (WFAs) are often used to represent <b>probabilistic</b> models, such as n-gram language models, because among other things, they are efficient for recognition tasks in time and space. The <b>probabilistic</b> source to be represented as a WFA, however, may come in many forms. Given a generic <b>probabilistic</b> <b>model</b> over sequences, we propose an algorithm to approximate it as a WFA such that the Kullback-Leibler divergence between the source <b>model</b> and the WFA target <b>model</b> is ...", "dateLastCrawled": "2022-02-02T01:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Design of <b>Probabilistic</b> Random Forests with Applications to Anticancer ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4820080/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4820080", "snippet": "A <b>weighted</b> random forest (wRF) for <b>regression</b> approach has been proposed, 16 where the weight of each tree has been calculated based on the prediction accuracy of out-of-bag samples for that tree. wRF considers the empirical out-of-bag errors for estimating the <b>regression</b> tree weights, whereas this article considers an analytical approach where parametric distributions are estimated to specify a <b>probabilistic</b> representation of each <b>regression</b> tree and the sample-dependent probability ...", "dateLastCrawled": "2021-12-13T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Weighted probabilistic neural network</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/abs/pii/S0020025517311003", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/abs/pii/S0020025517311003", "snippet": "In this paper, the <b>weighted probabilistic neural network</b> was proposed. The original PNN <b>model</b> was enriched by the weights introduced between pattern and summation layer of the network. The analytical formula for the weighting coefficients was provided with the use of the SA procedure. A 10-fold cross validation accuracy of WPNN was <b>compared</b> with the accuracy of the modified PNN available in literature, the traditional PNN and the state-of-the-art algorithms in ten benchmark data classification", "dateLastCrawled": "2022-01-05T17:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Comparing quantile <b>regression</b> methods for <b>probabilistic</b> forecasting of ...", "url": "https://www.nature.com/articles/s41598-021-90063-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-90063-3", "snippet": "In this work, we thoroughly <b>compared</b> 10 state of the art quantile <b>regression</b> models, using them to predict the distribution of NO2 concentrations in a urban location for a set of forecasting ...", "dateLastCrawled": "2022-02-01T02:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Probabilistic</b> Wavelet\u2013Support Vector <b>Regression</b> <b>Model</b> for Streamflow ...", "url": "https://journals.ametsoc.org/jhm/article-split/16/5/2209/69932/A-Probabilistic-Wavelet-Support-Vector-Regression", "isFamilyFriendly": true, "displayUrl": "https://journals.ametsoc.org/.../69932/A-<b>Probabilistic</b>-Wavelet-Support-Vector-<b>Regression</b>", "snippet": "The forecasting skill of the proposed BWS <b>model</b> is <b>compared</b> with the best single-member WS <b>model</b> and ANFIS. 2. Theoretical background. a. Support vector <b>regression</b> . SVR was proposed by Drucker et al. (1997) and is used to describe <b>regression</b> with SVMs (Vapnik et al. 1997). The idea of SVR is based on the computation of a linear <b>regression</b> function in a high-dimensional feature space, where the input data are mapped via a nonlinear function (Yu et al. 2006; Wei and Roan 2012). Using ...", "dateLastCrawled": "2020-10-24T19:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) A Novel Dynamic-<b>Weighted</b> <b>Probabilistic</b> Support Vector <b>Regression</b> ...", "url": "https://www.researchgate.net/publication/276429128_A_Novel_Dynamic-Weighted_Probabilistic_Support_Vector_Regression-Based_Ensemble_for_Prognostics_of_Time_Series_Data", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/276429128_A_Novel_Dynamic-<b>Weighted</b>...", "snippet": "In this paper, a novel Dynamic-<b>Weighted</b> <b>Probabilistic</b> Support Vector <b>Regression</b>-based Ensemble (DW-PSVR-ensemble) approach is proposed for prognostics of time series data monitored on components ...", "dateLastCrawled": "2022-01-23T11:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>PROBABILISTIC</b> APPROACHES: <b>SCENARIO</b> ANALYSIS, DECISION TREES AND SIMULATIONS", "url": "http://people.stern.nyu.edu/adamodar/pdfiles/papers/probabilistic.pdf", "isFamilyFriendly": true, "displayUrl": "people.stern.nyu.edu/adamodar/pdfiles/papers/<b>probabilistic</b>.pdf", "snippet": "<b>PROBABILISTIC</b> APPROACHES: <b>SCENARIO</b> ANALYSIS, DECISION TREES AND SIMULATIONS In the last chapter, we examined ways in which we <b>can</b> adjust the value of a risky asset for its risk. Notwithstanding their popularity, all of the approaches share a common theme. The riskiness of an asset is encapsulated in one number \u2013 a higher discount rate, lower cash flows or a discount to the value \u2013 and the computation almost always requires us to make assumptions (often unrealistic) about the nature of ...", "dateLastCrawled": "2022-01-28T22:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Comparison of different <b>quantile regression</b> methods to estimate ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/jfr3.12585", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/jfr3.12585", "snippet": "The estimation of predictive uncertainty and its application as a post-processor of hydrological <b>model</b> output, such as water level, <b>can</b> provide additional information useful for short-term hydrological forecasting. In this study, We applied <b>quantile regression</b> models for estimating predictive hydrological uncertainty and used it to derive <b>probabilistic</b> hydrological forecasts. Forecast water levels and associated forecast errors were used as predictor and predictand, respectively, to develop ...", "dateLastCrawled": "2021-07-08T23:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Lecture 4: Logistic <b>Regression</b>", "url": "https://shuaili8.github.io/Teaching/VE445/L4_logistic%20regression.pdf", "isFamilyFriendly": true, "displayUrl": "https://shuaili8.github.io/Teaching/VE445/L4_logistic <b>regression</b>.pdf", "snippet": "\u2022<b>Probabilistic</b>: \u2022Directly <b>model</b> the dependence for label prediction \u2022Easy to define dependence on specific features and models \u2022Practically yielding higher prediction performance \u2022E.g. linear <b>regression</b>, logistic <b>regression</b>, k nearest neighbor, SVMs, (multi-layer) perceptrons, decision trees, random forest 6. Generative Models \u2022Generative models \u2022Modeling the joint <b>probabilistic</b> distribution of data \u2022Given some hidden parameters or variables \u2022Then do the conditional ...", "dateLastCrawled": "2022-02-03T01:44:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b>: The <b>Probabilistic</b> Perspective", "url": "https://kt.era.ee/lectures/ifiss2014/3-statistics.pdf", "isFamilyFriendly": true, "displayUrl": "https://kt.era.ee/lectures/ifiss2014/3-statistics.pdf", "snippet": "Reasoning by <b>analogy</b> Dragons. So far\u2026 <b>Machine</b> <b>learning</b> is important and interesting The general concept: IFI Summer School. June 2014 Fitting models to data. So far\u2026 <b>Machine</b> <b>learning</b> is important and interesting The general concept: IFI Summer School. June 2014 Fitting models to data Optimization Probability Theory. So far\u2026 Instance-based methods Tree <b>learning</b> methods The \u201csoul\u201d of <b>machine</b> <b>learning</b>: Particular models: OLS <b>regression</b> (\u21132-loss, 0-penalty <b>regression</b>) Ridge ...", "dateLastCrawled": "2021-09-03T03:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Classification of Machine Learning Models</b>", "url": "https://www.enjoyalgorithms.com/blog/classification-of-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://www.enjoyalgorithms.com/blog/<b>classification-of-machine-learning-models</b>", "snippet": "<b>Regression</b> Problem:-<b>Regression</b> is a problem that requires <b>machine</b> <b>learning</b> algorithms that learn to predict continuous variables. An elementary example will be to predict the temperature of the city. (Temperature can take any numeric value between -50 to +50 degrees Celsius.) Clustering Problem:-Clustering is a type of problem that requires the use of <b>Machine</b> <b>Learning</b> algorithms to group the given data samples into a specified number of groups. A simple example will be to group the lemons ...", "dateLastCrawled": "2022-02-03T15:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Deep Probabilistic Decision Machines for Building</b> a Causally Generative ...", "url": "https://medium.com/noodle-labs-the-future-of-ai/deep-probabilistic-decision-machines-for-building-a-causally-generative-process-model-based-action-3f65552409b8", "isFamilyFriendly": true, "displayUrl": "https://medium.com/noodle-labs-the-future-of-ai/<b>deep-probabilistic-decision-machines</b>...", "snippet": "Our favorite <b>analogy</b> for the need of deep <b>probabilistic</b> models combining deep <b>learning</b> (implicit, scalable, associative, deterministic, experience data-driven) and Bayesian <b>probabilistic</b> <b>learning</b> ...", "dateLastCrawled": "2021-10-16T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "CASE-BASED REASONING FOR EXPLAINING <b>PROBABILISTIC</b> <b>MACHINE</b> <b>LEARNING</b>", "url": "http://www.diva-portal.org/smash/get/diva2:1043422/FULLTEXT01.pdf", "isFamilyFriendly": true, "displayUrl": "www.diva-portal.org/smash/get/diva2:1043422/FULLTEXT01.pdf", "snippet": "For instance, a <b>probabilistic</b> <b>machine</b> <b>learning</b> <b>model</b> can be hard to understand for non-experts while CBR is conceptually much more intuitive and easy to explain. Therefore, by complementing a <b>probabilistic</b> <b>model</b> with a CBR-based explanation facility, we can make the system more understandable. Explanation using preceding cases has some advantages compared to other approaches. For instance, it has been shown in a user experiment that users in some domains prefer case-based over rule-based ...", "dateLastCrawled": "2022-01-30T01:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> Concepts for Revision | by Raunak Sarada | Medium", "url": "https://raunaksarada-cse21.medium.com/machine-learning-concepts-for-revision-491384952d27", "isFamilyFriendly": true, "displayUrl": "https://raunaksarada-cse21.medium.com/<b>machine</b>-<b>learning</b>-concepts-for-revision-491384952d27", "snippet": "ML Concepts. A.I \u2014 Intelligence showed by machines which is common for humans <b>Machine</b> <b>Learning</b>- Recognize the pattern in data and automatically learn and improve through experience without explicitly being programmed Deep <b>Learning</b>- branch of <b>machine</b> <b>learning</b>.We have to deal with lots of data so in that case problems can\u2019t be solved with simple ML algorithms.", "dateLastCrawled": "2022-01-25T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Modern <b>Machine Learning</b> Algorithms: Strengths and Weaknesses", "url": "https://elitedatascience.com/machine-learning-algorithms", "isFamilyFriendly": true, "displayUrl": "https://elitedatascience.com/mac", "snippet": "2.1. (Regularized) Logistic <b>Regression</b>. Logistic <b>regression</b> is the classification counterpart to linear <b>regression</b>. Predictions are mapped to be between 0 and 1 through the logistic function, which means that predictions can be interpreted as class probabilities.. The models themselves are still &quot;linear,&quot; so they work well when your classes are linearly separable (i.e. they can be separated by a single decision surface). Logistic <b>regression</b> can also be regularized by penalizing coefficients ...", "dateLastCrawled": "2022-02-03T00:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Probabilistic</b> Flight Delay Predictions Using <b>Machine</b> <b>Learning</b> and ...", "url": "https://www.researchgate.net/publication/351962528_Probabilistic_Flight_Delay_Predictions_Using_Machine_Learning_and_Applications_to_the_Flight-to-Gate_Assignment_Problem", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/351962528_<b>Probabilistic</b>_Flight_Delay...", "snippet": "operation using <b>machine</b> <b>learning</b> algorithms that perform <b>regression</b>. The authors consider The authors consider delay states of the aviation network as features, in addition to \ufb02ight schedule-related", "dateLastCrawled": "2022-02-01T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Regression</b> and Concept <b>Learning</b>", "url": "https://portals.au.edu.pk/imc/Content/course/lecs/Lecture-3%20(Regression_and_Concept_Learning).pdf", "isFamilyFriendly": true, "displayUrl": "https://portals.au.edu.pk/imc/Content/course/lecs/Lecture-3 (<b>Regression</b>_and_Concept...", "snippet": "linear <b>regression</b> or logistic <b>regression</b> where the calculating of <b>model</b> complexity penalty is known and tractable. e.g., Bayesian Information Criterion (BIC) and Structural Risk Minimization", "dateLastCrawled": "2022-01-22T11:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Introduction to Machine Learning</b> - UH", "url": "http://www2.cs.uh.edu/~ceick/ML/ML-Topic1A.ppt", "isFamilyFriendly": true, "displayUrl": "www2.cs.uh.edu/~ceick/ML/ML-Topic1A.ppt", "snippet": "Role of Statistics: Inference from a sample Role of Computer science: Efficient algorithms to Solve the optimization problem Representing and evaluating the <b>model</b> for inference Growth of <b>Machine</b> <b>Learning</b> <b>Machine</b> <b>learning</b> is preferred approach to Speech recognition, Natural language processing Computer vision Medical outcomes analysis Robot control Computational biology This trend is accelerating Improved <b>machine</b> <b>learning</b> algorithms Improved data capture, networking, faster computers Software ...", "dateLastCrawled": "2022-02-02T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Dealing with <b>Categorical Data</b>. For <b>Machine</b> <b>Learning</b> - Multi-target ...", "url": "https://medium.com/analytics-vidhya/dealing-with-categorical-data-942a8c8fdbad", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/dealing-with-<b>categorical-data</b>-942a8c8fdbad", "snippet": "\u201clogistic <b>regression</b> is for classification \u2014 and the problem we are dealing with is classification \u2014 logistic <b>regression</b> is the most simple linear <b>model</b> for classification\u201d \u2014 Dave 24 24", "dateLastCrawled": "2022-02-02T17:53:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(probabilistic regression model)  is like +(weighted average)", "+(probabilistic regression model) is similar to +(weighted average)", "+(probabilistic regression model) can be thought of as +(weighted average)", "+(probabilistic regression model) can be compared to +(weighted average)", "machine learning +(probabilistic regression model AND analogy)", "machine learning +(\"probabilistic regression model is like\")", "machine learning +(\"probabilistic regression model is similar\")", "machine learning +(\"just as probabilistic regression model\")", "machine learning +(\"probabilistic regression model can be thought of as\")", "machine learning +(\"probabilistic regression model can be compared to\")"]}