{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b> Silhouette Analysis: Towards Assessing the Quality of <b>Bias</b> Metrics ...", "url": "https://www.ijcai.org/proceedings/2021/0077.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/proceedings/2021/0077.pdf", "snippet": "dings are used in real-world applications <b>like</b> creditworthiness assessment or crime prediction [Dev and Phillips, 2019]. To quantify the biases in pretrained models, different metrics have been proposed, such as the Embedding Coherence Test (ECT) [Dev and Phillips, 2019], the Relative Negative Sen-timent <b>Bias</b> (RNSB) [Sweeney and Naja\ufb01an, 2019], and the Word Embedding Association Test (WEAT) [Caliskan et al., 2017]. To the best of our knowledge, all such <b>bias</b> metrics follow the general ...", "dateLastCrawled": "2022-02-03T04:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Is KNN affected by change in <b>bias</b> for some <b>distance</b> <b>metric</b>?", "url": "https://math.stackexchange.com/questions/4353375/is-knn-affected-by-change-in-bias-for-some-distance-metric", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/4353375/is-knn-affected-by-change-in-<b>bias</b>-for...", "snippet": "Is there a <b>distance</b> <b>metric</b> for which KNN is affected such it may change predictions due to a change in <b>bias</b>? So this KNN will give one answer if you added <b>bias</b> to your input vectors and another answer if you did not.", "dateLastCrawled": "2022-01-10T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Refactor <b>bias</b> metrics \u00b7 Issue #30 \u00b7 synthesized-io/fairlens \u00b7 GitHub", "url": "https://github.com/synthesized-io/fairlens/issues/30", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/synthesized-io/fairlens/issues/30", "snippet": "This way we can avoid storing actual data in the metrics and we can replace kwargs with explicit keyword arguments in any <b>metric</b>&#39;s __init__.. Looks nice. Perhaps since some metrics require the target <b>metric</b> as well (Jensen-Shannon Divergence), we could have two separate classes or some kind of inheritance that would involve having an extra parameter in call in one subclass.. ie.", "dateLastCrawled": "2022-01-29T04:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Self-selection <b>bias</b> of similarity metrics in <b>translation</b> memory ...", "url": "https://link.springer.com/article/10.1007%2Fs10590-016-9185-8", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10590-016-9185-8", "snippet": "This <b>metric</b> is based on possibly the best known string <b>distance</b> function, usually called the Levenshtein <b>distance</b> (Levenshtein 1966). The Levenshtein <b>distance</b> is the number of insertions, deletions and substitutions required to transform the one string into the other. It is also called \u201c4-operation edit <b>distance</b>\u201d with the understanding that the fourth operation is the identity operation (no change).", "dateLastCrawled": "2021-11-22T04:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>BIAS</b> REDUCTION USING MAHALANOBIS <b>METRIC</b> MATCHING", "url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.2333-8504.1978.tb01164.x", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.2333-8504.1978.tb01164.x", "snippet": "<b>Bias</b> Reduction Using Mahalanobis <b>Metric</b> Matching 1. Introduction Matched sampling refers to the selection of treatment units (e.g., smokers) and control units (e.g., nonsmokers) with similar values of matching variables X (e.g., age, sex, family medical history). Rubin (1976a,b) presents analytical work on a class of matching methods with multivariate X called &quot;<b>Equal percent bias reducing&quot; (EPBR</b>) because they yield the same percent reduction in expected <b>bias</b> for each matching variable and ...", "dateLastCrawled": "2022-01-20T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Simple mathematical derivation of <b>bias</b>-variance error | by Damian Ejlli ...", "url": "https://towardsdatascience.com/simple-mathematical-derivation-of-bias-variance-error-4ab223f28791", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/simple-mathematical-derivation-of-<b>bias</b>-variance-error-4...", "snippet": "2. Notations and definitions. Let me start first by introducing some notations that will be useful in what follows. Here, X is the dependent variable or predictor or feature matrix and y is the independent or output variable vector. Other important notations are the dataset, D=(X, y), and the model function f(X; \u03b8) where \u03b8 is the parameter vector of our selected model.For example, in the simple linear regression where we try to fit a linear function, the model parameters can be the ...", "dateLastCrawled": "2022-02-02T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Unbiased <b>Metric</b> Learning: On the Utilization of Multiple Datasets and ...", "url": "https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Fang_Unbiased_Metric_Learning_2013_ICCV_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Fang_Un<b>bias</b>ed_<b>Metric</b>...", "snippet": "Unbiased <b>Metric</b> Learning: On the Utilization of Multiple Datasets and Web Images for Softening <b>Bias</b> Chen Fang Ye Xu Daniel N. Rockmore Computer Science Department Dartmouth College Hanover, NH 03755, U.S.A. {chenfang, ye, rockmore}@cs.dartmouth.edu Abstract Many standard computer vision datasets exhibit biases due to a variety of sources including illumination condi-tion, imaging system, and preference of dataset collectors. Biases <b>like</b> these can have downstream effects in the use of vision ...", "dateLastCrawled": "2022-02-03T14:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Reducing Noise Pixels and <b>Metric</b> <b>Bias</b> in Semantic Inpainting on ...", "url": "https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/He_Reducing_Noise_Pixels_and_Metric_Bias_in_Semantic_Inpainting_on_ICCVW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/He_Reducing_Noise_Pixels...", "snippet": "from the ground truths, the <b>metric</b> <b>bias</b> should be reduced. We first analyze the appearances of latent ground truths to reduce the <b>metric</b> <b>bias</b>. The appearances should have tar-get objects with the same semantics as the ground truths, due to the task requirement of SISM. Since having the same semantics is the key factor of latent ground truths, we pro-pose a new <b>metric</b>, Semantic Similarity (Sem), to quan-tify semantic divergence between the generated and ground-truth target objects by a ...", "dateLastCrawled": "2022-02-02T00:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Different Types of <b>Distance</b> Metrics used in Machine Learning | by Kunal ...", "url": "https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@kunal_gohrani/different-types-of-<b>distance</b>-<b>metrics</b>-used-in-machine...", "snippet": "We use Manhattan <b>distance</b>, also known as city block <b>distance</b>, or taxicab geometry if we need to calculate the <b>distance</b> between two data points in a grid-<b>like</b> path. Manhattan <b>distance</b> <b>metric</b> can be ...", "dateLastCrawled": "2022-01-30T04:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Guide to AI Fairness 360: An <b>Open Source Toolkit for Detection</b> And ...", "url": "https://analyticsindiamag.com/guide-to-ai-fairness-360-an-open-source-toolkit-for-detection-and-mitigation-of-bias-in-ml-models/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/guide-to-ai-fairness-360-an-open-source-toolkit-for...", "snippet": "It is the first system to bring together <b>bias</b> metrics, <b>bias</b> mitigation algorithms, <b>bias</b> <b>metric</b> explanation and industrial usability under one toolkit. The goal is to provide a comprehensive study of fairness <b>metric</b> and mitigation algorithms which helps the industry to make an ideal AI system. AIF360 is an open-source library containing algorithms for each and every step involved in the AI lifecycle. The package for this toolkit is available in both Python and R. This toolkit provides:", "dateLastCrawled": "2022-02-01T20:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) A <b>distance</b>-based sample selection <b>bias</b> <b>metric</b>", "url": "https://www.researchgate.net/publication/329538893_A_distance-based_sample_selection_bias_metric", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../329538893_A_<b>distance</b>-based_sample_selection_<b>bias</b>_<b>metric</b>", "snippet": "5.1 Comparing the <b>bias</b> <b>distance</b> <b>metric</b> to Pearson\u2019s \u03c7 2 test. F or the purp ose of the \ufb01rst part, consider the AGE v ariable in the dataset - a histogram plot, where the data range is split ...", "dateLastCrawled": "2022-01-03T12:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Self-selection <b>bias</b> of similarity metrics in <b>translation</b> memory ...", "url": "https://link.springer.com/article/10.1007%2Fs10590-016-9185-8", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10590-016-9185-8", "snippet": "This <b>metric</b> is based on possibly the best known string <b>distance</b> function, usually called the Levenshtein <b>distance</b> (Levenshtein 1966). The Levenshtein <b>distance</b> is the number of insertions, deletions and substitutions required to transform the one string into the other. It is also called \u201c4-operation edit <b>distance</b>\u201d with the understanding that the fourth operation is the identity operation (no change).", "dateLastCrawled": "2021-11-22T04:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Bias</b> Silhouette Analysis: Towards Assessing the Quality of <b>Bias</b> Metrics ...", "url": "https://www.ijcai.org/proceedings/2021/0077.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/proceedings/2021/0077.pdf", "snippet": "embedding models show the values of a <b>bias</b> <b>metric</b> on several subsets of size k of the used word lists. Their area re\ufb02ects the robustness of the lists, the area between them accuracy of the <b>metric</b> with the lists. To this end, we present <b>Bias</b> Silhouette Analysis (BSA), a method to assess the quality of any combination of <b>bias</b> <b>met-ric</b> and word lists in terms of their accuracy and robustness. The core idea of BSA is to quantify how much the <b>bias</b> val-ues of a <b>metric</b> vary depending on what words ...", "dateLastCrawled": "2022-02-03T04:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Distance</b>-Based <b>Bias</b> in Model-Directed Optimization of Additively ...", "url": "https://www.researchgate.net/publication/51988704_Distance-Based_Bias_in_Model-Directed_Optimization_of_AdditivelyDecomposable_Problems", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/51988704_<b>Distance</b>-Based_<b>Bias</b>_in_Model...", "snippet": "While the <b>distance</b> <b>metric</b> is strongly related to the problem being solved, the aforementioned study [12] described a rather general <b>metric</b> that can be applied to practically any problem with the ...", "dateLastCrawled": "2021-11-21T12:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Building Blocks of Spatial Analysis &gt; <b>Distance</b> Operations &gt; <b>Metrics</b>", "url": "https://www.spatialanalysisonline.com/HTML/metrics.htm", "isFamilyFriendly": true, "displayUrl": "https://www.spatialanalysisonline.com/HTML/<b>metrics</b>.htm", "snippet": "<b>Similar</b> <b>bias</b> exists if other variants of the L p <b>metric</b> family are plotted. This highlights the fact that a <b>distance</b> value obtained by measurement and application of any of these modified formulas will change if the reference frame is rotated. If this seems a bit obscure, imagine measuring the <b>distance</b> between two points randomly located on a ...", "dateLastCrawled": "2022-01-29T14:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "4.1 Clustering: Grouping samples based on their <b>similarity</b> ...", "url": "https://compgenomr.github.io/book/clustering-grouping-samples-based-on-their-similarity.html", "isFamilyFriendly": true, "displayUrl": "https://compgenomr.github.io/book/clustering-grouping-samples-based-on-their...", "snippet": "We need to define a <b>distance</b> or <b>similarity</b> <b>metric</b> between patients\u2019 expression profiles and use that <b>metric</b> to find groups of patients that are more <b>similar</b> to each other than the rest of the patients. This, in essence, is the general idea behind clustering. We need a <b>distance</b> <b>metric</b> and a method to utilize that <b>distance</b> <b>metric</b> to find self-<b>similar</b> groups. Clustering is a ubiquitous procedure in bioinformatics as well as any field that deals with high-dimensional data. It is very likely ...", "dateLastCrawled": "2022-02-02T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>METRIC LEARNING FOR HYPERSPECTRAL IMAGE SEGMENTATION</b>", "url": "https://ml.jpl.nasa.gov/papers/thompson/2011_WHISPERS_ML.pdf", "isFamilyFriendly": true, "displayUrl": "https://ml.jpl.nasa.gov/papers/thompson/2011_WHISPERS_ML.pdf", "snippet": "For a given <b>distance</b> <b>metric</b>, the internal <b>bias</b> k (Equation 3) alters the size \u2013 and subsequently the quantity \u2013 of the resulting superpixels. To acheive this balance, we segment each image using a range of k values in [10\u22123,101] and provide overall statistics for each algorithm on that range. We chose this range be-cause the number of superpixels produced by each <b>metric</b> followed a <b>similar</b> trend for all of the images we studied. Also, we focus on segmentations that produce 200-1250 ...", "dateLastCrawled": "2021-09-15T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>BIAS</b> REDUCTION USING MAHALANOBIS <b>METRIC</b> MATCHING", "url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.2333-8504.1978.tb01164.x", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.2333-8504.1978.tb01164.x", "snippet": "matching variables more <b>similar</b> in matched samples than in random samples. <b>Bias</b> Reduction Using Mahalanobis <b>Metric</b> Matching 1. Introduction Matched sampling refers to the selection of treatment units (e.g., smokers) and control units (e.g., nonsmokers) with <b>similar</b> values of matching variables X (e.g., age, sex, family medical history). Rubin (1976a,b) presents analytical work on a class of matching methods with multivariate X called &quot;<b>Equal percent bias reducing&quot; (EPBR</b>) because they yield ...", "dateLastCrawled": "2022-01-20T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Bias</b> Reduction Using Mahalanobis-<b>Metric</b> Matching", "url": "https://www.jstor.org/stable/2529981", "isFamilyFriendly": true, "displayUrl": "https://www.jstor.org/stable/2529981", "snippet": "<b>Bias</b> Reduction Using Mahalanobis-<b>Metric</b> Matching Donald B. Rubir Educational Testing Service, Princeton, New Jersey 08541, U.S.A. SUMMARY Monte Carlo methods are used to study the ability of nearest-available, Mahalanobis-<b>metric</b> matching to make the means of matching variables more <b>similar</b> in matched samples than in random samples. 1. Introduction Matched sampling is a method for selecting treatment units (e.g. smokers) and control units (e.g. nonsmokers) with <b>similar</b> values of matching ...", "dateLastCrawled": "2022-01-20T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What <b>distance</b> <b>metric</b> should I use for the kNN classifier when dealing ...", "url": "https://www.quora.com/What-distance-metric-should-I-use-for-the-kNN-classifier-when-dealing-with-categorical-data-such-as-color-and-shape", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-<b>distance</b>-<b>metric</b>-should-I-use-for-the-kNN-classifier-when...", "snippet": "Answer (1 of 5): You could use a very simple <b>metric</b>: 1 if the colors are different, 0 otherwise. Without further information, that is the typical <b>metric</b> used. Alternatively, with domain knowledge you could devise a better <b>metric</b> if one is applicable (for example, red <b>is similar</b> to orange, but bo...", "dateLastCrawled": "2022-01-15T00:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "Common types of <b>bias</b> encountered in the recommender system domain are popularity <b>bias</b> (Abdollahpouri, Mansoury et al., 2019, Jannach et al., 2015), demographic <b>bias</b> (Drozdowski et al., 2020), observation <b>bias</b> (Yao &amp; Huang, 2017), sparsity <b>bias</b> (Bellog\u00edn, Castells, &amp; Cantador, 2017), inductive <b>bias</b>, selection <b>bias</b>, conformity <b>bias</b>, exposure <b>bias</b> and position <b>bias</b> (Chen et al., 2020). Mitigating <b>bias</b> in recommender systems <b>can</b> improve system usability and user satisfaction. For example ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>BIAS</b> REDUCTION USING MAHALANOBIS <b>METRIC</b> MATCHING", "url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.2333-8504.1978.tb01164.x", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.2333-8504.1978.tb01164.x", "snippet": "the values of ~ for units from G1 and GZ&#39; the <b>distance</b> between the units is ~2)Twhere S = [(N - 1) \u00a71 + (rN - l)~2]/(N + rN - 2), \u00a7i the sample covariance of X in G i, i = 1 , 2. Let ~2* be the expected value of ~ in the matched GZ sample. If the matching is EPBR~ then (~1- ~2) = k(~l- ~2*)~ where e = 100(1-k) is the percent reduction in expected <b>bias</b>. When the matching is EPBR~ e is an obvious measure of how much closer the distributions of X are in the;natched samples than the random ...", "dateLastCrawled": "2022-01-20T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Measuring Social <b>Bias</b> in Knowledge Graph Embeddings | DeepAI", "url": "https://deepai.org/publication/measuring-social-bias-in-knowledge-graph-embeddings", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/measuring-social-<b>bias</b>-in-knowledge-graph-embeddings", "snippet": "<b>Bias</b> <b>can</b> <b>be thought</b> of as \u201cprejudice in favor or against a person, group, or thing that is considered to be unfair\u201d Jones ... Sun et al. etc., the <b>distance</b> <b>metric</b> becomes increasingly less applicable, as associations in the <b>distance</b> space become less and less correlated with associations in the score function space. 2.4 Score based <b>metric</b>. In light of this, we present an alternative <b>metric</b> based on the score function. We define the sensitive attribute we are interested in, denoted S, and ...", "dateLastCrawled": "2022-01-27T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>MCQ-KNN - KNN QuiZ</b> - Bsc (computer science) - ELEC61 - SPPU - StuDocu", "url": "https://www.studocu.com/in/document/savitribai-phule-pune-university/bsc-computer-science/mcq-knn-knn-quiz/11200178", "isFamilyFriendly": true, "displayUrl": "https://www.studocu.com/in/document/savitribai-phule-pune-university/bsc-computer...", "snippet": "All of these <b>distance</b> <b>metric</b> <b>can</b> be used as a <b>distance</b> <b>metric</b> for k-NN. 4) Which of the following option is true about k-NN algorithm? A) It <b>can</b> be used for classification B) It <b>can</b> be used for regression C) It <b>can</b> be used in both classification and regression. Solution: C. We <b>can</b> also use k-NN for regression problems. In this case the ...", "dateLastCrawled": "2022-02-02T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "3 Evaluation Metrics for Regression | by Rebecca Vickery | Jan, 2022 ...", "url": "https://towardsdatascience.com/3-evaluation-metrics-for-regression-80cb34cee0e8", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/3-evaluation-<b>metrics</b>-for-regression-80cb34cee0e8", "snippet": "The <b>metric</b> that you choose will depend on the data used to train the model and the way in which the model will be used. Taking into consideration risks around <b>bias</b>, size of errors and the impact these could have when the model is used in practice. In most cases, several metrics are often used to evaluate overall performance and typically comparisons against a benchmark are most useful.", "dateLastCrawled": "2022-02-02T18:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Measuring <b>Bias</b> with Wasserstein <b>Distance</b>", "url": "https://kweku.me/wdcs_camera.pdf", "isFamilyFriendly": true, "displayUrl": "https://kweku.me/wdcs_camera.pdf", "snippet": "the Wasserstein <b>distance</b> <b>can</b> provide a more comprehensive fairness measurement than existing methods, and <b>can</b> also measure fairness with respect to a broad class of fairness notions that <b>can</b> encapsulate the already existing fairness de\ufb01nitions. 1 Introduction Paralleling the ongoing research centered on discrimination in machine learning [3, 6], is a series of critiques discussing how fair machine learning research has the potential to reinforce normative and potentially harmful ideas of ...", "dateLastCrawled": "2021-05-22T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Metrics for evaluating 3D medical image segmentation: analysis ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4533825/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4533825", "snippet": "Some metrics use parameters like the quantile value of the Hausdorff <b>distance</b>; these parameters <b>can</b> be optionally written following the <b>metric</b> symbol after an @, e.g. -use HD@0.9 instructs the tool to calculate the Hausdorff <b>distance</b> at 0.9 quantile. More options are described by typing EvaluateSegmentation at the command line.", "dateLastCrawled": "2022-01-26T21:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is MDS? MDS with other distances , Field of usage of ...", "url": "https://towardsdatascience.com/multidimensional-scaling-mds-for-dimensionality-reduction-and-data-visualization-d5252c8bc4c0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/multidimensional-scaling-mds-for-dimensionality...", "snippet": "Minimizing the linear <b>distance</b> using Euclidean <b>Distance</b> is similar to maximizing the linear correlations. Therefore, it <b>can</b> be said that the 2D graphics of the PCA and MDS applied dataset would have similar characteristics. Of course, this only applies to the use of MDS with Euclidean <b>distance</b>. In addition, different <b>distance</b> methods <b>can</b> be applied according to the project. (For example, Euclidean <b>distance</b> <b>can</b> be weak for large datasets.) PCA has been applied to the above dataset in the code ...", "dateLastCrawled": "2022-02-02T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Measuring social <b>bias</b> in knowledge graph embeddings", "url": "https://assets.amazon.science/96/d6/d6555711405cbc1463360700dad4/measuring-social-bias-in-knowledge-graph-embeddings.pdf", "isFamilyFriendly": true, "displayUrl": "https://assets.amazon.science/96/d6/d6555711405cbc1463360700dad4/measuring-social-<b>bias</b>...", "snippet": "<b>metric</b> suitable for measuring such <b>bias</b>. We conduct experiments on Wikidata and Free-base, and show that, as with word embed-dings, harmful social biases related to profes- sions are encoded in knowledge graph embed-dings with respect to gender, religion, ethnic-ity and nationality. For example, knowledge graph embeddings encode the information that men are more likely to be bankers, and women more likely to be homekeepers. As knowl-edge graph embeddings become increasingly utilized, we ...", "dateLastCrawled": "2022-01-26T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Deep Metric Learning</b>: a (Long) Survey \u2013 Chan Kha Vu", "url": "https://hav4ik.github.io/articles/deep-metric-learning-survey", "isFamilyFriendly": true, "displayUrl": "https://hav4ik.github.io/articles/<b>deep-metric-learning</b>-survey", "snippet": "State-of-the-Art Approaches. The success of SphereFace resulted in an avalanche of new methods that are based on the idea of employing angular <b>distance</b> with angular margin.. Please note that these methods are only applicable to Supervised <b>Deep Metric Learning</b> setting. In an Unsupervised setting, or in case when we have a lot of out-of-distribution samples during test time, Contrastive Learning approaches are still amongst the most decent choices.", "dateLastCrawled": "2022-01-29T16:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Is KNN affected by change in <b>bias</b> for some <b>distance</b> <b>metric</b>?", "url": "https://math.stackexchange.com/questions/4353375/is-knn-affected-by-change-in-bias-for-some-distance-metric", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/4353375/is-knn-affected-by-change-in-<b>bias</b>-for...", "snippet": "Is there a <b>distance</b> <b>metric</b> for which KNN is affected such it may change predictions due to a change in <b>bias</b>? So this KNN will give one answer if you added <b>bias</b> to your input vectors and another answer if you did not.", "dateLastCrawled": "2022-01-10T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) A <b>distance</b>-based sample selection <b>bias</b> <b>metric</b>", "url": "https://www.researchgate.net/publication/329538893_A_distance-based_sample_selection_bias_metric", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../329538893_A_<b>distance</b>-based_sample_selection_<b>bias</b>_<b>metric</b>", "snippet": "5.1 Comparing the <b>bias</b> <b>distance</b> <b>metric</b> to Pearson\u2019s \u03c7 2 test. F or the purp ose of the \ufb01rst part, consider the AGE v ariable in the dataset - a histogram plot, where the data range is split ...", "dateLastCrawled": "2022-01-03T12:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>A Preliminary Study of Spatial Bias</b> in Knn <b>Distance</b> Metrics", "url": "http://ozark.hendrix.edu/~ferrer/research/papers/flairs-2020.pdf", "isFamilyFriendly": true, "displayUrl": "ozark.hendrix.edu/~ferrer/research/papers/flairs-2020.pdf", "snippet": "One <b>distance</b> <b>metric</b> is inspired by the convolutional kernels employed in convolutional neural networks. The other metrics are based on BRIEF descriptors, which generate bit vectors correspond- ing to images based on comparisons of pixel intensity values. We found that the convolutional <b>distance</b> <b>metric</b> exhibited a strong positive spatial <b>bias</b>, as did one of the BRIEF descrip-tors. Another BRIEF descriptor exhibited a negative spatial <b>bias</b>, and the remainder exhibited little or no spatial <b>bias</b> ...", "dateLastCrawled": "2021-09-16T07:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Time versus Space: Choice of Effort <b>Metric</b> <b>Can</b> Avoid <b>Bias</b> in Boat ...", "url": "https://afspubs.onlinelibrary.wiley.com/doi/abs/10.1002/nafm.10351", "isFamilyFriendly": true, "displayUrl": "https://afspubs.onlinelibrary.wiley.com/doi/abs/10.1002/nafm.10351", "snippet": "Boat electrofishing guidelines refer to both time- and <b>distance</b>-based metrics, with little consensus about the appropriateness of one over the other. Catch rate metrics that use time-based effort may potentially be biased by gear saturation due to handling time. We evaluated the potential for <b>bias</b> resulting from effort <b>metric</b> choice by comparing catch rates based on one temporal and two spatial effort metrics\u2014time, shoreline length, and a GPS-based areal measurement\u2014using 3 years of data ...", "dateLastCrawled": "2022-01-10T05:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Regularized variational data assimilation for <b>bias</b> treatment using the ...", "url": "https://ui.adsabs.harvard.edu/abs/2020QJRMS.146.2332T/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2020QJRMS.146.2332T/abstract", "snippet": "This paper presents a new variational data assimilation (VDA) approach for the formal treatment of <b>bias</b> in both model outputs and observations. This approach relies on the Wasserstein <b>metric</b> stemming from the theory of optimal mass transport to penalize the <b>distance</b> between the probability histograms of the analysis state and an a priori reference dataset, which is likely to be more uncertain but less biased than both model and observations. Unlike previous <b>bias</b>-aware VDA approaches, the new ...", "dateLastCrawled": "2021-08-14T22:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Regularized Variational Data Assimilation for <b>Bias</b> Treatment ...", "url": "https://www.researchgate.net/publication/339737490_Regularized_Variational_Data_Assimilation_for_Bias_Treatment_using_the_Wasserstein_Metric", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339737490_Regularized_Variational_Data...", "snippet": "Speci\ufb01cally, this <b>distance</b> <b>metric</b> <b>can</b> quantify the dissimilarity between. 5. two probability histograms in terms of the amount of \u201cwork\u201d done during displacement of proba- bility masses ...", "dateLastCrawled": "2022-01-25T10:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "An Adaptive <b>Metric</b> Machine for Pattern Classification", "url": "https://proceedings.neurips.cc/paper/1875-an-adaptive-metric-machine-for-pattern-classification.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/1875-an-adaptive-<b>metric</b>-machine-for-pattern...", "snippet": "Severe <b>bias</b> <b>can</b> be introduced under these conditions when using the nearest neighbor rule. We propose a locally adaptive nearest neighbor classification method to try to minimize <b>bias</b>. We use a Chi-squared <b>distance</b> analysis to compute a flexible <b>metric</b> for pro\u00ad ducing neighborhoods that are elongated along less relevant feature dimensions and constricted along most influential ones. As a result, the class conditional probabilities tend to be smoother in the mod\u00ad ified neighborhoods ...", "dateLastCrawled": "2021-09-28T06:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "BoostML: An Adaptive <b>Metric</b> Learning for Nearest Neighbor Classi cation", "url": "https://users.monash.edu.au/~nzaidi/papers/paper6fb.pdf", "isFamilyFriendly": true, "displayUrl": "https://users.monash.edu.au/~nzaidi/papers/paper6fb.pdf", "snippet": "a <b>distance</b> <b>metric</b> using a feature relevance measure inspired by boost-ing. The modi ed <b>metric</b> results in a smooth neighborhood that leads to better classi cation results. We tested our technique on major UCI machine learning databases and <b>compared</b> the results to state of the art techniques. Our method resulted in signi cant improvements in the per-formance of the K-NN classi er and also performed better than other techniques on major databases. Key words: Adaptive <b>Metric</b> Learning, Nearest ...", "dateLastCrawled": "2021-09-13T10:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Symmetric <b>Metric</b> Learning with Adaptive Margin for Recommendation", "url": "https://ojs.aaai.org/index.php/AAAI/article/download/5894/5750", "isFamilyFriendly": true, "displayUrl": "https://ojs.aaai.org/index.php/AAAI/article/download/5894/5750", "snippet": "work. <b>Compared</b> with pure <b>metric</b> learning (CML), the la-tent relational <b>metric</b> learning methods improve the <b>distance</b> <b>metric</b> of user-item. Nevertheless, they still adopt the triple loss paradigm to measure the relative <b>distance</b> for a given triple (u,v,v\u2212), facing the similar limitations mentioned in the previous section. Proposed Method", "dateLastCrawled": "2021-12-02T19:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What <b>distance</b> <b>metric</b> should I use for the kNN classifier when dealing ...", "url": "https://www.quora.com/What-distance-metric-should-I-use-for-the-kNN-classifier-when-dealing-with-categorical-data-such-as-color-and-shape", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-<b>distance</b>-<b>metric</b>-should-I-use-for-the-kNN-classifier-when...", "snippet": "Answer (1 of 5): You could use a very simple <b>metric</b>: 1 if the colors are different, 0 otherwise. Without further information, that is the typical <b>metric</b> used. Alternatively, with domain knowledge you could devise a better <b>metric</b> if one is applicable (for example, red is similar to orange, but bo...", "dateLastCrawled": "2022-01-15T00:46:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b>, Variance, and <b>Overfitting</b> Explained, Step by Step", "url": "https://machinelearningcompass.com/model_optimization/bias_and_variance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>compass.com/model_optimization/<b>bias</b>_and_variance", "snippet": "The <b>bias</b> of a specific <b>machine learning</b> model trained on a specific dataset describes how well this <b>machine learning</b> model can capture the relationship between the features and the targets. So for our example, the <b>bias</b> of any one model would tell us how well this particular model can predict the exam points received for any number of hours studied in our specific dataset. That seems like a reasonable definition. Practical Examples (<b>Bias</b>) Let\u2019s take a look at three of the above models and ...", "dateLastCrawled": "2022-01-31T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Short Discussion On <b>Bias</b> In <b>Machine</b> <b>Learning</b>", "url": "https://www.encora.com/insights/a-short-discussion-on-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.encora.com/insights/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "A typical <b>machine</b> <b>learning</b> lifecycle might start with a Scoping stage. At this point, an important decision to be made by the analysts regards the level of performance the <b>machine</b> <b>learning</b> system should have. The <b>machine</b> <b>learning</b> team, along with the stakeholders involved, should decide on a <b>metric</b> to be used as a measure of success. This ...", "dateLastCrawled": "2022-02-03T02:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Short Discussion on <b>Bias</b> in <b>Machine</b> <b>Learning</b> | by Daitan | Daitan ...", "url": "https://medium.com/daitan-tech/a-short-discussion-on-bias-in-machine-learning-5bb2066afabc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/daitan-tech/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>-5bb2066afabc", "snippet": "The problem of <b>bias</b> in <b>machine</b> <b>learning</b> is very serious. Moreover, though it seems to be a \u201cdata related\u201d problem, one might think that it can be solved by simply curating datasets so that ...", "dateLastCrawled": "2021-08-05T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Short Discussion on <b>Bias</b> in <b>Machine</b> <b>Learning</b> - Adolfo Eliaz\u00e0t ...", "url": "https://adolfoeliazat.com/2021/06/16/a-short-discussion-on-bias-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://adolfoeliazat.com/2021/06/16/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "The problem of <b>bias</b> in <b>machine</b> <b>learning</b> is very serious. Moreover, though it seems to be a \u201cdata related\u201d problem, one might think that it can be solved by simply curating datasets so that classes and ethical groups are well represented. This line of thinking is a trap and must be avoided. Overall, <b>bias</b> in technology can happen anywhere or anytime a decision must be taken by a human. In such situations, it is very common to consider aspects that make sense from a marketing or profit ...", "dateLastCrawled": "2022-01-16T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A New <b>Metric for Quantifying Machine Learning Fairness in</b> Healthcare ...", "url": "https://towardsdatascience.com/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare-closedloop-ai-fc07b9c83487?source=post_internal_links---------3----------------------------", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-new-<b>metric-for-quantifying-machine-learning-fairness</b>...", "snippet": "The <b>analogy</b> would be the difference between a Pearson correlation or a residual sum of squared errors in regression. While both quantify the models performance, the former is significantly easier to understand and explain; unsurprisingly, it is the <b>metric</b> most individuals use to describe a regression model. In order to achieve this effect, many fairness metrics are presented as the quotient of a protected subgroup to a base subgroup[2]. As the goal of healthcare is to deliver interventions ...", "dateLastCrawled": "2022-01-19T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "CS 540 Lecture Notes: <b>Machine</b> <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/learning.html", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/<b>learning</b>.html", "snippet": "Inductive <b>Bias</b>. Inductive <b>learning</b> is an inherently conjectural process because any knowledge created by generalization from specific facts cannot be proven true; it can only be proven false. Hence, inductive inference is falsity preserving, not truth preserving. To generalize beyond the specific training examples, we need constraints or biases on what f is best. That is, <b>learning</b> can be viewed as searching the Hypothesis Space H of possible f functions. A <b>bias</b> allows us to choose one f over ...", "dateLastCrawled": "2022-02-03T15:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Fairness Metrics - Data Analytics - Data Science, <b>Machine</b> <b>Learning</b>, AI", "url": "https://vitalflux.com/fairness-metrics-ml-model-sensitivity-bias-detection/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>fairness-metrics-ml-model-sensitivity</b>-<b>bias</b>-detection", "snippet": "There are many different ways in which <b>machine</b> <b>learning</b> (ML) models\u2019 fairness could be determined. Some of them are statistical parity, the relative significance of features, model sensitivity etc. In this post, you would learn about how model sensitivity could be used to determine model fairness or <b>bias</b> of model towards the privileged or unprivileged group.The following are some of the topics covered in this post:", "dateLastCrawled": "2022-01-20T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Bias</b> -Variance &amp; <b>Precision</b>-Recall Trade-offs: How to aim for the sweet ...", "url": "https://towardsdatascience.com/tradeoffs-how-to-aim-for-the-sweet-spot-c20b40d5e6b6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/tradeoffs-how-to-aim-for-the-sweet-spot-c20b40d5e6b6", "snippet": "Enoug h with the \u2018Bookish\u2019 definition, let us understand it by more relatable <b>analogy</b> with the real world. \u2192 In simple English, \u201cThe inability of <b>machine</b> <b>learning</b> techniques to capture the true relationship is <b>Bias</b>\u201d. Low <b>Bias</b>: Predicted data points are close to the target. Also, the model suggests less assumptions about the form of the target function. High-<b>Bias</b>: Predicted data points are far from the target. Also, the model suggests more assumptions about the form of the target ...", "dateLastCrawled": "2022-01-30T08:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A New <b>Metric</b> for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare", "url": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/a-new-<b>metric</b>-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "A New <b>Metric</b> for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare. Joseph Gartner. March 2, 2020. Background. Several recent, high profile cases of unfair AI algorithms have highlighted the vital need to address <b>bias</b> early in the development of any AI system. For the most part, <b>bias</b> does not come into algorithms due to malicious intent by the individual creating the algorithm. <b>Bias</b> comes from a lack of diligence in ensuring that the AI system is fair for everyone. In order to combat <b>bias</b> ...", "dateLastCrawled": "2022-02-01T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Solutions to the exercises for <b>Machine</b> <b>Learning</b>", "url": "http://www.perfmath.com/ml/ml_liu_text_solutions.pdf", "isFamilyFriendly": true, "displayUrl": "www.perfmath.com/ml/ml_liu_text_solutions.pdf", "snippet": "2 <b>Machine</b> <b>Learning</b> Fundamentals Illustrated with Regression 2.1 Try to find a publicly available <b>machine</b> <b>learning</b> dataset and apply an end-to-end procedure similar to the one we used with the fuel economy dataset to come up with your own first linear regression <b>machine</b> <b>learning</b> project. Summarize how you explored the data, pre-processed the", "dateLastCrawled": "2022-01-18T07:21:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bias metric)  is like +(distance metric)", "+(bias metric) is similar to +(distance metric)", "+(bias metric) can be thought of as +(distance metric)", "+(bias metric) can be compared to +(distance metric)", "machine learning +(bias metric AND analogy)", "machine learning +(\"bias metric is like\")", "machine learning +(\"bias metric is similar\")", "machine learning +(\"just as bias metric\")", "machine learning +(\"bias metric can be thought of as\")", "machine learning +(\"bias metric can be compared to\")"]}