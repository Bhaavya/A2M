{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Pizza</b> Archives - <b>Mini Batch</b> Baker", "url": "https://minibatchbaker.com/category/pizza/", "isFamilyFriendly": true, "displayUrl": "https://<b>minibatch</b>baker.com/category/<b>pizza</b>", "snippet": "<b>Mini Batch</b> Baker is a place I created for very <b>small</b>-batch baking. I love sweets and I hate leftovers so if you&#39;re <b>like</b> me, hope on! PS, Almost all of my recipes are also vegan and gluten-free. PPS, Find me on Instagram for a daily sneak preview into my process and my thoughts on the topics I care strongly about. Read More\u2026", "dateLastCrawled": "2022-01-21T18:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Mini Batch</b> Baker - Love sweets, Hate leftovers!", "url": "http://minibatchqueen.com/", "isFamilyFriendly": true, "displayUrl": "<b>minibatch</b>queen.com", "snippet": "Two-ingredient Dough <b>Pizza</b> Super Simple Hazelnut Banana Bread Crazy Easy Single-serving Blondie. <b>Small</b>-batch Chocolate Oatmeal Cookies . December 26, 2021 By Elif. Yet another one of my recipes inspired by the gosh darn amazing Kayak cookies. These are vegan, as opposed to the original, full of chocolate, a bit more on the soft-baked side\u2026 Color me obsessed. They also happen to be lunchbox approved. Hope you try these and love! Print Recipe. <b>Small</b>-batch Chocolate Oatmeal Cookies. Prep Time ...", "dateLastCrawled": "2022-01-24T09:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Make Your Own Mini Pizzas</b> + Homemade <b>Pizza</b> Dough \u2013 The Comfort of Cooking", "url": "https://www.thecomfortofcooking.com/2012/08/make-your-own-mini-pizzas.html", "isFamilyFriendly": true, "displayUrl": "https://www.thecomfortofcooking.com/2012/08/<b>make-your-own-mini-pizzas</b>.html", "snippet": "Stir together yeast and warm water in a <b>small</b> bowl; set aside for 5 minutes. Mix together the flour, salt, sugar and olive oil in a large bowl, or the bowl of a stand mixer fitted with the dough hook. Optionally, add dried herbs <b>like</b> basil, oregano or rosemary. Stir in the yeast water. Knead with the dough hook or by hand on a well floured surface for about 5 minutes. If using the stand mixer, once finished kneading, remove dough from bowl and shape into a large ball by hand. Oil two bowls ...", "dateLastCrawled": "2022-02-03T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Small</b> Batch Archives - <b>Mini Batch</b> Baker", "url": "https://minibatchbaker.com/category/small-batch/", "isFamilyFriendly": true, "displayUrl": "https://<b>minibatch</b>baker.com/category/<b>small</b>-batch", "snippet": "<b>Mini Batch</b> Baker is a place I created for very <b>small</b>-batch baking. I love sweets and I hate leftovers so if you&#39;re <b>like</b> me, hope on! PS, Almost all of my recipes are also vegan and gluten-free. PPS, Find me on Instagram for a daily sneak preview into my process and my thoughts on the topics I care strongly about. Read More\u2026", "dateLastCrawled": "2021-12-12T09:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "100+ <b>Data Science Interview Questions and Answers for</b> 2021", "url": "https://www.projectpro.io/article/100-data-science-interview-questions-and-answers-for-2021/184", "isFamilyFriendly": true, "displayUrl": "https://www.projectpro.io/article/100-<b>data-science-interview-questions-and-answers-for</b>...", "snippet": "<b>Mini Batch</b> Gradient Descent: A <b>small</b> number/batch of training samples is used for computation in <b>mini-batch</b> gradient descent. For example, if a dataset has 1000 data points, then batch GD, will train on all the 1000 datapoints, Stochastic GD, will train on only a single sample and the <b>mini-batch</b> GD will consider a batch size of say100 data points and update the parameters. 39. How do data management procedures <b>like</b> missing data handling make selection bias worse? Missing value treatment is ...", "dateLastCrawled": "2022-01-29T21:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Recipes - <b>Mini Batch</b> Baker", "url": "http://www.plentysweet.net/recipes/", "isFamilyFriendly": true, "displayUrl": "www.plentysweet.net/recipes", "snippet": "<b>Mini Batch</b> Baker is a place I created for very <b>small</b>-batch baking. I love sweets and I hate leftovers so if you&#39;re <b>like</b> me, hope on! I love sweets and I hate leftovers so if you&#39;re <b>like</b> me, hope on! PS, Almost all of my recipes are also vegan and gluten-free .", "dateLastCrawled": "2022-01-12T12:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Small Batch Pesto</b> | pescetariangourmand", "url": "https://pescetariangourmand.wordpress.com/2014/08/22/small-batch-pesto/", "isFamilyFriendly": true, "displayUrl": "https://pescetariangourmand.wordpress.com/2014/08/22/<b>small-batch-pesto</b>", "snippet": "It usually only has enough leaves to make one <b>small</b> batch, but you could certainly buy fresh grocery store basil and double this recipe. It\u2019s fantastic on <b>pizza</b> or pasta, especially with shrimp and mushrooms! Process the garlic first, and then add walnuts with some of the olive oil. Add the rest of the ingredients and process until smooth.", "dateLastCrawled": "2022-01-20T13:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "One problem we face with SGD and <b>mini-batch</b> gradient descent is that there will be too many oscillations in the gradient steps. This oscillation happens because we update the parameter of the network after iterating through every point or every n data points and thus the direction of the update will possess some variances causing oscillation in the gradient steps.", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "\ud83c\udfc5 <b>Small Batch Focaccia</b> - cocinarrecetasdepostres.net", "url": "https://cocinarrecetasdepostres.net/small-batch-focaccia/", "isFamilyFriendly": true, "displayUrl": "https://cocinarrecetasdepostres.net/<b>small-batch-focaccia</b>", "snippet": "Preheat the oven to 425. Sprinkle the rosemary on top of the dough, and sprinkle additional salt (coarse is fun here) on top. Bake the bread for 18-21 minutes, until it starts to turn a light golden brown. Immediately after baking, flip the bread onto a cooling rack (do not let it cool in the pan).", "dateLastCrawled": "2021-12-27T03:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Small Batch Frostings and Glazes</b> - Toaster Oven Love", "url": "https://toasterovenlove.com/small-batch-frostings-and-glazes/", "isFamilyFriendly": true, "displayUrl": "https://toasterovenlove.com/<b>small-batch-frostings-and-glazes</b>", "snippet": "Avoid the tempting leftovers and whip up one of these easy <b>small-batch frostings and glazes</b>. Each recipe makes just a few tablespoons or teaspoons. They\u2019re perfect for topping mug cakes, muffins, and more! After creating these fun cake mix mini cakes for two the natural next step was whipping up some frosting. Unfortunately, I\u2019m a bit of a frosting addict and will devour spoonful after spoonful until my stomach feels queasy. So I wanted a way to make just enough frosting for the mini ...", "dateLastCrawled": "2022-01-27T06:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "HW4.pdf - CS246 Mining Massive Data Sets Winter 2020 Problem Set 4 ...", "url": "https://www.coursehero.com/file/127512653/HW4pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/127512653/HW4pdf", "snippet": "<b>Mini batch</b> gradient descent: Go through the dataset in batches of predetermined size and update the parameters as follows: ... What to submit (i) Values of G for wine, running and <b>pizza</b> attributes. [part (a)] (ii) The attribute you would use for splitting the data at the root. [part (a)] (iii) Explain what the decision tree looks like in the described setting. Explain how a decision tree should look like to avoid overfitting. (1-2 lines each) [part (b)] 3 Clustering Data Streams (20 points ...", "dateLastCrawled": "2022-01-28T14:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Small-batch Classic Cheesecake</b> - <b>Mini Batch</b> Baker", "url": "http://minibatchbaker.com/small-batch-classic-cheesecake/", "isFamilyFriendly": true, "displayUrl": "<b>minibatch</b>baker.com/<b>small-batch-classic-cheesecake</b>", "snippet": "6-inch springform pan or <b>similar</b>. Food processor or hand mixer. Ingredients. Crust layer. 1 cup your fav cookie/graham cracker crumbs (120 g) 1 tbsp (nut) milk (15 g) Cheesecake layer. 8 oz block of cream cheese (225 g) at room temp; 1 egg at room temp; 1/4 cup (optional) greek yogurt/sour cream (I didn&#39;t use it, will make it fluffier) 1/4 cup sugar (48 g) add +2 tbsp for really sweet cake; 1 tsp vanilla extract; 1 tsp lemon juice; Instructions. Preheat oven to 250F and line your pan with ...", "dateLastCrawled": "2022-01-14T03:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "100+ <b>Data Science Interview Questions and Answers for</b> 2021", "url": "https://www.projectpro.io/article/100-data-science-interview-questions-and-answers-for-2021/184", "isFamilyFriendly": true, "displayUrl": "https://www.projectpro.io/article/100-<b>data-science-interview-questions-and-answers-for</b>...", "snippet": "<b>Mini Batch</b> Gradient Descent: A <b>small</b> number/batch of training samples is used for computation in <b>mini-batch</b> gradient descent. For example, if a dataset has 1000 data points, then batch GD, will train on all the 1000 datapoints, Stochastic GD, will train on only a single sample and the <b>mini-batch</b> GD will consider a batch size of say100 data points and update the parameters. 39. How do data management procedures like missing data handling make selection bias worse? Missing value treatment is ...", "dateLastCrawled": "2022-01-29T21:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Small</b>-batch Pecan Pie Brownie Bars - <b>Mini Batch</b> Baker", "url": "https://minibatchbaker.com/small-batch-pecan-pie-brownie-bars/", "isFamilyFriendly": true, "displayUrl": "https://<b>minibatch</b>baker.com/<b>small</b>-batch-pecan-pie-brownie-bars", "snippet": "Standard loaf pan or <b>similar</b>. Ingredients. Brownie layer. 3/4 cup oat flour (90 g) 1/3 cup cocoa powder (30 g) 1/4 cup (nut) milk (60 g) 2 tbsp maple syrup (42 g) 2 tbsp sugar (24 g) pinch of salt; Pecan layer. 2 tbsp maple syrup (42 g) 2 tbsp sugar (24 g) 1 tbsp coconut oil (15 g) 1 tbsp (nut) milk (15 g) 1 tbsp flour (7 g) 3/4 cup chopped pecans (90 g) sub walnuts or other nuts; Instructions. Line a standard loaf pan (or <b>similar</b>) with parchment. In a medium bowl add all brownie layer ...", "dateLastCrawled": "2021-12-14T21:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Problem Set 4</b> - GitHub Pages", "url": "https://yishuai.github.io/bigalgo/hw/hw4.pdf", "isFamilyFriendly": true, "displayUrl": "https://yishuai.github.io/bigalgo/hw/hw4.pdf", "snippet": "3000 iterations with <b>Mini Batch</b> GD somewhere in-between. However, the number of itera-tions may vary greatly due to randomness. If your implementation consistently takes longer though, you may have a bug. What to submit (i)Equation for r bf(w;b). [part (a)] (ii)Plot of f k(w;b) vs. the number of updates (k). Total time taken for convergence by each of the gradient descent techniques. Interpretation of plot and convergence times. [part (b)] (iii)Submit the code on Gradescope submission ...", "dateLastCrawled": "2021-11-22T19:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "One problem we face with SGD and <b>mini-batch</b> gradient descent is that there will be too many oscillations in the gradient steps. This oscillation happens because we update the parameter of the network after iterating through every point or every n data points and thus the direction of the update will possess some variances causing oscillation in the gradient steps.", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>K-means Clustering Algorithm: Applications, Types</b>, and Demos [Updated ...", "url": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/k-means-clustering-algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/k-means-clustering...", "snippet": "Fuzzy c-means is very <b>similar</b> to k-means in the sense that it clusters objects that have <b>similar</b> characteristics together. In k-means clustering, a single object cannot belong to two different clusters. But in c-means, objects can belong to more than one cluster, as shown. What is meant by the K-means algorithm? K-Means clustering is an unsupervised learning algorithm. There is no labeled data for this clustering, unlike in supervised learning. K-Means performs the division of objects into ...", "dateLastCrawled": "2022-02-02T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Visualize Image Classifications Using Maximal and Minimal</b> Activating ...", "url": "https://www.mathworks.com/help/deeplearning/ug/visualize-image-classifications-using-maximal-and-minimal-activating-images.html", "isFamilyFriendly": true, "displayUrl": "https://www.mathworks.com/help/deeplearning/ug/visualize-image-classifications-using...", "snippet": "Set InitialLearnRate to a <b>small</b> value to slow down learning in the transferred layers that are not already frozen. In the previous step, you increased the learning rate factors for the last learnable layer to speed up learning in the new final layers. This combination of learning rate settings results in fast learning in the new layers, slower learning in the middle layers, and no learning in the earlier, frozen layers.", "dateLastCrawled": "2022-01-26T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Can larger <b>data sets require higher learning rates when</b> using ... - Quora", "url": "https://www.quora.com/Can-larger-data-sets-require-higher-learning-rates-when-using-deep-neural-networks-to-converge-to-a-good-solution", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Can-larger-<b>data-sets-require-higher-learning-rates-when</b>-using...", "snippet": "Answer (1 of 2): Kasper Fredenslund\u2019s answer looks pretty good. I like the fact that he suggests some sort of concrete recipe for finding a learning rate: &gt; The basic idea is to start with a very <b>small</b> learning rate (think 10^{-7}), and then increase the learning rate after each <b>mini-batch</b> unti...", "dateLastCrawled": "2022-01-14T14:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Many say deep learning is nothing more than a gradient descent on a ...", "url": "https://www.quora.com/Many-say-deep-learning-is-nothing-more-than-a-gradient-descent-on-a-function-with-millions-of-parameter-What-is-your-take-on-that", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Many-say-deep-learning-is-nothing-more-than-a-gradient-descent...", "snippet": "Answer (1 of 3): Eh, some people also say that deep learning is boring because we \u201cfigured out the math\u201d decades ago. Being able to state a concept simply does not impact its utility. It would be just as accurate for me to say: \u201cNo program ever written is interesting. It\u2019s nothing but a few mill...", "dateLastCrawled": "2022-01-21T00:31:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Small</b>-batch <b>Mocha-chip Ice Cream Sandwiches</b> - <b>Mini Batch</b> Baker", "url": "https://minibatchbaker.com/small-batch-mocha-chip-ice-cream-sandwiches/", "isFamilyFriendly": true, "displayUrl": "https://<b>minibatch</b>baker.com/<b>small</b>-batch-<b>mocha-chip-ice-cream-sandwiches</b>", "snippet": "<b>Mini Batch</b> Baker is a place I created for very <b>small</b>-batch baking. I love sweets and I hate leftovers so if you&#39;re like me, hope on! PS, Almost all of my recipes are also vegan and gluten-free. PPS, Find me on Instagram for a daily sneak preview into my process and my thoughts on the topics I care strongly about. Read More\u2026", "dateLastCrawled": "2022-01-24T20:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>K-means Clustering Algorithm: Applications, Types</b>, and Demos [Updated ...", "url": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/k-means-clustering-algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/k-means-clustering...", "snippet": "You <b>can</b> see that there is a very gradual change in the value of WSS as the K value increases from 2. ... It means the original point, which we <b>thought</b> was the centroid, will shift to the new position, which is the actual centroid for each of these groups. Step 4: Keep repeating step 2 and step 3 until convergence is achieved. Demo: K-Means Clustering. Problem Statement - Walmart wants to open a chain of stores across the state of Florida, and it wants to find the optimal store locations to ...", "dateLastCrawled": "2022-02-02T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Make Your Own Mini Pizzas</b> + Homemade <b>Pizza</b> Dough \u2013 The Comfort of Cooking", "url": "https://www.thecomfortofcooking.com/2012/08/make-your-own-mini-pizzas.html", "isFamilyFriendly": true, "displayUrl": "https://www.thecomfortofcooking.com/2012/08/<b>make-your-own-mini-pizzas</b>.html", "snippet": "Stir together yeast and warm water in a <b>small</b> bowl; set aside for 5 minutes. Mix together the flour, salt, sugar and olive oil in a large bowl, or the bowl of a stand mixer fitted with the dough hook. Optionally, add dried herbs like basil, oregano or rosemary. Stir in the yeast water. Knead with the dough hook or by hand on a well floured surface for about 5 minutes. If using the stand mixer, once finished kneading, remove dough from bowl and shape into a large ball by hand. Oil two bowls ...", "dateLastCrawled": "2022-02-03T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Small</b> Batch Baking: How to <b>Create a Small Sourdough Starter and Bake</b> a ...", "url": "https://iamafoodblog.com/small-batch-baking-how-to-create-a-small-sourdough-starter-and-bake-a-small-sourdough-loaf/", "isFamilyFriendly": true, "displayUrl": "https://iamafoodblog.com/<b>small</b>-batch-baking-how-to-<b>create-a-small-sourdough-starter</b>...", "snippet": "The buns <b>can</b> be made in the evening and then cook in the AM. Or you <b>can</b> make then in the AM, and let them sit for about 2 \u2013 3 hours to double in size. Since these are in a muffing tin, I put a pan of water in the bottom of the oven, and spritz the buns just before baking at 400 F. And I bake them for 22 \u2013 25 minutes.", "dateLastCrawled": "2022-02-01T10:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "That is, the object <b>can</b> be in the center region of the image, or it <b>can</b> be in the <b>small</b> corner of the image. Also, the shape of the object <b>can</b> vary from image to image. In some images, the object takes large shape while in other images the object takes <b>small</b> shape. Since the object in the image varies greatly in the image in terms of size and location, it is difficult to identify the object in the image if we use only a single filter with a fixed size. So in the inception network, we use ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Toaster Biscuits Recipes", "url": "https://www.tfrecipes.com/toaster-biscuits/", "isFamilyFriendly": true, "displayUrl": "https://www.tfrecipes.com/toaster-biscuits", "snippet": "BISCUIT <b>MINI-BATCH</b> FOR TOASTER OVEN. A nice, little batch of fresh, hot, biscuits to make in the toaster oven when you just need a little something. Drop biscuits are no more trouble to make than opening a <b>can</b> of dough and you don&#39;t have to keep track of expiration dates. Of course you could roll them and cut them if you wanted, but I&#39;ve always liked the crunchy bits you get from the texture of the drop biscuits. Provided by 3KillerBs. Categories Breads. Time 13m. Yield 6 2 inch biscuits ...", "dateLastCrawled": "2022-01-22T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Single-serving Vegan Pancakes - <b>Mini Batch</b> Baker", "url": "https://minibatchbaker.com/single-serving-vegan-pancakes/", "isFamilyFriendly": true, "displayUrl": "https://<b>minibatch</b>baker.com/single-serving-vegan-pancakes", "snippet": "I <b>thought</b> of you (potentially) single gals/guys and finally came up with this recipe. Enjoy and forget the rest, no leftovers, yes fluffiness. Print Recipe . 5 from 1 vote. Single-serving Vegan Pancakes. Prep Time 5 mins. Cook Time 5 mins. Total Time 10 mins. Course: Breakfast, Dessert, Snack. Cuisine: American. Keyword: pancakes, plantbased, single-serving, vegan. Servings: 1 serving. Calories: 180 kcal. Ingredients. 1/4 cup flour (30 g) gf all purpose if desired; 1/4 tsp baking powder ...", "dateLastCrawled": "2022-01-25T03:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "the italian enough late-game holiday gift guide", "url": "https://italianenough.com/blog/last-minute-holiday-gift-guide", "isFamilyFriendly": true, "displayUrl": "https://italianenough.com/blog/last-minute-holiday-gift-guide", "snippet": "My go-to for roasting vegetables, baking a <b>mini batch</b> of cookies, and making <b>pizza</b> bagels. Everybody <b>can</b> use one of these, yet this size is often the one people don\u2019t think to buy even though it\u2019s arguably the more useful than a half-sheet for <b>small</b> households. This particular one is extremely thick, matte, nonstick, and doesn\u2019t warp in the oven the way thinner metal sheets will. My", "dateLastCrawled": "2022-02-01T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Why are convolutional operations found in deep neural networks are ...", "url": "https://www.quora.com/Why-are-convolutional-operations-found-in-deep-neural-networks-are-traditionally-very-slow-to-execute-on-CPUs", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-are-convolutional-operations-found-in-deep-neural-networks...", "snippet": "Answer (1 of 4): Let\u2019s see how the difference between CPU and GPU architecture makes this particular operation very fast. In case of CPU you have a few (4) physical cores. Which means that using more than 4 parallet threads for your task will not give you any speedups. Instead, they offer you hi...", "dateLastCrawled": "2022-01-22T10:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "7up <b>Pizza</b> - <b>made it last night ( images included</b> ) - New York Style ...", "url": "https://www.pizzamaking.com/forum/index.php?topic=2052.0", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pizza</b>making.com/forum/index.php?topic=2052.0", "snippet": "Unless you <b>can</b> get fresh yeast in <b>small</b> quantities at a reasonable price from a baker, the better and more practical choice for home <b>pizza</b> makers is either ADY or IDY, both of which are in dry form, convenient to use, and <b>can</b> be stored (preferably in the freezer) for a long period of time. You might want to look into a source of IDY since it is the form that most of out members appear to be using. However, there is nothing wrong with ADY. You have to proof it, of course, and convert from IDY ...", "dateLastCrawled": "2022-01-15T05:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Stochastic Gradient Descent</b> explained in real life | by Carolina Bento ...", "url": "https://towardsdatascience.com/stochastic-gradient-descent-explained-in-real-life-predicting-your-pizzas-cooking-time-b7639d5e6a32", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>stochastic-gradient-descent</b>-explained-in-real-life...", "snippet": "Gradient Descent is one of the most popular methods to pick the model that best fits the training data. Typically, that\u2019s the model that minimizes the loss function, for example, minimizing the Residual Sum of Squares in Linear Regression.. <b>Stochastic Gradient Descent</b> is a stochastic, as in probabilistic, spin on Gradient Descent. It improves on the limitations of Gradient Descent and performs much better in large-scale datasets.", "dateLastCrawled": "2022-02-01T23:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "100+ <b>Data Science Interview Questions and Answers for</b> 2021", "url": "https://www.projectpro.io/article/100-data-science-interview-questions-and-answers-for-2021/184", "isFamilyFriendly": true, "displayUrl": "https://www.projectpro.io/article/100-<b>data-science-interview-questions-and-answers-for</b>...", "snippet": "<b>Mini Batch</b> Gradient Descent: A <b>small</b> number/batch of training samples is used for computation in <b>mini-batch</b> gradient descent. For example, if a dataset has 1000 data points, then batch GD, will train on all the 1000 datapoints, Stochastic GD, will train on only a single sample and the <b>mini-batch</b> GD will consider a batch size of say100 data points and update the parameters. 39. How do data management procedures like missing data handling make selection bias worse? Missing value treatment is ...", "dateLastCrawled": "2022-01-29T21:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Small-batch Oatmeal Peanut Butter Cups</b> - <b>Mini Batch</b> Baker", "url": "https://minibatchbaker.com/small-batch-oatmeal-peanut-butter-cups/", "isFamilyFriendly": true, "displayUrl": "https://<b>minibatch</b>baker.com/<b>small-batch-oatmeal-peanut-butter-cups</b>", "snippet": "Instructions. Preheat oven to 350F and grease a muffin pan or line with liners. In a medium bowl combine mashed banana, maple syrup, oat flour and oats. Press into 6 muffin cavities, slighly pushing up the sides to form a cup. Bake 12 minutes, cool completely. Add about 1/2 tbsp nut butter in each cup, freeze about 1 hour to set.", "dateLastCrawled": "2021-12-08T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Open set task augmentation facilitates generalization of deep neural ...", "url": "https://link.springer.com/article/10.1007/s00521-021-06753-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-021-06753-6", "snippet": "For the oven example, this is the case for distinguishing fresh from frozen food items like <b>pizza</b> that look very similar but require different processing. Also in other domains, e.g., monitoring the biodiversity of a particular group of animals (birds), such fine-grained classification tasks are of high practical relevance. Fine-grained classification in combination with rather <b>small</b> data sets <b>can</b> ultimately result in a high risk for overfitting: While the model is tuned to discriminate ...", "dateLastCrawled": "2022-02-01T05:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>K-means Clustering Algorithm: Applications, Types</b>, and Demos [Updated ...", "url": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/k-means-clustering-algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/k-means-clustering...", "snippet": "Here, the features or characteristics are <b>compared</b>, and all objects having similar characteristics are clustered together. ... You <b>can</b> see that there is a very gradual change in the value of WSS as the K value increases from 2. So, you <b>can</b> take the elbow point value as the optimal value of K. It should be either two, three, or at most four. But, beyond that, increasing the number of clusters does not dramatically change the value in WSS, it gets stabilized. Step 2: Let&#39;s assume that these ...", "dateLastCrawled": "2022-02-02T18:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "That is, the object <b>can</b> be in the center region of the image, or it <b>can</b> be in the <b>small</b> corner of the image. Also, the shape of the object <b>can</b> vary from image to image. In some images, the object takes large shape while in other images the object takes <b>small</b> shape. Since the object in the image varies greatly in the image in terms of size and location, it is difficult to identify the object in the image if we use only a single filter with a fixed size. So in the inception network, we use ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Stainless Steel Air Fryer Toaster Oven - AirFryerProClub.com", "url": "https://www.airfryerproclub.com/stainless-steel-air-fryer-toaster-oven/", "isFamilyFriendly": true, "displayUrl": "https://www.airfryerproclub.com/stainless-steel-air-fryer-toaster-oven", "snippet": "With this Breville convection toaster oven air fryer, you <b>can</b> declutter your countertop, as it <b>can</b> be used as a convection oven, a toaster oven, air fryer, dehydrator, broiler, and so much more. It <b>can</b> also bake, roast, warm, proof, reheat, slow cook, prepare <b>pizza</b>, and bagels. 9-Slice Capacity The 1 cubic foot oven cavity <b>can</b> fit 9 toast ...", "dateLastCrawled": "2022-01-26T04:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to <b>reheat food without a microwave: 11 easy</b> ways \u2014 Garlic Delight", "url": "https://garlicdelight.com/reheat-food-without-microwave/", "isFamilyFriendly": true, "displayUrl": "https://garlicdelight.com/reheat-food-without-microwave", "snippet": "For example, you <b>can</b> reheat boiled dumplings by pan frying them to transform them into potstickers. 7: Bake it in the oven. Baking in the oven or a toaster oven is a well-known way to reheat frozen <b>pizza</b>, casseroles, and meals. It\u2019s also a great way to reheat a large volume of food without drying it out.", "dateLastCrawled": "2022-02-03T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Can</b> larger <b>data sets require higher learning rates when</b> using deep ...", "url": "https://www.quora.com/Can-larger-data-sets-require-higher-learning-rates-when-using-deep-neural-networks-to-converge-to-a-good-solution", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Can</b>-larger-<b>data-sets-require-higher-learning-rates-when</b>-using...", "snippet": "Answer (1 of 2): Kasper Fredenslund\u2019s answer looks pretty good. I like the fact that he suggests some sort of concrete recipe for finding a learning rate: &gt; The basic idea is to start with a very <b>small</b> learning rate (think 10^{-7}), and then increase the learning rate after each <b>mini-batch</b> unti...", "dateLastCrawled": "2022-01-14T14:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Pancakes for Two</b> (<b>small</b> batch of pancakes) - Dessert for Two", "url": "https://www.dessertfortwo.com/small-batch-pancakes-for-two/", "isFamilyFriendly": true, "displayUrl": "https://www.dessertfortwo.com/<b>small</b>-batch-<b>pancakes-for-two</b>", "snippet": "The number of times I want to make my family a <b>small</b> batch of pancakes <b>compared</b> to the times I host big brunch parties is staggering. Usually, a <b>small</b> batch of pancakes suffices. My recipe makes 6 perfect, fluffy pancakes. That\u2019s two stacks of 3, if math isn\u2019t your strong suit. <b>Pancakes for Two</b>, the origin: This recipe is actually 15 years old. I scaled down a recipe for pancakes when I was in college, way before food blogging existed. It was just me and my roommate, also named Christina ...", "dateLastCrawled": "2022-02-03T01:08:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Batch, <b>Mini Batch</b> &amp; Stochastic <b>Gradient Descent</b> | by Sushant Patrikar ...", "url": "https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/batch-<b>mini-batch</b>-stochastic-<b>gradient-descent</b>-7a62ecba642a", "snippet": "So, after creating the mini-batches of fixed size, we do the following steps in one epoch: Pick a <b>mini-batch</b>. Feed it to Neural Network. Calculate the mean gradient of the <b>mini-batch</b>. Use the mean gradient we calculated in step 3 to update the weights. Repeat steps 1\u20134 for the mini-batches we created.", "dateLastCrawled": "2022-02-02T11:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Gradient Descent: One of <b>Machine</b> <b>Learning</b>\u2019s Most Popular Algorithms ...", "url": "https://urmiparekh.medium.com/gradient-descent-one-of-machine-learnings-most-popular-algorithms-c31963d1e67f", "isFamilyFriendly": true, "displayUrl": "https://urmiparekh.medium.com/gradient-descent-one-of-<b>machine</b>-<b>learning</b>s-most-popular...", "snippet": "<b>Mini-batch</b> Gradient Descent: It computes the gradients on small random sets of instances called as mini-batches. It is most favorable and widely used algorithm which makes precise and faster results using a batch of \u2018m\u2019 training examples. The common <b>mini-batch</b> sizes range between 50 and 256 but it can be vary for different applications.", "dateLastCrawled": "2022-01-17T15:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A.5 <b>Mini-Batch</b> Optimization", "url": "https://jermwatt.github.io/machine_learning_refined/notes/3_First_order_methods/3_11_Minibatch.html", "isFamilyFriendly": true, "displayUrl": "https://jermwatt.github.io/<b>machine</b>_<b>learning</b>_refined/notes/3_First_order_methods/3_11...", "snippet": "The size of the subset used is called the batch-size of the proces e.g., in our description of the <b>mini-batch</b> optimization scheme above we used batch-size = $1$ (<b>mini-batch</b> optimization using a batch-size of $1$ is also often referred to as stochastic optimization). What batch-size works best in practice - in terms of providing the greatest speed up in optimization - varies and is often problem dependent.", "dateLastCrawled": "2022-01-25T15:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Batch vs <b>Mini-batch</b> vs <b>Stochastic Gradient Descent</b> with Code Examples ...", "url": "https://medium.datadriveninvestor.com/batch-vs-mini-batch-vs-stochastic-gradient-descent-with-code-examples-cd8232174e14", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/batch-vs-<b>mini-batch</b>-vs-stochastic-gradient...", "snippet": "Batch vs Stochastic vs <b>Mini-batch</b> <b>Gradient Descent</b>. Source: Stanford\u2019s Andrew Ng\u2019s MOOC Deep <b>Learning</b> Course. It is possible to use only the <b>Mini-batch</b> <b>Gradient Descent</b> code to implement all versions of <b>Gradient Descent</b>, you just need to set the <b>mini_batch</b>_size equals one to Stochastic GD or the number of training examples to Batch GD. Thus ...", "dateLastCrawled": "2022-01-27T13:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Gradient</b> Descent: A Quick, Simple Introduction | Built In", "url": "https://builtin.com/data-science/gradient-descent", "isFamilyFriendly": true, "displayUrl": "https://builtin.com/data-science/<b>gradient</b>-descent", "snippet": "Common <b>mini-batch</b> sizes range between 50 and 256, but like any other <b>machine</b> <b>learning</b> technique, there is no clear rule because it varies for different applications. This is the go-to algorithm when training a neural network and it is the most common type of <b>gradient</b> descent within deep <b>learning</b>.", "dateLastCrawled": "2022-02-02T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Variants of Gradient Descent Optimizer in Deep <b>Learning</b> with Simple <b>Analogy</b>", "url": "https://manasanoolumortha.medium.com/variants-of-gradient-descent-optimizer-in-deep-learning-with-simple-analogy-6f2f59bd2e26", "isFamilyFriendly": true, "displayUrl": "https://manasanoolumortha.medium.com/variants-of-gradient-descent-optimizer-in-deep...", "snippet": "Variants of Gradient Descent Optimizer in Deep <b>Learning</b> with Simple <b>Analogy</b>. Manasa Noolu(Mortha) Jan 9, 2021 \u00b7 5 min read. The role of optimizers is an essential phase in deep <b>learning</b>. It is important to understand the underlying math to decide on appropriate parameters to boost up the accuracy. There are different types of optimizers, however, I am going to explain the variants of the Gradient Descent optimizer with a simple <b>analogy</b>. Sometimes, it is difficult to interpret the ...", "dateLastCrawled": "2022-01-24T21:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b> 101: An Intuitive Introduction to <b>Gradient</b> Descent ...", "url": "https://towardsdatascience.com/machine-learning-101-an-intuitive-introduction-to-gradient-descent-366b77b52645", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-101-an-intuitive-introduction-to...", "snippet": "To build a <b>Machine</b> <b>Learning</b> model, we often need at least 3 things. A problem T, a performance measure P, and an experience E, ... In <b>analogy</b>, we can think of <b>Gradient</b> Descent as being a ball rolling down on a valley. The deepest valley is the optimal global minimum and that is the place we aim for. Depending on where the ball starts rolling, it may rest in the bottom of a valley. But not in the lowest one. This is called a local minimum and in the context of our model, the valley is the ...", "dateLastCrawled": "2022-01-30T05:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "<b>Machine</b> <b>learning</b> terminology for model building and validation There seems to be an <b>analogy</b> between statistical modeling and <b>machine</b> <b>learning</b> that we will cover in subsequent chapters in depth. However, a quick view has been provided as follows: in statistical modeling, linear regression with two independent variables is trying to fit the best plane with\u2026", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>All Unit MCQ questions of ML</b> \u2013 TheCodingShef", "url": "https://thecodingshef.com/all-unit-mcq-questions-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://thecodingshef.com/<b>all-unit-mcq-questions-of</b>-<b>machine</b>-<b>learning</b>", "snippet": "<b>Analogy</b>; Deduction; Introduction Correct option is D. Types of <b>learning</b> used in <b>machine</b> Supervised; Unsupervised; Reinforcement; All of these Correct option is D. A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience Supervised <b>learning</b> problem; Un Supervised <b>learning</b> problem; Well posed <b>learning</b> problem; All of these Correct option is C. Which of the ...", "dateLastCrawled": "2022-01-30T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Model 1: accuracy = 92%. Model 2: accuracy = 95%. Model 2 has higher accuracy than model 1, but model 2 is useless. This is called accuracy paradox, which means the model with higher accuracy may not have better generalization power. In general, when TP &lt; FP, the accuracy will always increase when we change the classifier to always output &#39;negative&#39;.Conversely, when TN &lt; FN, the same will happen when we change the classifier to always output &#39;positive&#39; [1].. Recall@k", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>full batch vs online learning vs mini batch</b> - <b>Cross Validated</b>", "url": "https://stats.stackexchange.com/questions/110078/full-batch-vs-online-learning-vs-mini-batch", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/110078/<b>full-batch-vs-online-learning</b>-vs-mini...", "snippet": "a) full-batch <b>learning</b>. b) online-<b>learning</b> where for every iteration we randomly pick a training case. c) mini-batch <b>learning</b> where for every iteration we randomly pick 100 training cases. The answer is b. But I wonder why c is wrong. Isn&#39;t online-<b>learning</b> a special case of mini-batch where each iteration contains only a single training case?", "dateLastCrawled": "2022-01-24T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Initialisation, Normalisation, Dropout", "url": "https://www.inf.ed.ac.uk/teaching/courses/mlp/2019-20/lectures/mlp06-enc.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.inf.ed.ac.uk/teaching/courses/mlp/2019-20/lectures/mlp06-enc.pdf", "snippet": "<b>Machine</b> <b>Learning</b> Practical | MLP Lecture 6 22 October 2019 MLP Lecture 6 / 22 October 2019 Initialisation, Normalisation, Dropout1. Recap: Vanishing/exploding gradients z(1) = W(1)x, h(1) = f(z(1)) and y = h(L) Assuming f is identity mapping, y = W(L)W(L 1):::W(2)W(1)x W(l) = &quot; 2 0 0 2 #! y = W(L) &quot; 2 0 0 2 # L 1 x (Exploding gradients) W(l) = &quot;:5 0 0 :5 #! y = W(L) &quot;:5 0 0 :5 # L 1 x (Vanishing gradients) MLP Lecture 6 / 22 October 2019 Initialisation, Normalisation, Dropout2. Recap ...", "dateLastCrawled": "2022-01-31T14:01:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> | Ordinary Least Squares | Mathematical Optimization", "url": "https://www.scribd.com/document/429447261/Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/429447261/<b>Machine-Learning</b>", "snippet": "<b>Machine Learning</b>", "dateLastCrawled": "2021-11-04T20:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "sgd-bias-variance.pdf - S&amp;DS 355 555 Introductory <b>Machine</b> <b>Learning</b> ...", "url": "https://www.coursehero.com/file/80854564/sgd-bias-variancepdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/80854564/sgd-bias-variancepdf", "snippet": "View sgd-bias-variance.pdf from S&amp;DS 355 at Yale University. S&amp;DS 355 / 555 Introductory <b>Machine</b> <b>Learning</b> Stochastic Gradient Descent and Bias-Variance Tradeoffs September 22 Goings on \u2022 Nothing", "dateLastCrawled": "2021-12-06T21:41:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(mini-batch)  is like +(small pizza)", "+(mini-batch) is similar to +(small pizza)", "+(mini-batch) can be thought of as +(small pizza)", "+(mini-batch) can be compared to +(small pizza)", "machine learning +(mini-batch AND analogy)", "machine learning +(\"mini-batch is like\")", "machine learning +(\"mini-batch is similar\")", "machine learning +(\"just as mini-batch\")", "machine learning +(\"mini-batch can be thought of as\")", "machine learning +(\"mini-batch can be compared to\")"]}