{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Loss Functions in Machine Learning</b> | Working | Different Types", "url": "https://www.educba.com/loss-functions-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>loss-functions-in-machine-learning</b>", "snippet": "Types of <b>Loss Functions in Machine Learning</b>. Below are the different types of the <b>loss</b> function in <b>machine</b> <b>learning</b> which are as follows: 1. Regression <b>loss</b> functions. Linear regression is a fundamental concept of this function. Regression <b>loss</b> functions establish a linear relationship between a dependent variable (Y) and an independent ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Learning</b> <b>Rate</b> in <b>Machine</b> <b>Learning</b> - Deepchecks", "url": "https://deepchecks.com/glossary/learning-rate-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://deepchecks.com/g<b>loss</b>ary/<b>learning</b>-<b>rate</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "The <b>learning</b> <b>rate</b>, denoted by the symbol \u03b1, is a hyper-parameter used to govern the pace at which an <b>algorithm</b> updates or learns the values of a parameter estimate. In other words, the <b>learning</b> <b>rate</b> regulates the weights of our neural network concerning the <b>loss</b> gradient &gt;.", "dateLastCrawled": "2022-01-30T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to interpret <b>loss</b> and accuracy for a <b>machine</b> <b>learning</b> model", "url": "https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34518656", "snippet": "The lower the <b>loss</b>, the better a model (unless the model has over-fitted to the training data). The <b>loss</b> is calculated on training and validation and its interperation is how well the model is doing for these two sets. Unlike accuracy, <b>loss</b> is not a percentage. It is a summation of the errors made for each example in training or validation sets.", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning - Performance Metrics</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_algorithms_performance_metrics.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/.../<b>machine</b>_<b>learning</b>_<b>algorithms</b>_performance_metrics.htm", "snippet": "LOGLOSS (Logarithmic <b>Loss</b>) It is also called Logistic regression <b>loss</b> or cross-entropy <b>loss</b>. It basically defined on probability estimates and measures the performance of a classification model where the input is a probability value between 0 and 1. It can be understood more clearly by differentiating it with accuracy. As we know that accuracy ...", "dateLastCrawled": "2022-02-02T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Optimization in <b>Machine Learning</b> \u2014 Part 1 | by Abhishek Chatterjee ...", "url": "https://medium.com/swlh/optimization-in-machine-learning-part-1-e9da1aa1eedf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/optimization-in-<b>machine-learning</b>-part-1-e9da1aa1eedf", "snippet": "The optimizer is a function that optimizes <b>Machine Learning</b> models using training data. Optimizers use a <b>Loss</b> Function to calculate the <b>loss</b> of the model and then based on that tries to optimize ...", "dateLastCrawled": "2022-02-02T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is <b>Cost Function in Machine Learning</b> | Simplilearn", "url": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/cost-function-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/<b>machine</b>-<b>learning</b>-tutorial/cost-function-in...", "snippet": "A neural network is a <b>machine</b> <b>learning</b> <b>algorithm</b> that takes in multiple inputs, runs them through an <b>algorithm</b>, and essentially sums the output of the different algorithms to get the final output. The cost function of a neural network will be the sum of errors in each layer.", "dateLastCrawled": "2022-02-02T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Loss</b> Functions and Optimization Algorithms. Demystified. | by Apoorva ...", "url": "https://medium.com/data-science-group-iitr/loss-functions-and-optimization-algorithms-demystified-bb92daff331c", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-group-iitr/<b>loss</b>-functions-and-optimization-<b>algorithms</b>...", "snippet": "A <b>learning</b> <b>rate</b> that is too small leads to painfully slow convergence i.e will result in small baby steps towards finding optimal parameter values which minimize <b>loss</b> and finding that valley which ...", "dateLastCrawled": "2022-01-31T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ML | <b>Models Score and Error - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/ml-models-score-and-error/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/ml-models-score-and-<b>error</b>", "snippet": "In <b>Machine</b> <b>Learning</b> one of the main task is to model the data and predict the output using various Classification and Regression Algorithms. But since there are so many Algorithms, it is really difficult to choose the one for predicting the final data. So we need to compare our models and choose the one with the highest accuracy.", "dateLastCrawled": "2022-02-03T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> <b>Learning</b> MCQ questions and answers - PhDTalks", "url": "https://phdtalks.org/2021/10/machine-learning-mcq.html", "isFamilyFriendly": true, "displayUrl": "https://phdtalks.org/2021/10/<b>machine</b>-<b>learning</b>-mcq.html", "snippet": "In this blog post, we have important <b>Machine</b> <b>Learning</b> MCQ questions. All these basic ML MCQs are provided with answers. In these MCQs on <b>Machine</b> <b>Learning</b>, topics <b>like</b> classification, clustering, supervised <b>learning</b> and others are covered.. The <b>Machine</b> <b>Learning</b> MCQ questions and answers are very useful for placements, college &amp; university exams.. More MCQs related to <b>Machine</b> <b>Learning</b>. Top MCQ on linear regression in <b>Machine</b> <b>Learning</b>; MCQ on Clustering in Data Mining: <b>Machine</b> <b>Learning</b>", "dateLastCrawled": "2022-02-01T04:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Understanding Learning Rate in Machine Learning</b>", "url": "https://www.mygreatlearning.com/blog/understanding-learning-rate-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>understanding-learning-rate-in-machine-learning</b>", "snippet": "Effect of different values for <b>learning</b> <b>rate</b>. <b>Learning</b> <b>rate</b> is used to scale the magnitude of parameter updates during gradient descent. The choice of the value for <b>learning</b> <b>rate</b> can impact two things: 1) how fast the <b>algorithm</b> learns and 2) whether the cost function is minimized or not. Figure 2 shows the variation in cost function with a ...", "dateLastCrawled": "2022-02-02T05:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Loss</b> Functions in <b>Machine</b> <b>Learning</b>: An Easy Overview(2021)", "url": "https://www.jigsawacademy.com/blogs/ai-ml/loss-function", "isFamilyFriendly": true, "displayUrl": "https://www.<b>jigsawacademy</b>.com/blogs/ai-ml/<b>loss</b>-function", "snippet": "Many other considerations are involved in choosing a <b>loss</b> of function for a particular problem, such as the type of <b>machine</b> <b>learning</b> <b>algorithm</b> selected, ease of computing the derivatives, and the type of <b>machine</b> <b>learning</b> <b>algorithm</b> is selected at some degree of outliers percentage to set in the data. The <b>loss</b> function can be categorized into two main groups based upon the type of <b>learning</b> task, and those are : Regression Losses ; Classification Losses; In classification, one can predict the ...", "dateLastCrawled": "2022-01-26T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Loss Functions and Optimization Algorithms</b> - XpertUp", "url": "https://www.xpertup.com/blog/machine-learning/loss-functions-and-optimization-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.xpertup.com/blog/<b>machine</b>-<b>learning</b>/<b>loss-functions-and-optimization-algorithms</b>", "snippet": "November 6, 2021. xpertup <b>machine</b> <b>learning</b>. Choosing Optimization Algorithms and <b>Loss</b> Functions for a model especially for deep <b>learning</b> model plays a major role in building optimum and faster results. In this blog we are going to discuss about various <b>loss functions and optimization algorithms</b>. If you new to deep <b>learning</b>, I strongly recommend ...", "dateLastCrawled": "2022-01-09T08:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Introduction to <b>Loss</b> Functions - Algorithmia Blog", "url": "https://www.algorithmia.com/blog/introduction-to-loss-functions", "isFamilyFriendly": true, "displayUrl": "https://www.<b>algorithm</b>ia.com/blog/introduction-to-<b>loss</b>-functions", "snippet": "Picking <b>Loss</b> Functions: A Comparison Between MSE, Cross Entropy, And Hinge <b>Loss</b> (Rohan Varma): \u201c<b>Loss</b> functions are a key part of any <b>machine</b> <b>learning</b> model: they define an objective against which the performance of your model is measured, and the setting of weight parameters learned by the model is determined by minimizing a chosen <b>loss function</b>. There are several different common <b>loss</b> functions to choose from: the cross-entropy <b>loss</b>, the mean-squared <b>error</b>, the huber <b>loss</b>, and the hinge ...", "dateLastCrawled": "2022-02-03T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Loss</b> Functions and Optimization Algorithms. Demystified. | by Apoorva ...", "url": "https://medium.com/data-science-group-iitr/loss-functions-and-optimization-algorithms-demystified-bb92daff331c", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-group-iitr/<b>loss</b>-functions-and-optimization-<b>algorithms</b>...", "snippet": "A <b>learning</b> <b>rate</b> that is too small leads to painfully slow convergence i.e will result in small baby steps towards finding optimal parameter values which minimize <b>loss</b> and finding that valley which ...", "dateLastCrawled": "2022-01-31T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Common <b>loss</b> functions that you should know! | by Sowmya Yellapragada ...", "url": "https://medium.com/ml-cheat-sheet/winning-at-loss-functions-common-loss-functions-that-you-should-know-a72c1802ecb4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/ml-cheat-sheet/winning-at-<b>loss</b>-functions-common-<b>loss</b>-functions-that...", "snippet": "Thus measuring the model performance is at the crux of any <b>machine</b> <b>learning</b> <b>algorithm</b>, and this is done by the use of <b>loss</b> functions.Choosing the right <b>loss function</b> can help your model learn ...", "dateLastCrawled": "2022-01-16T20:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Minimizing The Misclassification <b>Error Rate Using a Surrogate Convex Loss</b>", "url": "https://icml.cc/Conferences/2012/papers/917.pdf", "isFamilyFriendly": true, "displayUrl": "https://icml.cc/Conferences/2012/papers/917.pdf", "snippet": "theory of <b>machine</b> <b>learning</b> is that of binary classi\ufb01-cation with half-spaces. However the problem of ag-nostically <b>learning</b> half-spaces is known to be NP-hard in general (Kearns et al., 1994). Even when one only wants to learn a half-space relative to the best possible M-margin <b>error</b>, Ben-david &amp; Simon (2000) show that (subject to P 6= NP) there exists no proper <b>learning</b> <b>algorithm</b> (i.e. returning a linear predictor) that runs in time polynomial in both 1/M and the desired ac-curacy. Under ...", "dateLastCrawled": "2022-01-17T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b> | by Aditya Mishra ...", "url": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metrics-to-evaluate-your-<b>machine</b>-<b>learning</b>-<b>algorithm</b>-f10...", "snippet": "Evaluating your <b>machine</b> <b>learning</b> <b>algorithm</b> is an essential part of any project. Your model may give you satisfying results when evaluated using a metric say <b>accuracy</b>_score but may give poor results\u2026 Get started. Open in app. Sign in. Get started. Follow. 618K Followers \u00b7 Editors&#39; Picks Features Deep Dives Grow Contribute. About. Get started. Open in app. Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b>. Aditya Mishra. Feb 24, 2018 \u00b7 7 min read. Evaluating your <b>machine</b> <b>learning</b> ...", "dateLastCrawled": "2022-02-02T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Gradient Descent in <b>Machine</b> <b>Learning</b> - Javatpoint", "url": "https://www.javatpoint.com/gradient-descent-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/gradient-descent-in-<b>machine</b>-<b>learning</b>", "snippet": "Gradient Descent is known as one of the most commonly used optimization algorithms to train <b>machine</b> <b>learning</b> models by means of minimizing errors between actual and expected results. Further, gradient descent is also used to train Neural Networks. In mathematical terminology, Optimization <b>algorithm</b> refers to the task of minimizing/maximizing an ...", "dateLastCrawled": "2022-02-02T12:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Comparing the performance of different machine learning algorithms</b> ...", "url": "https://dibyendudeb.com/comparing-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://dibyendudeb.com/comparing-<b>machine</b>-<b>learning</b>-<b>algorithms</b>", "snippet": "Comparing <b>Machine</b> <b>Learning</b> Algorithms (MLAs) are important to come out with the best-suited <b>algorithm</b> for a particular problem. This post discusses comparing different <b>machine</b> <b>learning</b> algorithms and how we can do this using scikit-learn package of python. You will learn how to compare multiple MLAs at a time using more than one fit statistics provided by scikit-learn and also creating plots to visualize the differences.", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Training &amp; Test <b>Error: Validating Models in Machine Learning</b> | RapidMiner", "url": "https://rapidminer.com/blog/validate-models-training-test-error/", "isFamilyFriendly": true, "displayUrl": "https://rapidminer.com/blog/validate-models-training-test-<b>error</b>", "snippet": "Table 1: A data table for predictive modeling. The goal is to find a function that maps the x-values to the correct value of y. A predictive model is a function which maps a given set of values of the x-columns to the correct corresponding value of the y-column.Finding a function for the given dataset is called training the model.. Good models not only avoid errors for x-values they already know, but, in particular, they are also able to create predictions for situations which are only ...", "dateLastCrawled": "2022-02-02T22:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> MCQ questions and answers - PhDTalks", "url": "https://phdtalks.org/2021/10/machine-learning-mcq.html", "isFamilyFriendly": true, "displayUrl": "https://phdtalks.org/2021/10/<b>machine</b>-<b>learning</b>-mcq.html", "snippet": "In this blog post, we have important <b>Machine</b> <b>Learning</b> MCQ questions. All these basic ML MCQs are provided with answers. In these MCQs on <b>Machine</b> <b>Learning</b>, topics like classification, clustering, supervised <b>learning</b> and others are covered.. The <b>Machine</b> <b>Learning</b> MCQ questions and answers are very useful for placements, college &amp; university exams.. More MCQs related to <b>Machine</b> <b>Learning</b>. Top MCQ on linear regression in <b>Machine</b> <b>Learning</b>; MCQ on Clustering in Data Mining: <b>Machine</b> <b>Learning</b>", "dateLastCrawled": "2022-02-01T04:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Loss</b> Functions in <b>Machine</b> <b>Learning</b>: An Easy Overview(2021)", "url": "https://www.jigsawacademy.com/blogs/ai-ml/loss-function", "isFamilyFriendly": true, "displayUrl": "https://www.<b>jigsawacademy</b>.com/blogs/ai-ml/<b>loss</b>-function", "snippet": "Many other considerations are involved in choosing a <b>loss</b> of function for a particular problem, such as the type of <b>machine</b> <b>learning</b> <b>algorithm</b> selected, ease of computing the derivatives, and the type of <b>machine</b> <b>learning</b> <b>algorithm</b> is selected at some degree of outliers percentage to set in the data. The <b>loss</b> function <b>can</b> be categorized into two main groups based upon the type of <b>learning</b> task, and those are : Regression Losses ; Classification Losses; In classification, one <b>can</b> predict the ...", "dateLastCrawled": "2022-01-26T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Loss</b> Functions and Optimization Algorithms. Demystified. | by Apoorva ...", "url": "https://medium.com/data-science-group-iitr/loss-functions-and-optimization-algorithms-demystified-bb92daff331c", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-group-iitr/<b>loss</b>-functions-and-optimization-<b>algorithms</b>...", "snippet": "The choice of Optimisation Algorithms and <b>Loss</b> Functions for a deep <b>learning</b> model <b>can</b> play a big role in producing optimum and faster results. Before we begin, let us see how different components ...", "dateLastCrawled": "2022-01-31T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> 99+ Most Important MCQ Part-2 | <b>Machine</b> <b>Learning</b> MCQ ...", "url": "https://www.jobsaarnee.com/2021/06/machine-learning-100-most-important-mcq-part2.html", "isFamilyFriendly": true, "displayUrl": "https://www.jobsaarnee.com/2021/06/<b>machine</b>-<b>learning</b>-100-most-important-mcq-part2.html", "snippet": "The three gene operators we have discussed <b>can</b> <b>be thought</b> of as: (A) Crossover: Receiving the best genes from both parents. (B) Mutation: Changing one gene so that the child is almost like the parent. (C) Mirror: Changing a string of genes in the child so it is like a cousinto the parent. (D) A and B only. Sol. (D) A and B only. Q49. If a population contains only one strain, you <b>can</b> introduce new strains by: (A) Using the Crossover operator. (B) Injecting random strains into the population ...", "dateLastCrawled": "2022-02-03T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is <b>Cost Function in Machine Learning</b> | Simplilearn", "url": "https://www.simplilearn.com/tutorials/machine-learning-tutorial/cost-function-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.simplilearn.com/tutorials/<b>machine</b>-<b>learning</b>-tutorial/cost-function-in...", "snippet": "A neural network is a <b>machine</b> <b>learning</b> <b>algorithm</b> that takes in multiple inputs, runs them through an <b>algorithm</b>, and essentially sums the output of the different algorithms to get the final output. The cost function of a neural network will be the sum of errors in each layer.", "dateLastCrawled": "2022-02-02T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to interpret <b>loss</b> and accuracy for a <b>machine</b> <b>learning</b> model", "url": "https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34518656", "snippet": "I\u2019m voting to close this question because <b>Machine</b> <b>learning</b> (ML) theory questions are off-topic on Stack Overflow - gift-wrap candidate for Cross-Validated \u2013 Daniel F. Feb 10 &#39;21 at 12:13. Add a comment | 3 Answers Active Oldest Score. 339 The lower the <b>loss</b>, the better a model (unless the model has over-fitted to the training data). The <b>loss</b> is calculated on training and validation and its interperation is how well the model is doing for these two sets. Unlike accuracy, <b>loss</b> is not a ...", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "A. <b>Machine</b> <b>Learning</b> (ML) is that field of computer science. B. ML is a type of artificial intelligence that extract patterns out of raw data by using an <b>algorithm</b> or method. C. The main focus of ML is to allow computer systems learn from experience without being explicitly programmed or human intervention. D.", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Project 5 - <b>Machine</b> <b>Learning</b> - CS 188: Introduction to Artificial ...", "url": "https://inst.eecs.berkeley.edu/~cs188/su21/project5/", "isFamilyFriendly": true, "displayUrl": "https://inst.eecs.berkeley.edu/~cs188/su21/project5", "snippet": "You <b>can</b> take a state-of-the-art model from a research paper, and change the <b>learning</b> <b>rate</b> such that it performs no better than random. A <b>learning</b> <b>rate</b> too low will result in the model <b>learning</b> too slowly, and a <b>learning</b> <b>rate</b> too high may cause <b>loss</b> to diverge to infinity. Begin by trying different <b>learning</b> rates while looking at how the <b>loss</b> decreases over time.", "dateLastCrawled": "2022-01-30T00:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Getting out of <b>Loss Plateaus by adjusting Learning Rates</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2020/02/26/getting-out-of-loss-plateaus-by-adjusting-learning-rates/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/.../getting-out-of-<b>loss-plateaus-by-adjusting-learning-rates</b>", "snippet": "Here\u2019s the answer: supervised <b>machine</b> <b>learning</b> models are optimized by means of the gradients. If they\u2019re zero, the model gets stuck. Contrary to local minima, which we will cover next, saddle points are extra problematic because they don\u2019t represent an extremum. Hence, for example, if you\u2019d go left and right, you\u2019d find a <b>loss</b> that increases \u2013 while it would decrease for the other two directions. This means that it\u2019s extra difficult to escape such points. Let\u2019s therefore ...", "dateLastCrawled": "2022-02-02T04:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - Does KNN have a <b>loss function</b>? - Cross Validated", "url": "https://stats.stackexchange.com/questions/420416/does-knn-have-a-loss-function", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/420416/does-knn-have-a-<b>loss-function</b>", "snippet": "2 Answers2. Show activity on this post. k -NN does not have a <b>loss function</b> that <b>can</b> be minimized during training. In fact, this <b>algorithm</b> is not trained at all. The only &quot;training&quot; that happens for k -NN, is memorising the data (creating a local copy), so that during prediction you <b>can</b> do a search and majority vote.", "dateLastCrawled": "2022-02-01T15:31:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Loss Functions in Machine Learning</b> | Working | Different Types", "url": "https://www.educba.com/loss-functions-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>loss-functions-in-machine-learning</b>", "snippet": "Types of <b>Loss Functions in Machine Learning</b>. Below are the different types of the <b>loss</b> function in <b>machine</b> <b>learning</b> which are as follows: 1. Regression <b>loss</b> functions. Linear regression is a fundamental concept of this function. Regression <b>loss</b> functions establish a linear relationship between a dependent variable (Y) and an independent ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to interpret \u201c<b>loss</b>\u201d and \u201c<b>accuracy</b>\u201d for a <b>machine</b> <b>learning</b> model ...", "url": "https://intellipaat.com/community/368/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/community/368/how-to-interpret-<b>loss</b>-and-<b>accuracy</b>-for-a-<b>machine</b>...", "snippet": "A <b>loss</b> function is used to optimize a <b>machine</b> <b>learning</b> <b>algorithm</b>. The <b>loss</b> is calculated on training and validation and its interpretation is based on how well the model is doing in these two sets. It is the sum of errors made for each example in training or validation sets. <b>Loss</b> value implies how poorly or well a model behaves after each iteration of optimization. An <b>accuracy</b> metric is used to measure the <b>algorithm</b>\u2019s performance in an interpretable way. The <b>accuracy</b> of a model is usually ...", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Loss</b> Functions in <b>Machine</b> <b>Learning</b>: An Easy Overview(2021)", "url": "https://www.jigsawacademy.com/blogs/ai-ml/loss-function", "isFamilyFriendly": true, "displayUrl": "https://www.<b>jigsawacademy</b>.com/blogs/ai-ml/<b>loss</b>-function", "snippet": "Many other considerations are involved in choosing a <b>loss</b> of function for a particular problem, such as the type of <b>machine</b> <b>learning</b> <b>algorithm</b> selected, ease of computing the derivatives, and the type of <b>machine</b> <b>learning</b> <b>algorithm</b> is selected at some degree of outliers percentage to set in the data. The <b>loss</b> function <b>can</b> be categorized into two main groups based upon the type of <b>learning</b> task, and those are : Regression Losses ; Classification Losses; In classification, one <b>can</b> predict the ...", "dateLastCrawled": "2022-01-26T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Loss</b> Functions and Optimization Algorithms. Demystified. | by Apoorva ...", "url": "https://medium.com/data-science-group-iitr/loss-functions-and-optimization-algorithms-demystified-bb92daff331c", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-group-iitr/<b>loss</b>-functions-and-optimization-<b>algorithms</b>...", "snippet": "The choice of Optimisation Algorithms and <b>Loss</b> Functions for a deep <b>learning</b> model <b>can</b> play a big role in producing optimum and faster results. Before we begin, let us see how different components ...", "dateLastCrawled": "2022-01-31T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to interpret <b>loss</b> and accuracy for a <b>machine</b> <b>learning</b> model", "url": "https://stackoverflow.com/questions/34518656/how-to-interpret-loss-and-accuracy-for-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/34518656", "snippet": "The lower the <b>loss</b>, the better a model (unless the model has over-fitted to the training data). The <b>loss</b> is calculated on training and validation and its interperation is how well the model is doing for these two sets. Unlike accuracy, <b>loss</b> is not a percentage. It is a summation of the errors made for each example in training or validation sets.", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning - Performance Metrics</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_algorithms_performance_metrics.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/.../<b>machine</b>_<b>learning</b>_<b>algorithms</b>_performance_metrics.htm", "snippet": "With the help of Log <b>Loss</b> value, we <b>can</b> have more accurate view of the performance of our model. We <b>can</b> use log_<b>loss</b> function of sklearn.metrics to compute Log <b>Loss</b>. Example. The following is a simple recipe in Python which will give us an insight about how we <b>can</b> use the above explained performance metrics on binary classification model \u2212", "dateLastCrawled": "2022-02-02T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b> | by Aditya Mishra ...", "url": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metrics-to-evaluate-your-<b>machine</b>-<b>learning</b>-<b>algorithm</b>-f10...", "snippet": "Evaluating your <b>machine</b> <b>learning</b> <b>algorithm</b> is an essential part of any project. Your model may give you satisfying results when evaluated using a metric say <b>accuracy</b>_score but may give poor results\u2026 Get started. Open in app. Sign in. Get started. Follow. 618K Followers \u00b7 Editors&#39; Picks Features Deep Dives Grow Contribute. About. Get started. Open in app. Metrics to Evaluate your <b>Machine</b> <b>Learning</b> <b>Algorithm</b>. Aditya Mishra. Feb 24, 2018 \u00b7 7 min read. Evaluating your <b>machine</b> <b>learning</b> ...", "dateLastCrawled": "2022-02-02T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Comparing the performance of different machine learning algorithms</b> ...", "url": "https://dibyendudeb.com/comparing-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://dibyendudeb.com/comparing-<b>machine</b>-<b>learning</b>-<b>algorithms</b>", "snippet": "Comparing <b>Machine</b> <b>Learning</b> Algorithms (MLAs) are important to come out with the best-suited <b>algorithm</b> for a particular problem. This post discusses comparing different <b>machine</b> <b>learning</b> algorithms and how we <b>can</b> do this using scikit-learn package of python. You will learn how to compare multiple MLAs at a time using more than one fit statistics provided by scikit-learn and also creating plots to visualize the differences.", "dateLastCrawled": "2022-02-03T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "40 Questions to test a <b>Data Scientist on Machine Learning</b> Flashcards ...", "url": "https://quizlet.com/300350513/40-questions-to-test-a-data-scientist-on-machine-learning-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/300350513/40-questions-to-test-a-data-scientist-on-<b>machine</b>...", "snippet": "Time taken by an <b>algorithm</b> for training (on a model with max_depth 2) 4-fold is 10 seconds and for the prediction on remaining 1-fold is 2 seconds. In previous question, if you train the same <b>algorithm</b> for tuning 2 hyper parameters say &quot;max_depth&quot; and &quot;<b>learning</b>_<b>rate</b>&quot;.", "dateLastCrawled": "2022-01-15T03:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Training &amp; Test <b>Error: Validating Models in Machine Learning</b> | RapidMiner", "url": "https://rapidminer.com/blog/validate-models-training-test-error/", "isFamilyFriendly": true, "displayUrl": "https://rapidminer.com/blog/validate-models-training-test-<b>error</b>", "snippet": "Table 1: A data table for predictive modeling. The goal is to find a function that maps the x-values to the correct value of y. A predictive model is a function which maps a given set of values of the x-columns to the correct corresponding value of the y-column.Finding a function for the given dataset is called training the model.. Good models not only avoid errors for x-values they already know, but, in particular, they are also able to create predictions for situations which are only ...", "dateLastCrawled": "2022-02-02T22:41:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> fundamentals I: An <b>analogy</b> | Finn Rietz.dev", "url": "http://www.finnrietz.dev/machine%20learning/part-1-analogy/", "isFamilyFriendly": true, "displayUrl": "www.finnrietz.dev/<b>machine</b> <b>learning</b>/part-1-<b>analogy</b>", "snippet": "And this is what the <b>loss</b> function does, so the <b>loss</b> function for a <b>Machine</b> <b>learning</b> algorithm is like the teacher for the real-world dermatologist in-training. In mathematical terms, the <b>loss</b> function could look something like this: \\(L = (y_i - \\hat{y_i})^2\\), where \\(y_i\\) is the actual output value (the one that the teacher has written down) and \\(\\hat{y_i}\\) is the one our <b>learning</b> algorithm produced.", "dateLastCrawled": "2022-01-16T09:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "Minimize a <b>loss</b> function in ... and it has been used for conducting research and for deploying <b>machine</b> <b>learning</b> systems into production across more than a dozen areas of computer science and other ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Human learning as an analogy of machine learning</b> - Weina Jin, MD", "url": "https://weina.me/ml-vs-human-learning/", "isFamilyFriendly": true, "displayUrl": "https://weina.me/ml-vs-human-<b>learning</b>", "snippet": "<b>Human learning as an analogy of machine learning</b>. 5 minute read. Published: July 24, 2018. These days, during my reading of computer vision papers, I discover a recurrent theme: to orient CNN-based network to a specific CV task, most papers focus on designing new architectures of the network and/or <b>loss</b> functions. This approach seems obvious.", "dateLastCrawled": "2020-07-13T08:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Basic Concepts in Machine Learning</b>", "url": "https://machinelearningmastery.com/basic-concepts-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>basic-concepts-in-machine-learning</b>", "snippet": "What are the <b>basic concepts in machine learning</b>? I found that the best way to discover and get a handle on the <b>basic concepts in machine learning</b> is to review the introduction chapters to <b>machine learning</b> textbooks and to watch the videos from the first model in online courses. Pedro Domingos is a lecturer and professor on <b>machine learning</b> at the University of Washing and", "dateLastCrawled": "2022-02-02T15:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Is training <b>a neural network</b> like forming a habit? | Blog", "url": "https://jmsbrdy.com/blog/habit-formation-as-analogy-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://jmsbrdy.com/blog/habit-formation-as-<b>analogy</b>-for-<b>machine</b>-<b>learning</b>", "snippet": "Reward: during backpropagation, update our input weights according to the <b>loss</b> function; In fact, the <b>analogy</b> also works at the level of the network as a whole: Cue: transform our input example and input it into the first layer of the network; Routine: the network processes the input through its layers to produce a result; Reward: calculate how accurate the result is \u2013 compared to the labeling of the input example \u2013 and backpropagate; So, from a process perspective there do seem to broad ...", "dateLastCrawled": "2021-12-29T12:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Why <b>Machine Learning Is A Metaphor For</b> Life \u2013 Adit Deshpande ...", "url": "https://adeshpande3.github.io/Why-Machine-Learning-is-a-Metaphor-For-Life", "isFamilyFriendly": true, "displayUrl": "https://adeshpande3.github.io/Why-<b>Machine-Learning-is-a-Metaphor-For</b>-Life", "snippet": "Another cool <b>analogy</b> is that of the epsilon greedy policy. This is a term used in reinforcement <b>learning</b> to fight the problem of exploration vs exploitation. The basic idea is that the RL agent will take a random action (instead of the optimal action according to its current policy) with probability \u03b5, in hope of searching a larger area of the state space, and eventually getting a better reward.", "dateLastCrawled": "2022-01-31T13:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The intuition of <b>Triplet Loss</b>. Getting an essence of how <b>loss</b> is\u2026 | by ...", "url": "https://medium.com/analytics-vidhya/triplet-loss-b9da35be21b8", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>triplet-loss</b>-b9da35be21b8", "snippet": "Many of us feel <b>Machine</b> <b>learning</b> is a black box that takes some input and gives out some fantastic output. In recent years, this same Black box has been creating wonders by acting as a mimic of\u2026", "dateLastCrawled": "2022-01-23T03:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>About loss and loss functions</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2019/10/04/about-loss-and-loss-functions/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2019/10/04/<b>about-loss-and-loss-functions</b>", "snippet": "The high-level supervised <b>learning</b> process. Before we can actually introduce the concept of loss, we\u2019ll have to take a look at the high-level supervised <b>machine</b> <b>learning</b> process.All supervised training approaches fall under this process, which means that it is equal for deep neural networks such as MLPs or ConvNets, but also for SVMs.. Let\u2019s take a look at this training process, which is cyclical in nature.", "dateLastCrawled": "2022-01-25T13:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>machine</b> <b>learning</b> - Why there is sudden drop in loss after every epoch ...", "url": "https://stackoverflow.com/questions/57248723/why-there-is-sudden-drop-in-loss-after-every-epoch", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/57248723", "snippet": "<b>machine</b>-<b>learning</b> keras deep-<b>learning</b> loss-function. Share. Follow edited Jul 29 &#39;19 at 12:40. Community Bot. 1 1 1 silver badge. asked Jul 29 &#39;19 at 7:09. Rahul Anand Rahul Anand. 389 1 1 gold badge 3 3 silver badges 15 15 bronze badges. Add a comment | 2 Answers Active Oldest Votes. 11 Note: This answer is assuming you are using Keras -- you might want to add this information to your post or at least add a relevant tag. ...", "dateLastCrawled": "2022-01-21T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>machine</b> <b>learning</b> - In training a triplet network, I first have a solid ...", "url": "https://stats.stackexchange.com/questions/475655/in-training-a-triplet-network-i-first-have-a-solid-drop-in-loss-but-eventually", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/475655/in-training-a-triplet-network-i-first...", "snippet": "Changing the losses changes the tasks, so comparing the value of semi-hard loss to batch hard <b>loss is like</b> comparing apples to oranges. Because of how semi-hard loss is defined, its value will always be smaller than ordinary triplet loss. But we still want to achieve the inequality $(*)$! To make a consistent comparison as training progresses, you should measure the loss on the hardest task throughout training to confirm that the model is, indeed, improving as you change tasks during ...", "dateLastCrawled": "2022-02-03T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Comparing images in frequency domain. \u201cSpectral loss\u201d \u2013 does it make ...", "url": "https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss-does-it-make-sense/", "isFamilyFriendly": true, "displayUrl": "https://bartwronski.com/2021/07/06/comparing-images-in-frequency-domain-spectral-loss...", "snippet": "Recently, numerous academic papers in the <b>machine</b> <b>learning</b> / computer vision / image processing domains (re)introduce and discuss a \u201cfrequency loss function\u201d or &quot;spectral loss&quot; - and while for many it makes sense and nicely improves achieved results, some of them define or use it wrongly. The basic idea is - instead of comparing pixels\u2026", "dateLastCrawled": "2022-01-28T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "neural networks - Explanation of <b>Spikes</b> in training loss vs. iterations ...", "url": "https://stats.stackexchange.com/questions/303857/explanation-of-spikes-in-training-loss-vs-iterations-with-adam-optimizer", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/303857/explanation-of-<b>spikes</b>-in-training...", "snippet": "Cross Validated is a question and answer site for people interested in statistics, <b>machine</b> <b>learning</b>, data analysis, data mining, and data visualization. It only takes a minute to sign up. Sign up to join this community. Anybody can ask a question Anybody can answer The best answers are voted up and rise to the top Home Public; Questions; Tags Users Unanswered Teams. Stack Overflow for Teams \u2013 Collaborate and share knowledge with a private group. Create a free Team What is Teams? Teams ...", "dateLastCrawled": "2022-01-27T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>machine</b> <b>learning</b> - <b>how to classify Iris flowers</b> - Data Science Stack ...", "url": "https://datascience.stackexchange.com/questions/43057/how-to-classify-iris-flowers", "isFamilyFriendly": true, "displayUrl": "https://<b>datascience.stackexchange</b>.com/questions/43057/<b>how-to-classify-iris-flowers</b>", "snippet": "<b>machine</b>-<b>learning</b> neural-network ai. Share. Improve this question. Follow asked Dec 23 &#39;18 at 10:21. Fahd Fahd. 9 1 1 bronze badge $\\endgroup$ 5 $\\begingroup$ If you did that what would be your loss? $\\endgroup$ \u2013 Robin Nicole. Dec 23 &#39;18 at 10:44 ...", "dateLastCrawled": "2022-01-11T15:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[D] Looking for papers on treating regression as classification vs ...", "url": "https://www.reddit.com/r/MachineLearning/comments/7gun87/d_looking_for_papers_on_treating_regression_as/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/7gun87/d_looking_for_papers_on...", "snippet": "Doing the L2 <b>loss is like</b> doing maximum likelihood on a gaussian with a fixed variance - so the bad regression here is largely coming from the gaussian being mis-specified. I think the richer question would involve comparing approaches that consider the ordering vs. approaches that don t consider the ordering but where both have flexible enough distributions.", "dateLastCrawled": "2021-01-17T22:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Alan-D-Chen</b> (<b>Alan D Chen</b>) \u00b7 <b>GitHub</b>", "url": "https://github.com/Alan-D-Chen", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>Alan-D-Chen</b>", "snippet": "\ud83d\udd25 CDIoU and CDIoU <b>loss is like</b> a convenient plug-in that can be used in multiple models. CDIoU and CDIoU loss have different excellent performances in several models such as Faster R-CNN, YOLOv4, Re\u2026 Python 22 6 PCA_ICA_DEMO Public. Demo for PCA(Principal Component Analysis) &amp; ICA(Independent Component Analysis) in data analysis in Python and image separation written in MATLAB Python 8 2 meachine_<b>learning</b> Public. \u7b80\u5355\u7ebf\u6027\u56de\u5f52\uff0c\u591a\u5143\u7ebf\u6027\u56de\u5f52\uff0c\u975e\u7ebf\u6027\u56de\u5f52\uff0cKmeans\u7b97\u6cd5 ...", "dateLastCrawled": "2021-12-29T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Hearing Loss Simulator</b> - Find Out What <b>Hearing Loss is Like</b>", "url": "https://www.starkey.com/hearing-loss-simulator", "isFamilyFriendly": true, "displayUrl": "https://www.starkey.com/<b>hearing-loss-simulator</b>", "snippet": "Find out what they&#39;re experiencing with our <b>Hearing Loss Simulator</b>. Choose a situation. Select the <b>hearing loss</b> level you want to hear. Click Play. Set your computer volume to 50% for the best experience. Start.", "dateLastCrawled": "2022-02-02T08:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "7 <b>Things I\u2019ve Learned Since the Loss of</b> My Child", "url": "https://abedformyheart.com/7-things-since-loss-of-child/", "isFamilyFriendly": true, "displayUrl": "https://abedformyheart.com/7-things-since-loss-of-child", "snippet": "It is no worse than any loss of a child it is just different. I just want a time <b>machine</b> to go back and stop him to hold him and never let him go. It didn\u2019t have to happen I guess that\u2019s why the grief or denial or hope they will walk through the door is felt because you feel you could have stopped it. Maybe we could maybe they would have done it another time. Their are so many questions and no answers X . Reply. foreversadmom says. January 11, 2016 at 4:15 am. Sorry for your loss. I too ...", "dateLastCrawled": "2022-02-03T01:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What\u2019s considered a good Log <b>Loss</b> in <b>Machine</b> <b>Learning</b> ? | by Federico ...", "url": "https://medium.com/@fzammito/whats-considered-a-good-log-loss-in-machine-learning-a529d400632d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@fzammito/whats-considered-a-good-log-<b>loss</b>-in-<b>machine</b>-<b>learning</b>-a529...", "snippet": "Log <b>Loss is similar</b> to the Accuracy, but it will favor models that distinguish more strongly the classes. Log <b>Loss</b> it useful to compare models not only on their output but on their probabilistic ...", "dateLastCrawled": "2022-01-30T14:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Introduction to loss functions used in Deep Metric <b>Learning</b>. | Towards ...", "url": "https://towardsdatascience.com/metric-learning-loss-functions-5b67b3da99a5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metric-<b>learning</b>-loss-functions-5b67b3da99a5", "snippet": "Contributors : Jake Buglione, Sethu Hareesh Kolluru Recent advancements in <b>deep learning</b> have made it possible to learn a similarity measure for a set o f images using a deep metric <b>learning</b> network that maps visually similar images onto nearby locations in an embedding manifold, and visually dissimilar images apart from each other. Deep features learned using this approach result in well discriminative features with compact intra-product variance and well separated inter-product differences ...", "dateLastCrawled": "2022-01-25T23:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> Cats and Dogs\u2019 Breeds Classifier | by Mariana Santos ...", "url": "https://towardsdatascience.com/machine-learning-cats-and-dogs-breeds-classifier-b26a9df45000", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-cats-and-dogs-breeds-classifier-b26a9...", "snippet": "The accuracy of both the training and validation show similar curves and values, and even the train <b>loss is similar</b>, even though it is somewhat lower with the lower <b>learning</b> rate. The biggest difference is in the validation loss. With the larger <b>learning</b> rate, this curve did not converge to a value, probably because it was \u201chopping\u201d through the local minimum, due to the larger step. In this experience, we concluded that 0.001 is the best <b>learning</b> of all compared.", "dateLastCrawled": "2022-01-30T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Key techniques for Evaluating <b>Machine</b> <b>Learning</b> models - Data Analytics", "url": "https://vitalflux.com/key-techniques-evaluating-machine-learning-models-performance/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/key-techniques-evaluating-<b>machine</b>-<b>learning</b>-models-performance", "snippet": "Log loss is used to evaluate the performance of classification <b>machine</b> <b>learning</b> models that are built using classification algorithms such as logistic regression, support vector <b>machine</b> (SVM), random forest, and gradient boosting. The idea behind the use of Log <b>loss is similar</b> to taking a base-e exponential or natural logarithm in order to compare model scores from high-value functions which may indicate poor <b>machine</b> <b>learning</b> model performance. The logarithmic loss value is defined as ...", "dateLastCrawled": "2022-01-31T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "[2110.01601] DiffNet: Neural Field Solutions of Parametric Partial ...", "url": "https://arxiv.org/abs/2110.01601", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2110.01601", "snippet": "Computer Science &gt; <b>Machine</b> <b>Learning</b>. arXiv:2110.01601 (cs) [Submitted on 4 Oct 2021] ... (FEM <b>loss) is similar</b> to an energy functional that produces improved solutions, satisfies \\textit{a priori} mesh convergence, and can model Dirichlet and Neumann boundary conditions. We prove theoretically, and illustrate with experiments, convergence results analogous to mesh convergence analysis deployed in finite element solutions to PDEs. These results suggest that a mesh-based neural network ...", "dateLastCrawled": "2021-10-05T12:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Faster R-CNN step by step, Part II</b> | Notes for <b>machine</b> <b>learning</b>", "url": "https://dongjk.github.io/code/object+detection/keras/2018/06/10/Faster_R-CNN_step_by_step,_Part_II.html", "isFamilyFriendly": true, "displayUrl": "https://dongjk.github.io/code/object+detection/keras/2018/06/10/<b>Faster_R-CNN_step_by</b>...", "snippet": "regression <b>loss is similar</b> to RPN, using smooth l1 loss. there have 800 values but only 4 values are participant the gradient calculation. Summary. In this two posts, we have learnt how to implement <b>Faster R-CNN step by</b> step, how to prepare training data.", "dateLastCrawled": "2022-01-29T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - <b>hinge loss</b> vs logistic loss advantages and ...", "url": "https://stats.stackexchange.com/questions/146277/hinge-loss-vs-logistic-loss-advantages-and-disadvantages-limitations", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/146277/<b>hinge-loss</b>-vs-logistic-loss...", "snippet": "<b>machine</b>-<b>learning</b> svm loss-functions computer-vision. Share. Cite. Improve this question. Follow edited Jul 23 &#39;18 at 15:41. DHW. 644 3 3 silver badges 13 13 bronze badges. asked Apr 14 &#39;15 at 11:18. user570593 user570593. 1,059 2 2 gold badges 12 12 silver badges 19 19 bronze badges $\\endgroup$ Add a comment | 3 Answers Active Oldest Votes. 31 $\\begingroup$ Logarithmic loss minimization leads to well-behaved probabilistic outputs. <b>Hinge loss</b> leads to some (not guaranteed) sparsity on the ...", "dateLastCrawled": "2022-01-26T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Tabular Playground Series \u2013 June 2021 (Part 3) \u2013 <b>MACHINE</b> <b>LEARNING</b> CONCEPTS", "url": "https://srirangatarun.wordpress.com/2021/11/14/tabular-playground-series-june-2021-part-3/", "isFamilyFriendly": true, "displayUrl": "https://srirangatarun.wordpress.com/2021/11/14/tabular-playground-series-june-2021-part-3", "snippet": "The gap between the training and validation <b>loss is similar</b> to that of lightgbm, and lower than that of xgboost. So overfitting is not a major concern here. Additionally, catboost shows a strong LB performance with a score of 1.76 (very close to that of xgboost). catboost\u2019s CPU implementation is very fast compared to that of xgboost. catboost trains 20 estimators in just 6 seconds, compared to xgboost\u2019s 30. catboost, like xgboost, shows an impressive speed-up on GPU, going from 5.780 to ...", "dateLastCrawled": "2022-01-01T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What is an intuitive explanation for the log</b> loss function? - Quora", "url": "https://www.quora.com/What-is-an-intuitive-explanation-for-the-log-loss-function", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-an-intuitive-explanation-for-the-log</b>-loss-function", "snippet": "Answer (1 of 8): To me an intuitive explanation is that minimizing the log loss equals minimizing the Kullback-Leibler divergence (Kullback\u2013Leibler divergence - Wikipedia) between the function you want to optimize (for example a neural network) and the true function that generates the data (from ...", "dateLastCrawled": "2022-01-30T02:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Best <b>Artificial Intelligence</b> Course (AIML) by UT Austin", "url": "https://www.mygreatlearning.com/pg-program-artificial-intelligence-course", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/pg-program-<b>artificial-intelligence</b>-course", "snippet": "In <b>learning</b> a projection where the inputs can be distinguished, the triplet <b>loss is similar</b> to metric <b>learning</b>. The triplet loss is used for understanding the score vectors for the images. You can use the score vectors of face descriptors for verifying the faces in Euclidean Space. Natural Language Processing 4 Quizzes 2 Projects 4 Quizzes 2 Projects Learn how to work with natural language processing with Python using traditional <b>machine</b> <b>learning</b> methods. Then, deep dive into the realm of ...", "dateLastCrawled": "2022-02-01T17:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>learning</b> for metal additive manufacturing: Towards a physics ...", "url": "https://www.sciencedirect.com/science/article/pii/S0278612521002259", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0278612521002259", "snippet": "<b>Machine</b> <b>learning</b> (ML) has shown to be an effective alternative to physical models for quality prediction and process optimization of metal additive manufacturing (AM). However, the inherent \u201cblack box\u201d nature of ML techniques such as those represented by artificial neural networks has often presented a challenge to interpret ML outcomes in the framework of the complex thermodynamics that govern AM. While the practical benefits of ML provide an adequate justification, its utility as a ...", "dateLastCrawled": "2022-01-27T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "commonplace book redux \u2013 a diary of quotations", "url": "https://quotables.github.io/", "isFamilyFriendly": true, "displayUrl": "https://quotables.github.io", "snippet": "English-<b>learning</b> infants under the age of six months distinguish phonemes used in Czech, Hindi, and Inslekampx (a Native American language), but English-speaking adults cannot, even with five hundred trials of training or a year of university coursework. Adult ears can tell the sounds apart, though, when the consonants are stripped from the syllables and presented alone as chirpy sounds; they just cannot tell them apart as phonemes. [\u2026]", "dateLastCrawled": "2022-02-01T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Full text of &quot;91288819 Tosh Pursuit Of History 5th Ed&quot;", "url": "https://archive.org/stream/91288819ToshPursuitOfHistory5thEd/91288819-Tosh-Pursuit-of-History-5th-Ed_djvu.txt", "isFamilyFriendly": true, "displayUrl": "https://archive.org/stream/91288819ToshPursuitOfHistory5thEd/91288819-Tosh-Pursuit-of...", "snippet": "An illustration of a computer application window Wayback <b>Machine</b>. An illustration of an open book. Books. An illustration of two cells of a film strip. Video. An illustration of an audio speaker. Audio. An illustration of a 3.5&quot; floppy disk. Software. An illustration of two photographs. Images. An illustration of a heart shape Donate. An illustration of text ellipses. More. An icon used to represent a menu that can be toggled by interacting with this icon. ...", "dateLastCrawled": "2022-01-31T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Read <b>Mushoku Tensei</b> (WN),Free online novel online reading, online book ...", "url": "https://readnovelfreeonline.com/mushoku-tensei-wn/volume-5-h", "isFamilyFriendly": true, "displayUrl": "https://readnovelfreeonline.com/<b>mushoku-tensei</b>-wn/volume-5-h", "snippet": "If I remember correctly, I was <b>learning</b> swordsmanship at my house. It was an everyday life of being scolded by my father. Even when I put in a bit of work, he would complain about everything and hit me. &quot;Do you think the you of that time could have survived on the Magic Continent?&quot; &quot;Hah, Gisu, that entire premise is strange. Rudi you know, had ...", "dateLastCrawled": "2022-01-29T13:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Notes on <b>Machine</b> <b>Learning</b> 3: <b>Decision theory</b>", "url": "https://cveai.github.io/notes/2018/03/27/mm-ml-3.html", "isFamilyFriendly": true, "displayUrl": "https://cveai.github.io/notes/2018/03/27/mm-ml-3.html", "snippet": "(ML 3.6) The Big Picture (part 2) Core ideas &amp; methods of ML: (not necessarily disjoint) Exact inference (usually not possible) Multivariate Gaussian (very nice) / Conjugate priors / Graphical models (use DP)", "dateLastCrawled": "2022-01-02T01:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What\u2019s My Line? <b>Next Sentence Prediction</b> in RunwayML with BERT | by ...", "url": "https://medium.com/runwayml/whats-my-line-next-sentence-prediction-in-runway-ad76cbf28c86", "isFamilyFriendly": true, "displayUrl": "https://medium.com/runwayml/whats-my-line-<b>next-sentence-prediction</b>-in-runway-ad76cbf28c86", "snippet": "The <b>loss can be thought of as</b> how much the model is surprised by the sequence. The lower the loss, the more likely it judges the sequence to be. Results: I\u2019m not sure what a score of 4.0966539 ...", "dateLastCrawled": "2022-01-31T03:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Defect <b>Detection</b> in Products using Image Segmentation | by Vinithavn ...", "url": "https://medium.com/analytics-vidhya/defect-detection-in-products-using-image-segmentation-a87a8863a9e5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/defect-<b>detection</b>-in-products-using-image...", "snippet": "Dice <b>loss can be thought of as</b> 1-Dice coefficient where Dice coefficient is defined as, Dice coefficient=2* area of overlap area of intersection. You can read more about these metrics here. 5 ...", "dateLastCrawled": "2022-02-03T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Decision-Theoretic Approximations for Machine Learning</b>", "url": "https://www.ijcai.org/Proceedings/13/Papers/487.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/Proceedings/13/Papers/487.pdf", "snippet": "<b>Decision-Theoretic Approximations for Machine Learning</b> M. Ehsan Abbasnejad Abstract Decision theory focuses on the problem of mak-ing decisions under uncertainty. This uncertainty arises from the unknown aspects of the state of the world the decision maker is in or the unknown util- ity function of performing actions. The uncertainty can be modeled as a probability distribution captur-ing our belief about the world the decision maker is in. Upon making new observations, the decision maker ...", "dateLastCrawled": "2022-02-02T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Automatic Di\ufb00erentiation and <b>Neural Networks</b> 1 Introduction", "url": "https://people.cs.umass.edu/~domke/courses/sml2010/07autodiff_nnets.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.umass.edu/~domke/courses/sml2010/07autodiff_nnets.pdf", "snippet": "Statistical <b>Machine</b> <b>Learning</b> Notes 7 Automatic Di\ufb00erentiation and <b>Neural Networks</b> Instructor: Justin Domke 1 Introduction The name \u201cneuralnetwork\u201d is sometimes used torefer tomany things (e.g. Hop\ufb01eld networks, self-organizing maps). In these notes, we are only interested in the most common type of neural network, the multi-layer perceptron. A basic problem in <b>machine</b> <b>learning</b> is function approximation. We have some inputs x\u02c6 and some outputs y\u02c6, and we want to \ufb01t some function f ...", "dateLastCrawled": "2022-01-28T01:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Automatic Di\ufb00erentiation and Neural Networks</b>", "url": "https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf", "snippet": "Statistical <b>Machine</b> <b>Learning</b> Notes 8 <b>Automatic Di\ufb00erentiation and Neural Networks</b> Instructor: Justin Domke Contents 1 Introduction 1 2 Automatic Di\ufb00erentiation 2 3 Multi-Layer Perceptrons 5 4 MNIST 7 5 Backpropagation 10 6 Discussion 13 1 Introduction The name \u201cneuralnetwork\u201d is sometimes used torefer tomany things (e.g. Hop\ufb01eld networks, self-organizing maps). In these notes, we are only interested in the most common type of neural network, the multi-layer perceptron. A basic ...", "dateLastCrawled": "2022-01-28T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A cascaded fully convolutional network framework for dilated pancreatic ...", "url": "https://link.springer.com/article/10.1007/s11548-021-02530-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11548-021-02530-x", "snippet": "Deep-<b>learning</b>-base methods have successfully solved many challenging tasks in image processing, such as classification [8, 25], ... The Dice <b>loss can be thought of as</b> the minimization of the Dice score subtracted by one, which is minimized toward 0 to achieve optimal segmentation performance. Focal loss is proposed to dynamically rescale cross entropy loss and is conducive to imbalance problems . The voxel-wise Focal loss function is expressed as $$\\begin{aligned} {\\mathcal {L}}_F = -\\frac{1 ...", "dateLastCrawled": "2022-01-30T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Exploring deep neural networks via layer-peeled model: Minority ...", "url": "https://www.pnas.org/content/118/43/e2103091118", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/118/43/e2103091118", "snippet": "The remarkable development of deep <b>learning</b> over the past decade relies heavily on sophisticated heuristics and tricks. To better exploit its potential in the coming decade, perhaps a rigorous framework for reasoning about deep <b>learning</b> is needed, which, however, is not easy to build due to the intricate details of neural networks. For near-term purposes, a practical alternative is to develop a mathematically tractable surrogate model, yet maintaining many characteristics of neural networks.", "dateLastCrawled": "2021-12-30T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Adversarial Examples are Just Bugs</b>, Too - Latest articles about <b>machine</b> ...", "url": "https://distill.pub/2019/advex-bugs-discussion/response-5/", "isFamilyFriendly": true, "displayUrl": "https://distill.pub/2019/advex-bugs-discussion/response-5", "snippet": "Adversarial Examples With No Features. Using the above, we can construct adversarial examples which do not suffice for <b>learning</b>. Here, we replicate the Ilyas et al. experiment that \u201cNon-robust features suffice for standard classification\u201d (Section 3.2 of ), but show that it fails for our construction of adversarial examples.. To review, the Ilyas et al. non-robust experiment was:", "dateLastCrawled": "2022-01-31T12:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Network Traffic Anomaly Detection Using Recurrent Neural Networks", "url": "https://www.researchgate.net/publication/324104291_Network_Traffic_Anomaly_Detection_Using_Recurrent_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/324104291_Network_Traffic_Anomaly_Detection...", "snippet": "Next, a supervised <b>machine</b> <b>learning</b> algorithm one-class SVM is trained to generalize the behavior model in order to predict user behavior anomalies. Results show that One-Class SVM is the most ...", "dateLastCrawled": "2022-01-26T23:23:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(loss)  is like +(the error rate of a machine learning algorithm)", "+(loss) is similar to +(the error rate of a machine learning algorithm)", "+(loss) can be thought of as +(the error rate of a machine learning algorithm)", "+(loss) can be compared to +(the error rate of a machine learning algorithm)", "machine learning +(loss AND analogy)", "machine learning +(\"loss is like\")", "machine learning +(\"loss is similar\")", "machine learning +(\"just as loss\")", "machine learning +(\"loss can be thought of as\")", "machine learning +(\"loss can be compared to\")"]}