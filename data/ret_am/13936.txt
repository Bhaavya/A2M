{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>multimodal</b> system of AI and its evolution", "url": "https://analyticsindiamag.com/what-is-the-multimodal-system-of-ai-and-its-evolution/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/what-is-the-<b>multimodal</b>-system-of-ai-and-its-evolution", "snippet": "What is <b>multimodal</b> interaction? As <b>human</b> beings, we experience the world as <b>multimodal</b>: we can feel texture, hear sounds, see objects, smell odours and taste flavours. However, standard AI systems are usually unimodal, meaning they are trained to do a specific task such as processing images or languages. The systems are fed a single sample of training data, from which they are able to identify corresponding images or words. While it is easier to work with a single source of information, it ...", "dateLastCrawled": "2022-01-30T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Multimodal</b> Integration of <b>Human</b>-<b>Like</b> Attention in Visual Question ...", "url": "https://deepai.org/publication/multimodal-integration-of-human-like-attention-in-visual-question-answering", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>multimodal</b>-integration-of-<b>human</b>-<b>like</b>-attention-in...", "snippet": "While the integration of <b>human</b>-<b>like</b> attention on only images (73.67%) or text (73.77% on test-std) can lead to an increase in performance, our full MULAN <b>model</b> employing <b>multimodal</b> integration is the best performing approach. This further underlines the importance of jointly integrating <b>human</b>-<b>like</b> attention on both text and images for the VQA task, which is inherently <b>multimodal</b>.", "dateLastCrawled": "2021-12-30T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Editing <b>Like</b> Humans: A Contextual, <b>Multimodal</b> Framework for Automated ...", "url": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Koorathota_Editing_Like_Humans_A_Contextual_Multimodal_Framework_for_Automated_Video_CVPRW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Koorathota_Editing_<b>Like</b>...", "snippet": "\u2022 evaluate our <b>model</b> through <b>human</b> judgements of CMVE- and <b>human</b> professionally-edited videos in participants recruited on Amazon MTurk. 2. Related Work 2.1. <b>Multimodal</b> Reasoning Whilepastworkusedthespatial-temporalrelationofob-jects in video for retrieval, allowing discrimination power about different video criteria [30], recent research related to <b>multimodal</b> video retrieval has focused on improving natu-ral language descriptors [23] or extracting key events from videos [31, 12 ...", "dateLastCrawled": "2022-01-29T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Mind <b>Model</b> for <b>Multimodal</b> Communicative Creatures &amp; Humanoids", "url": "https://alumni.media.mit.edu/~kris/ftp/IJAAI.pdf", "isFamilyFriendly": true, "displayUrl": "https://alumni.media.mit.edu/~kris/ftp/IJAAI.pdf", "snippet": "This paper presents a computational <b>model</b> of real-time task-oriented dialogue skills. The architecture, termed Ymir, bridges between <b>multimodal</b> perception and <b>multimodal</b> action and supports the creation of autonomous computer characters that afford full-duplex, real-time face-to-face interaction with a <b>human</b>. Ymir has been prototyped in ...", "dateLastCrawled": "2022-01-29T13:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Multimodal</b> models are fast becoming a reality -- consequences be damned ...", "url": "https://venturebeat.com/2021/12/21/multimodal-models-are-fast-becoming-a-reality-consequences-be-damned/", "isFamilyFriendly": true, "displayUrl": "https://<b>venturebeat.com</b>/2021/12/21/<b>multimodal</b>-<b>models</b>-are-fast-becoming-a-reality...", "snippet": "Some hurdles have yet to be overcome, <b>like</b> <b>model</b> bias. But already, <b>multimodal</b> models have been applied to real-world applications including hate speech detection. Promising new directions. Humans ...", "dateLastCrawled": "2022-01-30T18:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "[2109.13139] <b>Multimodal</b> Integration of <b>Human</b>-<b>Like</b> Attention in Visual ...", "url": "https://arxiv.org/abs/2109.13139", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2109.13139", "snippet": "We present the <b>Multimodal</b> <b>Human</b>-<b>like</b> Attention Network (MULAN) - the first method for <b>multimodal</b> integration of <b>human</b>-<b>like</b> attention on image and text during training of VQA models. MULAN integrates attention predictions from two state-of-the-art text and image saliency models into neural self-attention layers of a recent transformer-based VQA <b>model</b>. Through evaluations on the challenging VQAv2 dataset, we show that MULAN achieves a new state-of-the-art performance of 73.98% accuracy on test ...", "dateLastCrawled": "2021-12-25T11:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>MIDA</b>: A <b>Multimodal</b> Imaging-Based Detailed Anatomical <b>Model</b> of the <b>Human</b> ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0124126", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0124126", "snippet": "Computational modeling and simulations are increasingly being used to complement experimental testing for analysis of safety and efficacy of medical devices. Multiple voxel- and surface-based whole- and partial-body models have been proposed in the literature, typically with spatial resolution in the range of 1\u20132 mm and with 10\u201350 different tissue types resolved. We have developed a <b>multimodal</b> imaging-based detailed anatomical <b>model</b> of the <b>human</b> head and neck, named \u201c<b>MIDA</b>\u201d. The <b>model</b> ...", "dateLastCrawled": "2021-09-27T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Combating <b>Human</b> Trafcking with Deep <b>Multimodal</b> Models", "url": "https://aclanthology.org/P17-1142.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/P17-1142.pdf", "snippet": "deep <b>multimodal</b> <b>model</b> called the <b>Human</b> Trafcking Deep Network (HTDN). 1 Introduction <b>Human</b> trafcking a crime that shames us all (UNODC,2008),hasseenasteepriseintheUnited States since 2012. The number of cases reported rose from 3,279 in 2012 to 7,572 in 2016 more than doubling over the course of v e years (Hot-line ...", "dateLastCrawled": "2022-01-29T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Premise-based Multimodal Reasoning: A Human</b>-<b>like</b> Cognitive Process | DeepAI", "url": "https://deepai.org/publication/premise-based-multimodal-reasoning-a-human-like-cognitive-process", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>premise-based-multimodal-reasoning-a-human</b>-<b>like</b>...", "snippet": "<b>Premise-based Multimodal Reasoning: A Human</b>-<b>like</b> Cognitive Process. 05/15/2021 \u2219 by Qingxiu Dong, et al. \u2219 0 \u2219 share . Reasoning is one of the major challenges of <b>Human</b>-<b>like</b> AI and has recently attracted intensive attention from natural language processing (NLP) researchers. However, cross-modal reasoning needs further research.", "dateLastCrawled": "2021-12-14T06:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A Quantum-<b>Like</b> <b>multimodal</b> network framework for modeling interaction ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "snippet": "In this paper, we design a quantum-<b>like</b> <b>multimodal</b> network (QMN) framework, which leverages the mathematical formalism of quantum theory (QT) and a long short-term memory (LSTM) network, to <b>model</b> both intra- and inter-utterance interaction dynamics and recognize speakers\u2019 emotions. The main idea is to use a density matrix-based CNN, a quantum measurement-inspired strong-weak influence <b>model</b> and a quantum interference-inspired <b>multimodal</b> decision fusion approach. The experimental results on ...", "dateLastCrawled": "2022-01-24T13:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Multimodal</b> Characterization of the <b>Human</b> Nucleus Accumbens", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7341972/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7341972", "snippet": "All other tracts examined required supraphysiologic currents to achieve <b>similar</b> levels of <b>model</b> nerve fiber activation. Furthermore, behavioral trends for stimulation as a function of current amplitude on both sides of the brain best matched input-output curves of <b>model</b> nerve fiber activation for projections from the insula. On the right side, both active contacts had <b>similar</b> insular axon activation profiles. On the left side, significantly more insular axons were activated at lower currents ...", "dateLastCrawled": "2021-12-14T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Combating <b>Human</b> Trafcking with Deep <b>Multimodal</b> Models", "url": "https://aclanthology.org/P17-1142.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/P17-1142.pdf", "snippet": "deep <b>multimodal</b> <b>model</b> called the <b>Human</b> Trafcking Deep Network (HTDN). 1 Introduction <b>Human</b> trafcking a crime that shames us all (UNODC,2008),hasseenasteepriseintheUnited States since 2012. The number of cases reported rose from 3,279 in 2012 to 7,572 in 2016 more than doubling over the course of v e years (Hot-line ...", "dateLastCrawled": "2022-01-29T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Multimodal</b> models are fast becoming a reality -- consequences be damned ...", "url": "https://venturebeat.com/2021/12/21/multimodal-models-are-fast-becoming-a-reality-consequences-be-damned/", "isFamilyFriendly": true, "displayUrl": "https://<b>venturebeat.com</b>/2021/12/21/<b>multimodal</b>-<b>models</b>-are-fast-becoming-a-reality...", "snippet": "In a paper published by Stanford\u2019s Institute for <b>Human</b>-Centered Artificial Intelligence (HAI), the coauthors argue that advances in <b>multimodal</b> models like DALL-E will result in higher-quality ...", "dateLastCrawled": "2022-01-30T18:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Deep <b>Multimodal</b> Emotion Recognition on <b>Human</b> Speech: A Review", "url": "https://www.mdpi.com/2076-3417/11/17/7962/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2076-3417/11/17/7962/htm", "snippet": "In order for a <b>multimodal</b> <b>model</b> to function <b>similar</b> to the way our brain perceives multimodality, it should therefore satisfy both of the aforementioned requirements. Based on the above, the two key challenges to address when learning from <b>multimodal</b> data are that: (i) models must learn the complex intra-modal and cross-modal interactions to predict emotional content , and (ii) trained models must be robust to unexpected missing or noisy modalities during testing . The two traditional and ...", "dateLastCrawled": "2022-01-28T11:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "MODEC: <b>Multimodal</b> Decomposable Models for <b>Human</b> Pose Estimation", "url": "https://openaccess.thecvf.com/content_cvpr_2013/papers/Sapp_MODEC_Multimodal_Decomposable_2013_CVPR_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_cvpr_2013/papers/Sapp_MODEC_<b>Multimodal</b>...", "snippet": "We propose a <b>multimodal</b>, decomposable <b>model</b> for ar-ticulated <b>human</b> pose estimation in monocular images. A typical approach to this problem is to use a linear struc- tured <b>model</b>, which struggles to capture the wide range of appearance present in realistic, unconstrained images. In this paper, we instead propose a <b>model</b> of <b>human</b> pose that explicitly captures a variety of pose modes. Unlike other <b>multimodal</b> models, our approach includes both global and local pose cues and uses a convex ...", "dateLastCrawled": "2022-01-30T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Multimodal</b> Probabilistic <b>Model</b>-Based Planning for <b>Human</b>-Robot Interaction", "url": "https://stanfordasl.github.io/wp-content/papercite-data/pdf/Schmerling.Leung.Vollprecht.Pavone.ICRA18.pdf", "isFamilyFriendly": true, "displayUrl": "https://stanfordasl.github.io/wp-content/papercite-data/pdf/Schmerling.Leung...", "snippet": "<b>Multimodal</b> Probabilistic <b>Model</b>-Based Planning for <b>Human</b>-Robot Interaction Edward Schmerling1 Karen Leung 2Wolf Vollprecht3 Marco Pavone Abstract\u2014This paper presents a method for constructing <b>human</b>-robot interaction policies in settings where <b>multimodal</b>-ity, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traf\ufb01c weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars ...", "dateLastCrawled": "2022-01-16T09:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Multimodal Explanations: Justifying Decisions and Pointing</b> to the Evidence", "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Park_Multimodal_Explanations_Justifying_CVPR_2018_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Park_<b>Multimodal</b>_Explanations...", "snippet": "Explaining decisions is an integral part of <b>human</b> com-munication, understanding, and learning, and humans nat- urally provide both deictic (pointing) and textual modali-ties in a typical explanation. We aim to build deep learn-ing models that also are able to explain their decisions with <b>similar</b> \ufb02uency in both visual and textual modalities. Previ-ous machine learning methods for explanation were able to provide a text-only explanation conditioned on an image in context of a task, or were ...", "dateLastCrawled": "2022-01-25T21:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>MULTIMODAL</b> <b>HUMAN</b> ACTION RECOGNITION IN ASSISTIVE <b>HUMAN</b>-ROBOT ...", "url": "http://cvsp.cs.ntua.gr/publications/confr/RKPMKTM_MultimodalHumanActionRecogn-AssistHRI_ICASSP2016.pdf", "isFamilyFriendly": true, "displayUrl": "cvsp.cs.ntua.gr/publications/confr/RKPMKTM_<b>MultimodalHuman</b>ActionRecogn-AssistHRI...", "snippet": "<b>Multimodal</b> <b>human</b> action recognition poses challenges due to distant speech recognition and noise, pronunciation variability, scene noise by other subjects, camera motion and variation in ac- tion/gesture performance. Another source of difculties concerns the nature of our task, i.e. elderly subjects who often articulate or pronounce the <b>multimodal</b> gestures in a loose manner. Overcoming such problems for each modality separately is still open. Further, there are issues related to fusion ...", "dateLastCrawled": "2021-12-21T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Multimodal</b> Emotion Recognition <b>Model</b> using Physiological Signals - <b>NASA/ADS</b>", "url": "https://ui.adsabs.harvard.edu/abs/2019arXiv191112918Z/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2019arXiv191112918Z/abstract", "snippet": "As an important field of research in <b>Human</b>-Machine Interactions, emotion recognition based on physiological signals has become research hotspots. Motivated by the outstanding performance of deep learning approaches in recognition tasks, we proposed a <b>Multimodal</b> Emotion Recognition <b>Model</b> that consists of a 3D convolutional neural network <b>model</b>, a 1D convolutional neural network <b>model</b> and a biologically inspired <b>multimodal</b> fusion <b>model</b> which integrates <b>multimodal</b> information on the decision ...", "dateLastCrawled": "2021-06-18T12:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "An interdisciplinary agent-based <b>multimodal</b> wildfire evacuation <b>model</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1361920921004429", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1361920921004429", "snippet": "These results are <b>similar</b> to those from other disaster research that also found a strong predilection for private vehicles compared with other transportation modes (Lindell et al., 2019). In addition, modal split data provide information about evacuees\u2019 movement through the road network using transportation modes that differ in size and capacity. It is important to account for these behaviors in the wildfire studies since vehicles take more space on the roads than people evacuating by foot.", "dateLastCrawled": "2022-01-28T11:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "MODEC: <b>Multimodal</b> Decomposable Models for <b>Human</b> Pose Estimation", "url": "https://openaccess.thecvf.com/content_cvpr_2013/papers/Sapp_MODEC_Multimodal_Decomposable_2013_CVPR_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_cvpr_2013/papers/Sapp_MODEC_<b>Multimodal</b>...", "snippet": "<b>can</b> <b>be thought</b> of as a typical unimodal <b>model</b> over yc, one <b>model</b> for each value of zc. Hence, we refer to these terms as mode-speci\ufb01c submodels. The bene\ufb01ts of such a <b>model</b> over a non-<b>multimodal</b> one s(x,y) is that different modeling behaviors <b>can</b> be captured by the different mode submodels. This introduces bene\ufb01cial \ufb02exibility, especially", "dateLastCrawled": "2022-01-30T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Multimodal human\u2013computer interaction</b>: A survey - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1077314206002335", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1077314206002335", "snippet": "In general, vision-based <b>human</b> motion analysis systems used for MMHCI <b>can</b> <b>be thought</b> of as having mainly four stages: (1) motion segmentation, (2) object classification, (3) tracking, and (4) interpretation. While some approaches use geometric primitives to <b>model</b> different components (e.g., cylinders used to <b>model</b> limbs, head, and torso for body movements, or for hand and fingers in gesture recognition), others use feature representations based on appearance (appearance-based methods). In ...", "dateLastCrawled": "2022-02-02T17:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "the <b>multimodal</b> counseling <b>model</b> - JSTOR", "url": "https://www.jstor.org/stable/24008713", "isFamilyFriendly": true, "displayUrl": "https://www.jstor.org/stable/24008713", "snippet": "understanding and meeting <b>human</b> needs? What is its promise for the future? The <b>multimodal</b> <b>model</b> of counseling is not yet 10 years old. Because these early years in the <b>model</b>&#39;s development have provided a foundation for the growth and maturation of the <b>model</b>, it is not too early to begin asking questions about that foundation. The answers to these questions should identify some strengths and weaknesses of the foundation and may indicate if the <b>multimodal</b> <b>model</b> is about to take its place among ...", "dateLastCrawled": "2021-10-23T19:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Multimodal</b> models are fast becoming a reality -- consequences be damned ...", "url": "https://venturebeat.com/2021/12/21/multimodal-models-are-fast-becoming-a-reality-consequences-be-damned/", "isFamilyFriendly": true, "displayUrl": "https://<b>venturebeat.com</b>/2021/12/21/<b>multimodal</b>-<b>models</b>-are-fast-becoming-a-reality...", "snippet": "It describes a <b>multimodal</b> <b>model</b> called Guided Language to Image Diffusion for Generation and Editing (GLIDE), which \u2014 like DALL-E \u2014 <b>can</b> create photos given a short text caption. But GLIDE <b>can</b> ...", "dateLastCrawled": "2022-01-30T18:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Visual and Affective <b>Multimodal</b> Models of Word Meaning in Language and Mind", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7816238/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7816238", "snippet": "The random walks <b>can</b> <b>be thought</b> of as a vector with the same dimensionality as the number of nodes in the graph where each element corresponds to a weighted sum of direct and indirect paths, with longer paths receiving a lower weight. The random walks implement the idea of spreading activation over a semantic network. To limit the contribution of long paths, a decay parameter \u03b1 was set to 0.75, in line with De Deyne, Navarro, et al. . This algorithm is similar to other approaches ...", "dateLastCrawled": "2022-01-31T10:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The origin <b>of human multi-modal communication</b> | Philosophical ...", "url": "https://royalsocietypublishing.org/doi/10.1098/rstb.2013.0302", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rstb.2013.0302", "snippet": "The accumulations <b>can</b> <b>be thought</b> of as strata, and peeling away the strata successively <b>can</b> give us some insights into the probable evolution of the whole complex system. This holistic account of our communicational capacities also helps to bridge the gulf between the articulate species and our inarticulate cousins, allowing us to see precursor adaptations in, for example, the turn-taking widely if sparsely represented in current primates and the gestural skills of great apes.", "dateLastCrawled": "2022-01-29T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Challenges and opportunities of multimodal</b> data in <b>human</b> learning: The ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/jcal.12542", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/jcal.12542", "snippet": "Using these devices, researchers <b>can</b> collect data such as heart rate, gaze, electrophysiological activity of the brain, or facial expressions data, to study and <b>model</b> learning strategies (Mangaroska et al., 2018; Worsley &amp; Blikstein, 2015), to predict high-level constructs such as learner attention and engagement (Chan et al., 2020), to design <b>multimodal</b> learning interfaces (Echeverria et al., 2019), or to generate insights about teaching at a more fine-grained levels (Martinez-Maldonado ...", "dateLastCrawled": "2022-01-12T18:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A <b>Model</b> for <b>Multimodal</b> Reference Resolution", "url": "https://aclanthology.org/J00-2002.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/J00-2002.pdf", "snippet": "manuals) and from the point of view of <b>human</b>-computer interaction (HCI) where it <b>can</b> help in the design of computer interfaces in which the interpretation constraints of <b>multimodal</b> messages should be taken into account. Consider Figure 1 (adapted from Rist [1996]) in which a message is expressed through two different modalities, namely text and graphics. The figure illustrates a kind of reasoning required to understand <b>multimodal</b> presentations: in order to make sense of the message, the ...", "dateLastCrawled": "2022-01-30T09:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Editing Like Humans: A Contextual, <b>Multimodal</b> Framework for Automated ...", "url": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Koorathota_Editing_Like_Humans_A_Contextual_Multimodal_Framework_for_Automated_Video_CVPRW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Koorathota_Editing_Like...", "snippet": "\u2022 evaluate our <b>model</b> through <b>human</b> judgements of CMVE- and <b>human</b> professionally-edited videos in participants recruited on Amazon MTurk. 2. Related Work 2.1. <b>Multimodal</b> Reasoning Whilepastworkusedthespatial-temporalrelationofob-jects in video for retrieval, allowing discrimination power about different video criteria [30], recent research related to <b>multimodal</b> video retrieval has focused on improving natu-ral language descriptors [23] or extracting key events from videos [31, 12 ...", "dateLastCrawled": "2022-01-29T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>multimodal</b> stereovision framework to <b>model</b> wildfires", "url": "http://researchfeatures.com/multimodal-stereovision-framework-model-wildfires/", "isFamilyFriendly": true, "displayUrl": "researchfeatures.com/<b>multimodal</b>-stereovision-framework-<b>model</b>-wildfires", "snippet": "<b>Thought</b> Leaders. <b>Thought</b> Leaders . Uncategorized. Uncategorized . More results... A <b>multimodal</b> stereovision framework to <b>model</b> wildfires. October 20, 2021 Earth &amp; Environment; Article Detail Download PDF. Wildfires propagate in a chaotic way so finding patterns in their spread would help us understand how best to tackle them. Dr Lucile Rossi from the University of Corsica, France, is a lead scientist in the field of image processing. Dr Rossi proposes a system of <b>multimodal</b> vision, using ...", "dateLastCrawled": "2022-01-15T17:52:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>multimodal</b> system of AI and its evolution", "url": "https://analyticsindiamag.com/what-is-the-multimodal-system-of-ai-and-its-evolution/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/what-is-the-<b>multimodal</b>-system-of-ai-and-its-evolution", "snippet": "What is <b>multimodal</b> interaction? As <b>human</b> beings, we experience the world as <b>multimodal</b>: we <b>can</b> feel texture, hear sounds, see objects, smell odours and taste flavours. However, standard AI systems are usually unimodal, meaning they are trained to do a specific task such as processing images or languages. The systems are fed a single sample of training data, from which they are able to identify corresponding images or words. While it is easier to work with a single source of information, it ...", "dateLastCrawled": "2022-01-30T17:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Combating <b>Human</b> Trafcking with Deep <b>Multimodal</b> Models", "url": "https://aclanthology.org/P17-1142.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/P17-1142.pdf", "snippet": "deep <b>multimodal</b> <b>model</b> called the <b>Human</b> Trafcking Deep Network (HTDN). 1 Introduction <b>Human</b> trafcking a crime that shames us all (UNODC,2008),hasseenasteepriseintheUnited States since 2012. The number of cases reported rose from 3,279 in 2012 to 7,572 in 2016 more than doubling over the course of v e years (Hot-line ...", "dateLastCrawled": "2022-01-29T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Human</b> vs Machine: Establishing a <b>Human</b> Baseline for <b>Multimodal</b> Location ...", "url": "https://www.icsi.berkeley.edu/pubs/multimedia/humanmachine13.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.icsi.berkeley.edu/pubs/multimedia/<b>human</b>machine13.pdf", "snippet": "<b>Human</b> vs Machine: Establishing a <b>Human</b> Baseline for <b>Multimodal</b> Location Estimation Jaeyoung Choi1, Howard Lei1, Venkatesan Ekambaram2, Pascal Kelm3, Luke Gottlieb1, Thomas Sikora3, Kannan Ramchandran2 and Gerald Friedland1 1International Computer Science Institute, Berkeley, CA, USA 2Department of Electrical Engineering and Computer Sciences, UC Berkeley, Berkeley, CA, USA 3Communication Systems Group, Technische Universit\u00e4t Berlin, Germany 1{jaeyoung,hlei,luke,fractor}@icsi.berkeley.edu 2 ...", "dateLastCrawled": "2022-01-06T13:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Multimodal</b> Integration of <b>Human</b>-Like Attention in Visual Question ...", "url": "https://deepai.org/publication/multimodal-integration-of-human-like-attention-in-visual-question-answering", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>multimodal</b>-integration-of-<b>human</b>-like-attention-in...", "snippet": "To <b>model</b> <b>human</b>-like attention on text we make use of the recently proposed Text Saliency <b>Model</b> (TSM) ... Specifically, we <b>compared</b> <b>multimodal</b> with text-only, image-only, and integration of <b>human</b>-like attention. Afterwards, we evaluated performance of the <b>multimodal</b> method when integrating <b>human</b>-like attention at different layers of the Transformer network. Finally, we evaluated more fine-grained performance values of the <b>multimodal</b>, unimodal, and no attention integration method for the ...", "dateLastCrawled": "2021-12-30T14:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Multimodal</b> models are fast becoming a reality -- consequences be damned ...", "url": "https://venturebeat.com/2021/12/21/multimodal-models-are-fast-becoming-a-reality-consequences-be-damned/", "isFamilyFriendly": true, "displayUrl": "https://<b>venturebeat.com</b>/2021/12/21/<b>multimodal</b>-<b>models</b>-are-fast-becoming-a-reality...", "snippet": "\u201cWe hope that Merlot <b>can</b> inspire future work for learning vision plus language representations in a more <b>human</b>-like fashion <b>compared</b> to ... It describes a <b>multimodal</b> <b>model</b> called Guided Language ...", "dateLastCrawled": "2022-01-30T18:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretable Multimodal Routing for Human Multimodal Language</b> | DeepAI", "url": "https://deepai.org/publication/interpretable-multimodal-routing-for-human-multimodal-language", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>interpretable-multimodal-routing-for-human-multimodal</b>...", "snippet": "In our experiments, we provide both global and local interpretation using <b>Multimodal</b> Routing on sentiment analysis and emotion prediction, without loss of performance <b>compared</b> to state-of-the-art methods. For example, we observe that our <b>model</b> relies mostly on the text modality for neutral sentiment predictions, the acoustic modality for extremely negative predictions, and the text-acoustic bimodal interaction for extremely positive predictions.", "dateLastCrawled": "2021-12-29T00:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep learning based <b>multimodal complex human activity recognition</b> using ...", "url": "https://link.springer.com/article/10.1007/s10489-020-02005-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10489-020-02005-7", "snippet": "<b>Compared</b> with simple <b>human</b> activity (SHA) recognition, complex <b>human</b> activity (CHA) recognition faces more challenges, e.g., various modalities of input and long sequential information. In this paper, we propose a deep learning <b>model</b> named DEBONAIR (Deep lEarning Based <b>multimodal cOmplex humaN Activity Recognition</b>) to address these problems, which is an end-to-end <b>model</b> extracting features systematically. We design specific sub-network architectures for different sensor data and merge the ...", "dateLastCrawled": "2022-02-02T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Multimodal 3D Human Pose Estimation from a Single Image</b>", "url": "https://facstaff.elon.edu/sspurlock/papers/spurlock19_mdnpose.pdf", "isFamilyFriendly": true, "displayUrl": "https://facstaff.elon.edu/sspurlock/papers/spurlock19_mdnpose.pdf", "snippet": "We propose a <b>model</b> that predicts a <b>multimodal</b> prob-ability distribution over the possible output values by in-corporating Mixture Density Networks (MDNs) [2]. This approach allows for more accurate modeling of the ambi-guity in <b>human</b> pose <b>compared</b> with traditional averaging methods. Predicted distributions <b>can</b> also be naturally ag-gregated over a sequence of frames for video prediction or a set of cameras for multi-view prediction. 1.2. Modeling Joint Dependencies There have been a variety ...", "dateLastCrawled": "2022-01-25T04:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "AttnSense: Multi-level Attention Mechanism For <b>Multimodal</b> <b>Human</b> ...", "url": "https://www.ijcai.org/Proceedings/2019/0431.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijcai.org/Proceedings/2019/0431.pdf", "snippet": "ral network <b>model</b> called AttnSense for <b>multimodal</b> <b>human</b> activity recognition. AttnSense introduce the framework of combining attention mechanism with a convolutional neural network (CNN) and a Gated Recurrent Units (GRU) network to capture the de- pendencies of sensing signals in both spatial and temporal domains, which shows advantages in prior-itized sensor selection and improves the comprehen-sibility. Extensive experiments based on three public datasets show that AttnSense achieves a ...", "dateLastCrawled": "2022-01-30T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Multimodal</b> End-to-End Sparse <b>Model</b> for Emotion Recognition", "url": "https://aclanthology.org/2021.naacl-main.417.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/2021.naacl-main.417.pdf", "snippet": "overhead <b>compared</b> to the two-phase pipeline, and exhaustively processing all the data points makes it computationally expensive and prone to over-\ufb01tting. Thus, to mitigate these side-effects, we also propose a <b>multimodal</b> end-to-end sparse <b>model</b>, a combination of a sparse cross-modal attention mechanism and sparse Convolutional Neural Net-work (CNN) (Graham and van der Maaten,2017), to select the most relevant features for the task and reduce the redundant information and noise in the video ...", "dateLastCrawled": "2022-02-03T03:55:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Towards <b>Multimodal</b> <b>Machine</b> <b>Learning</b> Prediction of Individual Cognitive ...", "url": "http://oliverychen.github.io/files/doc/Stijn_Denissen_et_al.pdf", "isFamilyFriendly": true, "displayUrl": "oliverychen.github.io/files/doc/Stijn_Denissen_et_al.pdf", "snippet": "used to learn the function is the <b>model</b> of choice. The concept can be clari\ufb01ed by means of an <b>analogy</b>; a student studying for a future exam. In the \ufb01rst phase, the student will gather knowledge on the domain by using available resources such as books and lecture notes (training). The student subsequently veri\ufb01es whether additional study is necessary by completing an exam from previous years to which the answers are available (validation). Together, this is called the training phase. As ...", "dateLastCrawled": "2022-01-04T13:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A <b>multilayer multimodal detection and prediction</b> <b>model</b> based on ...", "url": "https://www.nature.com/articles/s41598-021-82098-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-021-82098-3", "snippet": "An interpretable <b>machine</b> <b>learning</b> <b>model</b> for diagnosis of Alzheimer\u2019s disease. PeerJ 7 , e6543 (2019). PubMed PubMed Central Article Google Scholar", "dateLastCrawled": "2022-02-02T22:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Man-<b>Machine</b> Oral and <b>Multimodal</b> Communication", "url": "https://www.irisa.fr/ra2007/cordial.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.irisa.fr/ra2007/cordial.pdf", "snippet": "3.4.<b>Machine</b> <b>learning</b> in dialogue systems5 3.4.1.Grammatical inference.6 3.4.2.Nearest Neighbors <b>learning</b> of tree structures6 3.4.3.<b>Learning</b> by <b>analogy</b> in sequences and trees structures7 3.4.3.1.Solving analogical equations7 3.4.3.2.Aims of this study7 3.4.4.<b>Learning</b> to improve the dialogue management8 3.5.Speech Processing8", "dateLastCrawled": "2021-11-18T19:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Quantum-Like <b>multimodal</b> network framework for modeling interaction ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253520302554", "snippet": "Our double-slit experiment <b>analogy</b> for <b>multimodal</b> sentiment analysis. We use the wave function \u03c6(x) ... <b>Multimodal</b> deep <b>learning</b> (MDL) <b>model</b>: this <b>model</b> can learn a joint representation of various features extracted in different modalities, which is similar to the method proposed in . In , the authors used a restricted Boltzmann <b>machine</b> (RBM) to learn the joint distribution over image and text inputs. We choose to replace the RBM with a convolutional neural network (CNN) to learn the joint ...", "dateLastCrawled": "2022-01-24T13:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>machine</b> <b>learning</b> - How to identify the modes in a (<b>multimodal</b> ...", "url": "https://stackoverflow.com/questions/51179095/how-to-identify-the-modes-in-a-multimodal-continuous-variable", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/51179095", "snippet": "<b>machine</b>-<b>learning</b> statistics probability probability-density kernel-density. Share. Follow asked Jul 4 &#39;18 at 18:12. Paulo Paulo. 73 3 3 ... I&#39;ll recommend a mixture density <b>model</b>, with varying numbers of components. E.g. mixture with 1 component, mixture with 2 components, 3, 4, 5, etc. Note that with k components, the maximum possible number of modes is k, although, depending on the locations and scales of the components, there might be fewer modes. There are probably many libraries which ...", "dateLastCrawled": "2022-01-03T12:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Adaptive Modality Distillation for Separable <b>Multimodal</b> Sentiment Analysis", "url": "http://sentic.net/modality-distillation-for-multimodal-sentiment-analysis.pdf", "isFamilyFriendly": true, "displayUrl": "sentic.net/modality-distillation-for-<b>multimodal</b>-sentiment-analysis.pdf", "snippet": "Consider a <b>machine</b> <b>learning</b> processing with the training data formulated by a collection of triplets f(x 1;x 1;y 1);:::::;(x n;x n;y n)g, where the (x i;y i) is the data-label pair commonly used in supervised <b>learning</b> tasks and can be accessed during the whole <b>learning</b> procedure. x i is the input data (feature) and y i is its label. The novel element x i represents the heterogeneous data of x i with different modalities and it is missing during the inference procedure. Thus, x i works as the ...", "dateLastCrawled": "2021-10-30T23:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Preliminary performance study of a brief review on <b>machine</b> <b>learning</b> ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "snippet": "<b>Analogy</b>-based effort estimation is the major task of software engineering which estimates the effort required for new software projects using existing histories for corresponding development and management. In general, the high accuracy of software effort estimation techniques can be a non-solvable problem we named as multi-objective problem. Recently, most of the authors have been used <b>machine</b> <b>learning</b> techniques for the same process however not possible to meet the higher performance ...", "dateLastCrawled": "2022-01-02T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Structure-Mapping: A Computational Model of Analogy and</b> Similarity", "url": "https://www.qrg.northwestern.edu/ideas/smeidea.htm", "isFamilyFriendly": true, "displayUrl": "https://www.qrg.northwestern.edu/ideas/smeidea.htm", "snippet": "<b>Analogy</b> is also crucial in <b>learning</b> from instruction and in aligning experiential knowledge with knowledge gained via instruction. We have built a set of computational tools to facilitate detailed modeling of human analogical <b>learning</b> and reasoning. Our tools are accountable cognitive simulations. What we mean by this is that we use a theoretically-driven decomposition of the processes being simulated. Any choices that are not determined by the theory (i.e., are empirically open) are made ...", "dateLastCrawled": "2022-01-26T15:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - What is the difference between multi-agent and multi ...", "url": "https://ai.stackexchange.com/questions/13794/what-is-the-difference-between-multi-agent-and-multi-modal-systems", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/13794/what-is-the-difference-between-multi...", "snippet": "<b>Multimodal</b> interaction (MI) refers to the interaction with a system (e.g. a computer) using multiple modalities (e.g. speech or gestures). For example, we usually can interact with a laptop using a keyboard and a touchpad (or mouse), so the keyboard and the touchpad are the two different modalities that are used to interact with the computer. MI could thus be considered a sub-field of", "dateLastCrawled": "2022-01-11T08:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Building a <b>Benchmark for Human-Level Concept Learning and Reasoning</b> ...", "url": "https://developer.nvidia.com/blog/building-a-benchmark-for-human-level-concept-learning-and-reasoning/", "isFamilyFriendly": true, "displayUrl": "https://developer.nvidia.com/blog/building-a-<b>benchmark-for-human-level-concept</b>...", "snippet": "Even though today\u2019s <b>machine</b> <b>learning</b> models excel with an abundance of training data on standard recognition tasks, a considerable gap exists between <b>machine</b>-level pattern recognition and human-level concept <b>learning</b>. Over 50 years ago, M. M. Bongard, a Russian computer scientist, invented a collection of one hundred human-designed visual recognition tasks, now named the Bongard problems (BPs), aiming to narrow the gap. According to Harry Foundalis, BPs allow us to get a glimpse at the ...", "dateLastCrawled": "2022-01-29T09:08:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(multimodal model)  is like +(human)", "+(multimodal model) is similar to +(human)", "+(multimodal model) can be thought of as +(human)", "+(multimodal model) can be compared to +(human)", "machine learning +(multimodal model AND analogy)", "machine learning +(\"multimodal model is like\")", "machine learning +(\"multimodal model is similar\")", "machine learning +(\"just as multimodal model\")", "machine learning +(\"multimodal model can be thought of as\")", "machine learning +(\"multimodal model can be compared to\")"]}