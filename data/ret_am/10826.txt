{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Use Timesteps in LSTM Networks for <b>Time Series Forecasting</b>", "url": "https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/use-<b>timestep</b>s-lstm-networks-<b>time-series-forecasting</b>", "snippet": "Transform the <b>time</b> series into a supervised <b>learning</b> problem. Specifically, the organization of data into input and output patterns where the observation at the previous <b>time step</b> is used as an input to forecast the observation at the current <b>time</b> <b>timestep</b>; Transform the observations to have a specific scale. Specifically, to rescale the data ...", "dateLastCrawled": "2022-02-02T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>One</b> <b>Timestep</b> is All You Need: Training Spiking Neural Networks with ...", "url": "https://deepai.org/publication/one-timestep-is-all-you-need-training-spiking-neural-networks-with-ultra-low-latency", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>one</b>-<b>timestep</b>-is-all-you-need-training-spiking-neural...", "snippet": "If we unroll SNNs in <b>time</b>, it becomes obvious that each <b>timestep</b> adds a hidden state to a spiking neuron. Thus, reducing latency compresses the SNNs in the temporal axis and the eventual unit <b>timestep</b> network consists of a single forward pass, with no internal states. From a related perspective, we can perceive gradual latency reduction as sequential temporal distillation, where at each step, the network with higher timesteps acts as the teacher, while the student network with reduced ...", "dateLastCrawled": "2021-12-30T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Time-series</b> Forecasting using Conv1D-LSTM : Multiple timesteps into ...", "url": "https://shivapriya-katta.medium.com/time-series-forecasting-using-conv1d-lstm-multiple-timesteps-into-future-acc684dcaaa", "isFamilyFriendly": true, "displayUrl": "https://shivapriya-katta.medium.com/<b>time-series</b>-forecasting-using-conv1d-lstm-multiple...", "snippet": "This adds a great benefit in <b>time series</b> forecasting, where classical linear methods can be difficult to adapt to multivariate or multiple input forecasting problems (A side <b>note</b> here for multivariate forecasting \u2014 keep in mind that when we use multivariate data for forecasting, then we also need \u201cfuture multi-variate\u201d input data to predict the future outcome!\u2026to mitigate this we have two methods discussed below.)", "dateLastCrawled": "2022-02-02T16:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Is it possible to take more than <b>one</b> action per <b>timestep</b>? - Unity Forum", "url": "https://forum.unity.com/threads/is-it-possible-to-take-more-than-one-action-per-timestep.1148348/", "isFamilyFriendly": true, "displayUrl": "https://forum.unity.com/threads/is-it-possible-to-take-more-than-<b>one</b>-action-per...", "snippet": "This is due to the RL formulations where the process is defined as series of (observation, action, reward) pairs. On that <b>note</b>, none of those environment stepping are tied to wall-clock <b>time</b>, or <b>timestep</b>. So it might helpful to clarify more on what you mean by &quot;take as many actions per <b>timestep</b> as possible without slowing down the scene&quot;.", "dateLastCrawled": "2022-01-19T11:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "machine <b>learning</b> - What is the input to LSTM exactly? - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/49883290/what-is-the-input-to-lstm-exactly", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/49883290", "snippet": "Input <b>timestep</b> 1: node 1 = 0, node 2 = 5, node 3 = 0 next <b>timestep</b>: node 1 = 4, node 2 = 3, node 3 = 3 last <b>timestep</b>: node 1 = 2, node 2 = 1, node 3 = - so again each node gets a different input but this <b>time</b> the window doesn\u2019t slide over the list it rather jumps. In this case each number is only <b>one</b> <b>time</b> presented to the LSTM.", "dateLastCrawled": "2022-01-20T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Tutorial on LSTMs: A Computational Perspective | by Manu Rastogi ...", "url": "https://towardsdatascience.com/tutorial-on-lstm-a-computational-perspective-f3417442c2cd", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/tutorial-on-<b>lstm</b>-a-computational-perspective-f3417442c2cd", "snippet": "<b>LSTM</b> input outputs and the corresponding equations for a single <b>timestep</b>. <b>Note</b> that the <b>LSTM</b> equations also generate f(t), i(t), c\u2019(t) these are for internal consumption of the <b>LSTM</b> and are used for generating c(t) and h(t). There are a few key points to <b>note</b> from the above: The above equations are for only a <b>one</b>-<b>time step</b>. This means that ...", "dateLastCrawled": "2022-02-03T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "ANSYS Fluent transient simulation <b>timestep</b> is very small? : CFD", "url": "https://www.reddit.com/r/CFD/comments/s5ic46/ansys_fluent_transient_simulation_timestep_is/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/CFD/comments/s5ic46/ansys_fluent_transient_simulation_<b>timestep</b>_is", "snippet": "If you want to increase the <b>time step</b> without losing the information, try to get a slightly coarser mesh, wherever possible. Also use adaptive <b>time</b> steps instead of fixed <b>time</b> steps. (I don\u2019t remember how the fluent adaptive menu looks <b>like</b>, but it is controlled by CFL number as the criteria). The system will automatically \u201caccelerate\u201d and decelerate the solution based on local courant number. (For most cases, cfl&lt;=0.5, but sometimes even cfl~1 is acceptable). Good luck", "dateLastCrawled": "2022-01-18T15:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is the difference between LSTM with <b>one</b> <b>timestep</b> and MLP? - Quora", "url": "https://www.quora.com/What-is-the-difference-between-LSTM-with-one-timestep-and-MLP", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-LSTM-with-<b>one</b>-<b>timestep</b>-and-MLP", "snippet": "Answer (1 of 6): Basically yes, the only difference will be, that you not just perform a single forward pass but three of them, also these operations will include information from the networks memory, which in theory could be reformulated as a simple bias if the hidden state vector was fixed.", "dateLastCrawled": "2022-01-22T01:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "tensorflow - How does the Transformer predict n steps into the future ...", "url": "https://datascience.stackexchange.com/questions/90441/how-does-the-transformer-predict-n-steps-into-the-future", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/90441/how-does-the-transformer-predict...", "snippet": "At training <b>time</b>, you pass to the Transformer model both the source and target tokens, just <b>like</b> what you do with LSTMs or GRUs with teacher forcing, which is the default way of training them. <b>Note</b> that, in the Transformer decoder, we need to apply masking to avoid the predictions depending on the current and future tokens. At inference <b>time</b>, we don&#39;t have the target tokens (because that is what we are trying to predict). In this case, the decoder input in the first step would just be the ...", "dateLastCrawled": "2022-01-28T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>User defined time step - Possible to put variable time</b> stepping in it ...", "url": "https://www.cfd-online.com/Forums/fluent-udf/201579-user-defined-time-step-possible-put-variable-time-stepping.html", "isFamilyFriendly": true, "displayUrl": "https://www.cfd-online.com/Forums/fluent-udf/201579-<b>user-defined-time-step-possible</b>...", "snippet": "I don\u00b4t know if it is possible to define automatic variable <b>time</b> stepping during a certain period of simulation <b>time</b> in a udf. <b>Like</b> I wrote above, I would <b>like</b> to define a udf in this way: 1. <b>Time</b> period at the beginning with fixed <b>time step</b> size 2. <b>Time</b> period in the middle where automatic variable <b>time</b> stepping is desired 3. <b>Time</b> period at the end with fixed <b>time step</b> size Best Regards May 8, 2018, 22:16 #4: AlexanderZ. Senior Member . Alexander. Join Date: Apr 2013. Posts: 1,893 Rep ...", "dateLastCrawled": "2022-01-30T14:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Learning</b> <b>Time-Dependent</b> Models \u2014 QInfer 1.0b4 documentation", "url": "http://docs.qinfer.org/en/latest/guide/timedep.html", "isFamilyFriendly": true, "displayUrl": "docs.qinfer.org/en/latest/guide/<b>time</b>dep.html", "snippet": "<b>Learning</b> <b>Time-Dependent</b> Models ... As this distribution is in general dependent on the experiment being performed, update_<b>timestep</b>() is vectorized in a manner <b>similar</b> to likelihood() (see Designing and Using Models for details). That is, given a tensor \\(X_{i,j}\\) of model parameter vectors and a vector \\(e_k\\) of experiments, update_<b>timestep</b>() returns a tensor \\(X_{i,j,k}&#39;\\) of sampled model parameters at the next <b>time step</b>. Random Walk Models\u00b6 As an example, RandomWalkModel implements ...", "dateLastCrawled": "2022-01-19T00:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>One</b> <b>Timestep</b> is All You Need: Training Spiking Neural Networks with ...", "url": "https://deepai.org/publication/one-timestep-is-all-you-need-training-spiking-neural-networks-with-ultra-low-latency", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>one</b>-<b>timestep</b>-is-all-you-need-training-spiking-neural...", "snippet": "If we unroll SNNs in <b>time</b>, it becomes obvious that each <b>timestep</b> adds a hidden state to a spiking neuron. Thus, reducing latency compresses the SNNs in the temporal axis and the eventual unit <b>timestep</b> network consists of a single forward pass, with no internal states. From a related perspective, we can perceive gradual latency reduction as sequential temporal distillation, where at each step, the network with higher timesteps acts as the teacher, while the student network with reduced ...", "dateLastCrawled": "2021-12-30T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to Use Timesteps in LSTM Networks for <b>Time Series Forecasting</b>", "url": "https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/use-<b>timestep</b>s-lstm-networks-<b>time-series-forecasting</b>", "snippet": "Transform the <b>time</b> series into a supervised <b>learning</b> problem. Specifically, the organization of data into input and output patterns where the observation at the previous <b>time step</b> is used as an input to forecast the observation at the current <b>time</b> <b>timestep</b>; Transform the observations to have a specific scale. Specifically, to rescale the data ...", "dateLastCrawled": "2022-02-02T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Tuning Recurrent Neural Networks with <b>Reinforcement</b> <b>Learning</b>", "url": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://magenta.tensorflow.org/.../tuning-recurrent-networks-with-<b>reinforcement</b>-<b>learning</b>", "snippet": "A <b>Note</b> RNN is conceptually <b>similar</b> to a Character RNN, a popular model for generating text, <b>one</b> character <b>at a time</b>. While both types of models can produce impressive results, they have some frustrating limitations. They both suffer from common failure modes, such as continually repeating the same token. Further, the sequences produced by the models tend to lack a consistent global structure. To see this more clearly, take a look at the text below, which was generated by a Character RNN ...", "dateLastCrawled": "2022-02-03T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "CS7015 (Deep <b>Learning</b>) : Lecture 15", "url": "https://cse.iitm.ac.in/~miteshk/CS7015/Slides/Handout/Lecture15.pdf", "isFamilyFriendly": true, "displayUrl": "https://cse.iitm.ac.in/~miteshk/CS7015/Slides/Handout/Lecture15.pdf", "snippet": "information from all previous <b>time</b> steps At each new <b>timestep</b> the old information gets morphed by the current input <b>One</b> could imagine that after tsteps the information stored at <b>time step</b> t k(for some k&lt;t) gets completely morphed so much that it would be impossible to extract the original information stored at <b>time step</b> t k Mitesh M. Khapra CS7015 (Deep <b>Learning</b>) : Lecture 15. 4/43 s1 W V U x1 y1 s2 x2 y2 W V U s3 x3 y3 W V U s4 x4 y4 W V U... st xt yt W V U A <b>similar</b> problem occurs when the ...", "dateLastCrawled": "2022-02-03T09:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Speech Recognition with Neural Networks - Andrew Gibiansky", "url": "https://andrew.gibiansky.com/blog/machine-learning/speech-recognition-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://andrew.gibiansky.com/blog/machine-<b>learning</b>/speech-recognition-neural-networks", "snippet": "Standard Recurrent Neural Networks. Recall that a recurrent neural network is <b>one</b> in which each layer represents another step in <b>time</b> (or another step in some sequence), and that each <b>time step</b> gets <b>one</b> input and predicts <b>one</b> output. However, the network is constrained to use the same &quot;transition function&quot; for each <b>time step</b>, thus <b>learning</b> to predict the output sequence from the input sequence for sequences of any length.", "dateLastCrawled": "2022-01-31T10:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Is it possible to take more than <b>one</b> action per <b>timestep</b>? - Unity Forum", "url": "https://forum.unity.com/threads/is-it-possible-to-take-more-than-one-action-per-timestep.1148348/", "isFamilyFriendly": true, "displayUrl": "https://forum.unity.com/threads/is-it-possible-to-take-more-than-<b>one</b>-action-per...", "snippet": "This is due to the RL formulations where the process is defined as series of (observation, action, reward) pairs. On that <b>note</b>, none of those environment stepping are tied to wall-clock <b>time</b>, or <b>timestep</b>. So it might helpful to clarify more on what you mean by &quot;take as many actions per <b>timestep</b> as possible without slowing down the scene&quot;.", "dateLastCrawled": "2022-01-19T11:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ANSYS Fluent transient simulation <b>timestep</b> is very small? : CFD", "url": "https://www.reddit.com/r/CFD/comments/s5ic46/ansys_fluent_transient_simulation_timestep_is/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/CFD/comments/s5ic46/ansys_fluent_transient_simulation_<b>timestep</b>_is", "snippet": "If you want to increase the <b>time step</b> without losing the information, try to get a slightly coarser mesh, wherever possible. Also use adaptive <b>time</b> steps instead of fixed <b>time</b> steps. (I don\u2019t remember how the fluent adaptive menu looks like, but it is controlled by CFL number as the criteria). The system will automatically \u201caccelerate\u201d and decelerate the solution based on local courant number. (For most cases, cfl&lt;=0.5, but sometimes even cfl~1 is acceptable). Good luck", "dateLastCrawled": "2022-01-18T15:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Time step too small</b> error in Explicit Dynamics \u2014 Ansys <b>Learning</b> Forum", "url": "https://forum.ansys.com/discussion/14504/time-step-too-small-error-in-explicit-dynamics", "isFamilyFriendly": true, "displayUrl": "https://forum.ansys.com/discussion/14504/<b>time-step-too-small</b>-error-in-explicit-dynamics", "snippet": "<b>Note</b>: you cannot type the word b u l l e t on the site, it is a prohibited word. Share on Twitter Share on ... I tried to change the MIN <b>timestep</b> from programme controlled to 1e-15s (or even 1e-25s), but it didn&#39;t helped much. Please find attached my project archive. I&#39;d be very grateful if you could please adjust the settings. If you don&#39;t have <b>time</b> to solve that, that&#39;s fine, I&#39;ll do that. What&#39;s important for me is to learn how to properly set such simulations , not just to solve that <b>one</b> ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Image Captions with Attention in <b>Tensorflow</b>, Step-by-step | by Ketan ...", "url": "https://towardsdatascience.com/image-captions-with-attention-in-tensorflow-step-by-step-927dad3569fa", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/image-captions-with-attention-in-<b>tensorflow</b>-step-by...", "snippet": "We wrap the training data in a <b>Tensorflow</b> Dataset object so that it can be efficiently fetched and fed, <b>one</b> batch <b>at a time</b>, to the model during training. The data is fetched lazily so that it doesn\u2019t all have to be in memory at the same <b>time</b>. This allows us to support very large datasets. The dataset loads the pre-processed encoded image vectors that were saved earlier. It uses the image file name to identify the saved file path. Much of the code for this example has been taken from the ...", "dateLastCrawled": "2022-02-01T12:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Use Timesteps in LSTM Networks for <b>Time Series Forecasting</b>", "url": "https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/use-<b>timestep</b>s-lstm-networks-<b>time-series-forecasting</b>", "snippet": "The Long Short-Term Memory (LSTM) network in Keras supports <b>time</b> steps. This raises the question as to whether lag observations for a univariate <b>time</b> series <b>can</b> be used as <b>time</b> steps for an LSTM and whether or not this improves forecast performance. In this tutorial, we will investigate the use of lag observations as <b>time</b> steps in LSTMs models in Python. After completing", "dateLastCrawled": "2022-02-02T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "&quot;Fix your (Unity) <b>Timestep</b>!&quot; - Everything you need to know about the ...", "url": "https://forum.unity.com/threads/fix-your-unity-timestep-everything-you-need-to-know-about-the-unity-time-step.685966/", "isFamilyFriendly": true, "displayUrl": "https://forum.unity.com/threads/fix-your-unity-<b>timestep</b>-everything-you-need-to-know...", "snippet": "Please take the <b>time</b> to read our Code of Conduct here to familiarize yourself with the rules and how to post constructively. Unity 2022.1 Beta Announcement NEW FORUM USER NOTICE &quot;Fix your (Unity) <b>Timestep</b>!&quot; - Everything you need to know about the Unity <b>time step</b>. Discussion in &#39;Scripting&#39; started by Kleptine, May 28, 2019. csharp; debugging; optimization; Kleptine. Joined: Dec 23, 2013 Posts: 172. I wrote up an article on the Unity <b>timestep</b> in the vein of the classic Gaffer on Games article ...", "dateLastCrawled": "2022-01-28T22:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "python - Training LSTM over multiple datasets of different <b>timestep</b> ...", "url": "https://stackoverflow.com/questions/70590541/training-lstm-over-multiple-datasets-of-different-timestep-number", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/70590541/training-lstm-over-multiple-datasets-of...", "snippet": "(a <b>Note</b> below) Now if the sequence length is not equal, there are multiple things you could do. First, you should ask yourself if you want to train on the full sequences. Is it necessary to read the full N steps to get an estimate of the result, or could it be enough to only look at n &lt; N steps? If that is the case, you <b>can</b> sample b (your new batch size, which you <b>can</b> define how you like) sequences of length n, where n &lt; N for all sequences. If parts of the sequence are not sufficient to ...", "dateLastCrawled": "2022-01-18T03:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Reinforcement <b>Learning</b> in Simulations | by Ben Goldhaber | Towards Data ...", "url": "https://towardsdatascience.com/exploring-simulations-with-q-learning-and-rl-f961311b539a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/exploring-simulations-with-q-<b>learning</b>-and-rl-f961311b539a", "snippet": "Every <b>timestep</b> the agent <b>can</b> consider taking <b>one</b> of four actions \u2014 it <b>can</b> move up, down, right, or left. actions = ... The policy of a Q-<b>Learning</b> agent <b>can</b> <b>be thought</b> of as the collection of values in its q_table (along with how it samples those values) <b>Note</b>: The q_table is an array of arrays; the first level represents locations in the gridworld, the second level represents actions. The value of [location] [action] is a \u2018quality\u2019 score. To make this more concrete, consider the ...", "dateLastCrawled": "2022-01-30T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Reinforcement <b>Learning</b> in HASH Simulations - HASH", "url": "https://hash.ai/blog/reinforcement-learning-in-hash-simulations", "isFamilyFriendly": true, "displayUrl": "https://hash.ai/blog/reinforcement-<b>learning</b>-in-hash-simulations", "snippet": "Every <b>timestep</b> the agent <b>can</b> consider taking <b>one</b> of four actions \u2013 it <b>can</b> move up, down, right, or left. actions = [ [1, 0], [0, 1], [-1, 0], [0, -1] ] At certain positions in gridworld, some of these actions would take it outside the bounds of our simulation. To prevent that, this behavior filters all possible actions to a subset of valid actions. It then stores these in state[\u201cactions\u201d]. action.py. The agent now chooses which action to take based on how well a given action has ...", "dateLastCrawled": "2022-01-18T20:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Time step too small</b> error in Explicit Dynamics \u2014 Ansys <b>Learning</b> Forum", "url": "https://forum.ansys.com/discussion/14504/time-step-too-small-error-in-explicit-dynamics", "isFamilyFriendly": true, "displayUrl": "https://forum.ansys.com/discussion/14504/<b>time-step-too-small</b>-error-in-explicit-dynamics", "snippet": "<b>Note</b>: you cannot type the word b u l l e t on the site, it is a prohibited word. Share on Twitter Share on ... I tried to change the MIN <b>timestep</b> from programme controlled to 1e-15s (or even 1e-25s), but it didn&#39;t helped much. Please find attached my project archive. I&#39;d be very grateful if you could please adjust the settings. If you don&#39;t have <b>time</b> to solve that, that&#39;s fine, I&#39;ll do that. What&#39;s important for me is to learn how to properly set such simulations , not just to solve that <b>one</b> ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Frequency resolution and timestep in</b> DFT - <b>Signal Processing Stack Exchange</b>", "url": "https://dsp.stackexchange.com/questions/8525/frequency-resolution-and-timestep-in-dft", "isFamilyFriendly": true, "displayUrl": "https://dsp.stackexchange.com/questions/8525/<b>frequency-resolution-and-timestep-in</b>-dft", "snippet": "The result are frequencies which occur in this chunk of audio. Now we <b>can</b> display the spectrum (like Winamp does). But we would like to display the spectrum while the song is playing thus calculating DFT for many such windows. Because it would take a long <b>time</b> to do this with all the windows, we say we have a <b>timestep</b> (dt) between windows. This ...", "dateLastCrawled": "2022-02-02T19:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "deep <b>learning</b> - Tensorflow/LSTM machanism: How to specify the previous ...", "url": "https://stackoverflow.com/questions/44325179/tensorflow-lstm-machanism-how-to-specify-the-previous-output-of-first-time-step", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/44325179", "snippet": "I suddenly feel like i&#39;m totally lost about the <b>time</b> span of LSTM memory. I&#39;ve been thinking the <b>time</b> span of memory is limited by <b>timeStep</b>_size only. if <b>timeStep</b>_size = 5, the network <b>can</b> only recall up to 4 steps back, since every training we only feed [5 x 2] of x feature vector. please correct me if i&#39;m wrong. Again thank you so much", "dateLastCrawled": "2022-01-23T17:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Pixels-to-Control Learning</b> | Chan`s Jupyter", "url": "https://goodboychan.github.io/python/reinforcement_learning/tensorflow/mit/2021/03/06/Pixel-to-Control-Learning.html", "isFamilyFriendly": true, "displayUrl": "https://goodboychan.github.io/python/reinforcement_<b>learning</b>/tensorflow/mit/2021/03/06/...", "snippet": "Like in supervised <b>learning</b>, we <b>can</b> use stochastic gradient descent methods to achieve the desired minimization. Let&#39;s begin by defining the loss function. # Arguments: # logits: network&#39;s predictions for actions to take # actions: the actions the agent took in an episode # rewards: the rewards the agent received in an episode # Returns: # loss def compute_loss (logits, actions, rewards): # compute the negative log probabilities neg_logprob = tf. nn. sparse_softmax_cross_entropy_with_logits ...", "dateLastCrawled": "2021-11-04T10:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "CS 188 Introduction to Arti cial Intelligence Fall 2018 <b>Note</b> 8 Markov ...", "url": "https://inst.eecs.berkeley.edu/~cs188/fa18/assets/notes/n8.pdf", "isFamilyFriendly": true, "displayUrl": "https://inst.eecs.berkeley.edu/~cs188/fa18/assets/<b>notes</b>/n8.pdf", "snippet": "Fall 2018 <b>Note</b> 8 Markov Models In previous notes, we talked about Bayes\u2019 nets and how they are a wonderful structure used for compactly representing relationships between random variables. We\u2019ll now cover a very intrinsically related structure called a Markov model, which for the purposes of this course <b>can</b> <b>be thought</b> of as analogous to a chain-like, in\ufb01nite-length Bayes\u2019 net. The running example we\u2019ll be working with in this section is the day-to-day \ufb02uctuations in weather ...", "dateLastCrawled": "2021-11-09T23:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>One</b> <b>Timestep</b> is All You Need: Training Spiking Neural Networks with ...", "url": "https://deepai.org/publication/one-timestep-is-all-you-need-training-spiking-neural-networks-with-ultra-low-latency", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>one</b>-<b>timestep</b>-is-all-you-need-training-spiking-neural...", "snippet": "At each <b>timestep</b> reduction stage, the network trained at previous iteration with higher <b>timestep</b> is utilized as initialization for subsequent training with lower <b>timestep</b>. Direct transition from ANN or 5 <b>timestep</b> SNN to 1 <b>timestep</b> for deep SNNs results in training failures due to spike vanishing at the deeper layers. However, the proposed iterative process enables some spike propagation till the final layer through which backpropagation <b>can</b> start training and proper layerwise thresholds <b>can</b> ...", "dateLastCrawled": "2021-12-30T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to Use Timesteps in LSTM Networks for <b>Time Series Forecasting</b>", "url": "https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/use-<b>timestep</b>s-lstm-networks-<b>time-series-forecasting</b>", "snippet": "The Long Short-Term Memory (LSTM) network in Keras supports <b>time</b> steps. This raises the question as to whether lag observations for a univariate <b>time</b> series <b>can</b> be used as <b>time</b> steps for an LSTM and whether or not this improves forecast performance. In this tutorial, we will investigate the use of lag observations as <b>time</b> steps in LSTMs models in Python. After completing", "dateLastCrawled": "2022-02-02T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>One</b> <b>Timestep</b> is All You Need: Training Spiking Neural Networks ...", "url": "https://www.researchgate.net/publication/355222116_One_Timestep_is_All_You_Need_Training_Spiking_Neural_Networks_with_Ultra_Low_Latency", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/355222116_<b>One</b>_<b>Timestep</b>_is_All_You_Need...", "snippet": "PDF | Spiking Neural Networks (SNNs) are energy efficient alternatives to commonly used deep neural networks (DNNs). Through event-driven information... | Find, read and cite all the research you ...", "dateLastCrawled": "2021-10-22T02:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Tuning Recurrent Neural Networks with <b>Reinforcement</b> <b>Learning</b>", "url": "https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://magenta.tensorflow.org/.../tuning-recurrent-networks-with-<b>reinforcement</b>-<b>learning</b>", "snippet": "A <b>Note</b> RNN is conceptually similar to a Character RNN, a popular model for generating text, <b>one</b> character <b>at a time</b>. While both types of models <b>can</b> produce impressive results, they have some frustrating limitations. They both suffer from common failure modes, such as continually repeating the same token. Further, the sequences produced by the models tend to lack a consistent global structure. To see this more clearly, take a look at the text below, which was generated by a Character RNN ...", "dateLastCrawled": "2022-02-03T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "RLS: <b>Learning</b> on the Fly. A simple model that learns on the fly\u2026 | by ...", "url": "https://towardsdatascience.com/recursive-least-squares-learning-on-the-fly-f8bb878eb270", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/recursive-least-squares-<b>learning</b>-on-the-fly-f8bb878eb270", "snippet": "At each <b>timestep</b>, when a new data point is received, Rn <b>can</b> be expressed as above. The weights <b>can</b> then be updated using the rank-<b>one</b> update. As you <b>can</b> see, the updated inverse of Rn has been computed without needing to perform the inverse of the matrix. The full derivation of the updated weights equation won&#39;t be shown, however, these equations are enough to implement your own version of the Recursive Least Squares algorithm. What&#39;s important to <b>note</b> is that the updated weights are equal ...", "dateLastCrawled": "2022-02-03T11:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Controlling the Time Dependent solver timesteps</b> - Knowledge Base", "url": "https://www.comsol.com/support/knowledgebase/1254", "isFamilyFriendly": true, "displayUrl": "https://www.comsol.com/support/knowledgebase/1254", "snippet": "<b>Note</b> that the software is still free to choose a <b>timestep</b> smaller than this value, but will not make it larger. Also consider if Events <b>can</b> be used instead. Specifying the initial <b>timestep</b> size that the solver tries to take. During the solution, the solver will automatically make the <b>timestep</b> smaller as needed to resolve any fast variations in the solution, as needed. It will also make the <b>timestep</b> larger during periods when the solution is only varying gradually. You <b>can</b> control the maximum ...", "dateLastCrawled": "2022-02-03T02:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Fixed vs Adaptive time steps</b> -- CFD Online Discussion Forums", "url": "https://www.cfd-online.com/Forums/fluent/122039-fixed-vs-adaptive-time-steps.html", "isFamilyFriendly": true, "displayUrl": "https://www.cfd-online.com/Forums/fluent/122039-<b>fixed-vs-adaptive-time-steps</b>.html", "snippet": "I used <b>time step</b> size of 1e-5 for Adaptive <b>time step</b>. <b>can</b> the CL change with using Fixed and/or Adaptive <b>time</b> stepping? I am in <b>learning</b> stage so thanks for your patience.. August 13, 2013, 11:46 #4: duri. Senior Member . duri. Join Date: May 2010. Posts: 245 Rep Power: 14. I am not getting how unsteadiness related to reynolds number. It should be independent. When the flow is unsteady and if you are running with higher <b>time step</b> it ends up in aliasing. In case of steady flow it doesn&#39;t ...", "dateLastCrawled": "2022-02-01T06:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Reinforcement <b>Learning</b>: Introduction to Policy Gradients | by Cheng Xi ...", "url": "https://medium.com/nerd-for-tech/reinforcement-learning-introduction-to-policy-gradients-aa2ff134c1b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/nerd-for-tech/reinforcement-<b>learning</b>-introduction-to-policy...", "snippet": "Looking at our training history, we <b>can</b> see that our agent slowly learns over <b>time</b>. However, we notice that <b>compared</b> to other <b>learning</b> methods such as DQN in my previous post, the <b>learning</b> is slow ...", "dateLastCrawled": "2022-01-28T08:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>User defined time step - Possible to put variable time</b> stepping in it ...", "url": "https://www.cfd-online.com/Forums/fluent-udf/201579-user-defined-time-step-possible-put-variable-time-stepping.html", "isFamilyFriendly": true, "displayUrl": "https://www.cfd-online.com/Forums/fluent-udf/201579-<b>user-defined-time-step-possible</b>...", "snippet": "Although I defined a really small minimum <b>time</b> change factor, which would allow Fluent to reduce the <b>time step</b> size from <b>one</b> <b>time step</b> to the next to a size small enough for the mesh to not fold, Fluent fails with this. So it looks like I need to use a user defined <b>time step</b>. My question is if I <b>can</b> define a udf in the following way:", "dateLastCrawled": "2022-01-30T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Image Captions with Attention in <b>Tensorflow</b>, Step-by-step | by Ketan ...", "url": "https://towardsdatascience.com/image-captions-with-attention-in-tensorflow-step-by-step-927dad3569fa", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/image-captions-with-attention-in-<b>tensorflow</b>-step-by...", "snippet": "We wrap the training data in a <b>Tensorflow</b> Dataset object so that it <b>can</b> be efficiently fetched and fed, <b>one</b> batch <b>at a time</b>, to the model during training. The data is fetched lazily so that it doesn\u2019t all have to be in memory at the same <b>time</b>. This allows us to support very large datasets. The dataset loads the pre-processed encoded image vectors that were saved earlier. It uses the image file name to identify the saved file path. Much of the code for this example has been taken from the ...", "dateLastCrawled": "2022-02-01T12:37:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Using Analog For AI | Alchip</b> Technologies, Limited", "url": "https://www.alchip.com/alchip-in-the-news/using-analog-for-ai/", "isFamilyFriendly": true, "displayUrl": "https://www.alchip.com/alchip-in-the-news/<b>using-analog-for-ai</b>", "snippet": "As <b>machine</b> <b>learning</b> applications spread out, more energy efficient adaptive mixed-signal analog-front devices will be needed.\u201d Could analog help? It has been proven that AI functions can be performed using orders of magnitude less power and that it is capable of solving problems far more complex than AI systems currently being developed. That example is the mammalian brain. Even the most power hungry, the human brain, only consumes about 25W. The power consumption of a TPU is likely ...", "dateLastCrawled": "2022-01-31T14:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "noc20 cs50 assigment 12 - NPTEL", "url": "https://nptel.ac.in/content/storage2/courses/downloads_new/106106184/noc20_cs50_assigment_12.pdf", "isFamilyFriendly": true, "displayUrl": "https://nptel.ac.in/content/storage2/courses/downloads_new/106106184/noc20_cs50...", "snippet": "NPTEL \u00bb Deep <b>Learning</b> - Part 1 Unit 13 - Week 11 Course outline How does an NPTEL online course work? Week O Week 1 week 2 ... current state of the network at <b>timestep</b> i sigmoid at <b>timestep</b> previous state of the network at <b>timestep</b> i next state of the network at <b>timestep</b> i No, the answer is incorrect. Score: 0 Accepted Answers: current state of the network at <b>timestep</b> i 8) Which neural network architecture would be suitable to find the nth character given the character sequence of length n ...", "dateLastCrawled": "2022-01-25T10:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Multistep Time Series Forecasting with</b> LSTMs in Python", "url": "https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>multi-step-time-series-forecasting</b>-long-short-term...", "snippet": "How to Setup a Python Environment for <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> with Anaconda; Next, let\u2019s take a look at a standard <b>time series forecasting</b> problem that we can use as context for this experiment. Need help with Deep <b>Learning</b> for Time Series? Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course . Shampoo Sales Dataset. This dataset describes the monthly number of sales of ...", "dateLastCrawled": "2022-02-02T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Computing Time Part (I): Recurrent Neural Networks</b> \u2013 The Beauty of ...", "url": "https://thebeautyofml.wordpress.com/2017/01/01/computing-time-part-i-recurrent-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://thebeautyofml.wordpress.com/2017/01/01/<b>computing-time-part-i-recurrent-neural</b>...", "snippet": "Nothing will surprise you more than recurrent nets if you practice <b>machine</b> <b>learning</b>. Recurrent net is the most powerful, successful and the luckiest neural network ever. Today\u2019s research in deep <b>learning</b> relies heavily on recurrent nets, although they are not recognized as deep <b>learning</b> techniques. The history of recurrent nets returns back to 1980s but only saw this renaissance with the rise of deep <b>learning</b> and deep neural networks. Introduction. Before introducing how recurrent neural ...", "dateLastCrawled": "2022-01-23T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Gentle Introduction to <b>Long Short-Term Memory</b> Networks by the Experts", "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>long-short-term-memory</b>-networks...", "snippet": "<b>Long Short-Term Memory</b> (LSTM) networks are a type of recurrent neural network capable of <b>learning</b> order dependence in sequence prediction problems. This is a behavior required in complex problem domains like <b>machine</b> translation, speech recognition, and more. LSTMs are a complex area of deep <b>learning</b>. It can be hard to get your hands around what LSTMs are, and how terms like bidirectional", "dateLastCrawled": "2022-01-31T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Interpretability in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/interpretability-in-ml-a-broad-overview", "snippet": "First, interpretability in <b>machine</b> <b>learning</b> is useful because it can aid in trust. As humans, we may be reluctant to rely on <b>machine</b> <b>learning</b> models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in something opaque, which we see when people confront new technology, and this can slow down adoption. Approaches to interpretability that focus on transparency could help mitigate some of these fears.", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>machine</b> <b>learning</b> - Is there a way to understand neural networks without ...", "url": "https://ai.stackexchange.com/questions/15977/is-there-a-way-to-understand-neural-networks-without-using-the-concept-of-brain", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/15977/is-there-a-way-to-understand-neural...", "snippet": "neural-networks <b>machine</b>-<b>learning</b> function-approximation history. Share. Improve this question . Follow edited Dec 12 &#39;21 at 12:43. nbro \u2666. 31.7k 8 8 gold badges 66 66 silver badges 131 131 bronze badges. asked Oct 19 &#39;19 at 18:23. Evgeniy Evgeniy. 229 1 1 silver badge 3 3 bronze badges $\\endgroup$ 2. 1 $\\begingroup$ I haven&#39;t seen any explanation of NNs relying on brain except just for an initial motivation of NN structure in earlier days. As far as separation of data is concerned it ...", "dateLastCrawled": "2022-01-22T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Problems in AI Safety Explained with a Pizza Robot | Towards Data Science", "url": "https://towardsdatascience.com/dangers-of-a-pizza-making-robot-41cbbc09caeb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>dangers-of-a-pizza-making-robot</b>-41cbbc09caeb", "snippet": "<b>Machine</b> <b>learning</b> practitioners would recognize the regularizer as a mathematical expression that penalizes the overfitting to the data set. Similarly, an impact regularizer penalizes any a change to the environment. 2. Reward Hacking. Is it possible for the pizza-making robot to game the objective function given to it by its creator? For instance, if the objective function is to make a pizza as quickly as possible, the pizza-making robot might skimp on the toppings and bake a toppingless ...", "dateLastCrawled": "2022-02-02T10:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Visual Agnosia: A Neural Network Analogy</b> | by Aryan Singh | Towards ...", "url": "https://towardsdatascience.com/visual-agnosia-a-neural-network-analogy-8e208438b1ec", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>visual-agnosia-a-neural-network-analogy</b>-8e208438b1ec", "snippet": "<b>Visual Agnosia: A Neural Network Analogy</b>. This week I began reading Dr. Oliver Sacks\u2019s story, The Man Who Mistook His Wife for a Hat, a compel l ing story of one Dr. P who has lost the power of visual interpretation known in neurological terms as Visual Agnosia. The story started off with a cursory description of his symptoms, steadily moving ...", "dateLastCrawled": "2022-01-18T18:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[D] <b>Machine</b> <b>Learning</b> - WAYR (What Are You Reading) - Week 85 ...", "url": "https://www.reddit.com/r/MachineLearning/comments/fvk7j6/d_machine_learning_wayr_what_are_you_reading_week/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/fvk7j6/d_<b>machine</b>_<b>learning</b>_wayr_what...", "snippet": "This is a place to share <b>machine</b> <b>learning</b> research papers, journals, and articles that you&#39;re reading this week. If it relates to what you&#39;re researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you&#39;ve read. Please try to provide some insight from your understanding and please don&#39;t post things which are present in wiki. Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not ...", "dateLastCrawled": "2021-11-04T04:41:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Novel Re-<b>weighting Method for Connectionist Temporal Classification</b> ...", "url": "https://deepai.org/publication/a-novel-re-weighting-method-for-connectionist-temporal-classification", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-novel-re-<b>weighting-method-for-connectionist-temporal</b>...", "snippet": "The connectionist temporal classification (CTC) enables end-to-end sequence <b>learning</b> by maximizing the probability of correctly recognizing sequences during training. With an extra blank class, the CTC implicitly converts recognizing a sequence into classifying each timestep within the sequence. But the CTC loss is not intuitive for such classification task, so the class imbalance within each sequence, caused by the overwhelming blank timesteps, is a knotty problem.", "dateLastCrawled": "2021-12-21T21:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Novel Re-weighting Method for <b>Connectionist Temporal Classification</b> ...", "url": "https://www.arxiv-vanity.com/papers/1904.10619/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1904.10619", "snippet": "The <b>connectionist temporal classification</b> (CTC) enables end-to-end sequence <b>learning</b> by maximizing the probability of correctly recognizing sequences during training. With an extra blank class, the CTC implicitly converts recognizing a sequence into classifying each timestep within the sequence. But the CTC loss is not intuitive for such classification task, so the class imbalance within each sequence, caused by the overwhelming blank timesteps, is a knotty problem. In this paper, we define ...", "dateLastCrawled": "2021-11-30T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Neural network augmented wave-equation simulation", "url": "https://slim.gatech.edu/Publications/Public/TechReport/2019/siahkoohi2019TRnna/siahkoohi2019TRnna.html", "isFamilyFriendly": true, "displayUrl": "https://slim.gatech.edu/Publications/Public/TechReport/2019/siahkoohi2019TRnna/...", "snippet": "We describe how we augment low-fidelity physics with <b>learning</b> techniques to handle incomplete and/or inaccurate physics, where the low-fidelity physics is modeled via finite-difference method with a poor discretization of the Laplacian. To ensure accuracy, the temporal and spatial discretization in high-fidelity wave-equation simulations have to be chosen very fine, typically one to two orders of magnitude smaller than Nyquist sampling rate. As mentioned earlier, we will utilize a poor ...", "dateLastCrawled": "2021-12-16T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "COWES: Web user clustering based on evolutionary web sessions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0169023X09000792", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0169023X09000792", "snippet": "Let us look at novel clusters which can be discovered based on evolutionary characteristics of web usage data in our motivating example in Fig. 2.Pages accessed in a web session can be organized into a hierarchical structure, called web session tree, based on the URLs of the pages .For example, Fig. 1b is the web session tree constructed for the pages in the web session shown in Fig. 1a. A web session tree represents the information needs of a user.", "dateLastCrawled": "2021-12-12T14:51:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(timestep)  is like +(learning one note at a time)", "+(timestep) is similar to +(learning one note at a time)", "+(timestep) can be thought of as +(learning one note at a time)", "+(timestep) can be compared to +(learning one note at a time)", "machine learning +(timestep AND analogy)", "machine learning +(\"timestep is like\")", "machine learning +(\"timestep is similar\")", "machine learning +(\"just as timestep\")", "machine learning +(\"timestep can be thought of as\")", "machine learning +(\"timestep can be compared to\")"]}