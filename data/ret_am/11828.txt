{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning</b> - Data Revenue", "url": "https://www.datarevenue.com/en-blog/interpretable-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.datarevenue.com/en-blog/<b>interpretable-machine-learning</b>", "snippet": "That said, we can think of explainability as meeting a lower bar of <b>understanding</b> than <b>interpretability</b>. A <b>machine</b> learning model is interpretable if we can fundamentally understand how it <b>arrived</b> at a specific <b>decision</b>. A model is explainable if we can understand how a specific node in a complex model technically influences the output.", "dateLastCrawled": "2022-02-03T15:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability Methods in Machine Learning</b>: A Brief Survey - Two Sigma", "url": "https://www.twosigma.com/articles/interpretability-methods-in-machine-learning-a-brief-survey/", "isFamilyFriendly": true, "displayUrl": "https://www.twosigma.com/articles/<b>interpretability-methods-in-machine-learning</b>-a-brief...", "snippet": "<b>Interpretability</b> remains a very active area of research in <b>machine</b> learning, and for good reason. The major model-agnostic methods surveyed in this post each represent a step toward more fully <b>understanding</b> <b>machine</b> learning models. As <b>machine</b> learning becomes more and more ubiquitous, grasping how these models find answers will be crucial to improving their performance and reliability.", "dateLastCrawled": "2022-02-02T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability</b> of <b>machine</b> learning models - explaining the black-box", "url": "https://ayc-data.com/data_science/2021/09/09/machine-learning-interpretability-on-top.html", "isFamilyFriendly": true, "displayUrl": "https://ayc-data.com/data_science/2021/09/09/<b>machine</b>-learning-<b>interpretability</b>-on-top.html", "snippet": "<b>Interpretability</b> of <b>machine</b> learning models - explaining the black-box The &#39;why&#39; is just as important as the &#39;what&#39; Posted by Albert Cheng on 09 September 2021. Last Updated: 12 January 2022 . The world we are in is very automated. In the world we are in, automation is becoming increasingly common. It is impossible to go about your day-to-day life without some sort of automated <b>decision</b>-making occurring. Some are minor (e.g. what YouTube video is recommended), but others may be life-changing ...", "dateLastCrawled": "2022-01-13T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Review on Advances in <b>Machine</b> Learning <b>Interpretability</b>", "url": "https://www.irjet.net/archives/V8/i10/IRJET-V8I1062.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.irjet.net/archives/V8/i10/IRJET-V8I1062.pdf", "snippet": "A Review on Advances in <b>Machine</b> Learning <b>Interpretability</b> Kruthi N Raj Final Year B.E. Student, Department of Computer Science and Engineering, Bangalore Institute of Technology, Bengaluru, India-----***-----Abstract - Whilst AI systems provide astonishingly good and accurate results, it is difficult to comprehend why and how an algorithm <b>arrived</b> <b>at its</b> conclusions, giving rise to the black-box notion in the field. Interpretable <b>Machine</b> Learning is no longer a novelty; it is a need. As the ...", "dateLastCrawled": "2021-11-18T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretability</b>: <b>Decision</b> Attribution", "url": "https://napsterinblue.github.io/notes/machine_learning/computer_vision/interpretable_attribution/", "isFamilyFriendly": true, "displayUrl": "https://napsterinblue.github.io/notes/<b>machine</b>_learning/computer_vision/interpretable...", "snippet": "Cracking open the intermediate layers of a Convolutional Neural Network can be incredibly instructive and help reinforce your intuition for the types of features learned within a \u201cblack box\u201d algorithm. However, from an image classification standpoint, it\u2019s hard to overstate just how effective seeing a simple heatmap of \u201c<b>decision</b> attribution\u201d can be for debugging and <b>understanding</b> the behavior of your model as a whole. In this notebook, we\u2019ll give a quick overview of an approach ...", "dateLastCrawled": "2021-12-13T06:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Can you explain this? The story of <b>machine</b> learning <b>interpretability</b> ...", "url": "https://medium.com/codex/can-you-explain-this-221130c6e264", "isFamilyFriendly": true, "displayUrl": "https://medium.com/codex/can-you-explain-this-221130c6e264", "snippet": "The story of <b>machine</b> learning <b>interpretability</b>. Sumanth S Rao . Follow. Mar 21 \u00b7 8 min read. It\u2019s the year 2030, we are living in an age of increasing automation and artificially intelligent ...", "dateLastCrawled": "2021-06-21T21:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Decoding the Black Box: An Important Introduction to Interpretable ...", "url": "https://medium.com/analytics-vidhya/decoding-the-black-box-an-important-introduction-to-interpretable-machine-learning-models-in-fb137768d31d?source=post_internal_links---------6----------------------------", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/decoding-the-black-box-an-important-introduction...", "snippet": "Building and <b>Understanding</b> Interpretable <b>Machine</b> Learning Models. Let us first look at how to do <b>interpretability</b> for inherently interpretable <b>machine</b> learning models. Importing the Required Libraries", "dateLastCrawled": "2021-12-21T17:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "15. <b>Interpretability in Deep Learning</b> \u2014 Deep Learning for Molecules and ...", "url": "https://dmol.pub/dl/xai.html", "isFamilyFriendly": true, "displayUrl": "https://dmol.pub/dl/xai.html", "snippet": "15. <b>Interpretability in Deep Learning</b>. <b>Interpretability</b>, part of the broader topic of explainable AI (XAI), is the process of adding explanations to deep learning model predictions. These explanations should help us understand why particular predictions are made. This is a critical topic because being able to understand model predictions is ...", "dateLastCrawled": "2022-01-31T19:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Picking an explainability technique | by Divya Gopinath | Towards Data ...", "url": "https://towardsdatascience.com/picking-an-explainability-technique-48e807d687b9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/picking-an-explainability-technique-48e807d687b9", "snippet": "It is impossible to trust a <b>machine</b> learning model without <b>understanding</b> how and why it makes <b>its</b> decisions, and whether these decisions are justified. Peering into ML models is absolutely necessary before deploying them in the wild, where a poorly understood model can not only fail to achieve <b>its</b> objective, but also cause negative business or social impacts, or encounter regulatory trouble. Explainability is also an important backbone to other trustworthy ML pillars <b>like</b> fairness and ...", "dateLastCrawled": "2022-02-02T22:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Understanding SHAP(XAI) through LEAPS</b> - Analyttica", "url": "https://analyttica.com/understanding-shap-xai-through-leaps/", "isFamilyFriendly": true, "displayUrl": "https://analyttica.com/<b>understanding-shap-xai-through-leaps</b>", "snippet": "As the complexitiy of the model increases, <b>its</b> <b>interpretability</b> reduces. At times, it becomes difficult even for the model creator to explain why the model has <b>arrived</b> at a particular <b>decision</b>. As the organizations start looking out for highly accurate and explainable models, the need for explainable AI is growing. Explainable AI provides a justification post-prediction. XAI frameworks. There are many XAI frameworks available amongst which LIME &amp; SHAP are the popular ones. Refer to the ...", "dateLastCrawled": "2022-02-01T18:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning</b> - Data Revenue", "url": "https://www.datarevenue.com/en-blog/interpretable-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.datarevenue.com/en-blog/<b>interpretable-machine-learning</b>", "snippet": "global <b>interpretability</b> is <b>understanding</b> how the complete model works; ... That said, we can think of explainability as meeting a lower bar of <b>understanding</b> than <b>interpretability</b>. A <b>machine</b> learning model is interpretable if we can fundamentally understand how it <b>arrived</b> at a specific <b>decision</b>. A model is explainable if we can understand how a specific node in a complex model technically influences the output. If every component of a model is explainable and we can keep track of each ...", "dateLastCrawled": "2022-02-03T15:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability Methods in Machine Learning</b>: A Brief Survey - Two Sigma", "url": "https://www.twosigma.com/articles/interpretability-methods-in-machine-learning-a-brief-survey/", "isFamilyFriendly": true, "displayUrl": "https://www.twosigma.com/articles/<b>interpretability-methods-in-machine-learning</b>-a-brief...", "snippet": "<b>Interpretability</b> remains a very active area of research in <b>machine</b> learning, and for good reason. The major model-agnostic methods surveyed in this post each represent a step toward more fully <b>understanding</b> <b>machine</b> learning models. As <b>machine</b> learning becomes more and more ubiquitous, grasping how these models find answers will be crucial to improving their performance and reliability.", "dateLastCrawled": "2022-02-02T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Unlocking Business Value from <b>Machine</b> Learning: Model <b>Interpretability</b> ...", "url": "https://towardsdatascience.com/unlocking-business-value-from-machine-learning-model-interpretability-c08100b788c8", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/unlocking-business-value-from-<b>machine</b>-learning-model...", "snippet": "There is a <b>similar</b> paradigm for <b>m achine</b> learning. The more powerful the model, the harder it is to interpret <b>its</b> inner workings. Sure, you may get a more accurate answer from a neural network, but how it <b>arrived</b> at that answer may be a total mystery. This can be a problem when trying to figure out what went wrong or how to improve it.", "dateLastCrawled": "2022-01-29T06:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "15. <b>Interpretability in Deep Learning</b> \u2014 Deep Learning for Molecules and ...", "url": "https://dmol.pub/dl/xai.html", "isFamilyFriendly": true, "displayUrl": "https://dmol.pub/dl/xai.html", "snippet": "15. <b>Interpretability in Deep Learning</b>. <b>Interpretability</b>, part of the broader topic of explainable AI (XAI), is the process of adding explanations to deep learning model predictions. These explanations should help us understand why particular predictions are made. This is a critical topic because being able to understand model predictions is ...", "dateLastCrawled": "2022-01-31T19:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Explainable AI</b> - India | <b>IBM</b>", "url": "https://www.ibm.com/in-en/watson/explainable-ai", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ibm.com</b>/in-en/watson/<b>explainable-ai</b>", "snippet": "<b>Interpretability</b> is the degree to which an observer can understand the cause of a <b>decision</b>. It is the success rate that humans can predict for the result of an AI output, while explainability goes a step further and looks at how the AI <b>arrived</b> at the result.", "dateLastCrawled": "2022-02-01T20:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretability</b>: <b>Decision</b> Attribution", "url": "https://napsterinblue.github.io/notes/machine_learning/computer_vision/interpretable_attribution/", "isFamilyFriendly": true, "displayUrl": "https://napsterinblue.github.io/notes/<b>machine</b>_learning/computer_vision/interpretable...", "snippet": "Cracking open the intermediate layers of a Convolutional Neural Network can be incredibly instructive and help reinforce your intuition for the types of features learned within a \u201cblack box\u201d algorithm. However, from an image classification standpoint, it\u2019s hard to overstate just how effective seeing a simple heatmap of \u201c<b>decision</b> attribution\u201d can be for debugging and <b>understanding</b> the behavior of your model as a whole. In this notebook, we\u2019ll give a quick overview of an approach ...", "dateLastCrawled": "2021-12-13T06:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Decoding the Black Box: An Important Introduction to Interpretable ...", "url": "https://medium.com/analytics-vidhya/decoding-the-black-box-an-important-introduction-to-interpretable-machine-learning-models-in-fb137768d31d?source=post_internal_links---------6----------------------------", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/decoding-the-black-box-an-important-introduction...", "snippet": "Building and <b>Understanding</b> Interpretable <b>Machine</b> Learning Models. Let us first look at how to do <b>interpretability</b> for inherently interpretable <b>machine</b> learning models. Importing the Required Libraries", "dateLastCrawled": "2021-12-21T17:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Electronics | Free Full-Text | <b>Machine Learning</b> <b>Interpretability</b>: A ...", "url": "https://www.mdpi.com/2079-9292/8/8/832/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2079-9292/8/8/832/htm", "snippet": "<b>Machine learning</b> systems are becoming increasingly ubiquitous. These systems\u2019s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate <b>decision</b> support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their ...", "dateLastCrawled": "2022-02-02T09:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>How the machine</b> \u2018thinks\u2019: <b>Understanding</b> <b>opacity</b> in <b>machine</b> learning ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2053951715622512", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2053951715622512", "snippet": "Some popular <b>machine</b> learning models include neural networks, <b>decision</b> trees, Na\u00efve Bayes, and logistic regression. The choice of model depends upon the domain (i.e. loan default prediction vs. image recognition), <b>its</b> demonstrated accuracy in classification, and available computational resources, among other concerns. Models may also be combined into \u2018model ensembles,\u2019 an approach often used in <b>machine</b> learning competitions that seek to maximize accuracy in classification. Two ...", "dateLastCrawled": "2022-01-29T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>How the machine &#39;thinks: Understanding opacity in</b> <b>machine</b> ...", "url": "https://www.researchgate.net/publication/289555278_How_the_machine_'thinks_Understanding_opacity_in_machine_learning_algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/289555278_<b>How_the_machine</b>_", "snippet": "<b>Ho w the machine \u2018thinks\u2019: Understanding. opacity in machine learning</b> algorithms. Jenna Burrell. Abstract. This article considers the issue of opacity as a pr oblem for socially consequential ...", "dateLastCrawled": "2022-01-23T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>interpretability</b> - Chandan Singh | chandan singh", "url": "https://csinva.io/notes/research_ovws/ovw_interp.html", "isFamilyFriendly": true, "displayUrl": "https://csinva.io/notes/research_ovws/ovw_interp.html", "snippet": "Evaluating <b>interpretability</b> <b>can</b> be very difficult (largely because it rarely makes sense to talk about <b>interpretability</b> outside of a specific context). The best possible evaluation of <b>interpretability</b> requires benchmarking it with respect to the relevant audience in a context. For example, if an interpretation claims to help understand radiology models, it should be tested based on how well it helps radiologists when actually making diagnoses. The papers here try to find more generic ...", "dateLastCrawled": "2021-11-06T01:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Explainable AI</b> - India | <b>IBM</b>", "url": "https://www.ibm.com/in-en/watson/explainable-ai", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ibm.com</b>/in-en/watson/<b>explainable-ai</b>", "snippet": "<b>Explainable AI</b> <b>can</b> help humans understand and explain <b>machine</b> learning (ML) algorithms, deep learning and neural networks. ML models are often <b>thought</b> of as black boxes that are impossible to interpret.\u00b2 Neural networks used in deep learning are some of the hardest for a human to understand. Bias, often based on race, gender, age or location ...", "dateLastCrawled": "2022-02-01T20:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The Myth of Model <b>Interpretability</b> - <b>KDnuggets</b>", "url": "https://www.kdnuggets.com/2015/04/model-interpretability-neural-networks-deep-learning.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2015/04/model-<b>interpretability</b>-neural-networks-deep-learning...", "snippet": "We should also note that <b>decision</b> trees, often championed for their <b>interpretability</b>, <b>can</b> be similarly opaque. To get accuracy rivaling other approaches, typically hundreds or thousands of <b>decision</b> trees are combined together in an ensemble. If we want just a single <b>decision</b> tree, this may come at the expense of the model&#39;s accuracy. And even with one tree, if it grows too large, it might cease to be interpretable, much like high-dimensional linear models.", "dateLastCrawled": "2022-01-08T01:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>How the machine &#39;thinks: Understanding opacity in</b> <b>machine</b> ...", "url": "https://www.researchgate.net/publication/289555278_How_the_machine_'thinks_Understanding_opacity_in_machine_learning_algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/289555278_<b>How_the_machine</b>_", "snippet": "<b>Ho w the machine \u2018thinks\u2019: Understanding. opacity in machine learning</b> algorithms. Jenna Burrell. Abstract. This article considers the issue of opacity as a pr oblem for socially consequential ...", "dateLastCrawled": "2022-01-23T12:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpreting Machine Learning Models - Introduction</b> \u00b7 Sujay S Kumar", "url": "https://sujayskumar.com/2019/07/10/interpreting-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://sujayskumar.com/2019/07/10/interpreting-<b>machine</b>-learning", "snippet": "We, as humans, tend to give more importance to how a <b>decision</b> was <b>arrived</b> at rather than the <b>decision</b> itself. Taking an advisor-investor relationship as an example, if the advisor recommends a particular stock to the investor, he needs to explain why he came to that <b>decision</b>. Even if the investor is not as savvy as the advisor and might not grasp all the <b>decision</b> making factors of the advisor, he will be wary of investing without any type of explanation. And if the advisor insists on not ...", "dateLastCrawled": "2021-12-03T02:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Supervised Learning With Python</b> - Oracle", "url": "https://blogs.oracle.com/ai-and-datascience/post/supervised-learning-with-python", "isFamilyFriendly": true, "displayUrl": "https://blogs.oracle.com/ai-and-datascience/post/<b>supervised-learning-with-python</b>", "snippet": "Here, <b>interpretability</b> refers to the ability to see how a model <b>arrived</b> at a particular answer, or at a higher level, why the model made the decisions it did. This tradeoff <b>can</b> be viewed in terms of the overall flexibility of a model. Models that are less flexible tend to be less accurate, as they assume a somewhat rigid form of f(x), and <b>can</b> only produce a small range of estimates. Most real world phenomena do not follow such an explicit form, and thus the model will not be able to ...", "dateLastCrawled": "2022-01-26T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is <b>Explainable AI</b> (XAI)?. An introduction to building trust in ...", "url": "https://towardsdatascience.com/what-is-explainable-ai-xai-afc56938d513", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/what-is-<b>explainable-ai</b>-xai-afc56938d513", "snippet": "An introduction to building trust in <b>machine</b> learning through global and local variable importance using post-hoc explanations. Nicklas Ankarstad . Dec 30, 2020 \u00b7 8 min read. Photo by Fitore F on Unsplash. There is a lot of buzz around AI these days. Almost every company either has plans to incorporate AI, is actively using it, or is rebranding their old rule-based engines as AI-enabled technologies. As more and more companies embed AI and advanced analytics within a business process and ...", "dateLastCrawled": "2022-01-28T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Generating Understanding in Machine Learning Models</b>", "url": "https://www.researchgate.net/publication/342409369_Generating_Understanding_in_Machine_Learning_Models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342409369_Generating_<b>Understanding</b>_in_<b>Machine</b>...", "snippet": "F or some, <b>understanding</b> does not dep end on <b>interpretability</b>, but <b>can</b> come indirectly , either through the analysis of the dataset or from the ex- ternal support of the model.", "dateLastCrawled": "2021-08-09T06:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>The Case For Failsafe</b> Protocols In AI Based Automation Deployments", "url": "https://www.edgeverve.com/the-edge-quarterly/the-case-for-failsafe-protocols/", "isFamilyFriendly": true, "displayUrl": "https://www.edgeverve.com/the-edge-quarterly/<b>the-case-for-failsafe</b>-protocols", "snippet": "Finally, introducing high degrees of <b>interpretability</b> in model outputs allow humans to quickly identify why the model <b>arrived</b> at a particular <b>decision</b> and what are the alternative actions any human <b>can</b> take to avoid a catastrophic outcome. Achieving high degrees of <b>interpretability</b> requires developers to have a deep algorithmic <b>understanding</b> of AI algorithms and provide \u201csimple English readouts\u201d of features and how they contribute to <b>decision</b>-making capabilities. An example of human ...", "dateLastCrawled": "2022-01-25T18:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Perspectives on the challenges of generalizability, transparency and ...", "url": "https://www.sciencedirect.com/science/article/pii/S2666557321000318", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2666557321000318", "snippet": "It <b>can</b> be tempting to use <b>machine</b> learning models that come with a high degree of intrinsic <b>interpretability</b>, but they produce less accurate models. The reverse is true with black-box algorithms. However, the trade-off is that additional tools need to be used in order to unpack both the internals of the models at an abstract level, as well as a suite of tools that provide explanations at an individual level of each student. The second scenario places additional burdens on educational ...", "dateLastCrawled": "2022-01-22T06:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability Methods in Machine Learning</b>: A Brief Survey - Two Sigma", "url": "https://www.twosigma.com/articles/interpretability-methods-in-machine-learning-a-brief-survey/", "isFamilyFriendly": true, "displayUrl": "https://www.twosigma.com/articles/<b>interpretability-methods-in-machine-learning</b>-a-brief...", "snippet": "<b>Interpretability</b> remains a very active area of research in <b>machine</b> learning, and for good reason. The major model-agnostic methods surveyed in this post each represent a step toward more fully <b>understanding</b> <b>machine</b> learning models. As <b>machine</b> learning becomes more and more ubiquitous, grasping how these models find answers will be crucial to improving their performance and reliability.", "dateLastCrawled": "2022-02-02T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Review on Advances in <b>Machine</b> Learning <b>Interpretability</b>", "url": "https://www.irjet.net/archives/V8/i10/IRJET-V8I1062.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.irjet.net/archives/V8/i10/IRJET-V8I1062.pdf", "snippet": "A Review on Advances in <b>Machine</b> Learning <b>Interpretability</b> Kruthi N Raj Final Year B.E. Student, Department of Computer Science and Engineering, Bangalore Institute of Technology, Bengaluru, India-----***-----Abstract - Whilst AI systems provide astonishingly good and accurate results, it is difficult to comprehend why and how an algorithm <b>arrived</b> <b>at its</b> conclusions, giving rise to the black-box notion in the field. Interpretable <b>Machine</b> Learning is no longer a novelty; it is a need. As the ...", "dateLastCrawled": "2021-11-18T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Explainable AI (XAI) and Interpretable <b>Machine</b> Learning (IML) models ...", "url": "https://ambiata.com/blog/2021-04-12-xai-part-1/", "isFamilyFriendly": true, "displayUrl": "https://ambiata.com/blog/2021-04-12-xai-part-1", "snippet": "For these reasons, improving model transparency and <b>interpretability</b> not only helps us build safer, explainable, more performant models, but <b>can</b> also help build confidence and trust in the model and <b>its</b> output in the eyes of technical and non-technical stakeholders. This is especially important in environments where a poorly understood model could take actions that bring financial, reputational or regulatory risks.", "dateLastCrawled": "2022-01-28T21:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretability</b> With Accurate Small Models", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7861231/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7861231", "snippet": "As <b>Machine</b> Learning (ML) becomes pervasive in our daily lives, there is an increased desire to know how models reach specific decisions. In certain contexts this might not be important as long as the ML model itself works well, e.g., in product or movie recommendations. But for certain others, such as medicine and healthcare (Caruana et al., 2015; Ustun and Rudin, 2016), banking 1, defense applications 2, and law enforcement 3 model transparency is an important concern. Very soon ...", "dateLastCrawled": "2021-11-14T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "15. <b>Interpretability in Deep Learning</b> \u2014 Deep Learning for Molecules and ...", "url": "https://dmol.pub/dl/xai.html", "isFamilyFriendly": true, "displayUrl": "https://dmol.pub/dl/xai.html", "snippet": "15. <b>Interpretability in Deep Learning</b>. <b>Interpretability</b>, part of the broader topic of explainable AI (XAI), is the process of adding explanations to deep learning model predictions. These explanations should help us understand why particular predictions are made. This is a critical topic because being able to understand model predictions is ...", "dateLastCrawled": "2022-01-31T19:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Electronics | Free Full-Text | <b>Machine Learning</b> <b>Interpretability</b>: A ...", "url": "https://www.mdpi.com/2079-9292/8/8/832/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2079-9292/8/8/832/htm", "snippet": "In the context of <b>machine learning</b> (ML) systems, Kim et al. describe <b>interpretability</b> as \u201cthe degree to which a human <b>can</b> consistently predict the model\u2019s result\u201d . This means that the <b>interpretability</b> of a model is higher if it is easier for a person to reason and trace back why a prediction was made by the model. Comparatively, a model is more interpretable than another model if the prior\u2019s decisions are easier to understand than the decisions of the latter", "dateLastCrawled": "2022-02-02T09:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine learning applications in microbial ecology</b>, human microbiome ...", "url": "https://www.sciencedirect.com/science/article/pii/S2001037021000325", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2001037021000325", "snippet": "However, often <b>machine</b> learning models <b>can</b> be used as black boxes to predict a specific outcome, with little <b>understanding</b> of how the models <b>arrived</b> at predictions. Complex <b>machine</b> learning algorithms often may value higher accuracy and performance at the sacrifice of <b>interpretability</b>. In order to leverage <b>machine</b> learning into more translational research related to the microbiome and strengthen our ability to extract meaningful biological information, it is important for models to be ...", "dateLastCrawled": "2022-01-26T23:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Understanding SHAP(XAI) through LEAPS</b> - Analyttica", "url": "https://analyttica.com/understanding-shap-xai-through-leaps/", "isFamilyFriendly": true, "displayUrl": "https://analyttica.com/<b>understanding-shap-xai-through-leaps</b>", "snippet": "<b>Understanding SHAP(XAI) through LEAPS</b>. Published by Lakshmi E | Assistant Vice President, Client Solutions . Things to know before starting with SHAP What is Explainable AI (XAI) By definition, Explainable AI (XAI) refers to methods and techniques in the application of artificial intelligence technology (AI) such that the results of the solution <b>can</b> be understood by humans Explainable AI helps in justifying why a model has made a particular choice. It makes the <b>decision</b> transparent by ...", "dateLastCrawled": "2022-02-01T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>How pricing influences conversion rates: A</b> case study - smec", "url": "https://smarter-ecommerce.com/blog/en/data-science/how-pricing-influences-conversion-rates-a-case-study/", "isFamilyFriendly": true, "displayUrl": "https://smarter-ecommerce.com/blog/en/data-science/how-pricing-influences-conversion...", "snippet": "In certain practical applications, model insights, which illuminate how a model <b>arrived</b> <b>at its</b> predictions, <b>can</b> be even more valuable than the predictions themselves. Consider an example: During the pricing process, a retailer is particularly interested in <b>understanding</b> the link between product prices and conversion rates. A simple illustration (as below) might reveal that during a sale period, an increase in conversions <b>can</b> be expected. But to answer questions like \u201cHow does a 20% ...", "dateLastCrawled": "2022-02-02T23:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "AI Regulation Is Coming to Life Sciences: Three Steps to Take Now", "url": "https://www.cognizant.com/us/en/whitepapers/documents/ai-regulation-is-coming-to-life-sciences-three-steps-to-take-now-codex5980.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cognizant.com/us/en/whitepapers/documents/ai-regulation-is-coming-to-life...", "snippet": "To maximize the value of artificial intelligence and <b>machine</b> learning for patients, ... determine how an AI solution <b>arrived</b> at a conclusion. Governance models must be adapted to account for varying levels of risk tolerance and limits on the explainability and <b>interpretability</b> of AI/ML solutions. In addition, AI/ML governance frameworks must allow for modifications in how the AI/ML solutions are measured as the algorithms, and their uses, change. LS companies will need to demonstrate they ...", "dateLastCrawled": "2022-01-30T18:30:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/<b>interpretability</b>-in-ml-a-broad-overview", "snippet": "First, <b>interpretability</b> in <b>machine</b> <b>learning</b> is useful because it can aid in trust. As humans, we may be reluctant to rely on <b>machine</b> <b>learning</b> models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in something opaque, which we see when people confront new technology, and this can slow down adoption. Approaches to <b>interpretability</b> that focus on transparency could help mitigate some of these fears.", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Figure 1: <b>Interpretability</b> for <b>machine</b> <b>learning</b> models bridges the concrete objectives models optimize for and the real-world (and less easy to define) desiderata that ML applications aim to achieve. Introduction . The objectives <b>machine</b> <b>learning</b> models optimize for do not always reflect the actual desiderata of the task at hand. <b>Interpretability</b> in models allows us to evaluate their decisions and obtain information that the objective alone cannot confer. <b>Interpretability</b> takes many forms ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "snippet": "This provides a novel <b>analogy</b> between data compression and regularization. Qualitative and quantitative state-of-the-art results on three datasets. 20 / 33. Interpretable Lens Variable Model (ILVM) 21 / 33. Interactive <b>Interpretability</b> via Active <b>Learning</b> Interactive \u2018human-in-the-loop\u2019 <b>interpretability</b> Choose the point with index j that maximizes : ^j = argmax jI(s ; ) = H(s ) E q \u02da(z js)[H(s jz j)] = Z p(s j)log p(s j)ds + E q \u02da(z js) Z p (s jjz)log p (s jjz)ds : (5) Choose the point ...", "dateLastCrawled": "2022-01-19T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-16T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://arxiv.org/abs/2005.12800", "isFamilyFriendly": true, "displayUrl": "https://<b>arxiv</b>.org/abs/2005.12800", "snippet": "Principles of analogical reasoning have recently been applied in the context of <b>machine</b> <b>learning</b>, for example to develop new methods for classification and preference <b>learning</b>. In this paper, we argue that, while analogical reasoning is certainly useful for constructing new <b>learning</b> algorithms with high predictive accuracy, is is arguably not less interesting from an <b>interpretability</b> and explainability point of view. More specifically, we take the view that an <b>analogy</b>-based approach is a ...", "dateLastCrawled": "2021-10-24T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Confusion Matrices</b> &amp; <b>Interpretable ML</b> | by andrea b | high stakes ...", "url": "https://medium.com/high-stakes-design/interpretability-techniques-explained-in-simple-terms-f5e1573674f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/high-stakes-design/<b>interpretability</b>-techniques-explained-in-simple...", "snippet": "The best [<b>analogy</b>] I can think of is an indicator light in your car \u2014 [and the] <b>machine</b> that you plug in to tell you more about the readout. ANDREA: Do you see <b>interpretability</b>, primarily, as ...", "dateLastCrawled": "2021-03-22T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Economic Methodology Meets Interpretable Machine Learning</b> - Part I ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. Intro - Part ...", "dateLastCrawled": "2022-01-22T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Economic Methodology Meets Interpretable <b>Machine</b> <b>Learning</b> ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. But first ...", "dateLastCrawled": "2022-01-05T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "Neuroscience \u2194 <b>Interpretability</b>. <b>Analogy</b>: model=brain. Artificial neural networks are historically inspired by neuroscience, but I used to be pretty skeptical that the connection was anything more than superficial. I&#39;ve since come around: I now think this is a very deep connection. The thing that personally persuaded me was that, in my own investigations of what goes on inside neural networks, we kept finding things that were previously discovered by neuroscientists. The most recent ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chris Olah on what the hell is going on inside neural networks - 80,000 ...", "url": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/", "isFamilyFriendly": true, "displayUrl": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research", "snippet": "Chris is a <b>machine</b> <b>learning</b> researcher currently focused on neural network interpretability. Until last December he led OpenAI\u2019s interpretability team but along with some colleagues he recently moved on to help start a new AI lab focussed on large models and safety called Anthropic. Rob Wiblin: Before OpenAI he spent 4 years at Google Brain developing tools to visualize what\u2019s going on in neural networks. Chris was hugely impactful at Google Brain. He was second author on the launch of ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Marketing AI: Interpretability and Explainability</b> - Christopher S. Penn ...", "url": "https://www.christopherspenn.com/2021/03/marketing-ai-interpretability-and-explainability/", "isFamilyFriendly": true, "displayUrl": "https://www.christopherspenn.com/2021/03/<b>marketing-ai-interpretability-and-explainability</b>", "snippet": "<b>Interpretability is like</b> inspecting the baker\u2019s recipe for the cake. We look at the list of ingredients and the steps taken to bake the cake, and we verify that the recipe makes sense and the ingredients were good. This is a much more rigorous way of validating our results, but it\u2019s the most complete \u2013 and if we\u2019re in a high-stakes situation where we need to remove all doubt, this is the approach we take. Interpretability in AI is like that \u2013 we step through the code itself that ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Causal <b>Learning</b> From Predictive Modeling for Observational Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931928/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7931928", "snippet": "Given the recent success of <b>machine</b> <b>learning</b>, specifically deep <b>learning</b>, in several applications (Goodfellow et al., ... This statistical <b>interpretability is similar</b> in spirit to traditional interpretability. This allows to answer questions, such as \u201cdoes BMI influence susceptibility to Covid?\u201d Moreover, it has been argued that developing an effective CBN for practical applications requires expert knowledge when data collection is cumbersome (Fenton and Neil, 2012). This applies to ...", "dateLastCrawled": "2021-12-09T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimal <b>Predictive Clustering</b> - Dimitris Bertsimas", "url": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-predictive-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-<b>predictive-clustering</b>.pdf", "snippet": "Table 1 Comparison of major <b>machine</b> <b>learning</b> methods relative to each other across the metrics of performance (out-of-sample R2), scalability and interpretability. 1 is the best, while 5 is the worst. Optimal <b>Predictive Clustering</b> 3 From Table 1, we observe all existing methods have weakness in at least one category. We therefore seek to design a method that has strong performance in all three categories at the same time. Optimal <b>Predictive Clustering</b> (OPC) is an algorithm that uses mixed ...", "dateLastCrawled": "2021-11-24T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reviewing Challenges of Predicting Protein Melting Temperature Change ...", "url": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "snippet": "Predicting the effects of mutations on protein stability is a key problem in fundamental and applied biology, still unsolved even for the relatively simple case of small, soluble, globular, monomeric, two-state-folder proteins. Many articles discuss the limitations of prediction methods and of the datasets used to train them, which result in low reliability for actual applications despite globally capturing trends. Here, we review these and other issues by analyzing one of the most detailed ...", "dateLastCrawled": "2022-02-03T02:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "In my view, a shor t coming of interpretable <b>machine</b> <b>learning</b> is that it assumes to a degree that the data being fed into the model is always going to be suitable for human interpretation. This is not necessarily the case. For instance, let\u2019s say that a company is trying to implement interpretable <b>machine</b> <b>learning</b> to devise a credit scoring model, whereby prospective credit card applications are classified as approved or rejected based on numerous features. It is often the case that such ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Breaking the interpretability barrier - a</b> method for interpreting deep ...", "url": "http://www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "isFamilyFriendly": true, "displayUrl": "www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o between performance and inter-pretability. Graph classi cation is normally a domain which requires the ap-plication of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to in-terpret complex models post-hoc (brie y reviewed in section2). However, most ...", "dateLastCrawled": "2021-09-22T17:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Discovering Discriminative Nodes for Classi\ufb01cation with Deep Graph ...", "url": "http://muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "isFamilyFriendly": true, "displayUrl": "muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o\ufb00 between performance and inter-pretability. Graph classi\ufb01cation is normally a domain which requires the appli-cation of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to interpret complex models post-hoc (brie\ufb02y reviewed in Sect.2). However ...", "dateLastCrawled": "2021-09-02T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Confronting Abusive Language Online: A Survey from the Ethical and ...", "url": "https://www.arxiv-vanity.com/papers/2012.12305/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2012.12305", "snippet": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this ...", "dateLastCrawled": "2021-10-13T19:21:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(interpretability)  is like +(understanding how the machine arrived at its decision)", "+(interpretability) is similar to +(understanding how the machine arrived at its decision)", "+(interpretability) can be thought of as +(understanding how the machine arrived at its decision)", "+(interpretability) can be compared to +(understanding how the machine arrived at its decision)", "machine learning +(interpretability AND analogy)", "machine learning +(\"interpretability is like\")", "machine learning +(\"interpretability is similar\")", "machine learning +(\"just as interpretability\")", "machine learning +(\"interpretability can be thought of as\")", "machine learning +(\"interpretability can be compared to\")"]}