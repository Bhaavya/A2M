{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Explainability versus <b>Interpretability</b> of <b>Machine</b> <b>Learning</b> Models 1/2 ...", "url": "https://prevision.io/blog/explainability-versus-interpretability-of-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://prevision.io/.../<b>explainability</b>-versus-<b>interpretability</b>-of-<b>machine</b>-<b>learning</b>-<b>models</b>", "snippet": "This <b>ability</b>, how a <b>machine</b> <b>learning</b> algorithm came to <b>its</b> conclusions, is also called <b>interpretability</b>. <b>Interpretability</b> is a very active area of investigation among AI researchers in academia and industry. It differs slightly from explainability, trying to answer why an algorithm produces the responses it produces. Explainability can reveal the causes and effects of changes within a <b>model</b>, even if the inner workings of the <b>model</b> remain a mystery. How = <b>Interpretability</b> Why = Explainability ...", "dateLastCrawled": "2022-02-03T00:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Interpreting <b>machine</b> <b>learning</b> models | by Lars Hulstaert | Towards Data ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-70c30694a05f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-<b>machine</b>-<b>learning</b>-70c30694a05f", "snippet": "<b>Interpretability</b> of data and <b>machine</b> <b>learning</b> models is one of those aspects that is critical in the practical \u2018usefulness\u2019 of a data science pipeline and it ensures that the <b>model</b> is aligned with the problem you want to solve. Although it is easy to lose yourself in experimenting with state-of-the-art techniques when building models, being able to properly interpret your findings is an essential part of the data science process.", "dateLastCrawled": "2022-02-03T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/<b>interpretability</b>-in-ml-a-broad-overview", "snippet": "Manipulating and Measuring <b>Model</b> <b>Interpretability</b>, a large pre-registered study [2] from Microsoft Research, found that models with additional information <b>like</b> <b>model</b> weights were often not useful in helping users decide how to make more accurate judgments on their own or even notice when the <b>model</b> was wrong. Users were given either a black-box <b>model</b> or a more interpretable one.", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "3.1 Importance of <b>Interpretability</b> | Interpretable <b>Machine</b> <b>Learning</b>", "url": "https://christophm.github.io/interpretable-ml-book/interpretability-importance.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-book/<b>interpretability</b>-importance.html", "snippet": "The more a <b>machine</b>\u2019s decision affects a person\u2019s life, the more important it is for the <b>machine</b> <b>to explain</b> <b>its</b> behavior. If a <b>machine</b> <b>learning</b> <b>model</b> rejects a loan application, this may be completely unexpected for the applicants. They can only reconcile this inconsistency between expectation and reality with some kind of explanation. The explanations do not actually have to fully <b>explain</b> the situation, but should address a main cause. Another example is algorithmic product ...", "dateLastCrawled": "2022-02-03T05:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "On the <b>interpretability</b> of <b>machine</b> <b>learning</b>-based <b>model</b> for predicting ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6664803/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6664803", "snippet": "<b>Machine</b> <b>learning</b> <b>interpretability</b> is defined as the degree to which a <b>machine</b> <b>learning</b> user can understand and interpret the prediction made by a <b>machine</b> <b>learning</b> <b>model</b> [2, 3]. Despite the growing use of <b>machine</b> <b>learning</b>-based prediction models in the medical domains [ 4 \u2013 7 ], clinicians still find it hard to rely on these models in practice for different reasons.", "dateLastCrawled": "2022-01-22T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretability</b>, Explainability, and <b>Machine</b> <b>Learning</b> \u2013 What Data ...", "url": "https://www.kdnuggets.com/2020/11/interpretability-explainability-machine-learning.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/11/<b>interpretability</b>-<b>explainability</b>-<b>machine</b>-<b>learning</b>.html", "snippet": "Even a random forest <b>model</b> can offer a measure of the relative importance of each variable in generating the <b>model</b>\u2019s <b>predictions</b>. However, you won\u2019t know exactly how all the trees were constructed and how they all contributed together to the final <b>predictions</b> offered by the <b>model</b>. An example of the variable (feature) importance plot generated by the Forest <b>Model</b> Tool. Whichever method is used to gain insight into a <b>model</b>\u2019s operation, being able to discuss how it makes <b>predictions</b> with ...", "dateLastCrawled": "2022-01-25T14:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretable Machine Learning</b>: A Step-by-Step Guide", "url": "https://www.explorium.ai/blog/interpretability-and-explainability-part-1/", "isFamilyFriendly": true, "displayUrl": "https://www.explorium.ai/blog/<b>interpretability-and-explainability-part-1</b>", "snippet": "<b>Machine</b> <b>Learning</b> <b>interpretability</b> and explainability are becoming essential in solutions we build nowadays. In fields such as healthcare or banking, <b>interpretability</b> and explainability could for example help overcome some legal constraints. In solutions that support a human decision, it is essential to establish a trust relationship and <b>explain</b> the outcome and the internal mechanics of an algorithm. The whole idea behind interpretable and explainable ML is to avoid the black box effect.", "dateLastCrawled": "2022-02-02T14:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Model</b> <b>Complexity</b>, Accuracy and <b>Interpretability</b> | by Ann Sajee ...", "url": "https://towardsdatascience.com/model-complexity-accuracy-and-interpretability-59888e69ab3d", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>model</b>-<b>complexity</b>-accuracy-and-<b>interpretability</b>-59888e69ab3d", "snippet": "Part 1: <b>Model</b> <b>Complexity</b>, Accuracy and <b>Interpretability</b>. We will be using re a l world dataset to showcast the relationship between <b>complexity</b>, accuracy and <b>interpretability</b> <b>of a Machine</b> <b>Learning</b> <b>model</b>. We will try out <b>Machine</b> <b>learning</b> models of increasing <b>complexity</b> and see how accuracy increases and <b>interpretability</b> decreases with it.", "dateLastCrawled": "2022-02-02T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Explainable AI: A Review of <b>Machine</b> <b>Learning</b> <b>Interpretability</b> Methods", "url": "https://www.researchgate.net/publication/348032815_Explainable_AI_A_Review_of_Machine_Learning_Interpretability_Methods", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/348032815_<b>Explain</b>able_AI_A_Review_of_<b>Machine</b>...", "snippet": "Recent advances in artificial intelligence (AI) have led to <b>its</b> widespread industrial adoption, with <b>machine</b> <b>learning</b> systems demonstrating superhuman performance in a significant number of tasks.", "dateLastCrawled": "2022-01-25T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>How important is interpretability for a</b> <b>model</b> in <b>Machine</b> <b>Learning</b>? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-<b>model</b>-in-<b>Machine</b>-<b>Learning</b>", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/<b>interpretability</b>-in-ml-a-broad-overview", "snippet": "&quot;[o]n typical examples, we saw no significant difference between a transparent <b>model</b> with few features and a black-box <b>model</b> with many features in terms of how closely participants followed the <b>model</b>&#39;s <b>predictions</b>. We also saw that people would have been better off simply following the models rather than adjusting their <b>predictions</b>. Even more surprisingly, we found that transparent models had the unwanted effect of impairing people&#39;s <b>ability</b> to correct inaccurate <b>predictions</b>, seemingly due ...", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Towards the <b>Interpretability</b> of <b>Machine</b> <b>Learning</b> <b>Predictions</b> for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8122817/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8122817", "snippet": "In general, there are two approaches to <b>interpretability</b>: <b>model</b> <b>interpretability</b> and inference <b>interpretability</b> . <b>Model</b> <b>interpretability</b> relates to understanding how a <b>model</b> behaves in general, whereas inference <b>interpretability</b> aims to describe how systems decide on each instance. Hence, these are two facets of the same problem. However, in both cases, <b>interpretability</b> may be obtained by showing symbols (e.g., natural language or structured languages such as logical forms) <b>to explain</b> models ...", "dateLastCrawled": "2022-01-27T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Interpretable <b>Machine</b> <b>Learning</b>. Extracting human understandable\u2026 | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-1dec0f2f3e6b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/interpretable-<b>machine</b>-<b>learning</b>-1dec0f2f3e6b", "snippet": "What would happen if the <b>model</b>\u2019s <b>predictions</b> went awry? You would lose money. As long as the <b>model</b> is having no significant impact, <b>its</b> <b>interpretability</b> doesn\u2019t matter so much but when there are implications involved based on a <b>model</b>\u2019s prediction, be it financial or social, <b>interpretability</b> becomes relevant. Interpretable <b>Machine</b> <b>Learning</b>. Interpret means <b>to explain</b> or to present in understandable terms. In the context of ML systems, <b>interpretability</b> is the <b>ability</b> <b>to explain</b> or to ...", "dateLastCrawled": "2022-02-03T11:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Transferability: Humans possess a far greater <b>ability</b> to generalize than <b>machine</b> <b>learning</b> models do. <b>Model</b> <b>interpretability</b> helps us understand how models might fare when the test environment shifts from the training environment. In some cases, this shift is a natural consequence of the data itself, or as a result of the <b>model</b> deployment ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Explainability V/s <b>Interpretability In Artificial Intelligence</b>", "url": "https://analyticsindiamag.com/explainability-vs-interpretability-in-artificial-intelligence-and-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/<b>explainability</b>-vs-<b>interpretability</b>-in-", "snippet": "It is easier to know the reason behind certain decisions or <b>predictions</b> if the <b>interpretability</b> <b>of a machine</b> <b>learning</b> <b>model</b> is higher. Evaluation Of <b>Interpretability</b>. Application Level Evaluation: This is basically the real-task. It means putting the explanation into the product and the end user will do all the tests. Human Level Evaluation: This is a simple task or can be termed as a simplified application level evaluation. In this case, the experiments are carried out by laypersons by ...", "dateLastCrawled": "2022-02-01T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Explainable AI: A Review of <b>Machine</b> <b>Learning</b> <b>Interpretability</b> Methods", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7824368/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7824368", "snippet": "<b>Machine</b> <b>Learning</b> Fairness is a sub-domain of <b>machine</b> <b>learning</b> <b>interpretability</b> that focuses solely on the social and ethical impact of <b>machine</b> <b>learning</b> algorithms by evaluating them in terms impartiality and discrimination. The study of fairness in <b>machine</b> <b>learning</b> is becoming more broad and diverse, and it is progressing rapidly. Traditionally, the fairness <b>of a machine</b> <b>learning</b> system has been evaluated by checking the models\u2019 <b>predictions</b> and errors across certain demographic segments ...", "dateLastCrawled": "2022-01-29T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What <b>do you mean by &quot;interpretability&quot; in models</b>?", "url": "https://www.researchgate.net/post/What-do-you-mean-by-interpretability-in-models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What-<b>do-you-mean-by-interpretability-in-models</b>", "snippet": "<b>Interpretability</b> is closely connected with the <b>ability</b> of users to understand the <b>model</b>. Typical criteria are: * a small number of input features (only the necessary ones), ideally not more than 2 ...", "dateLastCrawled": "2021-12-24T19:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What exactly is meant by <b>explainability</b> and <b>interpretability</b> of AI ...", "url": "https://medium.com/analytics-vidhya/what-exactly-is-meant-by-explainability-and-interpretability-of-ai-bcea30ca1e56", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/what-exactly-is-meant-by-<b>explainability</b>-and...", "snippet": "A post hoc explanation of a <b>learning</b> <b>model</b> can be propounded, however, the <b>interpretability</b> of the <b>learning</b> <b>model</b> is a feature that is arrived at from the design of the <b>learning</b> <b>model</b> itself.", "dateLastCrawled": "2022-02-03T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Explainable AI: A Review of <b>Machine</b> <b>Learning</b> <b>Interpretability</b> Methods", "url": "https://www.researchgate.net/publication/348032815_Explainable_AI_A_Review_of_Machine_Learning_Interpretability_Methods", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/348032815_<b>Explain</b>able_AI_A_Review_of_<b>Machine</b>...", "snippet": "Recent advances in artificial intelligence (AI) have led to <b>its</b> widespread industrial adoption, with <b>machine</b> <b>learning</b> systems demonstrating superhuman performance in a significant number of tasks.", "dateLastCrawled": "2022-01-25T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>How important is interpretability for a</b> <b>model</b> in <b>Machine</b> <b>Learning</b>? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-<b>model</b>-in-<b>Machine</b>-<b>Learning</b>", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "\u201cMythos of <b>Model</b> <b>Interpretability</b>\u201d (Lipton 2016) lists the desiderata for which we desire <b>interpretability</b>, and describes the criteria by which the <b>interpretability</b> of models <b>can</b> be analyzed. We use this framework to discuss recent advances in <b>interpretability</b> research \u2013 LIME, SHAP, and the Olah method \u2013 and the tradeoffs that interpretable models present. Though <b>interpretability</b> research has made large advances, much more remains to be done as <b>machine</b> <b>learning</b> models are deployed ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Assessing the Local Interpretability of Machine Learning Models</b> | DeepAI", "url": "https://deepai.org/publication/assessing-the-local-interpretability-of-machine-learning-models", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../<b>assessing-the-local-interpretability-of-machine-learning-models</b>", "snippet": "\u201c<b>Interpretability</b>\u201d as a goal <b>can</b> be broadly divided into global <b>interpretability</b>, meaning understanding the entirety of a trained <b>model</b> including all decision paths, and local <b>interpretability</b>, the goal of understanding the results of a trained <b>model</b> on a specific input and small deviations from that input.In this paper, we focus on local <b>interpretability</b>, and on two specific definitions. We assess simulatability [] - here interpreted as the <b>ability</b> of a person to run a <b>model</b> and get the ...", "dateLastCrawled": "2022-01-20T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What <b>do you mean by &quot;interpretability&quot; in models</b>?", "url": "https://www.researchgate.net/post/What-do-you-mean-by-interpretability-in-models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What-<b>do-you-mean-by-interpretability-in-models</b>", "snippet": "<b>Interpretability</b> is closely connected with the <b>ability</b> of users to understand the <b>model</b>. Typical criteria are: * a small number of input features (only the necessary ones), ideally not more than 2 ...", "dateLastCrawled": "2021-12-24T19:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Explaining Explanations: <b>An Approach to Evaluating Interpretability of</b> ...", "url": "https://deepai.org/publication/explaining-explanations-an-approach-to-evaluating-interpretability-of-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>explain</b>ing-explanations-an-approach-to-evaluating...", "snippet": "The authors define <b>interpretability</b> as \u201cthe <b>ability</b> <b>to explain</b> or to present in understandable terms to a human\u201d and suggest a variety of definitions for explainability, converging on the notion that interpretation is the act of discovering the evaluations of an explanation. The authors attempt to reach consensus on the definition of interpretable <b>machine</b> <b>learning</b> and how it should be measured. While we are inspired by the taxonomy of this paper, we focus on the explainability aspect ...", "dateLastCrawled": "2022-01-03T03:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Legal requirements on explainability in machine learning</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10506-020-09270-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10506-020-09270-4", "snippet": "As deep <b>learning</b> and other highly accurate black-box models develop, the social demand or legal requirements for <b>interpretability</b> and explainability of <b>machine</b> <b>learning</b> models are becoming more significant (Pasquale 2015; Doshi-Velez and Kortz 2017).<b>Interpretability</b> <b>can</b> be defined as the <b>ability</b> for a <b>model</b> to be understood by <b>its</b> users (Kodratoff 1994).For instance, decision trees with a small number of nodes <b>can</b> be considered interpretable, while support vector machines and neural networks ...", "dateLastCrawled": "2022-02-02T17:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Explaining <b>Explanations: An Overview of Interpretability of Machine</b> ...", "url": "https://www.researchgate.net/publication/330880261_Explaining_Explanations_An_Overview_of_Interpretability_of_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330880261_<b>Explain</b>ing_Explanations_An_Overview...", "snippet": "Trust and credibility in <b>machine</b> <b>learning</b> models are bolstered by the <b>ability</b> of a <b>model</b> <b>to explain</b> <b>its</b> decisions. While explainability of deep <b>learning</b> models is a well-known challenge, a further ...", "dateLastCrawled": "2022-02-01T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretability: Cracking open the black</b> box \u2013 Part I \u2013 Deep &amp; Shallow", "url": "https://deep-and-shallow.com/2019/11/13/interpretability-cracking-open-the-black-box-part-i/", "isFamilyFriendly": true, "displayUrl": "https://deep-and-shallow.com/2019/11/13/<b>interpretability-cracking-open-the-black</b>-box...", "snippet": "Yann LeCun, Turing Award winner and Facebook\u2019s Chief AI Scientist and Cassie Kozyrkov, Google\u2019s Chief Decision Intelligence Engineer, are strong proponents of the line of <b>thought</b> that you <b>can</b> infer a <b>model</b>\u2019s reasoning by observing it\u2019s actions(i.e. <b>predictions</b> in a supervised <b>learning</b> framework) . On the other hand Microsoft Research\u2019s Rich Caruana and a few others have insisted that the models inherently have <b>interpretability</b> and not just derived through the performance of the <b>model</b>.", "dateLastCrawled": "2022-01-18T00:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>How important is interpretability for a</b> <b>model</b> in <b>Machine</b> <b>Learning</b>? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-<b>model</b>-in-<b>Machine</b>-<b>Learning</b>", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "An overview of <b>model</b> <b>explainability</b> in modern <b>machine</b> <b>learning</b> | by Rui ...", "url": "https://towardsdatascience.com/an-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-overview-of-<b>model</b>-<b>explainability</b>-in-modern-<b>machine</b>...", "snippet": "It\u2019s even possible to understand which features are the most salient in a <b>model</b>\u2019s <b>predictions</b>. In this article, I give a comprehensive overview of <b>model</b> <b>explainability</b> for deeper models in <b>machine</b> <b>learning</b>. I hope <b>to explain</b> how deeper models more traditionally considered \u201cblack boxes\u201d <b>can</b> actually be surprisingly explainable. We use <b>model</b>-agnostic methods to apply <b>interpretability</b> to all different kinds of black box models. Partial Dependence Plots. A partial dependence plot shows ...", "dateLastCrawled": "2022-01-31T22:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Definitions, methods, and applications in interpretable <b>machine</b> <b>learning</b>", "url": "https://www.pnas.org/content/116/44/22071", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/116/44/22071", "snippet": "<b>Machine</b> <b>learning</b> (ML) has recently received considerable attention for <b>its</b> <b>ability</b> to accurately predict a wide variety of complex phenomena. However, there is a growing realization that, in addition to <b>predictions</b>, ML models are capable of producing knowledge about domain relationships contained in data, often referred to as interpretations. These interpretations have found uses in their own right, e.g., medicine , policymaking , and science (3, 4), as well as in auditing the <b>predictions</b> ...", "dateLastCrawled": "2022-02-02T18:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Explainable AI: A Review of <b>Machine</b> <b>Learning</b> <b>Interpretability</b> Methods", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7824368/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7824368", "snippet": "<b>Machine</b> <b>Learning</b> Fairness is a sub-domain of <b>machine</b> <b>learning</b> <b>interpretability</b> that focuses solely on the social and ethical impact of <b>machine</b> <b>learning</b> algorithms by evaluating them in terms impartiality and discrimination. The study of fairness in <b>machine</b> <b>learning</b> is becoming more broad and diverse, and it is progressing rapidly. Traditionally, the fairness <b>of a machine</b> <b>learning</b> system has been evaluated by checking the models\u2019 <b>predictions</b> and errors across certain demographic segments ...", "dateLastCrawled": "2022-01-29T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "On the <b>interpretability</b> of <b>machine</b> <b>learning</b>-based <b>model</b> for predicting ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6664803/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6664803", "snippet": "<b>Machine</b> <b>learning</b> <b>interpretability</b> is defined as the degree to which a <b>machine</b> <b>learning</b> user <b>can</b> understand and interpret the prediction made by a <b>machine</b> <b>learning</b> <b>model</b> [2, 3]. Despite the growing use of <b>machine</b> <b>learning</b>-based prediction models in the medical domains [ 4 \u2013 7 ], clinicians still find it hard to rely on these models in practice for different reasons.", "dateLastCrawled": "2022-01-22T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "\u201cMythos of <b>Model</b> <b>Interpretability</b>\u201d (Lipton 2016) lists the desiderata for which we desire <b>interpretability</b>, and describes the criteria by which the <b>interpretability</b> of models <b>can</b> be analyzed. We use this framework to discuss recent advances in <b>interpretability</b> research \u2013 LIME, SHAP, and the Olah method \u2013 and the tradeoffs that interpretable models present. Though <b>interpretability</b> research has made large advances, much more remains to be done as <b>machine</b> <b>learning</b> models are deployed ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "3.1 Importance of <b>Interpretability</b> | Interpretable <b>Machine</b> <b>Learning</b>", "url": "https://christophm.github.io/interpretable-ml-book/interpretability-importance.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-book/<b>interpretability</b>-importance.html", "snippet": "The more a <b>machine</b>\u2019s decision affects a person\u2019s life, the more important it is for the <b>machine</b> <b>to explain</b> <b>its</b> behavior. If a <b>machine</b> <b>learning</b> <b>model</b> rejects a loan application, this may be completely unexpected for the applicants. They <b>can</b> only reconcile this inconsistency between expectation and reality with some kind of explanation. The explanations do not actually have to fully <b>explain</b> the situation, but should address a main cause. Another example is algorithmic product ...", "dateLastCrawled": "2022-02-03T05:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/<b>interpretability</b>-in-ml-a-broad-overview", "snippet": "First, <b>interpretability</b> in <b>machine</b> <b>learning</b> is useful because it <b>can</b> aid in trust. As humans, we may be reluctant to rely on <b>machine</b> <b>learning</b> models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in something opaque, which we see when people confront new technology, and this <b>can</b> slow down adoption. Approaches to <b>interpretability</b> that focus on transparency could help mitigate some of these fears.", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretability</b> in <b>Machine Learning</b>: Looking into ... - AltexSoft", "url": "https://www.altexsoft.com/blog/interpretability-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.altexsoft.com/blog/<b>interpretability</b>-<b>machine-learning</b>", "snippet": "It\u2019s not that we <b>can</b>\u2019t <b>explain</b> the design of these models. But rather it\u2019s challenging to grasp all factors and causations that lead to individual decisions. Because that\u2019s what makes ML great in the first place \u2014 an <b>ability</b> to consider hundreds or thousands of factors in data. And that\u2019s what actually makes ML trump traditional programming \u2014 it <b>can</b> surpass humans by many times in devising intricate logic. People, on the other hand, crave simple explanations. This black box ...", "dateLastCrawled": "2022-01-30T01:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretability Methods in Machine Learning</b>: A Brief Survey - Two Sigma", "url": "https://www.twosigma.com/articles/interpretability-methods-in-machine-learning-a-brief-survey/", "isFamilyFriendly": true, "displayUrl": "https://www.twosigma.com/articles/<b>interpretability-methods-in-machine-learning</b>-a-brief...", "snippet": "<b>Machine</b> <b>learning</b> (ML) models <b>can</b> be astonishingly good at making <b>predictions</b>, but they often <b>can</b>\u2019t yield explanations for their forecasts in terms that humans <b>can</b> easily understand. The features from which they draw conclusions <b>can</b> be so numerous, and their calculations so complex, that researchers <b>can</b> find it impossible to establish exactly why an algorithm produces the answers it does. It is possible, however, to determine how a <b>machine</b> <b>learning</b> algorithm arrived at <b>its</b> conclusions. This ...", "dateLastCrawled": "2022-02-02T19:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Interpretable <b>Machine</b> <b>Learning</b>. Extracting human understandable\u2026 | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-1dec0f2f3e6b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/interpretable-<b>machine</b>-<b>learning</b>-1dec0f2f3e6b", "snippet": "What would happen if the <b>model</b>\u2019s <b>predictions</b> went awry? You would lose money. As long as the <b>model</b> is having no significant impact, <b>its</b> <b>interpretability</b> doesn\u2019t matter so much but when there are implications involved based on a <b>model</b>\u2019s prediction, be it financial or social, <b>interpretability</b> becomes relevant. Interpretable <b>Machine</b> <b>Learning</b>. Interpret means <b>to explain</b> or to present in understandable terms. In the context of ML systems, <b>interpretability</b> is the <b>ability</b> <b>to explain</b> or to ...", "dateLastCrawled": "2022-02-03T11:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "On the <b>interpretability</b> of <b>machine</b> <b>learning</b>-based <b>model</b> for predicting ...", "url": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-0874-0", "isFamilyFriendly": true, "displayUrl": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-0874-0", "snippet": "Although complex <b>machine</b> <b>learning</b> models are commonly outperforming the traditional simple interpretable models, clinicians find it hard to understand and trust these complex models due to the lack of intuition and explanation of their <b>predictions</b>. The aim of this study to demonstrate the utility of various <b>model</b>-agnostic explanation techniques of <b>machine</b> <b>learning</b> models with a case study for analyzing the outcomes of the <b>machine</b> <b>learning</b> random forest <b>model</b> for predicting the individuals at ...", "dateLastCrawled": "2022-02-02T12:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Limitations of <b>Machine Learning</b> | by Matthew Stewart, PhD ...", "url": "https://towardsdatascience.com/the-limitations-of-machine-learning-a00e0c3040c6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-limitations-of-<b>machine-learning</b>-a00e0c3040c6", "snippet": "For this reason, <b>interpretability</b> is a paramount quality that <b>machine learning</b> methods should aim to achieve if they are to be applied in practice. The blossoming -omics sciences (genomics, proteomics, metabolomics and the like), in particular, have become the main target for <b>machine learning</b> researchers precisely because of their dependence on large and non-trivial databases.", "dateLastCrawled": "2022-02-02T17:57:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/<b>interpretability</b>-in-ml-a-broad-overview", "snippet": "First, <b>interpretability</b> in <b>machine</b> <b>learning</b> is useful because it can aid in trust. As humans, we may be reluctant to rely on <b>machine</b> <b>learning</b> models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in something opaque, which we see when people confront new technology, and this can slow down adoption. Approaches to <b>interpretability</b> that focus on transparency could help mitigate some of these fears.", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "snippet": "This provides a novel <b>analogy</b> between data compression and regularization. Qualitative and quantitative state-of-the-art results on three datasets. 20 / 33. Interpretable Lens Variable Model (ILVM) 21 / 33. Interactive <b>Interpretability</b> via Active <b>Learning</b> Interactive \u2018human-in-the-loop\u2019 <b>interpretability</b> Choose the point with index j that maximizes : ^j = argmax jI(s ; ) = H(s ) E q \u02da(z js)[H(s jz j)] = Z p(s j)log p(s j)ds + E q \u02da(z js) Z p (s jjz)log p (s jjz)ds : (5) Choose the point ...", "dateLastCrawled": "2022-01-19T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Figure 1: <b>Interpretability</b> for <b>machine</b> <b>learning</b> models bridges the concrete objectives models optimize for and the real-world (and less easy to define) desiderata that ML applications aim to achieve. Introduction . The objectives <b>machine</b> <b>learning</b> models optimize for do not always reflect the actual desiderata of the task at hand. <b>Interpretability</b> in models allows us to evaluate their decisions and obtain information that the objective alone cannot confer. <b>Interpretability</b> takes many forms ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "There is increasing emphasis on interpretable <b>machine</b> <b>learning</b> in the world of data. Models have been growing ever more complex with the use of neural networks becoming more mainstream, along with the sheer size of data being analysed today. In many cases, such complex models may not be fit for human interpretation in their own right. Therefore, there has been a push to make the model interpretable, whereby both the results and the process in achieving those results are understood by humans ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Economic Methodology Meets Interpretable <b>Machine</b> <b>Learning</b> ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. But first ...", "dateLastCrawled": "2022-01-05T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Economic Methodology Meets Interpretable Machine Learning</b> - Part I ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. Intro - Part ...", "dateLastCrawled": "2022-01-22T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-16T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://arxiv.org/abs/2005.12800", "isFamilyFriendly": true, "displayUrl": "https://<b>arxiv</b>.org/abs/2005.12800", "snippet": "Principles of analogical reasoning have recently been applied in the context of <b>machine</b> <b>learning</b>, for example to develop new methods for classification and preference <b>learning</b>. In this paper, we argue that, while analogical reasoning is certainly useful for constructing new <b>learning</b> algorithms with high predictive accuracy, is is arguably not less interesting from an <b>interpretability</b> and explainability point of view. More specifically, we take the view that an <b>analogy</b>-based approach is a ...", "dateLastCrawled": "2021-10-24T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "Neuroscience \u2194 <b>Interpretability</b>. <b>Analogy</b>: model=brain. Artificial neural networks are historically inspired by neuroscience, but I used to be pretty skeptical that the connection was anything more than superficial. I&#39;ve since come around: I now think this is a very deep connection. The thing that personally persuaded me was that, in my own investigations of what goes on inside neural networks, we kept finding things that were previously discovered by neuroscientists. The most recent ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chris Olah on what the hell is going on inside neural networks - 80,000 ...", "url": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/", "isFamilyFriendly": true, "displayUrl": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research", "snippet": "Chris is a <b>machine</b> <b>learning</b> researcher currently focused on neural network interpretability. Until last December he led OpenAI\u2019s interpretability team but along with some colleagues he recently moved on to help start a new AI lab focussed on large models and safety called Anthropic. Rob Wiblin: Before OpenAI he spent 4 years at Google Brain developing tools to visualize what\u2019s going on in neural networks. Chris was hugely impactful at Google Brain. He was second author on the launch of ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Marketing AI: Interpretability and Explainability</b> - Christopher S. Penn ...", "url": "https://www.christopherspenn.com/2021/03/marketing-ai-interpretability-and-explainability/", "isFamilyFriendly": true, "displayUrl": "https://www.christopherspenn.com/2021/03/<b>marketing-ai-interpretability-and-explainability</b>", "snippet": "<b>Interpretability is like</b> inspecting the baker\u2019s recipe for the cake. We look at the list of ingredients and the steps taken to bake the cake, and we verify that the recipe makes sense and the ingredients were good. This is a much more rigorous way of validating our results, but it\u2019s the most complete \u2013 and if we\u2019re in a high-stakes situation where we need to remove all doubt, this is the approach we take. Interpretability in AI is like that \u2013 we step through the code itself that ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Causal <b>Learning</b> From Predictive Modeling for Observational Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931928/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7931928", "snippet": "Given the recent success of <b>machine</b> <b>learning</b>, specifically deep <b>learning</b>, in several applications (Goodfellow et al., ... This statistical <b>interpretability is similar</b> in spirit to traditional interpretability. This allows to answer questions, such as \u201cdoes BMI influence susceptibility to Covid?\u201d Moreover, it has been argued that developing an effective CBN for practical applications requires expert knowledge when data collection is cumbersome (Fenton and Neil, 2012). This applies to ...", "dateLastCrawled": "2021-12-09T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimal <b>Predictive Clustering</b> - Dimitris Bertsimas", "url": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-predictive-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-<b>predictive-clustering</b>.pdf", "snippet": "Table 1 Comparison of major <b>machine</b> <b>learning</b> methods relative to each other across the metrics of performance (out-of-sample R2), scalability and interpretability. 1 is the best, while 5 is the worst. Optimal <b>Predictive Clustering</b> 3 From Table 1, we observe all existing methods have weakness in at least one category. We therefore seek to design a method that has strong performance in all three categories at the same time. Optimal <b>Predictive Clustering</b> (OPC) is an algorithm that uses mixed ...", "dateLastCrawled": "2021-11-24T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reviewing Challenges of Predicting Protein Melting Temperature Change ...", "url": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "snippet": "Predicting the effects of mutations on protein stability is a key problem in fundamental and applied biology, still unsolved even for the relatively simple case of small, soluble, globular, monomeric, two-state-folder proteins. Many articles discuss the limitations of prediction methods and of the datasets used to train them, which result in low reliability for actual applications despite globally capturing trends. Here, we review these and other issues by analyzing one of the most detailed ...", "dateLastCrawled": "2022-02-03T02:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "In my view, a shor t coming of interpretable <b>machine</b> <b>learning</b> is that it assumes to a degree that the data being fed into the model is always going to be suitable for human interpretation. This is not necessarily the case. For instance, let\u2019s say that a company is trying to implement interpretable <b>machine</b> <b>learning</b> to devise a credit scoring model, whereby prospective credit card applications are classified as approved or rejected based on numerous features. It is often the case that such ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Breaking the interpretability barrier - a</b> method for interpreting deep ...", "url": "http://www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "isFamilyFriendly": true, "displayUrl": "www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o between performance and inter-pretability. Graph classi cation is normally a domain which requires the ap-plication of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to in-terpret complex models post-hoc (brie y reviewed in section2). However, most ...", "dateLastCrawled": "2021-09-22T17:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Discovering Discriminative Nodes for Classi\ufb01cation with Deep Graph ...", "url": "http://muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "isFamilyFriendly": true, "displayUrl": "muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o\ufb00 between performance and inter-pretability. Graph classi\ufb01cation is normally a domain which requires the appli-cation of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to interpret complex models post-hoc (brie\ufb02y reviewed in Sect.2). However ...", "dateLastCrawled": "2021-09-02T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Confronting Abusive Language Online: A Survey from the Ethical and ...", "url": "https://www.arxiv-vanity.com/papers/2012.12305/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2012.12305", "snippet": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this ...", "dateLastCrawled": "2021-10-13T19:21:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(interpretability)  is like +(the ability of a machine learning model to explain its predictions)", "+(interpretability) is similar to +(the ability of a machine learning model to explain its predictions)", "+(interpretability) can be thought of as +(the ability of a machine learning model to explain its predictions)", "+(interpretability) can be compared to +(the ability of a machine learning model to explain its predictions)", "machine learning +(interpretability AND analogy)", "machine learning +(\"interpretability is like\")", "machine learning +(\"interpretability is similar\")", "machine learning +(\"just as interpretability\")", "machine learning +(\"interpretability can be thought of as\")", "machine learning +(\"interpretability can be compared to\")"]}