{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Cooperative <b>Swarm</b> based Evolutionary Approach to find optimal cluster ...", "url": "http://ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "isFamilyFriendly": true, "displayUrl": "ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "snippet": "<b>Centroid-based</b> <b>clustering</b> is a NP-hard optimization problem, and thus the common approach is to search for cluster centers only for approximate solutions. Well-known <b>centroid-based</b> <b>clustering</b> methods are k-means, k-medoids and fuzzy c-means. In this paper we proposed <b>swarm</b> intelligence based nature-inspired center-based <b>clustering</b> method using PSO optimization. PSO searches the optimized solution from available solutions in multidimensional search space. So PSO is capable to search best ...", "dateLastCrawled": "2021-09-15T23:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Artificial intelligence approaches and mechanisms for big data ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8053021/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8053021", "snippet": "Ianni et al. (2020) introduced a parallel version of CLUBS + <b>centroid-based</b> <b>clustering</b> algorithm, named CLUBS-P, for efficient <b>centroid-based</b> <b>clustering</b>. The presented unsupervised algorithm provides high-quality clusters of data around the cluster centroid. The authors examined the performance of the proposed algorithm against the performance of the parallel k-means <b>clustering</b>. The results revealed that the algorithm can achieve high accuracy and high scalability.", "dateLastCrawled": "2021-10-12T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Nature Inspired Techniques for Data <b>Clustering</b>", "url": "https://www.researchgate.net/profile/Sandeep-Mane-6/publication/269301299_Nature_inspired_techniques_for_data_clustering/links/5c94a2f7a6fdccd460318791/Nature-inspired-techniques-for-data-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../Nature-inspired-techniques-for-data-<b>clustering</b>.pdf", "snippet": "artificial <b>bee</b> colony algorithm, particle <b>swarm</b> optimization, ant colony optimization, bat algorithm, firefly algorithm, glowworm <b>swarm</b> optimization etc. In this paper we have given overview of ...", "dateLastCrawled": "2021-07-08T08:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A population based hybrid FCM-PSO <b>algorithm for clustering analysis and</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417420308691", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417420308691", "snippet": "In FCM, the <b>centroid based</b> <b>clustering</b> algorithm, if the final cluster&#39;s centroid is significantly far from the actual cluster&#39;s centroid, then the <b>clustering</b> result will deteriorate. However, the population based metaheuristic PSO is a global optimization algorithm based on a random search technique, but the <b>clustering</b> performance is poor. To overcome the local minima trapping problem of FCM and achieve the promising PSO results, we have proposed a hybrid FCM-PSO algorithm, which combines ...", "dateLastCrawled": "2022-01-19T00:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Swarm</b> Intelligence Algorithms in Text Document <b>Clustering</b> with Various ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8125674/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8125674", "snippet": "SI algorithms include particle <b>swarm</b> optimization (PSO), the bat algorithm (BA), grey wolf optimization (GWO), the firefly algorithm (FFA), ant colony optimization (ACO), the artificial fish <b>swarm</b> algorithm (AFSA), and artificial <b>bee</b> colony optimization (ABC) . These algorithms can be used in many real-world problems such as traveling salesman problems (TSPs), feature selection (FS), robot <b>swarm</b> learning, cluster analysis, and scheduling. SI algorithms have advantages <b>like</b> adaptability ...", "dateLastCrawled": "2021-08-03T12:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Swarm intelligence based clustering technique for automated lesion</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1476927118302524", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1476927118302524", "snippet": "There are a total of eight different suitable combinations of conventional <b>clustering</b> (i.e., K-means and Fuzzy C-means (FCMs)) and four <b>swarm</b> intelligence (SI) techniques (i.e., seeker optimization (SO), artificial <b>bee</b> colony (ABC), ant colony optimization (ACO) and particle <b>swarm</b> optimization (PSO)) have been implemented in this study. The experiments are performed on the dataset of 780 psoriasis images from 74 patients collected at Psoriasis Clinic and Research Centre, Psoriatreat, Pune ...", "dateLastCrawled": "2021-11-14T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Improved clustering criterion for image clustering</b> with artificial <b>bee</b> ...", "url": "https://link.springer.com/article/10.1007%2Fs10044-014-0365-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10044-014-0365-y", "snippet": "In this paper, a new objective function is proposed for image <b>clustering</b> and is applied with the artificial <b>bee</b> colony (ABC) algorithm, the particle <b>swarm</b> optimization algorithm and the genetic algorithm. The performance of the proposed objective function is tested on seven benchmark images by comparing it with the three well-known objective functions in the literature and the K-means algorithm in terms of separateness and compactness which are the main criterions of the <b>clustering</b> problem ...", "dateLastCrawled": "2022-01-16T19:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Kao and Cheng (2006) designed a <b>centroid-based</b> ACO <b>clustering</b> algorithm, where ants assign each data instance to one of the available clusters and cluster centroids are adjusted based on this ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A YBRID ARMONIC MEANS WITH ABCCLUSTERING ALGORITHM USING AN OPTIMAL K ...", "url": "https://aircconline.com/ijci/V5N2/5216ijci06.pdf", "isFamilyFriendly": true, "displayUrl": "https://aircconline.com/ijci/V5N2/5216ijci06.pdf", "snippet": "<b>like</b> its sensitivity to initialization, provides local optimum solutions. K-harmonic means <b>clustering</b> is an improved variant of K-means which is insensitive to the initialization of centroids, but still in some cases it ends up with local optimum solutions. <b>Clustering</b> using Artificial <b>Bee</b> Colony (ABC) algorithm always gives global optimum solutions. In this paper a new hybrid <b>clustering</b> algorithm (KHM-ABC) is presented by combining both K-harmonic means and ABC algorithm to perform accurate ...", "dateLastCrawled": "2022-01-20T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Artificial intelligence approaches and mechanisms for</b> big data ... - PeerJ", "url": "https://peerj.com/articles/cs-488/", "isFamilyFriendly": true, "displayUrl": "https://peerj.com/articles/cs-488", "snippet": "Ianni et al. (2020) introduced a parallel version of CLUBS + <b>centroid-based</b> <b>clustering</b> algorithm, named CLUBS-P, for efficient <b>centroid-based</b> <b>clustering</b>. The presented unsupervised algorithm provides high-quality clusters of data around the cluster centroid. The authors examined the performance of the proposed algorithm against the performance of the parallel k-means <b>clustering</b>. The results revealed that the algorithm can achieve high accuracy and high scalability.", "dateLastCrawled": "2022-02-01T07:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Cooperative <b>Swarm</b> based Evolutionary Approach to find optimal cluster ...", "url": "http://ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "isFamilyFriendly": true, "displayUrl": "ijcsi.org/papers/IJCSI-9-3-1-425-434.pdf", "snippet": "<b>Centroid-based</b> <b>clustering</b> is a NP-hard optimization problem, and thus the common approach is to search for cluster centers only for approximate solutions. Well-known <b>centroid-based</b> <b>clustering</b> methods are k-means, k-medoids and fuzzy c-means. In this paper we proposed <b>swarm</b> intelligence based nature-inspired center-based <b>clustering</b> method using PSO optimization. PSO searches the optimized solution from available solutions in multidimensional search space. So PSO is capable to search best ...", "dateLastCrawled": "2021-09-15T23:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Modified ACS Centroid Memory for Data <b>Clustering</b>", "url": "http://repo.uum.edu.my/27858/1/jcssp%2015%2010%202019%201439%201449.pdf", "isFamilyFriendly": true, "displayUrl": "repo.uum.edu.my/27858/1/jcssp 15 10 2019 1439 1449.pdf", "snippet": "<b>centroid-based</b> <b>clustering</b> is the label position, in which the label refers to the current cluster number. The algorithm is a dynamic cluster center (centroid) and each iteration is randomly updated. Once updated, the pheromone information is forgotten and the algorithm learning process is lost. In this case, the algorithm is unable to transfer previous information to the next iterations. The algorithm becomes a local search algorithm <b>similar</b> to the K-means algorithm. The pheromone ...", "dateLastCrawled": "2021-08-28T00:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Clustering</b> Algorithms: Their Application to Gene Expression Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5135122/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5135122", "snippet": "Model-based <b>clustering</b> algorithm might sometimes rely on the suppositions that the dataset fits a specific distribution. 4 SOM <b>similar</b> to K-means and PAM, requires the grid structure and the number of clusters as inputs. 1, 4, 75, 85, 86 SOM maps high-dimensional data into 2D or 3D space. 1 SOM is widely adopted as a <b>clustering</b> technique for gene expression data; however, the attempt to merge different patterns into a cluster can make SOM ineffective. 4 Each time it produces an unstable ...", "dateLastCrawled": "2022-01-28T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Water End Use <b>Clustering</b> Using Hybrid Pattern Recognition Techniques ...", "url": "http://www.ijmlc.org/vol8/733-L034.pdf", "isFamilyFriendly": true, "displayUrl": "www.ijmlc.org/vol8/733-L034.pdf", "snippet": "K-Medoids <b>clustering</b> is one of the <b>centroid-based</b> <b>clustering</b> or rather, an improved algorithm of K-means. Its advantages include: (i) K- Medoids algorithm has the ability to process a large dataset. (ii) K-Medoids algorithm can reduce the effect of the outliers on the results. However, K-Medoids <b>clustering</b> also has advantages such as the influence of initial medoids being strong and the ability of global searching being poor. B. Data <b>Clustering</b> in Water End Use Analysis . DTW algorithm is a ...", "dateLastCrawled": "2021-11-22T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Kao and Cheng (2006) designed a <b>centroid-based</b> ACO <b>clustering</b> algorithm, where ants assign each data instance to one of the available clusters and cluster centroids are adjusted based on this ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A population based hybrid FCM-PSO <b>algorithm for clustering analysis and</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417420308691", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417420308691", "snippet": "<b>Clustering</b>&#39;s objective is grouping the unlabeled data into groups (called clusters) such that data in one cluster are more <b>similar</b> to each other and are dissimilar to the data in other clusters. The unlabeled data in the same cluster are more <b>similar</b> than data in other clusters. It is like a group of people with a particular interest in the social network, where they have some <b>similar</b> opinion. With time, different <b>clustering</b> methods have been defined and categorized as <b>centroid based</b> ...", "dateLastCrawled": "2022-01-19T00:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Improved clustering criterion for image clustering</b> with artificial <b>bee</b> ...", "url": "https://link.springer.com/article/10.1007%2Fs10044-014-0365-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10044-014-0365-y", "snippet": "In this paper, a new objective function is proposed for image <b>clustering</b> and is applied with the artificial <b>bee</b> colony (ABC) algorithm, the particle <b>swarm</b> optimization algorithm and the genetic algorithm. The performance of the proposed objective function is tested on seven benchmark images by comparing it with the three well-known objective functions in the literature and the K-means algorithm in terms of separateness and compactness which are the main criterions of the <b>clustering</b> problem ...", "dateLastCrawled": "2022-01-16T19:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A YBRID ARMONIC MEANS WITH ABCCLUSTERING ALGORITHM USING AN OPTIMAL K ...", "url": "https://aircconline.com/ijci/V5N2/5216ijci06.pdf", "isFamilyFriendly": true, "displayUrl": "https://aircconline.com/ijci/V5N2/5216ijci06.pdf", "snippet": "<b>Clustering</b> using Artificial <b>Bee</b> Colony (ABC) algorithm always gives global optimum solutions. In this paper a new hybrid <b>clustering</b> algorithm (KHM-ABC) is presented by combining both K-harmonic means and ABC algorithm to perform accurate <b>clustering</b>. Experimental results indicate that the performance of the proposed algorithm is superior to the available algorithms in terms of the quality of clusters. KEYWORDS Data Mining, <b>Clustering</b>, K-means <b>Clustering</b>, K-Harmonic means <b>Clustering</b> ...", "dateLastCrawled": "2022-01-20T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Centroid-Based</b> Particle <b>Swarm</b> Optimization Variant for Data ...", "url": "https://www.researchgate.net/publication/330937798_Centroid-Based_Particle_Swarm_Optimization_Variant_for_Data_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330937798_<b>Centroid-Based</b>_Particle_<b>Swarm</b>...", "snippet": "Request PDF | <b>Centroid-Based</b> Particle <b>Swarm</b> Optimization Variant for Data Classification | Recently, data mining has become more attractive for researchers as a technique to analyze and transform ...", "dateLastCrawled": "2022-02-03T08:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Density-based particle swarm optimization algorithm for data clustering</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417417305912", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417417305912", "snippet": "In the particle <b>swarm</b> <b>clustering</b> (PSC) proposed by Cohen and Castro (2006), noticeable modifications were made to the traditional PSO algorithm. Instead of each particle being the whole solution, it acts as a prototype that represents a portion of the solution. In other words, the whole <b>swarm</b> encodes the final <b>clustering</b> solution to the input data, and each particle holds information associated with one cluster. The fitness function is replaced with the distances between particles and the ...", "dateLastCrawled": "2021-12-14T01:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) A Hybrid Sequential Approach for Data <b>Clustering</b> Using K-Means ...", "url": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_Clustering_Using_K_Means_and_Particle_Swarm_Optimization_Algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/61182164/A_Hybrid_Sequential_Approach_for_Data_<b>Clustering</b>...", "snippet": "However, if good initial <b>clustering</b> centroids <b>can</b> be obtained using any of the other techniques, the K-Means would work well in refining the <b>clustering</b> centroids to find the optimal <b>clustering</b> centers. The same idea is proposed in this paper to determine initial points for K-Means algorithm by some other global optimization search algorithms. Evolutionary and bio-inspired algorithms eradicate some of the above mentioned difficulties and are quickly replacing the classical methods in solving ...", "dateLastCrawled": "2022-01-18T07:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Kao and Cheng (2006) designed a <b>centroid-based</b> ACO <b>clustering</b> algorithm, where ants assign each data instance to one of the available clusters and cluster centroids are adjusted based on this ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Cooperative bare-bone particle <b>swarm</b> optimization for data <b>clustering</b> ...", "url": "https://www.researchgate.net/publication/271924160_Cooperative_bare-bone_particle_swarm_optimization_for_data_clustering", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/271924160_Cooperative_bare-bone_particle...", "snippet": "Jiang and Wang [24] proposed cooperative bare-bone particle <b>swarm</b> optimization (CBPSO) for data <b>clustering</b>, using a new <b>centroid-based</b> encoding scheme for each particle and the Chernoff bounds on ...", "dateLastCrawled": "2022-01-30T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Public Science Framework-Journals - Paper - HTML", "url": "http://files.aiscience.org/journal/article/html/70270006.html", "isFamilyFriendly": true, "displayUrl": "files.aiscience.org/journal/article/html/70270006.html", "snippet": "In <b>centroid-based</b> <b>clustering</b>, clusters are represented by a central vector, which may not necessarily be a member of the data set. When the number of clusters is fixed to k, k-means <b>clustering</b> gives a formal definition as an optimization problem: find the k cluster centers and assign the objects to the nearest cluster center, such that the squared distances from the cluster are minimized. 34-39", "dateLastCrawled": "2021-11-21T01:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "MOMHR: A Dynamic Multi-hop Routing Protocol for WSN Using Heuristic ...", "url": "https://link.springer.com/article/10.1007/s11277-019-06891-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11277-019-06891-0", "snippet": "Jain et al. used a Multi Objective Particle <b>Swarm</b> Optimization (MOPSO) to propose a novel Multi-objective Load Balancing <b>Clustering</b> (MLBC) method. Energy Efficiency and Reliability are the two mentioned objective functions. Based on the usual residual energy of Cluster Heads (CHs) the energy efficiency is considered, whereas the reliability is formed on the inter-cluster routings communication cost. The nodes in single-hop or multi-hop mode transmit their information to CH or Base Station ...", "dateLastCrawled": "2022-01-11T10:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Comprehensive Survey <b>on Particle Swarm Optimization Algorithm and</b> Its ...", "url": "https://www.hindawi.com/journals/mpe/2015/931256/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/mpe/2015/931256", "snippet": "Particle <b>swarm</b> optimization (PSO) is a heuristic global optimization method, proposed originally by Kennedy and Eberhart in 1995. It is now one of the most commonly used optimization techniques. This survey presented a comprehensive investigation of PSO. On one hand, we provided advances with PSO, including its modifications (including quantum-behaved PSO, bare-bones PSO, chaotic PSO, and fuzzy PSO), population topology (as fully connected, von Neumann, ring, star, random, etc ...", "dateLastCrawled": "2022-02-02T04:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Kernel-based multiobjective clustering algorithm with automatic</b> ...", "url": "https://link.springer.com/article/10.1007%2Fs00500-017-2590-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00500-017-2590-y", "snippet": "<b>Clustering</b> algorithms with attribute weighting have gained much attention during the last decade. However, they usually optimize a single-objective function that <b>can</b> be a limitation to cope with different kinds of data, especially those with non-hyper-spherical shapes and/or linearly non-separable patterns. In this paper, the multiobjective optimization approach is introduced into the kernel-based attribute-weighted <b>clustering</b> algorithm, in which two objective functions separately ...", "dateLastCrawled": "2021-12-26T04:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Intelligent Engineering Informatics [PDF] [7le0imhdvnn0]", "url": "https://vdoc.pub/documents/intelligent-engineering-informatics-7le0imhdvnn0", "isFamilyFriendly": true, "displayUrl": "https://vdoc.pub/documents/intelligent-engineering-informatics-7le0imhdvnn0", "snippet": "Many metaheuristic methods such as tabu search [2, 15], unconscious search [3], discrete particle <b>swarm</b> optimization [16], arti\ufb01cial <b>bee</b> colony optimization [17, 18], genetic algorithm [5], simulated annealing [19], ant colony optimization [20], \ufb01re\ufb02y algorithm [21] have been developed for solving UFLP. The Monkey Algorithm (MA) is a relatively new <b>swarm</b> intelligence-based algorithm. MA was proposed by Zhao and Tang in 2008 [22]. MA simulates the mountainclimbing processes of monkeys ...", "dateLastCrawled": "2022-01-28T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Top PDF genetic-algorithm based methodology - 1Library", "url": "https://1library.net/subject/genetic-algorithm-based-methodology", "isFamilyFriendly": true, "displayUrl": "https://1library.net/subject/genetic-algorithm-based-methodology", "snippet": "The advantage of GA it <b>can</b> emulates natural genetic operator such as reproduction, crossover, and mutation. Several studies have been conducted to implement this technique on solving BJ traditional procedure. Ong [29] focus on GA-based model identification to solve problem on local optima in the family of BJ model. While Hammour [30] apply GA technique to estimate orders and parameters of ARMA model. Since GA is more likely to converge towards a global optimum solution. The motivation of ...", "dateLastCrawled": "2021-04-24T00:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Internet of Things (IoT): Concepts and Applications (S.M.A.R.T ...", "url": "https://dokumen.pub/internet-of-things-iot-concepts-and-applications-smart-environments-1nbsped-303037467x-9783030374679.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/internet-of-things-iot-concepts-and-applications-smart...", "snippet": "Data mining techniques such as classification, regression and <b>clustering</b> <b>can</b> be done on data to find classes, groups or abnormalities, trends in acquired sensor data. Query Processing: It is the process for querying the data stored in the IoT platform. Querying mechanism also uses publish/subscribe mechanism like data acquisition (Cheng et al. 2015). The query <b>can</b> be a simple query or complex query aggregating data from multiple databases. Data Visualization: in response to users query on ...", "dateLastCrawled": "2022-01-30T06:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Centroid-Based</b> Particle <b>Swarm</b> Optimization Variant for Data Classi\ufb01cation", "url": "http://cs.ndsu.edu/~siludwig/Publish/papers/SSCI2018.pdf", "isFamilyFriendly": true, "displayUrl": "cs.ndsu.edu/~siludwig/Publish/papers/SSCI2018.pdf", "snippet": "<b>compared</b> to twelve classi\ufb01cation algorithms. The experimental results show that the CPSO algorithm is competitive <b>compared</b> to other classi\ufb01cation algorithms. In addition, the algorithm <b>can</b> be ef\ufb01ciently used for data classi\ufb01cation. Index Terms\u2014Classi\ufb01cation, Particle <b>Swarm</b> Optimization I. INTRODUCTION Data mining is a process of discovering hidden patterns and extracting valuable information from raw data sets. It is an interdisciplinary research area which combines dif-ferent ...", "dateLastCrawled": "2021-12-23T19:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Centroid-Based</b> Particle <b>Swarm</b> Optimization Variant for Data ...", "url": "https://www.researchgate.net/publication/330937798_Centroid-Based_Particle_Swarm_Optimization_Variant_for_Data_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330937798_<b>Centroid-Based</b>_Particle_<b>Swarm</b>...", "snippet": "Request PDF | <b>Centroid-Based</b> Particle <b>Swarm</b> Optimization Variant for Data Classification | Recently, data mining has become more attractive for researchers as a technique to analyze and transform ...", "dateLastCrawled": "2022-02-03T08:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Clustering</b> Algorithms: Their Application to Gene Expression Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5135122/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5135122", "snippet": "K-means <b>clustering</b> algorithm is a renowned <b>clustering</b> method; however, the computational complexity of the original K-means algorithm 13 is very high, especially for large datasets and for real-life problem, 2 the number of expected clusters is required, \u201csuitable number of clusters cannot be predicted\u201d.1,2,4,5,16,71,76,80,85 Handhayani and Hiryanto 16 proposed a fully unsupervised <b>clustering</b> method called IKKM, which <b>can</b> be used to cluster the gene in the feature space.", "dateLastCrawled": "2022-01-28T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Swarm</b> Intelligence Algorithms in Text Document <b>Clustering</b> with Various ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8125674/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8125674", "snippet": "<b>Compared</b> to traditional <b>clustering</b> algorithms, these solving mechanisms make <b>swarm</b> algorithms suitable for resolving complex document <b>clustering</b> problems. However, each SI algorithm shows a different performance based on its own strengths and weaknesses. In this paper, to find the best performing SI algorithm in text document <b>clustering</b>, we performed a comparative study for the PSO, bat, grey wolf optimization (GWO), and K-means algorithms using six data sets of various sizes, which were ...", "dateLastCrawled": "2021-08-03T12:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>An ACO-based clustering algorithm</b> - ResearchGate", "url": "https://www.researchgate.net/publication/220901705_An_ACO-based_clustering_algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220901705_<b>An_ACO-based_clustering_algorithm</b>", "snippet": "Kao and Cheng (2006) designed a <b>centroid-based</b> ACO <b>clustering</b> algorithm, where ants assign each data instance to one of the available clusters and cluster centroids are adjusted based on this ...", "dateLastCrawled": "2021-10-25T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Water End Use <b>Clustering</b> Using Hybrid Pattern Recognition Techniques ...", "url": "http://www.ijmlc.org/vol8/733-L034.pdf", "isFamilyFriendly": true, "displayUrl": "www.ijmlc.org/vol8/733-L034.pdf", "snippet": "K-Medoids <b>clustering</b> is one of the <b>centroid-based</b> <b>clustering</b> or rather, an improved algorithm of K-means. Its advantages include: (i) K- Medoids algorithm has the ability to process a large dataset. (ii) K-Medoids algorithm <b>can</b> reduce the effect of the outliers on the results. However, K-Medoids <b>clustering</b> also has advantages such as the influence of initial medoids being strong and the ability of global searching being poor. B. Data <b>Clustering</b> in Water End Use Analysis . DTW algorithm is a ...", "dateLastCrawled": "2021-11-22T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Swarm intelligence based clustering technique for automated lesion</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1476927118302524", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1476927118302524", "snippet": "There are a total of eight different suitable combinations of conventional <b>clustering</b> (i.e., K-means and Fuzzy C-means (FCMs)) and four <b>swarm</b> intelligence (SI) techniques (i.e., seeker optimization (SO), artificial <b>bee</b> colony (ABC), ant colony optimization (ACO) and particle <b>swarm</b> optimization (PSO)) have been implemented in this study. The experiments are performed on the dataset of 780 psoriasis images from 74 patients collected at Psoriasis Clinic and Research Centre, Psoriatreat, Pune ...", "dateLastCrawled": "2021-11-14T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Cost-Sensitive <b>Centroid-based Differential Evolution Classi\ufb01cation</b> ...", "url": "http://cs.ndsu.edu/~siludwig/Publish/papers/SSCI2019.pdf", "isFamilyFriendly": true, "displayUrl": "cs.ndsu.edu/~siludwig/Publish/papers/SSCI2019.pdf", "snippet": "works related to solving data classi\ufb01cation using DE <b>can</b> be found in [8], [9]. De Falco et al. [10] introduced a new classi\ufb01cation al-gorithm based on the Particle <b>Swarm</b> Optimization method (PSO). The main goal is the same as in the previous works, which is \ufb01nding the optimal centroids for all labels in a train-ing data set. Three ...", "dateLastCrawled": "2022-01-30T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A YBRID ARMONIC MEANS WITH ABCCLUSTERING ALGORITHM USING AN OPTIMAL K ...", "url": "https://aircconline.com/ijci/V5N2/5216ijci06.pdf", "isFamilyFriendly": true, "displayUrl": "https://aircconline.com/ijci/V5N2/5216ijci06.pdf", "snippet": "<b>Clustering</b> using Artificial <b>Bee</b> Colony (ABC) algorithm always gives global optimum solutions. In this paper a new hybrid <b>clustering</b> algorithm (KHM-ABC) is presented by combining both K-harmonic means and ABC algorithm to perform accurate <b>clustering</b>. Experimental results indicate that the performance of the proposed algorithm is superior to the available algorithms in terms of the quality of clusters. KEYWORDS Data Mining, <b>Clustering</b>, K-means <b>Clustering</b>, K-Harmonic means <b>Clustering</b> ...", "dateLastCrawled": "2022-01-20T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Improved clustering criterion for image clustering</b> with artificial <b>bee</b> ...", "url": "https://link.springer.com/article/10.1007%2Fs10044-014-0365-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10044-014-0365-y", "snippet": "In this paper, a new objective function is proposed for image <b>clustering</b> and is applied with the artificial <b>bee</b> colony (ABC) algorithm, the particle <b>swarm</b> optimization algorithm and the genetic algorithm. The performance of the proposed objective function is tested on seven benchmark images by comparing it with the three well-known objective functions in the literature and the K-means algorithm in terms of separateness and compactness which are the main criterions of the <b>clustering</b> problem ...", "dateLastCrawled": "2022-01-16T19:45:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~bgibson/cs540/handouts/learning_intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~bgibson/cs540/handouts/<b>learning</b>_intro.pdf", "snippet": "human <b>learning</b> (e.g., Computer-Aided Instruction (CAI)) \u2022Discover new things or structures that are unknown to humans (\u201cdata mining\u201d) \u2022Fill in skeletal or incomplete specifications about a domain Major Paradigms of <b>Machine</b> <b>Learning</b> \u2022Rote <b>Learning</b> \u2022Induction \u2022<b>Clustering</b> \u2022<b>Analogy</b> \u2022Discovery \u2022Genetic Algorithms \u2022Reinforcement", "dateLastCrawled": "2021-08-25T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Unsupervised Learning</b> and Data <b>Clustering</b> | by Sanatan Mishra | Towards ...", "url": "https://towardsdatascience.com/unsupervised-learning-and-data-clustering-eeecb78b422a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>unsupervised-learning</b>-and-data-<b>clustering</b>-eeecb78b422a", "snippet": "<b>Unsupervised Learning</b> and Data <b>Clustering</b>. Sanatan Mishra. May 19, 2017 \u00b7 15 min read. A task involving <b>machine</b> <b>learning</b> may not be linear, but it has a number of well known steps: Problem definition. Preparation of Data. Learn an underlying model. Improve the underlying model by quantitative and qualitative evaluations. Present the model. One good way to come to terms with a new problem is to work through identifying and defining the problem in the best possible way and learn a model that ...", "dateLastCrawled": "2022-02-02T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Density-Based <b>Clustering</b>", "url": "https://blog.dominodatalab.com/topology-and-density-based-clustering", "isFamilyFriendly": true, "displayUrl": "https://blog.dominodatalab.com/topology-and-density-based-<b>clustering</b>", "snippet": "Compared to <b>centroid-based</b> <b>clustering</b> like k-means, density-based <b>clustering</b> works by identifying \u201cdense\u201d clusters of points, allowing it to learn clusters of arbitrary shape and identify outliers in the data. In particular, I will: Discuss the highly popular DBSCAN algorithm. Use the denpro R package.", "dateLastCrawled": "2022-02-02T08:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Predicate Project Outcomes Using <b>Machine</b> <b>Learning</b>", "url": "https://www.ijsr.net/archive/v6i6/ART20174679.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ijsr.net/archive/v6i6/ART20174679.pdf", "snippet": "<b>Machine</b> <b>learning</b> is a set of algorithms that train on a data set to make predictions or take actions in order to optimize some systems. this method are able to considerably improve <b>learning</b> This paper outlines an introduction of introduction of <b>machine</b> <b>learning</b>, <b>machine</b> <b>learning</b> algorithms, ML Predictive Modeling, some of the related work and important ML model that can used to predicate project outcomes. Otherwise, acquiring unlabeled data generally doesn\u2019t 2. <b>Machine</b> <b>Learning</b> <b>Machine</b> ...", "dateLastCrawled": "2021-11-23T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Determination of miscible CO2 flooding analogue projects with <b>machine</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0920410521014455", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0920410521014455", "snippet": "We use <b>machine</b> <b>learning</b> <b>clustering</b> methods to group successfully executed miscible CO 2 flooding projects into clusters of projects with similar fluid/reservoir characteristics and to identify analogues for new target projects. Porosity, permeability, oil gravity and viscosity, reservoir pressure and temperature, minimum miscibility pressure (MMP), and depth were all input parameters. Data from nearly 200 miscible CO 2 EOR projects around the world were clustered using the Agglomerative ...", "dateLastCrawled": "2022-01-24T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "MaxMin <b>clustering</b> for <b>historical analogy</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s42452-020-03202-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42452-020-03202-2", "snippet": "In natural language processing and <b>machine</b> <b>learning</b> studies, <b>clustering</b> algorithms are widely used; therefore, several types of <b>clustering</b> algorithms have been developed. The key purpose of a <b>clustering</b> algorithm is to identify similarities between data and to cluster them into groups 1, 19]. As several surveys presenting a broad overview of <b>clustering</b> have been published, e.g., [17, 59, 60], this study compares previously proposed partitioning-, hierarchy-, distribution- and graph-based ...", "dateLastCrawled": "2021-12-27T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Tour of the <b>Most Popular Machine Learning Algorithms</b> | by Athreya ...", "url": "https://towardsdatascience.com/a-tour-of-the-most-popular-machine-learning-algorithms-b57d50c2eb51", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tour-of-the-<b>most-popular-machine-learning-algorithms</b>...", "snippet": "In <b>machine</b> <b>learning</b>, it is tradition to categorize algorithms by their <b>learning</b> style. In general, <b>learning</b> style is just a fancy way of saying what data you have readily available to train your algorithm. Let\u2019s look at some! 1. Supervised <b>Learning</b>. In supervised <b>learning</b>, input data is called training data and has a known label/result. An example of an input could be a picture of an animal and a label could be the name of it (i.e. elephant, cat, etc.). Another example can be emails as ...", "dateLastCrawled": "2022-01-29T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deep <b>Clustering</b> with a Dynamic Autoencoder - deepai.org", "url": "https://deepai.org/publication/deep-clustering-with-a-dynamic-autoencoder", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/deep-<b>clustering</b>-with-a-dynamic-autoencoder", "snippet": "4 Experiments. 4.1 Datasets. We compare DynAE with five of the state-of-the-art autoencoder-based deep <b>clustering</b> algorithms on four image datasets: MNIST-full ( 30), MNIST-test, USPS ( 41) and Fashion-MNIST ( 42). MNIST-full ( 30): a dataset that consists of 70000, 28\u00d728 grayscale images of handwritten digits.", "dateLastCrawled": "2021-12-29T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How <b>Machine Learning</b> enhances <b>Personalization</b> at scale? | Opensense Labs", "url": "https://opensenselabs.com/blog/articles/machine-learning-enhances-personalization", "isFamilyFriendly": true, "displayUrl": "https://opensenselabs.com/blog/articles/<b>machine-learning</b>-enhances-<b>personalization</b>", "snippet": "If you want to learn about the miracles of the technological marvel of the 21st century, then this article is no less than a treat for you. In today\u2019s era, digital marketing may sound like a messy environment filled with constant change and complex systems. With the buzzword like <b>Machine Learning</b> (ML) that has penetrated into various aspects of our everyday life, human inputs are reduced to minimal. In other words, more freedom falls in the lap of a <b>machine</b> wherein the <b>machine</b> acts on its ...", "dateLastCrawled": "2022-01-17T11:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What are some use <b>cases of clustering in machine learning? - Quora</b>", "url": "https://www.quora.com/What-are-some-use-cases-of-clustering-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-some-use-<b>cases-of-clustering-in-machine-learning</b>", "snippet": "Answer (1 of 2): You are given the following types of objects (in four separate images) and you are asked to group them. What would you do? The most obvious way is to group all fruits together, and all the cars in another group (or cluster) based on the criteria that objects in one group are edi...", "dateLastCrawled": "2022-01-04T22:08:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(centroid-based clustering)  is like +(bee swarm)", "+(centroid-based clustering) is similar to +(bee swarm)", "+(centroid-based clustering) can be thought of as +(bee swarm)", "+(centroid-based clustering) can be compared to +(bee swarm)", "machine learning +(centroid-based clustering AND analogy)", "machine learning +(\"centroid-based clustering is like\")", "machine learning +(\"centroid-based clustering is similar\")", "machine learning +(\"just as centroid-based clustering\")", "machine learning +(\"centroid-based clustering can be thought of as\")", "machine learning +(\"centroid-based clustering can be compared to\")"]}