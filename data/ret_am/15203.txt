{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Area Under</b> <b>the ROC</b> <b>Curve</b> \u2014 Explained | by Sarath S | Medium", "url": "https://medium.com/@sarath13/area-under-the-roc-curve-explained-d056854d3815", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@sarath13/<b>area-under</b>-<b>the-roc</b>-<b>curve</b>-explained-d056854d3815", "snippet": "<b>Area Under</b> <b>the ROC</b> <b>curve</b> otherwise known as <b>Area under the curve</b> is the evaluation metric to calculate the performance of a binary classifier. Before getting into details of AUC, lets understand ...", "dateLastCrawled": "2022-01-31T06:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The <b>Area Under</b> an <b>ROC</b> <b>Curve</b>", "url": "http://gim.unmc.edu/dxtests/RoC3.htm", "isFamilyFriendly": true, "displayUrl": "gim.unmc.edu/dxtests/<b>RoC</b>3.htm", "snippet": "The <b>accuracy</b> of the test depends on how well the test separates the group being tested into those with and without the disease in question. <b>Accuracy</b> is measured by the <b>area under</b> <b>the ROC</b> <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the <b>accuracy</b> of a diagnostic test is the traditional academic point system: .90-1 = excellent (A) .80-.90 = good (B) .70-.80 = fair (C) .60-.70 = poor (D) .50-.60 = fail (F) Recall the T4 ...", "dateLastCrawled": "2022-01-28T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Receiver Operating Characteristic (ROC) Area Under</b> the <b>Curve</b> (AUC ...", "url": "https://www.tc.columbia.edu/elda/blog/content/receiver-operating-characteristic-roc-area-under-the-curve-auc/", "isFamilyFriendly": true, "displayUrl": "https://www.tc.columbia.edu/elda/blog/content/<b>receiver-operating-characteristic-roc</b>...", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (<b>ROC</b> AUC) which ranges from 0.0 to 1.0 indicates the <b>accuracy</b> of a predictor where the diagonal gray line has an AUC of 0.5 and means random guessing. The closer a <b>curve</b> is to the point (0, 1), the more accurate a predictor is. As a rule of thumb, an AUC above 0.85 means high classification <b>accuracy</b>, one between 0.75 and 0.85 moderate <b>accuracy</b>, and one less than 0.75 low <b>accuracy</b> (D&#39; Agostino, Rodgers, &amp; Mauck, 2018).", "dateLastCrawled": "2022-02-02T21:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is a <b>ROC</b> <b>Curve and How to Interpret It</b> - Displayr", "url": "https://www.displayr.com/what-is-a-roc-curve-how-to-interpret-it/", "isFamilyFriendly": true, "displayUrl": "https://www.displayr.com/what-is-a-<b>roc</b>-<b>curve</b>-how-to-interpret-it", "snippet": "One common approach is to calculate the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, which is abbreviated to AUC. It is equivalent to the probability that a randomly chosen positive instance is ranked higher than a randomly chosen negative instance, i.e. it is equivalent to the two sample Wilcoxon rank-sum statistic. A classifier with high AUC can occassionally score worse in a specific region than another classifier with lower AUC. But in practice, the AUC performs well as a general <b>measure</b> of predictive ...", "dateLastCrawled": "2022-02-03T06:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-<b>the-roc</b>-<b>curve</b>-assessing-discrimination...", "snippet": "Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a model with no discrimination ability. The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is also sometimes referred to as the c-statistic (c for concordance). The <b>area</b> <b>under</b> the estimated <b>ROC</b> <b>curve</b> (AUC) is reported when we plot <b>the ROC</b> <b>curve</b> in R&#39;s Console.", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Understanding the AUC-<b>ROC</b> <b>Curve</b> in Machine Learning Classification", "url": "https://analyticsindiamag.com/understanding-the-auc-roc-curve-in-machine-learning-classification/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/<b>under</b>standing-the-auc-<b>roc</b>-<b>curve</b>-in-machine-learning...", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> is one of the good ways to estimate the <b>accuracy</b> of the model. An excellent model poses an AUC near to the 1 which tells that it has a good <b>measure</b> of separability. A poor model will have an AUC near 0 which describes that it has the worst <b>measure</b> of separability. In fact, it means it is reciprocating the result and predicting 0s as 1s and 1s as 0s. When an AUC is 0.5, it means the model has no class separation capacity present whatsoever.", "dateLastCrawled": "2022-02-03T00:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Understanding <b>AUC</b> - <b>ROC</b> <b>Curve</b> | by Sarang Narkhede | Towards Data Science", "url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>auc</b>-<b>roc</b>-<b>curve</b>-68b2303cc9c5", "snippet": "<b>ROC</b> is a probability <b>curve</b> and <b>AUC</b> represents the degree or <b>measure</b> of separability. It tells how much the model is capable of distinguishing between classes. Higher the <b>AUC</b>, the better the model is at predicting 0 classes as 0 and 1 classes as 1. By analogy, the Higher the <b>AUC</b>, the better the model is at distinguishing between patients with the disease and no disease.", "dateLastCrawled": "2022-01-30T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Understanding <b>the ROC Curve</b> and AUC | by Doug Steen | Towards Data Science", "url": "https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>the-roc-curve</b>-and-auc-dd4f9a192ecb", "snippet": "<b>The ROC Curve</b>. <b>The receiver operating characteristic</b> (<b>ROC) curve</b> is frequently used for evaluating the performance of binary classification algorithms. It provides a graphical representation of a classifier\u2019s performance, rather than a single value <b>like</b> most other metrics. First, let\u2019s establish that in binary classification, there are four possible outcomes for a test prediction: true positive, false positive, true negative, and false negative.", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "r - <b>ROC</b> <b>curve for classification from randomForest</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/12370670/roc-curve-for-classification-from-randomforest", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/12370670", "snippet": "So, I have the performance measures <b>like</b> <b>accuracy</b>, MCC, sensitivity, specificity, etc for 9 cutoff points. Now, I want to plot <b>the ROC</b> <b>curve</b> and obtain the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> to see how good the performance is. Most of the packages in R (<b>like</b> ROCR, pROC) require prediction and labels but I have sensitivity (TPR) and specificity (1-FPR).", "dateLastCrawled": "2022-01-25T23:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>the relationship between Accuracy, precision and</b> AUC (<b>Area</b> ...", "url": "https://www.quora.com/What-is-the-relationship-between-Accuracy-precision-and-AUC-Area-Under-the-Curve", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-relationship-between-Accuracy-precision-and</b>-AUC-<b>Area</b>...", "snippet": "Answer: This is surely possible. <b>Accuracy</b> shows the percentage of the correct classifications with respect to the all samples. But it does not say anything about the performances for negative and positive classes. Precision measures how many of the positively classified samples were really positi...", "dateLastCrawled": "2022-01-28T07:03:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Area Under</b> <b>the ROC</b> <b>Curve</b> \u2014 Explained | by Sarath S | Medium", "url": "https://medium.com/@sarath13/area-under-the-roc-curve-explained-d056854d3815", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@sarath13/<b>area-under</b>-<b>the-roc</b>-<b>curve</b>-explained-d056854d3815", "snippet": "<b>Area Under</b> <b>the ROC</b> <b>curve</b> otherwise known as <b>Area under the curve</b> is the evaluation metric to calculate the performance of a binary classifier. Before getting into details of AUC, lets understand ...", "dateLastCrawled": "2022-01-31T06:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Receiver Operating Characteristic (ROC) Area Under</b> the <b>Curve</b> (AUC ...", "url": "https://www.tc.columbia.edu/elda/blog/content/receiver-operating-characteristic-roc-area-under-the-curve-auc/", "isFamilyFriendly": true, "displayUrl": "https://www.tc.columbia.edu/elda/blog/content/<b>receiver-operating-characteristic-roc</b>...", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (<b>ROC</b> AUC) which ranges from 0.0 to 1.0 indicates the <b>accuracy</b> of a predictor where the diagonal gray line has an AUC of 0.5 and means random guessing. The closer a <b>curve</b> is to the point (0, 1), the more accurate a predictor is. As a rule of thumb, an AUC above 0.85 means high classification <b>accuracy</b>, one between 0.75 and 0.85 moderate <b>accuracy</b>, and one less than 0.75 low <b>accuracy</b> (D&#39; Agostino, Rodgers, &amp; Mauck, 2018).", "dateLastCrawled": "2022-02-02T21:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is <b>area under the curve</b> in statistics?", "url": "https://askinglot.com/what-is-area-under-the-curve-in-statistics", "isFamilyFriendly": true, "displayUrl": "https://askinglot.com/what-is-<b>area-under-the-curve</b>-in-statistics", "snippet": "<b>Area</b> <b>under</b> <b>curve</b> (AUC) The <b>area</b> <b>under</b> (a <b>ROC</b>) <b>curve</b> is a summary <b>measure</b> of the <b>accuracy</b> of a quantitative diagnostic test. A test with no better <b>accuracy</b> than chance has an AUC of 0.5, a test with perfect <b>accuracy</b> has an AUC of 1.", "dateLastCrawled": "2022-02-03T03:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "F1 <b>Score</b> vs <b>ROC</b> AUC vs <b>Accuracy</b> vs PR AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-<b>accuracy</b>-<b>roc</b>-auc-pr-auc", "snippet": "<b>ROC</b> AUC. AUC means <b>area</b> <b>under</b> the <b>curve</b> so to speak about <b>ROC</b> AUC <b>score</b> we need to define <b>ROC</b> <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart. Of course, the higher TPR and the lower FPR is for each threshold the better and so classifiers that have curves that are more top-left-side are better. An extensive discussion of <b>ROC</b> <b>Curve</b> and <b>ROC</b> ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-<b>the-roc</b>-<b>curve</b>-assessing-discrimination...", "snippet": "Interpretation of the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> Although it is not obvious from its definition, the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (AUC) has a somewhat appealing interpretation. It turns out that the AUC is the probability that if you were to take a random pair of observations, one with . and one with , the observation with . has a higher predicted probability than the other. The AUC thus gives the probability that the model correctly ranks such pairs of observations. In the biomedical context of ...", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Assessing the <b>accuracy</b> of species distribution models: prevalence ...", "url": "https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2664.2006.01214.x", "isFamilyFriendly": true, "displayUrl": "https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2664.2006.01214.x", "snippet": "supported by the fact that a <b>similar</b> pattern was found for the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, a <b>measure</b> known to be independent of prevalence. 5. Synthesis and applications . Our results provide theoretical and empirical evidence that kappa, one of the most widely used measures of model performance in ecology, has serious limitations that make it unsuitable for such applications. The alternative we suggest, TSS, compensates for the shortcomings of kappa while keeping all of its advantages. We ...", "dateLastCrawled": "2022-01-29T01:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Model Evaluation - Classification</b>", "url": "https://saedsayad.com/model_evaluation_c.htm", "isFamilyFriendly": true, "displayUrl": "https://saedsayad.com/model_evaluation_c.htm", "snippet": "<b>Accuracy</b> : the proportion of the total number <b>of predictions</b> that were correct. ... <b>Area</b> <b>under</b> <b>ROC</b> <b>curve</b> is often used as a <b>measure</b> of quality of the classification models. A random classifier has an <b>area</b> <b>under</b> the <b>curve</b> of 0.5, while AUC for a perfect classifier is equal to 1. In practice, most of the classification models have an AUC between 0.5 and 1. ...", "dateLastCrawled": "2022-02-03T06:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) Estimation of the <b>area</b> <b>under</b> <b>ROC</b> <b>curve</b> with censored data", "url": "https://www.researchgate.net/publication/223031193_Estimation_of_the_area_under_ROC_curve_with_censored_data", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/223031193_Estimation_of_the_<b>area</b>_<b>under</b>_<b>ROC</b>...", "snippet": "The <b>area</b> <b>under</b> <b>the receiver operating characteristic</b> <b>curve</b> is the most commonly used summary <b>measure</b> of diagnostic <b>accuracy</b> for a continuous-scale diagnostic test. In this paper, we develop ...", "dateLastCrawled": "2021-10-26T17:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>AUC-ROC Curve - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/auc-roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/auc-<b>roc</b>-<b>curve</b>", "snippet": "If you are familiar with some basics of Machine Learning then you must have across some of these metrics like <b>accuracy</b>, precision, recall, auc-<b>roc</b>, etc. Let\u2019s say you are working on a binary classification problem and come up with a model with 95% <b>accuracy</b>, now someone asks you what does that mean you would be quick enough to say out of 100 <b>predictions</b> your model makes, 95 of them are correct. Well lets notch it up a bit, now the underlying metric is recall and you are asked the same ...", "dateLastCrawled": "2022-01-30T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to select Performance Metrics for <b>Classification</b> Models | by Ruchi ...", "url": "https://medium.com/analytics-vidhya/how-to-select-performance-metrics-for-classification-models-c847fe6b1ea3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/how-to-select-performance-metrics-for...", "snippet": "<b>ROC</b> Curves of both Model-1 and Model-2 have the same <b>area</b> <b>under</b> the <b>curve</b>. But when we pick a threshold, we want to look where the steepest and flattest parts of the <b>curve</b> start and stop.", "dateLastCrawled": "2022-02-02T21:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The <b>Area Under</b> an <b>ROC</b> <b>Curve</b>", "url": "http://gim.unmc.edu/dxtests/RoC3.htm", "isFamilyFriendly": true, "displayUrl": "gim.unmc.edu/dxtests/<b>RoC</b>3.htm", "snippet": "The <b>accuracy</b> of the test depends on how well the test separates the group being tested into those with and without the disease in question. <b>Accuracy</b> is measured by the <b>area under</b> <b>the ROC</b> <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the <b>accuracy</b> of a diagnostic test is the traditional academic point system: .90-1 = excellent (A) .80-.90 = good (B) .70-.80 = fair (C) .60-.70 = poor (D) .50-.60 = fail (F) Recall the T4 ...", "dateLastCrawled": "2022-01-28T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-<b>the-roc</b>-<b>curve</b>-assessing-discrimination...", "snippet": "Interpretation of the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> Although it is not obvious from its definition, the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (AUC) has a somewhat appealing interpretation. It turns out that the AUC is the probability that if you were to take a random pair of observations, one with . and one with , the observation with . has a higher predicted probability than the other. The AUC thus gives the probability that the model correctly ranks such pairs of observations. In the biomedical context of ...", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "F1 <b>Score</b> vs <b>ROC</b> AUC vs <b>Accuracy</b> vs PR AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-<b>accuracy</b>-<b>roc</b>-auc-pr-auc", "snippet": "AUC means <b>area</b> <b>under</b> the <b>curve</b> so to speak about <b>ROC</b> AUC <b>score</b> we need to define <b>ROC</b> <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart. Of course, the higher TPR and the lower FPR is for each threshold the better and so classifiers that have curves that are more top-left-side are better. An extensive discussion of <b>ROC</b> <b>Curve</b> and <b>ROC</b> AUC <b>score</b> ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Prodding <b>the ROC</b> <b>Curve</b>: Constrained Optimization of Classifier Performance", "url": "https://proceedings.neurips.cc/paper/2001/file/2cd4e8a2ce081c3d7c32c3cde4312ef7-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://p<b>roc</b>eedings.neurips.cc/paper/2001/file/2cd4e8a2ce081c3d7c32c3cde4312ef7-Paper.pdf", "snippet": "<b>ROC</b> <b>curve</b>, a classi\ufb01er <b>can</b> <b>be thought</b> of as making a positive/negative judgement as to whether an input is a member of some class. Two different <b>accuracy</b> measures <b>can</b> be obtained from the classi\ufb01er: the <b>accuracy</b> of correctly identifying an input as a member of the class (acorrect acceptance orCA), and the <b>accuracy</b> of correctly identifying an input as a nonmember of the class (a correct rejection or CR). To evaluate the CA and CR rates, it is necessary to pick a threshold above which the ...", "dateLastCrawled": "2021-08-24T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>ROC Curve</b> - Devopedia", "url": "https://devopedia.org/roc-curve", "isFamilyFriendly": true, "displayUrl": "https://devopedia.org/<b>roc-curve</b>", "snippet": "After plotting <b>the ROC Curve</b>, the <b>area</b> <b>under</b> it is called <b>Area</b> <b>Under</b> <b>the ROC Curve</b> (AUC), <b>Area</b> <b>Under</b> the <b>Curve</b> (AUC), or AUROC.It&#39;s been said that &quot;<b>ROC</b> is a probability <b>curve</b> and AUC represents degree or <b>measure</b> of separability&quot;.In other words, AUC is a single metric that <b>can</b> be used to quantify how well two classes are separated by a binary classifier. It&#39;s also useful when comparing different classifiers. AUC has some useful properties. It&#39;s scale-invariant.This means it tells how well ...", "dateLastCrawled": "2022-02-03T08:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>ROC Curve</b>, a Complete Introduction | by Reza Bagheri | Towards Data Science", "url": "https://towardsdatascience.com/roc-curve-a-complete-introduction-2f2da2e0434c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>roc-curve</b>-a-complete-introduction-2f2da2e0434c", "snippet": "Figure 7. In this figure point B represents a general random classifier which predicts a positive point with probability p.Point A is a classifier that predicts everything as negative, and it <b>can</b> <b>be thought</b> of as a random classifier with p=0.Point C is a classifier that predicts everything as positive, and it is a random classifier with p=1.Both TPR and FPR range from 0 to 1 and all these points lie on the diagonal line. By changing the selection probability, you <b>can</b> change the position of ...", "dateLastCrawled": "2022-01-30T19:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>AUC-ROC Curve - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/auc-roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/auc-<b>roc</b>-<b>curve</b>", "snippet": "If you are familiar with some basics of Machine Learning then you must have across some of these metrics like <b>accuracy</b>, precision, recall, auc-<b>roc</b>, etc. Let\u2019s say you are working on a binary classification problem and come up with a model with 95% <b>accuracy</b>, now someone asks you what does that mean you would be quick enough to say out of 100 <b>predictions</b> your model makes, 95 of them are correct. Well lets notch it up a bit, now the underlying metric is recall and you are asked the same ...", "dateLastCrawled": "2022-01-30T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) The Meaning and Use of the <b>Area</b> <b>Under</b> a Receiver Operating ...", "url": "https://www.researchgate.net/publication/16134792_The_Meaning_and_Use_of_the_Area_Under_a_Receiver_Operating_Characteristic_ROC_Curve", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/16134792_The_Meaning_and_Use_of_the_<b>Area</b>...", "snippet": "Meanwhile, <b>the ROC</b> <b>curve</b> is used to calculate the <b>area</b> <b>under</b> <b>curve</b>, which ranges from 0 to 1; the larger value, the better [44,45, 47]. The AUC was 0.983 in the training set, which meant excellent ...", "dateLastCrawled": "2022-01-19T09:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How <b>can</b> we find <b>the ROC</b> <b>curve</b> and <b>area</b> <b>under</b> <b>ROC</b> <b>curve</b> for a multi ...", "url": "https://www.quora.com/How-can-we-find-the-ROC-curve-and-area-under-ROC-curve-for-a-multi-instance-multi-label-classification-One-feature-vector-may-correspond-to-one-or-more-labels", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>can</b>-we-find-<b>the-ROC</b>-<b>curve</b>-and-<b>area</b>-<b>under</b>-<b>ROC</b>-<b>curve</b>-for-a...", "snippet": "Answer: Lets say you have 3 labels 1,2,3 and you have data belonging to these 3 labels. Let&#39;s say they were labelled as a(1), b(2), c(3) by your model 1 2 3 A 25 5 5 B 5 15 10 C 5 10 20 This table means that 25 instances which were label 1 were labeled a and so on. The true positives would be ...", "dateLastCrawled": "2022-01-19T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "machine learning - Reason of having high <b>AUC</b> and low <b>accuracy</b> in a ...", "url": "https://stackoverflow.com/questions/38387913/reason-of-having-high-auc-and-low-accuracy-in-a-balanced-dataset", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/38387913", "snippet": "Before we ponder why the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (<b>AUC</b>) <b>can</b> be high while <b>accuracy</b> is low, let&#39;s first recapitulate the meanings of these terms. The receiver-operator characteristic (<b>ROC</b>) <b>curve</b> plots the false positive rate FPR(t) against the true positive rate TPR(t), for varying decision thresholds (or prediction cutoffs) t. TPR and FPR are defined as follows: TPR = TP / P = TP / (TP+FN) = number of true positives / number of positives FPR = FP / N = FP / (FP+TN) = number of false ...", "dateLastCrawled": "2022-01-22T05:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Receiver Operating Characteristic (ROC) Area Under</b> the <b>Curve</b> (AUC ...", "url": "https://www.tc.columbia.edu/elda/blog/content/receiver-operating-characteristic-roc-area-under-the-curve-auc/", "isFamilyFriendly": true, "displayUrl": "https://www.tc.columbia.edu/elda/blog/content/<b>receiver-operating-characteristic-roc</b>...", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (<b>ROC</b> AUC) which ranges from 0.0 to 1.0 indicates the <b>accuracy</b> of a predictor where the diagonal gray line has an AUC of 0.5 and means random guessing. The closer a <b>curve</b> is to the point (0, 1), the more accurate a predictor is. As a rule of thumb, an AUC above 0.85 means high classification <b>accuracy</b>, one between 0.75 and 0.85 moderate <b>accuracy</b>, and one less than 0.75 low <b>accuracy</b> (D&#39; Agostino, Rodgers, &amp; Mauck, 2018).", "dateLastCrawled": "2022-02-02T21:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "F1 <b>Score</b> vs <b>ROC</b> AUC vs <b>Accuracy</b> vs PR AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-<b>accuracy</b>-<b>roc</b>-auc-pr-auc", "snippet": "AUC means <b>area</b> <b>under</b> the <b>curve</b> so to speak about <b>ROC</b> AUC <b>score</b> we need to define <b>ROC</b> <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart. Of course, the higher TPR and the lower FPR is for each threshold the better and so classifiers that have curves that are more top-left-side are better. An extensive discussion of <b>ROC</b> <b>Curve</b> and <b>ROC</b> AUC <b>score</b> ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The <b>Area Under</b> an <b>ROC</b> <b>Curve</b>", "url": "http://gim.unmc.edu/dxtests/RoC3.htm", "isFamilyFriendly": true, "displayUrl": "gim.unmc.edu/dxtests/<b>RoC</b>3.htm", "snippet": "The <b>accuracy</b> of the test depends on how well the test separates the group being tested into those with and without the disease in question. <b>Accuracy</b> is measured by the <b>area under</b> <b>the ROC</b> <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the <b>accuracy</b> of a diagnostic test is the traditional academic point system: .90-1 = excellent (A) .80-.90 = good (B) .70-.80 = fair (C) .60-.70 = poor (D) .50-.60 = fail (F) Recall the T4 ...", "dateLastCrawled": "2022-01-28T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-<b>the-roc</b>-<b>curve</b>-assessing-discrimination...", "snippet": "Interpretation of the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> Although it is not obvious from its definition, the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (AUC) has a somewhat appealing interpretation. It turns out that the AUC is the probability that if you were to take a random pair of observations, one with . and one with , the observation with . has a higher predicted probability than the other. The AUC thus gives the probability that the model correctly ranks such pairs of observations. In the biomedical context of ...", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Classification: <b>ROC</b> <b>Curve</b> and AUC | Machine Learning Crash Course ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/crash-course/classification/<b>roc</b>-and-auc", "snippet": "AUC: <b>Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>. AUC stands for &quot;<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>.&quot; That is, AUC measures the entire two-dimensional <b>area</b> underneath the entire <b>ROC</b> <b>curve</b> (think integral calculus) from (0,0) to (1,1). Figure 5. AUC (<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>). AUC provides an aggregate <b>measure</b> of performance across all possible classification thresholds ...", "dateLastCrawled": "2022-02-02T09:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Receiver Operating Characteristic</b> (<b>ROC</b>) <b>Curve</b> Analysis for Medical ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3755824/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3755824", "snippet": "The derived summary <b>measure</b> <b>of accuracy</b>, such as the <b>area</b> <b>under</b> the <b>curve</b> (AUC) determines the inherent ability of the test to discriminate between the diseased and healthy populations . Using this as a <b>measure</b> of a diagnostic performance, one <b>can</b> compare individual tests or judge whether the various combination of tests (e.g. combination of imaging techniques or combination of readers) <b>can</b> improve diagnostic <b>accuracy</b>.", "dateLastCrawled": "2022-02-02T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Understanding <b>the ROC Curve</b> and AUC | by Doug Steen | Towards Data Science", "url": "https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>the-roc-curve</b>-and-auc-dd4f9a192ecb", "snippet": "Fig. 1 \u2014 Some theoretical <b>ROC</b> curves AUC. While it is useful to visualize a classifier\u2019s <b>ROC curve</b>, in many cases we <b>can</b> boil this information down to a single metric \u2014 the AUC. AUC stands for <b>area</b> <b>under</b> <b>the (ROC) curve</b>. Generally, the higher the AUC score, the better a classifier performs for the given task.", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to get <b>the ROC curve and AUC for Keras model</b>? - knowledge Transfer", "url": "https://androidkt.com/get-the-roc-curve-and-auc-for-keras-model/", "isFamilyFriendly": true, "displayUrl": "https://androidkt.com/get-<b>the-roc-curve-and-auc-for-keras-model</b>", "snippet": "One way to compare classifiers is <b>to measure</b> the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, whereas a purely random classifier will have a <b>ROC</b> AUC equal to 0.5. Scikit-Learn provides a function to get AUC. auc_score=<b>roc</b>_auc_score (y_val_cat,y_val_cat_prob) #0.8822. AUC is the percentage of this <b>area</b> that is <b>under</b> this <b>ROC</b> <b>curve</b>, ranging between 0~1.", "dateLastCrawled": "2022-02-03T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to select Performance Metrics for <b>Classification</b> Models | by Ruchi ...", "url": "https://medium.com/analytics-vidhya/how-to-select-performance-metrics-for-classification-models-c847fe6b1ea3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/how-to-select-performance-metrics-for...", "snippet": "The <b>area</b> <b>under</b> <b>the ROC</b> <b>Curve</b> is also known as AUC (<b>Area</b> <b>Under</b> the <b>Curve</b>). AUC is another performance metric that we <b>can</b> use to improve our models on. AUC represents degree or <b>measure</b> of separability.", "dateLastCrawled": "2022-02-02T21:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>the relationship between Accuracy, precision and</b> AUC (<b>Area</b> ...", "url": "https://www.quora.com/What-is-the-relationship-between-Accuracy-precision-and-AUC-Area-Under-the-Curve", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-relationship-between-Accuracy-precision-and</b>-AUC-<b>Area</b>...", "snippet": "Answer: This is surely possible. <b>Accuracy</b> shows the percentage of the correct classifications with respect to the all samples. But it does not say anything about the performances for negative and positive classes. Precision measures how many of the positively classified samples were really positi...", "dateLastCrawled": "2022-01-28T07:03:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The Receiver Operating <b>Curve</b> (<b>ROC</b>) and The Scale \u2014 Understanding <b>ROC</b> ...", "url": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the-scale-understanding-roc-through-an-analogy-8b8f9d954f84", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-everyday/the-receiver-operating-<b>curve</b>-<b>roc</b>-and-the...", "snippet": "The Receiver Operating <b>Curve</b> (<b>ROC</b>) is used to evaluate and improve classification <b>Machine</b> <b>Learning</b> models. Who does not want an accurate classifier, that place observations where they actually\u2026", "dateLastCrawled": "2021-02-13T00:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding <b>AUC</b> - <b>ROC</b> <b>Curve</b> | by Sarang Narkhede | Towards Data Science", "url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>auc</b>-<b>roc</b>-<b>curve</b>-68b2303cc9c5", "snippet": "In <b>Machine</b> <b>Learning</b>, performance measurement is an essential task. So when it comes to a classification problem, we can count on an <b>AUC</b> - <b>ROC</b> <b>Curve</b>. When we need to check or visualize the performance of the multi-class classification problem, we use the <b>AUC</b> <b>Area</b> <b>Under</b> The <b>Curve</b>) <b>ROC</b> (Receiver Operating Characteristics) <b>curve</b>. It is one of the most important evaluation metrics for checking any classification model\u2019s performance. It is also written as AUROC (<b>Area</b> <b>Under</b> the Receiver Operating ...", "dateLastCrawled": "2022-01-30T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>What is</b> AUC - <b>ROC</b> in <b>Machine</b> <b>Learning</b> | Overview of <b>ROC</b>", "url": "https://www.mygreatlearning.com/blog/roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>roc</b>-<b>curve</b>", "snippet": "By <b>analogy</b>, Higher the AUC, better the model is at distinguishing between patients with the disease and no disease. <b>The ROC</b> <b>curve</b> is plotted with TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis. Defining terms used in AUC and <b>ROC</b> <b>Curve</b>. Consider a two-class prediction problem, in which the outcomes are labeled either as positive (p) or negative (n). There are four possible outcomes from a binary classifier. If the outcome from a prediction is p and the actual value is ...", "dateLastCrawled": "2022-01-30T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "AUC calculates the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, and therefore it is between 0 and 1. One way of interpreting AUC is the probability that the model ranks a random positive example more highly than a random negative example. Youden\u2019s index Youden\u2019s J statistic (also called Youden\u2019s index) is a single statistic that captures the performance of a dichotomous (A partition of a whole into two) diagnostic tests. Youden\u2019s J statistic is J = sensitivity + specificity - 1 The right-hand two ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Comparison of <b>machine</b>-<b>learning</b> methodologies for accurate diagnosis of ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8128240/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8128240", "snippet": "After completion of training and prediction steps during each iteration, predictive metrics (<b>area</b> <b>under</b> the <b>curve</b> (AUC) and probability of correct classification (PCC)) are calculated based on the respective <b>machine</b>-<b>learning</b> classifier results, and <b>receiver operating characteristic</b> (<b>ROC</b>) plots are generated using R package \u201cPresenceAbsence\u201d . The difference between AUC and PCC means was compared by unpaired Student\u2019s t-tests using R base functions for all <b>machine</b>-<b>learning</b>-based ...", "dateLastCrawled": "2022-01-26T11:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is the AUC \u2014 <b>ROC</b> <b>Curve</b>?. AUC-<b>ROC</b> <b>CURVE</b> | CONFUSION MATRIX |\u2026 | by ...", "url": "https://medium.com/computer-architecture-club/what-is-the-auc-roc-curve-47fbdcbf7a4a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/computer-architecture-club/what-is-the-auc-<b>roc</b>-<b>curve</b>-47fbdcbf7a4a", "snippet": "The <b>Area</b> <b>Under</b> the <b>Curve</b> (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of <b>the ROC</b> <b>curve</b>. AUC-<b>ROC</b> <b>curve</b> is a performance measurement ...", "dateLastCrawled": "2022-01-26T00:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "C. <b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b> D. All of the above Answer : D. 24. Which of the following is a good test dataset characteristic? A. Large enough to yield meaningful results B. Is representative of the dataset as a whole C. Both A and B D. None of the above Answer : C. 25. Which of the following is a disadvantage of decision trees? A. Factor analysis", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "In <b>machine</b> <b>learning</b>, how model accuracy and <b>ROC</b> AUC (<b>area</b> <b>under</b> the TP ...", "url": "https://www.quora.com/In-machine-learning-how-model-accuracy-and-ROC-AUC-area-under-the-TP-vs-FP-rates-curve-are-related", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-<b>machine</b>-<b>learning</b>-how-model-accuracy-and-<b>ROC</b>-AUC-<b>area</b>-<b>under</b>...", "snippet": "Answer (1 of 2): High accuracy and higher AUC are both good things generally. Before understanding AUROC, first the concept of confusion matrix must be understood ...", "dateLastCrawled": "2022-01-07T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Applying <b>machine</b> <b>learning</b> algorithms to predict default probability in ...", "url": "https://www.sciencedirect.com/science/article/pii/S1057521921002878", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1057521921002878", "snippet": "The results show that, first, based on the AUC (<b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>) value, accuracy rate and Brier score, the <b>machine</b> <b>learning</b> models can accurately predict the default risk of online borrowers. Second, the integrated discrimination improvement (IDI) test results show that the prediction performance of the <b>machine</b> <b>learning</b> algorithms is significantly better than that of the logistic model. Third, after constructing the investor profit function with misclassification cost, we find that ...", "dateLastCrawled": "2022-01-27T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "21 <b>Machine</b> <b>Learning</b> <b>Interview Questions</b> and Answers", "url": "https://elitedatascience.com/machine-learning-interview-questions-answers", "isFamilyFriendly": true, "displayUrl": "https://elitedatascience.com/<b>machine</b>-<b>learning</b>-<b>interview-questions</b>-answers", "snippet": "7.2 - Why is <b>Area</b> <b>Under</b> <b>ROC</b> <b>Curve</b> (AUROC) better than raw accuracy as an out-of- sample evaluation metric? AUROC is robust to class imbalance, unlike raw accuracy. For example, if you want to detect a type of cancer that&#39;s prevalent in only 1% of the population, you can build a model that achieves 99% accuracy by simply classifying everyone has cancer-free.", "dateLastCrawled": "2022-02-02T19:37:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Newest &#39;auc&#39; Questions</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/tagged/auc", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/tagged/auc", "snippet": "The <b>area under the ROC curve can be thought of as</b> a single scalar representation of the ROC curve itself. The AUC of a classifier has the property of being equivalent to the probability that the classifier will rank a randomly chosen positive data point higher than a randomly chosen negative data point.", "dateLastCrawled": "2022-01-19T11:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Reliability and Validity of the Ocular Surface Disease Index | External ...", "url": "https://jamanetwork.com/journals/jamaophthalmology/fullarticle/413145", "isFamilyFriendly": true, "displayUrl": "https://jamanetwork.com/journals/jamaophthalmology/fullarticle/413145", "snippet": "The <b>area under the ROC curve can be thought of as</b> a summary measure for these curves, with 0.5 indicating that the test is no better than chance at predicting dry eye disease and 1.0 indicating a perfect test for dry eye. The areas under the ROC curve for the <b>OSDI</b> demonstrate good to excellent discrimination with the instrument .", "dateLastCrawled": "2022-02-01T22:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Mastering <b>Machine</b> <b>Learning</b> with Spark 2.x [PDF] | Online Book Share", "url": "https://docero.net/doc/mastering-machine-learning-with-spark-2x-k9ezgwpn4w", "isFamilyFriendly": true, "displayUrl": "https://docero.net/doc/mastering-<b>machine</b>-<b>learning</b>-with-spark-2x-k9ezgwpn4w", "snippet": "Therefore, the <b>area under the ROC curve can be thought of as</b> an average model accuracy whereby a value of 1.0 would represent perfect classification, 0.5 would be a coin-flip (meaning our model is doing a 50-50 job at guessing 1 or 0), and anything less than 0.5 would mean flipping a coin is more accurate than our model! This is an incredibly useful metric which we will see can be used to compare against different hyperparameter tweaks and different models altogether! Let&#39;s go ahead and ...", "dateLastCrawled": "2022-01-27T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "US20160278736A1 - Monitoring structural features of cerebral blood flow ...", "url": "https://patents.google.com/patent/US20160278736A1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US20160278736A1/en", "snippet": "US20160278736A1 US15/036,776 US201415036776A US2016278736A1 US 20160278736 A1 US20160278736 A1 US 20160278736A1 US 201415036776 A US201415036776 A US 201415036776A US 2016278736 A", "dateLastCrawled": "2021-12-29T18:22:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(area under the roc curve)  is like +(measure of accuracy of predictions)", "+(area under the roc curve) is similar to +(measure of accuracy of predictions)", "+(area under the roc curve) can be thought of as +(measure of accuracy of predictions)", "+(area under the roc curve) can be compared to +(measure of accuracy of predictions)", "machine learning +(area under the roc curve AND analogy)", "machine learning +(\"area under the roc curve is like\")", "machine learning +(\"area under the roc curve is similar\")", "machine learning +(\"just as area under the roc curve\")", "machine learning +(\"area under the roc curve can be thought of as\")", "machine learning +(\"area under the roc curve can be compared to\")"]}