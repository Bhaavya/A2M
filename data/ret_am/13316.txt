{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Recognition of Consumer <b>Preference</b> by Analysis and Classification EEG ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7838383/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7838383", "snippet": "EEG-based <b>preference</b> classification normally includes the spectral conversion of waveforms <b>into</b> features exploited by data-mining algorithms, which are trained on labeled data to forecast whether <b>preferences</b> are presently being detected. The <b>preference</b> classification of EEG varies from binary labels such as (\u201c<b>like</b>\u201d vs. \u201cdislike\u201d) and (most favored vs. least favored) to multiple ordinal labels in the form of ranks, such as the nine-scale rank or five-scale rank. Several <b>preference</b> ...", "dateLastCrawled": "2022-02-02T20:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The <b>Cross-Entropy Method for Network Reliability Estimation</b> | Request PDF", "url": "https://www.researchgate.net/publication/226494839_The_Cross-Entropy_Method_for_Network_Reliability_Estimation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/226494839_The_<b>Cross-Entropy</b>_Method_for...", "snippet": "Individual employees <b>like</b> to have a good work-life balance, by having personal <b>preferences</b> taken <b>into</b> account, whereas there is also the common goal to work efficiently. By applying techniques and ...", "dateLastCrawled": "2022-01-02T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A <b>cross entropy approach to design of reliable networks</b> | Request PDF", "url": "https://www.researchgate.net/publication/222952511_A_cross_entropy_approach_to_design_of_reliable_networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/222952511_A_<b>cross_entropy_approach_to_design</b>...", "snippet": "Individual employees <b>like</b> to have a good work-life balance, by having personal <b>preferences</b> taken <b>into</b> account, whereas there is also the common goal to work efficiently. By applying techniques and ...", "dateLastCrawled": "2021-10-19T04:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Evaluating Machine Learning Models</b> \u2013 O\u2019Reilly", "url": "https://www.oreilly.com/content/evaluating-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/content/<b>evaluating-machine-learning-models</b>", "snippet": "<b>Cross entropy</b> incorporates the entropy of the true distribution, plus the extra unpredictability when <b>one</b> assumes a different distribution than the true distribution. So log-loss is an information-theoretic measure to gauge the \u201cextra noise\u201d that comes from using a predictor as opposed to the true labels. By minimizing the <b>cross entropy</b>, we maximize the accuracy of the classifier.", "dateLastCrawled": "2022-01-26T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Neural <b>Collaborative Filtering</b>. Supercharging <b>collaborative filtering</b> ...", "url": "https://towardsdatascience.com/neural-collaborative-filtering-96cef1009401", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-<b>collaborative-filtering</b>-96cef1009401", "snippet": "<b>Collaborative filtering</b> models user <b>preference</b> on items based on their past interactions. Matrix Factorisation(MF) represents user/item as a <b>vector</b> of latent features which are projected <b>into</b> a shared feature space. In this feature space, the user-item interactions could be modeled using the inner product of user-item latent vectors. This vanilla implementation of MF can be enhanced by integrating it with neighbor based models, <b>combining</b> it with topic models of item content and extending it ...", "dateLastCrawled": "2022-02-03T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Lean improvement of the stage shows in theme park based on consumer ...", "url": "https://link.springer.com/article/10.1007/s11042-020-09112-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11042-020-09112-0", "snippet": "The traditional word <b>vector</b> is transformed <b>into</b> the emotion word <b>vector</b>, whose dimension is determined by the quantity of seed emotion words, and then the emotions contained in the user comments are deeply explored by <b>combining</b> GRU neural network, and in result the user emotional polarity is identified more accurately. Thirdly, this study develops a correlation width mining model for user <b>preferences</b> in the information missing environment based on the emotion correlation between attributes ...", "dateLastCrawled": "2022-01-15T20:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Learning to rank products based on online product ... - ScienceDirect.com", "url": "https://www.sciencedirect.com/science/article/pii/S1567422319300511", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1567422319300511", "snippet": "They attempted to predict the <b>preference</b> of customers overall by integrating online product reviews affected by a <b>customer</b>\u2019s evaluation of a single item. These product ranking models could recommend product items to users and also provide overall <b>customer</b> <b>preference</b> patterns for a product category to manufacturers. In this study, we focus on developing a product ranking model that will reflect the overall <b>customer</b> <b>preferences</b>, which is implicitly represented by online product reviews.", "dateLastCrawled": "2021-12-02T22:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) A <b>heuristic based on clustering for the vehicle routing</b> problem ...", "url": "https://www.academia.edu/347934/A_heuristic_based_on_clustering_for_the_vehicle_routing_problem_a_case_study_on_spare_parts_distribution", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/347934", "snippet": "In this paper, a case is considered where a distribution center (warehouse of an auto spare parts company) receives orders regularly. Warehouse management is interested in assigning available vehicles to picked orders in such a way that lead time", "dateLastCrawled": "2022-01-29T10:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Recommendation Based on Users\u2019 Long</b>-Term and Short-Term Interests with ...", "url": "https://www.hindawi.com/journals/mpe/2019/7586589/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/mpe/2019/7586589", "snippet": "Unlike short-term <b>preference</b> learning, long-term <b>preference</b> learning is a global representation of a user\u2019s historical <b>preferences</b>. User\u2019s historical behavior data are very large even for a short period of time (such as two weeks). In order to balance efficiency and performance, this paper uses LSTM variant GRU to model dependence between user behaviors, and its input is user\u2019s historical interaction behavior. Hidasi et al.", "dateLastCrawled": "2022-01-30T10:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "<b>Vector</b> is useful sometimes because it will get you a set of values and you can easily perform an operation on it. Example. x &lt;-list(a =1, b =1:3, c =10:100) #Compare with above; a named <b>vector</b>, not a list sapply(x, FUN = length) a b c 1391 sapply(x, FUN = sum) a b c 165005. How to make scatterplot in R? A scatterplot is a graph which shows many points plotted in the Cartesian plane. Each point holds 2 values that are present on the x and y-axis. The simple scatterplot is plotted using plot ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Recognition of Consumer <b>Preference</b> by Analysis and Classification EEG ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7838383/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7838383", "snippet": "EEG-based <b>preference</b> classification normally includes the spectral conversion of waveforms <b>into</b> features exploited by data-mining algorithms, which are trained on labeled data to forecast whether <b>preferences</b> are presently being detected. The <b>preference</b> classification of EEG varies from binary labels such as (\u201clike\u201d vs. \u201cdislike\u201d) and (most favored vs. least favored) to multiple ordinal labels in the form of ranks, such as the nine-scale rank or five-scale rank. Several <b>preference</b> ...", "dateLastCrawled": "2022-02-02T20:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The <b>Cross-Entropy Method for Network Reliability Estimation</b> | Request PDF", "url": "https://www.researchgate.net/publication/226494839_The_Cross-Entropy_Method_for_Network_Reliability_Estimation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/226494839_The_<b>Cross-Entropy</b>_Method_for...", "snippet": "Individual employees like to have a good work-life balance, by having personal <b>preferences</b> taken <b>into</b> account, whereas there is also the common goal to work efficiently. By applying techniques and ...", "dateLastCrawled": "2022-01-02T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A <b>cross entropy approach to design of reliable networks</b> | Request PDF", "url": "https://www.researchgate.net/publication/222952511_A_cross_entropy_approach_to_design_of_reliable_networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/222952511_A_<b>cross_entropy_approach_to_design</b>...", "snippet": "Another entropy concept is <b>one</b> of <b>cross-entropy</b> which has been employed for measuring synchronization between time series (Xie et al. 2010). Altiparmak and Dengiz (2009) used <b>cross-entropy</b> for ...", "dateLastCrawled": "2021-10-19T04:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Evaluating Machine Learning Models</b> \u2013 O\u2019Reilly", "url": "https://www.oreilly.com/content/evaluating-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/content/<b>evaluating-machine-learning-models</b>", "snippet": "<b>Cross entropy</b> incorporates the entropy of the true distribution, plus the extra unpredictability when <b>one</b> assumes a different distribution than the true distribution. So log-loss is an information-theoretic measure to gauge the \u201cextra noise\u201d that comes from using a predictor as opposed to the true labels. By minimizing the <b>cross entropy</b>, we maximize the accuracy of the classifier.", "dateLastCrawled": "2022-01-26T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Neural <b>Collaborative Filtering</b>. Supercharging <b>collaborative filtering</b> ...", "url": "https://towardsdatascience.com/neural-collaborative-filtering-96cef1009401", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-<b>collaborative-filtering</b>-96cef1009401", "snippet": "<b>Collaborative filtering</b> models user <b>preference</b> on items based on their past interactions. Matrix Factorisation(MF) represents user/item as a <b>vector</b> of latent features which are projected <b>into</b> a shared feature space. In this feature space, the user-item interactions could be modeled using the inner product of user-item latent vectors. This vanilla implementation of MF can be enhanced by integrating it with neighbor based models, <b>combining</b> it with topic models of item content and extending it ...", "dateLastCrawled": "2022-02-03T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Prediction of Repeat Customers on E-Commerce Platform</b> Based ... - <b>Hindawi</b>", "url": "https://www.hindawi.com/journals/wcmc/2020/8841437/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/wcmc/2020/8841437", "snippet": "In recent years, blockchain has substantially enhanced the credibility of e-commerce platforms for users. The prediction accuracy of the repeat purchase behaviour of e-commerce users directly affects the impact of precision marketing by merchants. The existing ensemble learning models have low prediction accuracy when the purchase behaviour sample is unbalanced and the information dimension of feature engineering is single. To overcome this problem, an ensemble learning prediction model ...", "dateLastCrawled": "2022-02-02T23:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A purchase decision support model considering consumer personalization ...", "url": "https://www.sciencedirect.com/science/article/pii/S0969698921002940", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0969698921002940", "snippet": "The personalized decision aids, on the <b>one</b> hand, can reduce consumers&#39; information overload and make online shopping more convenient and attractive; on the other hand, it integrates consumers&#39; personal <b>preferences</b> to make consumers&#39; choices more targeted and reduce the purchasing burden and pressure. Additionally, the ranking system also has important practical significances for manufacturers. From the ranking results, they can clearly see where their products stand in the competition, which ...", "dateLastCrawled": "2021-11-18T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Research on Understanding the Effect of Deep Learning on User Preferences</b>", "url": "https://link.springer.com/article/10.1007/s13369-020-05112-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13369-020-05112-2", "snippet": "Conforming to the concepts of user-based collaborative filtering, as discussed in Sect. 2.1.2, users having <b>similar</b> <b>preferences</b> in <b>one</b> domain tend to have <b>similar</b> <b>preferences</b> in other domains as well. However, in many cases, this assumption may be rendered ineffective. Hence, the basic knowledge of the correlations between different domains is an essential aspect of MV-DNN. It is based on a Deep Structure-based Semantic Model (DSSM). In MV-DNN, the architecture of DSSM contains multiple ...", "dateLastCrawled": "2022-01-29T10:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Reinforcement learning based recommender systems: A survey \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2101.06286/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2101.06286", "snippet": "In order to decompose the Q-value of a slate <b>into</b> a combination of item-wise Q-values, they assume: 1) only <b>one</b> item from slate is consumed by the user, 2) the reward depends only on the item consumed. Using this decomposition, they show that TD methods, like SARSA and Q-learning, can be used to maximize long-term user engagement. They also propose a flexible environment simulator, called RecSim, which simulates the dynamics of both users and RSs. In an interesting RS application that is ...", "dateLastCrawled": "2022-01-23T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "These are again divided <b>into</b> 50 models as above and each model has 10 colors. So number of red-colored swift cars among unmarried unmarried people = 6 lakh / 500 -&gt; 12,000 Senior citizens Out of 2 Mn families(4 Mn people), 20% i.e. 0.4 Mn families own a car. Again, as above, these cars are divided <b>into</b> 50 models with each model having 10 colors ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>US7340408B1 - Method for evaluating customer valve</b> to guide loyalty and ...", "url": "https://patents.google.com/patent/US7340408B1/en", "isFamilyFriendly": true, "displayUrl": "https://patents.google.com/patent/US7340408", "snippet": "The <b>vector</b> {h i (t)} <b>can</b> <b>be thought</b> of as a raw hazard function for the i-th individual that the neural net will relate to the underlying covariates. The dataset is then split <b>into</b> training, testing and holdout, or validation, datasets. The train and test datasets use the target vectors described above and are used to train the neural network and avoid overfitting. The holdout data are used to evaluate performance of the neural network. Training the Neural Network. FIG. 2 represents the ...", "dateLastCrawled": "2022-02-03T05:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Combinatorial Optimization, <b>Cross-Entropy</b>, Ants and Rare Events", "url": "https://www.researchgate.net/publication/268007374_Combinatorial_Optimization_Cross-Entropy_Ants_and_Rare_Events", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/268007374_Combinatorial_Optimization_Cross...", "snippet": "The <b>Cross-Entropy</b> (CE) algorithm [22] is a relatively new method solving combinatorial optimization problems, and it was initially used for estimating probabilities of rare events in complex ...", "dateLastCrawled": "2022-01-29T14:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>The effectiveness of imprecise probability forecasts</b>, Journal of ...", "url": "https://www.deepdyve.com/lp/wiley/the-effectiveness-of-imprecise-probability-forecasts-lVnGx3ulK5", "isFamilyFriendly": true, "displayUrl": "https://www.deepdyve.com/lp/wiley/<b>the-effectiveness-of-imprecise-probability-forecasts</b>...", "snippet": "Minimum <b>cross-entropy</b> When uncertainty about first-order probabilities is expressed in the form of linear constraints on the first-order probabilities, the principle of minimum <b>cross-entropy</b> <b>can</b> be used to choose a single, \u00e2 minimally biased\u00e2 probability distribution. The minimum <b>cross-entropy</b> principle employs an information theoretic measure proposed by Kullback and Liebler (1951) of the distance between two discrete probability distributions, p and q. This measure, later named \u00e2 cross ...", "dateLastCrawled": "2020-06-09T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Victoria&#39;s ML Implementation Notes - Persagen", "url": "http://persagen.com/files/ml-implementation_notes.html", "isFamilyFriendly": true, "displayUrl": "persagen.com/files/ml-implementation_notes.html", "snippet": "When we have <b>one</b> good answer, we use a 1 hot <b>vector</b>, with <b>one</b> 1. We define the cost function as the <b>cross entropy</b> of the softmax <b>vector</b> with the good answer. What do we do when we have 2 or more good answers ? Do we define the last layer as sigmoid and we use the <b>cross entropy</b> on the sigmoid <b>vector</b> and the <b>one</b> hot good answer <b>vector</b> with several 1s ? If there are several things at the same time in my input, what is the best:", "dateLastCrawled": "2022-02-02T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) A <b>heuristic based on clustering for the vehicle routing</b> problem ...", "url": "https://www.academia.edu/347934/A_heuristic_based_on_clustering_for_the_vehicle_routing_problem_a_case_study_on_spare_parts_distribution", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/347934", "snippet": "In this paper, a case is considered where a distribution center (warehouse of an auto spare parts company) receives orders regularly. Warehouse management is interested in assigning available vehicles to picked orders in such a way that lead time", "dateLastCrawled": "2022-01-29T10:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Evaluating Machine Learning Models</b> \u2013 O\u2019Reilly", "url": "https://www.oreilly.com/content/evaluating-machine-learning-models/", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/content/<b>evaluating-machine-learning-models</b>", "snippet": "The trending topics change every day, sometimes every hour; what was popular yesterday may no longer be relevant today. <b>One</b> <b>can</b> imagine the distribution of user <b>preference</b> for news articles changing rapidly over time. Hence it\u2019s important to be able to detect distribution drift and adapt the model accordingly. <b>One</b> way to detect distribution drift is to continue to track the model\u2019s performance on the validation metric on live data. If the performance is comparable to the validation ...", "dateLastCrawled": "2022-01-26T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>New submissions for Tue, 13 Apr</b> 21 \u00b7 Issue #309 \u00b7 kobiso/daily-arxiv ...", "url": "https://github.com/kobiso/daily-arxiv-noti/issues/309", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/kobiso/daily-arxiv-noti/issues/309", "snippet": "Modern human-object interaction (HOI) detection approaches <b>can</b> be divided <b>into</b> <b>one</b>-stage methods and twostage ones. <b>One</b>-stage models are more efficient due to their straightforward architectures, but the two-stage models are still advantageous in accuracy. Existing <b>one</b>-stage models usually begin by detecting predefined interaction areas or points, and then attend to these areas only for interaction prediction; therefore, they lack reasoning steps that dynamically search for discriminative ...", "dateLastCrawled": "2021-10-20T12:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "<b>One</b> simple way to understand overfitting is that our information from past experiences <b>can</b> be divided <b>into</b> two groups. 1. Information that is relevant for prediction 2. Information that is irrelevant for prediction. It is also called noise. Whenever there is more noise, it is more difficult for a model to predict correctly. It is a difficult ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Proceedings of the 59th Annual Meeting of the Association for ...", "url": "https://aclanthology.org/volumes/2021.acl-long/", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/volumes/2021.acl-long", "snippet": "The nodes and edges <b>can</b> be generated respectively in <b>one</b> stage with a grid tagging scheme and learned jointly using a novel architecture named Mac. Then discontinuous NER <b>can</b> be reformulated as a non-parametric process of discovering maximal cliques in the graph and concatenating the spans in each clique. Experiments on three benchmarks show that our method outperforms the state-of-the-art (SOTA) results, with up to 3.5 percentage points improvement on F1, and achieves 5x speedup over the ...", "dateLastCrawled": "2022-01-29T06:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) A <b>Neural Engine for Movie Recommendation System</b>", "url": "https://www.researchgate.net/publication/326438976_A_Neural_Engine_for_Movie_Recommendation_System", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/326438976_A_Neural_Engine_for_Movie...", "snippet": "A recommendation system is a sort of information filtering. technique in which seek to predict the rating or <b>preferences</b> of a. user and make recommendations based on these <b>preferences</b> [1]. There ...", "dateLastCrawled": "2022-01-02T15:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The <b>Cross-Entropy Method for Network Reliability Estimation</b> | Request PDF", "url": "https://www.researchgate.net/publication/226494839_The_Cross-Entropy_Method_for_Network_Reliability_Estimation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/226494839_The_<b>Cross-Entropy</b>_Method_for...", "snippet": "In this paper we study how the <b>Cross-Entropy</b> method <b>can</b> be used to obtain more efficient network reliability estimation procedures. Three techniques of estimation are considered: Crude Monte Carlo ...", "dateLastCrawled": "2022-01-02T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Recognition of Consumer <b>Preference</b> by Analysis and Classification EEG ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7838383/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7838383", "snippet": "EEG-based <b>preference</b> classification normally includes the spectral conversion of waveforms <b>into</b> features exploited by data-mining algorithms, which are trained on labeled data to forecast whether <b>preferences</b> are presently being detected. The <b>preference</b> classification of EEG varies from binary labels such as (\u201clike\u201d vs. \u201cdislike\u201d) and (most favored vs. least favored) to multiple ordinal labels in the form of ranks, such as the nine-scale rank or five-scale rank. Several <b>preference</b> ...", "dateLastCrawled": "2022-02-02T20:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Cross Entropy</b> for Discrete Z-numbers and Its Application in Multi ...", "url": "https://www.researchgate.net/publication/333989925_Cross_Entropy_for_Discrete_Z-numbers_and_Its_Application_in_Multi-Criteria_Decision-Making", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/333989925_<b>Cross_Entropy</b>_for_Discrete_Z...", "snippet": "The <b>cross entropy</b> of discrete Z-numbers, which is based on the <b>cross entropy</b> of restriction and reliability of Znumbers [44]. The negation of Z-numbers is proposed based on combination of ...", "dateLastCrawled": "2022-01-11T17:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A deep recommendation model of cross-grained sentiments of user reviews ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321003149", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321003149", "snippet": "Textual reviews usually contain rich information about items\u2019 features and users\u2019 sentiments and <b>preferences</b>, which <b>can</b> solve the problem of insufficient information from only user ratings. However, most recommendation algorithms that take sentiment analysis of review texts <b>into</b> account are either fine- or coarse-grained, but not both, leading to uncertain accuracy and comprehensiveness regarding user <b>preference</b>. This study proposes a deep learning recommendation model (i.e., DeepCGSR ...", "dateLastCrawled": "2022-01-23T21:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Neural <b>Collaborative Filtering</b>. Supercharging <b>collaborative filtering</b> ...", "url": "https://towardsdatascience.com/neural-collaborative-filtering-96cef1009401", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/neural-<b>collaborative-filtering</b>-96cef1009401", "snippet": "<b>Collaborative filtering</b> models user <b>preference</b> on items based on their past interactions. Matrix Factorisation(MF) represents user/item as a <b>vector</b> of latent features which are projected <b>into</b> a shared feature space. In this feature space, the user-item interactions could be modeled using the inner product of user-item latent vectors. This vanilla implementation of MF <b>can</b> be enhanced by integrating it with neighbor based models, <b>combining</b> it with topic models of item content and extending it ...", "dateLastCrawled": "2022-02-03T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Short Question | Short Question Online Test - Avatto", "url": "https://avatto.com/interview-questions/short-question/", "isFamilyFriendly": true, "displayUrl": "https://avatto.com/interview-questions/short-question", "snippet": "<b>One</b> simple way to understand overfitting is that our information from past experiences <b>can</b> be divided <b>into</b> two groups. 1. Information that is relevant for prediction 2. Information that is irrelevant for prediction. It is also called noise. Whenever there is more noise, it is more difficult for a model to predict correctly. It is a difficult ...", "dateLastCrawled": "2022-01-26T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "SDM: <b>Sequential Deep Matching</b> Model for Online Large-scale Recommender ...", "url": "https://deepai.org/publication/sdm-sequential-deep-matching-model-for-online-large-scale-recommender-system", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/sdm-<b>sequential-deep-matching</b>-model-for-online-large...", "snippet": "<b>Compared</b> with existing sequence-aware recommendation methods, we tackle the following two inherent problems in real-world applications: (1) there could exist multiple interest tendencies in <b>one</b> session. (2) long-term <b>preferences</b> may not be effectively fused with current session interests. Long-term behaviors are various and complex, hence those highly related to the short-term session should be kept for fusion. We propose to encode behavior sequences with two corresponding components: multi ...", "dateLastCrawled": "2021-12-20T11:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "FG-RS: Capture user fine-grained <b>preferences</b> through attribute ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231221008213", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231221008213", "snippet": "This method uses the interaction between the user and the item to model the user\u2019s interaction <b>preferences</b> and embeds the user and the item <b>into</b> the same size low-dimensional representation space, and then uses the inner product to obtain the user\u2019s <b>preference</b> <b>vector</b>. On the other hand, the model uses the attribute information of users and items to model user <b>preferences</b> on attributes. In order to capture more fine-grained user <b>preferences</b>, we use the attention mechanism to distinguish ...", "dateLastCrawled": "2021-11-24T15:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Prediction of Repeat Customers on E-Commerce Platform</b> Based ... - <b>Hindawi</b>", "url": "https://www.hindawi.com/journals/wcmc/2020/8841437/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/wcmc/2020/8841437", "snippet": "In recent years, blockchain has substantially enhanced the credibility of e-commerce platforms for users. The prediction accuracy of the repeat purchase behaviour of e-commerce users directly affects the impact of precision marketing by merchants. The existing ensemble learning models have low prediction accuracy when the purchase behaviour sample is unbalanced and the information dimension of feature engineering is single. To overcome this problem, an ensemble learning prediction model ...", "dateLastCrawled": "2022-02-02T23:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) A <b>heuristic based on clustering for the vehicle routing</b> problem ...", "url": "https://www.academia.edu/347934/A_heuristic_based_on_clustering_for_the_vehicle_routing_problem_a_case_study_on_spare_parts_distribution", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/347934", "snippet": "In this paper, a case is considered where a distribution center (warehouse of an auto spare parts company) receives orders regularly. Warehouse management is interested in assigning available vehicles to picked orders in such a way that lead time", "dateLastCrawled": "2022-01-29T10:03:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Why and How to use <b>Cross Entropy</b>. The fundamental reasons for ...", "url": "https://towardsdatascience.com/why-and-how-to-use-cross-entropy-4e983cbdd873", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/why-and-how-to-use-<b>cross-entropy</b>-4e983cbdd873", "snippet": "The fundamental reasons for minimizing binary <b>cross entropy</b> (log loss) with probabilistic classification models . Will Arliss. Sep 26, 2020 \u00b7 7 min read. Introduction. This post discusses why logistic regression necessarily uses a different loss function than linear regression. First, the simple yet inefficient way to solve logistic regression will be presented, then the slightly less simple but much more efficient way will be explained and compared. The simple way. Linear regression is the ...", "dateLastCrawled": "2022-01-31T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Cross-Entropy</b> Demystified. What is it? Is there any relation to\u2026 | by ...", "url": "https://naokishibuya.medium.com/demystifying-cross-entropy-e80e3ad54a8", "isFamilyFriendly": true, "displayUrl": "https://naokishibuya.medium.com/demystifying-<b>cross-entropy</b>-e80e3ad54a8", "snippet": "However, the <b>machine</b> <b>learning</b> application uses the base e logarithm for implementation convenience. Binary <b>Cross-Entropy</b>. We can use the binary <b>cross-entropy</b> for binary classification where we have yes/no answer. For example, there are only dogs or cats in images. For the binary classifications, the <b>cross-entropy</b> formula contains only two ...", "dateLastCrawled": "2022-01-26T13:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Gentle Introduction to Information Entropy - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/what-is-information-entropy/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/what-is-information-entropy", "snippet": "Calculating information and entropy is a useful tool in <b>machine</b> <b>learning</b> and is used as the basis for techniques such as feature selection, building decision trees, and, more generally, fitting classification models. As such, a <b>machine</b> <b>learning</b> practitioner requires a strong understanding and intuition for information and entropy. In this post, you will discover a gentle introduction to information entropy. After reading this post, you will know: Information theory is concerned with data ...", "dateLastCrawled": "2022-02-02T13:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>machine</b> <b>learning</b> - <b>Cross-entropy loss</b> explanation - Data Science Stack ...", "url": "https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/20296", "snippet": "The answer from Neil is correct. However I think its important to point out that while the loss does not depend on the distribution between the incorrect classes (only the distribution between the correct class and the rest), the gradient of this loss function does effect the incorrect classes differently depending on how wrong they are. So when you use cross-ent in <b>machine</b> <b>learning</b> you will change weights differently for [0.1 0.5 0.1 0.1 0.2] and [0.1 0.6 0.1 0.1 0.1].", "dateLastCrawled": "2022-01-27T03:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> Concepts for Revision | by Raunak Sarada | Medium", "url": "https://raunaksarada-cse21.medium.com/machine-learning-concepts-for-revision-491384952d27", "isFamilyFriendly": true, "displayUrl": "https://raunaksarada-cse21.medium.com/<b>machine</b>-<b>learning</b>-concepts-for-revision-491384952d27", "snippet": "ML Concepts. A.I \u2014 Intelligence showed by machines which is common for humans <b>Machine</b> <b>Learning</b>- Recognize the pattern in data and automatically learn and improve through experience without explicitly being programmed Deep <b>Learning</b>- branch of <b>machine</b> <b>learning</b>.We have to deal with lots of data so in that case problems can\u2019t be solved with simple ML algorithms.", "dateLastCrawled": "2022-01-25T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Shannon <b>entropy</b> in the context of <b>machine</b> <b>learning</b> and AI | by Frank ...", "url": "https://medium.com/swlh/shannon-entropy-in-the-context-of-machine-learning-and-ai-24aee2709e32", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/shannon-<b>entropy</b>-in-the-context-of-<b>machine</b>-<b>learning</b>-and-ai-24...", "snippet": "Closely related to <b>cross entropy</b>, the KL divergence from q to p, written DKL(p||q), is another similarity measure often used in <b>machine</b> <b>learning</b>. In the language of Bayesian Inference, DKL(p||q ...", "dateLastCrawled": "2022-01-30T12:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Main concepts behind Machine Learning</b> | by Bruno Eidi Nishimoto ...", "url": "https://medium.com/neuronio/main-concepts-behind-machine-learning-22cd81d68a11", "isFamilyFriendly": true, "displayUrl": "https://medium.com/neuronio/<b>main-concepts-behind-machine-learning</b>-22cd81d68a11", "snippet": "<b>Machine</b> <b>Learning</b> is a concept that is currently trending. It is a subarea from Artificial Intelligence and it consists on the fact that the <b>machine</b> can learn by itself without being explicitly ...", "dateLastCrawled": "2022-01-19T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Lecture 4 Fundamentals of deep <b>learning</b> and neural networks", "url": "https://web.stanford.edu/class/biods388/downloads/BIODS388_Lecture_4.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/biods388/downloads/BIODS388_Lecture_4.pdf", "snippet": "Deep <b>learning</b>: <b>Machine</b> <b>learning</b> models based on \u201cdeep\u201d neural networks comprising millions (sometimes billions) of parameters organized into hierarchical layers. Features are multiplied and added together repeatedly, with the outputs from one layer of parameters being fed into the next layer -- before a prediction is made. Contrast with linear regression: Agenda for today - More on the structure of neural network models - <b>Machine</b> <b>learning</b> training loop and concept of loss, in the context ...", "dateLastCrawled": "2022-02-02T09:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Deep Learning and Information Theory</b> \u2013 Deep &amp; Shallow", "url": "https://deep-and-shallow.com/2020/01/09/deep-learning-and-information-theory/", "isFamilyFriendly": true, "displayUrl": "https://deep-and-shallow.com/2020/01/09/<b>deep-learning-and-information-theory</b>", "snippet": "If you have tried to understand the maths behind <b>machine</b> <b>learning</b>, including deep <b>learning</b>, you would have come across topics from Information Theory \u2013 Entropy, <b>Cross Entropy</b>, KL Divergence, etc. The concepts from information theory is ever prevalent in the realm of <b>machine</b> <b>learning</b>, right from the splitting criteria of a Decision Tree to loss functions in Generative Adversarial Networks.", "dateLastCrawled": "2022-02-01T00:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[D] A Short Introduction to Entropy, <b>Cross-Entropy</b> and KL-Divergence ...", "url": "https://www.reddit.com/r/MachineLearning/comments/7vhmp7/d_a_short_introduction_to_entropy_crossentropy/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/7vhmp7/d_a_short_introduction_to...", "snippet": "I am having trouble reconciling the concept with the <b>analogy</b>. At 2:35 even if a rainy day was 25% likely, there&#39;s still only two states, rainy and sunny, and therefor only 1 bit of information is needed to convey that, so only one bit of data needs to be sent, even though the 1 bit of data reduces the uncertainty of a rainy day by a factor of 4. I quite don&#39;t get what he means by this being 2 bits of information. I guess where I am stuck is how the uncertainty reduction factor translates to ...", "dateLastCrawled": "2021-08-20T08:03:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Beat the Bookmakers With Tree-Based <b>Machine</b> <b>Learning</b> Algorithms | by ...", "url": "https://medium.com/analytics-vidhya/beat-the-bookmakers-with-tree-based-machine-learning-algorithms-1d349335b54", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/beat-the-bookmakers-with-tree-based-<b>machine</b>...", "snippet": "<b>Cross-entropy is similar</b> to Gini Impurity, but it involves using the concept of entropy from information theory. This article won\u2019t go in depth about it, but essentially, as the cross-entropy ...", "dateLastCrawled": "2022-01-26T04:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>A Traveler\u2019s Diary on the Road to Machine</b> <b>Learning</b> - Chapter 1 | by ...", "url": "https://medium.com/swlh/a-travelers-diary-on-the-road-to-machine-learning-chapter-1-8850ec5b4243", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>a-travelers-diary-on-the-road-to-machine</b>-<b>learning</b>-chapter-1...", "snippet": "Types of <b>Machine</b> <b>Learning</b> algorithms: ... Sparse categorical <b>cross entropy is similar</b> to categorical cross entropy, only difference is it uses only one value as target. It saves memory as well as ...", "dateLastCrawled": "2021-05-21T04:27:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Deep Learning for Computer Architects</b> | Chen Jeff - Academia.edu", "url": "https://www.academia.edu/40860009/Deep_Learning_for_Computer_Architects", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/40860009/<b>Deep_Learning_for_Computer_Architects</b>", "snippet": "This text serves as a primer for computer architects in a new and rapidly evolving \ufb01eld. We review how <b>machine</b> <b>learning</b> has evolved since its inception in the 1960s and track the key developments leading up to the emergence of the powerful deep <b>learning</b> techniques that emerged in the last decade.", "dateLastCrawled": "2022-01-28T02:18:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(cross-entropy)  is like +(combining the preferences of a customer into one preference vector)", "+(cross-entropy) is similar to +(combining the preferences of a customer into one preference vector)", "+(cross-entropy) can be thought of as +(combining the preferences of a customer into one preference vector)", "+(cross-entropy) can be compared to +(combining the preferences of a customer into one preference vector)", "machine learning +(cross-entropy AND analogy)", "machine learning +(\"cross-entropy is like\")", "machine learning +(\"cross-entropy is similar\")", "machine learning +(\"just as cross-entropy\")", "machine learning +(\"cross-entropy can be thought of as\")", "machine learning +(\"cross-entropy can be compared to\")"]}