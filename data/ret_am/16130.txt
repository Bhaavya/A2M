{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> Fairness: Types of <b>Bias</b> | by Svs Nagesh | Medium", "url": "https://nageshsomayajula.medium.com/machine-learning-fairness-types-of-bias-82bcf3df2d47", "isFamilyFriendly": true, "displayUrl": "https://nageshsomayajula.medium.com/<b>machine</b>-<b>learning</b>-fairness-types-of-<b>bias</b>-82bcf3df2d47", "snippet": "In <b>machine</b> <b>learning</b> projects where the <b>machine</b> does sentiment analysis for movies rating by each user, a sentiment-analysis model is trained to predict whether movie reviews are positive or negative based on the corpus of user\u2019s submission to a popular website <b>like</b> Netflix, etc. Most reviews in the training data set reflect extreme opinions (reviewers who either loved or hated a movie) because people were less likely to submit a review of a movie if they did not respond to it strongly. As ...", "dateLastCrawled": "2022-01-30T12:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "See also <b>out-group</b> <b>homogeneity</b> <b>bias</b> and in-group <b>bias</b>. H. hashing. In <b>machine learning</b>, a mechanism for bucketing categorical data, particularly when the number of categories is large, but the number of categories actually appearing in the dataset is comparatively small. For example, Earth is home to about 60,000 tree species. You could ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "GitHub - ikasu93/Data-Science-<b>Bias</b>-Guideline: A simple <b>bias</b> guideline ...", "url": "https://github.com/ikasu93/Data-Science-Bias-Guideline", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ikasu93/Data-Science-<b>Bias</b>-Guideline", "snippet": "<b>Out-group</b> <b>homogeneity</b> <b>bias</b>: A tendency to stereotype individual members of a group to which you do not belong, or to see their characteristics as more uniform. Example: Two engineers training a r\u00e9sum\u00e9-screening model for software developers are predisposed to believe that all applicants who did not attend a computer-science academy do not have sufficient expertise for the role [70]. Best Practices: In order to avoid group attribution biases, data scientists should not behave judgmentally ...", "dateLastCrawled": "2021-11-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The <b>Data Science ABCs: A Whirlwind Tour of the Field</b> | by Andre Ye ...", "url": "https://medium.com/analytics-vidhya/the-data-science-abcs-a-whirlwind-tour-of-the-field-779f2e3c4d8d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/the-<b>data-science-abcs-a-whirlwind-tour</b>-of-the...", "snippet": "<b>Out-Group</b> <b>Homogeneity</b> <b>Bias</b> comes from a group of biases that are too often ignored in <b>machine</b> <b>learning</b>. The water is only as good as the ice caps are pure, and hence, the model and analyses are ...", "dateLastCrawled": "2020-07-23T07:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Why Mitigating AI Biases Is The</b> Need Of The Hour?", "url": "https://analyticsindiamag.com/why-mitigating-ai-biases-is-the-need-of-the-hour/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/<b>why-mitigating-ai-biases-is-the</b>-need-of-the-hour", "snippet": "Some of the common biases for AI models would include group attribution <b>bias</b>, <b>out-group</b> <b>homogeneity</b> <b>bias</b>, and selection-based <b>bias</b>, to name a few. In fact, some of the famous AI biases happened \u2014 when Google Photos classified black people as gorillas, when Google\u2019s facial recognition wasn\u2019t able to recognise people of colour, and when an education software showed discrimination against Guamanian students with their passing score. Also Read: How Businesses Can Adopt Responsible AI Amid ...", "dateLastCrawled": "2022-02-03T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Biases in <b>machine</b> <b>learning</b> models and big data analytics: The ...", "url": "http://international-review.icrc.org/articles/biases-machine-learning-big-data-analytics-ihl-implications-913", "isFamilyFriendly": true, "displayUrl": "international-review.icrc.org/articles/<b>bias</b>es-<b>machine</b>-<b>learning</b>-big-data-analytics-ihl...", "snippet": "Non-response <b>bias</b> or participation <b>bias</b> is a form of selection <b>bias</b> that occurs when users from certain groups opt out from participating in the process, such that the data set ends up being unrepresentative due to participation gaps in the data collection process.41 This <b>bias</b> can be prevalent where marginalized or traditionally under-represented groups distrust the process and are consequently less likely to participate in it.42 This also happens to be a common issue in internal armed ...", "dateLastCrawled": "2022-02-01T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Algorithmic <b>bias</b> in data-driven innovation in the age of AI - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0268401221000803", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0268401221000803", "snippet": "Similarly, if sample elements are selected from an incorrect target population, <b>out-group</b> <b>homogeneity</b> <b>bias</b> can arise as developers tend to identify members from incorrect sample units as more <b>like</b> a target population with regard to attributes, traits, values, attitudes and personality. Due to these biases, Amazon has recently abandoned using an AI-based recruitment <b>algorithm</b> platform that treated female applicants unfairly due to the scarcity of female applicants\u2019 data incorporated into ...", "dateLastCrawled": "2022-01-08T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Understanding and Mitigating <b>Bias</b> - GitHub Pages", "url": "https://axa-rev-research.github.io/static/AXA_Booklet_Bias.pdf", "isFamilyFriendly": true, "displayUrl": "https://axa-rev-research.github.io/static/AXA_Booklet_<b>Bias</b>.pdf", "snippet": "<b>Like</b> a recipe, they consist of a hard-coded set of rules which always produce the same output. The software engineer explicitly programs the <b>algorithm</b>\u2019s logic without using any data. When the <b>algorithm</b> is put into production, data are fed to the <b>algorithm</b> in order to produce results. Data has no impact on the <b>algorithm</b> in itself. \u02dc\u02da\u02db\u02da \u02dc\u02da\u02db\u02da Development roduction 11. 12 Figure 2: <b>Machine</b> <b>Learning</b> (ML) <b>algorithm</b> in development and production phase <b>Machine</b> <b>learning</b> ( ML) In contrast to ...", "dateLastCrawled": "2021-09-17T04:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "algorithmic <b>bias</b> \u2014 Research \u2014 Katina Michael", "url": "https://www.katinamichael.com/research/tag/algorithmic+bias", "isFamilyFriendly": true, "displayUrl": "https://www.katinamichael.com/research/tag/<b>algorithm</b>ic+<b>bias</b>", "snippet": "Similarly, if sample elements are selected from an incorrect target population, <b>out-group</b> <b>homogeneity</b> <b>bias</b> can arise as developers tend to identify members from incorrect sample units as more <b>like</b> a target population with regard to attributes, traits, values, attitudes and personality. Due to these biases, Amazon has recently abandoned using an AI-based recruitment <b>algorithm</b> platform that treated female applicants unfairly due to the scarcity of female applicants\u2019 data incorporated into ...", "dateLastCrawled": "2021-11-04T14:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Biases <b>Make People Vulnerable to Misinformation</b> Spread by Social Media ...", "url": "https://www.scientificamerican.com/article/biases-make-people-vulnerable-to-misinformation-spread-by-social-media/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.scientificamerican.com</b>/article/<b>bias</b>es-make-people-vulnerable-to...", "snippet": "<b>Bias</b> in the <b>machine</b>. The third group of biases arises directly from the algorithms used to determine what people see online. Both social media platforms and search engines employ them. These ...", "dateLastCrawled": "2022-01-30T01:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "See also <b>out-group</b> <b>homogeneity</b> <b>bias</b> and in-group <b>bias</b>. H. hashing. In <b>machine learning</b>, a mechanism for bucketing categorical data, particularly when the number of categories is large, but the number of categories actually appearing in the dataset is comparatively small. For example, Earth is home to about 60,000 tree species. You could ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Algorithmic <b>bias</b> in data-driven innovation in the age of AI - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0268401221000803", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0268401221000803", "snippet": "Similarly, if sample elements are selected from an incorrect target population, <b>out-group</b> <b>homogeneity</b> <b>bias</b> can arise as developers tend to identify members from incorrect sample units as more like a target population with regard to attributes, traits, values, attitudes and personality. Due to these biases, Amazon has recently abandoned using an AI-based recruitment <b>algorithm</b> platform that treated female applicants unfairly due to the scarcity of female applicants\u2019 data incorporated into ...", "dateLastCrawled": "2022-01-08T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "GitHub - ikasu93/Data-Science-<b>Bias</b>-Guideline: A simple <b>bias</b> guideline ...", "url": "https://github.com/ikasu93/Data-Science-Bias-Guideline", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ikasu93/Data-Science-<b>Bias</b>-Guideline", "snippet": "<b>Out-group</b> <b>homogeneity</b> <b>bias</b>: A tendency to stereotype individual members of a group to which you do not belong, or to see their characteristics as more uniform. Example: Two engineers training a r\u00e9sum\u00e9-screening model for software developers are predisposed to believe that all applicants who did not attend a computer-science academy do not have sufficient expertise for the role [70]. Best Practices: In order to avoid group attribution biases, data scientists should not behave judgmentally ...", "dateLastCrawled": "2021-11-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>machine learning</b> - missylafferty.com", "url": "https://missylafferty.com/tag/machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://missylafferty.com/tag/<b>machine-learning</b>", "snippet": "Selection <b>bias</b>: The training data for <b>machine learning</b> systems is not a random sample of the world but instead things we find interesting ; Overgeneralization: Conclusion is made based on limited information or information not specific enough ; <b>Out-group</b> <b>homogeneity</b> <b>bias</b>: We assume people in groups we don\u2019t interact with every day are more <b>similar</b> to each other than those in our in-group; Confirmation <b>bias</b>: Tendency to search for, interpret and favor information that confirms our own pre ...", "dateLastCrawled": "2021-12-29T11:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The <b>Data Science ABCs: A Whirlwind Tour of the Field</b> | by Andre Ye ...", "url": "https://medium.com/analytics-vidhya/the-data-science-abcs-a-whirlwind-tour-of-the-field-779f2e3c4d8d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/the-<b>data-science-abcs-a-whirlwind-tour</b>-of-the...", "snippet": "<b>Out-Group</b> <b>Homogeneity</b> <b>Bias</b> comes from a group of biases that are too often ignored in <b>machine</b> <b>learning</b>. The water is only as good as the ice caps are pure, and hence, the model and analyses are ...", "dateLastCrawled": "2020-07-23T07:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "algorithmic <b>bias</b> \u2014 Research \u2014 Katina Michael", "url": "https://www.katinamichael.com/research/tag/algorithmic+bias", "isFamilyFriendly": true, "displayUrl": "https://www.katinamichael.com/research/tag/<b>algorithm</b>ic+<b>bias</b>", "snippet": "Similarly, if sample elements are selected from an incorrect target population, <b>out-group</b> <b>homogeneity</b> <b>bias</b> can arise as developers tend to identify members from incorrect sample units as more like a target population with regard to attributes, traits, values, attitudes and personality. Due to these biases, Amazon has recently abandoned using an AI-based recruitment <b>algorithm</b> platform that treated female applicants unfairly due to the scarcity of female applicants\u2019 data incorporated into ...", "dateLastCrawled": "2021-11-04T14:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Designing medical artificial intelligence for in- and out-groups ...", "url": "https://www.researchgate.net/publication/352673651_Designing_medical_artificial_intelligence_for_in-_and_out-groups", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/352673651_Designing_medical_artificial...", "snippet": "The classic (symmetric) view accounted well for differences in perceived variability: all groups showed the <b>out-group</b> <b>homogeneity</b> <b>bias</b>. Ethnocentrism also appeared to be a symmetrical effect ...", "dateLastCrawled": "2022-01-23T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Predictive usefulness of RT-PCR testing in different patterns of Covid ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8551264/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8551264", "snippet": "We use a <b>machine</b>-<b>learning</b> <b>algorithm</b> (decision tree) in order to predict RT-PCR results based on the clinical presentation. We show that symptoms alone are sufficient to predict RT-PCR outcome with a mean average precision of 86%. We identify combinations of symptoms that are predictive of RT-PCR positivity (90% for anosmia/ageusia) or negativity (only 30% of RT-PCR+ for a subgroup with cardiopulmonary symptoms): in both cases, RT-PCR provides little added diagnostic value. We propose a ...", "dateLastCrawled": "2021-12-06T14:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Biases in <b>machine</b> <b>learning</b> models and big data analytics: The ...", "url": "http://international-review.icrc.org/articles/biases-machine-learning-big-data-analytics-ihl-implications-913", "isFamilyFriendly": true, "displayUrl": "international-review.icrc.org/articles/<b>bias</b>es-<b>machine</b>-<b>learning</b>-big-data-analytics-ihl...", "snippet": "Advances in mobile phone technology and social media have created a world where the volume of information generated and shared is outpacing the ability of humans to review and use that data. <b>Machine</b> <b>learning</b> (ML) models and \u201cbig data\u201d analytical tools have the power to ease that burden by making sense of this information and providing insights that might not otherwise exist. In the context of international criminal and human rights law, ML is being used for a variety of purposes ...", "dateLastCrawled": "2022-02-01T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "\u5b66\u4e60\u7b14\u8bb0\u4e4b<b>Machine</b> <b>Learning</b> Crash Course | Google Developers_weixin_34166472 ...", "url": "https://its401.com/article/weixin_34166472/93303327", "isFamilyFriendly": true, "displayUrl": "https://its401.com/article/weixin_34166472/93303327", "snippet": "<b>Out-group</b> <b>homogeneity</b> <b>bias</b>: A tendency to stereotype individual members of a group to which you do not belong, or to see their characteristics as more uniform. EXAMPLE: Two engineers training a r\u00e9sum\u00e9-screening model for software developers are predisposed to believe that all applicants who did not attend a computer-science academy do not have sufficient expertise for the role.", "dateLastCrawled": "2022-01-10T20:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The <b>Data Science ABCs: A Whirlwind Tour of the Field</b> | by Andre Ye ...", "url": "https://medium.com/analytics-vidhya/the-data-science-abcs-a-whirlwind-tour-of-the-field-779f2e3c4d8d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/the-<b>data-science-abcs-a-whirlwind-tour</b>-of-the...", "snippet": "<b>Out-Group</b> <b>Homogeneity</b> <b>Bias</b> comes from a group of biases that are too often ignored in <b>machine</b> <b>learning</b>. The water is only as good as the ice caps are pure, and hence, the model and analyses are ...", "dateLastCrawled": "2020-07-23T07:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "IJIM \u2014 Research \u2014 Katina Michael", "url": "https://www.katinamichael.com/research/category/IJIM", "isFamilyFriendly": true, "displayUrl": "https://www.katinamichael.com/research/category/IJIM", "snippet": "Similarly, if sample elements are selected from an incorrect target population, <b>out-group</b> <b>homogeneity</b> <b>bias</b> <b>can</b> arise as developers tend to identify members from incorrect sample units as more like a target population with regard to attributes, traits, values, attitudes and personality. Due to these biases, Amazon has recently abandoned using an AI-based recruitment <b>algorithm</b> platform that treated female applicants unfairly due to the scarcity of female applicants\u2019 data incorporated into ...", "dateLastCrawled": "2022-01-23T03:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "GitHub - ikasu93/Data-Science-<b>Bias</b>-Guideline: A simple <b>bias</b> guideline ...", "url": "https://github.com/ikasu93/Data-Science-Bias-Guideline", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ikasu93/Data-Science-<b>Bias</b>-Guideline", "snippet": "Nr. Sources of Algorithmic <b>Bias</b>[48]:; 1: Biased Training data <b>can</b> be the source of algorithmic <b>bias</b>.: 2: Algorithms <b>can</b> be biased via differential use of information (using morally irrelevant categories to make morally relevant and sensitive judgements).: 3: During the data processing, the <b>algorithm</b> <b>can</b> itself be biased, called <b>Algorithm</b> Processing <b>Bias</b>.The most obvious instance of algorithmic processing <b>bias</b> is the use of a statistically biased estimator in the <b>algorithm</b> for better future ...", "dateLastCrawled": "2021-11-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Biases in Data Science Lifecycle</b>", "url": "https://www.researchgate.net/publication/344334843_Biases_in_Data_Science_Lifecycle", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344334843_<b>Biases_in_Data_Science_Lifecycle</b>", "snippet": "(3) During the data processing, the <b>algorithm</b> <b>can</b> itself be biased, called <b>Algorithm</b> Processing <b>Bias</b>. The most obvious in stance of algorithmic processing <b>bia s</b> is the use of a statistically", "dateLastCrawled": "2021-09-17T19:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Resources for <b>the Teaching of Social Psychology</b> - Prejudice", "url": "http://jfmueller.faculty.noctrl.edu/crow/prejudice.htm", "isFamilyFriendly": true, "displayUrl": "jfmueller.faculty.noctrl.edu/crow/prejudice.htm", "snippet": "Each student in a group dynamics course observed two groups in conflict and identified examples of in-group <b>bias</b>, double-standard thinking, <b>out-group</b> <b>homogeneity</b> <b>bias</b>, law of small numbers, group attribution error, ultimate attribution error, and moral exclusion. Students individually wrote papers detailing their observations. The author then carefully structured students&#39; small and large group discussions so students could present and compare their findings orally. Pretest\u2013posttest ...", "dateLastCrawled": "2022-01-26T15:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 5, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "Heuristic (psychology) - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Heuristic_(psychology)", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/Heuristic_(psychology)", "snippet": "Heuristic (psychology) Heuristics is the process by which humans use mental short cuts to arrive at decisions. Heuristics are simple strategies that humans, animals, organizations, and even machines use to quickly form judgments, make decisions, and find solutions to complex problems. Often this involves focusing on the most relevant aspects of ...", "dateLastCrawled": "2022-01-27T18:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Psychology Review Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/161319497/psychology-review-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/161319497/psychology-review-flash-cards", "snippet": "In-group/<b>out-group</b> <b>bias</b>: Us vs. Them Inclusion Exclusion. <b>Out-group</b> <b>Homogeneity</b>. We tend to classify people who are not in our-group as being similar to one another &quot;They&#39;re all like that&quot; Inclusion. Group membership or belonging. Exclusion. Being left out. Attitudes . Evaluation of things, events, and people Components: ~Cognitive ~Affective ~Behavioral. Cognitive Dissonance Theory. Feeling of discomfort that occurs when faced with conflict. We bring out attitudes in line with our actions ...", "dateLastCrawled": "2018-11-08T07:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Two example of <b>bias</b> brainly | two examples of b", "url": "https://mespoliziotti.com/resources/knowledge/other/type-ii-error/p03hv2703cbo", "isFamilyFriendly": true, "displayUrl": "https://mespoliziotti.com/resources/knowledge/other/type-ii-error/p03hv2703cbo", "snippet": "A biased survey <b>can</b> lead to survey response <b>bias</b> and higher than normal drop-out rates. Now, let&#39;s view 10 examples of survey <b>bias</b>. #1: The Leading Question. One of the biggest mistakes survey creators make is creating a question that leads respondents to give the correct answer ; C. cultural <b>bias</b>. D. socioeconomic <b>bias</b>. b. Provide two examples of environmental deprivation. Describe how they <b>can</b> influence intelligence. Environmental deprivation (conditions of isolation, poor nutrition ...", "dateLastCrawled": "2022-01-28T15:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Intergroup Relations</b> | SpringerLink", "url": "https://link.springer.com/chapter/10.1007/978-94-007-6772-0_18", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-94-007-6772-0_18", "snippet": "This process is experimental and the keywords may be updated as the <b>learning</b> <b>algorithm</b> improves. This is a preview of subscription content, log in to check access. References. Abrams, D., &amp; Hogg, M. A. (1988). Comments on the motivational status of self-esteem in social identity and intergroup discrimination. European Journal of Social Psychology, 18, 317\u2013334. Google Scholar. Abrams, D., &amp; Hogg, M. A. (2004). Metatheory: Lessons from social identity research. Personality and Social Psychol", "dateLastCrawled": "2021-12-12T07:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "AP Psych Term 4 Exam Flashcards | Quizlet", "url": "https://quizlet.com/409077049/ap-psych-term-4-exam-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/409077049/ap-psych-term-4-exam-flash-cards", "snippet": "a type of <b>learning</b> in which a behavior becomes more likely to recur if followed by a reinforcer or less likely to recur if followed by a punishment. token economy . an operant conditioning procedure in which people earn a token for exhibiting a desired behavior and <b>can</b> later exchange tokens for privileges or treats. behavioral therapies focus. changing unwanted behaviors (varied) or responses to situations (phobias, etc) Rational emotive therapy. a confrontational cognitive therapy ...", "dateLastCrawled": "2022-01-07T06:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "See also <b>out-group</b> <b>homogeneity</b> <b>bias</b> and in-group <b>bias</b>. H. hashing. In <b>machine learning</b>, a mechanism for bucketing categorical data, particularly when the number of categories is large, but the number of categories actually appearing in the dataset is comparatively small. For example, Earth is home to about 60,000 tree species. You could ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding and Mitigating <b>Bias</b> - GitHub Pages", "url": "https://axa-rev-research.github.io/static/AXA_Booklet_Bias.pdf", "isFamilyFriendly": true, "displayUrl": "https://axa-rev-research.github.io/static/AXA_Booklet_<b>Bias</b>.pdf", "snippet": "<b>Machine</b> <b>learning</b> (ML) algorithms identify pattern in data. Its major strength is the desired capability to find and discriminate classes in training data, and to use those insights to make predic - tions for new, unseen data. In the era of \u201cbig data\u201d, a lot of data is available with all sorts of variables. The general assumption is that the more data is used, the more precise becomes the <b>algo-rithm</b> and its predictions. When using a large amount of data, it clearly contains many ...", "dateLastCrawled": "2021-09-17T04:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Biases in <b>machine</b> <b>learning</b> models and big data analytics: The ...", "url": "http://international-review.icrc.org/articles/biases-machine-learning-big-data-analytics-ihl-implications-913", "isFamilyFriendly": true, "displayUrl": "international-review.icrc.org/articles/<b>bias</b>es-<b>machine</b>-<b>learning</b>-big-data-analytics-ihl...", "snippet": "A common implicit <b>bias</b> is confirmation <b>bias</b>, where individuals or model builders unconsciously process data in ways that affirm pre-existing beliefs and hypotheses.25 Within the context of international investigations, confirmation <b>bias</b> <b>can</b> cause investigators or prosecutors to miss the exculpatory quality of evidence or to discount its value, which <b>can</b> lead to a failure to disclose or collect that data.26 Similarly, in the pressurized theatre of war, confirmation <b>bias</b> <b>can</b> cause combatants ...", "dateLastCrawled": "2022-02-01T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Predictive usefulness of RT-PCR testing in different patterns of Covid ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8551264/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8551264", "snippet": "We use a <b>machine</b>-<b>learning</b> <b>algorithm</b> (decision tree) in order to predict RT-PCR results based on the clinical presentation. We show that symptoms alone are sufficient to predict RT-PCR outcome with a mean average precision of 86%. We identify combinations of symptoms that are predictive of RT-PCR positivity (90% for anosmia/ageusia) or negativity (only 30% of RT-PCR+ for a subgroup with cardiopulmonary symptoms): in both cases, RT-PCR provides little added diagnostic value. We propose a ...", "dateLastCrawled": "2021-12-06T14:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "GitHub - ikasu93/Data-Science-<b>Bias</b>-Guideline: A simple <b>bias</b> guideline ...", "url": "https://github.com/ikasu93/Data-Science-Bias-Guideline", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ikasu93/Data-Science-<b>Bias</b>-Guideline", "snippet": "Nr. Sources of Algorithmic <b>Bias</b>[48]:; 1: Biased Training data <b>can</b> be the source of algorithmic <b>bias</b>.: 2: Algorithms <b>can</b> be biased via differential use of information (using morally irrelevant categories to make morally relevant and sensitive judgements).: 3: During the data processing, the <b>algorithm</b> <b>can</b> itself be biased, called <b>Algorithm</b> Processing <b>Bias</b>.The most obvious instance of algorithmic processing <b>bias</b> is the use of a statistically biased estimator in the <b>algorithm</b> for better future ...", "dateLastCrawled": "2021-11-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Google <b>Cloud Professional Machine Learning Engineer Certification</b>: Post ...", "url": "https://www.linkedin.com/pulse/google-cloud-professional-machine-learning-engineer-post-timoteo", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/google-<b>cloud-professional-machine-learning-engineer</b>...", "snippet": "Don\u2019t be afraid to launch a product without <b>machine</b> <b>learning</b>; <b>Machine</b> <b>learning</b> is cool, but it requires data. Theoretically, you <b>can</b> take data from a different problem and then tweak the model ...", "dateLastCrawled": "2022-01-28T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Biases in Data Science Lifecycle</b>", "url": "https://www.researchgate.net/publication/344334843_Biases_in_Data_Science_Lifecycle", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344334843_<b>Biases_in_Data_Science_Lifecycle</b>", "snippet": "(3) During the data processing, the <b>algorithm</b> <b>can</b> itself be biased, called <b>Algorithm</b> Processing <b>Bias</b>. The most obvious in stance of algorithmic processing <b>bia s</b> is the use of a statistically", "dateLastCrawled": "2021-09-17T19:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Neutral bots probe political <b>bias</b> on social media | Nature Communications", "url": "https://www.nature.com/articles/s41467-021-25738-6", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-021-25738-6", "snippet": "<b>Compared</b> with traditional media, online social media <b>can</b> connect more people in a cheaper and faster way than ever before. As a large portion of the population frequently use social media to ...", "dateLastCrawled": "2022-01-21T08:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 8, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Selection bias</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Selection_bias", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Selection_bias</b>", "snippet": "<b>Selection bias</b> is the <b>bias</b> introduced by the selection of individuals, groups, or data for analysis in such a way that proper randomization is not achieved, thereby failing to ensure that the sample obtained is representative of the population intended to be analyzed. It is sometimes referred to as the selection effect.The phrase &quot;<b>selection bias</b>&quot; most often refers to the distortion of a statistical analysis, resulting from the method of collecting samples.If the <b>selection bias</b> is not taken ...", "dateLastCrawled": "2022-02-03T00:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Two example of <b>bias</b> brainly | two examples of b", "url": "https://mespoliziotti.com/resources/knowledge/other/type-ii-error/p03hv2703cbo", "isFamilyFriendly": true, "displayUrl": "https://mespoliziotti.com/resources/knowledge/other/type-ii-error/p03hv2703cbo", "snippet": "A biased survey <b>can</b> lead to survey response <b>bias</b> and higher than normal drop-out rates. Now, let&#39;s view 10 examples of survey <b>bias</b>. #1: The Leading Question. One of the biggest mistakes survey creators make is creating a question that leads respondents to give the correct answer ; C. cultural <b>bias</b>. D. socioeconomic <b>bias</b>. b. Provide two examples of environmental deprivation. Describe how they <b>can</b> influence intelligence. Environmental deprivation (conditions of isolation, poor nutrition ...", "dateLastCrawled": "2022-01-28T15:05:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> Glossary | Google Developers", "url": "https://developers.google.com/machine-learning/glossary/?hl=ja", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/glossary/?hl=ja", "snippet": "<b>Out-group</b> <b>homogeneity</b> <b>bias</b> is a form of group attribution <b>bias</b>. See also in-group <b>bias</b>. outlier detection. The process of identifying outliers in a training set. Contrast with novelty detection. outliers. Values distant from most other values. In <b>machine</b> <b>learning</b>, any of the following are outliers: Weights with high absolute values.", "dateLastCrawled": "2022-02-01T12:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "THE STATE OF NETWORK ORGANIZATION", "url": "http://ccs.mit.edu/papers/CCSWP192/ccswp192.html", "isFamilyFriendly": true, "displayUrl": "ccs.mit.edu/papers/CCSWP192/ccswp192.html", "snippet": "Members can exhibit in-group <b>bias</b> reflecting both <b>homogeneity</b> preferences and conservation of effort, and differences in tie strength can alter the movement of information throughout the network. Ineffable constructs such as power, status, role, identity, and group affiliation are difficult to quantify in either economic or computational terminology. Sociological explanations differ from those in computer science and economics, and studies tend to remain close to empirical particulars, often ...", "dateLastCrawled": "2022-02-02T21:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Data Science Glossary", "url": "https://aboutds.com/en/content/data-science-glossary", "isFamilyFriendly": true, "displayUrl": "https://aboutds.com/en/content/data-science-glossary", "snippet": "If testers or raters consist of the <b>machine</b> <b>learning</b> developer&#39;s friends, family, or colleagues, then in-group <b>bias</b> may invalidate product testing or the data set. In-group <b>bias</b> is a form of group attribution <b>bias</b> .", "dateLastCrawled": "2021-12-01T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 3, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>List of cognitive biases</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/List_of_cognitive_biases", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>List_of_cognitive_biases</b>", "snippet": "<b>Outgroup</b> <b>homogeneity</b> <b>bias</b>, where individuals see members of other groups as being relatively less varied than members of their own group. Other. Name Description Assumed similarity <b>bias</b>: Where an individual assumes that others have more traits in common with them than those others actually do. Pygmalion effect: The phenomenon whereby others&#39; expectations of a target person affect the target person&#39;s performance. Reactance: The urge to do the opposite of what someone wants you to do out of a ...", "dateLastCrawled": "2022-01-30T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Resources for <b>the Teaching of Social Psychology</b> - Prejudice", "url": "http://jfmueller.faculty.noctrl.edu/crow/prejudice.htm", "isFamilyFriendly": true, "displayUrl": "jfmueller.faculty.noctrl.edu/crow/prejudice.htm", "snippet": "Each student in a group dynamics course observed two groups in conflict and identified examples of in-group <b>bias</b>, double-standard thinking, <b>out-group</b> <b>homogeneity</b> <b>bias</b>, law of small numbers, group attribution error, ultimate attribution error, and moral exclusion. Students individually wrote papers detailing their observations. The author then carefully structured students&#39; small and large group discussions so students could present and compare their findings orally. Pretest\u2013posttest ...", "dateLastCrawled": "2022-01-26T15:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Using Word Embeddings to Analyze how Universities Conceptualize ...", "url": "https://link.springer.com/article/10.1007/s12115-019-00362-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12115-019-00362-9", "snippet": "Recent advances in <b>machine</b> <b>learning</b> for natural language processing (NLP) have given credence to the distributional hypothesis. In particular, new techniques for creating word embeddings that leverage the context in which words appear in large corpuses of textual data have significantly contributed to improve the state-of-the-art in <b>machine</b> translation, sentiment analysis, part of speech tagging, document summarization, text classification and information retrieval. Word embeddings is the ...", "dateLastCrawled": "2021-12-28T15:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bias</b> and clinical judgment <b>in counselling and psychotherapy: extending</b> ...", "url": "https://open.library.ubc.ca/handle/2429/1746", "isFamilyFriendly": true, "displayUrl": "https://open.library.ubc.ca/handle/2429/1746", "snippet": "In an investigation of how counsellors make decisions about how to intervene on behalf of their clients twelve trainees (six family counsellors and six person-centered counsellors) sorted a series of 32 possible counseling procedures from most to least desirable into a quasi-normal Q-distribution. Each subject completed the sort under four conditions, once for each hypothetical counselling client. The sex, age, gender, type of disorder, and severity of disorder were held constant across all ...", "dateLastCrawled": "2020-04-05T05:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>That illusion where you think the other</b> side is united and your side is ...", "url": "https://statmodeling.stat.columbia.edu/2019/05/09/that-illusion-where-you-think-the-other-side-is-united-and-your-side-is-diverse/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2019/05/09/<b>that-illusion-where-you-think-the</b>...", "snippet": "Take the <b>analogy</b> of walking on a sidewalk. You pay a lot of attention to all the bumps and cracks where you are walking because you have to or else risk tripping. The sidewalk a block away warrants only cursory thought, say to recognize that there is a sidewalk up there you could walk on if you go that way. You worry about the cracks and bumps when you get there. This ties to Lee Jussim\u2019s work on stereotypes. Stereotypes are simple heuristics for things you don\u2019t deal with a lot. Lee\u2019s ...", "dateLastCrawled": "2022-01-14T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Category: Research And Statistics</b> - BOOKS FOR PSYCHOLOGY CLASS", "url": "https://booksforpsychologyclass.weebly.com/blog/category/research-and-statistics", "isFamilyFriendly": true, "displayUrl": "https://booksforpsychologyclass.weebly.com/blog/<b>category/research-and-statistics</b>", "snippet": "Finally, the last portion of the book is devoted to the most famous work Sherif conducted, which examined in-group and <b>out-group</b> <b>bias</b> between the Rattlers and Eagles at Robbers Cave State Park in Oklahoma. The 22 boys in this study were 10 and 11 years-old, from lower-middle class and working-class families in the area. The two groups of boys were located about a mile away from one another, andSherif`s team was careful to facilitate the creation of strong group alliances from the start by ...", "dateLastCrawled": "2022-01-22T08:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Assessment of Student <b>Learning</b> | PDF | Educational Assessment ...", "url": "https://www.scribd.com/presentation/214803403/Assessment-of-Student-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/presentation/214803403/Assessment-of-Student-<b>Learning</b>", "snippet": "From the try-<b>out group</b>, each item will be analyzed in terms of its ability to discriminate between those who know and those who do not know and also its level of difficulty (item analysis phase). The item analysis will provide information that will allow the teacher to decide whether to revise or replace an item (item revision phase). Then, the final draft of the test is subjected to validation if the intent is to make use of the test as a standard test for the particular unit or period.", "dateLastCrawled": "2021-12-10T10:34:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(out-group homogeneity bias)  is like +(machine learning algorithm)", "+(out-group homogeneity bias) is similar to +(machine learning algorithm)", "+(out-group homogeneity bias) can be thought of as +(machine learning algorithm)", "+(out-group homogeneity bias) can be compared to +(machine learning algorithm)", "machine learning +(out-group homogeneity bias AND analogy)", "machine learning +(\"out-group homogeneity bias is like\")", "machine learning +(\"out-group homogeneity bias is similar\")", "machine learning +(\"just as out-group homogeneity bias\")", "machine learning +(\"out-group homogeneity bias can be thought of as\")", "machine learning +(\"out-group homogeneity bias can be compared to\")"]}