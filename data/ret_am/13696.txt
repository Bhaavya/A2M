{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning: An Overview", "url": "https://hacker-news.news/post/25250455", "isFamilyFriendly": true, "displayUrl": "https://hacker-news.news/post/25250455", "snippet": "<b>Why</b> Care About <b>Interpretability</b>? First, <b>interpretability</b> in machine learning is useful because it can aid in trust. As humans, we may be reluctant to rely on machine learning models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in <b>something</b> opaque, which we ...", "dateLastCrawled": "2022-01-25T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Model <b>Interpretability</b> : <b>ELI5</b> &amp; Permutation Importance | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/why-should-i-trust-your-model-bdda6be94c6f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>why</b>-should-i-trust-your-model-bdda6be94c6f", "snippet": "For this prediction, it looks <b>like</b> the most important factor was that the prospect was contacted via phone (contact__cellular==1) and <b>did</b> not have a default (default__no==1). This information can ...", "dateLastCrawled": "2022-02-02T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Teaching Machines to Read <b>Movie Reviews: Thinking About Interpretability</b>", "url": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about-interpretability-63c12248b8e5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about...", "snippet": "It\u2019s <b>something</b> <b>like</b> using the grains of sand (words) in the mortar or type of bricks (stance) to identify a building architecturally. Of course, it\u2019s not that humans don\u2019t use words or stance to read. Rather, we make use of them without seeing larger patterns explicitly, the way we recognize a pattern <b>like</b> Art Deco without being able to easily rattle off the micro features that build up to the pattern.", "dateLastCrawled": "2022-01-19T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Against <b>Interpretability</b>: a Critical Examination of the ...", "url": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "snippet": "Although these problems have not received explicit mention in the <b>interpretability</b> literature, they might nonetheless reasonably motivate a call for <b>something</b> <b>like</b> <b>interpretability</b>, insofar as supplying one\u2019s reasoning is frequently central to the reconciliation procedures that people use when dealing with one another. Likewise, when considering (e.g.) how to synthesize the results of a medical study with clinical experience, the data and methodologies of each distinct source are in ...", "dateLastCrawled": "2021-12-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretability</b>, validity, and the minimum important difference ...", "url": "https://link.springer.com/article/10.1007/s11017-011-9186-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11017-011-9186-9", "snippet": "For instance, <b>someone</b> with rheumatoid arthritis might see this disease as a \u201cbetrayal\u201d of dignity, as <b>something</b> that necessitates a life without dignity. Alternatively, an individual might reinterpret her <b>understanding</b> of ideals such as dignity in light of the new limitations that come with this disease. These interpretations indicate a transformation in the person about what matters, what is significant, what provides meaning in one\u2019s life.", "dateLastCrawled": "2022-01-19T05:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Confusion Matrices</b> &amp; <b>Interpretable ML</b> | by andrea b | high stakes ...", "url": "https://medium.com/high-stakes-design/interpretability-techniques-explained-in-simple-terms-f5e1573674f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/high-stakes-design/<b>interpretability</b>-techniques-explained-in-simple...", "snippet": "NINA: With explainability, you have a black box and you try to explain what it <b>did</b>; with <b>interpretability</b> you are actually doing <b>something</b> within the black box that lets you understand how it ...", "dateLastCrawled": "2021-03-22T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretability</b> 2020", "url": "https://ff06-2020.fastforwardlabs.com/", "isFamilyFriendly": true, "displayUrl": "https://ff06-2020.fastforwardlabs.com", "snippet": "The question of <b>interpretability</b> has been important in applied machine learning for many years, but as black-box techniques <b>like</b> deep learning grow in popularity, it\u2019s becoming an urgent concern. These techniques offer breakthrough capabilities in analyzing and even generating rich media and text data. These systems are so effective in part because they abstract out the need for manual feature engineering. This allows for automated systems that are able to do completely new things, but are ...", "dateLastCrawled": "2022-01-16T21:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Interpretability</b> in Machine Learning: An Overview | Hacker News", "url": "https://news.ycombinator.com/item?id=25250455", "isFamilyFriendly": true, "displayUrl": "https://news.ycombinator.com/item?id=25250455", "snippet": "This is a good exposition of some formal definitions for &#39;<b>interpretability</b>&#39; in the context of machine learning, but I am still not really clear on <b>why</b> such a property is necessary or even desirable in the context of high dimensional statistical learning algorithms. In some sense the power of modern machine learning (as opposed to a set of heuristics + feature engineering + a linear classifier) is that it is not limited by what its designers are able to imagine or understand. If it were ...", "dateLastCrawled": "2021-04-10T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Picking an explainability technique | by Divya Gopinath | Towards Data ...", "url": "https://towardsdatascience.com/picking-an-explainability-technique-48e807d687b9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/picking-an-explainability-technique-48e807d687b9", "snippet": "It is impossible to trust a machine learning model without <b>understanding</b> how and <b>why</b> it makes its decisions, and whether these decisions are justified. Peering into ML models is absolutely necessary before deploying them in the wild, where a poorly understood model can not only fail to achieve its objective, but also cause negative business or social impacts, or encounter regulatory trouble. Explainability is also an important backbone to other trustworthy ML pillars <b>like</b>", "dateLastCrawled": "2022-02-02T22:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Building Trust in AI-<b>Based Decision Making by Understanding</b> the ...", "url": "https://www.capgemini.com/research/building-trust-in-ai-based-decision-making-by-understanding-the-strengths-and-limitations-of-machines-daniela-rus/", "isFamilyFriendly": true, "displayUrl": "https://www.capgemini.com/research/building-trust-in-ai-based-decision-making-by...", "snippet": "So, if <b>someone</b> didn\u2019t get a loan, <b>why</b> not? This kind of <b>interpretability</b> is critical. People need to be aware of how these systems work. Additionally, it is critical that the data used to train the system is correct and has checks for biases, because the performance of machine learning and decision systems is only as good as the data used to train them. Altogether, <b>interpretability</b>, explainability, fairness, and data provenance are the critical attributes that ensure trust in the decision ...", "dateLastCrawled": "2021-12-23T10:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning: An Overview", "url": "https://hacker-news.news/post/25250455", "isFamilyFriendly": true, "displayUrl": "https://hacker-news.news/post/25250455", "snippet": "<b>Why</b> Care About <b>Interpretability</b>? First, <b>interpretability</b> in machine learning is useful because it can aid in trust. As humans, we may be reluctant to rely on machine learning models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in <b>something</b> opaque, which we ...", "dateLastCrawled": "2022-01-25T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Confusion Matrices</b> &amp; <b>Interpretable ML</b> | by andrea b | high stakes ...", "url": "https://medium.com/high-stakes-design/interpretability-techniques-explained-in-simple-terms-f5e1573674f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/high-stakes-design/<b>interpretability</b>-techniques-explained-in-simple...", "snippet": "A sizable body of research is aimed at <b>understanding</b> the black box of the brain, so it was intuitive to apply a <b>similar</b> approach to an RNN. As much as we think of the brain as a black box \u2014in ...", "dateLastCrawled": "2021-03-22T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability</b>, validity, and the minimum important difference ...", "url": "https://link.springer.com/article/10.1007/s11017-011-9186-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11017-011-9186-9", "snippet": "For instance, <b>someone</b> with rheumatoid arthritis might see this disease as a \u201cbetrayal\u201d of dignity, as <b>something</b> that necessitates a life without dignity. Alternatively, an individual might reinterpret her <b>understanding</b> of ideals such as dignity in light of the new limitations that come with this disease. These interpretations indicate a transformation in the person about what matters, what is significant, what provides meaning in one\u2019s life.", "dateLastCrawled": "2022-01-19T05:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Towards defining data <b>interpretability</b> in open data portals: Challenges ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306437921001538", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306437921001538", "snippet": "<b>Interpretability</b> means that data quality metrics must be understandable, so their measurement must be easy for users to interpret. Melo 2017: <b>Interpretability</b> means <b>understanding</b> and applying the meaning of <b>something</b>. Alves 2017: <b>Interpretability</b> assesses how to clear information is enough to be used properly. Sousa et al. 2017", "dateLastCrawled": "2021-12-04T00:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Model <b>Interpretability</b> : <b>ELI5</b> &amp; Permutation Importance | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/why-should-i-trust-your-model-bdda6be94c6f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>why</b>-should-i-trust-your-model-bdda6be94c6f", "snippet": "ML Model <b>Interpretability</b> : <b>ELI5</b> &amp; Permutation Importance . Introduction. Despite widespread adoption, machine learning models remain mostly black boxes. <b>Understanding</b> <b>why</b> certains predictions are ...", "dateLastCrawled": "2022-02-02T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Against <b>Interpretability</b>: a Critical Examination of the ...", "url": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "snippet": "Participants in the <b>interpretability</b> literature make more fine-grained distinctions within these terms, for instance between a \u201cglobal\u201d explanation which provides some account of the overall pattern of functioning of the algorithm, and a \u201clocal\u201d interpretation which provides some account of <b>why</b> the algorithm provided the output it <b>did</b> for a particular input (Doshi-Velez and Kim 2017). Since I raise concerns regarding whether the notion of <b>interpretability</b> has (or can have) any ...", "dateLastCrawled": "2021-12-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretability in neural networks towards universal consistency</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S266630742100005X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S266630742100005X", "snippet": "The <b>interpretability</b> of neural networks is a subject linked to deep structure, ... On the other hand, if <b>someone</b> wants the computer to be intuitive like human cognition, it is necessary that the information provided to computational models is based on the natural logic of the brain in search of the principles by which it is guided, that is, to have contextual reality as an interpretive basis. For S\u00e1nchez 1991, p. 15) semantics [related to context] ends where the system of logical evidence ...", "dateLastCrawled": "2021-12-09T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Interpretability</b> 2020", "url": "https://ff06-2020.fastforwardlabs.com/", "isFamilyFriendly": true, "displayUrl": "https://ff06-2020.fastforwardlabs.com", "snippet": "The first is the adversarial application of model-agnostic <b>interpretability</b> \u2013 that is, use of LIME by <b>someone</b> other than the owner of the model. Regulators will use these techniques to demonstrate discrimination in a model. Explanations derived from LIME-like techniques will be used by courts to assign blame when a model fails.", "dateLastCrawled": "2022-01-16T21:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Interpretability</b> in Machine Learning: An Overview | Hacker News", "url": "https://news.ycombinator.com/item?id=25250455", "isFamilyFriendly": true, "displayUrl": "https://news.ycombinator.com/item?id=25250455", "snippet": "This is a good exposition of some formal definitions for &#39;<b>interpretability</b>&#39; in the context of machine learning, but I am still not really clear on <b>why</b> such a property is necessary or even desirable in the context of high dimensional statistical learning algorithms. In some sense the power of modern machine learning (as opposed to a set of heuristics + feature engineering + a linear classifier) is that it is not limited by what its designers are able to imagine or understand. If it were ...", "dateLastCrawled": "2021-04-10T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "interpretation - <b>Most interpretable classification models</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/235007/most-interpretable-classification-models", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/235007", "snippet": "So at one level of <b>interpretability</b> or explainability (#1 with a little #4, above), K-Nearest Neighbor is easy: &quot;this customer was judged to be high risk because 8 out of 10 customers who have been previously evaluated and were most <b>similar</b> to them in terms of X, Y, and Z, were found to be high risk.&quot; At actionable, full level #4, it&#39;s not so interpretable. (I&#39;ve thought of actually presenting the other 8 customers to them, but that would require them to drill down into those customers to ...", "dateLastCrawled": "2022-01-28T11:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Achieving Trusted AI With Model <b>Interpretability</b> - Dataiku Community", "url": "https://community.dataiku.com/t5/General-Discussion/Achieving-Trusted-AI-With-Model-Interpretability/m-p/21793", "isFamilyFriendly": true, "displayUrl": "https://community.dataiku.com/t5/General-Discussion/Achieving-Trusted-AI-With-Model...", "snippet": "We should always be vigilant when examining model <b>interpretability</b>, whether we <b>can</b> clearly see when the model is biased or unfair toward a group of people, defined by any attribute, race, income, age or gender for example. While this is an analytic technique, the ultimate judgement of bias and fairness (i.e., where the inter-group differences are unacceptable) is a human judgement.", "dateLastCrawled": "2022-01-14T06:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability</b>, validity, and the minimum important difference ...", "url": "https://link.springer.com/article/10.1007/s11017-011-9186-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11017-011-9186-9", "snippet": "For instance, <b>someone</b> with rheumatoid arthritis might see this disease as a \u201cbetrayal\u201d of dignity, as <b>something</b> that necessitates a life without dignity. Alternatively, an individual might reinterpret her <b>understanding</b> of ideals such as dignity in light of the new limitations that come with this disease. These interpretations indicate a transformation in the person about what matters, what is significant, what provides meaning in one\u2019s life.", "dateLastCrawled": "2022-01-19T05:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Achieving Trusted AI With Model <b>Interpretability</b>", "url": "https://blog.dataiku.com/model-interpretability", "isFamilyFriendly": true, "displayUrl": "https://blog.dataiku.com/model-<b>interpretability</b>", "snippet": "We should always be vigilant when examining model <b>interpretability</b>, whether we <b>can</b> clearly see when the model is biased or unfair toward a group of people, defined by any attribute, race, income, age or gender for example. While this is an analytic technique, the ultimate judgement of bias and fairness (i.e., where the inter-group differences are unacceptable) is a human judgement.", "dateLastCrawled": "2022-01-31T14:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Against <b>Interpretability</b>: a Critical Examination of the ...", "url": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "snippet": "Interpret means to explain or present in understandable terms.In the context of ML systems, we define <b>interpretability</b> as the ability to explain or to present in understandable terms to a human (Doshi-Velez and Kim 2017).. In the strictest sense, we might call a model transparent if a person <b>can</b> contemplate the entire model at once (Lipton 2018, emphasis mine).. A second notion of transparency might be that each part of the model \u2014 each input, parameter, and calculation \u2014 admits an ...", "dateLastCrawled": "2021-12-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Confusion Matrices</b> &amp; <b>Interpretable ML</b> | by andrea b | high stakes ...", "url": "https://medium.com/high-stakes-design/interpretability-techniques-explained-in-simple-terms-f5e1573674f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/high-stakes-design/<b>interpretability</b>-techniques-explained-in-simple...", "snippet": "A sizable body of research is aimed at <b>understanding</b> the black box of the brain, so it was intuitive to apply a similar approach to an RNN. As much as we think of the brain as a black box \u2014in ...", "dateLastCrawled": "2021-03-22T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretability in neural networks towards universal consistency</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S266630742100005X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S266630742100005X", "snippet": "In Section 7, we explain how <b>interpretability</b> <b>can</b> be managed in artificial neural networks using human language as a model. We show paths for universal consistency in the interpretation of analyzed data, since training alone is not enough, as the brushing technique shows that the data <b>can</b> be manipulated. Section 8 is dedicated to the conclusion that the &#39;key&#39; to a good information classifier for neural networks lies in the dynamic aspect of human linguistic process. This needs to be ...", "dateLastCrawled": "2021-12-09T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretability</b> 2020", "url": "https://ff06-2020.fastforwardlabs.com/", "isFamilyFriendly": true, "displayUrl": "https://ff06-2020.fastforwardlabs.com", "snippet": "FIGURE 2.6 Local <b>interpretability</b> means you <b>can</b> explain a model\u2019s predictions and even suggest actions. A model of customer churn tells you how likely a customer is to leave. A locally interpretable model \u2013 that is, one in which you <b>can</b> explain a particular prediction \u2013 offers an answer to the question of <b>why</b> this customer is going to ...", "dateLastCrawled": "2022-01-16T21:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>The Indefinite Interpretability of the Bible</b> \u2013 Vridar", "url": "https://vridar.org/2020/09/14/the-indefinite-interpretability-of-the-bible/", "isFamilyFriendly": true, "displayUrl": "https://vridar.org/2020/09/14/<b>the-indefinite-interpretability-of-the-bible</b>", "snippet": "Indefinite <b>interpretability</b>. In group Bible studies each person may offer what impresses him or her about a particular passage, \u201cwhat it meant for their lives.\u201d Their interpretations were usually expressed with some degree of tentativeness, and were framed as observations on the passage rather than as expressions of \u201cthe meaning.\u201dThey <b>did</b> say that the text had a meaning\u2014and a real, definite one\u2014but none of them pretended to know it exhaustively. Their claims, at most, were to ...", "dateLastCrawled": "2022-02-03T12:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Towards defining data <b>interpretability</b> in open data portals: Challenges ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306437921001538", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306437921001538", "snippet": "Citizens <b>can</b> use the open data portals to participate more effectively in democratic processes. \u2022 Data <b>interpretability</b>, in the context of open government data, is the capability of an accurate, complete, consistent, coherent, and organized dataset to convey significance to the user, stimulating the formation of his knowledge and his engagement, from a simple and clear language.", "dateLastCrawled": "2021-12-04T00:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "interpretation - <b>Most interpretable classification models</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/235007/most-interpretable-classification-models", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/235007", "snippet": "If you want actionable <b>interpretability</b>, I&#39;d suggest they might not make the cut. 2) Another issue is clarifying what you mean by &quot;<b>interpretability</b> of results&quot;. I&#39;ve run into <b>interpretability</b> in four contexts: The client being able to understand the methodology. (Not what you&#39;re asking about.) A Random Forest is pretty straightforwardly explainable by analogy, and most clients feel comfortable with it once it&#39;s explained simply. Explaining how the methodology fits a model. (I had a client ...", "dateLastCrawled": "2022-01-28T11:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning: An Overview", "url": "https://hacker-news.news/post/25250455", "isFamilyFriendly": true, "displayUrl": "https://hacker-news.news/post/25250455", "snippet": "<b>Why</b> Care About <b>Interpretability</b>? First, <b>interpretability</b> in machine learning is useful because it <b>can</b> aid in trust. As humans, we may be reluctant to rely on machine learning models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in <b>something</b> opaque, which we ...", "dateLastCrawled": "2022-01-25T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability</b>, validity, and the minimum important difference ...", "url": "https://link.springer.com/article/10.1007/s11017-011-9186-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11017-011-9186-9", "snippet": "For instance, <b>someone</b> with rheumatoid arthritis might see this disease as a \u201cbetrayal\u201d of dignity, as <b>something</b> that necessitates a life without dignity. Alternatively, an individual might reinterpret her <b>understanding</b> of ideals such as dignity in light of the new limitations that come with this disease. These interpretations indicate a transformation in the person about what matters, what is significant, what provides meaning in one\u2019s life.", "dateLastCrawled": "2022-01-19T05:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Interpretable Neural Networks With PyTorch | by Dr. Robert K\u00fcbler | Dec ...", "url": "https://towardsdatascience.com/interpretable-neural-networks-with-pytorch-76f1c31260fe", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/interpretable-neural-networks-with-pytorch-76f1c31260fe", "snippet": "There are several approaches to rate machine learning models, two of them being accuracy and <b>interpretability</b>.A model with high accuracy is what we usually call a good model, it learned the relationship between the inputs X and outputs y well.. If a model has high <b>interpretability</b> or explainability, we u nderstand how the model makes a prediction and how we <b>can</b> influence this prediction by changing input features. While it is hard to say how the output of a deep neural network behaves when ...", "dateLastCrawled": "2022-02-02T23:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Teaching Machines to Read <b>Movie Reviews: Thinking About Interpretability</b>", "url": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about-interpretability-63c12248b8e5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about...", "snippet": "Researchers at Stanford\u2019s Literary Lab have <b>compared</b> human and machine reading using the analogy of identifying writing genres as if they were buildings. Human beings <b>can</b> use themes (dark secrets, mounting dread) to identify a genre like gothic fiction, just as people <b>can</b> use architectural elements (plinths, smooth surfaces) to identify an architectural genre like neoclassical. Whereas computers <b>can</b> use word counts (lexical level features) and DocuScope\u2019s stance categories ...", "dateLastCrawled": "2022-01-19T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Confusion Matrices</b> &amp; <b>Interpretable ML</b> | by andrea b | high stakes ...", "url": "https://medium.com/high-stakes-design/interpretability-techniques-explained-in-simple-terms-f5e1573674f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/high-stakes-design/<b>interpretability</b>-techniques-explained-in-simple...", "snippet": "NINA: With explainability, you have a black box and you try to explain what it <b>did</b>; with <b>interpretability</b> you are actually doing <b>something</b> within the black box that lets you understand how it ...", "dateLastCrawled": "2021-03-22T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Model <b>Interpretability</b> : <b>ELI5</b> &amp; Permutation Importance | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/why-should-i-trust-your-model-bdda6be94c6f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>why</b>-should-i-trust-your-model-bdda6be94c6f", "snippet": "This information <b>can</b> be shared with domain experts to understand <b>why</b> those features were important. The contribution is weights * the column value. The contribution is weights * the column value. 2 .", "dateLastCrawled": "2022-02-02T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretability in neural networks towards universal consistency</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S266630742100005X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S266630742100005X", "snippet": "In Section 7, we explain how <b>interpretability</b> <b>can</b> be managed in artificial neural networks using human language as a model. We show paths for universal consistency in the interpretation of analyzed data, since training alone is not enough, as the brushing technique shows that the data <b>can</b> be manipulated. Section 8 is dedicated to the conclusion that the &#39;key&#39; to a good information classifier for neural networks lies in the dynamic aspect of human linguistic process. This needs to be ...", "dateLastCrawled": "2021-12-09T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is Explainable AI? Concepts &amp; Examples - Data Analytics", "url": "https://vitalflux.com/what-is-explainable-ai-concepts-examples/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/what-is-explainable-ai-concepts-examples", "snippet": "Explainable AI is part of the larger umbrella term for artificial intelligence known as \u201c<b>interpretability</b>.\u201d Explainable AI is a type of AI system that is modeled after how humans think and make decisions. Explainable AI Systems <b>can</b> be helpful when trying to understand the reasoning behind a particular prediction or decision made by machine learning models. Explainable AI Systems could also be helpful for situations involving accountability, such as with autonomous vehicles; if <b>something</b> ...", "dateLastCrawled": "2022-01-30T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Interpretability</b> in Machine Learning: An Overview | Hacker News", "url": "https://news.ycombinator.com/item?id=25250455", "isFamilyFriendly": true, "displayUrl": "https://news.ycombinator.com/item?id=25250455", "snippet": "This is a good exposition of some formal definitions for &#39;<b>interpretability</b>&#39; in the context of machine learning, but I am still not really clear on <b>why</b> such a property is necessary or even desirable in the context of high dimensional statistical learning algorithms. In some sense the power of modern machine learning (as opposed to a set of heuristics + feature engineering + a linear classifier) is that it is not limited by what its designers are able to imagine or understand. If it were ...", "dateLastCrawled": "2021-04-10T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Building Trust in AI-<b>Based Decision Making by Understanding</b> the ...", "url": "https://www.capgemini.com/research/building-trust-in-ai-based-decision-making-by-understanding-the-strengths-and-limitations-of-machines-daniela-rus/", "isFamilyFriendly": true, "displayUrl": "https://www.capgemini.com/research/building-trust-in-ai-based-decision-making-by...", "snippet": "For autonomous decision making, it is important that the machine\u2019s decision <b>can</b> be interpreted and explained, so that people get justifications for how the system decided the way it <b>did</b>. So, if <b>someone</b> didn\u2019t get a loan, <b>why</b> not? This kind of <b>interpretability</b> is critical. People need to be aware of how these systems work. Additionally, it is critical that the data used to train the system is correct and has checks for biases, because the performance of machine learning and decision ...", "dateLastCrawled": "2021-12-23T10:02:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "snippet": "This provides a novel <b>analogy</b> between data compression and regularization. Qualitative and quantitative state-of-the-art results on three datasets. 20 / 33. Interpretable Lens Variable Model (ILVM) 21 / 33. Interactive <b>Interpretability</b> via Active <b>Learning</b> Interactive \u2018human-in-the-loop\u2019 <b>interpretability</b> Choose the point with index j that maximizes : ^j = argmax jI(s ; ) = H(s ) E q \u02da(z js)[H(s jz j)] = Z p(s j)log p(s j)ds + E q \u02da(z js) Z p (s jjz)log p (s jjz)ds : (5) Choose the point ...", "dateLastCrawled": "2022-01-19T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Figure 1: <b>Interpretability</b> for <b>machine</b> <b>learning</b> models bridges the concrete objectives models optimize for and the real-world (and less easy to define) desiderata that ML applications aim to achieve. Introduction . The objectives <b>machine</b> <b>learning</b> models optimize for do not always reflect the actual desiderata of the task at hand. <b>Interpretability</b> in models allows us to evaluate their decisions and obtain information that the objective alone cannot confer. <b>Interpretability</b> takes many forms ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "There is increasing emphasis on interpretable <b>machine</b> <b>learning</b> in the world of data. Models have been growing ever more complex with the use of neural networks becoming more mainstream, along with the sheer size of data being analysed today. In many cases, such complex models may not be fit for human interpretation in their own right. Therefore, there has been a push to make the model interpretable, whereby both the results and the process in achieving those results are understood by humans ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-16T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://arxiv.org/abs/2005.12800", "isFamilyFriendly": true, "displayUrl": "https://<b>arxiv</b>.org/abs/2005.12800", "snippet": "Principles of analogical reasoning have recently been applied in the context of <b>machine</b> <b>learning</b>, for example to develop new methods for classification and preference <b>learning</b>. In this paper, we argue that, while analogical reasoning is certainly useful for constructing new <b>learning</b> algorithms with high predictive accuracy, is is arguably not less interesting from an <b>interpretability</b> and explainability point of view. More specifically, we take the view that an <b>analogy</b>-based approach is a ...", "dateLastCrawled": "2021-10-24T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Economic Methodology Meets Interpretable <b>Machine</b> <b>Learning</b> ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. But first ...", "dateLastCrawled": "2022-01-05T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Economic Methodology Meets Interpretable Machine Learning</b> - Part I ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. Intro - Part ...", "dateLastCrawled": "2022-01-22T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "Neuroscience \u2194 <b>Interpretability</b>. <b>Analogy</b>: model=brain. Artificial neural networks are historically inspired by neuroscience, but I used to be pretty skeptical that the connection was anything more than superficial. I&#39;ve since come around: I now think this is a very deep connection. The thing that personally persuaded me was that, in my own investigations of what goes on inside neural networks, we kept finding things that were previously discovered by neuroscientists. The most recent ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>SHAP</b>: A reliable way to analyze model <b>interpretability</b> | by Sharayu ...", "url": "https://towardsdatascience.com/shap-a-reliable-way-to-analyze-your-model-interpretability-874294d30af6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>shap</b>-a-reliable-way-to-analyze-your-model...", "snippet": "The balance: Accuracy vs. <b>Interpretability</b>. 2. How to interpret <b>machine</b> <b>learning</b> models? 3. LIME: Explaining predictions of <b>machine</b> <b>learning</b> models. In this blog, I wil l be talking about one of the most popular model agnostic technique that is used to explain predictions. <b>SHAP</b> stands for SHapley Additive exPlanations. Shapely values are obtained by incorporating concepts from Cooperative Game Theory and local explanations. Given a set of palyers, Cooperative Game Theory defines how well and ...", "dateLastCrawled": "2022-01-31T17:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chris Olah on what the hell is going on inside neural networks - 80,000 ...", "url": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/", "isFamilyFriendly": true, "displayUrl": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research", "snippet": "Chris is a <b>machine</b> <b>learning</b> researcher currently focused on neural network interpretability. Until last December he led OpenAI\u2019s interpretability team but along with some colleagues he recently moved on to help start a new AI lab focussed on large models and safety called Anthropic. Rob Wiblin: Before OpenAI he spent 4 years at Google Brain developing tools to visualize what\u2019s going on in neural networks. Chris was hugely impactful at Google Brain. He was second author on the launch of ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Marketing AI: Interpretability and Explainability</b> - Christopher S. Penn ...", "url": "https://www.christopherspenn.com/2021/03/marketing-ai-interpretability-and-explainability/", "isFamilyFriendly": true, "displayUrl": "https://www.christopherspenn.com/2021/03/<b>marketing-ai-interpretability-and-explainability</b>", "snippet": "<b>Interpretability is like</b> inspecting the baker\u2019s recipe for the cake. We look at the list of ingredients and the steps taken to bake the cake, and we verify that the recipe makes sense and the ingredients were good. This is a much more rigorous way of validating our results, but it\u2019s the most complete \u2013 and if we\u2019re in a high-stakes situation where we need to remove all doubt, this is the approach we take. Interpretability in AI is like that \u2013 we step through the code itself that ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Causal <b>Learning</b> From Predictive Modeling for Observational Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931928/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7931928", "snippet": "Given the recent success of <b>machine</b> <b>learning</b>, specifically deep <b>learning</b>, in several applications (Goodfellow et al., ... This statistical <b>interpretability is similar</b> in spirit to traditional interpretability. This allows to answer questions, such as \u201cdoes BMI influence susceptibility to Covid?\u201d Moreover, it has been argued that developing an effective CBN for practical applications requires expert knowledge when data collection is cumbersome (Fenton and Neil, 2012). This applies to ...", "dateLastCrawled": "2021-12-09T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimal <b>Predictive Clustering</b> - Dimitris Bertsimas", "url": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-predictive-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-<b>predictive-clustering</b>.pdf", "snippet": "Table 1 Comparison of major <b>machine</b> <b>learning</b> methods relative to each other across the metrics of performance (out-of-sample R2), scalability and interpretability. 1 is the best, while 5 is the worst. Optimal <b>Predictive Clustering</b> 3 From Table 1, we observe all existing methods have weakness in at least one category. We therefore seek to design a method that has strong performance in all three categories at the same time. Optimal <b>Predictive Clustering</b> (OPC) is an algorithm that uses mixed ...", "dateLastCrawled": "2021-11-24T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reviewing Challenges of Predicting Protein Melting Temperature Change ...", "url": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "snippet": "Predicting the effects of mutations on protein stability is a key problem in fundamental and applied biology, still unsolved even for the relatively simple case of small, soluble, globular, monomeric, two-state-folder proteins. Many articles discuss the limitations of prediction methods and of the datasets used to train them, which result in low reliability for actual applications despite globally capturing trends. Here, we review these and other issues by analyzing one of the most detailed ...", "dateLastCrawled": "2022-02-03T02:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "In my view, a shor t coming of interpretable <b>machine</b> <b>learning</b> is that it assumes to a degree that the data being fed into the model is always going to be suitable for human interpretation. This is not necessarily the case. For instance, let\u2019s say that a company is trying to implement interpretable <b>machine</b> <b>learning</b> to devise a credit scoring model, whereby prospective credit card applications are classified as approved or rejected based on numerous features. It is often the case that such ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Breaking the interpretability barrier - a</b> method for interpreting deep ...", "url": "http://www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "isFamilyFriendly": true, "displayUrl": "www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o between performance and inter-pretability. Graph classi cation is normally a domain which requires the ap-plication of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to in-terpret complex models post-hoc (brie y reviewed in section2). However, most ...", "dateLastCrawled": "2021-09-22T17:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Discovering Discriminative Nodes for Classi\ufb01cation with Deep Graph ...", "url": "http://muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "isFamilyFriendly": true, "displayUrl": "muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o\ufb00 between performance and inter-pretability. Graph classi\ufb01cation is normally a domain which requires the appli-cation of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to interpret complex models post-hoc (brie\ufb02y reviewed in Sect.2). However ...", "dateLastCrawled": "2021-09-02T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Confronting Abusive Language Online: A Survey from the Ethical and ...", "url": "https://www.arxiv-vanity.com/papers/2012.12305/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2012.12305", "snippet": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this ...", "dateLastCrawled": "2021-10-13T19:21:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(interpretability)  is like +(understanding why someone did something)", "+(interpretability) is similar to +(understanding why someone did something)", "+(interpretability) can be thought of as +(understanding why someone did something)", "+(interpretability) can be compared to +(understanding why someone did something)", "machine learning +(interpretability AND analogy)", "machine learning +(\"interpretability is like\")", "machine learning +(\"interpretability is similar\")", "machine learning +(\"just as interpretability\")", "machine learning +(\"interpretability can be thought of as\")", "machine learning +(\"interpretability can be compared to\")"]}