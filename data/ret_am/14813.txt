{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Attention</b> in Psychology, Neuroscience, and Machine Learning", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7177153/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7177153", "snippet": "These weightings scale the word encodings themselves to create the next <b>layer</b> in the model, a process known as \u201c<b>self-attention</b>.\u201d This process repeats, and eventually interacts with the autoregressive decoder which <b>also</b> has <b>attention</b> mechanisms that allow it to flexibly focus on the encoded input (as in the standard form of <b>attention</b>) and on the previously generated output. The Transformer\u2014the name given to this new <b>attention</b> architecture\u2014outperformed many previous models and quickly ...", "dateLastCrawled": "2021-12-27T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Frontiers | <b>Attention in Psychology, Neuroscience, and Machine Learning</b> ...", "url": "https://www.frontiersin.org/articles/10.3389/fncom.2020.00029/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fncom.2020.00029", "snippet": "These weightings scale the word encodings themselves to create the next <b>layer</b> in the model, a process known as \u201c<b>self-attention</b>.\u201d This process repeats, and eventually interacts with the autoregressive decoder which <b>also</b> has <b>attention</b> mechanisms that allow it to flexibly focus on the encoded input (as in the standard form of <b>attention</b>) and on the previously generated output. The Transformer\u2014the name given to this new <b>attention</b> architecture\u2014outperformed many previous models and quickly ...", "dateLastCrawled": "2022-02-03T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Details for Neural Network <b>Self Attention</b> and Related Queries", "url": "https://www.affiliatejoin.com/neural-network-self-attention", "isFamilyFriendly": true, "displayUrl": "https://www.affiliatejoin.com/neural-network-<b>self-attention</b>", "snippet": "<b>Self-Attention</b> <b>Self-attention</b>, <b>also</b> known as intra-<b>attention</b>, is an <b>attention</b> mechanism relating different positions of a single sequence in order to compute a representation of the same sequence. It has been shown to be very useful in machine reading, abstractive summarization, or image description generation.", "dateLastCrawled": "2022-02-02T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Intuitive Understanding of <b>Attention</b> Mechanism in Deep Learning | by ...", "url": "https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/intuitive-understanding-of-<b>attention</b>-mechanism-in-deep...", "snippet": "In <b>our</b> case we would expect values <b>like</b> below: (just for intuition) e1 = 0.75, e2 = 0.2, e3 = 0.02, e4 = 0.02, e5 = 0.01 This means that while predicting the word \u201c\u0930\u093e\u0939\u0941\u0932\u201d, the decoder needs to put more <b>attention</b> on the states h1 and h2 (since values of e1 and e2 are high) while ignoring the states h3, h4 and h5 (since the values of e3, e4 and e5 are very small).", "dateLastCrawled": "2022-02-02T18:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Deep Learning for AI | July 2021 | Communications of the ACM", "url": "https://people.idsia.ch/~juergen/DLforAIjuly2021.html", "isFamilyFriendly": true, "displayUrl": "https://people.idsia.ch/~juergen/DLforAIjuly2021.html", "snippet": "The transformer architecture, 85 which has become the dominant architecture in many applications, stacks many layers of &quot;<b>self-attention</b>&quot; modules. Each module in a <b>layer</b> uses a scalar product to compute the match between its query vector and the key vectors of other modules in that <b>layer</b>. The matches are normalized to sum to 1, and the resulting scalar coefficients are then used to form a convex combination of the value vectors produced by the other modules in the previous <b>layer</b>. The ...", "dateLastCrawled": "2021-12-25T14:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>ATTENTION</b>, PLEASE! A <b>SURVEY OF NEURAL ATTENTION MODELS IN DEEP</b> ...", "url": "https://www.researchgate.net/publication/350539262_ATTENTION_PLEASE_A_SURVEY_OF_NEURAL_ATTENTION_MODELS_IN_DEEP_LEARNING_A_PREPRINT", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350539262_<b>ATTENTION</b>_PLEASE_A_SURVEY_OF_NEURAL...", "snippet": "These architectures and all that use <b>self-attention</b> belong to a new category of neural networks, <b>called</b> Self-Attentiv e Neural Networks. They aim to explore <b>self-attention</b> in", "dateLastCrawled": "2022-01-26T02:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Analyzing the Structure of <b>Attention</b> in a Transformer Language Model ...", "url": "https://deepai.org/publication/analyzing-the-structure-of-attention-in-a-transformer-language-model", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/analyzing-the-structure-of-<b>attention</b>-in-a-transformer...", "snippet": "Each <b>layer</b> applies multi-head <b>self-attention</b> (see below) in combination with a feedforward network, <b>layer</b> normalization, ... (which cannot be in a dependency relation with <b>itself</b>) and the second disperses <b>attention</b> roughly evenly, without regard to content. An interesting counterexample is <b>layer</b> 4, head 11 (Figure 1), which has the highest dependency alignment out of all the heads (DepAl \u03b1 = 0.42) 7 7 7 Assuming relation may be in either direction. but is <b>also</b> the most position-focused ...", "dateLastCrawled": "2021-12-13T16:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Visual <b>Attention</b> Model in Deep Learning | by Tristan | Towards Data Science", "url": "https://towardsdatascience.com/visual-attention-model-in-deep-learning-708813c2912c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/visual-<b>attention</b>-model-in-deep-learning-708813c2912c", "snippet": "Spatial Transformer Network is <b>also</b> studied as latest development in the visual <b>attention</b> regime, refer to paper [5] ... while <b>paying</b> less \u201c<b>attention</b>\u201d elsewhere. The advantage of this approach is: (1) the model can pay more <b>attention</b> to the relevant region of the image (2) and therefore the image processing power required is reduced (3) \u201coff-focus\u201d blurry area still captures a general concept of what\u2019s happening. This intuition may help in <b>our</b> augmented MNIST dataset challenge ...", "dateLastCrawled": "2022-01-31T12:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Minds of Its Own</b> \u2014 Acko.net", "url": "https://acko.net/blog/minds-of-its-own/", "isFamilyFriendly": true, "displayUrl": "https://acko.net/blog/<b>minds-of-its-own</b>", "snippet": "&quot;Oh but it is. You&#39;re properly <b>called</b> a Transformer. A big part of what makes you tick is <b>self-attention</b>: the ability to discover for yourself the interesting relationships between your inputs. You correlate values using a fully connected N-to-N matrix. Whereas my human <b>attention</b> is much more sparse, I think.&quot; he explains.", "dateLastCrawled": "2021-12-22T02:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>ICML2020</b>/<b>icml2020</b>_1.md at master \u00b7 <b>haozhangcn/ICML2020</b> \u00b7 <b>GitHub</b>", "url": "https://github.com/haozhangcn/ICML2020/blob/master/icml2020_1.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/haozhangcn/<b>ICML2020</b>/blob/master/<b>icml2020</b>_1.md", "snippet": "On the other hand, <b>our</b> theory <b>also</b> shows that if the <b>layer</b> normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in <b>our</b> experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide ...", "dateLastCrawled": "2022-01-29T11:21:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Attention</b> in Psychology, Neuroscience, and Machine Learning", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7177153/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7177153", "snippet": "Interestingly, <b>self-attention</b> has less in common with biological <b>attention</b> than the recurrent <b>attention</b> models originally used for machine translation. First, it reduces the role of recurrence and dynamics, whereas the <b>brain</b> necessarily relies on recurrence in sequential processing tasks, including language processing and attentional selection. Second, <b>self-attention</b> provides a form of horizontal interaction between words\u2014which allows for words in the encoded sentence to be processed in ...", "dateLastCrawled": "2021-12-27T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Frontiers | <b>Attention in Psychology, Neuroscience, and Machine Learning</b> ...", "url": "https://www.frontiersin.org/articles/10.3389/fncom.2020.00029/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fncom.2020.00029", "snippet": "Interestingly, <b>self-attention</b> has less in common with biological <b>attention</b> than the recurrent <b>attention</b> models originally used for machine translation. First, it reduces the role of recurrence and dynamics, whereas the <b>brain</b> necessarily relies on recurrence in sequential processing tasks, including language processing and attentional selection. Second, <b>self-attention</b> provides a form of horizontal interaction between words\u2014which allows for words in the encoded sentence to be processed in ...", "dateLastCrawled": "2022-02-03T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Analyzing the Structure of <b>Attention</b> in a Transformer Language Model ...", "url": "https://deepai.org/publication/analyzing-the-structure-of-attention-in-a-transformer-language-model", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/analyzing-the-structure-of-<b>attention</b>-in-a-transformer...", "snippet": "The <b>attention</b>-head view (Figure 1) visualizes <b>attention</b> for one or more heads in a model <b>layer</b>. <b>Self-attention</b> is depicted as lines connecting the attending tokens (left) with the tokens being attended to (right). Colors identify the head(s), and line weight reflects the <b>attention</b> weight.", "dateLastCrawled": "2021-12-13T16:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Body and Hand\u2013Object ROI-Based Behavior Recognition Using Deep Learning", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7961580/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7961580", "snippet": "A neural network was designed that uses a 3D skeleton sequence and a single middle frame as input. The <b>self-attention</b> module and skeleton <b>attention</b> module were used. Further, temporal features were extracted from the skeleton sequence via a Bi-directional long short term memory (Bi-LSTM). Moreover, the spatial and temporal features were ...", "dateLastCrawled": "2022-01-19T19:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Attention</b>-based <b>Dropout Layer for Weakly Supervised Object Localization</b> ...", "url": "https://deepai.org/publication/attention-based-dropout-layer-for-weakly-supervised-object-localization", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>attention</b>-based-<b>dropout-layer-for-weakly-supervised</b>...", "snippet": "At lower-level layers, the <b>self-attention</b> maps include general features, while class-specific features are included in the <b>self-attention</b> maps at higher-level layers. The drop masks <b>also</b> erase most discriminative part more effectively at higher-level layers. Please note that the drop mask is overlaid with input image for better visualization. Because the importance map has a distribution very <b>similar</b> to that of the <b>self-attention</b> map, we do not visualize it.", "dateLastCrawled": "2022-01-15T20:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Generalized <b>attention</b>-weighted reinforcement learning - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0893608021003853", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0893608021003853", "snippet": "In <b>our</b> application of <b>self-attention</b> as a feature selector, lower temperatures would enforce sparser feature selection, possibly resulting in <b>attention</b> heads that carry only a single feature representation. The effects on learning of sparse and dense heads need to be researched in future work, as sparser heads might lead to more compact task-state representations and even better interpretability of the model behavior. Unlike the explicit comparison of single-selection vs. feature-mixing in ...", "dateLastCrawled": "2021-12-23T19:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>ATTENTION</b>, PLEASE! A <b>SURVEY OF NEURAL ATTENTION MODELS IN DEEP</b> ...", "url": "https://www.researchgate.net/publication/350539262_ATTENTION_PLEASE_A_SURVEY_OF_NEURAL_ATTENTION_MODELS_IN_DEEP_LEARNING_A_PREPRINT", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350539262_<b>ATTENTION</b>_PLEASE_A_SURVEY_OF_NEURAL...", "snippet": "] <b>also</b> features an <b>attention</b> mechanism that reduces <b>self-attention</b> from quadratic to linear, allowing scaling for high inputs and data sets. Some approaches adapt the Transformer to new ...", "dateLastCrawled": "2022-01-26T02:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Visual <b>Attention</b> Model in Deep Learning | by Tristan | Towards Data Science", "url": "https://towardsdatascience.com/visual-attention-model-in-deep-learning-708813c2912c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/visual-<b>attention</b>-model-in-deep-learning-708813c2912c", "snippet": "Spatial Transformer Network is <b>also</b> studied as latest development in the visual <b>attention</b> regime, refer to paper [5] ... while <b>paying</b> less \u201c<b>attention</b>\u201d elsewhere. The advantage of this approach is: (1) the model can pay more <b>attention</b> to the relevant region of the image (2) and therefore the image processing power required is reduced (3) \u201coff-focus\u201d blurry area still captures a general concept of what\u2019s happening. This intuition may help in <b>our</b> augmented MNIST dataset challenge ...", "dateLastCrawled": "2022-01-31T12:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "From symbols to AI pair programmers \ud83d\udcbb (Practical AI #140) |&gt; Changelog", "url": "https://changelog.com/practicalai/140", "isFamilyFriendly": true, "displayUrl": "https://changelog.com/practicalai/140", "snippet": "So what happened was partly out of computational reasons, people started looking at these layers <b>called</b> <b>attention</b>, or <b>self-attention</b>, or soft <b>attention</b> layers, where actually you take your set of inputs and you shove them all at once into a <b>layer</b>, and let the model decide which ones of the inputs are important to pay <b>attention</b> to as it processes them through. You still have this sort of sequence of things and in some cases you wanna <b>also</b> put in something indicative of the sequence order, but ...", "dateLastCrawled": "2022-01-01T22:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>ICML2020</b>/<b>icml2020</b>_1.md at master \u00b7 <b>haozhangcn/ICML2020</b> \u00b7 <b>GitHub</b>", "url": "https://github.com/haozhangcn/ICML2020/blob/master/icml2020_1.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/haozhangcn/<b>ICML2020</b>/blob/master/<b>icml2020</b>_1.md", "snippet": "On the other hand, <b>our</b> theory <b>also</b> shows that if the <b>layer</b> normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in <b>our</b> experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide ...", "dateLastCrawled": "2022-01-29T11:21:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Attention</b> in Psychology, Neuroscience, and Machine Learning", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7177153/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7177153", "snippet": "These weightings scale the word encodings themselves to create the next <b>layer</b> in the model, a process known as \u201c<b>self-attention</b>.\u201d This process repeats, and eventually interacts with the autoregressive decoder which <b>also</b> has <b>attention</b> mechanisms that allow it to flexibly focus on the encoded input (as in the standard form of <b>attention</b>) and on the previously generated output. The Transformer\u2014the name given to this new <b>attention</b> architecture\u2014outperformed many previous models and quickly ...", "dateLastCrawled": "2021-12-27T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Frontiers | <b>Attention in Psychology, Neuroscience, and Machine Learning</b> ...", "url": "https://www.frontiersin.org/articles/10.3389/fncom.2020.00029/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fncom.2020.00029", "snippet": "These weightings scale the word encodings themselves to create the next <b>layer</b> in the model, a process known as \u201c<b>self-attention</b>.\u201d This process repeats, and eventually interacts with the autoregressive decoder which <b>also</b> has <b>attention</b> mechanisms that allow it to flexibly focus on the encoded input (as in the standard form of <b>attention</b>) and on the previously generated output. The Transformer\u2014the name given to this new <b>attention</b> architecture\u2014outperformed many previous models and quickly ...", "dateLastCrawled": "2022-02-03T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Details for Neural Network <b>Self Attention</b> and Related Queries", "url": "https://www.affiliatejoin.com/neural-network-self-attention", "isFamilyFriendly": true, "displayUrl": "https://www.affiliatejoin.com/neural-network-<b>self-attention</b>", "snippet": "<b>Self-Attention</b> <b>Self-attention</b>, <b>also</b> known as intra-<b>attention</b>, is an <b>attention</b> mechanism relating different positions of a single sequence in order to compute a representation of the same sequence. It has been shown to be very useful in machine reading, abstractive summarization, or image description generation.", "dateLastCrawled": "2022-02-02T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Intuitive Understanding of <b>Attention</b> Mechanism in Deep Learning | by ...", "url": "https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/intuitive-understanding-of-<b>attention</b>-mechanism-in-deep...", "snippet": "Thus we want <b>our</b> decoder to pay more <b>attention</b> to the states h1 and h2 while <b>paying</b> less <b>attention</b> to the remaining states of the encoder. For this reason we train a feed forward neural network which will learn to identify relevant encoder states by generating a high score for the states for which <b>attention</b> is to be paid while low score for the states which are to be ignored.", "dateLastCrawled": "2022-02-02T18:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "transcripts/practical-ai-140.md at master - <b>github.com</b>", "url": "https://github.com/thechangelog/transcripts/blob/master/practicalai/practical-ai-140.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/thechangelog/transcripts/blob/master/practicalai/practical-ai-140.md", "snippet": "So what happened was partly out of computational reasons, people started looking at these layers <b>called</b> <b>attention</b>, or <b>self-attention</b>, or soft <b>attention</b> layers, where actually you take your set of inputs and you shove them all at once into a <b>layer</b>, and let the model decide which ones of the inputs are important to pay <b>attention</b> to as it processes them through. You still have this sort of sequence of things and in some cases you wanna <b>also</b> put in something indicative of the sequence order, but ...", "dateLastCrawled": "2021-09-10T00:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is <b>Attention Mechanism in Neural Networks</b>? - Quora", "url": "https://www.quora.com/What-is-Attention-Mechanism-in-Neural-Networks", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>Attention-Mechanism-in-Neural-Networks</b>", "snippet": "Answer (1 of 5): From a simplified layman\u2019s point of view, the <b>Attention</b> Mechanism <b>can</b> be viewed as a method for making the RNN work better by letting the network know where to look as it is performing its task. Let\u2019s walk through this with three examples: Task 1: translating a sentence from Eng...", "dateLastCrawled": "2022-01-17T19:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Minds of Its Own</b> \u2014 Acko.net", "url": "https://acko.net/blog/minds-of-its-own/", "isFamilyFriendly": true, "displayUrl": "https://acko.net/blog/<b>minds-of-its-own</b>", "snippet": "You give it some <b>thought</b>. &quot;How so? My <b>attention</b> isn&#39;t &#39;connected&#39; or &#39;approximate&#39; or whatever you&#39;re saying.&quot; You decide to test him. &quot;Oh but it is. You&#39;re properly <b>called</b> a Transformer. A big part of what makes you tick is <b>self-attention</b>: the ability to discover for yourself the interesting relationships between your inputs. You correlate values using a fully connected N-to-N matrix. Whereas my human <b>attention</b> is much more sparse, I think.&quot; he explains. &quot;You&#39;re only saying that because you ...", "dateLastCrawled": "2021-12-22T02:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "NeurIPS 2021 papers", "url": "https://tanelp.github.io/neurips2021/?s=09", "isFamilyFriendly": true, "displayUrl": "https://tanelp.github.io/neurips2021/?s=09", "snippet": "<b>Our</b> approach uses <b>self-attention</b> to reason about relationships between datapoints explicitly, which <b>can</b> be seen as realizing non-parametric models using parametric <b>attention</b> mechanisms. However, unlike conventional non-parametric models, we let the model learn end-to-end from the data how to make use of other datapoints for prediction. Empirically, <b>our</b> models solve cross-datapoint lookup and complex reasoning tasks unsolvable by traditional deep learning models. We show highly competitive ...", "dateLastCrawled": "2022-02-03T07:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>What is an attention neural network</b>? - Quora", "url": "https://www.quora.com/What-is-an-attention-neural-network", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-an-attention-neural-network</b>", "snippet": "Answer (1 of 2): <b>Attention</b> is a mechanism in deep learning that determines the strength of relationship between pieces of data. This is commonly used in sequential architectures, such as when processing tokens for natural language processing (NLP), but <b>can</b> be applied to other situations as well. ...", "dateLastCrawled": "2022-01-20T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "overview for <b>anustretch</b> - <b>Reddit</b>", "url": "https://www.reddit.com/user/anustretch", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/user/<b>anustretch</b>", "snippet": "It was <b>also</b> through its <b>self-attention</b> layers (as mentioned earlier) that tells the network the relevance of a particular word/feature vector in relation to others and by virtue, its derived meaning in relation to the entire input sentence. This context-aware conditioning (by taking into account all possible ways the input relates <b>to itself</b>) gives GPT-2 its so-<b>called</b> &quot;dynamic weights&quot;** or memory, unlike NNs without <b>self-attention</b>.", "dateLastCrawled": "2021-01-11T15:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Attention</b> in Psychology, Neuroscience, and Machine Learning", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7177153/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7177153", "snippet": "Interestingly, <b>self-attention</b> has less in common with biological <b>attention</b> than the recurrent <b>attention</b> models originally used for machine translation. First, it reduces the role of recurrence and dynamics, whereas the <b>brain</b> necessarily relies on recurrence in sequential processing tasks, including language processing and attentional selection. Second, <b>self-attention</b> provides a form of horizontal interaction between words\u2014which allows for words in the encoded sentence to be processed in ...", "dateLastCrawled": "2021-12-27T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Frontiers | <b>Attention in Psychology, Neuroscience, and Machine Learning</b> ...", "url": "https://www.frontiersin.org/articles/10.3389/fncom.2020.00029/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fncom.2020.00029", "snippet": "Interestingly, <b>self-attention</b> has less in common with biological <b>attention</b> than the recurrent <b>attention</b> models originally used for machine translation. First, it reduces the role of recurrence and dynamics, whereas the <b>brain</b> necessarily relies on recurrence in sequential processing tasks, including language processing and attentional selection. Second, <b>self-attention</b> provides a form of horizontal interaction between words\u2014which allows for words in the encoded sentence to be processed in ...", "dateLastCrawled": "2022-02-03T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Attention</b>-based <b>Dropout Layer for Weakly Supervised Object Localization</b> ...", "url": "https://deepai.org/publication/attention-based-dropout-layer-for-weakly-supervised-object-localization", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>attention</b>-based-<b>dropout-layer-for-weakly-supervised</b>...", "snippet": "Owing to the importance map, the more accurate <b>self-attention</b> map <b>can</b> be produced. The importance map is computed by applying sigmoid activation to the <b>self-attention</b> map. During training, either one of the drop mask or importance map is stochastically selected at each iteration, and then the selected one is applied to the input feature map by spatialwise multiplication. Figure 1 shows the block diagram of the proposed method. <b>Compared</b> to existing WSOL techniques, the proposed method is much ...", "dateLastCrawled": "2022-01-15T20:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Analyzing the Structure of <b>Attention</b> in a Transformer Language Model ...", "url": "https://deepai.org/publication/analyzing-the-structure-of-attention-in-a-transformer-language-model", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/analyzing-the-structure-of-<b>attention</b>-in-a-transformer...", "snippet": "The <b>attention</b>-head view (Figure 1) visualizes <b>attention</b> for one or more heads in a model <b>layer</b>. <b>Self-attention</b> is depicted as lines connecting the attending tokens (left) with the tokens being attended to (right). Colors identify the head(s), and line weight reflects the <b>attention</b> weight.", "dateLastCrawled": "2021-12-13T16:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Visual <b>Attention</b> Model in Deep Learning | by Tristan | Towards Data Science", "url": "https://towardsdatascience.com/visual-attention-model-in-deep-learning-708813c2912c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/visual-<b>attention</b>-model-in-deep-learning-708813c2912c", "snippet": "It is <b>also</b> known as \u201chard\u201d <b>attention</b>, since this stochastic process is non-differentiable (<b>compared</b> to \u201csoft\u201d <b>attention</b>). The intuition behind stochasticity is to balance between exploitation (to predict future using the history) and exploration (to try unprecedented stuff). Note that, this stochasticity makes the component non-differentiable, which will incur problem during back-propagation. And REINFORCE gradient policy algorithm is used to solve this problem, the detail is ...", "dateLastCrawled": "2022-01-31T12:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Generalized <b>attention</b>-weighted reinforcement learning - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0893608021003853", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0893608021003853", "snippet": "In <b>our</b> application of <b>self-attention</b> as a feature selector, lower temperatures would enforce sparser feature selection, possibly resulting in <b>attention</b> heads that carry only a single feature representation. The effects on learning of sparse and dense heads need to be researched in future work, as sparser heads might lead to more compact task-state representations and even better interpretability of the model behavior. Unlike the explicit comparison of single-selection vs. feature-mixing in ...", "dateLastCrawled": "2021-12-23T19:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>ATTENTION</b>, PLEASE! A <b>SURVEY OF NEURAL ATTENTION MODELS IN DEEP</b> ...", "url": "https://www.researchgate.net/publication/350539262_ATTENTION_PLEASE_A_SURVEY_OF_NEURAL_ATTENTION_MODELS_IN_DEEP_LEARNING_A_PREPRINT", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350539262_<b>ATTENTION</b>_PLEASE_A_SURVEY_OF_NEURAL...", "snippet": "In humans, <b>Attention</b> is a core property of all perceptual and cognitive operations. Given <b>our</b> limited ability to process competing sources, <b>attention</b> mechanisms select, modulate, and focus on the ...", "dateLastCrawled": "2022-01-26T02:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Minds of Its Own</b> \u2014 Acko.net", "url": "https://acko.net/blog/minds-of-its-own/", "isFamilyFriendly": true, "displayUrl": "https://acko.net/blog/<b>minds-of-its-own</b>", "snippet": "&quot;Oh but it is. You&#39;re properly <b>called</b> a Transformer. A big part of what makes you tick is <b>self-attention</b>: the ability to discover for yourself the interesting relationships between your inputs. You correlate values using a fully connected N-to-N matrix. Whereas my human <b>attention</b> is much more sparse, I think.&quot; he explains.", "dateLastCrawled": "2021-12-22T02:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "NeurIPS 2021 papers", "url": "https://tanelp.github.io/neurips2021/?s=09", "isFamilyFriendly": true, "displayUrl": "https://tanelp.github.io/neurips2021/?s=09", "snippet": "<b>Our</b> approach uses <b>self-attention</b> to reason about relationships between datapoints explicitly, which <b>can</b> be seen as realizing non-parametric models using parametric <b>attention</b> mechanisms. However, unlike conventional non-parametric models, we let the model learn end-to-end from the data how to make use of other datapoints for prediction. Empirically, <b>our</b> models solve cross-datapoint lookup and complex reasoning tasks unsolvable by traditional deep learning models. We show highly competitive ...", "dateLastCrawled": "2022-02-03T07:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>ICML2020</b>/<b>icml2020</b>_1.md at master \u00b7 <b>haozhangcn/ICML2020</b> \u00b7 <b>GitHub</b>", "url": "https://github.com/haozhangcn/ICML2020/blob/master/icml2020_1.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/haozhangcn/<b>ICML2020</b>/blob/master/<b>icml2020</b>_1.md", "snippet": "On the other hand, <b>our</b> theory <b>also</b> shows that if the <b>layer</b> normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in <b>our</b> experiments that Pre-LN Transformers without the warm-up stage <b>can</b> reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide ...", "dateLastCrawled": "2022-01-29T11:21:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Attention in Psychology, Neuroscience, and <b>Machine</b> <b>Learning</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7177153/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7177153", "snippet": "These weightings scale the word encodings themselves to create the next <b>layer</b> in the model, a process known as \u201c<b>self-attention</b>.\u201d This process repeats, and eventually interacts with the autoregressive decoder which <b>also</b> has attention mechanisms that allow it to flexibly focus on the encoded input (as in the standard form of attention) and on the previously generated output. The Transformer\u2014the name given to this new attention architecture\u2014outperformed many previous models and quickly ...", "dateLastCrawled": "2021-12-27T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>learning</b> glossary - DataTime", "url": "https://www.dtalg.com/article-1/", "isFamilyFriendly": true, "displayUrl": "https://www.dtalg.com/article-1", "snippet": "<b>self-attention</b> (<b>also</b> <b>called</b> <b>self-attention</b> <b>layer</b>) #language. A neural network <b>layer</b> that transforms a sequence of embeddings (for instance, token embeddings) into another sequence of embeddings. Each embedding in the output sequence is constructed by integrating information from the elements of the input sequence through an attention mechanism.", "dateLastCrawled": "2022-01-25T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "10.6. <b>Self-Attention</b> and <b>Positional Encoding</b> \u2014 Dive into Deep <b>Learning</b> ...", "url": "http://d2l.ai/chapter_attention-mechanisms/self-attention-and-positional-encoding.html", "isFamilyFriendly": true, "displayUrl": "d2l.ai/chapter_attention-mechanisms/<b>self-attention</b>-and-<b>positional-encoding</b>.html", "snippet": "In deep <b>learning</b>, we often use CNNs or RNNs to encode a sequence. Now with attention mechanisms, imagine that we feed a sequence of tokens into attention pooling so that the same set of tokens act as queries, keys, and values. Specifically, each query attends to all the key-value pairs and generates one attention output. Since the queries, keys, and values come from the same place, this performs <b>self-attention</b> [Lin et al., 2017b] [Vaswani et al., 2017], which is <b>also</b> <b>called</b> intra-attention ...", "dateLastCrawled": "2022-02-02T23:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Lecture 7: Transformers</b> - Deep <b>Learning</b>", "url": "https://chinmayhegde.github.io/dl-notes/notes/lecture07/", "isFamilyFriendly": true, "displayUrl": "https://chinmayhegde.github.io/dl-notes/notes/lecture07", "snippet": "<b>Self-Attention</b>. This is the point where papers-blogs-tweets-slides etc start talking about keys/values and attention mechanisms and everything goes a bit haywire. Let\u2019s just ignore all that for now, and instead talk about something <b>called</b> <b>self-attention</b>. The use of the \u201cself-\u201c prefix will become clear later on. Here is how it is defined.", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Enhancing LSTM Models with <b>Self-attention</b> and Stateful Training ...", "url": "https://www.academia.edu/69040947/Enhancing_LSTM_Models_with_Self_attention_and_Stateful_Training", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/69040947/Enhancing_LSTM_Models_with_<b>Self_attention</b>_and_Statef...", "snippet": "<b>Self-attention</b>, <b>also</b> known as intra-attention, is an attention mechanism relat- ing di\ufb00erent positions of a sequence in order to model dependencies between dif- ferent parts of the sequence. This di\ufb00ers from general attention in that instead of seeking to discover the \u201cimportant\u201d parts of the sequence relating to the net- work output, <b>self-attention</b> seeks to \ufb01nd the \u201cimportant\u201d portions of the sequence that relate to each other. This is done in order to leverage those intra ...", "dateLastCrawled": "2022-02-03T12:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Transformers in NLP: A beginner friendly explanation | Towards Data Science", "url": "https://towardsdatascience.com/transformers-89034557de14", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>transformer</b>s-89034557de14", "snippet": "<b>Self attention</b>, sometimes <b>called</b> intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. In simpler terms, <b>self attention</b> helps us create similar connections but within the same sentence. Look at the following example: \u201cI poured water from the bottle into the cup until it was full.\u201d it =&gt; cup \u201cI poured water from the bottle into the cup until it was empty.\u201d it=&gt; bottle. By changing one word ...", "dateLastCrawled": "2022-02-02T13:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Attending to Attention. A summary of a revolutionary paper\u2026 | by Akash ...", "url": "https://towardsdatascience.com/attending-to-attention-eba798f0e940", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/attending-to-attention-eba798f0e940", "snippet": "The encoder is composed of a stack of N = 6 identical layers. Each <b>layer</b> has two sub-layers. The first is a multi-head <b>self-attention</b> mechanism, and the second is a simple, position-wise fully connected feed-forward network. We employ a residual connection around each of the two sub-layers, followed by <b>layer</b> normalization. That is, the output ...", "dateLastCrawled": "2022-01-25T10:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to perform Text Summarization with Python, HuggingFace Transformers ...", "url": "https://www.machinecurve.com/index.php/2020/12/21/easy-text-summarization-with-huggingface-transformers-and-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2020/12/21/easy-text-summarization-with-hugging...", "snippet": "Summary &amp; Example: Text Summarization with Transformers. Transformers are taking the world of language processing by storm. These models, which learn to interweave the importance of tokens by means of a mechanism <b>called</b> <b>self-attention</b> and without recurrent segments, have allowed us to train larger models without all the problems of recurrent neural networks.", "dateLastCrawled": "2022-02-02T23:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Journal of Physics: Conference Series PAPER OPEN ACCESS You may <b>also</b> ...", "url": "https://iopscience.iop.org/article/10.1088/1742-6596/1651/1/012019/pdf", "isFamilyFriendly": true, "displayUrl": "https://iopscience.iop.org/article/10.1088/1742-6596/1651/1/012019/pdf", "snippet": "Different <b>machine</b> <b>learning</b> techniques have been used in this field for many years. But recently, deep <b>learning</b> has caused more and more attention in the field of education. Deep <b>learning</b> is a <b>machine</b> <b>learning</b> method based on neural network structure of multi-<b>layer</b> processing units, and it has been successfully applied to a series of problems in the field of image recognition and natural language processing[2]. With the diversified cultivation of traditional universities and the development ...", "dateLastCrawled": "2021-12-29T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is &#39;attention&#39; in the context of deep <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-attention-in-the-context-of-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-attention-in-the-context-of-deep-<b>learning</b>", "snippet": "Answer (1 of 5): In feed-forward deep networks, the entire input is presented to the network, which computes an output in one pass. In recurrent networks, new inputs can be presented at each time step, and the output of the previous time step can be used as an input to the network. This can be ...", "dateLastCrawled": "2022-01-15T04:26:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(self-attention (also called self-attention layer))  is like +(our brain paying attention to itself)", "+(self-attention (also called self-attention layer)) is similar to +(our brain paying attention to itself)", "+(self-attention (also called self-attention layer)) can be thought of as +(our brain paying attention to itself)", "+(self-attention (also called self-attention layer)) can be compared to +(our brain paying attention to itself)", "machine learning +(self-attention (also called self-attention layer) AND analogy)", "machine learning +(\"self-attention (also called self-attention layer) is like\")", "machine learning +(\"self-attention (also called self-attention layer) is similar\")", "machine learning +(\"just as self-attention (also called self-attention layer)\")", "machine learning +(\"self-attention (also called self-attention layer) can be thought of as\")", "machine learning +(\"self-attention (also called self-attention layer) can be compared to\")"]}