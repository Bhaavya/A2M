{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Unfair biases in <b>Machine Learning</b>: what, why, where and how to ...", "url": "https://medium.com/disaitek/unfair-biases-in-machine-learning-what-why-where-and-how-to-obliterate-them-1d6e682ac556", "isFamilyFriendly": true, "displayUrl": "https://medium.com/disaitek/unfair-<b>bias</b>es-in-<b>machine-learning</b>-what-why-where-and-how...", "snippet": "For instance, in one case of hiring <b>machine learning</b> system the age <b>bias</b> seems unfair but in a model involved in predicting the survival of a patient which <b>has</b> the COVID-19, age seems to be an ...", "dateLastCrawled": "2022-01-29T21:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Unfair biases in Machine Learning: what, why, where</b> and how to ...", "url": "https://www.mlsecurity.ai/post/unfair-biases-in-machine-learning-what-why-where-and-how-to-obliterate-them", "isFamilyFriendly": true, "displayUrl": "https://www.mlsecurity.ai/post/<b>unfair-biases-in-machine-learning-what-why-where</b>-and...", "snippet": "For instance, in one case of hiring <b>machine</b> <b>learning</b> system the age <b>bias</b> seems unfair but in a model involved in predicting the survival of a patient which <b>has</b> the COVID-19, age seems to be an important variable to take into account. There is also the question of how fairness is measured that needs to be discussed; Different methods exist, which will not have the same relevance in all cases. This makes fairness a delicate subject.", "dateLastCrawled": "2022-02-01T14:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Algorithmic <b>bias</b>: Senses, sources, solutions - Fazelpour - 2021 ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/phc3.12760?af=R", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/phc3.12760?af=R", "snippet": "This situation is a textbook example of modern <b>machine</b> <b>learning</b>: collect <b>data</b> on past cases (e.g., students); train a model on these <b>data</b> that optimizes predictions about an outcome of interest (e.g., probability of success); and use that predictive model to guide action (e.g., policies for mentorship or admission strategies). These kinds of algorithms are being built at universities worldwide, likely including those with which the reader <b>has</b> some past or present affiliation. Of course ...", "dateLastCrawled": "2022-01-01T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bias</b> does not equal <b>bias</b>. A socio-technical typology of <b>bias</b> in <b>data</b> ...", "url": "https://policyreview.info/articles/analysis/bias-does-not-equal-bias-socio-technical-typology-bias-data-based-algorithmic", "isFamilyFriendly": true, "displayUrl": "https://policyreview.info/articles/analysis/<b>bias</b>-does-not-equal-<b>bias</b>-socio-technical...", "snippet": "Zooming into the technical details of <b>a machine</b> <b>learning</b> system\u2019s life cycle, Suresh and Guttag (2020) described various issues that can introduce <b>bias</b> into a system: historical <b>bias</b>, representation <b>bias</b>, measurement <b>bias</b>, aggregation <b>bias</b>, <b>learning</b> <b>bias</b>, evaluation <b>bias</b> and deployment <b>bias</b>. Some of these types <b>of data</b> <b>bias</b> can only be identified through extensive knowledge and close examination of the development process of a <b>particular</b> system including the underlying <b>data</b> used to build ...", "dateLastCrawled": "2022-01-22T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning with Python - Algorithms</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_algorithms.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/.../<b>machine_learning_with_python_algorithms</b>.htm", "snippet": "It is used for clustering a given <b>data</b> <b>set</b> into different groups, which is widely used for segmenting customers into different groups for specific intervention. Apriori <b>algorithm</b> and K-means are some of the examples of Unsupervised <b>Learning</b>. Reinforcement <b>Learning</b>. Using this <b>algorithm</b>, the <b>machine</b> is <b>trained</b> to make specific decisions. Here ...", "dateLastCrawled": "2022-02-02T19:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "linkedin-skill-assessments-quizzes/<b>machine</b>-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/.../blob/master/<b>machine</b>-<b>learning</b>/<b>machine</b>-<b>learning</b>-quiz.md", "snippet": "No, <b>data</b> model <b>bias</b> and variance are only a challenge with reinforcement <b>learning</b>. Yes, <b>data</b> model <b>bias</b> is a challenge when the <b>machine</b> creates clusters. Yes, <b>data</b> model variance trains the unsupervised <b>machine</b> <b>learning</b> <b>algorithm</b>. No, <b>data</b> model <b>bias</b> and variance involve supervised <b>learning</b>. Q37. Which choice is best for binary classification ...", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Managing <b>bias and unfairness</b> in <b>data</b> for decision support: a survey of ...", "url": "https://link.springer.com/article/10.1007/s00778-021-00671-8", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00778-021-00671-8", "snippet": "This function is typically <b>a machine</b> <b>learning</b> model (<b>like</b> a classifier, regression, or a ranking <b>algorithm</b>, etc.) <b>trained</b> on labelled <b>data</b> and exposed to unseen instances after deployment. Decisions, whether made by people or systems, may show <b>bias</b>. A <b>bias</b> is observed if <b>data</b> instances belonging to certain classes show a systematically ...", "dateLastCrawled": "2022-02-01T12:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Bias</b>, awareness, and ignorance in deep-<b>learning</b>-based face recognition ...", "url": "https://link.springer.com/article/10.1007%2Fs43681-021-00108-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s43681-021-00108-6", "snippet": "FR <b>has</b> improved considerably and constantly over the last decade [1,2,3,4], giving rise to numerous applications ranging from services on mobile consumer devices to the use by law enforcement agencies [5,6,7].The increased deployment <b>has</b> triggered an intense debate on the dangers of the pervasive use of biometrics [8,9,10,11] up to the point where regulation [] and bans on the technology are discussed [] and partially enforced [14, 15].Several civil rights groups oppose facial recognition ...", "dateLastCrawled": "2022-02-03T10:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Algorithmic <b>bias</b>: Senses, sources, solutions | Request PDF", "url": "https://www.researchgate.net/publication/352358520_Algorithmic_bias_Senses_sources_solutions", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/352358520_<b>Algorithm</b>ic_<b>bias</b>_Senses_sources...", "snippet": "In <b>particular</b>, this work <b>has</b> explored what fairness might mean in the context of decisions based on the predictions of statistical and <b>machine</b> <b>learning</b> models. The rapid growth of this new field ...", "dateLastCrawled": "2022-01-04T12:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Programming Fairness in Algorithms</b> - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/programming-fairness-in-algorithms-4943a13dd9f8", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/<b>programming-fairness-in-algorithms</b>-4943a13dd9f8", "snippet": "<b>Machine</b> <b>learning</b> fairness is a young subfield of <b>machine</b> <b>learning</b> <b>that has</b> <b>been</b> growing in popularity over the last few years in response to the rapid integration of <b>machine</b> <b>learning</b> into social realms. Computer scientists, unlike doctors, are not necessarily <b>trained</b> to consider the ethical implications of their actions. It is only relatively recently (one could argue since the advent of social media) that the designs or inventions of computer scientists were able to take on an ethical ...", "dateLastCrawled": "2022-01-23T21:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b> does not equal <b>bias</b>. A socio-technical typology of <b>bias</b> in <b>data</b> ...", "url": "https://policyreview.info/articles/analysis/bias-does-not-equal-bias-socio-technical-typology-bias-data-based-algorithmic", "isFamilyFriendly": true, "displayUrl": "https://policyreview.info/articles/analysis/<b>bias</b>-does-not-equal-<b>bias</b>-socio-technical...", "snippet": "Zooming into the technical details of a <b>machine</b> <b>learning</b> system\u2019s life cycle, Suresh and Guttag (2020) described various issues that can introduce <b>bias</b> into a system: historical <b>bias</b>, representation <b>bias</b>, measurement <b>bias</b>, aggregation <b>bias</b>, <b>learning</b> <b>bias</b>, evaluation <b>bias</b> and deployment <b>bias</b>. Some of these types <b>of data</b> <b>bias</b> can only be identified through extensive knowledge and close examination of the development process of a <b>particular</b> system including the underlying <b>data</b> used to build ...", "dateLastCrawled": "2022-01-22T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias</b>, awareness, and ignorance in deep-<b>learning</b>-based face recognition ...", "url": "https://link.springer.com/article/10.1007%2Fs43681-021-00108-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s43681-021-00108-6", "snippet": "FR <b>has</b> improved considerably and constantly over the last decade [1,2,3,4], giving rise to numerous applications ranging from services on mobile consumer devices to the use by law enforcement agencies [5,6,7].The increased deployment <b>has</b> triggered an intense debate on the dangers of the pervasive use of biometrics [8,9,10,11] up to the point where regulation [] and bans on the technology are discussed [] and partially enforced [14, 15].Several civil rights groups oppose facial recognition ...", "dateLastCrawled": "2022-02-03T10:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Accuracy comparison across face recognition algorithms: Where are we on ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7879975/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7879975", "snippet": "The issue of <b>bias</b> <b>has</b> <b>been</b> studied also in the wider field of biometrics ... among others\u201d; and Group 3: people from \u201cJapan, China, Korea, and other countries in that region\u201d. Across the 12 <b>data</b> sets, 77% of the identities are <b>in Group</b> 1, 14% in from Group 2, and 7% <b>in Group</b> 3. For gender, 60% of the identities are male and 40% are female. The authors created the DiveFace <b>data</b> <b>set</b>, which <b>has</b> identities equally distributed across gender and the three groups. On this <b>set</b>, they tested VGG ...", "dateLastCrawled": "2022-01-29T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Interventions | <b>Machine Learning Bias Mitigation</b>", "url": "https://cdeiuk.github.io/bias-mitigation/interventions/", "isFamilyFriendly": true, "displayUrl": "https://cdeiuk.github.io/<b>bias</b>-mitigation/interventions", "snippet": "There was a small drop in accuracy, whereas our baseline achieved 85.3% test <b>set</b> accuracy, the model <b>trained</b> on the fair <b>data</b> achieved 85.0%. However there was also hardly any change in demographic parity difference, going from 0.193 to 0.186. Below we show a box plot of the score distributions for the two models. They appear very <b>similar</b>.", "dateLastCrawled": "2022-02-02T02:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "linkedin-skill-assessments-quizzes/<b>machine</b>-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/.../blob/master/<b>machine</b>-<b>learning</b>/<b>machine</b>-<b>learning</b>-quiz.md", "snippet": "No, <b>data</b> model <b>bias</b> and variance are only a challenge with reinforcement <b>learning</b>. Yes, <b>data</b> model <b>bias</b> is a challenge when the <b>machine</b> creates clusters. Yes, <b>data</b> model variance trains the unsupervised <b>machine</b> <b>learning</b> <b>algorithm</b>. No, <b>data</b> model <b>bias</b> and variance involve supervised <b>learning</b>. Q37. Which choice is best for binary classification ...", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning with Python - Algorithms</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_algorithms.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/.../<b>machine_learning_with_python_algorithms</b>.htm", "snippet": "It is used for clustering a given <b>data</b> <b>set</b> into different groups, which is widely used for segmenting customers into different groups for specific intervention. Apriori <b>algorithm</b> and K-means are some of the examples of Unsupervised <b>Learning</b>. Reinforcement <b>Learning</b>. Using this <b>algorithm</b>, the <b>machine</b> is <b>trained</b> to make specific decisions. Here ...", "dateLastCrawled": "2022-02-02T19:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Algorithmic <b>bias</b>: Senses, sources, solutions - Fazelpour - 2021 ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/phc3.12760?af=R", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/phc3.12760?af=R", "snippet": "Given a dataset, developers use a <b>learning</b> <b>algorithm</b> to \u2018fit\u2019 a predictive model on a portion of the <b>data</b>\u2013the \u2018training <b>set</b>\u2019\u2013whose performance is validated on a previously unseen portion of the dataset\u2013the \u2018test <b>set</b>\u2019. 3 These modeling and validation processes, often conducted iteratively, almost always optimize and evaluate model performance relative to some criteria of success. While this stage can be highly technical, it also involves multiple value judgments. As noted ...", "dateLastCrawled": "2022-01-01T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Top 5 Predictive Analytics Models and Algorithms | Logi Analytics Blog", "url": "https://www.logianalytics.com/predictive-analytics/predictive-algorithms-and-models/", "isFamilyFriendly": true, "displayUrl": "https://www.logianalytics.com/predictive-analytics/predictive-<b>algorithms</b>-and-models", "snippet": "<b>Machine</b> <b>learning</b> involves structural <b>data</b> that we see in a table. Algorithms for this comprise both linear and nonlinear varieties. Linear algorithms train more quickly, while nonlinear are better optimized for the problems they are likely to face (which are often nonlinear). Deep <b>learning</b> is a subset of <b>machine</b> <b>learning</b> that is more popular to deal with audio, video, text, and images. With <b>machine</b> <b>learning</b> predictive modeling, there are several different algorithms that can be applied ...", "dateLastCrawled": "2022-02-02T22:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Programming Fairness in Algorithms</b> - Towards <b>Data</b> Science", "url": "https://towardsdatascience.com/programming-fairness-in-algorithms-4943a13dd9f8", "isFamilyFriendly": true, "displayUrl": "https://towards<b>data</b>science.com/<b>programming-fairness-in-algorithms</b>-4943a13dd9f8", "snippet": "<b>Machine</b> <b>learning</b> fairness is a young subfield of <b>machine</b> <b>learning</b> <b>that has</b> <b>been</b> growing in popularity over the last few years in response to the rapid integration of <b>machine</b> <b>learning</b> into social realms. Computer scientists, unlike doctors, are not necessarily <b>trained</b> to consider the ethical implications of their actions. It is only relatively recently (one could argue since the advent of social media) that the designs or inventions of computer scientists were able to take on an ethical ...", "dateLastCrawled": "2022-01-23T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Which machine learning algorithms are optimal for</b> boolean features? - Quora", "url": "https://www.quora.com/Which-machine-learning-algorithms-are-optimal-for-boolean-features", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Which-machine-learning-algorithms-are-optimal-for</b>-boolean-features", "snippet": "Answer (1 of 5): Boosted decision trees work very well for categorical (in this case, 2-categorical) features. The information gain criterion [1] works especially ...", "dateLastCrawled": "2022-01-28T21:31:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bias</b> does not equal <b>bias</b>. A socio-technical typology of <b>bias</b> in <b>data</b> ...", "url": "https://policyreview.info/articles/analysis/bias-does-not-equal-bias-socio-technical-typology-bias-data-based-algorithmic", "isFamilyFriendly": true, "displayUrl": "https://policyreview.info/articles/analysis/<b>bias</b>-does-not-equal-<b>bias</b>-socio-technical...", "snippet": "Zooming into the technical details of a <b>machine</b> <b>learning</b> system\u2019s life cycle, Suresh and Guttag (2020) described various issues that <b>can</b> introduce <b>bias</b> into a system: historical <b>bias</b>, representation <b>bias</b>, measurement <b>bias</b>, aggregation <b>bias</b>, <b>learning</b> <b>bias</b>, evaluation <b>bias</b> and deployment <b>bias</b>. Some of these types <b>of data</b> <b>bias</b> <b>can</b> only be identified through extensive knowledge and close examination of the development process of a <b>particular</b> system including the underlying <b>data</b> used to build ...", "dateLastCrawled": "2022-01-22T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias</b>, awareness, and ignorance in deep-<b>learning</b>-based face recognition ...", "url": "https://link.springer.com/article/10.1007%2Fs43681-021-00108-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s43681-021-00108-6", "snippet": "We investigate how well <b>machine</b> <b>learning</b> models <b>can</b> predict the sensitive features, such as ethnicity and gender, based on the face embedding. The intuition is that an FR model is \u201caware\u201d of a sensitive feature if it <b>can</b> be predicted from the embedding vectors produced by the FR model. This inference is a classification task and the performance depends on the classification model at hand. If simple models, more precisely models with a low number of parameters, <b>can</b> properly infer the ...", "dateLastCrawled": "2022-02-03T10:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "linkedin-skill-assessments-quizzes/<b>machine</b>-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/.../blob/master/<b>machine</b>-<b>learning</b>/<b>machine</b>-<b>learning</b>-quiz.md", "snippet": "Q54. Your <b>data</b> science team is working on a <b>machine</b> <b>learning</b> product that <b>can</b> act as an artificial opponent in video games. The team is using a <b>machine</b> <b>learning</b> <b>algorithm</b> that focuses on rewards: If the <b>machine</b> does some things well, then it improves the quality of the outcome. How would you describe this type of <b>machine</b> <b>learning</b> <b>algorithm</b>?", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Algorithmic <b>Bias</b> in Education | SpringerLink", "url": "https://link.springer.com/article/10.1007/s40593-021-00285-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s40593-021-00285-9", "snippet": "A reference <b>data</b> <b>set</b> <b>can</b> be used to compare algorithms to reduce algorithmic <b>bias</b>, to compare metrics for evaluating algorithmic <b>bias</b>, and as a model for future <b>data</b> <b>set</b> developers to compare their own efforts to. Within education, reference <b>data</b> sets should contain a wide variety of demographic variables (as detailed in the previous sub-section), have a variety of label variables across <b>data</b> sets (both macro-outcomes such as school dropout or course failure, and finer-grained variables such ...", "dateLastCrawled": "2022-01-28T10:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Amazon SageMaker Clarify: <b>Machine</b> <b>Learning</b> <b>Bias</b> Detection and ...", "url": "https://deepai.org/publication/amazon-sagemaker-clarify-machine-learning-bias-detection-and-explainability-in-the-cloud", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/amazon-sagemaker-clarify-<b>machine</b>-<b>learning</b>-<b>bias</b>...", "snippet": "<b>Machine</b> <b>learning</b> (ML) models and <b>data</b>-driven systems are increasingly used to assist in decision-making across domains such as financial services, healthcare, education, and human resources. Benefits of using ML include improved accuracy, increased productivity, and cost savings. The increasing adoption of ML is the result of multiple factors, most notably ubiquitous connectivity, the ability to collect, aggregate, and process large amounts <b>of data</b> using cloud computing, and improved access ...", "dateLastCrawled": "2022-01-25T08:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Ethical machines: The human-centric use of artificial intelligence", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7973859/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7973859", "snippet": "Compared to humans, there are advantages that <b>can</b> hardly be denied in the use of <b>machine</b> <b>learning</b> algorithms: they <b>can</b> perform tasks in a shorter amount of time, they are able to process significantly larger amounts <b>of data</b> than humans <b>can</b>, they do not get tired, hungry, or bored and they are not susceptible to corruption or conflicts of interest (Danziger et al., 2011). Furthermore, the increasing tendency in adopting algorithms <b>can</b> be seen as an answer to the request of a greater ...", "dateLastCrawled": "2022-01-29T00:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Fairness in machine learning with tractable models</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0950705120308443", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0950705120308443", "snippet": "The prevalence of <b>machine</b> <b>learning</b> techniques <b>has</b> raised concerns about the potential for learned algorithms to become biased against certain groups. Many definitions have <b>been</b> proposed in the literature, but the fundamental task of reasoning about probabilistic events is a challenging one, owing to the intractability of inference. The focus of this paper is taking steps towards the application of tractable probabilistic models to fairness in <b>machine</b> <b>learning</b>. Tractable probabilistic models ...", "dateLastCrawled": "2022-01-20T21:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Lecture 23: Fairness | Lecture Videos | <b>Machine</b> <b>Learning</b> for Healthcare ...", "url": "https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s897-machine-learning-for-healthcare-spring-2019/lecture-videos/lecture-23-fairness/", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/courses/electrical-engineering-and-computer-science/6-s897-<b>machine</b>...", "snippet": "So this is an idea that I&#39;ve seen used in <b>machine</b> <b>learning</b> for robustness rather than for fairness, where people say, the problem is that given a <b>particular</b> <b>data</b> <b>set</b>, you <b>can</b> overfit to that <b>data</b> <b>set</b>, and so one of the ideas is to do a Gann-like method where you say, I want to train my classifier, let&#39;s say, not only to work well on getting the right answer, but also to work as poorly as possible on identifying which <b>data</b> <b>set</b> my example came from.", "dateLastCrawled": "2022-01-30T18:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Which machine learning algorithms are optimal for</b> boolean features? - Quora", "url": "https://www.quora.com/Which-machine-learning-algorithms-are-optimal-for-boolean-features", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Which-machine-learning-algorithms-are-optimal-for</b>-boolean-features", "snippet": "Answer (1 of 5): Boosted decision trees work very well for categorical (in this case, 2-categorical) features. The information gain criterion [1] works especially ...", "dateLastCrawled": "2022-01-28T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning Algorithms From Scratch.pdf</b> [9n0o0xe6epnv]", "url": "https://idoc.pub/documents/machine-learning-algorithms-from-scratchpdf-9n0o0xe6epnv", "isFamilyFriendly": true, "displayUrl": "https://idoc.pub/documents/<b>machine-learning-algorithms-from-scratchpdf</b>-9n0o0xe6epnv", "snippet": "Chapter 2 Scale <b>Machine</b> <b>Learning</b> <b>Data</b> Many <b>machine</b> <b>learning</b> algorithms expect <b>data</b> to be scaled consistently. There are two popular methods that you should consider when scaling your <b>data</b> for <b>machine</b> <b>learning</b>. In this tutorial, you will discover how you <b>can</b> rescale your <b>data</b> for <b>machine</b> <b>learning</b>. After reading this tutorial you will know: How ...", "dateLastCrawled": "2022-01-30T02:55:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Biases in <b>machine</b> <b>learning</b> models and big <b>data</b> analytics: The ...", "url": "http://international-review.icrc.org/articles/biases-machine-learning-big-data-analytics-ihl-implications-913", "isFamilyFriendly": true, "displayUrl": "international-review.icrc.org/articles/<b>bias</b>es-<b>machine</b>-<b>learning</b>-big-<b>data</b>-analytics-ihl...", "snippet": "<b>Data</b> sets often contain biases which have the potential to unfairly disadvantage certain groups or to over-focus on certain activities to the detriment of others, and ML models or big <b>data</b> analytics <b>trained</b> on such <b>data</b> sets <b>can</b> inherit these biases.22 The following section discusses human biases that most commonly appear in <b>data</b> sets used for ML models and thus are most likely to impact ICL investigations and IHL considerations: implicit <b>bias</b>, selection <b>bias</b>, reporting <b>bias</b>, group ...", "dateLastCrawled": "2022-02-01T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A comparison of <b>machine</b> <b>learning</b> and Bayesian modelling for molecular ...", "url": "https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-017-3998-6", "isFamilyFriendly": true, "displayUrl": "https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-017-3998-6", "snippet": "The strength of the <b>machine</b> <b>learning</b> approach is that there may be features in the <b>data</b> important for accurate classification which are currently unknown but which <b>machine</b> <b>learning</b> <b>can</b> identify automatically. And with sufficient training examples <b>machine</b> <b>learning</b> <b>can</b> cope with biological and experimental variability in features important for classification. The errors that do occur in the results from the GBM <b>algorithm</b> may be due to biological variability occurring in the erroneous samples ...", "dateLastCrawled": "2022-01-22T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "linkedin-skill-assessments-quizzes/<b>machine</b>-<b>learning</b>-quiz.md at master ...", "url": "https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/master/machine-learning/machine-learning-quiz.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/.../blob/master/<b>machine</b>-<b>learning</b>/<b>machine</b>-<b>learning</b>-quiz.md", "snippet": "Q54. Your <b>data</b> science team is working on a <b>machine</b> <b>learning</b> product that <b>can</b> act as an artificial opponent in video games. The team is using a <b>machine</b> <b>learning</b> <b>algorithm</b> that focuses on rewards: If the <b>machine</b> does some things well, then it improves the quality of the outcome. How would you describe this type of <b>machine</b> <b>learning</b> <b>algorithm</b>?", "dateLastCrawled": "2022-02-02T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Interventions | <b>Machine Learning Bias Mitigation</b>", "url": "https://cdeiuk.github.io/bias-mitigation/interventions/", "isFamilyFriendly": true, "displayUrl": "https://cdeiuk.github.io/<b>bias</b>-mitigation/interventions", "snippet": "The result of applying the <b>algorithm</b> is a modified dataset, such that each feature in the <b>data</b> <b>has</b> <b>been</b> decorrelated from the protected attribute. The idea is that a model <b>trained</b> on this <b>data</b>, should not be able to learn to discriminate based on the protected attributes.", "dateLastCrawled": "2022-02-02T02:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning with Python - Algorithms</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_algorithms.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/.../<b>machine_learning_with_python_algorithms</b>.htm", "snippet": "<b>Machine</b> <b>learning</b> algorithms <b>can</b> be broadly classified into two types - Supervised and Unsupervised. This chapter discusses them in detail. Supervised <b>Learning</b> . This <b>algorithm</b> consists of a target or outcome or dependent variable which is predicted from a given <b>set</b> of predictor or independent variables. Using these <b>set</b> of variables, we generate a function that maps input variables to desired output variables. The training process continues until the model achieves a desired level of accuracy ...", "dateLastCrawled": "2022-02-02T19:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Accuracy comparison across face recognition algorithms: Where are we on ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7879975/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7879975", "snippet": "They <b>compared</b> two fused algorithms: a Western <b>algorithm</b> (created from a fusion of 8 Western algorithms) and an East Asian <b>algorithm</b> (created from a fusion of 5 East Asian algorithms). Both algorithms demonstrated an other-race effect for face identification. The Western <b>algorithm</b> performed more accurately for Caucasian faces and the East Asian <b>algorithm</b> was more accurate for East Asian faces. This is the only study that shows that <b>algorithm</b> origin <b>can</b> predict race <b>bias</b>. The algorithms tested ...", "dateLastCrawled": "2022-01-29T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The Myth of the <b>Impartial Machine</b> - parametric.press", "url": "https://parametric.press/issue-01/the-myth-of-the-impartial-machine/", "isFamilyFriendly": true, "displayUrl": "https://parametric.press/issue-01/the-myth-of-the-<b>impartial-machine</b>", "snippet": "Beyond tackling <b>bias</b> directly in the <b>data</b> and / or the <b>algorithm</b>, there are broader measures that tech companies in <b>particular</b> have begun to adopt. One measure is to establish ethical AI guidelines, where minimizing <b>bias</b> is included as part of a company\u2019s overarching AI objectives. (As ML is a subset of AI, the same ethical guidelines would then apply to ML product developments as well.)", "dateLastCrawled": "2022-02-03T05:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Intelligence at the Edge</b> with <b>Learning</b> Centric Power ... - DeepAI", "url": "https://deepai.org/publication/machine-intelligence-at-the-edge-with-learning-centric-power-allocation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>machine-intelligence-at-the-edge</b>-with-<b>learning</b>-centric...", "snippet": "We consider an edge <b>machine</b> <b>learning</b> system shown in Fig. 1, which consists of an intelligent edge with N antennas and K users. The goal of the edge is to train M classification models by collecting <b>data</b> observed at M user groups 1 1 1 In case where some <b>data</b> from a <b>particular</b> user is used to train both model m and model j, we <b>can</b> allow Y m and Y j to include a common user. That is, Y m \u22c2 Y j \u2260 \u2205 for m \u2260 j. (e.g., UAVs with camera sensors) {Y 1, Y 2, \u22ef, Y M}, with the group Y m ...", "dateLastCrawled": "2021-12-13T05:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Racist in <b>the Machine: The Disturbing Implications of Algorithmic Bias</b>", "url": "https://www.researchgate.net/publication/312080801_Racist_in_the_Machine_The_Disturbing_Implications_of_Algorithmic_Bias", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/312080801_Racist_in_the_<b>Machine</b>_The...", "snippet": "<b>Machine</b> <b>learning</b> is comprised of many steps where human intervention <b>can</b> impose additional <b>bias</b> on the <b>data</b> collection, such as racial and gender differences [64], and study samples not reflecting ...", "dateLastCrawled": "2022-01-21T19:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning Algorithms From Scratch.pdf</b> [9n0o0xe6epnv]", "url": "https://idoc.pub/documents/machine-learning-algorithms-from-scratchpdf-9n0o0xe6epnv", "isFamilyFriendly": true, "displayUrl": "https://idoc.pub/documents/<b>machine-learning-algorithms-from-scratchpdf</b>-9n0o0xe6epnv", "snippet": "Chapter 2 Scale <b>Machine</b> <b>Learning</b> <b>Data</b> Many <b>machine</b> <b>learning</b> algorithms expect <b>data</b> to be scaled consistently. There are two popular methods that you should consider when scaling your <b>data</b> for <b>machine</b> <b>learning</b>. In this tutorial, you will discover how you <b>can</b> rescale your <b>data</b> for <b>machine</b> <b>learning</b>. After reading this tutorial you will know: How ...", "dateLastCrawled": "2022-01-30T02:55:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning Techniques for Group Technology Applications</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0007850607627450", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0007850607627450", "snippet": "Based on the relative roles of teacher and learner, <b>learning</b> can be classified as 1131: <b>learning</b> by rote, <b>learning</b> by instruction, <b>learning</b> by <b>analogy</b>, <b>learning</b> from examples, <b>learning</b> from observation and discovery. The laat two kinds require inductive <b>learning</b> which is the process of acquiring new knowledge by making inductive inferences from facts provided by a teacher or environment. For a typical inductive <b>learning</b> problem, the givens are (1) a set of observational statements that ...", "dateLastCrawled": "2022-01-19T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Bow-tie signaling in c-di-GMP: <b>Machine</b> <b>learning</b> in a simple biochemical ...", "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005677", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005677", "snippet": "The <b>analogy</b> between c-di-GMP signaling and a <b>machine</b> <b>learning</b> classifier explains that weak selection favors generalist bacteria; generalists integrate environmental stimuli and decide between biofilm and swarming according to the environmental fluctuations experienced in their evolutionary history. Evolution in strong selection, on the other hand, favors specialists. This is similar to how small data sets tend to produce biased classifiers.", "dateLastCrawled": "2019-11-12T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Types Of <b>Analogy</b> With Examples", "url": "https://groups.google.com/g/4xrfyphy/c/SSzeFfWKlAo", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/4xrfyphy/c/SSzeFfWKlAo", "snippet": "The Incremental Analogical <b>Machine</b>: a computational model of <b>analogy</b>. Use these steps and try solving a few examples given below. Schlimm provides an example of an analogical reasoning problem <b>in group</b> theory that involves a single relation in each domain. It is possible to go much deeper into the subcategories than this, and I highly recommend reading the official guide multiple times to get a feel for these relationships. Aid for the problem. This website uses cookies to improve your ...", "dateLastCrawled": "2022-01-28T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Multi-Dimensional Gender <b>Bias</b> Classification | DeepAI", "url": "https://deepai.org/publication/multi-dimensional-gender-bias-classification", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/multi-dimensional-gender-<b>bias</b>-classification", "snippet": "Multi-Dimensional Gender <b>Bias</b> Classification. 05/01/2020 \u2219 by Emily Dinan, et al. \u2219 0 \u2219 share. <b>Machine</b> <b>learning</b> models are trained to find patterns in data. NLP models can inadvertently learn socially undesirable patterns when training on gender biased text. In this work, we propose a general framework that decomposes gender <b>bias</b> in text ...", "dateLastCrawled": "2021-12-15T17:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Recommendation System Series Part 7: The 3 Variants of Boltzmann ...", "url": "https://towardsdatascience.com/recsys-series-part-7-the-3-variants-of-boltzmann-machines-for-collaborative-filtering-4c002af258f9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/recsys-series-part-7-the-3-variants-of-boltzmann...", "snippet": "The <b>learning</b> algorithm is intuitive: They subtracted the sleep phase correlation from the wake <b>learning</b> phase and then adjusted the weights accordingly. With a big enough dataset, this algorithm can effectively learn arbitrary mappings between input and output. The Boltzmann <b>machine</b> <b>analogy</b> turns out to be a good insight into what\u2019s happing in the human brain during sleep. In cognitive science, there\u2019s a concept called replay, where the hippocampus plays back our memories and experiences ...", "dateLastCrawled": "2022-01-31T08:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The human factor: Working with machines to make big decisions", "url": "https://images.forbes.com/forbesinsights/StudyPDFs/PwC-The_Human_Factor-REPORT.pdf", "isFamilyFriendly": true, "displayUrl": "https://images.forbes.com/forbesinsights/StudyPDFs/PwC-The_Human_Factor-REPORT.pdf", "snippet": "role of <b>machine</b> <b>learning</b> in the business world. \u201cArtificial intelligence can help people make faster, better, and cheaper decisions. For that to happen, first and foremost, you need an openness of mind to collaborate with the <b>machine</b>, as opposed to treating the technology as either a servant or an overlord.\u201d This balance of mind and machines is just taking hold as companies experiment. Executives say their internal cultures could be more data-driven, with a greater emphasis on data ...", "dateLastCrawled": "2022-01-29T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "Simply put, the goal of classification is to determine a plausible value for an unknown variable Y given an observed variable X.For example, we might try to predict whether a loan applicant will pay back her loan by looking at various characteristics such as credit history, income, and net worth. Classification also applies in situations where the variable Y does not refer to an event that lies in the future. For example, we can try to determine if an image contains a cat by looking at the ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Understanding Unconscious Bias - A Deeper</b> Dive | Webfor", "url": "https://webfor.com/blog/understanding-unconscious-bias-a-deeper-dive/", "isFamilyFriendly": true, "displayUrl": "https://webfor.com/blog/<b>understanding-unconscious-bias-a-deeper</b>-dive", "snippet": "There\u2019s the \u201c<b>in\u201d group</b> and \u201cout\u201d group. So what happens with a team <b>bias</b>, I often call it as if I\u2019m in a game and I\u2019m watching the Blazers play. If the other team does a foul against my team in basketball, I\u2019m going to be screaming and yelling like, \u201cHey call the foul,\u201d right? But on the other side of the floor, when our team fouls their team and possibly gets away with it, I\u2019m probably not going to be yelling and screaming that out because I have this association, this ...", "dateLastCrawled": "2021-12-31T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Comparing diversity between groups - drive5", "url": "https://www.drive5.com/usearch/manual/diversity_metrics_compare_groups.html", "isFamilyFriendly": true, "displayUrl": "https://www.drive5.com/usearch/manual/diversity_metrics_compare_groups.html", "snippet": "<b>Machine</b> <b>learning</b> Chimeras Read quality Paired reads OTU errors and biases. Publications. Comparing diversity between sample groups. See also alpha_div_sig command Which alpha and beta diversity metrics are recommended? Interpreting alpha and beta diversity Alpha diversity Beta diversity Abundance <b>bias</b> Cross-talk. Diversity metrics can be compared between groups by amplicon sequencing It is not possible to measure alpha diversity of a single sample. However, diversity metrics can nevertheless ...", "dateLastCrawled": "2022-02-01T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Bow-tie signaling in c-di-GMP: <b>Machine learning in a simple</b> ...", "url": "https://www.researchgate.net/publication/318884143_Bow-tie_signaling_in_c-di-GMP_Machine_learning_in_a_simple_biochemical_network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/318884143_Bow-tie_signaling_in_c-di-GMP...", "snippet": "The <b>analogy</b> immediately suggests a mechanism for <b>learning</b> through evolution: adaptation though incremental changes in c-di-GMP network proteins acquires knowledge from past experiences and enables ...", "dateLastCrawled": "2022-01-03T04:32:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(in-group bias)  is like +(a machine learning algorithm that has been \u201ctrained\u201d on a particular set of data)", "+(in-group bias) is similar to +(a machine learning algorithm that has been \u201ctrained\u201d on a particular set of data)", "+(in-group bias) can be thought of as +(a machine learning algorithm that has been \u201ctrained\u201d on a particular set of data)", "+(in-group bias) can be compared to +(a machine learning algorithm that has been \u201ctrained\u201d on a particular set of data)", "machine learning +(in-group bias AND analogy)", "machine learning +(\"in-group bias is like\")", "machine learning +(\"in-group bias is similar\")", "machine learning +(\"just as in-group bias\")", "machine learning +(\"in-group bias can be thought of as\")", "machine learning +(\"in-group bias can be compared to\")"]}