{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Learning Additive Models Online with Fast Evaluating Kernels</b> | Request PDF", "url": "https://www.researchgate.net/publication/221497666_Learning_Additive_Models_Online_with_Fast_Evaluating_Kernels", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221497666_Learning_Additive_Models_Online...", "snippet": "We thus have obtained a bound on the <b>squared</b> <b>hinge</b> <b>loss</b>. The same bound was also derived by Herbster [52] . We can immediately use this bound to derive a <b>mistake</b> bound for the MIRA algorithm. ...", "dateLastCrawled": "2022-01-03T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Data Mining Practical Machine Learning Tools and Techniques</b> 3rd ...", "url": "https://www.academia.edu/23331284/Data_Mining_Practical_Machine_Learning_Tools_and_Techniques_3rd_Edition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/23331284/<b>Data_Mining_Practical_Machine_Learning_Tools</b>_and...", "snippet": "A short summary of this <b>paper</b>. 37 Full PDFs related to this <b>paper</b>. Read <b>Paper</b>. <b>Data Mining Practical Machine Learning Tools and Techniques</b> 3rd Edition. Download ...", "dateLastCrawled": "2022-01-30T15:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Answers to the practical questions and problems contained in the ...", "url": "https://quod.lib.umich.edu/m/moa/AJN2367.0001.001?rgn=main;view=fulltext", "isFamilyFriendly": true, "displayUrl": "https://<b>quod.lib.umich.edu</b>/m/moa/AJN2367.0001.001?rgn=main;view=fulltext", "snippet": "72. I. Olefiant gas may be <b>made</b> by heating in the flask one part, by measure, of alcohol and two parts of sulphuric acid. Pass it through a solution of potash, as shown on page 88, and then collect in the gas-bag. Fit <b>a piece</b> of glass tubing, drawn to a fine point at one end, to the stop-cock of the gas-bag by means of a bit of the rubber ...", "dateLastCrawled": "2022-02-02T11:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Errata</b> - O&#39;Reilly Media", "url": "https://www.oreilly.com/catalog/errata.csp?isbn=0636920052289", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/catalog/<b>errata</b>.csp?isbn=0636920052289", "snippet": "The former (cross-validation) is typically done on the training set: in K-<b>fold</b> CV, the training set is split into K pieces, and the same model *architecture* is trained K times (on the training set minus <b>piece</b> #i, for i in [1, K]), and then evaluated on the <b>piece</b> it was not trained on. The latter (evaluation of a trained model) is typically done on the validation set (when not using cross-validation) for model selection (which should be called model architecture &amp; hyperparameter selection ...", "dateLastCrawled": "2022-01-30T16:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>The Late Great United States: The Decline and</b> Fall of the United States ...", "url": "http://www.foundationwebsite.org/TheLateGreatUnitedStatesAppendices.htm", "isFamilyFriendly": true, "displayUrl": "www.foundationwebsite.org/<b>TheLateGreatUnitedStates</b>Appendices.htm", "snippet": "This reduced the <b>cost</b> <b>associated</b> with acquiring original source documents, and <b>made</b> the materials available to everyone, not just the first person to check the source document out of the library. The appendices that follow are a modern version of these \u201creading files.\u201d) I have extracted extensively from two sources: James Howard Kunstler\u2019s The Long Emergency (Grove Press, 2005) and Ellen Hodgson Brown\u2019s The Web of Debt (2 nd edition, Third Millennium Press, 2007, 2008. Kunstler\u2019s ...", "dateLastCrawled": "2022-01-17T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Discussion on Data Mining - <b>Assignment Den</b>", "url": "https://www.assignmentden.com/discussion-on-data-mining/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>assignmentden</b>.com/discussion-on-data-mining", "snippet": "medical: 2, <b>cost</b>: 3, increase: 2, patient: 2, health: 3, care: 1 Anomaly detection is the task of identifying observations whose characteristics are significantly different from the rest of the data. Such observations are known as anomalies or outliers. The goal of an anomaly detection algorithm is to discover the real anomalies and avoid falsely labeling normal objects as anomalous. In other words, a good anomaly detector must have a high detection rate and a low false alarm rate ...", "dateLastCrawled": "2022-02-03T12:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Pattern Recognition and Machine Learning</b> [PDF] - Free Online Publishing", "url": "https://authorzilla.com/GzDMv/pattern-recognition-and-machine-learning.html", "isFamilyFriendly": true, "displayUrl": "https://authorzilla.com/GzDMv/<b>pattern-recognition-and-machine-learning</b>.html", "snippet": "This particular <b>loss</b> matrix says that there is no <b>loss</b> incurred if the correct decision is <b>made</b>, there is a <b>loss</b> of 1 if a healthy patient is diagnosed as having cancer, whereas there is a <b>loss</b> of 1000 if a patient having cancer is diagnosed as healthy. The optimal solution is the one which minimizes the <b>loss</b> function. However, the <b>loss</b> function depends on the true class, which is unknown. For a given input vector x, our uncertainty in the true class is expressed through the joint ...", "dateLastCrawled": "2022-02-01T01:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Convergence Drives Acquisition and Alliance Strategies</b> - Security <b>Squared</b>", "url": "http://www.securitysquared.com/2010/07/convergence-drives-acquisition-and-alliance-strategies.html", "isFamilyFriendly": true, "displayUrl": "www.security<b>squared</b>.com/2010/07/<b>convergence-drives-acquisition-and-alliance-strategies</b>...", "snippet": "British <b>Cost</b> of living of ordinary people are always in the hands of the interests under the control ring up - because Chinese overloaded rail freight and logistics companies in order to apply for a wagon of the indicators, the additional <b>cost</b> of shipping outside of even of up to 5000-50000 yuan room, where the flow of these costs is unknown, but the source is clear enough - ordinary people <b>like</b> you and me.", "dateLastCrawled": "2022-01-12T20:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Numerical Methods for Engineers 7th Edition - <b>DOKUMEN.PUB</b>", "url": "https://dokumen.pub/numerical-methods-for-engineers-7th-edition.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/numerical-methods-for-engineers-7th-edition.html", "snippet": "16.1 Least-<b>Cost</b> Design of a Tank (Chemical/Bio Engineering) 416 16.2 Least-<b>Cost</b> Treatment of Wastewater (Civil/Environmental Engineering) 421 16.3 Maximum Power Transfer for a Circuit (Electrical Engineering) 425 16.4 Equilibrium and Minimum Potential Energy (Mechanical/Aerospace Engineering) 429 Problems 431 EPILOGUE: PART FOUR 438 PT4.4 Trade-Offs 438 PT4.5 Additional References 439", "dateLastCrawled": "2022-01-28T12:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Make No <b>Mistake</b> - dickyang, vageege - One <b>Piece</b> [Archive of Our Own]", "url": "https://archiveofourown.org/works/1592732?show_comments=true&view_full_work=true", "isFamilyFriendly": true, "displayUrl": "https://<b>archiveofourown.org</b>/works/1592732?show_comments=true&amp;view_full_work=true", "snippet": "<b>Like</b> the TV-B-Gone, an invention <b>made</b> by a student of his three years ago. It emitted 209 different turn-off codes for nearly every television. It was a little gray button on a keychain. It looked <b>like</b> a garage-door opener and it could turn off every television in a crowded bar. So awesome.", "dateLastCrawled": "2022-01-26T19:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Hands-On Transfer Learning with Python: Implement advanced deep ...", "url": "https://dokumen.pub/hands-on-transfer-learning-with-python-implement-advanced-deep-learning-and-neural-network-models-using-tensorflow-and-keras-1788831306-9781788831307.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/hands-on-transfer-learning-with-python-implement-advanced-deep...", "snippet": "<b>Hinge</b> <b>loss</b>/<b>squared</b>-<b>hinge</b> <b>loss</b>: <b>Hinge</b> <b>loss</b> is used in SVMs. They penalize marginally misclassified points differently. They are good alternatives to crossentropy <b>loss</b> and lead to faster training for neural networks as well. Higher-order <b>hinge</b> losses, such as <b>squared</b>-<b>hinge</b> losses, are even better for some classification tasks. Kullback-Leibler (KL) divergence: KL divergence is a measure of how one probability distribution diverges from a second expected probability distribution.", "dateLastCrawled": "2021-12-15T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning Additive Models Online with Fast Evaluating Kernels</b> | Request PDF", "url": "https://www.researchgate.net/publication/221497666_Learning_Additive_Models_Online_with_Fast_Evaluating_Kernels", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221497666_Learning_Additive_Models_Online...", "snippet": "In this <b>paper</b> we show the ... We thus have obtained a bound on the <b>squared</b> <b>hinge</b> <b>loss</b>. The same bound was also derived by Herbster [8]. We can immediately use this bound to derive a <b>mistake</b> bound ...", "dateLastCrawled": "2022-01-03T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Data Mining Practical Machine Learning Tools and Techniques</b> 3rd ...", "url": "https://www.academia.edu/23331284/Data_Mining_Practical_Machine_Learning_Tools_and_Techniques_3rd_Edition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/23331284/<b>Data_Mining_Practical_Machine_Learning_Tools</b>_and...", "snippet": "A short summary of this <b>paper</b>. 37 Full PDFs related to this <b>paper</b>. Read <b>Paper</b>. <b>Data Mining Practical Machine Learning Tools and Techniques</b> 3rd Edition. Download ...", "dateLastCrawled": "2022-01-30T15:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Answers to the practical questions and problems contained in the ...", "url": "https://quod.lib.umich.edu/m/moa/AJN2367.0001.001?rgn=main;view=fulltext", "isFamilyFriendly": true, "displayUrl": "https://<b>quod.lib.umich.edu</b>/m/moa/AJN2367.0001.001?rgn=main;view=fulltext", "snippet": "72. I. Olefiant gas may be <b>made</b> by heating in the flask one part, by measure, of alcohol and two parts of sulphuric acid. Pass it through a solution of potash, as shown on page 88, and then collect in the gas-bag. Fit <b>a piece</b> of glass tubing, drawn to a fine point at one end, to the stop-cock of the gas-bag by means of a bit of the rubber ...", "dateLastCrawled": "2022-02-02T11:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Numerical Methods for Engineers 7th Edition steven chapra</b> | Dana ...", "url": "https://www.academia.edu/31722261/Numerical_Methods_for_Engineers_7th_Edition_steven_chapra", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/31722261/<b>Numerical_Methods_for_Engineers_7th_Edition</b>_steven...", "snippet": "A short summary of this <b>paper</b>. 27 Full PDFs related to this <b>paper</b>. Read <b>Paper</b>. <b>Numerical Methods for Engineers 7th Edition steven chapra</b>. Download ...", "dateLastCrawled": "2022-02-02T16:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Errata</b> - O&#39;Reilly Media", "url": "https://www.oreilly.com/catalog/errata.csp?isbn=0636920052289", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/catalog/<b>errata</b>.csp?isbn=0636920052289", "snippet": "The former (cross-validation) is typically done on the training set: in K-<b>fold</b> CV, the training set is split into K pieces, and the same model *architecture* is trained K times (on the training set minus <b>piece</b> #i, for i in [1, K]), and then evaluated on the <b>piece</b> it was not trained on. The latter (evaluation of a trained model) is typically done on the validation set (when not using cross-validation) for model selection (which should be called model architecture &amp; hyperparameter selection ...", "dateLastCrawled": "2022-01-30T16:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Phrasal verbs list meanings and examples</b>", "url": "https://www.easypacelearning.com/all-lessons/grammar/1219-phrasal-verbs-list-meanings-and-examples", "isFamilyFriendly": true, "displayUrl": "https://www.easypacelearning.com/all-lessons/grammar/1219-<b>phrasal-verbs-list-meanings</b>...", "snippet": "The government should be <b>made</b> to ANSWER FOR their failure to sort out the problem. Answer for. Speak on behalf of someone or from knowing them. I can ANSWER FOR my partner because I know her position on this issue. Argue down. Beat someone in a debate, discussion or argument. The teacher tried to ARGUE the girl DOWN, but she couldn&#39;t. Argue down. Persuade someone to drop the price of something they&#39;re selling. She ARGUED him DOWN ten percent. Argue down. Try to persuade people not to accept ...", "dateLastCrawled": "2022-01-30T23:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Appendix:Glossary of U.S. Navy slang - Wiktionary", "url": "https://en.wiktionary.org/wiki/Appendix:Glossary_of_U.S._Navy_slang", "isFamilyFriendly": true, "displayUrl": "https://en.wiktionary.org/wiki/Appendix:G<b>loss</b>ary_of_U.S._Navy_slang", "snippet": "0-9: \u00b7Naval method of indicating the time of day aboard ship, usually over the 1MC. One bell corresponds to 30 minutes past the hour. Bells will only be rung as a single strike, or a closely spaced double strike, with a maximum of eight bells (4 sets of 2). Bells repeat themselves every 4 hours. For example 2 sets of 2 bells, followed by a single bell (5 total) could be 0230, 0630, 1030, 1430, 1830, or 2230.\u00b7 Method of requesting speed changes from the Engine Room using the Engine Order ...", "dateLastCrawled": "2022-02-03T05:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Dive into Deep Learning [0.16.1&amp;nbsp;ed.] - DOKUMEN.PUB", "url": "https://dokumen.pub/dive-into-deep-learning-0161nbsped.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/dive-into-deep-learning-0161nbsped.html", "snippet": "Thus, we need to compute the expected risk that we incur as the <b>loss</b> function, i.e., we need to multiply the probability of the outcome with the benefit (or harm) <b>associated</b> with it. In this case, the <b>loss</b> incurred by eating the mushroom can be 0.2\u00d7\u221e+0.8\u00d70 = \u221e, whereas the <b>loss</b> of discarding it is 0.2 \u00d7 0 + 0.8 \u00d7 1 = 0.8. Our caution was justified: as any mycologist would tell us, the mushroom in Fig. 1.3.2 actually is a death cap. Classification can get much more complicated than ...", "dateLastCrawled": "2022-01-02T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Make No <b>Mistake</b> - dickyang, vageege - One <b>Piece</b> [Archive of Our Own]", "url": "https://archiveofourown.org/works/1592732?show_comments=true&view_full_work=true", "isFamilyFriendly": true, "displayUrl": "https://<b>archiveofourown.org</b>/works/1592732?show_comments=true&amp;view_full_work=true", "snippet": "Usopp had <b>made</b> the <b>mistake</b> of informing Luffy that it was possible to modify his scooter to make it faster, and Luffy was way too enthusiastic over the idea, and Usopp hadn\u2019t planned on signing himself up for anything, what the hell, and Sanji was laughing at his misfortune as he lit a new cigarette from his regular spot on one of the barstools when there was a loud knock at the door.", "dateLastCrawled": "2022-01-26T19:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Hands-On Transfer Learning with Python: Implement advanced deep ...", "url": "https://dokumen.pub/hands-on-transfer-learning-with-python-implement-advanced-deep-learning-and-neural-network-models-using-tensorflow-and-keras-1788831306-9781788831307.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/hands-on-transfer-learning-with-python-implement-advanced-deep...", "snippet": "<b>Hinge</b> <b>loss</b>/<b>squared</b>-<b>hinge</b> <b>loss</b>: <b>Hinge</b> <b>loss</b> is used in SVMs. They penalize marginally misclassified points differently. They are good alternatives to crossentropy <b>loss</b> and lead to faster training for neural networks as well. Higher-order <b>hinge</b> losses, such as <b>squared</b>-<b>hinge</b> losses, are even better for some classification tasks. Kullback-Leibler (KL) divergence: KL divergence is a measure of how one probability distribution diverges from a second expected probability distribution.", "dateLastCrawled": "2021-12-15T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Research Project - Student Copy</b> | Aniruddha Ghosh - Academia.edu", "url": "https://www.academia.edu/8763852/Research_Project_Student_Copy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/8763852/<b>Research_Project_Student_Copy</b>", "snippet": "This <b>Paper</b>. A short summary of this <b>paper</b>. 31 Full PDFs related to this <b>paper</b>. Read <b>Paper</b>. <b>Research Project - Student Copy</b>. Download ...", "dateLastCrawled": "2022-02-01T04:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Answers to the practical questions and problems contained in the ...", "url": "https://quod.lib.umich.edu/m/moa/AJN2367.0001.001?rgn=main;view=fulltext", "isFamilyFriendly": true, "displayUrl": "https://<b>quod.lib.umich.edu</b>/m/moa/AJN2367.0001.001?rgn=main;view=fulltext", "snippet": "The test-tube <b>can</b> be held by a strip of twisted <b>paper</b> or wire. 59 At the close of the Ist exp. perform the one figured on page 79. A small <b>piece</b> of wire-gauze, 4 or 6 inches square, for this purpose <b>can</b> be purchased of any tinsmith. If you do not force the gas out too rapidly, you will be able to burn it on either side of the gauze at pleasure.", "dateLastCrawled": "2022-02-02T11:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Theories and Manifestoes of Contemporary Architecture</b> | Johana C ...", "url": "https://www.academia.edu/26570192/Theories_and_Manifestoes_of_Contemporary_Architecture", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/26570192", "snippet": "A short summary of this <b>paper</b>. 30 Full PDFs related to this <b>paper</b>. Read <b>Paper</b>. <b>Theories and Manifestoes of Contemporary Architecture</b>. Download ...", "dateLastCrawled": "2022-02-01T20:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "best way to cut <b>hinge</b> mortises \ud83d\ude16John The Woodworking", "url": "https://rishiraj.info/best-way-to-cut-hinge-mortises.bing?bestwaycut=mortisesbesthinge", "isFamilyFriendly": true, "displayUrl": "https://rishiraj.info/best-way-to-cut-<b>hinge</b>-mortises.bing?bestwaycut=mortisesbest<b>hinge</b>", "snippet": "Now you <b>can</b> attach with tape <b>a piece</b> of cardboard as a backing where the art <b>paper</b> will be placed. You <b>can</b> add a binder clip at the top to hold the <b>paper</b>.|(6) 3/4\u201d x 36\u201d PVC pipe (2) 3/4\u201d x 28\u201d PVC pipe (4) 3/4\u201d x 12\u201d PVC pipe", "dateLastCrawled": "2022-01-02T10:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Errata</b> - O&#39;Reilly Media", "url": "https://www.oreilly.com/catalog/errata.csp?isbn=0636920052289", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/catalog/<b>errata</b>.csp?isbn=0636920052289", "snippet": "I initially <b>thought</b> that this function would be self-explanatory, given its name and the fact that it is used to compute the mean of the <b>squared</b> error, but I agree that the name <b>can</b> actually be confusing: it is somewhat unfortunate that they didn&#39;t just name it &quot;mean()&quot; instead of &quot;reduce_mean()&quot;, as it&#39;s really analogous to NumPy&#39;s mean() function. To clarify this, I added the following line: --- * The `reduce_mean()` function creates a node in the graph that will compute the mean of its ...", "dateLastCrawled": "2022-01-30T16:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Discussion on Data Mining - <b>Assignment Den</b>", "url": "https://www.assignmentden.com/discussion-on-data-mining/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>assignmentden</b>.com/discussion-on-data-mining", "snippet": "mining standards are the subject of a <b>paper</b> by Grossman et al. [24]. Bradley [7] discusses how data mining algorithms <b>can</b> be scaled to large data sets. The emergence of new data mining applications has produced new challenges that need to be addressed. For instance, concerns about privacy breaches as a result of data mining have escalated in recent years, particularly in application domains such as web commerce and health care. As a result, there is growing interest in developing data mining ...", "dateLastCrawled": "2022-02-03T12:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Convergence Drives Acquisition and Alliance Strategies</b> - Security <b>Squared</b>", "url": "http://www.securitysquared.com/2010/07/convergence-drives-acquisition-and-alliance-strategies.html", "isFamilyFriendly": true, "displayUrl": "www.security<b>squared</b>.com/2010/07/<b>convergence-drives-acquisition-and-alliance-strategies</b>...", "snippet": "One <b>can</b> be <b>made</b> from chrysanthemum flowers porridge Oral; two <b>can</b> be smashed with the egg white mix Fumian <b>can</b> whiten the skin. Or the petals of the lily lily white liquid into the bottle, sealed after the injection of alcohol, in January, with its 2-<b>fold</b> dilution of cold water on the skin whitening effect, especially for oily skin better. 3", "dateLastCrawled": "2022-01-12T20:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Dive into Deep Learning [0.16.1&amp;nbsp;ed.] - DOKUMEN.PUB", "url": "https://dokumen.pub/dive-into-deep-learning-0161nbsped.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/dive-into-deep-learning-0161nbsped.html", "snippet": "In this case, the <b>loss</b> incurred by eating the mushroom <b>can</b> be 0.2\u00d7\u221e+0.8\u00d70 = \u221e, whereas the <b>loss</b> of discarding it is 0.2 \u00d7 0 + 0.8 \u00d7 1 = 0.8. Our caution was justified: as any mycologist would tell us, the mushroom in Fig. 1.3.2 actually is a death cap. Classification <b>can</b> get much more complicated than just binary, multiclass, or even multi-label classification. For instance, there are some variants of classification for addressing hierarchies. Hierarchies assume that there exist some ...", "dateLastCrawled": "2022-01-02T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "_empty_ Crossword Clue Answers", "url": "https://www.crosswordsolver.org/clues/0/empty.291901", "isFamilyFriendly": true, "displayUrl": "https://www.crosswordsolver.org/clues/0/empty.291901", "snippet": "any projection that is <b>thought</b> to resemble a human arm; &quot;the arm of the record player&quot;; &quot;an arm of the sea&quot;; &quot;a branch of the sewer&quot; the part of a garment that is attached at the armhole and that provides a cloth covering for the arm ; prepare oneself for a military confrontation; &quot;The U.S. is girding for a conflict in the Middle East&quot;; &quot;troops are building up on the Iraqi border&quot; any instrument or instrumentality used in fighting or hunting; &quot;he was licensed to carry a weapon&quot; supply with ...", "dateLastCrawled": "2022-02-02T14:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Hands-On Transfer Learning with Python: Implement advanced deep ...", "url": "https://dokumen.pub/hands-on-transfer-learning-with-python-implement-advanced-deep-learning-and-neural-network-models-using-tensorflow-and-keras-1788831306-9781788831307.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/hands-on-transfer-learning-with-python-implement-advanced-deep...", "snippet": "<b>Hinge</b> <b>loss</b>/<b>squared</b>-<b>hinge</b> <b>loss</b>: <b>Hinge</b> <b>loss</b> is used in SVMs. They penalize marginally misclassified points differently. They are good alternatives to crossentropy <b>loss</b> and lead to faster training for neural networks as well. Higher-order <b>hinge</b> losses, such as <b>squared</b>-<b>hinge</b> losses, are even better for some classification tasks. Kullback-Leibler (KL) divergence: KL divergence is a measure of how one probability distribution diverges from a second expected probability distribution.", "dateLastCrawled": "2021-12-15T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning Additive Models Online with Fast Evaluating Kernels</b> | Request PDF", "url": "https://www.researchgate.net/publication/221497666_Learning_Additive_Models_Online_with_Fast_Evaluating_Kernels", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221497666_Learning_Additive_Models_Online...", "snippet": "We thus have obtained a bound on the <b>squared</b> <b>hinge</b> <b>loss</b>. The same bound was also derived by Herbster [8] . We <b>can</b> immediately use this bound to derive a <b>mistake</b> bound for the PA algorithm. ...", "dateLastCrawled": "2022-01-03T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "170 Machine Learning Interview Question and Answers in 2022", "url": "https://www.mygreatlearning.com/blog/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreatlearning.com/blog/<b>machine-learning-interview-questions</b>", "snippet": "Given an array of integers where each element represents the max number of steps that <b>can</b> be <b>made</b> forward from that element. The task is to find the minimum number of jumps to reach the end of the array (starting from the first element). If an element is 0, then cannot move through that element. Solution: This problem is famously called as end of array problem. We want to determine the minimum number of jumps required in order to reach the end. The element in the array represents the maximum ...", "dateLastCrawled": "2022-02-03T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Discussion on Data Mining - <b>Assignment Den</b>", "url": "https://www.assignmentden.com/discussion-on-data-mining/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>assignmentden</b>.com/discussion-on-data-mining", "snippet": "<b>Compared</b> to more traditional research in social science, which is often based on surveys, this analysis requires a broader range of skills and tools, and involves far larger amounts of data. Thus, data science is, by necessity, a highly interdisciplinary field that builds on the continuing work of many fields. The data-driven approach of data science emphasizes the direct discovery of patterns and relationships from data, especially in large quantities of data, often without the need for ...", "dateLastCrawled": "2022-02-03T12:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Pattern Recognition and Machine Learning</b> [PDF] - Free Online Publishing", "url": "https://authorzilla.com/GzDMv/pattern-recognition-and-machine-learning.html", "isFamilyFriendly": true, "displayUrl": "https://authorzilla.com/GzDMv/<b>pattern-recognition-and-machine-learning</b>.html", "snippet": "Thus the consequences of these two types of <b>mistake</b> <b>can</b> be dramatically different. It would clearly be better to make fewer mistakes of the second kind, even if this was at the expense of making more mistakes of the rst kind. We <b>can</b> formalize such issues through the introduction of a <b>loss</b> function, also called a <b>cost</b> function, which is a single, overall measure of <b>loss</b> incurred in taking any of the available decisions or actions. Our goal is then to minimize the total <b>loss</b> incurred. Note ...", "dateLastCrawled": "2022-02-01T01:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Convergence Drives Acquisition and Alliance Strategies</b> - Security <b>Squared</b>", "url": "http://www.securitysquared.com/2010/07/convergence-drives-acquisition-and-alliance-strategies.html", "isFamilyFriendly": true, "displayUrl": "www.security<b>squared</b>.com/2010/07/<b>convergence-drives-acquisition-and-alliance-strategies</b>...", "snippet": "lighters <b>made</b> in China, 75% of DVD players <b>made</b> in China, 60 percent of the jeans <b>made</b> in China, <b>Made</b> in China spread globally in the context that gave birth to another paradox - the same paragraph commodities, domestic prices higher than abroad. RMB and U.S. dollars in foreign trade transactions are often the game to start in China exports $ 1 for each commodity, we must follow the domestic exchange rate of RMB and U.S. dollar <b>compared</b> with the corresponding number of additional RMB to ...", "dateLastCrawled": "2022-01-12T20:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>The Late Great United States: The Decline and</b> Fall of the United States ...", "url": "http://www.foundationwebsite.org/TheLateGreatUnitedStatesAppendices.htm", "isFamilyFriendly": true, "displayUrl": "www.foundationwebsite.org/<b>TheLateGreatUnitedStates</b>Appendices.htm", "snippet": "This reduced the <b>cost</b> <b>associated</b> with acquiring original source documents, and <b>made</b> the materials available to everyone, not just the first person to check the source document out of the library. The appendices that follow are a modern version of these \u201creading files.\u201d) I have extracted extensively from two sources: James Howard Kunstler\u2019s The Long Emergency (Grove Press, 2005) and Ellen Hodgson Brown\u2019s The Web of Debt (2 nd edition, Third Millennium Press, 2007, 2008. Kunstler\u2019s ...", "dateLastCrawled": "2022-01-17T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Educational perspectives on exploratory data analysis", "url": "https://unesdoc.unesco.org/ark:/48223/pf0000097822", "isFamilyFriendly": true, "displayUrl": "https://unesdoc.unesco.org/ark:/48223/pf0000097822", "snippet": "Albrecht Abele\u2019s experiences of <b>trying</b> to teach statistics to slow- learning pupils has convinced him that success <b>can</b> grow only out of a rich experience of facing a variety of problems drawn from the environment, or from playing games of chance and taking part in lotteries. He illustrates his approach by giving instances of projects under three broad headings: the collection and representation of data, issues of quantification and random sampling. Part 3 of the volume is a collection of ...", "dateLastCrawled": "2022-02-02T19:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Resource Center - <b>PrintNinja</b>", "url": "https://printninja.com/printing-resource-center/", "isFamilyFriendly": true, "displayUrl": "https://<b>printninja</b>.com/printing-resource-center", "snippet": "Starting with a white <b>piece</b> <b>of paper</b>, which reflects every color of light, we <b>can</b> use Cyan, Magenta, and Yellow inks to subtract specific colors of light to make a wide gamut of colors. Theoretically, combining Cyan, Magenta, and Yellow ink makes black, but because inks are not perfectly aligned to our RGB vision, we also add blacK ink (Key), which reflects no light, to help provide darker tones and truer blacks.", "dateLastCrawled": "2022-02-02T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Amazon.com. Spend less. Smile more.", "url": "https://www.amazon.com/", "isFamilyFriendly": true, "displayUrl": "https://www.amazon.com", "snippet": "Free shipping on millions of items. Get the best of Shopping and Entertainment with Prime. Enjoy low prices and great deals on the largest selection of everyday essentials and other products, including fashion, home, beauty, electronics, Alexa Devices, sporting goods, toys, automotive, pets, baby, books, video games, musical instruments, office supplies, and more.", "dateLastCrawled": "2022-02-02T22:30:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "<b>Squared</b> <b>loss</b> (for regression) <b>Hinge</b> <b>loss</b> (SVM) Logistic/log <b>loss</b> (logistic regression) Some <b>loss</b> functions are as follows: When to stop tuning <b>machine</b> <b>learning</b> models. When to stop tuning the hyperparameters in a <b>machine</b> <b>learning</b> model is a million-dollar question. This problem can be mostly solved by keeping tabs on training and testing errors. While increasing the complexity of a model, the following stages occur: Stage 1: Underfitting stage \u2013 high train and high test errors (or low ...", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Data Science: <b>Support Vector Machines (SVM</b>)", "url": "https://www.datasciencesmachinelearning.com/2019/01/support-vector-machines-svm.html", "isFamilyFriendly": true, "displayUrl": "https://www.datasciences<b>machinelearning</b>.com/2019/01/<b>support-vector-machines-svm</b>.html", "snippet": "In this case, <b>squared</b> <b>hinge</b> <b>loss</b> function (as against <b>hinge</b> <b>loss</b> function) and l2 penalty are the major changes compared to the earlier three methods. This method is useful for when sample size is larger.", "dateLastCrawled": "2022-01-28T08:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Introduction to <b>Machine</b> <b>Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-machine-learning-3/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-<b>machine</b>-<b>learning</b>-3", "snippet": "However, in <b>machine</b> <b>learning</b> methodology, <b>squared</b> <b>loss</b> will be minimized with respect to ... <b>Squared</b> <b>loss</b> (for regression) <b>Hinge</b> <b>loss</b> (SVM) Logistic/log <b>loss</b> (logistic regression) Some <b>loss</b> functions are as follows: When to stop tuning <b>machine</b> <b>learning</b> models. When to stop tuning the hyperparameters in a <b>machine</b> <b>learning</b> model is a million-dollar question. This problem can be mostly solved by keeping tabs on training and testing errors. While increasing the complexity of a model, the ...", "dateLastCrawled": "2022-01-28T18:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A study on L2-<b>loss (Squared Hinge-Loss) multiclass SVM</b> | Request PDF", "url": "https://www.researchgate.net/publication/235884495_A_study_on_L2-loss_Squared_Hinge-Loss_multiclass_SVM", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/235884495_A_study_on_L2-<b>loss</b>_<b>Squared</b>_<b>Hinge</b>...", "snippet": "Taking the <b>analogy</b> to classification task, it has been previously studied [13] that using the <b>squared</b> <b>hinge</b> <b>loss</b> in SVM would yield better accuracy when \u03bb is large. In this case, underfitting ...", "dateLastCrawled": "2021-12-14T01:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Metrics to Evaluate Classification and Regression Algorithms | by ...", "url": "https://medium.com/@poojitha.penmethsa/metrics-to-evaluate-classification-and-regression-algorithms-1554f1e00a75", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@poojitha.penmethsa/metrics-to-evaluate-classification-and...", "snippet": "<b>Hinge</b> <b>loss</b>. cross-entropy <b>loss</b> / log <b>loss</b>. likelihood <b>loss</b>. MSE / Quadratic <b>loss</b> / L2 <b>loss</b>: Mean <b>Squared</b> Error, or MSE <b>loss</b> is the default <b>loss</b> to use for regression problems. Mathematically, it ...", "dateLastCrawled": "2022-01-17T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Understanding the 3 most common <b>loss</b> functions for <b>Machine</b> <b>Learning</b> ...", "url": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-the-3-most-common-<b>loss</b>-functions-for...", "snippet": "A <b>loss function</b> in <b>Machine</b> <b>Learning</b> is a measure of how accurately your ML model is able to predict the expected outcome i.e the ground truth. The <b>loss function</b> will take two items as input: the output value of our model and the ground truth expected value. The output of the <b>loss function</b> is called the <b>loss</b> which is a measure of how well our model did at predicting the outcome. A high value for the <b>loss</b> means our model performed very poorly. A low value for the <b>loss</b> means our model performed ...", "dateLastCrawled": "2022-02-02T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning with Shallow Neural Networks: A Textbook</b> | Request PDF", "url": "https://www.researchgate.net/publication/327232162_Machine_Learning_with_Shallow_Neural_Networks_A_Textbook", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/327232162_<b>Machine</b>_<b>Learning</b>_with_Shallow...", "snippet": "We propose a backpropagation <b>learning</b> algorithm that uses a <b>squared</b> <b>hinge</b> <b>loss</b> function to maximize the margins between labels to train this network. The results show that our model outperforms ...", "dateLastCrawled": "2021-10-22T08:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Scikit Learn - Stochastic Gradient Descent</b>", "url": "https://www.tutorialspoint.com/scikit_learn/scikit_learn_stochastic_gradient_descent.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/scikit_learn/<b>scikit_learn_stochastic_gradient_descent</b>.htm", "snippet": "The default value is \u2018<b>hinge</b>\u2019 which will give us a linear SVM. The other options which can be used are \u2212. log \u2212 This <b>loss</b> will give us logistic regression i.e. a probabilistic classifier. modified_huber \u2212 a smooth <b>loss</b> that brings tolerance to outliers along with probability estimates. <b>squared</b>_<b>hinge</b> \u2212 similar to \u2018<b>hinge</b>\u2019 <b>loss</b> but ...", "dateLastCrawled": "2022-02-03T02:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "CPSC 340: Data Mining <b>Machine</b> <b>Learning</b>", "url": "https://www.cs.ubc.ca/~schmidtm/Courses/340-F16/L35.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~schmidtm/Courses/340-F16/L35.pdf", "snippet": "<b>Machine</b> <b>Learning</b> and Data Mining Course Review/Preview Fall 2016 Some images from this lecture are taken from Google Image Search. Admin \u2022Assignment 6: \u20131 late day to hand in next Monday, 2 for Wednesday, 3 for Friday. \u2022Final: \u2013December 12 (8:30am \u2013HEBB 100) \u2013Covers Assignments 1-6. \u2013List of topics posted. \u2013Final from last year will be posted after class. \u2013Closed-book, cheat sheet: 4-pages each double-sided. Last Time: Semi-Supervised <b>Learning</b> \u2022In semi-supervised <b>learning</b> ...", "dateLastCrawled": "2021-11-22T01:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning for Economists: Part 1 \u2013 Criterion Functions</b>", "url": "https://michalandrle.weebly.com/uploads/1/3/9/2/13921270/imf_ml_1_lossfun.pdf", "isFamilyFriendly": true, "displayUrl": "https://michalandrle.weebly.com/uploads/1/3/9/2/13921270/imf_ml_1_<b>loss</b>fun.pdf", "snippet": "<b>Machine Learning for Economists: Part 1 \u2013 Criterion Functions</b> Michal Andrle International Monetary Fund Washington, D.C., October, 2018. Disclaimer #1: The views expressed herein are those of the authors and should not be attributed to the International Monetary Fund, its Executive Board, or its management. <b>LOSS</b> FUNCTIONS. <b>Loss</b> Functions in Algorithm Training <b>loss</b> function model/algorithm parameters classication regression train predict. Decisions and <b>Loss</b> Function Choice (A) <b>Loss</b> ...", "dateLastCrawled": "2021-11-18T03:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>About loss and loss functions</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2019/10/04/about-loss-and-loss-functions/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2019/10/04/<b>about-loss-and-loss-functions</b>", "snippet": "We\u2019re then using <b>machine</b> <b>learning</b> for ... The <b>squared hinge loss is like</b> the hinge formula displayed above, but then the \\(max()\\) function output is squared. This helps achieving two things: Firstly, it makes the loss value more sensitive to outliers, just as we saw with MSE vs MAE. Large errors will add to the loss more significantly than smaller errors. Note that simiarly, this may also mean that you\u2019ll need to inspect your dataset for the presence of such outliers first. Secondly ...", "dateLastCrawled": "2022-01-25T13:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "\u635f\u5931\u51fd\u6570 - \u7b97\u6cd5\u6742\u8d27\u94fa - bjmsong.github.io", "url": "https://bjmsong.github.io/2020/02/21/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/", "isFamilyFriendly": true, "displayUrl": "https://bjmsong.github.io/2020/02/21/\u635f\u5931\u51fd\u6570", "snippet": "the training data is fed into the <b>machine</b> <b>learning</b> model; Loss : compare between some actual targets and predicted targets; the lower the loss, the more the set of targets and the set of predictions resemble each other; the more they resemble each other, the better the <b>machine</b> <b>learning</b> model performs. Backward pass", "dateLastCrawled": "2021-12-27T11:43:00.0000000Z", "language": "zh_chs", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(squared hinge loss)  is like +(cost associated with a mistake made when trying to fold a piece of paper in half)", "+(squared hinge loss) is similar to +(cost associated with a mistake made when trying to fold a piece of paper in half)", "+(squared hinge loss) can be thought of as +(cost associated with a mistake made when trying to fold a piece of paper in half)", "+(squared hinge loss) can be compared to +(cost associated with a mistake made when trying to fold a piece of paper in half)", "machine learning +(squared hinge loss AND analogy)", "machine learning +(\"squared hinge loss is like\")", "machine learning +(\"squared hinge loss is similar\")", "machine learning +(\"just as squared hinge loss\")", "machine learning +(\"squared hinge loss can be thought of as\")", "machine learning +(\"squared hinge loss can be compared to\")"]}