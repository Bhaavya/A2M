{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "5 Types of <b>bias</b> &amp; how to eliminate them in your <b>machine</b> <b>learning</b> ...", "url": "https://towardsdatascience.com/5-types-of-bias-how-to-eliminate-them-in-your-machine-learning-project-75959af9d3a0", "isFamilyFriendly": true, "displayUrl": "https://<b>towards</b>datascience.com/5-types-of-<b>bias</b>-how-to-eliminate-them-in-your-<b>machine</b>...", "snippet": "T he following is a devastating truth about a <b>biased</b> <b>machine</b> <b>learning</b> program that happened in real life. It is safe to say that the following is an example of the reasons why racism still exists. It\u2019s what I\u2019d <b>like</b> to start with to show you how important it is to fix any <b>bias</b> in your AI program. Compas. Developed by a private company called Equiv a nt (formerly Northpointe). Compas is a <b>machine</b> <b>learning</b> <b>algorithm</b> that predicts the defendant\u2019s likelihoods to commit crimes, it has been ...", "dateLastCrawled": "2022-01-26T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Bias in Machine Learning</b> &amp; Deep <b>Learning</b>?", "url": "https://www.foreseemed.com/blog/bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.foreseemed.com/blog/<b>bias-in-machine-learning</b>", "snippet": "<b>Bias in machine learning</b> can be applied when collecting the data to build the models. It can come with testing the outputs of the models to verify their validity. <b>Bias</b> <b>machine</b> <b>learning</b> can even be applied when interpreting valid or invalid results from an approved data model. Nearly all of the common <b>machine</b> <b>learning</b> <b>biased</b> data types come from ...", "dateLastCrawled": "2022-02-02T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Survey on <b>Bias</b> and <b>Fairness in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/a-survey-on-bias-and-fairness-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-survey-on-<b>bias</b>-and-<b>fairness-in-machine-learning</b>", "snippet": "Therefore, they propose a calibration <b>algorithm</b> called RBA (reducing <b>bias</b> amplification); RBA is a debiasing technique for calibrating <b>prediction</b> in structured <b>prediction</b> models. The idea behind RBA is to force constraints to ensure that the model predictions follow the same distribution in the training data. They study two cases: visual semantic role labeling and multi-label object classification. They show how these methods exemplify the existing <b>bias</b> in data.", "dateLastCrawled": "2022-01-22T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Eliminating AI <b>Bias</b>. Identifying AI <b>Bias</b> and knowing how to\u2026 | by ...", "url": "https://towardsdatascience.com/eliminating-ai-bias-5b8462a84779", "isFamilyFriendly": true, "displayUrl": "https://<b>towards</b>datascience.com/eliminating-ai-<b>bias</b>-5b8462a84779", "snippet": "As AI algorithms can have long-term impact s on an organisation\u2019s reputation and severe consequences for the public, it is important to ensure that they are not <b>biased</b> <b>towards</b> <b>a particular</b> subgroup within a population. In layman\u2019s terms, algorithmic <b>bias</b> within AI algorithms occurs when the <b>outcome</b> is a lack of fairness or a favouritism <b>towards</b> one group due to a specific categorical distinction, where the categories are ethnicity, age, gender, qualifications, disabilities, and ...", "dateLastCrawled": "2022-02-02T06:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding <b>Bias</b> in <b>Machine</b> <b>Learning</b> - lexalytics.com", "url": "https://www.lexalytics.com/resources/Lexalytics_Understanding_Bias_In_Machine_Learning_WhitePaper.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.lexalytics.com/resources/Lexalytics_Understanding_<b>Bias</b>_In_<b>Machine</b>_<b>Learning</b>...", "snippet": "Perceptive <b>Bias</b> Many <b>machine</b> <b>learning</b> (ML) training tasks seek to replicate human judgments, and those judgments may be based on existing conscious or unconscious biases. In a project at Lexalytics, we analyzed the sentiment phrases from employee reviews at <b>a particular</b> company and found the most gendered examples. Male employees were praised for being \u201cproactive,\u201d and frequently received strong compliments <b>like</b> \u201csignificant\u201d and \u201csuccessful.\u201d Female employees were praised for ...", "dateLastCrawled": "2022-02-01T16:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Comparing different supervised <b>machine</b> <b>learning</b> algorithms for disease ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6925840/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6925840", "snippet": "For these reasons, we used both \u201c<b>machine</b> <b>learning</b>\u201d and \u201cdata mining\u201d in the search terms although the focus of this study is on the supervised <b>machine</b> <b>learning</b> <b>algorithm</b>. The four search items were then considered to launch searches on the titles, abstracts and keywords of an article for both Scopus and PubMed. This resulted in 305 and 83 articles from Scopus and PubMed, respectively. After combining these two lists of articles and removing the articles written in languages other ...", "dateLastCrawled": "2022-01-28T14:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b> 99+ Most Important MCQ Part-2 | <b>Machine</b> <b>Learning</b> MCQ ...", "url": "https://www.jobsaarnee.com/2021/06/machine-learning-100-most-important-mcq-part2.html", "isFamilyFriendly": true, "displayUrl": "https://www.jobsaarnee.com/2021/06/<b>machine</b>-<b>learning</b>-100-most-important-mcq-part2.html", "snippet": "FIND-S <b>algorithm</b> ignores negative examples that&#39;s why we come up with candidate elimination <b>algorithm</b>. Q 6. Regarding <b>bias</b> and variance, which of the following statements are true?(Here &#39;high&#39; and &#39;low&#39; are relative to the idea model.) (A) Models which overfit have a high <b>bias</b>. (B) Models which overfit have a low <b>bias</b>. (C) Models which underfit have a high variance. (D) None of these Sol. Models which overfit have a low <b>bias</b>. Explanation: Models which overfit have a low <b>bias</b>. Models which ...", "dateLastCrawled": "2022-02-03T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Bias in Artificial Intelligence</b>. How <b>bias</b> can explode our AI models ...", "url": "https://adabhishekdabas.medium.com/bias-in-artificial-intelligence-d2ccec3abb2b", "isFamilyFriendly": true, "displayUrl": "https://adabhishekdabas.medium.com/<b>bias-in-artificial-intelligence</b>-d2ccec3abb2b", "snippet": "2. Prejudice <b>Bias</b>: It is a result of cultural influences and stereotypes. Things that a person doesn\u2019t <b>like</b> in reality <b>like</b> appearances, social class, gender, and others get reflected in the data. For Example, Some people are more <b>biased</b> <b>towards</b> <b>a particular</b> political affiliation or religion or sex, while others might disagree with that view ...", "dateLastCrawled": "2022-01-30T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "5 <b>Algorithms that Demonstrate Artificial Intelligence Bias - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/5-algorithms-that-demonstrate-artificial-intelligence-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/5-<b>algorithms-that-demonstrate-artificial-intelligence-bias</b>", "snippet": "And while it hurts the groups that the <b>algorithm</b> is <b>biased</b> against, it also hurts the trust of humans in the artificial intelligence algorithms to work without <b>bias</b>. It reduces the chances of Artificial Intelligence being used in all aspects of business and industry as this produces mistrust and the fear that people may be discriminated against. So technical industries that produce these artificial intelligence algorithms need to ensure that their algorithms are <b>bias</b>-free before releasing ...", "dateLastCrawled": "2022-02-02T23:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>The Problem of Biased Algorithms and How to Prevent</b> Them | DataScience.US", "url": "https://www.datascience.us/problem-biased-algorithms-prevent/", "isFamilyFriendly": true, "displayUrl": "https://www.datascience.us/problem-<b>biased</b>-<b>algorithms</b>-prevent", "snippet": "Very rarely is it the intent of an <b>algorithm</b>\u2019s creator to create an <b>algorithm</b> that is <b>biased</b> or discriminatory. In fact, algorithms <b>like</b> the kind the used to determine the likelihood of paying back a loan from a bank are often intended to be as non-discriminatory as possible. A <b>machine</b> <b>learning</b> <b>algorithm</b> is not usually trained on variables <b>like</b> race, sex, or similar variables that could be used to treat someone in a <b>biased</b> way. Instead it could be trained on things <b>like</b> the words used in ...", "dateLastCrawled": "2022-02-02T00:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Racially Unbiased, <b>Machine</b> <b>Learning</b> Approach to <b>Prediction</b> of ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7644374/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7644374", "snippet": "To assess whether the <b>machine</b> <b>learning</b> <b>algorithm</b> and each comparator identified <b>similar</b> at-risk individuals, the McNemar test was used, comparing performance of the two systems at a sensitivity around 0.75. Performance was assessed both on the overall sample and after stratifying by race. Racial categories were defined as white and nonwhite, where only non-Hispanic white patients were included in the white category (eg, a white Hispanic patient was considered nonwhite for the purpose of this ...", "dateLastCrawled": "2021-12-18T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Is your <b>Machine Learning</b> Model <b>Biased</b>? | by Parul Pandey | <b>Towards</b> Data ...", "url": "https://towardsdatascience.com/is-your-machine-learning-model-biased-94f9ee176b67", "isFamilyFriendly": true, "displayUrl": "https://<b>towards</b>datascience.com/is-your-<b>machine-learning</b>-model-<b>biased</b>-94f9ee176b67", "snippet": "<b>Machine learning</b> models are being increasingly used to make decisions that affect people\u2019s lives. With this power comes a responsibility to ensure that the model predictions are fair and not discriminating. ProPublica, an independent, investigative journalism outfit, came out with a disturbing story on May 23, 2016, titled <b>Machine</b> <b>Bias</b>. It highlighted a significant <b>bias</b> in the US judicial system, citing an example of an 18-year-old girl named Brisha Borden. In 2014, Brisha was arrested for ...", "dateLastCrawled": "2022-02-01T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is <b>Bias in Machine Learning</b> &amp; Deep <b>Learning</b>?", "url": "https://www.foreseemed.com/blog/bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.foreseemed.com/blog/<b>bias-in-machine-learning</b>", "snippet": "<b>Similar</b> to observational studies, how the deep <b>learning</b> and <b>machine</b> <b>learning</b> models are planned, developed, tested, analyzed, and deployed can lead to removing <b>bias</b> inherent in all systems. At ForeSee Medical , we have a dedicated team of clinicians, medical NLP linguists and <b>machine</b> <b>learning</b> experts focused on understanding, tracking and mitigating <b>bias</b> within our HCC risk adjustment coding data models.", "dateLastCrawled": "2022-02-02T23:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Comparing different supervised <b>machine</b> <b>learning</b> algorithms for disease ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6925840/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6925840", "snippet": "For these reasons, we used both \u201c<b>machine</b> <b>learning</b>\u201d and \u201cdata mining\u201d in the search terms although the focus of this study is on the supervised <b>machine</b> <b>learning</b> <b>algorithm</b>. The four search items were then considered to launch searches on the titles, abstracts and keywords of an article for both Scopus and PubMed. This resulted in 305 and 83 articles from Scopus and PubMed, respectively. After combining these two lists of articles and removing the articles written in languages other ...", "dateLastCrawled": "2022-01-28T14:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Label <b>Bias</b> Identification in ML model using Python code | by Prasenjit ...", "url": "https://towardsdatascience.com/label-bias-identification-in-ml-model-using-python-code-a0fec9febaa6", "isFamilyFriendly": true, "displayUrl": "https://<b>towards</b>datascience.com/label-<b>bias</b>-identification-in-ml-model-using-python-code...", "snippet": "Therefore it is of utmost importance to ensure that the <b>outcome</b> of the <b>machine</b> <b>learning</b> model <b>prediction</b> is not <b>biased</b> <b>towards</b> any <b>particular</b> protected class variables like gender, ethnicity, nationality. I would highlight two key metrics here which would help in identifying if there exists any <b>bias</b> in the model <b>outcome</b>. a)Disparate Impact \u2014 which occurs when a selection process has widely different outcomes for different groups. One of the ways to measure is to see the distribution of the ...", "dateLastCrawled": "2022-01-29T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Fairness and Biases in Machine Learning</b> - Synthesized Blog", "url": "https://www.synthesized.io/post/fairness-and-biases-in-machine-learning-and-their-impact-on-banking-and-insurance", "isFamilyFriendly": true, "displayUrl": "https://www.synthesized.io/post/<b>fairness-and-biases-in-machine-learning</b>-and-their...", "snippet": "If the dataset has <b>bias</b> then a <b>machine</b> <b>learning</b> <b>algorithm</b> will factor it in when making a <b>prediction</b>. This is the nature of algorithms. For example, assume there is a <b>bias</b> <b>towards</b> a minority group committing a crime in a given dataset, as a result of not enough people being analysed and taken into account. If there is only a minority group of people present in the area the crime will naturally be higher by that group, but that doesn\u2019t mean the minority group is actually prone to committing ...", "dateLastCrawled": "2022-01-31T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>The Problem of Biased Algorithms and How to Prevent</b> Them | DataScience.US", "url": "https://www.datascience.us/problem-biased-algorithms-prevent/", "isFamilyFriendly": true, "displayUrl": "https://www.datascience.us/problem-<b>biased</b>-<b>algorithms</b>-prevent", "snippet": "Very rarely is it the intent of an <b>algorithm</b>\u2019s creator to create an <b>algorithm</b> that is <b>biased</b> or discriminatory. In fact, algorithms like the kind the used to determine the likelihood of paying back a loan from a bank are often intended to be as non-discriminatory as possible. A <b>machine</b> <b>learning</b> <b>algorithm</b> is not usually trained on variables like race, sex, or <b>similar</b> variables that could be used to treat someone in a <b>biased</b> way. Instead it could be trained on things like the words used in ...", "dateLastCrawled": "2022-02-02T00:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Bias In, Bias Out? Evaluating the Folk Wisdom</b> | DeepAI", "url": "https://deepai.org/publication/bias-in-bias-out-evaluating-the-folk-wisdom", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>bias-in-bias-out-evaluating-the-folk-wisdom</b>", "snippet": "The typical \u201c<b>bias</b> in, <b>bias</b> out\u201d result can be obtained if either i) the <b>algorithm</b> is instead trained to predict the human decision, or ii) the <b>outcome</b> of interest is assumed to be zero for those not selected by the human decision-maker. Second, while we assume that selection into the training data is determined by a <b>biased</b> decision-making process, we assume that the label of interest is measured without <b>bias</b>. This rules out \u201clabel <b>bias</b>,\u201d an additional source of <b>bias</b> in training data ...", "dateLastCrawled": "2022-01-12T06:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Machine</b> <b>Learning</b> Based Photovoltaics (PV) Power <b>Prediction</b> Using ...", "url": "https://www.researchgate.net/publication/334599389_Machine_Learning_Based_Photovoltaics_PV_Power_Prediction_Using_Different_Environmental_Parameters_of_Qatar", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334599389_<b>Machine</b>_<b>Learning</b>_Based_Photovoltaic...", "snippet": "testing of one <b>machine</b> <b>learning</b> <b>algorithm</b> for PV power <b>prediction</b> [16]. An adaptive ANN was used . to model and size a stand-alone PV plant, using a minimum input dataset [17, 18]. An ANFIS was ...", "dateLastCrawled": "2021-11-19T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) A Racially Unbiased, <b>Machine</b> <b>Learning</b> Approach to <b>Prediction</b> of ...", "url": "https://www.researchgate.net/publication/346363487_A_Racially_Unbiased_Machine_Learning_Approach_to_Prediction_of_Mortality_Algorithm_Development_Study", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/346363487_A_Racially_Un<b>biased</b>_<b>Machine</b>...", "snippet": "The <b>machine</b> <b>learning</b> <b>algorithm</b> was found to be unbiased (equal opportunity difference 0.016, P=.20). APACHE was also found to be unbiased (equal opportunity difference 0.019, P=.11), while SAPS II ...", "dateLastCrawled": "2021-10-18T11:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "5 Types of <b>bias</b> &amp; how to eliminate them in your <b>machine</b> <b>learning</b> ...", "url": "https://towardsdatascience.com/5-types-of-bias-how-to-eliminate-them-in-your-machine-learning-project-75959af9d3a0", "isFamilyFriendly": true, "displayUrl": "https://<b>towards</b>datascience.com/5-types-of-<b>bias</b>-how-to-eliminate-them-in-your-<b>machine</b>...", "snippet": "T he following is a devastating truth about a <b>biased</b> <b>machine</b> <b>learning</b> program that happened in real life. It is safe to say that the following is an example of the reasons why racism still exists. It\u2019s what I\u2019d like to start with to show you how important it is to fix any <b>bias</b> in your AI program. Compas. Developed by a private company called Equiv a nt (formerly Northpointe). Compas is a <b>machine</b> <b>learning</b> <b>algorithm</b> that predicts the defendant\u2019s likelihoods to commit crimes, it has been ...", "dateLastCrawled": "2022-01-26T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "inductive <b>bias</b> in <b>machine</b> <b>learning</b> geeksforgeeks", "url": "http://pahurling.com/site/9zrmu5t/inductive-bias-in-machine-learning-geeksforgeeks", "isFamilyFriendly": true, "displayUrl": "pahurling.com/site/9zrmu5t/inductive-<b>bias</b>-in-<b>machine</b>-<b>learning</b>-geeksforgeeks", "snippet": "<b>Machine</b> <b>Learning</b> Any de\ufb01nition of <b>machine</b> <b>learning</b> is bound to be controversial. Inductive <b>Learning</b> <b>Algorithm</b> in <b>Machine</b> <b>Learning</b>. al, 2018) is an amazing read, which I will be referring to throughout this answer. Intuitively, <b>bias</b> <b>can</b> <b>be thought</b> as having a \u2018<b>bias</b>\u2019 <b>towards</b> people. In addition, the training data is also necessarily <b>biased</b> ...", "dateLastCrawled": "2022-01-29T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> 99+ Most Important MCQ Part-2 | <b>Machine</b> <b>Learning</b> MCQ ...", "url": "https://www.jobsaarnee.com/2021/06/machine-learning-100-most-important-mcq-part2.html", "isFamilyFriendly": true, "displayUrl": "https://www.jobsaarnee.com/2021/06/<b>machine</b>-<b>learning</b>-100-most-important-mcq-part2.html", "snippet": "Q74 Which of the following <b>machine</b> <b>learning</b> <b>algorithm</b> <b>can</b> be used for imputing missing values of both categorical and continuous variables? (a) K-NN (b) Linear Regression (c) Logistic Regression (d) None of the Above. Sol. (a) K-NN. Q75 Typically, value of k in k-nearest neighbors lie between-(a) 0 to1 (b) 1 to 20 (c) 20 to 50 (d) -1 to 1. Sol ...", "dateLastCrawled": "2022-02-03T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Bias in Artificial Intelligence</b>. How <b>bias</b> <b>can</b> explode our AI models ...", "url": "https://adabhishekdabas.medium.com/bias-in-artificial-intelligence-d2ccec3abb2b", "isFamilyFriendly": true, "displayUrl": "https://adabhishekdabas.medium.com/<b>bias-in-artificial-intelligence</b>-d2ccec3abb2b", "snippet": "For Example, Some people are more <b>biased</b> <b>towards</b> <b>a particular</b> political affiliation or religion or sex, while others might disagree with that view. Say if the model learns that coders are men and homemakers are women, this is prejudice <b>bias</b> because women <b>can</b> obviously code and men <b>can</b> cook. The issue here is that the data set consciously or unconsciously reflects these social stereotypes. 3. <b>Biased</b> in Data Representation: \u201cYour model is as good as the dataset you use\u201d. Representation ...", "dateLastCrawled": "2022-01-30T19:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Mitigating Bias in AI with</b> AIF360 | by Bryan Truong | <b>Towards</b> Data Science", "url": "https://towardsdatascience.com/mitigating-bias-in-ai-with-aif360-b4305d1f88a9", "isFamilyFriendly": true, "displayUrl": "https://<b>towards</b>datascience.com/<b>mitigating-bias-in-ai-with</b>-aif360-b4305d1f88a9", "snippet": "In this article, I demonstrate how biases in data <b>can</b> be exacerbated through <b>machine</b> <b>learning</b>. I first created an ML model that was <b>biased</b>, then used AI Fairness 360 (AIF360), an open-source toolkit by IBM Research, in an attempt to mitigate the <b>bias</b>. The dataset and Jupyter Notebook for this exercise are available in a GitHub repo here.", "dateLastCrawled": "2022-02-02T22:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>learning</b> applications in <b>cancer</b> prognosis and <b>prediction</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S2001037014000464", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2001037014000464", "snippet": "In supervised <b>learning</b> this procedure <b>can</b> <b>be thought</b> as a classification problem. The task of classification refers to a <b>learning</b> process that categorizes the data into a set of finite classes. Two other common ML tasks are regression and clustering. In the case of regression problems, a <b>learning</b> function maps the data into a real-value variable. Subsequently, for each new sample the value of a predictive variable <b>can</b> be estimated, based on this process. Clustering is a common unsupervised ...", "dateLastCrawled": "2022-02-02T18:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Towards</b> a pragmatist dealing with algorithmic <b>bias</b> in medical <b>machine</b> ...", "url": "https://link.springer.com/article/10.1007/s11019-021-10008-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11019-021-10008-5", "snippet": "The underlying assumption is that greater transparency will render algorithmic <b>bias</b> easier to detect and help understand a program\u2019s erroneous decisions, so that one <b>can</b> correct the <b>algorithm</b>\u2019s mistakes and avoid <b>bias</b> by curating the input variables accordingly. For many instances this solution <b>can</b> be sufficient, e.g. to identify so-called Clever Hans predictors that base a ML program\u2019s classification strategy on irrelevant correlations. A good example for such a misleading predictor ...", "dateLastCrawled": "2022-01-13T00:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Algorithmic <b>Bias</b> in Education | SpringerLink", "url": "https://link.springer.com/article/10.1007/s40593-021-00285-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s40593-021-00285-9", "snippet": "While several attempts have been made at locating sources of <b>bias</b> within the <b>machine</b> <b>learning</b> pipeline (See Fig. 1), other researchers have argued for locating algorithmic <b>bias</b>, not only at a stage within this process, but also as the product of the social interactions surrounding the production and use of an <b>algorithm</b>. Drawing from sociocultural activity theory, Ferrero and Barujel (2019) describe an <b>algorithm</b> as the artifact of an activity system, locating <b>bias</b> within the connected parts ...", "dateLastCrawled": "2022-01-28T10:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Algorithmic <b>bias</b> detection and mitigation: Best practices and policies ...", "url": "https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.brookings.edu</b>/research/<b>algorithm</b>ic-<b>bias</b>-detection-and-mitigation-best-", "snippet": "Turner Lee, Nicol. Detecting racial <b>bias</b> in algorithms and <b>machine</b> <b>learning</b>. Journal of Information, Communication and Ethics in Society 2018, Vol. 16 Issue 3, pp. 252-260. Available at https ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The <b>Killer Algorithmic Bias In Fashion</b> Forecasting | Stylumia Blog", "url": "https://www.stylumia.ai/blog/the-killer-algorithmic-bias-in-fashion-demand-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://www.stylumia.ai/blog/the-<b>killer-algorithmic-bias-in-fashion-demand-forecasting</b>", "snippet": "If the <b>algorithm</b> predicts 5% and if the same <b>prediction</b> is 2.5% always for a country of origin, there is a <b>bias</b>. Systematic errors (biases) by humans or algorithms have a serious impact on business performance. <b>Algorithmic Bias In Fashion Demand Forecasting</b>. There is a rising awareness of using data in fashion demand forecasting. Data has <b>bias</b>. Data is related to a context. Context is decisive. First, consider, for example, you categorized a store as \u201cC\u201d grade and always deprived of that ...", "dateLastCrawled": "2022-01-30T22:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Racially Unbiased, <b>Machine</b> <b>Learning</b> Approach to <b>Prediction</b> of ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7644374/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7644374", "snippet": "<b>Bias</b> was assessed through the equal opportunity difference. Model performance in terms of <b>bias</b> and accuracy was <b>compared</b> with the Modified Early Warning Score (MEWS), the Simplified Acute Physiology Score II (SAPS II), and the Acute Physiologic Assessment and Chronic Health Evaluation (APACHE). Results. The <b>machine</b> <b>learning</b> <b>algorithm</b> was found to be more accurate than all comparators, with a higher sensitivity, specificity, and area under the receiver operating characteristic. The <b>machine</b> ...", "dateLastCrawled": "2021-12-18T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Comparing different supervised <b>machine</b> <b>learning</b> algorithms for disease ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6925840/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6925840", "snippet": "For these reasons, we used both \u201c<b>machine</b> <b>learning</b>\u201d and \u201cdata mining\u201d in the search terms although the focus of this study is on the supervised <b>machine</b> <b>learning</b> <b>algorithm</b>. The four search items were then considered to launch searches on the titles, abstracts and keywords of an article for both Scopus and PubMed. This resulted in 305 and 83 articles from Scopus and PubMed, respectively. After combining these two lists of articles and removing the articles written in languages other ...", "dateLastCrawled": "2022-01-28T14:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding <b>Bias</b> in <b>Machine</b> <b>Learning</b> - lexalytics.com", "url": "https://www.lexalytics.com/resources/Lexalytics_Understanding_Bias_In_Machine_Learning_WhitePaper.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.lexalytics.com/resources/Lexalytics_Understanding_<b>Bias</b>_In_<b>Machine</b>_<b>Learning</b>...", "snippet": "Availability <b>Bias</b> <b>Machine</b> <b>Learning</b> performs best with clear, frequently repeated patterns. Idiosyncratic individuals are more likely to be overlooked by such systems. For example, women often have slightly more complicated work histories than men because of time taken off for childbirth. Another example is that a company hiring primarily from the United States may have a degree of understanding about university quality within the U.S., but fail to give credit to attendees of prestigious ...", "dateLastCrawled": "2022-02-01T16:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Survey on <b>Bias</b> and <b>Fairness in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/a-survey-on-bias-and-fairness-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-survey-on-<b>bias</b>-and-<b>fairness-in-machine-learning</b>", "snippet": "These types of toolkits <b>can</b> be helpful for learners, researchers, and people working in the industry to move <b>towards</b> developing fair <b>machine</b> <b>learning</b> application away from discriminatory behavior. In addition to COMPAS, discriminatory behavior was also evident in an <b>algorithm</b> that would deliver ads promoting job opportunities in the Science, Technology, Engineering and Math (STEM) fields ( lambrecht2018algorithmic ) .", "dateLastCrawled": "2022-01-22T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Anti-racism, algorithmic bias, and policing</b>: a ... - <b>Towards</b> Data Science", "url": "https://towardsdatascience.com/anti-racism-algorithmic-bias-and-policing-a-brief-introduction-bafa0dc75ac6", "isFamilyFriendly": true, "displayUrl": "https://<b>towards</b>datascience.com/<b>anti-racism-algorithmic-bias-and-policing</b>-a-brief...", "snippet": "Algorithmic <b>bias</b>, or <b>bias</b> in data analysis and <b>machine</b> <b>learning</b>, <b>can</b> arise from a number of places, including non-inclusive data sets, or an issue with the data analytical or statistical process. Algorithmic fairness <b>can</b> be achieved when data tools <b>can</b> be audited in public for how they contribute to the fairness of society.", "dateLastCrawled": "2022-01-11T23:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>learning</b>-based <b>prediction</b> of trace element concentrations using ...", "url": "https://www.sciencedirect.com/science/article/pii/S2666544121000289", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2666544121000289", "snippet": "<b>Machine</b> <b>learning</b> <b>can</b> predict trace element concentrations from major and minor element geochemical data. ... Our dataset exhibits strong coverage <b>bias</b> <b>towards</b> basalt (n = 3039), basaltic-andesite (n = 2643), gabbro (n = 680) and gabbroic-diorite (n = 359). Therefore, when these types of rocks are removed from the <b>prediction</b> database, we expected that there might be an overall performance change across nearly all elements. However, this is not observed except for the loss of performance in ...", "dateLastCrawled": "2022-01-09T12:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bias</b>, <b>Fairness</b> and Explainability \u2014 steps <b>towards</b> building Responsible ...", "url": "https://medium.com/walmartglobaltech/bias-fairness-and-explainability-steps-towards-building-responsible-ai-dc735b06279", "isFamilyFriendly": true, "displayUrl": "https://medium.com/walmartglobaltech/<b>bias</b>-<b>fairness</b>-and-explainability-steps-<b>towards</b>...", "snippet": "<b>Outcome</b> proxy <b>bias</b>: ... As mentioned in Wikipedia: \u201cIn <b>machine</b> <b>learning</b>, a given <b>algorithm</b> is said to be fair, or to have <b>fairness</b>, if its results are independent of given variables, especially ...", "dateLastCrawled": "2022-01-23T22:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) A Racially Unbiased, <b>Machine</b> <b>Learning</b> Approach to <b>Prediction</b> of ...", "url": "https://www.researchgate.net/publication/346363487_A_Racially_Unbiased_Machine_Learning_Approach_to_Prediction_of_Mortality_Algorithm_Development_Study", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/346363487_A_Racially_Un<b>biased</b>_<b>Machine</b>...", "snippet": "The <b>machine</b> <b>learning</b> <b>algorithm</b> was found to be unbiased (equal opportunity difference 0.016, P=.20). APACHE was also found to be unbiased (equal opportunity difference 0.019, P=.11), while SAPS II ...", "dateLastCrawled": "2021-10-18T11:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Comparison of traditional model-based statistical methods with <b>machine</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0022395621006786", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0022395621006786", "snippet": "One study examined the predictive accuracy of a <b>machine</b>-<b>learning</b> <b>algorithm</b> to detect suicide attempts using an adolescent hospital health record data and found an AUC of 0.8\u20130.9 (21). In this study, random forests significantly outperformed logistic regression in every comparison. Another study used community adolescents and young adults multiwave prospective-longitudinal data set. It <b>compared</b> a variety of suicide attempts <b>prediction</b> methods examining logistic regression, lasso, ridge, and ...", "dateLastCrawled": "2022-01-18T21:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Machine</b> <b>Learning</b> Based Photovoltaics (PV) Power <b>Prediction</b> Using ...", "url": "https://www.researchgate.net/publication/334599389_Machine_Learning_Based_Photovoltaics_PV_Power_Prediction_Using_Different_Environmental_Parameters_of_Qatar", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334599389_<b>Machine</b>_<b>Learning</b>_Based_Photovoltaic...", "snippet": "Two different <b>bias</b> calculation techniques were used to evaluate the instances of <b>biased</b> <b>prediction</b>, which <b>can</b> be utilized to reduce <b>bias</b> to improve accuracy. The ANN model outperforms other ...", "dateLastCrawled": "2021-11-19T14:07:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> has become one of the most studied aspects of <b>machine learning</b> in the past few years, and other frameworks have appeared to detect and mitigate <b>bias</b> in models. Local Interpretable Model-Agnostic Explanations (Lime) can be used to understand why a model provides a particular <b>prediction</b>.", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How <b>Bias</b> and Variance Affect a <b>Machine Learning</b> Model | by Ismael ...", "url": "https://medium.com/swlh/how-bias-and-variance-affect-a-machine-learning-model-6d258d9221db", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/how-<b>bias</b>-and-variance-affect-a-<b>machine-learning</b>-model-6d258d9221db", "snippet": "<b>Bias</b> and Variance Tradeoff. In <b>machine learning</b>, <b>bias</b> is the algorithm tendency to repeatedly learn the wrong thing by ignoring all the information in the data. Thus, high <b>bias</b> results from the ...", "dateLastCrawled": "2021-12-15T02:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to Predict It: Inductive <b>Prediction</b> by <b>Analogy</b> Using Taxonomic Info ...", "url": "https://www.aaai.org/Papers/MSL/1996/MSL96-027.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.aaai.org/Papers/MSL/1996/MSL96-027.pdf", "snippet": "This paper presents a novel <b>machine</b> <b>learning</b> technique in a logic programming environment: Inductive <b>Prediction</b> by <b>Analogy</b> (IPA). IPA learns the description a target predicate similar to a source predicate from examples of the target predicate. Akey feature of IPAis that it uses analogies to constrain the space of hypotheses using taxonomic information represented by first-order predicate logic. ~pical problems addressed by IPA are to decide whether a given ground atom is valid or not, when ...", "dateLastCrawled": "2021-09-22T21:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Calculation of Bias &amp; Variance in</b> python | by Nallaperumal | Analytics ...", "url": "https://medium.com/analytics-vidhya/calculation-of-bias-variance-in-python-8f96463c8942", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>calculation-of-bias-variance-in</b>-python-8f96463c8942", "snippet": "For any <b>machine</b> <b>learning</b> the performance of a model can be determined and characterized in terms of <b>Bias</b> and Variance. In supervised <b>machine</b> <b>learning</b> an algorithm learns a model from training data ...", "dateLastCrawled": "2022-01-29T11:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bias</b>-<b>variance</b> tradeoff in <b>machine</b> <b>learning</b>: an intuition | by Mahbubul ...", "url": "https://towardsdatascience.com/bias-variance-tradeoff-in-machine-learning-an-intuition-da85228c5074", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>bias</b>-<b>variance</b>-tradeoff-in-<b>machine</b>-<b>learning</b>-an-intuition...", "snippet": "But the model w ouldn\u2019t be able to make a 100% accurate <b>prediction</b>, ... Let\u2019s now connect this intuition with the formal concept of <b>bias</b>-<b>variance</b> tradeoff. In <b>machine</b> <b>learning</b>, each model is specified with a number of parameters that determine model performance. A good model performs well both in training and out-of-sample data. Some models can be used out-of-the-box with default parameters. But if we do not tune the parameters, there is always the possibility that the model will not ...", "dateLastCrawled": "2022-02-02T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Bias-Variance Decomposition</b> - mlxtend", "url": "http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/", "isFamilyFriendly": true, "displayUrl": "rasbt.github.io/mlxtend/user_guide/evaluate/<b>bias</b>_variance_decomp", "snippet": "<b>Bias variance decomposition</b> of <b>machine</b> <b>learning</b> algorithms for various loss functions. from mlxtend.evaluate import <b>bias</b>_variance_decomp. Overview . Often, researchers use the terms <b>bias</b> and variance or &quot;<b>bias</b>-variance tradeoff&quot; to describe the performance of a model -- i.e., you may stumble upon talks, books, or articles where people say that a model has a high variance or high <b>bias</b>. So, what does that mean? In general, we might say that &quot;high variance&quot; is proportional to overfitting, and ...", "dateLastCrawled": "2022-01-31T12:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b> Concepts for Revision | by Raunak Sarada | Medium", "url": "https://raunaksarada-cse21.medium.com/machine-learning-concepts-for-revision-491384952d27", "isFamilyFriendly": true, "displayUrl": "https://raunaksarada-cse21.medium.com/<b>machine</b>-<b>learning</b>-concepts-for-revision-491384952d27", "snippet": "ML Concepts. A.I \u2014 Intelligence showed by machines which is common for humans <b>Machine</b> <b>Learning</b>- Recognize the pattern in data and automatically learn and improve through experience without explicitly being programmed Deep <b>Learning</b>- branch of <b>machine</b> <b>learning</b>.We have to deal with lots of data so in that case problems can\u2019t be solved with simple ML algorithms.", "dateLastCrawled": "2022-01-25T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Preliminary performance study of a brief review on <b>machine</b> <b>learning</b> ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "snippet": "<b>Analogy</b>-based effort estimation is the major task of software engineering which estimates the effort required for new software projects using existing histories for corresponding development and management. In general, the high accuracy of software effort estimation techniques can be a non-solvable problem we named as multi-objective problem. Recently, most of the authors have been used <b>machine</b> <b>learning</b> techniques for the same process however not possible to meet the higher performance ...", "dateLastCrawled": "2022-01-02T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning</b> for Volatility Trading (Presentation Slides) by Artur ...", "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3186401", "isFamilyFriendly": true, "displayUrl": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3186401", "snippet": "By applying <b>machine learning</b> to the volatility modeling, we can reduce the back-test <b>bias</b> and, as a result, improve the performance of live strategies. First, I implemented about 40 different volatility models from 4 separate model classes including intraday estimators, GARCH-type and Bayesian models, and Hidden Markov Chain (HMC) models. Then, I applied the supervised <b>learning</b> for each of the volatility models with the goal is to analyze the out-of-sample fit of the model <b>prediction</b> to the ...", "dateLastCrawled": "2022-01-25T01:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>All Unit MCQ questions of ML</b> \u2013 TheCodingShef", "url": "https://thecodingshef.com/all-unit-mcq-questions-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://thecodingshef.com/<b>all-unit-mcq-questions-of</b>-<b>machine</b>-<b>learning</b>", "snippet": "It is used for <b>prediction</b>; It discovers causal relationships; It relates inputs to outputs; Correct option is C. Choose the correct option regarding <b>machine</b> <b>learning</b> (ML) and artificial intelligence (AI) ML is a set of techniques that turns a dataset into a software; AI is a software that can emulate the human mind; ML is an alternate way of programming intelligent machines; All of the above Correct option is D. Which of the factors affect the performance of the learner system does not ...", "dateLastCrawled": "2022-01-30T22:09:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(prediction bias)  is like +(machine learning algorithm biased towards a particular outcome)", "+(prediction bias) is similar to +(machine learning algorithm biased towards a particular outcome)", "+(prediction bias) can be thought of as +(machine learning algorithm biased towards a particular outcome)", "+(prediction bias) can be compared to +(machine learning algorithm biased towards a particular outcome)", "machine learning +(prediction bias AND analogy)", "machine learning +(\"prediction bias is like\")", "machine learning +(\"prediction bias is similar\")", "machine learning +(\"just as prediction bias\")", "machine learning +(\"prediction bias can be thought of as\")", "machine learning +(\"prediction bias can be compared to\")"]}