{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "ML From Scratch: Linear, Polynomial, and Regularized Regression Models ...", "url": "https://towardsdatascience.com/ml-from-scratch-linear-polynomial-and-regularized-regression-models-725672336076", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/ml-from-scratch-linear-polynomial-and-regularized...", "snippet": "Gradient descent is a generic optimization algorithm that searches for the optimal solution by <b>making</b> <b>small</b> <b>tweaks</b> to the parameters. To start, you fill \u0398 with random values (this approach is called random initialization). Then, tweak the parameters until the algorithm converges to a minimum solution by traveling in a direction that decreases ...", "dateLastCrawled": "2022-01-29T08:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Complete Guide to <b>Parameter</b> Tuning in Xgboost", "url": "https://shengyg.github.io/repository/machine%20learning/2017/02/25/Complete-Guide-to-Parameter-Tuning-xgboost.html", "isFamilyFriendly": true, "displayUrl": "https://shengyg.github.io/repository/<b>machine</b> learning/2017/02/25/Complete-Guide-to...", "snippet": "Standard GBM implementation has no regularization <b>like</b> XGBoost, ... If it is set to a positive value, it can help <b>making</b> the <b>update</b> step more conservative. Usually this <b>parameter</b> is not needed, but it might help in logistic regression when class is extremely imbalanced. This is generally not used but you can explore further if you wish. subsample [default=1] Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree. Lower values make the ...", "dateLastCrawled": "2022-02-02T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Matching Methods</b> for Causal Inference: A <b>Machine</b> Learning <b>Update</b>", "url": "https://humboldt-wi.github.io/blog/research/applied_predictive_modeling_19/matching_methods/", "isFamilyFriendly": true, "displayUrl": "https://humboldt-wi.github.io/blog/research/applied_predictive_modeling_19/matching...", "snippet": "<b>Machine</b> Learning Modeling: Matching Frontier, D-AEMR, Genetic Matching, and Nearest-Neighbor PSM w/ Random Forest. The methods outlined so far were first proposed in the 1980s with <b>tweaks</b> and updates throughout the years. In recent years, novel approaches have been published with increasing frequency. These approaches utilize some degree of ...", "dateLastCrawled": "2022-01-30T00:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Gradient</b> Descent: A Quick, Simple Introduction | Built In", "url": "https://builtin.com/data-science/gradient-descent", "isFamilyFriendly": true, "displayUrl": "https://builtin.com/data-science/<b>gradient</b>-descent", "snippet": "It&#39;s based on a convex function and <b>tweaks</b> its parameters iteratively to minimize a given function to its local minimum. What is <b>Gradient</b> Descent? <b>Gradient</b> Descent is an optimization algorithm for finding a local minimum of a differentiable function. <b>Gradient</b> descent is simply used in <b>machine</b> learning to find the values of a function&#39;s parameters (coefficients) that minimize a cost function as far as possible. You start by defining the initial <b>parameter</b>&#39;s values and from there <b>gradient</b> ...", "dateLastCrawled": "2022-02-02T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Adam</b> \u2014 latest trends in deep learning optimization. | by Vitaly Bushaev ...", "url": "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>adam</b>-latest-trends-in-deep-learning-optimization-6be9a...", "snippet": "This property add intuitive understanding to previous unintuitive learning rate hyper-<b>parameter</b>. Step size of <b>Adam</b> <b>update</b> rule is invariant to the magnitude of the gradient, which helps a lot when going through areas with tiny gradients (such as saddle points or ravines). In these areas SGD struggles to quickly navigate through them. <b>Adam</b> was designed to combine the advantages of Adagrad, which works well with sparse gradients, and RMSprop, which works well in on-line settings. Having both ...", "dateLastCrawled": "2022-02-02T03:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Optimization Algorithms in Neural Networks - <b>KDnuggets</b>", "url": "https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/12/optimization-algorithms-neural-networks.html", "snippet": "You start by defining the initial <b>parameter</b>&#39;s values and from there gradient descent uses calculus to iteratively adjust the values so they minimize the given cost-function. The weight is initialized using some initialization strategies and is updated with each epoch according to the <b>update</b> equation. The above equation computes the gradient of the cost function J(\u03b8) w.r.t. to the parameters/weights \u03b8 for the entire training dataset: Image source . Our aim is to get to the bottom of our ...", "dateLastCrawled": "2022-01-31T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Make Your <b>PC Boot Faster With These BIOS Tweaks</b>", "url": "https://www.pcworld.com/article/500279/speed_up_boot_time.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pcworld.com</b>/article/500279/speed_up_boot_time.html", "snippet": "<b>Update</b> the BIOS If your <b>machine</b> is more than a year old, chances are good that you can find an updated BIOS for it. Motherboard manufacturers often issue updates to solve problems, <b>update</b> features ...", "dateLastCrawled": "2022-02-02T22:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "8 <b>Ways to Increase Network Speed via</b> Regedit in Windows 10 - Make Tech ...", "url": "https://www.maketecheasier.com/3-ways-to-increase-network-speed-via-registry-editor-windows/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.maketecheasier.com</b>/3-<b>ways-to-increase-network-speed-via</b>-registry-editor...", "snippet": "For most servers, this is efficient enough, but sometimes you have a <b>small</b> amount of memory and cannot keep up with the high request volume. Here\u2019s the location of the key in your registry: \\ HKEY_LOCAL_<b>MACHINE</b> \\SYSTEM\\CurrentControlSet\\Services\\Lanman\\Server\\Parameters. Add \u201cSizReqBuf\u201d as a DWORD value on the right side of the regedit window. If you have a server with over 512 MB of physical memory, modify the value to 17424. If you have less than 512 MB of memory, you should consider ...", "dateLastCrawled": "2022-02-02T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Weekly Dev <b>Update</b> #71. THORChain Weekly Dev <b>Update</b> for Week\u2026 | by ...", "url": "https://medium.com/thorchain/weekly-dev-update-71-29d792fde42c", "isFamilyFriendly": true, "displayUrl": "https://medium.com/thorchain/weekly-dev-<b>update</b>-71-29d792fde42c", "snippet": "Note: Even if a user performed a <b>small</b> swap, <b>like</b> 0.1 BTC, but did it unknowingly in the same block as a user doing a large swap, <b>like</b> 20 BTC, both users will have to wait 4 confs, but this is ...", "dateLastCrawled": "2021-03-11T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Best <b>Tuning Tips to Improve Hyper-V Performance</b> - DNSstuff", "url": "https://www.dnsstuff.com/hyper-v-performance-tuning", "isFamilyFriendly": true, "displayUrl": "https://www.dnsstuff.com/hyper-v-performance-tuning", "snippet": "Windows drivers aren\u2019t <b>like</b> applications, because they can remove memory from the available pool permanently. If memory is improperly managed, you could encounter some serious Hyper-V performance issues. Avoid <b>making</b> your CSV cache too big. Limit the amount of memory you use for a virtual <b>machine</b> to an amount you can prove is necessary. Avoid using more memory than can fit in one NUMA node. If your virtual machines are performing a high number of memory operations, avoid using dynamic ...", "dateLastCrawled": "2022-02-03T04:40:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "ML From Scratch: Linear, Polynomial, and Regularized Regression Models ...", "url": "https://towardsdatascience.com/ml-from-scratch-linear-polynomial-and-regularized-regression-models-725672336076", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/ml-from-scratch-linear-polynomial-and-regularized...", "snippet": "Gradient descent is a generic optimization algorithm that searches for the optimal solution by <b>making</b> <b>small</b> <b>tweaks</b> to the parameters. To start, you fill \u0398 with random values (this approach is called random initialization). Then, tweak the parameters until the algorithm converges to a minimum solution by traveling in a direction that decreases ...", "dateLastCrawled": "2022-01-29T08:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Advanced Options with <b>Hyperopt</b> for Tuning Hyperparameters in Neural ...", "url": "https://towardsdatascience.com/advanced-options-with-hyperopt-for-tuning-hyperparameters-in-neural-networks-d108cf7655d9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/advanced-options-with-<b>hyperopt</b>-for-tuning-hyper...", "snippet": "Plot by author. The gray indicates the data that we\u2019ll set aside for final testing. The orange line (pedal %) is the input, which we called u in the code. The blue line (speed, with the artificially added noise) is the process variable (PV) or output data, which we represented with y.So as you can see, as we press the gas pedal down more, the speed gradually goes up until it reaches a steady state, and as we take the foot off the gas, the speed decreases.", "dateLastCrawled": "2022-01-31T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Optimization Algorithms in Neural Networks - <b>KDnuggets</b>", "url": "https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/12/optimization-algorithms-neural-networks.html", "snippet": "While Momentum first computes the current gradient (<b>small</b> brown vector in Image 4) and then takes a big jump in the direction of the updated accumulated gradient (big brown vector), NAG first makes a big jump in the direction of the previously accumulated gradient (green vector), measures the gradient and then makes a correction (red vector), which results in the complete NAG <b>update</b> (red vector). This anticipatory <b>update</b> prevents us from going too fast and results in increased responsiveness ...", "dateLastCrawled": "2022-01-31T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Complete Guide to <b>Parameter</b> Tuning in Xgboost", "url": "https://shengyg.github.io/repository/machine%20learning/2017/02/25/Complete-Guide-to-Parameter-Tuning-xgboost.html", "isFamilyFriendly": true, "displayUrl": "https://shengyg.github.io/repository/<b>machine</b> learning/2017/02/25/Complete-Guide-to...", "snippet": "User is required to supply a different value than other observations and pass that as a <b>parameter</b>. XGBoost tries different things as it encounters a missing value on each node and learns which path to take for missing values in future. Tree Pruning: A GBM would stop splitting a node when it encounters a negative loss in the split. Thus it is more of a greedy algorithm. XGBoost on the other hand make splits upto the max_depth specified and then start pruning the tree backwards and remove ...", "dateLastCrawled": "2022-02-02T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Matching Methods</b> for Causal Inference: A <b>Machine</b> Learning <b>Update</b>", "url": "https://humboldt-wi.github.io/blog/research/applied_predictive_modeling_19/matching_methods/", "isFamilyFriendly": true, "displayUrl": "https://humboldt-wi.github.io/blog/research/applied_predictive_modeling_19/matching...", "snippet": "Authors: Samantha Sizemore and Raiber Alkurdi Introduction. Practitioners from quantitative Social Sciences such as Economics, Sociology, Political Science, Epidemiology and Public Health have undoubtedly come across matching as a go-to technique for preprocessing observational data before treatment effect estimation; those on the <b>machine</b> learning side of the aisle, however, may be unfamiliar with the concept of matching.", "dateLastCrawled": "2022-01-30T00:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "SG :: <b>Windows 10, Server 2019 TCP/IP Tweaks</b>", "url": "https://www.speedguide.net/articles/windows-8-10-2012-server-tcpip-tweaks-5077", "isFamilyFriendly": true, "displayUrl": "https://<b>www.speedguide.net</b>/articles/windows-8-10-2012-server-tcpip-<b>tweaks</b>-5077", "snippet": "The TCP/IP speed <b>tweaks</b> below work with Windows 8, 10, 2012/2019 Server. The Windows 8/10 TCP/IP implementation shares many traits with earlier Windows versions, however, there are many subtle differences and updates, new syntax for applying <b>tweaks</b> using PowerShell cmdlets, and some new settings. Windows 10 generally works well by default for ...", "dateLastCrawled": "2022-02-02T04:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Word2Vec Tutorial - The Skip-Gram Model \u00b7 Chris McCormick", "url": "https://www.ccs.neu.edu/home/vip/teach/DMcourse/4_TF_supervised/notes_slides/Word2Vec%20Tutorial%20-%20The%20Skip-Gram%20Model%20%C2%B7%20Chris%20McCormick.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ccs.neu.edu/home/vip/teach/DMcourse/4_TF_supervised/notes_slides/Word2Vec...", "snippet": "uses a trick you may have seen elsewhere in <b>machine</b> learning. We\u02bcre going to train a simple neural network with a single hidden layer to perform a certain task, but then we\u02bcre not actually going to use that neural network for the task we trained it on! Instead, the goal is actually just to learn the weights of the hidden layer\u2013we\u02bcll see that these weights are actually the \u201cword vectors\u201d that we\u02bcre trying to learn. Another place you may have seen this trick is in unsupervised ...", "dateLastCrawled": "2022-02-02T20:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Make Your <b>PC Boot Faster With These BIOS Tweaks</b>", "url": "https://www.pcworld.com/article/500279/speed_up_boot_time.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pcworld.com</b>/article/500279/speed_up_boot_time.html", "snippet": "<b>Update</b> the BIOS If your <b>machine</b> is more than a year old, chances are good that you can find an updated BIOS for it. Motherboard manufacturers often issue updates to solve problems, <b>update</b> features ...", "dateLastCrawled": "2022-02-02T22:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Azure DevOps</b> YAML Pipeline Parameters Not Working from REST API Trigger ...", "url": "https://stackoverflow.com/questions/60852825/azure-devops-yaml-pipeline-parameters-not-working-from-rest-api-trigger", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/60852825", "snippet": "I&#39;m trying to create a YAML based pipeline that takes a <b>parameter</b>, then trigger the pipeline to run from a <b>Azure DevOps</b> REST API. I&#39;m able to see the build gets queued, but the <b>parameter</b> was not overridden from my POST body. My template my-template.yaml. parameters: - name: testParam type: string default: &#39;N/A&#39; steps: - script: echo ...", "dateLastCrawled": "2022-01-29T02:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The best drum machines in 2022 for every application and ... - <b>MusicRadar</b>", "url": "https://www.musicradar.com/news/best-drum-machines", "isFamilyFriendly": true, "displayUrl": "https://<b>www.musicradar.com</b>/news/best-drum-<b>machines</b>", "snippet": "The best drum <b>machine</b> for compact all-analogue beat <b>making</b>. Specifications. Price: $349/\u00a3280/\u20ac349. Sounds: Analogue. Effects: Yes. Pads/buttons: 8. Sequencer: Yes. Connectivity: Internal/MIDI/Clock sync. Analogue outputs: Master output and individual outputs for kick, snare, hats and FM sound. MIDI I/O: USB MIDI. Built-in speaker: No. Power: Mains. Dimensions: 342 x 243 x 57mm. Weight: 1.84kg. TODAY&#39;S BEST DEALS. \u00a3271. View at Gear 4 Music. Low Stock. \u00a3289. View at Gear 4 Music. Check ...", "dateLastCrawled": "2022-01-30T16:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Advanced Options with <b>Hyperopt</b> for Tuning Hyperparameters in Neural ...", "url": "https://towardsdatascience.com/advanced-options-with-hyperopt-for-tuning-hyperparameters-in-neural-networks-d108cf7655d9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/advanced-options-with-<b>hyperopt</b>-for-tuning-hyper...", "snippet": "Plot by author. The gray indicates the data that we\u2019ll set aside for final testing. The orange line (pedal %) is the input, which we called u in the code. The blue line (speed, with the artificially added noise) is the process variable (PV) or output data, which we represented with y.So as you <b>can</b> see, as we press the gas pedal down more, the speed gradually goes up until it reaches a steady state, and as we take the foot off the gas, the speed decreases.", "dateLastCrawled": "2022-01-31T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A <b>parametric design for 3D printed</b> boxes \u2013 Ace Makerspace", "url": "https://www.acemakerspace.org/a-parametric-design-for-3d-printed-boxes/", "isFamilyFriendly": true, "displayUrl": "https://www.acemakerspace.org/a-<b>parametric-design-for-3d-printed</b>-boxes", "snippet": "Note particularly the <b>small</b> horizontal segment dimensioned to the \u2018clearance\u2019 value. I\u2019ll adjust this <b>parameter</b> experimentally to get a good fit. With the profile done, I use the sweep tool, specifying the top inside edge of the box as the path. My box model is complete; now the tweaking begins. I just guessed at the initial clearance value of 0.4mm, since that size has worked reasonably well in the past. But I also know from experience that I <b>can</b>\u2019t predict this perfectly. Even ...", "dateLastCrawled": "2022-01-29T18:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Classificiation Using Logistic Regression in Visual Basic | by Acorn ...", "url": "https://acornaspiration.medium.com/classificiation-using-logistic-regression-in-visual-basic-1e180b1aeae3?source=post_internal_links---------1----------------------------", "isFamilyFriendly": true, "displayUrl": "https://acornaspiration.medium.com/classificiation-using-logistic-regression-in-visual...", "snippet": "Introduction. Logistic regression is an exciting bit of statistics that allows us to find relationships in data when the dependent variable is categorical. On account of this, it has captivated the minds of many a statistician to such a degree that my school uses it to help them predict A-Level grades. In this article we will discuss a simple ...", "dateLastCrawled": "2022-01-24T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A guide to an efficient way <b>to build neural network architectures- Part</b> ...", "url": "https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-i-hyper-parameter-8129009f131b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network...", "snippet": "Dropout:- The keep-probability of the Dropout layer <b>can</b> <b>be thought</b> of hyper-<b>parameter</b> which could act as a regularizer to help us find the optimum bias-variance spot. It does so by removing certain connections every iteration therefore the hidden units cannot depend a lot on any particular feature. The values it <b>can</b> take <b>can</b> be anywhere between 0\u20131 and it is solely based on how much is the model over-fitting.", "dateLastCrawled": "2022-02-02T09:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Citrix Provisioning \u2013 <b>Update vDisk</b> \u2013 Carl Stalhood", "url": "https://www.carlstalhood.com/pvs-update-vdisk/", "isFamilyFriendly": true, "displayUrl": "https://www.carlstalhood.com/pvs-<b>update-vdisk</b>", "snippet": "Windows 8/2012 and newer <b>can</b> boot from VHDX files. All you need to do is copy the vDisk VHD/VHDX to a Windows <b>machine</b>\u2019s local C: drive, run bcdedit to configure booting to the VHD/VHDX, reboot into the VHD/VHDX, make your changes, reboot back into the original Windows OS, copy the VHD/VHDX back to Citrix Provisioning and import it. Details below: Note: For Windows 7 vDisks, Enterprise Edition is required in the bootable VHD. Alternative methods of performing Reverse Image: George Spiers ...", "dateLastCrawled": "2022-02-03T02:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to fix apps that look <b>small</b> on high DPI and high ... - Winaero", "url": "https://winaero.com/how-to-fix-apps-that-look-small-on-high-dpi-and-high-resolution-displays/", "isFamilyFriendly": true, "displayUrl": "https://winaero.com/how-to-fix-apps-that-look-<b>small</b>-on-<b>high-dpi-and-high-resolution</b>...", "snippet": "HKEY_LOCAL_<b>MACHINE</b> &gt; SOFTWARE &gt; Microsoft &gt; Windows &gt; CurrentVersion &gt; SideBySide. Right-click, select NEW &gt; DWORD (32 bit) Value. Give it a name: PreferExternalManifest, and then press ENTER. Right-click PreferExternalManifest, and then click Modify. Enter Value Data 1. Click OK. Exit Registry Editor. Now restart Windows and run the app for which you added this manifest. The app should be scaled by Windows DPI virtualization feature and will no longer look too <b>small</b> with unusable controls ...", "dateLastCrawled": "2022-02-03T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "SMOTE for Imbalanced Classification with Python - <b>Machine</b> Learning Mastery", "url": "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://<b>machine</b>learningmastery.com/smote-oversampling-for-imbalanc", "snippet": "The original paper on SMOTE suggested combining SMOTE with random undersampling of the majority class. The imbalanced-learn library supports random undersampling via the RandomUnderSampler class.. We <b>can</b> <b>update</b> the example to first oversample the minority class to have 10 percent the number of examples of the majority class (e.g. about 1,000), then use random undersampling to reduce the number of examples in the majority class to have 50 percent more than the minority class (e.g. about 2,000).", "dateLastCrawled": "2022-02-02T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Editor/Librarian For The Yamaha DX200</b> - Sonic State", "url": "https://sonicstate.com/news/2019/01/21/editorlibrarian-for-the-yamaha-dx200/", "isFamilyFriendly": true, "displayUrl": "https://sonicstate.com/news/2019/01/21/<b>editorlibrarian-for-the-yamaha-dx200</b>", "snippet": "The DX200 <b>can</b> record a sequence of the knob <b>tweaks</b> you perform, on up to 4 different knobs controlling the synth. Each one of these 4 recorded motion tracks is called a Free Envelope, and Patch Base lets you hand-edit each of these with multiple tools: draw with your finger, draw lines, smooth a section, randomize a section, scale the envelope, and shift the envelope data left/right, or up/down. Each Free Envelope is 192 data points, and you <b>can</b> zoom in if you need to edit a <b>small</b> section ...", "dateLastCrawled": "2022-01-21T00:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How <b>to Classify Photos of Dogs and Cats</b> (with 97% accuracy)", "url": "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/", "isFamilyFriendly": true, "displayUrl": "https://<b>machine</b>learningmastery.com/how-to-develop-a-convolutional-neural-network-to...", "snippet": "Develop a Deep Convolutional Neural Network Step-by-Step to Classify Photographs of Dogs and Cats The Dogs vs. Cats dataset is a standard computer vision dataset that involves classifying photos as either containing a dog or cat. Although the problem sounds simple, it was only effectively addressed in the last few years using deep learning convolutional neural networks. While the dataset is effectively", "dateLastCrawled": "2022-02-03T02:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Trying to create AD signed cert for APC UPS, having issues with NMC ...", "url": "https://www.reddit.com/r/sysadmin/comments/kdopip/trying_to_create_ad_signed_cert_for_apc_ups/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/sysadmin/comments/kdopip/trying_to_create_ad_signed_cert_for...", "snippet": "I <b>thought</b> it was obvious that I was not envisioning some scenario where a user has an infected <b>machine</b> and you say &quot;Welp, sorry, I <b>can</b>&#39;t be assed to figure out what exactly you were infected with, say goodbye to all your data, and tough shit, be more careful next time, thanks for contacting IT, bye!&quot;. Going back to my Concession #3 (Point #5), I also understand that being able to get your end users to handle their data this way <b>can</b> also be borderline impossible, especially if you have C ...", "dateLastCrawled": "2021-12-25T12:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Complete Guide to <b>Parameter</b> Tuning in Xgboost", "url": "https://shengyg.github.io/repository/machine%20learning/2017/02/25/Complete-Guide-to-Parameter-Tuning-xgboost.html", "isFamilyFriendly": true, "displayUrl": "https://shengyg.github.io/repository/<b>machine</b> learning/2017/02/25/Complete-Guide-to...", "snippet": "If it is set to a positive value, it <b>can</b> help <b>making</b> the <b>update</b> step more conservative. Usually this <b>parameter</b> is not needed, but it might help in logistic regression when class is extremely imbalanced. This is generally not used but you <b>can</b> explore further if you wish. subsample [default=1] Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree. Lower values make the algorithm more conservative and prevents overfitting but too <b>small</b> values ...", "dateLastCrawled": "2022-02-02T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Advanced Options with <b>Hyperopt</b> for Tuning Hyperparameters in Neural ...", "url": "https://towardsdatascience.com/advanced-options-with-hyperopt-for-tuning-hyperparameters-in-neural-networks-d108cf7655d9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/advanced-options-with-<b>hyperopt</b>-for-tuning-hyper...", "snippet": "Plot by author. The gray indicates the data that we\u2019ll set aside for final testing. The orange line (pedal %) is the input, which we called u in the code. The blue line (speed, with the artificially added noise) is the process variable (PV) or output data, which we represented with y.So as you <b>can</b> see, as we press the gas pedal down more, the speed gradually goes up until it reaches a steady state, and as we take the foot off the gas, the speed decreases.", "dateLastCrawled": "2022-01-31T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Optimization Algorithms in Neural Networks - <b>KDnuggets</b>", "url": "https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/12/optimization-algorithms-neural-networks.html", "snippet": "While Momentum first computes the current gradient (<b>small</b> brown vector in Image 4) and then takes a big jump in the direction of the updated accumulated gradient (big brown vector), NAG first makes a big jump in the direction of the previously accumulated gradient (green vector), measures the gradient and then makes a correction (red vector), which results in the complete NAG <b>update</b> (red vector). This anticipatory <b>update</b> prevents us from going too fast and results in increased responsiveness ...", "dateLastCrawled": "2022-01-31T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Toward smart production: <b>Machine</b> intelligence in business operations ...", "url": "https://www.mckinsey.com/business-functions/operations/our-insights/toward-smart-production-machine-intelligence-in-business-operations", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mckinsey.com</b>/business-functions/operations/our-insights/toward-smart...", "snippet": "As a <b>small</b> internal team of experts and data scientists worked through the problem, they were able to train a computer model to become a process expert and focus its full attention on determining how to set this one <b>parameter</b>. Today, the model learns how to adapt to the continual <b>small</b> changes in the 41 variables that matter most, especially within the last 25 to 30 units produced. The process is now adjusted", "dateLastCrawled": "2022-02-02T02:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Matching Methods</b> for Causal Inference: A <b>Machine</b> Learning <b>Update</b>", "url": "https://humboldt-wi.github.io/blog/research/applied_predictive_modeling_19/matching_methods/", "isFamilyFriendly": true, "displayUrl": "https://humboldt-wi.github.io/blog/research/applied_predictive_modeling_19/matching...", "snippet": "This blog post aims to provide a succinct primer for matching neophytes and, for those already familiar with this technique, an overview of how state-of-the-art <b>machine</b> learning <b>can</b> be incorporated into the matching process. In addition, we provide a replicable coding excursion that demonstrates how different <b>matching methods</b> perform on various data generating processes and discuss if any one method <b>can</b> be deemed \u201cbetter\u201d for a certain type of dataset.", "dateLastCrawled": "2022-01-30T00:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Updated: Lanmanserver and</b> Lanmanworkstation Tuning", "url": "https://searchvirtualdesktop.techtarget.com/opinion/Updated-Lanmanserver-and-Lanmanworkstation-Tuning", "isFamilyFriendly": true, "displayUrl": "https://searchvirtualdesktop.techtarget.com/opinion/<b>Updated-Lanmanserver-and</b>-Lanman...", "snippet": "<b>Small</b> WorkItems use less memory, but large WorkItems <b>can</b> improve performance. When running applications that use a lot of copy or move functions to a remote server (profiles anyone?), the speed at which this function completes is determined by network speed (of course) and by the SMB size. By increasing this WorkItems size, you will allow the server to complete its file copies faster. This will increase the performance of the application <b>making</b> the copy/move calls. For computers running ...", "dateLastCrawled": "2022-02-03T08:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "4 Ways to Boost <b>Experience Replay</b> | Towards Data Science", "url": "https://towardsdatascience.com/4-ways-to-boost-experience-replay-999d9f17f7b6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/4-ways-to-boost-<b>experience-replay</b>-999d9f17f7b6", "snippet": "Common in many methods, we <b>can</b> train Q-values with n-step lookaheads. In classic Q-learning, targets are produced by using a one-step lookahead; we glanced in the future by one timestep. For n greater than one, we collect experiences in groups of n and \u201cunroll\u201d the transition, getting a more explicit target value for our value <b>update</b>.", "dateLastCrawled": "2022-02-02T21:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Performance Tuning in MySQL</b> \u2013 Stackify", "url": "https://stackify.com/performance-tuning-in-mysql/", "isFamilyFriendly": true, "displayUrl": "https://stackify.com/<b>performance-tuning-in-mysql</b>", "snippet": "The processor\u2019s speed shows how fast your <b>machine</b> is. The top command will give you insight into your CPU and memory usage per process \u2014 in other words, how your resources are being used. When using MySQL, keep an eye on that particular process as a percentage of usage. Anything too high and the bottleneck is likely your <b>machine</b>, which means it needs to be upgraded. Memory. Adjusting or improving your memory will boost the total RAM in your MySQL server and improve performance. Head to ...", "dateLastCrawled": "2022-02-02T02:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Demystifying Neural Network in <b>Skip-Gram</b> Language Modeling | Pythonic ...", "url": "https://aegis4048.github.io/demystifying_neural_network_in_skip_gram_language_modeling", "isFamilyFriendly": true, "displayUrl": "https://aegis4048.github.io/demystifying_neural_network_in_<b>skip_gram</b>_language_modeling", "snippet": "The cost function for the <b>Skip-Gram</b> model proposed in the Word2Vec original paper has the following equation: J ( \u03b8) = \u2212 1 T \u2211 t = 1 T \u2211 \u2212 c \u2264 j \u2264 c, j \u2260 0 log. \u2061. p ( w t + j \u2223 w t; \u03b8) Here, what gives us headache is the expression, 1 T \u2211 t = 1 T, because T <b>can</b> be larger than billions or more in many NLP applications.", "dateLastCrawled": "2022-02-02T20:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>What&#39;s new</b>? - <b>DECALmachine</b>", "url": "https://machin3.io/DECALmachine/docs/whatsnew/", "isFamilyFriendly": true, "displayUrl": "https://machin3.io/<b>DECALmachine</b>/docs/<b>whatsnew</b>", "snippet": "A <b>small</b> bugfix release in response to Blender 2.93.4 breaking the TrimCut tool. This release also addresses some some rare MacOS and Linux issues, that have come up. 2.4.0. This release focuses mostly on improving the general workflow in <b>DECALmachine</b> and it tries to iron out various usability kinks. A lot of this in direct response to user suggestions, so thank you for providing feedback, and a big shoutout to funcom. Decal Creation. Starting off with decal creation, you <b>can</b> now easily name ...", "dateLastCrawled": "2022-01-26T08:49:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> fundamentals I: An <b>analogy</b> | Finn Rietz.dev", "url": "http://www.finnrietz.dev/machine%20learning/part-1-analogy/", "isFamilyFriendly": true, "displayUrl": "www.finnrietz.dev/<b>machine</b> <b>learning</b>/part-1-<b>analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> fundamentals I: An <b>analogy</b> Tags: <b>Machine</b> <b>Learning</b> fundamentals. Categories: <b>Machine</b> <b>Learning</b>. Updated: March 3, 2020. 11 minute read On this page. Introduction and motivation; Setting the scene for supervised <b>learning</b>; Telling right from wrong ; About parameters and artificial <b>learning</b>; Summary; Introduction and motivation. I remember the first weeks of attending Professor Uc-Cetina\u2019s lecture on <b>Machine</b> <b>Learning</b>, which was my first \u201creal\u201d academic encounter with the ...", "dateLastCrawled": "2022-01-16T09:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> in <b>Machine</b> <b>Learning</b>", "url": "https://cambum.net/CCE/LearningParameter.pdf", "isFamilyFriendly": true, "displayUrl": "https://cambum.net/CCE/<b>LearningParameter</b>.pdf", "snippet": "We can convert a <b>machine</b> <b>learning</b> problem into an optimization problem by minimizing the expected loss on the training set. This means replacing the true distribution p(x, y) with the empirical distribution p\u1d27(x, y) defined by the training set. We now minimize the empirical risk \u2022where m is the number of training examples. 10 Empirical Probability Distribution from Training Data Loss Function Model Parameters. Differences in Classical Optimization and ML \u2022In optimization problem, we ...", "dateLastCrawled": "2022-01-29T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b>. November 2017 ; Authors: Colleen Farrelly. Jenzabar; Download file PDF Read file. Download file PDF. Read file. Download citation. Copy link Link copied. Read file ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A <b>machine</b> <b>learning</b> approach to Bayesian <b>parameter</b> estimation | npj ...", "url": "https://www.nature.com/articles/s41534-021-00497-w", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-021-00497-w", "snippet": "In <b>analogy</b> with the digits 0-9, ... The <b>machine</b>-<b>learning</b>-based <b>parameter</b> estimation illustrated in this manuscript can be readily applied for data analysis in current quantum sensors, providing ...", "dateLastCrawled": "2022-02-03T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "Optimization methods are applied to minimize the loss function by changing the <b>parameter</b> values, which is the central theme of <b>machine</b> <b>learning</b>.Zero-one loss is L0-1 = 1 (m &lt;= 0); in zero-one loss, value of loss is 0 for m &gt;= 0 whereas 1 for m &lt; 0. The difficult part with this loss is it is not differentiable, non-convex, and also NP-hard. Hence, in order to make optimization feasible and solvable, these losses are replaced by different surrogate losses for different problems.", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The Hitchhiker\u2019s Guide to Optimization in <b>Machine Learning</b> | by Aman ...", "url": "https://towardsdatascience.com/the-hitchhikers-guide-to-optimization-in-machine-learning-edcf5a104210", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-hitchhikers-guide-to-optimization-in-<b>machine</b>...", "snippet": "<b>Machine Learning</b> is the ideal culmination of Applied Mathematics and Computer Science, where we train and use data-driven applications to run inferences on the available data. Generally speaking, for an ML task, the type of inference (i.e., the prediction that the model makes) varies on the basis of the problem statement and the type of data one is dealing with for the task at hand. However, in contrast to these dissimilarities, these algorithms tend to share some similarities as well ...", "dateLastCrawled": "2022-02-02T19:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Artificial Intelligence Open Elective Module</b> 5: <b>Learning</b> CH15", "url": "https://hemanthrajhemu.github.io/FutureVisionBIE/DOWNLOAD/AI/AI_Module5_Learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://hemanthrajhemu.github.io/FutureVisionBIE/DOWNLOAD/AI/AI_Module5_<b>Learning</b>.pdf", "snippet": "\u2022 <b>Machine</b> <b>learning</b> systems perform the following iteratively: Produce a result Evaluate it against expected result Tweak a system \u2022 <b>Machine</b> <b>learning</b> systems also discover patterns without prior expected results \u2022 Open box: changes are clearly visible in the knowledge base and clearly interpretable by the human users. \u2022 Black box: changes done to the system are not readily visible or understandable. 5 Learner Architecture \u2022 <b>Machine</b> <b>learning</b> systems has the four main components ...", "dateLastCrawled": "2022-01-06T03:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - How does Gradient Descent work? - Data Science Stack ...", "url": "https://datascience.stackexchange.com/questions/102509/how-does-gradient-descent-work", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/102509/how-does-gradient-descent-work", "snippet": "I know the calculus and the famous hill and valley <b>analogy</b> (so to say) of gradient descent. However, I find the <b>update</b> rule of the weights and biases quite terrible. Let&#39;s say we have a couple of parameters, one weight &#39;w&#39; and one bias &#39;b&#39;. Using SGD, we can <b>update</b> both w and b after the evaluation of each mini-batch. If the size of the mini ...", "dateLastCrawled": "2022-01-16T12:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Gradient Descent in Logistic Regression [Explained</b> for ... - upGrad blog", "url": "https://www.upgrad.com/blog/gradient-descent-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/<b>gradient-descent-in-logistic-regression</b>", "snippet": "The reason is simple: it needs to compute the gradient, and <b>update</b> values simultaneously for every <b>parameter</b>,and that too for every training example. So think about all those calculations! It\u2019s massive, and hence there was a need for a slightly modified Gradient Descent Algorithm, namely \u2013 Stochastic Gradient Descent Algorithm (SGD). The only difference SGD has with Normal Gradient Descent is that, in SGD, we don\u2019t deal with the entire training instance at a single time. In SGD, we ...", "dateLastCrawled": "2022-01-28T16:49:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(parameter update)  is like +(making small tweaks to a machine)", "+(parameter update) is similar to +(making small tweaks to a machine)", "+(parameter update) can be thought of as +(making small tweaks to a machine)", "+(parameter update) can be compared to +(making small tweaks to a machine)", "machine learning +(parameter update AND analogy)", "machine learning +(\"parameter update is like\")", "machine learning +(\"parameter update is similar\")", "machine learning +(\"just as parameter update\")", "machine learning +(\"parameter update can be thought of as\")", "machine learning +(\"parameter update can be compared to\")"]}