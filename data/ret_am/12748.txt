{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "AI <b>in Society: 2. Algorithmic Fairness</b> - Kojin Oshiba", "url": "https://kojinoshiba.com/fairness/", "isFamilyFriendly": true, "displayUrl": "https://kojinoshiba.com/fairness", "snippet": "Fairness Through <b>Unawareness</b>. If we don\u2019t want to discriminate based on race, can\u2019t we just remove that from the set of features? This is the idea behind Fairness Through <b>Unawareness</b> (FTU). Essentially, FTU claims that a model is fair if it\u2019s not trained using <b>sensitive</b> attributes. FTU is a good starting point, but it is quite easy to see that this definition is too na\u00efve. For example, what if there was a feature about the zip code of where the criminals lived? Typically, zip code is ...", "dateLastCrawled": "2022-01-19T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Awareness in practice: tensions in access to <b>sensitive</b> <b>attribute</b> data ...", "url": "https://www.researchgate.net/publication/347462368_Awareness_in_practice_tensions_in_access_to_sensitive_attribute_data_for_antidiscrimination", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/347462368_Awareness_in_practice_tensions_in...", "snippet": "Bogen et al. [13] survey the requirements of U.S anti-discrimination law around the collection and usage of <b>sensitive</b> <b>attribute</b> data in employment, credit, and healthcare, and find that &quot;there are ...", "dateLastCrawled": "2022-01-14T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Classification", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "No fairness through <b>unawareness</b>. Some have hoped that removing or ignoring <b>sensitive</b> attributes would somehow ensure the impartiality of the resulting classifier. Unfortunately, this practice is usually somewhere on the spectrum between ineffective and harmful. In a typical data set, we have many features that are slightly correlated with the <b>sensitive</b> <b>attribute</b>. Visiting the website pinterest.com, for example, has a small statistical correlation with being female. As of August 2017, 58.9% ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The Man, The Machine, And The <b>Black</b> <b>Box</b>: ML Observability", "url": "https://blog.re-work.co/the-man-the-machine-and-the-black-box-ml-observability/", "isFamilyFriendly": true, "displayUrl": "https://blog.re-work.co/the-man-the-machine-and-the-<b>black</b>-<b>box</b>-ml-observability", "snippet": "Aparna believes that the most commonly used model across industries is <b>unawareness</b>. If I don&#39;t include <b>sensitive</b> attributes in my model, then clearly my models aren&#39;t biased. There is nothing to learn also. This connotation also has one really big problem in that, models can learn off of proxy information that could hide this protected class, protected class information. And you end up bleeding in these biases without even being aware of it. And in some organizations, that&#39;s enough to kind ...", "dateLastCrawled": "2022-01-21T07:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Measuring and Mitigating Algorithmic Bias \u00b7 Notes", "url": "https://jsinkers.github.io/notes/notebooks/machine_learning/03_fairness.html", "isFamilyFriendly": true, "displayUrl": "https://jsinkers.github.io/notes/notebooks/machine_learning/03_fairness.html", "snippet": "consider applying fairness through <b>unawareness</b>: would model be fair? no: there may be other attributes correlated with race, so may still be unfair; Problem: general features may be strongly correlated with <b>sensitive</b> features; this approach doesn\u2019t generally result in a fair model; Fairness Criteria Positive predictive value/precision. proportion of positive predictions that are truly positive \\[PPV = P = \\frac{TP}{TP+FP}\\] True positive rate/Recall. proportion of truly positive instances ...", "dateLastCrawled": "2022-01-28T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "160k+ high school students will only graduate if a statistical model ...", "url": "http://positivelysemidefinite.com/2020/06/160k-students.html", "isFamilyFriendly": true, "displayUrl": "positivelysemidefinite.com/2020/06/160k-students.html", "snippet": "Even if you don\u2019t include a <b>sensitive</b> <b>attribute</b> in a model, the model will learn it. Fairness through <b>unawareness</b> reminds me of the Chappelle Show educated guess line skit. Dave first guesses the race of the caller, then uses that to make a guess about the circumstances of the caller. Dave is \u2018a model\u2019 which is making malicious ...", "dateLastCrawled": "2022-01-31T10:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Patient-Reported Barriers to Colorectal Cancer Screening", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2946825/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2946825", "snippet": "<b>Unawareness</b> of the prevalence of colorectal cancer ... \u201cI&#39;ve had you know <b>like</b> the rectal and the stool testing [in the office]...and I always felt <b>like</b> if they found something there then it would go farther.\u201d An African-American woman said, \u201cI&#39;ve never had one of these [FOBT home kits] given to me, but I have one done every time I have my annual.\u201d Test-Specific Barriers. Barriers associated with specific tests (Table 5) were generally inutitive (\u201cadults don&#39;t play with poop ...", "dateLastCrawled": "2022-01-27T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "An introduction to Fairness in Machine Learning", "url": "https://cse.iitkgp.ac.in/~saptarshi/courses/ml2020s/ML-15-Fairness.pdf", "isFamilyFriendly": true, "displayUrl": "https://cse.iitkgp.ac.in/~saptarshi/courses/ml2020s/ML-15-Fairness.pdf", "snippet": "A --Protected <b>attribute</b>; can take values from {0, 1} Y\u2019 = 0 means rejection and Y\u2019 = 1 means selection (according to C) Let us assume A ~ Gender; A = 0 for Male and A = 1 for Female. Definition 1: Independence One of the most well-known criteria for fairness; also called Statistical Parity or Demographic Parity Strict version: P (Y\u2019 = 1 | A = 0) = P (Y\u2019 = 1 | A = 1) Probabilityof selection for Male should be equal to probability of selection for Female Several less strict versions, e ...", "dateLastCrawled": "2021-12-28T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "7 Questions to Ask <b>When Designing and Implementing Background Jobs</b> | by ...", "url": "https://codeburst.io/7-questions-to-ask-when-designing-and-implementing-background-jobs-a5cdb360839c", "isFamilyFriendly": true, "displayUrl": "https://codeburst.io/7-questions-to-ask-<b>when-designing-and-implementing-background</b>...", "snippet": "A background job is similar to a <b>black</b> <b>box</b> that processes input data and emits final results. The input data could be data records from a database, JSON objects from an API endpoint, files from an SFTP server, XML data over a TCP socket, messages in a queue, video/audio streams, and whatnot. In a happy path, all input data are sweet and lovely. To the contrary, human or machine errors can result in input data problems, thus breaking the program flow in background jobs. We have heard the ...", "dateLastCrawled": "2022-02-02T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>Black</b>-<b>box</b> Monitoring Approach to Measure Microservices Runtime ...", "url": "https://www.researchgate.net/publication/347578494_A_Black-box_Monitoring_Approach_to_Measure_Microservices_Runtime_Performance", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/347578494_A_<b>Black</b>-<b>box</b>_Monitoring_Approach_to...", "snippet": "For instance, two papers use a <b>black</b>-<b>box</b> dynamic analysis to gather results. This meant they focused on the measurable results of the application rather than the source code, with a framework ...", "dateLastCrawled": "2022-01-27T12:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "An introduction to Fairness in Machine Learning", "url": "https://cse.iitkgp.ac.in/~saptarshi/courses/ml2020s/ML-15-Fairness.pdf", "isFamilyFriendly": true, "displayUrl": "https://cse.iitkgp.ac.in/~saptarshi/courses/ml2020s/ML-15-Fairness.pdf", "snippet": "A Naive approach: <b>Unawareness</b> Do not include the <b>sensitive</b> attributes as features in the training data Fundamental limitation -there can be many other features that are highly correlated with the <b>sensitive</b> attributes E.g., height is often correlated with gender E.g., zip code is often correlated to racein USA", "dateLastCrawled": "2021-12-28T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Man, The Machine, And The <b>Black</b> <b>Box</b>: ML Observability", "url": "https://blog.re-work.co/the-man-the-machine-and-the-black-box-ml-observability/", "isFamilyFriendly": true, "displayUrl": "https://blog.re-work.co/the-man-the-machine-and-the-<b>black</b>-<b>box</b>-ml-observability", "snippet": "Aparna believes that the most commonly used model across industries is <b>unawareness</b>. If I don&#39;t include <b>sensitive</b> attributes in my model, then clearly my models aren&#39;t biased. There is nothing to learn also. This connotation also has one really big problem in that, models can learn off of proxy information that could hide this protected class, protected class information. And you end up bleeding in these biases without even being aware of it. And in some organizations, that&#39;s enough to kind ...", "dateLastCrawled": "2022-01-21T07:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Classification - fairmlbook.org", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "No fairness through <b>unawareness</b>. Some have hoped that removing or ignoring <b>sensitive</b> attributes would somehow ensure the impartiality of the resulting classifier. Unfortunately, this practice is usually somewhere on the spectrum between ineffective and harmful. In a typical data set, we have many features that are slightly correlated with the <b>sensitive</b> <b>attribute</b>. Visiting the website pinterest.com, for example, has a small statistical correlation with being female. As of August 2017, 58.9% ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Measuring and Mitigating Algorithmic Bias \u00b7 Notes", "url": "https://jsinkers.github.io/notes/notebooks/machine_learning/03_fairness.html", "isFamilyFriendly": true, "displayUrl": "https://jsinkers.github.io/notes/notebooks/machine_learning/03_fairness.html", "snippet": "<b>sensitive</b> <b>attribute</b> shall be statistically independent of the prediction for the classifier this means it is fair if - probability of good credit given martian is the same as the probability of good credit given human", "dateLastCrawled": "2022-01-28T09:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "21 fairer ML solutions - courses.cs.vt.edu", "url": "https://courses.cs.vt.edu/cs4824/Spring19/slide_pdfs/21%20fairer%20ML%20solutions.pdf", "isFamilyFriendly": true, "displayUrl": "https://courses.cs.vt.edu/cs4824/Spring19/slide_pdfs/21 fairer ML solutions.pdf", "snippet": "We propose a criterion for discrimination against a speci\ufb01ed <b>sensitive</b> <b>attribute</b> in su-pervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are avail- able, we show how to optimally adjust any learned predictor so as to remove discrimination according to our de\ufb01nition. Our framework also improves incentives by shifting the cost of poor classi\ufb01cation from disadvantaged ...", "dateLastCrawled": "2022-01-04T18:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Awareness in practice: tensions in access to <b>sensitive</b> <b>attribute</b> data ...", "url": "https://www.researchgate.net/publication/347462368_Awareness_in_practice_tensions_in_access_to_sensitive_attribute_data_for_antidiscrimination", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/347462368_Awareness_in_practice_tensions_in...", "snippet": "Bogen et al. [13] survey the requirements of U.S anti-discrimination law around the collection and usage of <b>sensitive</b> <b>attribute</b> data in employment, credit, and healthcare, and find that &quot;there are ...", "dateLastCrawled": "2022-01-14T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "THIS IS YOUR PRESENTATION (OR SLIDEDOC) TITLE", "url": "https://courses.cs.washington.edu/courses/cse416/20su/files/lectures/lec17/17_course_wrap_up.pdf", "isFamilyFriendly": true, "displayUrl": "https://courses.cs.washington.edu/courses/cse416/20su/files/lectures/lec17/17_course...", "snippet": "hurt or benefit people with certain <b>sensitive</b> <b>attribute</b> values 9. Fairness Frameworks No consensus on the mathematical definition of fairness Many papers have attempted to add frameworks - <b>unawareness</b> - demographic parity - equalized odds - predictive rate parity - individual fairness - counterfactual fairness Tradeoff between accuracy and fairness 10. Research directions in de-biasing ML Debiasing ML when you don\u2019t have access to private data - [race, gender, age] are protected attributes ...", "dateLastCrawled": "2022-01-23T14:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "160k+ high school students will only graduate if a statistical model ...", "url": "http://positivelysemidefinite.com/2020/06/160k-students.html", "isFamilyFriendly": true, "displayUrl": "positivelysemidefinite.com/2020/06/160k-students.html", "snippet": "Even if you don\u2019t include a <b>sensitive</b> <b>attribute</b> in a model, the model will learn it. Fairness through <b>unawareness</b> reminds me of the Chappelle Show educated guess line skit. Dave first guesses the race of the caller, then uses that to make a guess about the circumstances of the caller. Dave is \u2018a model\u2019 which is making malicious ...", "dateLastCrawled": "2022-01-31T10:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "7 Questions to Ask <b>When Designing and Implementing Background Jobs</b> | by ...", "url": "https://codeburst.io/7-questions-to-ask-when-designing-and-implementing-background-jobs-a5cdb360839c", "isFamilyFriendly": true, "displayUrl": "https://codeburst.io/7-questions-to-ask-<b>when-designing-and-implementing-background</b>...", "snippet": "A background job <b>is similar</b> to a <b>black</b> <b>box</b> that processes input data and emits final results. The input data could be data records from a database, JSON objects from an API endpoint, files from an SFTP server, XML data over a TCP socket, messages in a queue, video/audio streams, and whatnot. In a happy path, all input data are sweet and lovely. To the contrary, human or machine errors can result in input data problems, thus breaking the program flow in background jobs.", "dateLastCrawled": "2022-02-02T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Gender Slopes: Counterfactual Fairness for Computer Vision Models by ...", "url": "https://deepai.org/publication/gender-slopes-counterfactual-fairness-for-computer-vision-models-by-attribute-manipulation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/gender-slopes-counterfactual-fairness-for-computer...", "snippet": "<b>Similar</b> to (Kusner et al., 2017), ... Second, our research incorporates the generated data to measure the bias of <b>black</b>-<b>box</b> image classification APIs whereas (Denton et al., 2019) measures the bias of a dataset open to public (Liu et al., 2015). Using our distinct method and data, we aim to identify the internal biases of models trained from unknown data. Counterfactual Data Synthesis Problem Formulation. The objective of our paper is to measure counterfactual fairness of a predictor Y, a ...", "dateLastCrawled": "2021-12-03T02:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Bias and Algorithmic <b>Fairness</b>. The modern business leader\u2019s new\u2026 | by ...", "url": "https://towardsdatascience.com/bias-and-algorithmic-fairness-10f0805edc2b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/bias-and-algorithmic-<b>fairness</b>-10f0805edc2b", "snippet": "But while I previously <b>thought</b> the <b>black</b> <b>box</b> just needs safeguards to make sure ... (gender pay gap, discrimination etc.) and the data set includes <b>sensitive</b> data: race and sex. Consequently, we remove that <b>sensitive</b> data from the model input in an attempt to build a group unaware classifier. The following diagram shows the NeuralNetwork architecture we use for our problem: The architecture uses an Encoder Neural Network to create a shared data embedding which feeds 3 classification neural ...", "dateLastCrawled": "2022-01-29T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Counterfactual Fairness \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1703.06856/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1703.06856", "snippet": "Indeed, we demonstrate that depending on the relationship between a <b>sensitive</b> <b>attribute</b> and the data, certain definitions of fairness <b>can</b> actually increase discrimination. We describe how techniques from causal inference <b>can</b> be effective tools for designing fair algorithms and argue, as in DeDeo ( 2014 ) , that it is essential to properly address causality.", "dateLastCrawled": "2021-12-15T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Patient-Reported Barriers to Colorectal Cancer Screening", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2946825/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2946825", "snippet": "The groups were divided by gender and race because of evidence that such groups may have different perspectives on health, health care, and testing and may be more candid about <b>sensitive</b> topics in homogeneous groups. Focus groups were not restricted by screening status because it was <b>thought</b> that those with previous screening also experience barriers and that discussions would be enhanced if people had varying screening experiences. Participants were paid $50 for participation. The sessions ...", "dateLastCrawled": "2022-01-27T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The <b>Chinese Room Argument</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/chinese-room/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/<b>chinese-room</b>", "snippet": "These cyborgization <b>thought</b> experiments <b>can</b> be linked to the <b>Chinese Room</b>. Suppose Otto has a neural disease that causes one of the neurons in my brain to fail, but surgeons install a tiny remotely controlled artificial neuron, a synron, along side his disabled neuron. The control of Otto\u2019s neuron is by John Searle in the <b>Chinese Room</b>, unbeknownst to both Searle and Otto. Tiny wires connect the artificial neuron to the synapses on the cell-body of his disabled neuron. When his artificial ...", "dateLastCrawled": "2022-02-03T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A <b>Black</b>-<b>box</b> Monitoring Approach to Measure Microservices Runtime ...", "url": "https://www.researchgate.net/publication/347578494_A_Black-box_Monitoring_Approach_to_Measure_Microservices_Runtime_Performance", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/347578494_A_<b>Black</b>-<b>box</b>_Monitoring_Approach_to...", "snippet": "For instance, two papers use a <b>black</b>-<b>box</b> dynamic analysis to gather results. This meant they focused on the measurable results of the application rather than the source code, with a framework ...", "dateLastCrawled": "2022-01-27T12:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Critical thinking, the nursing process, and clinical judgment</b> | Nurse Key", "url": "https://nursekey.com/critical-thinking-the-nursing-process-and-clinical-judgment/", "isFamilyFriendly": true, "displayUrl": "https://nursekey.com/<b>critical-thinking-the-nursing-process-and-clinical-judgment</b>", "snippet": "CHAPTER 8 <b>Critical thinking, the nursing process, and clinical judgment</b> Learning outcomes After studying this chapter, students will be able to: \u2022 Define critical thinking. \u2022 Describe the importance of critical thinking in nursing. \u2022 Contrast the characteristics of \u201cnovice thinking\u201d with those of \u201cexpert thinking.\u201d \u2022 Explain the purpose and phases of the nursing process. \u2022 Differentiate between nursing\u2026", "dateLastCrawled": "2022-02-02T23:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Algorithmic Fairness: Choices, Assumptions, and Definitions</b> | Annual ...", "url": "https://www.annualreviews.org/doi/full/10.1146/annurev-statistics-042720-125902", "isFamilyFriendly": true, "displayUrl": "https://www.annualreviews.org/doi/full/10.1146/annurev-statistics-042720-125902", "snippet": "A recent wave of research has attempted to define fairness quantitatively. In particular, this work has explored what fairness might mean in the context of decisions based on the predictions of statistical and machine learning models. The rapid growth of this new field has led to wildly inconsistent motivations, terminology, and notation, presenting a serious challenge for cataloging and comparing definitions. This article attempts to bring much-needed order. First, we explicate the various ...", "dateLastCrawled": "2022-02-02T18:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Unconscious influences on decision making: A critical review ...", "url": "https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/unconscious-influences-on-decision-making-a-critical-review/86885344F7E8A44457C3FC63CFA3F3AF", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/...", "snippet": "The difference between B and C is subtle: In one case (C) it is <b>unawareness</b> of a cue, whereas in the other (B) it is <b>unawareness</b> of the ecological or predictive validity of the cue. (Arguably, lack of awareness of a cue entails lack of awareness of its validity, hence cases of <b>unawareness</b> at C entail <b>unawareness</b> at B as well.) Point D refers to a lack of awareness of one&#39;s utilization of cues. A doctor, for example, might appropriately base his or her diagnosis on features present in a ...", "dateLastCrawled": "2022-01-23T08:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "RoboCode-Ethicists Privacy-friendly robots, an ethical responsibility ...", "url": "https://www.alexandria.unisg.ch/241797/1/ACM_Web_Science_Robocode.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.alexandria.unisg.ch/241797/1/ACM_Web_Science_Robocode.pdf", "snippet": "(calmness) and the <b>black</b> <b>box</b> problem, i.e. users\u201f <b>unawareness</b> of and missing knowledge about how robots work and how the algorithms they apply function. In Chapter 3 we focus on ethical issues in robotics. We present a brief outline of robot ethics (3.1), and present two different rationalities in this context, applying", "dateLastCrawled": "2021-09-19T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Using Zaltman Metaphor Elicitation Technique to Map Beneficiaries</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/1098214016649054", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/1098214016649054", "snippet": "Based on the notion that mental life is unconscious and <b>can</b> provide us with much deeper meanings for <b>thought</b> and behavior (Zaltman, 1997), methods like ZMET, which use participant-produced metaphorical images to allow the unconscious states of people to be brought to a level of awareness, <b>can</b> therefore lead to discoveries of new elements to incorporate into programs and help capture elements that do not work or create undesired outcomes. The attributes, consequences, and values as end states ...", "dateLastCrawled": "2022-01-03T08:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "We <b>can</b> broaden this notion a bit and also include all other features, not just the <b>sensitive</b> <b>attribute</b>. So, let\u2019s call a criterion observational if it is a property of the joint distribution of the features X, the <b>sensitive</b> <b>attribute</b> A, a score function R and an outcome variable Y. Formally, this means an observational property is defined by set of joint distributions over a given set of variables.", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Bias and Fairness in Machine Learning, Part 2: building a baseline ...", "url": "https://freecontent.manning.com/bias-and-fairness-in-machine-learning-part-2-building-a-baseline-model-and-features/", "isFamilyFriendly": true, "displayUrl": "https://freecontent.manning.com/bias-and-fairness-in-machine-learning-part-2-building...", "snippet": "Building a Baseline Model. Check out part 1 for an intro to the dataset and how bias influences machine learning models, making fairness important to consider when dealing with data.. It\u2019s time to build our baseline ML model. For our first pass at our model, we will apply a bit of feature engineering to ensure our model interprets all of our data correctly and spend time analyzing the fairness/performance results of our model.", "dateLastCrawled": "2022-02-03T06:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "160k+ high school students will only graduate if a statistical model ...", "url": "http://positivelysemidefinite.com/2020/06/160k-students.html", "isFamilyFriendly": true, "displayUrl": "positivelysemidefinite.com/2020/06/160k-students.html", "snippet": "Even if you don\u2019t include a <b>sensitive</b> <b>attribute</b> in a model, the model will learn it. Fairness through <b>unawareness</b> reminds me of the Chappelle Show educated guess line skit. Dave first guesses the race of the caller, then uses that to make a guess about the circumstances of the caller. Dave is \u2018a model\u2019 which is making malicious ...", "dateLastCrawled": "2022-01-31T10:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Multi-Differential Fairness Auditor for Black</b> <b>Box</b> Classifiers - deepai.org", "url": "https://deepai.org/publication/multi-differential-fairness-auditor-for-black-box-classifiers", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>multi-differential-fairness-auditor-for-black</b>-<b>box</b>...", "snippet": "03/18/19 - Machine learning algorithms are increasingly involved in <b>sensitive</b> decision-making process with adversarial implications on indivi...", "dateLastCrawled": "2022-01-16T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Legal perspective on possible fairness measures \u2013 A legal discussion ...", "url": "https://www.sciencedirect.com/science/article/pii/S026736492100056X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S026736492100056X", "snippet": "Moreover, the <b>attribute</b> GPA depends on the observable <b>sensitive</b> <b>attribute</b> A which depicts the gender and a hidden <b>attribute</b> knowledge K that represents how much knowledge the applicant has. This causal graph <b>can</b> be specified by two equations as follows. G P A = \u03b1 1 \u00b7 A + \u03b1 2 \u00b7 K Y = \u03b2 1 \u00b7 G P A + \u03b2 2 \u00b7 D", "dateLastCrawled": "2021-10-26T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Black</b>-<b>box</b> Monitoring Approach to Measure Microservices Runtime ...", "url": "https://www.researchgate.net/publication/347578494_A_Black-box_Monitoring_Approach_to_Measure_Microservices_Runtime_Performance", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/347578494_A_<b>Black</b>-<b>box</b>_Monitoring_Approach_to...", "snippet": "For instance, two papers use a <b>black</b>-<b>box</b> dynamic analysis to gather results. This meant they focused on the measurable results of the application rather than the source code, with a framework ...", "dateLastCrawled": "2022-01-27T12:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Machine Learning \u2013 The Results Are Not the only Thing that Matters ...", "url": "https://link.springer.com/chapter/10.1007/978-3-030-50423-6_46", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-50423-6_46", "snippet": "Many researchers and systems architects are now using deep-learning capabilities (and other <b>black</b>-<b>box</b> ML methods) to solve detection or prediction tasks. However, in most cases, the results are provided by algorithms without any justification. Some solutions are offered as if it was magic and the Truth provider, while for decision-makers in a realistic setting the question why (the system arrives at certain answers) is crucial and has to be answered. Therefore, in this paper an overview of ...", "dateLastCrawled": "2021-12-22T00:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How Facebook\u2019s Advertising Algorithms <b>Can</b> Discriminate By Race and ...", "url": "https://techscience.org/a/2021101901/", "isFamilyFriendly": true, "displayUrl": "https://techscience.org/a/2021101901", "snippet": "<b>Black</b> users complained that the old system removed posts such as \u201cThank a <b>Black</b> woman for saving our country.\u201d Civil rights experts argued that \u201cyou <b>can</b>\u2019t have the conversation if it is being filtered out, bizarrely, by overly blunt hate speech algorithms\u201d[77]. Facebook is de-prioritizing its moderation of negative comments about \u201cWhites\u201d, \u201cmen\u201d, and \u201cAmericans\u201d as less likely to be harmful, while acknowledging that underrepresented groups need more protection [77].", "dateLastCrawled": "2022-02-02T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Soliciting Stakeholders&#39; Fairness Notions in Child Maltreatment ...", "url": "https://www.researchgate.net/publication/348980366_Soliciting_Stakeholders'_Fairness_Notions_in_Child_Maltreatment_Predictive_Systems", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/348980366_Soliciting_Stakeholders", "snippet": "PDF | Recent work in fair machine learning has proposed dozens of technical definitions of algorithmic fairness and methods for enforcing these... | Find, read and cite all the research you need ...", "dateLastCrawled": "2022-01-31T14:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Using Zaltman Metaphor Elicitation Technique to Map Beneficiaries</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/1098214016649054", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/1098214016649054", "snippet": "From this HVM, it <b>can</b> thus be concluded that parents with the experience of Peepoo in their children\u2019s school, <b>compared</b> with nonexperienced parents, see a more distinct connection between access to toilet, lack of disease, and clean environment and progress of the school and awareness of cleanliness, which <b>can</b> lead to donor involvement, giving the children an opportunity to learn skills and obtain an education and, therefore, have good self-esteem, obtain a job, and have a better life on ...", "dateLastCrawled": "2022-01-03T08:23:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "No fairness through <b>unawareness</b>. Some have hoped that removing or ignoring <b>sensitive</b> attributes would somehow ensure the impartiality of the resulting classifier. Unfortunately, this practice is usually somewhere on the spectrum between ineffective and harmful. In a typical data set, we have many features that are slightly correlated with the <b>sensitive</b> <b>attribute</b>. Visiting the website pinterest.com, for example, has a small statistical correlation with being female. As of August 2017, 58.9% ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) On Fair Representation in <b>Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/341736051_On_Fair_Representation_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../341736051_On_Fair_Representation_in_<b>Machine</b>_<b>Learning</b>", "snippet": "<b>Machine</b> <b>Learning</b> (ML) to <b>sensitive</b> areas such as \ufb01nancial, legal, and medical institutions as well as applications with high social impact such as employment procedures, fairness", "dateLastCrawled": "2022-01-26T19:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Fairness without the <b>sensitive</b> <b>attribute</b> via Causal Variational ...", "url": "https://www.researchgate.net/publication/354542106_Fairness_without_the_sensitive_attribute_via_Causal_Variational_Autoencoder", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/354542106_Fairness_without_the_<b>sensitive</b>...", "snippet": "<b>Machine</b> <b>learning</b> is a tool for building models that accurately represent input training data. When undesired biases concerning demographic groups are in the training data, well-trained models will ...", "dateLastCrawled": "2022-01-04T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>learning</b> glossary - DataTime", "url": "https://www.dtalg.com/article-1/", "isFamilyFriendly": true, "displayUrl": "https://www.dtalg.com/article-1", "snippet": "A distributed <b>machine</b> <b>learning</b> approach that trains <b>machine</b> <b>learning</b> models using decentralized examples residing on devices such as smartphones. In federated <b>learning</b>, a subset of devices downloads the current model from a central coordinating server. The devices use the examples stored on the devices to make improvements to the model. The devices then upload the model improvements (but not the training examples) to the coordinating server, where they are aggregated with other updates to ...", "dateLastCrawled": "2022-01-25T17:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Survey on Bias and Fairness in <b>Machine</b> <b>Learning</b> \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1908.09635/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1908.09635", "snippet": "With the widespread use of AI systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many <b>sensitive</b> environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in <b>machine</b> <b>learning</b>, natural language ...", "dateLastCrawled": "2021-11-15T17:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Manipulation by algorithms. Exploring the triangle of unfair commercial ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/eulj.12389?af=R", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/eulj.12389?af=R", "snippet": "Hence, the <b>machine</b> <b>learning</b> model will scrutinise large amounts of ... If the latter fuses economic transactions and privacy-<b>sensitive</b> data processing, the law should, to the extent that it is doctrinally possible and methodologically sound, mirror this tendency by building further bridges between different legal fields once considered separate.117 117 See the references in n. 14. The effects of privacy and GDPR breaches. This link is important because, for potential plaintiffs, it would ...", "dateLastCrawled": "2022-01-14T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Towards Fairness in Visual</b> Recognition: Effective Strategies for Bias ...", "url": "https://deepai.org/publication/towards-fairness-in-visual-recognition-effective-strategies-for-bias-mitigation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-fairness-in-visual</b>-recognition-effective...", "snippet": "Recent work on the effects of human bias on <b>machine</b> <b>learning</b> models investigates two challenging problems: identifying and quantifying bias in datasets, and mitigating its harmful effects. In relation to the former, [5, 27] study the effect of class-imbalance on <b>learning</b>, while reveal the surprising phenomenon of bias amplification. Additionally, recent works have shown that ML models possess bias towards legally protected classes [26, 6, 4, 7]. Our work complements these by presenting a ...", "dateLastCrawled": "2022-01-21T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The <b>Chinese Room Argument</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/chinese-room/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/<b>chinese-room</b>", "snippet": "A <b>machine</b> can be an intentional system because intentional explanations work in predicting the <b>machine</b>\u2019s behavior. Dennett also suggests that Searle conflates intentionality with awareness of intentionality. In his syntax-semantic arguments, \u201cSearle has apparently confused a claim about the underivability of semantics from syntax with a claim about the underivability of the consciousness of semantics from syntax\u201d (336). The emphasis on consciousness forces us to think about things from ...", "dateLastCrawled": "2022-02-03T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Critical rationalism and the state of unawareness in managers</b> ...", "url": "https://www.academia.edu/5847622/Critical_rationalism_and_the_state_of_unawareness_in_managers_theories", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/5847622/<b>Critical_rationalism_and_the_state</b>_of_<b>unawareness</b>_in...", "snippet": "Keywords Epistemology, organizational <b>learning</b>, positivism, strategy Managers\u2019 theories and <b>unawareness</b> Introducing the state of <b>unawareness</b> Human beings hold a theory of the world that guides their actions (Argyris, 1976a); managers draw upon their theories when they craft their strategies: \u2018Strategies are operationalizations of theories of the world\u2019 (Hedberg and Jonsson, 1977: 90). According to Mintzberg (1987: 16) the strategy embodies the theory: \u2018strategy is a perspective, its ...", "dateLastCrawled": "2021-10-28T03:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Hiding Incompetence</b> <b>By Being Polite, Positive</b> and Praising", "url": "https://omegazadvisors.com/2020/03/16/hiding-incompetence/", "isFamilyFriendly": true, "displayUrl": "https://omegazadvisors.com/2020/03/16/<b>hiding-incompetence</b>", "snippet": "Tags competence, Disruptive Innovation &amp; People <b>Analogy</b>, employees, politeness, positivity, praise , sycophant. Employees work to keep their jobs. It\u2019s not only about doing the job though. It\u2019s about influencing how bosses see them too. They know that if bosses like them they are more likely to see their work favorably. If bosses don\u2019t, they won\u2019t. Thus, this becomes a strategy for <b>hiding incompetence</b> too, getting the boss to like them. Gaining The Boss\u2019 Favor. Even if objective ...", "dateLastCrawled": "2022-01-16T16:06:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(unawareness (to a sensitive attribute))  is like +(black box)", "+(unawareness (to a sensitive attribute)) is similar to +(black box)", "+(unawareness (to a sensitive attribute)) can be thought of as +(black box)", "+(unawareness (to a sensitive attribute)) can be compared to +(black box)", "machine learning +(unawareness (to a sensitive attribute) AND analogy)", "machine learning +(\"unawareness (to a sensitive attribute) is like\")", "machine learning +(\"unawareness (to a sensitive attribute) is similar\")", "machine learning +(\"just as unawareness (to a sensitive attribute)\")", "machine learning +(\"unawareness (to a sensitive attribute) can be thought of as\")", "machine learning +(\"unawareness (to a sensitive attribute) can be compared to\")"]}