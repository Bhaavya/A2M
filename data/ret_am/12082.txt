{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The <b>Precision-Recall</b> Plot Is More Informative than the ROC Plot When ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4349800", "snippet": "For the numbers of <b>true</b> <b>and false</b> <b>positives</b> and negatives in the two datasets, ... If the same default values are assigned to these five instances as a measure to compensate for missing scores, the ROC <b>curve</b> <b>can</b> linearly continue to the point (1, 1) (15\u201320 in Fig. 2A). Although interpolation in PRC analysis requires more calculations than in ROC analysis, it is nonetheless critical to follow the correct procedure if misleading plots are to be avoided, especially when the distance of PRC ...", "dateLastCrawled": "2022-01-16T20:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Precision vs Recall</b> | Precision and <b>Recall Machine Learning</b>", "url": "https://www.analyticsvidhya.com/blog/2020/09/precision-recall-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2020/09/<b>precision-recall-machine-learning</b>", "snippet": "In the simplest terms, Precision is the ratio <b>between</b> the <b>True</b> <b>Positives</b> and all the <b>Positives</b>. For our problem statement, that would be the measure of patients that we correctly identify having a heart disease out of all the patients actually having it. Mathematically: What is the Precision for our model? Yes, it is 0.843 or, when it predicts that a patient has heart disease, it is correct around 84% of the time. Precision also gives us a measure of the relevant data points. It is important ...", "dateLastCrawled": "2022-02-02T20:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Machine Learning Experiment Scoring and Analysis - Financial Focus", "url": "https://h2oai.github.io/tutorials/machine-learning-experiment-scoring-and-analysis-financial-focus/", "isFamilyFriendly": true, "displayUrl": "https://h2oai.github.io/tutorials/machine-learning-experiment-scoring-and-analysis...", "snippet": "A ROC <b>curve</b> is a useful tool because it only focuses on how <b>well</b> the model <b>can</b> <b>distinguish</b> <b>between</b> classes. &quot;AUC&#39;s <b>can</b> help represent the probability that the classifier will rank a randomly selected positive observation higher than a randomly selected negative observation&quot; [4]. However, for models where the prediction happens rarely, a high AUC could provide a <b>false</b> sense that the model is correctly predicting the results. This is where the notion of precision and recall become important ...", "dateLastCrawled": "2022-01-29T04:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Binormal Precision\u2013Recall Curves for Optimal Classification</b> of ...", "url": "https://link.springer.com/article/10.1007/s12561-019-09231-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12561-019-09231-9", "snippet": "For algorithm II, this occurs at the point (0.1, 0.5), i.e., 200 <b>false</b> <b>positives</b> and 50 <b>true</b> <b>positives</b>; algorithm II gives a high <b>false</b> discovery rate of \\(200/(200+50)=0.8\\). On the other hand, algorithm I <b>can</b> achieve the same level of <b>true</b> positive rate (0.5) without making any <b>false</b> <b>positives</b>, leading to zero <b>false</b> discovery rate. In practice, in most typical cases, we prefer algorithm I although it has a comparatively smaller AUCROC. The reason for this is the large amount of area that ...", "dateLastCrawled": "2021-11-27T15:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>The Relationship Between Precision-Recall and</b> ROC Curves", "url": "https://www.researchgate.net/publication/215721831_The_Relationship_Between_Precision-Recall_and_ROC_Curves", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/215721831_The_Relationship_<b>Between</b>_Precision...", "snippet": "On the classification task, PRODeepSyn achieves an area under the receiver operator characteristics <b>curve</b> of 0.90, an area under the <b>precision-recall</b> <b>curve</b> of 0.63 and a Cohen&#39;s Kappa of 0.53. In ...", "dateLastCrawled": "2022-01-30T14:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) The <b>Precision-Recall</b> Plot Is More Informative than the ROC Plot ...", "url": "https://www.researchgate.net/publication/273155496_The_Precision-Recall_Plot_Is_More_Informative_than_the_ROC_Plot_When_Evaluating_Binary_Classifiers_on_Imbalanced_Datasets", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/273155496_The_<b>Precision-Recall</b>_Plot_Is_More...", "snippet": "two types of incorrect (or <b>false</b>) classification, <b>false</b> <b>positives</b> (FP) <b>and false</b> negatives (FN) (see Fig. 1B ). A 2x2 table formulated with these four outcomes is called a confusion matrix.", "dateLastCrawled": "2021-12-23T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Performance metrics</b> | Mastering Predictive Analytics with R", "url": "https://subscription.packtpub.com/book/application-development/9781783982806/1/ch01lvl1sec11/performance-metrics", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/book/application-development/9781783982806/1/ch01lvl...", "snippet": "This inverse relationship is often plotted for a particular problem on a <b>precision-recall</b> <b>curve</b>. By using an appropriate threshold parameter, we <b>can</b> often tune the performance of our model in such a way that we achieve a specific point on this <b>precision-recall</b> <b>curve</b> that is appropriate for our circumstances. For example, in some problem domains, we tend to be biased toward having a higher recall than a higher precision, because of the high cost of misclassifying an observation from the ...", "dateLastCrawled": "2022-01-29T16:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What would happen to the AUC and ROC curves if the model is unbalanced ...", "url": "https://www.quora.com/What-would-happen-to-the-AUC-and-ROC-curves-if-the-model-is-unbalanced-in-a-classification-problem", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-would-happen-to-the-AUC-and-ROC-<b>curves</b>-if-the-model-is...", "snippet": "Answer (1 of 2): Basically AUC and ROC curves are measures of <b>true</b> positive against <b>false</b> positive. With that said, if your training data is unbalanced, what happens is that you might get a lot of <b>false</b> <b>positives</b> <b>and false</b> negatives. The reason is because your model will pick up results from th...", "dateLastCrawled": "2022-01-20T11:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Data Science: <b>Confusion Matrix, Accuracy, Precision, Recall</b>, F score ...", "url": "https://www.datasciencesmachinelearning.com/2018/11/confusion-matrix-accuracy-precision.html", "isFamilyFriendly": true, "displayUrl": "https://www.datasciencesmachinelearning.com/2018/11/confusion-matrix-accuracy...", "snippet": "F1 = 2 * (<b>precision * recall</b>) / (<b>precision + recall</b>) However, F scores do not take <b>true</b> negatives into consideration. Other improved measures are. Matthews correlation coefficient (a value of +1 means perfect prediction, 0 means average random prediction and -1 means inverse prediction). Youden&#39;s J statistic (Sensitivity+specificity -1) Cohen&#39;s ...", "dateLastCrawled": "2022-01-28T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning Model Performance Metrics</b> | by Priyanka Dandale | Nerd ...", "url": "https://medium.com/nerd-for-tech/machine-learning-model-performance-metrics-84f94d39a92", "isFamilyFriendly": true, "displayUrl": "https://medium.com/nerd-for-tech/<b>machine-learning-model-performance-metrics</b>-84f94d39a92", "snippet": "<b>False</b> Positive Rate and <b>True</b> Positive Rate both have values in the range [0, 1]. FPR and TPR both are computed at varying threshold values such as (0.00, 0.02, 0.04, \u2026., 1.00) and a <b>graph</b> is drawn.", "dateLastCrawled": "2021-06-24T18:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Precision vs Recall</b> | Precision and <b>Recall Machine Learning</b>", "url": "https://www.analyticsvidhya.com/blog/2020/09/precision-recall-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2020/09/<b>precision-recall-machine-learning</b>", "snippet": "In the simplest terms, Precision is the ratio <b>between</b> the <b>True</b> <b>Positives</b> and all the <b>Positives</b>. For our problem statement, that would be the measure of patients that we correctly identify having a heart disease out of all the patients actually having it. Mathematically: What is the Precision for our model? Yes, it is 0.843 or, when it predicts that a patient has heart disease, it is correct around 84% of the time. Precision also gives us a measure of the relevant data points. It is important ...", "dateLastCrawled": "2022-02-02T20:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The <b>Precision-Recall</b> Plot Is More Informative than the ROC Plot When ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4349800", "snippet": "For the numbers of <b>true</b> <b>and false</b> <b>positives</b> and negatives in the two datasets, ... If the same default values are assigned to these five instances as a measure to compensate for missing scores, the ROC <b>curve</b> <b>can</b> linearly continue to the point (1, 1) (15\u201320 in Fig. 2A). Although interpolation in PRC analysis requires more calculations than in ROC analysis, it is nonetheless critical to follow the correct procedure if misleading plots are to be avoided, especially when the distance of PRC ...", "dateLastCrawled": "2022-01-16T20:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Binormal Precision\u2013Recall Curves for Optimal Classification</b> of ...", "url": "https://link.springer.com/article/10.1007/s12561-019-09231-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12561-019-09231-9", "snippet": "For algorithm II, this occurs at the point (0.1, 0.5), i.e., 200 <b>false</b> <b>positives</b> and 50 <b>true</b> <b>positives</b>; algorithm II gives a high <b>false</b> discovery rate of \\(200/(200+50)=0.8\\). On the other hand, algorithm I <b>can</b> achieve the same level of <b>true</b> positive rate (0.5) without making any <b>false</b> <b>positives</b>, leading to zero <b>false</b> discovery rate. In practice, in most typical cases, we prefer algorithm I although it has a comparatively smaller AUCROC. The reason for this is the large amount of area that ...", "dateLastCrawled": "2021-11-27T15:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Machine Learning Experiment Scoring and Analysis - Financial Focus", "url": "https://h2oai.github.io/tutorials/machine-learning-experiment-scoring-and-analysis-financial-focus/", "isFamilyFriendly": true, "displayUrl": "https://h2oai.github.io/tutorials/machine-learning-experiment-scoring-and-analysis...", "snippet": "A ROC <b>curve</b> is a useful tool because it only focuses on how <b>well</b> the model <b>can</b> <b>distinguish</b> <b>between</b> classes. &quot;AUC&#39;s <b>can</b> help represent the probability that the classifier will rank a randomly selected positive observation higher than a randomly selected negative observation&quot; [4]. However, for models where the prediction happens rarely, a high AUC could provide a <b>false</b> sense that the model is correctly predicting the results. This is where the notion of precision and recall become important ...", "dateLastCrawled": "2022-01-29T04:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Determining an Optimal Data Classification Model for Credibility-Based ...", "url": "https://link.springer.com/article/10.1007/s12626-021-00093-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12626-021-00093-6", "snippet": "<b>Precision/Recall</b> <b>Curve</b>. The second method used to analyse the performance of the machine learning algorithms is the <b>Precision/Recall</b> <b>Curve</b>. As stated in , the precision is a ratio of the number of <b>true</b> <b>positives</b> divided by the sum of the <b>true</b> <b>positives</b> <b>and false</b> <b>positives</b>. This <b>curve</b> describes how good a model is at predicting the positive ...", "dateLastCrawled": "2022-01-04T01:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) The <b>Precision-Recall</b> Plot Is More Informative than the ROC Plot ...", "url": "https://www.researchgate.net/publication/273155496_The_Precision-Recall_Plot_Is_More_Informative_than_the_ROC_Plot_When_Evaluating_Binary_Classifiers_on_Imbalanced_Datasets", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/273155496_The_<b>Precision-Recall</b>_Plot_Is_More...", "snippet": "two types of incorrect (or <b>false</b>) classification, <b>false</b> <b>positives</b> (FP) <b>and false</b> negatives (FN) (see Fig. 1B ). A 2x2 table formulated with these four outcomes is called a confusion matrix.", "dateLastCrawled": "2021-12-23T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Data Science: <b>Confusion Matrix, Accuracy, Precision, Recall</b>, F score ...", "url": "https://www.datasciencesmachinelearning.com/2018/11/confusion-matrix-accuracy-precision.html", "isFamilyFriendly": true, "displayUrl": "https://www.datasciencesmachinelearning.com/2018/11/confusion-matrix-accuracy...", "snippet": "F1 = 2 * (<b>precision * recall</b>) / (<b>precision + recall</b>) However, F scores do not take <b>true</b> negatives into consideration. Other improved measures are. Matthews correlation coefficient (a value of +1 means perfect prediction, 0 means average random prediction and -1 means inverse prediction). Youden&#39;s J statistic (Sensitivity+specificity -1) Cohen&#39;s ...", "dateLastCrawled": "2022-01-28T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Performance metrics</b> | Mastering Predictive Analytics with R", "url": "https://subscription.packtpub.com/book/application-development/9781783982806/1/ch01lvl1sec11/performance-metrics", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/book/application-development/9781783982806/1/ch01lvl...", "snippet": "This inverse relationship is often plotted for a particular problem on a <b>precision-recall</b> <b>curve</b>. By using an appropriate threshold parameter, we <b>can</b> often tune the performance of our model in such a way that we achieve a specific point on this <b>precision-recall</b> <b>curve</b> that is appropriate for our circumstances. For example, in some problem domains, we tend to be biased toward having a higher recall than a higher precision, because of the high cost of misclassifying an observation from the ...", "dateLastCrawled": "2022-01-29T16:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Chapter 11 Logistic Regression | Data Analysis and Visualization in R ...", "url": "https://gagneurlab.github.io/dataviz/chap-log-reg.html", "isFamilyFriendly": true, "displayUrl": "https://gagneurlab.github.io/dataviz/chap-log-reg.html", "snippet": "A classifier should maximize <b>true</b> <b>positives</b> (TP) and <b>true</b> negatives (TN), and minimize <b>false</b> negatives (FN) <b>and false</b> <b>positives</b> (FP) 11.5.3 Classification performance metrics. From the confusion matrix, various quality metrics have been defined. Moreover, depending on the application domain, the same quantities are referred to with <b>different</b> names. 44 We focus here on three metrics: The sensitivity refers to the fraction of actual <b>positives</b> that is predicted to be positive: \\(\\text ...", "dateLastCrawled": "2022-01-30T18:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What would happen to the AUC and ROC curves if the model is unbalanced ...", "url": "https://www.quora.com/What-would-happen-to-the-AUC-and-ROC-curves-if-the-model-is-unbalanced-in-a-classification-problem", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-would-happen-to-the-AUC-and-ROC-<b>curves</b>-if-the-model-is...", "snippet": "Answer (1 of 2): Basically AUC and ROC curves are measures of <b>true</b> positive against <b>false</b> positive. With that said, if your training data is unbalanced, what happens is that you might get a lot of <b>false</b> <b>positives</b> <b>and false</b> negatives. The reason is because your model will pick up results from th...", "dateLastCrawled": "2022-01-20T11:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Introduction to ROC analysis</b> - ResearchGate", "url": "https://www.researchgate.net/publication/222511520_Introduction_to_ROC_analysis", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/222511520", "snippet": "<b>graph</b> may <b>be thought</b> of as \u2018\u2018liberal\u2019\u2019: they make positive . classi\ufb01cations with weak evidence so they classify nearly. all <b>positives</b> correctly, but they often have high <b>false</b> posi-tive ...", "dateLastCrawled": "2022-02-01T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification Accuracy is Not Enough: More Performance Measures You ...", "url": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-", "snippet": "Precision is the number of <b>True</b> <b>Positives</b> divided by the number of <b>True</b> <b>Positives</b> <b>and False</b> <b>Positives</b>. Put another way, it is the number of positive predictions divided by the total number of positive class values predicted. It is also called the Positive Predictive Value (PPV). Precision <b>can</b> <b>be thought</b> of as a measure of a classifiers exactness. A low precision <b>can</b> also indicate a large number of <b>False</b> <b>Positives</b>. The precision of the All No Recurrence model is 0/(0+0) or not a number, or 0 ...", "dateLastCrawled": "2022-02-03T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "MitoFates: Improved Prediction of Mitochondrial Targeting Sequences and ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4390256/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4390256", "snippet": "Fig. 2 A shows the 11 point <b>precision-recall</b> <b>curve</b> (PR-<b>curve</b>) of each predictor averaged over 10 random selections of 500 negative test set proteins. MitoFates achieves an average precision of 84% on the PR-<b>curve</b>, outperforming TPpred2, Predotar, TargetP, and MitoProtII, which obtained an average precision of 81%, 79%, 78%, and 74%, respectively. In particular, MitoFates attains better precision for recall values of 50\u201380% (in this range the average precision of MitoFates, TPpred2 ...", "dateLastCrawled": "2022-01-22T12:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Evaluation metrics and validation of presence-only species distribution ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7811024/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7811024", "snippet": "The other two closely related groups were 1) metrics associated with <b>false</b> negatives (FN): AUC, Sensitivity, NPV, Recall, Detection rate, Balanced accuracy, TSS, and UPR, and 2) metrics associated with <b>true</b> <b>positives</b> (TP): NPV, S\u00f8rensen&#39;s Similarity Index, F1, Jaccard&#39;s Similarity Index, Kappa, Precision, PPV, Detection rate, Recall, and Sensitivity (Appendix 8). As is apparent from the results, relying on only one metric would be misleading, since individual metrics often tend to select ...", "dateLastCrawled": "2022-01-22T17:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "DeepLearning-500-questions/Chapter 2_TheBasisOfMachineLearning.md at ...", "url": "https://github.com/scutan90/DeepLearning-500-questions/blob/master/English%20version/ch02_MachineLearningFoundation/Chapter%202_TheBasisOfMachineLearning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/scutan90/DeepLearning-500-questions/blob/master/English version/ch02...", "snippet": "The ROC <b>curve</b> is an abbreviation for (Receiver Operating Characteristic <b>Curve</b>), which is a performance evaluation <b>curve</b> with sensitivity (<b>true</b> positive rate) as the ordinate and 1-specific (<b>false</b> positive rate) as the abscissa. . The ROC curves of <b>different</b> models for the same data set <b>can</b> be plotted in the same Cartesian coordinate system. The closer the ROC <b>curve</b> is to the upper left corner, the more reliable the corresponding model is. The model <b>can</b> also be evaluated by the area under the ...", "dateLastCrawled": "2022-01-13T17:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "GitHub - chilam27/Improve_Product_Review_System: Improved the ...", "url": "https://github.com/chilam27/Improve_Product_Review_System", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/chilam27/Improve_Product_Review_System", "snippet": "This plot tells us, specifically, how <b>well</b> my model <b>can</b> <b>distinguish</b> the classes (ratings) by showing the trade-off of <b>true</b> positive rate <b>and false</b>-positive rate for <b>different</b> threshold settings of the underlying model. Generally, if the <b>curve</b> is above the diagonal line (chance level) and the area is above 0.5, it <b>can</b> be considered a good ROC <b>curve</b>.", "dateLastCrawled": "2021-08-13T05:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A survey of Twitter research: Data model, <b>graph</b> structure, sentiment ...", "url": "https://www.sciencedirect.com/science/article/pii/S095741742030779X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S095741742030779X", "snippet": "<b>True</b> Positive, <b>True</b> Negative, <b>False</b> Positive, <b>False</b> Negative: Accuracy metrics: <b>Precision, Recall</b>, F1, Accuracy Benevenuto et al. (2010) Sensitivity: Area Under the <b>Curve</b> (AUC), Confidence Intervals Naveed et al. (2011) Efficiency : Time and resources needed for the complete workflow Grier et al. (2010) 3. Sentiment analysis. One of the most promising methods for content analysis in social media is sentiment analysis (Giachanou and Crestani, 2016, Mart\u00ednez-C\u00e1mara et al., 2014 ...", "dateLastCrawled": "2022-01-18T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Using AUC and Accuracy in Evaluating Learning Algorithms", "url": "https://www.researchgate.net/publication/220072647_Using_AUC_and_Accuracy_in_Evaluating_Learning_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220072647_Using_AUC_and_Accuracy_in...", "snippet": "The area under the <b>curve</b> (AUC) [39], [43] represents how <b>well</b> the binary classes (one vs. all in case of multiple classes) <b>can</b> be separated, with an ideal point at (0,1) where there are no ...", "dateLastCrawled": "2022-01-26T08:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Intrusion Detection System: A Survey \u2013 IJERT", "url": "https://www.ijert.org/intrusion-detection-system-a-survey", "isFamilyFriendly": true, "displayUrl": "https://www.ijert.org/intrusion-detection-system-a-survey", "snippet": "A labeled dataset is added to decrease the <b>false</b> <b>positives</b> and construct a supervised machine learning model by teaching it the difference <b>between</b> a usual and an attack packet in the network. The supervised model <b>can</b> expertly control the recognzed attacks and <b>can</b> identify variants of those attacks as <b>well</b>. The most common role in supervised learning is classification; but it is costly and time-consuming to manually mark data. The lack of adequate labeled data therefore forms the key ...", "dateLastCrawled": "2022-01-23T04:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning With Python - Quick Guide</b>", "url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_quick_guide.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/<b>machine_learning_with_python</b>/machine_learning_with...", "snippet": "To sigmoid <b>curve</b> <b>can</b> be represented with the help of following <b>graph</b>. We <b>can</b> see the values of y-axis lie <b>between</b> 0 and 1 and crosses the axis at 0.5. The classes <b>can</b> be divided into positive or negative. The output comes under the probability of positive class if it lies <b>between</b> 0 and 1. For our implementation, we are interpreting the output ...", "dateLastCrawled": "2022-02-02T17:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Precision vs Recall</b> | Precision and <b>Recall Machine Learning</b>", "url": "https://www.analyticsvidhya.com/blog/2020/09/precision-recall-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2020/09/<b>precision-recall-machine-learning</b>", "snippet": "In the simplest terms, Precision is the ratio <b>between</b> the <b>True</b> <b>Positives</b> and all the <b>Positives</b>. For our problem statement, that would be the measure of patients that we correctly identify having a heart disease out of all the patients actually having it. Mathematically: What is the Precision for our model? Yes, it is 0.843 or, when it predicts that a patient has heart disease, it is correct around 84% of the time. Precision also gives us a measure of the relevant data points. It is important ...", "dateLastCrawled": "2022-02-02T20:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The <b>Precision-Recall</b> Plot Is More Informative than the ROC Plot When ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4349800", "snippet": "For the numbers of <b>true</b> <b>and false</b> <b>positives</b> and negatives in the two datasets, ... If the same default values are assigned to these five instances as a measure to compensate for missing scores, the ROC <b>curve</b> <b>can</b> linearly continue to the point (1, 1) (15\u201320 in Fig. 2A). Although interpolation in PRC analysis requires more calculations than in ROC analysis, it is nonetheless critical to follow the correct procedure if misleading plots are to be avoided, especially when the distance of PRC ...", "dateLastCrawled": "2022-01-16T20:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Binormal Precision\u2013Recall Curves for Optimal Classification</b> of ...", "url": "https://link.springer.com/article/10.1007/s12561-019-09231-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12561-019-09231-9", "snippet": "For algorithm II, this occurs at the point (0.1, 0.5), i.e., 200 <b>false</b> <b>positives</b> and 50 <b>true</b> <b>positives</b>; algorithm II gives a high <b>false</b> discovery rate of \\(200/(200+50)=0.8\\). On the other hand, algorithm I <b>can</b> achieve the same level of <b>true</b> positive rate (0.5) without making any <b>false</b> <b>positives</b>, leading to zero <b>false</b> discovery rate. In practice, in most typical cases, we prefer algorithm I although it has a comparatively smaller AUCROC. The reason for this is the large amount of area that ...", "dateLastCrawled": "2021-11-27T15:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>The Relationship Between Precision-Recall and</b> ROC Curves", "url": "https://www.researchgate.net/publication/215721831_The_Relationship_Between_Precision-Recall_and_ROC_Curves", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/215721831_The_Relationship_<b>Between</b>_Precision...", "snippet": "On the classification task, PRODeepSyn achieves an area under the receiver operator characteristics <b>curve</b> of 0.90, an area under the <b>precision-recall</b> <b>curve</b> of 0.63 and a Cohen&#39;s Kappa of 0.53. In ...", "dateLastCrawled": "2022-01-30T14:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The <b>precision-recall</b> plot is more informative than the ROC plot when ...", "url": "https://europepmc.org/article/PMC/PMC4349800", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC4349800", "snippet": "The <b>precision-recall</b> plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. ... For the numbers of <b>true</b> <b>and false</b> <b>positives</b> and negatives in the two datasets, see Fig. 1C. While MMC and the three F \u03b2 scores also vary <b>between</b> the two datasets, precision is easier to interpret. For instance, a precision of 0.33 <b>can</b> immediately be understood as 33% correct predictions among the positive predictions. This understanding directly translates to the ...", "dateLastCrawled": "2022-01-14T18:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Machine Learning Experiment Scoring and Analysis - Financial Focus", "url": "https://h2oai.github.io/tutorials/machine-learning-experiment-scoring-and-analysis-financial-focus/", "isFamilyFriendly": true, "displayUrl": "https://h2oai.github.io/tutorials/machine-learning-experiment-scoring-and-analysis...", "snippet": "A ROC <b>curve</b> is a useful tool because it only focuses on how <b>well</b> the model <b>can</b> <b>distinguish</b> <b>between</b> classes. &quot;AUC&#39;s <b>can</b> help represent the probability that the classifier will rank a randomly selected positive observation higher than a randomly selected negative observation&quot; [4]. However, for models where the prediction happens rarely, a high AUC could provide a <b>false</b> sense that the model is correctly predicting the results. This is where the notion of precision and recall become important ...", "dateLastCrawled": "2022-01-29T04:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Classification: <b>ROC</b> <b>Curve</b> and AUC | Machine Learning Crash Course ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/crash-course/classification/<b>roc</b>-and-auc", "snippet": "An <b>ROC</b> <b>curve</b> ( receiver operating characteristic <b>curve</b>) is a <b>graph</b> showing the performance of a classification model at all classification thresholds. This <b>curve</b> plots two parameters: <b>True</b> Positive Rate. <b>False</b> Positive Rate. <b>True</b> Positive Rate ( TPR) is a synonym for recall and is therefore defined as follows: T P R = T P T P + F N.", "dateLastCrawled": "2022-02-02T09:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) The <b>Precision-Recall</b> Plot Is More Informative than the ROC Plot ...", "url": "https://www.researchgate.net/publication/273155496_The_Precision-Recall_Plot_Is_More_Informative_than_the_ROC_Plot_When_Evaluating_Binary_Classifiers_on_Imbalanced_Datasets", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/273155496_The_<b>Precision-Recall</b>_Plot_Is_More...", "snippet": "two types of incorrect (or <b>false</b>) classification, <b>false</b> <b>positives</b> (FP) <b>and false</b> negatives (FN) (see Fig. 1B ). A 2x2 table formulated with these four outcomes is called a confusion matrix.", "dateLastCrawled": "2021-12-23T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What would happen to the AUC and ROC curves if the model is unbalanced ...", "url": "https://www.quora.com/What-would-happen-to-the-AUC-and-ROC-curves-if-the-model-is-unbalanced-in-a-classification-problem", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-would-happen-to-the-AUC-and-ROC-<b>curves</b>-if-the-model-is...", "snippet": "Answer (1 of 2): Basically AUC and ROC curves are measures of <b>true</b> positive against <b>false</b> positive. With that said, if your training data is unbalanced, what happens is that you might get a lot of <b>false</b> <b>positives</b> <b>and false</b> negatives. The reason is because your model will pick up results from th...", "dateLastCrawled": "2022-01-20T11:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Performance metrics</b> | Mastering Predictive Analytics with R", "url": "https://subscription.packtpub.com/book/application-development/9781783982806/1/ch01lvl1sec11/performance-metrics", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/book/application-development/9781783982806/1/ch01lvl...", "snippet": "This inverse relationship is often plotted for a particular problem on a <b>precision-recall</b> <b>curve</b>. By using an appropriate threshold parameter, we <b>can</b> often tune the performance of our model in such a way that we achieve a specific point on this <b>precision-recall</b> <b>curve</b> that is appropriate for our circumstances. For example, in some problem domains, we tend to be biased toward having a higher recall than a higher precision, because of the high cost of misclassifying an observation from the ...", "dateLastCrawled": "2022-01-29T16:16:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "This is where Average Precision (AP), which is based on the <b>precision-recall</b> <b>curve</b>, comes into play. In essence, AP is the precision averaged across all unique recall levels. where, r1, r2, r3, \u2026, rn are the recall levels at which the precision is first interpolated. ROC <b>Curve</b> The Receiver Operating Characteristic <b>curve</b> is a plot that shows the performance of a binary classifier as a function of its cut-off threshold. It essentially shows the True Positive Rate (TPR) against the False ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>machine</b> <b>learning</b> - How to calculate precision and recall in a 3 x 3 ...", "url": "https://stats.stackexchange.com/questions/91044/how-to-calculate-precision-and-recall-in-a-3-x-3-confusion-matrix", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/91044/how-to-calculate-precision-and-recall...", "snippet": "<b>machine</b>-<b>learning</b> <b>precision-recall</b>. Share. Cite. Improve this question. Follow edited Mar 23 &#39;14 at 11:58. TooTone. 3,621 ... I already understand the <b>analogy</b> described in your solution. I will read paper. I will accept this as a answer. I don&#39;t understand PPV AND NPV.Please explain these concept as graphic as the Sens and Spec were explained and I will accept your answer. $\\endgroup$ \u2013 user22149. Mar 23 &#39;14 at 22:27. Add a comment | 3 $\\begingroup$ By reducing the data down to forced ...", "dateLastCrawled": "2022-01-30T05:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Learning</b> Curves in <b>Machine</b> <b>Learning</b> - ResearchGate", "url": "https://www.researchgate.net/publication/247934703_Learning_Curves_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/247934703_<b>Learning</b>_<b>Curves</b>_in_<b>Machine</b>_<b>Learning</b>", "snippet": "The area under the receiver operating characteristic (ROC) <b>curve</b> (AUC) was 0.62 (95% confidence interval [CI]: 0.57, 0.68) and the area under the <b>precision\u2010recall</b> <b>curve</b> was 0.58. <b>Learning</b> <b>curve</b> ...", "dateLastCrawled": "2021-12-15T10:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpret your Regression</b>. A walk through Logistic Regression | by ...", "url": "https://towardsdatascience.com/interpret-your-regression-d5f93908327b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpret-your-regression</b>-d5f93908327b", "snippet": "The <b>precision-recall</b> <b>curve</b> calls attention to the point that the model is just slightly above the no skill line for most thresholds. The no skill line is a line parallel to the x-axis with the value of the ratio of positive cases in the dataset, which is, in this case, 0.06. But this contradicts the high accuracy of 93%.", "dateLastCrawled": "2022-02-01T02:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>An Intuitive Explanation to Precision, Recall and</b> Accuracy", "url": "https://www.linkedin.com/pulse/intuitive-explanation-precision-recall-accuracy-daniel-d-souza/", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/intuitive-explanation-<b>precision-recall</b>-accuracy-daniel...", "snippet": "Earlier this year, at an interview in New York I was asked about the recall and precision of one of my <b>Machine</b> <b>Learning</b> Projects. For a couple of minutes following that, the interviewer sat back ...", "dateLastCrawled": "2021-10-21T22:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Bias -Variance &amp; <b>Precision-Recall</b> Trade-offs: How to aim for the sweet ...", "url": "https://towardsdatascience.com/tradeoffs-how-to-aim-for-the-sweet-spot-c20b40d5e6b6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/tradeoffs-how-to-aim-for-the-sweet-spot-c20b40d5e6b6", "snippet": "<b>Machine</b> <b>Learning</b> mostly have to deal with two Trade-offs, Bias-Variance Trade-offs; <b>Precision-Recall</b> Trade-offs; Part 1: Bias-Variance Trade-offs 1.1 First thing first, What is Bias, What is Variance? 1.1.1 Bias: To understand it, we must know its general meaning. Cambridge dictionary states as, The action of supporting or opposing a particular person or thing in an unfair way, because of allowing personal opinions to influence your judgment. \u2192 So in the world of stats, it is defined as ...", "dateLastCrawled": "2022-01-30T08:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Cohort-Derived <b>Machine Learning</b> Models for Individual Prediction of ...", "url": "https://academic.oup.com/jid/article/224/7/1198/5835004", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/jid/article/224/7/1198/5835004", "snippet": "We used 64 static and 502 time-changing variables: Across prediction horizons and algorithms and in contrast to expert-based standard models, most <b>machine learning</b> models achieved state-of-the-art predictive performances with areas under the receiver operating characteristic <b>curve</b> and <b>precision recall</b> <b>curve</b> ranging from 0.926 to 0.996 and from 0.631 to 0.956, respectively.", "dateLastCrawled": "2021-12-15T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Differential and Integral Calculus - Differentiate with Respect to Anything", "url": "https://machinelearningmastery.com/differential-and-integral-calculus-differentiate-with-respect-to-anything/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/differential-and-integral-calculus-differentiate...", "snippet": "The Sweeping Area <b>Analogy</b>; The Fundamental Theorem of Calculus \u2013 Part 1; The Fundamental Theorem of Calculus \u2013 Part 2; Integration Example ; Application of Integration in <b>Machine</b> <b>Learning</b>; Differential and Integral Calculus \u2013 What is the Link? In our journey through calculus so far, we have learned that differential calculus is concerned with the measurement of the rate of change. We have also discovered differentiation, and applied it to different functions from first principles. We ...", "dateLastCrawled": "2022-01-28T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "6 Useful <b>Metrics to Evaluate Binary Classification Models</b> \u2013 The Digital ...", "url": "https://thedigitalskye.com/2021/04/19/6-useful-metrics-to-evaluate-binary-classification-models/", "isFamilyFriendly": true, "displayUrl": "https://thedigitalskye.com/2021/04/19/6-useful-metrics-to-evaluate-binary...", "snippet": "Accuracy, <b>precision, recall</b>, F1 Score; ROC <b>curve</b> and ROC AUC; Confusion matrix: The basis of all metrics. Image by Author . A confusion matrix just a way to record how many times the classification model correctly or incorrectly classify things into the corresponding buckets. For example, the model initially classified 10 eggs as hatchable. However, out of those 10 eggs, only 6 are hatchable while the remaining 4 are unhatchable. In this case, the True Positive (TP) is 6 while the False ...", "dateLastCrawled": "2022-01-24T20:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "More Performance Evaluation Metrics for Classification Problems You ...", "url": "https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/04/performance-evaluation-metrics-classification.html", "snippet": "Decision Thresholds and Receiver Operating Characteristic (ROC) <b>curve</b> . Warming up: The flow of <b>Machine</b> <b>Learning</b> model . In any binary classification task, we model can only achieve two results, either our model is correct or incorrect in the prediction where we only have two classes. Imagine we now have a classification task to predict if an image is a dog or cat. In supervised <b>learning</b>, we first fit/train a model on training data, then test the model on testing data. Once we have the model ...", "dateLastCrawled": "2022-01-26T05:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>machine learning - precision recall curve is like</b> stairs - Data Science ...", "url": "https://datascience.stackexchange.com/questions/86830/precision-recall-curve-is-like-stairs", "isFamilyFriendly": true, "displayUrl": "https://<b>datascience.stackexchange</b>.com/questions/86830/<b>precision-recall-curve-is-like</b>...", "snippet": "<b>precision recall curve is like</b> stairs [closed] Ask Question Asked 1 year ago. Active 1 year ago. Viewed 83 times 0 $\\begingroup$ Closed. This question needs details or clarity. It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post. Closed 1 year ago. Improve this question I am training an ensemble model using a 400 data set sample this led to a precision recall curve that looks like stairs ? what would be the reason ...", "dateLastCrawled": "2022-01-14T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Newest &#39;ensemble-modeling&#39; Questions</b> - <b>Data Science Stack Exchange</b>", "url": "https://datascience.stackexchange.com/questions/tagged/ensemble-modeling", "isFamilyFriendly": true, "displayUrl": "https://<b>datascience.stackexchange</b>.com/questions/tagged/ensemble-modeling", "snippet": "Q&amp;A for Data science professionals, <b>Machine</b> <b>Learning</b> specialists, and those interested in <b>learning</b> more about the field. Stack Exchange Network. Stack Exchange network consists of 178 Q&amp;A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers. Visit Stack Exchange. Loading\u2026 0 +0; Tour Start here for a quick overview of the site Help Center Detailed answers to any questions you might have Meta ...", "dateLastCrawled": "2022-01-10T07:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Future Internet | Free Full-Text | <b>Machine</b> <b>Learning</b> in Detecting COVID ...", "url": "https://www.mdpi.com/1999-5903/13/10/244/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1999-5903/13/10/244/htm", "snippet": "Area under precision\u2013recall curve (PR-AUC): The <b>precision\u2013recall curve is similar</b> to the ROC curve, which is also a performance evaluation metric, especially when the supplied data are heavily imbalanced. PR-AUC is generally used to summarize the precision\u2013recall curve into a single value. If the value of PR-AUC is small, it indicates a bad classifier; a higher value such as 1 indicates an excellent classifier.", "dateLastCrawled": "2022-01-25T13:07:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(precision-recall curve)  is like +(graph of how well different machines can distinguish between true positives and false positives)", "+(precision-recall curve) is similar to +(graph of how well different machines can distinguish between true positives and false positives)", "+(precision-recall curve) can be thought of as +(graph of how well different machines can distinguish between true positives and false positives)", "+(precision-recall curve) can be compared to +(graph of how well different machines can distinguish between true positives and false positives)", "machine learning +(precision-recall curve AND analogy)", "machine learning +(\"precision-recall curve is like\")", "machine learning +(\"precision-recall curve is similar\")", "machine learning +(\"just as precision-recall curve\")", "machine learning +(\"precision-recall curve can be thought of as\")", "machine learning +(\"precision-recall curve can be compared to\")"]}