{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://satowaki.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://satowaki.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of model <b>interpretability</b> and how it relates to interpretable and explainable machine learning. To summarise, <b>interpretability</b> is the degree to which a model can be understood ...", "dateLastCrawled": "2022-02-06T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "As such, we believe that the true benefit of an <b>interpretability</b> framework is <b>being</b> <b>able</b> to formalize these different aspects of <b>interpretability</b>, then pick the most relevant method. The claim \u201cyou should use SHAP because it makes your model more interpretable\u201d is largely useless. However, the claim \u201cyou should use SHAP because the decomposability it offers is worth the risk of using a post-hoc explanation\u201d makes clear both the benefits and risks of SHAP.", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Interpreting machine learning models | by Lars Hulstaert | Towards Data ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-70c30694a05f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-70c30694a05f", "snippet": "With the rise of data and privacy protection regulation <b>like</b> GDPR, <b>interpretability</b> becomes even more essential. In addition, in medical applications or self-driving cars, a single incorrect prediction can have a significant impact and <b>being</b> <b>able</b> to \u2018verify\u2019 the model is critical. Therefore the system should be <b>able</b> to explain how it reached a given recommendation. Interpreting your models. A common quote on model <b>interpretability</b> is that with an increase in model complexity, model ...", "dateLastCrawled": "2022-02-03T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High model <b>interpretability</b> wins arguments. Risk and responsibility. A model with high <b>interpretability</b> is desirable on a high-risk stakes game. High interpretable models equate to <b>being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Teaching Machines <b>to Read</b> <b>Movie Reviews: Thinking About Interpretability</b>", "url": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about-interpretability-63c12248b8e5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/teaching-machines-<b>to-read</b>-movie-reviews-thinking-about...", "snippet": "I really <b>like</b> the idea of giving machines additional kinds/representations of data to help them <b>read</b> better. Then in turn, <b>being</b> <b>able</b> to look under the hood and understand how machines leveraged those additional representations in reading text data, because it can expand human knowledge, and likely for things more important than movie reviews.", "dateLastCrawled": "2022-01-19T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretable Machine Learning</b> Models | HCL Blogs", "url": "https://www.hcltech.com/blogs/interpretable-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.hcltech.com/blogs/<b>interpretable-machine-learning</b>", "snippet": "Even if we are <b>able</b> to understand each individual model separately, getting to understand how these models work in tandem is quite difficult. What is <b>interpretability</b> and why does it matter in machine learning? Here is a thought on <b>interpretability</b> and decision making using machine learning. Click <b>to read</b> @hclfs #machinelearning #machineinterpretability. So, what is <b>interpretability</b>? Simply stated, it is having the ability to confidently tell how/why a machine learning model is making the ...", "dateLastCrawled": "2022-01-12T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Interpretable Neural Networks with PyTorch * Machine Learning", "url": "https://machinelearningmastery.in/2022/01/11/interpretable-neural-networks-with-pytorch/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.in/2022/01/11/interpret<b>able</b>-neural-networks-with-pytorch", "snippet": "Now, you have probably often heard something <b>like</b> this: \u201cThere are interpretable models an there are well-performing models.\u201d \u2014 someone who doesn\u2019t know it better. However, if you have <b>read</b> my article about the Explainable Boosting Machine (EBM), then you already know that this is not true. The EBM is an example of a model that has a great performance while <b>being</b> interpretable. The Explainable Boosting Machine For my old article, I created the following figure displaying how we can ...", "dateLastCrawled": "2022-02-03T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What everyone <b>needs to know about interpretability in machine learning</b> ...", "url": "https://dallascard.medium.com/what-everyone-needs-to-know-about-interpretability-in-machine-learning-d5ce16730407", "isFamilyFriendly": true, "displayUrl": "https://dallascard.medium.com/what-everyone-<b>needs-to-know-about-interpretability</b>-in...", "snippet": "In addition to the supposedly delightful videos of children trying to fight their instincts, this experiment produced the finding that those who are <b>able</b> to delay their gratification will have better life outcomes in various ways (on average). Although one interpretation is that eating the marshmallow somehow made things worse for those who could not resist doing so, a much more reasonable interpretation is that there is some latent property which is <b>being</b> measured, such as self-control, and ...", "dateLastCrawled": "2022-01-12T04:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Model <b>Interpretability</b>. With the advancement in Machine\u2026 | by Sumedh ...", "url": "https://smdhtelang2.medium.com/model-interpretability-da57f807c42a", "isFamilyFriendly": true, "displayUrl": "https://smdhtelang2.medium.com/model-<b>interpretability</b>-da57f807c42a", "snippet": "Model <b>Interpretability</b>. With the advancement in Machine Learning where machine learning is <b>able</b> to solve the most complex problems in the world highly accurately, the need to understand the complexity of the black-box model working is increasing every day. In this article, I will be shedding light on some of the model agnostic methods <b>like</b> SHAP ...", "dateLastCrawled": "2022-01-21T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>ML Interpretability: LIME and SHAP in</b> prose and code - <b>Cloudera Blog</b>", "url": "https://blog.cloudera.com/ml-interpretability-lime-and-shap-in-prose-and-code/", "isFamilyFriendly": true, "displayUrl": "https://blog.cloudera.com/<b>ml-interpretability-lime-and-shap-in</b>-prose-and-code", "snippet": "At Cloudera Fast Forward, we see model <b>interpretability</b> as an important step in the data science workflow.<b>Being</b> <b>able</b> to explain how a model works serves many purposes, including building trust in the model\u2019s output, satisfying regulatory requirements, model debugging, and verifying model safety, amongst other things.", "dateLastCrawled": "2022-01-31T21:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "A model that provided <b>similar</b> explanations would be more useful than one that just provided predictions. ... we\u2019ll explain in more detail what is meant by <b>interpretability</b>. We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High model <b>interpretability</b> wins arguments. Risk and responsibility. A model with high <b>interpretability</b> is desirable on a high-risk stakes game. High interpretable models equate <b>to being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is <b>Interpretability</b>? | SpringerLink", "url": "https://link.springer.com/article/10.1007/s13347-020-00435-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-020-00435-2", "snippet": "One way <b>to read</b> this is as asserting that <b>interpretability</b> is merely synonymous with understandability; another is to see it as a special case. If an explanation is already understandable, then surely it is interpretable, since it gives rise to an understandable explanation (itself), trivially. But, as we have noted, not all interpretable explanations themselves provide understanding\u2014qualitative or otherwise. For that, we may have to wait for an explanation to be interpreted and to give ...", "dateLastCrawled": "2022-01-26T20:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "As such, we believe that the true benefit of an <b>interpretability</b> framework is <b>being</b> <b>able</b> to formalize these different aspects of <b>interpretability</b>, then pick the most relevant method. The claim \u201cyou should use SHAP because it makes your model more interpretable\u201d is largely useless. However, the claim \u201cyou should use SHAP because the decomposability it offers is worth the risk of using a post-hoc explanation\u201d makes clear both the benefits and risks of SHAP.", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Interpretable Neural Networks with PyTorch * Machine Learning", "url": "https://machinelearningmastery.in/2022/01/11/interpretable-neural-networks-with-pytorch/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.in/2022/01/11/interpret<b>able</b>-neural-networks-with-pytorch", "snippet": "Photo by Jan Schulz # Webdesigner Stuttgart on Unsplash There are several approaches to rate machine learning models, two of them <b>being</b> accuracy and <b>interpretability</b>.A model with high accuracy is what we usually call a good model, it learned the relationship between the inputs X and outputs y well. If a model has high <b>interpretability</b> or explainability, we understand how the model makes a prediction and how we can influence this prediction by changing input features. While it is hard to say ...", "dateLastCrawled": "2022-02-03T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards the <b>Interpretability</b> of Machine Learning Predictions for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8122817/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8122817", "snippet": "In general, there are two approaches to <b>interpretability</b>: model <b>interpretability</b> and inference <b>interpretability</b> . Model <b>interpretability</b> relates to understanding how a model behaves in general, whereas inference <b>interpretability</b> aims to describe how systems decide on each instance. Hence, these are two facets of the same problem. However, in both cases, <b>interpretability</b> may be obtained by showing symbols (e.g., natural language or structured languages such as logical forms) to explain models ...", "dateLastCrawled": "2022-01-27T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What <b>do you mean by &quot;interpretability&quot; in models</b>?", "url": "https://www.researchgate.net/post/What-do-you-mean-by-interpretability-in-models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What-<b>do-you-mean-by-interpretability-in-models</b>", "snippet": "Models have a purpose, for example to precisely simulate or predict the behavior of a system. Among other qualities, <b>interpretability</b> (or comprehensibility or understandability) is often recalled ...", "dateLastCrawled": "2021-12-24T19:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Model <b>Interpretability</b>. With the advancement in Machine\u2026 | by Sumedh ...", "url": "https://smdhtelang2.medium.com/model-interpretability-da57f807c42a", "isFamilyFriendly": true, "displayUrl": "https://smdhtelang2.medium.com/model-<b>interpretability</b>-da57f807c42a", "snippet": "Model <b>Interpretability</b>. Sumedh Telang. Dec 20, 2020 \u00b7 6 min <b>read</b>. Source: Majemo/GettyImages. With the advancement in Machine Learning where machine learning is <b>able</b> to solve the most complex problems in the world highly accurately, the need to understand the complexity of the black-box model working is increasing every day. In this article, I will be shedding light on some of the model agnostic methods like SHAP, LIME, Anchor, etc on the tabular dataset. In this article, I used Adult ...", "dateLastCrawled": "2022-01-21T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Interpretability</b> and Analysis of Models for NLP @ ACL 2020 | by Carolin ...", "url": "https://medium.com/@lawrence.carolin/interpretability-and-analysis-of-models-for-nlp-e6b977ac1dc6", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@lawrence.carolin/<b>interpretability</b>-and-analysis-of-models-for-nlp-e...", "snippet": "The first category is about the paper that in my personal opinion is a must-<b>read</b> for everyone planning to research <b>interpretability</b>: it asks crucial questions which we should all consider when ...", "dateLastCrawled": "2022-01-23T11:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "interpretation - <b>Most interpretable classification models</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/235007/most-interpretable-classification-models", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/235007", "snippet": "If you want actionable <b>interpretability</b>, I&#39;d suggest they might not make the cut. 2) Another issue is clarifying what you mean by &quot;<b>interpretability</b> of results&quot;. I&#39;ve run into <b>interpretability</b> in four contexts: The client <b>being</b> <b>able</b> to understand the methodology. (Not what you&#39;re asking about.) A Random Forest is pretty straightforwardly explainable by analogy, and most clients feel comfortable with it once it&#39;s explained simply. Explaining how the methodology fits a model. (I had a client ...", "dateLastCrawled": "2022-01-28T11:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of model <b>interpretability</b> and how it relates to interpretable and explainable machine learning. To summarise, <b>interpretability</b> is the degree to which a model <b>can</b> be understood ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "As such, we believe that the true benefit of an <b>interpretability</b> framework is <b>being</b> <b>able</b> to formalize these different aspects of <b>interpretability</b>, then pick the most relevant method. The claim \u201cyou should use SHAP because it makes your model more interpretable\u201d is largely useless. However, the claim \u201cyou should use SHAP because the decomposability it offers is worth the risk of using a post-hoc explanation\u201d makes clear both the benefits and risks of SHAP.", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High interpretable models equate to <b>being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was made. Highly interpretable models, and maintaining high <b>interpretability</b> as a design standard, <b>can</b> help build trust between engineers and users. It\u2019s bad enough when the chain of command prevents a person from <b>being</b> <b>able</b> to speak to the party responsible for making the decision. It is much worse ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What everyone <b>needs to know about interpretability in machine learning</b> ...", "url": "https://dallascard.medium.com/what-everyone-needs-to-know-about-interpretability-in-machine-learning-d5ce16730407", "isFamilyFriendly": true, "displayUrl": "https://dallascard.medium.com/what-everyone-<b>needs-to-know-about-interpretability</b>-in...", "snippet": "To some extent choices <b>can</b> be partially justified (typically because one model worked better than another on some held-out data), but this is not the same as <b>being</b> <b>able</b> to claim that one has discovered the \u201ctrue\u201d model in any meaningful sense. Nor does accuracy necessarily tell the full story. Even models that obtain relatively high accuracy on held out data <b>can</b> still be", "dateLastCrawled": "2022-01-12T04:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>AI Explainability, Interpretability &amp; Transparency</b> | by Swapna M ...", "url": "https://medium.datadriveninvestor.com/ai-explainability-interpretability-transparency-in-finance-95e61b5cd6df", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/<b>ai-explainability-interpretability-transparency</b>...", "snippet": "Hence minimal effort is put into creating practices around explainability for each capability or product. Secondly, the beauty of an AI algorithm is its ability to learn by itself, to find inferences and hidden patterns from datasets that a human mind won\u2019t be <b>able</b> to extract easily. Hence explainability is a valid challenge and will continue ...", "dateLastCrawled": "2022-01-19T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Neural Network <b>Interpretability</b> Fundamentals | by Andre Ye | Towards ...", "url": "https://towardsdatascience.com/every-ml-engineer-needs-to-know-neural-network-interpretability-afea2ac0824e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/every-ml-engineer-needs-to-know-neural-network...", "snippet": "Neural Network <b>Interpretability</b> Fundamentals. Activation Maximization, Sensitivity Analysis, &amp; More . Andre Ye. Jul 15, 2020 \u00b7 7 min <b>read</b>. Neural Networks are the pinnacle of machine learning: they <b>can</b> model extremely complex functions by matching it with an equally complex structure. Full of nonlinearities and information propagation streams, the mindset with data scientists has often been \u201cwhat we gain in power we sacrifice with <b>interpretability</b>.\u201d Indeed \u2014 the black-box nature of ...", "dateLastCrawled": "2022-02-03T04:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretability vs. Accuracy in Crypto Asset Predictions</b> | by Jesus ...", "url": "https://medium.com/intotheblock/interpretability-vs-accuracy-in-crypto-asset-predictions-ae0abadd065b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/intotheblock/<b>interpretability-vs-accuracy-in-crypto</b>-asset...", "snippet": "The friction between the <b>interpretability</b> and accuracy capabilities of deep learning models is the friction between <b>being</b> <b>able</b> to accomplish complex knowledge tasks and understanding how those ...", "dateLastCrawled": "2021-10-18T00:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Cultures, contexts, and interpretability</b>, World Englishes | 10.1111/j ...", "url": "https://www.deepdyve.com/lp/wiley/cultures-contexts-and-interpretability-RYZG0nB40i", "isFamilyFriendly": true, "displayUrl": "https://www.deepdyve.com/lp/wiley/<b>cultures-contexts-and-interpretability</b>-RYZG0nB40i", "snippet": "In this scheme, then, Intelligibility \u2018<b>can</b> <b>be thought</b> of as a degree of understanding on a continuum with intelligibility <b>being</b> lowest and <b>interpretability</b> <b>being</b> highest\u2019 ( Smith 1992 : 76). As <b>interpretability</b> depends on interaction, this conceptualization naturally brings to the fore the sociocultural context of interaction. CULTURE I have already made suggestions about defining culture in explicit terms for linguistic analysis of interaction in oral and written modalities ( Y. Kachru ...", "dateLastCrawled": "2020-06-13T04:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What <b>do you mean by &quot;interpretability&quot; in models</b>?", "url": "https://www.researchgate.net/post/What-do-you-mean-by-interpretability-in-models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What-<b>do-you-mean-by-interpretability-in-models</b>", "snippet": "The experts <b>can</b> indeed learn new dependencies and correlations from those models that <b>can</b> be easily interpreted, like rule-based systems or trees or graphical models. Let&#39;s say we&#39;re trying to ...", "dateLastCrawled": "2021-12-24T19:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Building Blocks of <b>Interpretability</b> - Distill", "url": "https://distill.pub/2018/building-blocks/", "isFamilyFriendly": true, "displayUrl": "https://distill.pub/2018/building-blocks", "snippet": "One way these interactions <b>can</b> pan out is as attribution <b>being</b> \u201cpath-dependent\u201d. A natural response to this would be for interfaces to explicitly surface this information: how path-dependent is the attribution? A deeper concern, however, would be whether this path-dependency dominates the attribution. Clearly, this is not a concern for attribution between adjacent layers because of the simple (essentially linear) mapping between them. While there may be technicalities about correlated ...", "dateLastCrawled": "2022-02-02T02:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High interpretable models equate <b>to being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was made. Highly interpretable models, and maintaining high <b>interpretability</b> as a design standard, <b>can</b> help build trust between engineers and users. It\u2019s bad enough when the chain of command prevents a person from <b>being</b> <b>able</b> to speak to the party responsible for making the decision. It is much worse ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "<b>Interpretability</b> takes many forms and <b>can</b> be difficult to define; we first explore general frameworks and sets of definitions in which model <b>interpretability</b> <b>can</b> be evaluated and <b>compared</b> (Lipton 2016, Doshi-Velez &amp; Kim 2017). Next, we analyze several well-known examples of <b>interpretability</b> methods\u2013LIME (Ribeiro et al. 2016), SHAP (Lundberg &amp; Lee 2017), and convolutional neural network visualization (Olah et al. 2018)\u2013in the context of this framework. Model <b>interpretability</b> has no ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Towards the <b>Interpretability</b> of Machine Learning Predictions for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8122817/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8122817", "snippet": "In this sense, learning tools are becoming a commodity but, to be <b>able</b> to assist doctors on a daily basis, it is essential to fully understand how models <b>can</b> be interpreted. In this survey, we analyse current machine learning models and other in-silico tools as applied to medicine\u2014specifically, to cancer research\u2014and we discuss their <b>interpretability</b>, performance and the input data they are fed with. Artificial neural networks (ANN), logistic regression (LR) and support vector machines ...", "dateLastCrawled": "2022-01-27T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Teaching Machines <b>to Read</b> <b>Movie Reviews: Thinking About Interpretability</b>", "url": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about-interpretability-63c12248b8e5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/teaching-machines-<b>to-read</b>-movie-reviews-thinking-about...", "snippet": "Researchers at Stanford\u2019s Literary Lab have <b>compared</b> human and machine reading using the analogy of identifying writing genres as if they were buildings. Human beings <b>can</b> use themes (dark secrets, mounting dread) to identify a genre like gothic fiction, just as people <b>can</b> use architectural elements (plinths, smooth surfaces) to identify an architectural genre like neoclassical. Whereas computers <b>can</b> use word counts (lexical level features) and DocuScope\u2019s stance categories ...", "dateLastCrawled": "2022-01-19T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Comparison and improvement of the predictability and <b>interpretability</b> ...", "url": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0417-9", "isFamilyFriendly": true, "displayUrl": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0417-9", "snippet": "Ensemble learning helps improve machine learning results by combining several models and allows the production of better predictive performance <b>compared</b> to a single model. It also benefits and accelerates the researches in quantitative structure\u2013activity relationship (QSAR) and quantitative structure\u2013property relationship (QSPR). With the growing number of ensemble learning models such as random forest, the effectiveness of QSAR/QSPR will be limited by the machine\u2019s inability to ...", "dateLastCrawled": "2022-02-01T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Interpretable Neural Networks with PyTorch * Machine Learning", "url": "https://machinelearningmastery.in/2022/01/11/interpretable-neural-networks-with-pytorch/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.in/2022/01/11/interpret<b>able</b>-neural-networks-with-pytorch", "snippet": "On the x-axis, you <b>can</b> see the range of feature_4. The y-axis shows the Score, which is the value by how much the output is changed. The histogram below shows you the distribution of feature_4. We <b>can</b> see the following from the graphic: If feature_4 is about 0.62, the output increases by about 10 <b>compared</b> to feature_4 <b>being</b> 0.6 or 0.65.", "dateLastCrawled": "2022-02-03T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>ML Interpretability: LIME and SHAP in</b> prose and code - <b>Cloudera Blog</b>", "url": "https://blog.cloudera.com/ml-interpretability-lime-and-shap-in-prose-and-code/", "isFamilyFriendly": true, "displayUrl": "https://blog.cloudera.com/<b>ml-interpretability-lime-and-shap-in</b>-prose-and-code", "snippet": "<b>Being</b> <b>able</b> to explain how a model works serves many purposes, including building trust in the model\u2019s output, satisfying regulatory requirements, model debugging, and verifying model safety, amongst other things. We have written a research report (which you <b>can</b> access here) that discusses this topic in detail.", "dateLastCrawled": "2022-01-31T21:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Interpretability</b> of artificial intelligence models that use data fusion ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03470-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03470-9", "snippet": "Despite <b>being</b> <b>able</b> to make accurate predictions, ML and DL techniques generate complex models that lack the <b>interpretability</b> that is desired in many applications. This issue is particularly evident in disciplines like medicine (Lundberg et al. 2018) and finance (Ariza-Garz\u00f3n et al. 2020), where the understanding of the features that cause a certain prediction is essential for the adoption of AI models. Likewise, with aeroponics, it is relevant to understand the features that could influence ...", "dateLastCrawled": "2022-01-23T16:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What makes <b>interpretability</b> in neural networks difficult? - Quora", "url": "https://www.quora.com/What-makes-interpretability-in-neural-networks-difficult", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-makes-<b>interpretability</b>-in-neural-networks-difficult", "snippet": "Answer (1 of 2): The ultimate goal of machine learning (or statistics), many would argue, is to build insight into some phenomenon. Thus far, the ML community has largely been obsessed with predictive accuracy. If you <b>read</b> the many papers in different subfields of ML at leading conferences, like ...", "dateLastCrawled": "2022-01-13T06:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Understanding model predictions with <b>LIME</b> | by Lars Hulstaert | Towards ...", "url": "https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-model-predictions-with-<b>lime</b>-a582fdff3a3b", "snippet": "The authors show that permutation importance provides more robust estimates when variables are strongly correlated, <b>compared</b> to random forest importance\u2019s. I highly recommend <b>to read</b> their blog post for a thorough understanding of the findings. <b>LIME</b>. <b>LIME</b> is model-agnostic, meaning that it <b>can</b> be applied to any machine learning model. The ...", "dateLastCrawled": "2022-02-03T00:26:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/<b>interpretability</b>-in-ml-a-broad-overview", "snippet": "First, <b>interpretability</b> in <b>machine</b> <b>learning</b> is useful because it can aid in trust. As humans, we may be reluctant to rely on <b>machine</b> <b>learning</b> models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in something opaque, which we see when people confront new technology, and this can slow down adoption. Approaches to <b>interpretability</b> that focus on transparency could help mitigate some of these fears.", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Figure 1: <b>Interpretability</b> for <b>machine</b> <b>learning</b> models bridges the concrete objectives models optimize for and the real-world (and less easy to define) desiderata that ML applications aim to achieve. Introduction . The objectives <b>machine</b> <b>learning</b> models optimize for do not always reflect the actual desiderata of the task at hand. <b>Interpretability</b> in models allows us to evaluate their decisions and obtain information that the objective alone cannot confer. <b>Interpretability</b> takes many forms ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "snippet": "This provides a novel <b>analogy</b> between data compression and regularization. Qualitative and quantitative state-of-the-art results on three datasets. 20 / 33. Interpretable Lens Variable Model (ILVM) 21 / 33. Interactive <b>Interpretability</b> via Active <b>Learning</b> Interactive \u2018human-in-the-loop\u2019 <b>interpretability</b> Choose the point with index j that maximizes : ^j = argmax jI(s ; ) = H(s ) E q \u02da(z js)[H(s jz j)] = Z p(s j)log p(s j)ds + E q \u02da(z js) Z p (s jjz)log p (s jjz)ds : (5) Choose the point ...", "dateLastCrawled": "2022-01-19T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-16T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Confusion Matrices</b> &amp; <b>Interpretable ML</b> | by andrea b | high stakes ...", "url": "https://medium.com/high-stakes-design/interpretability-techniques-explained-in-simple-terms-f5e1573674f3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/high-stakes-design/<b>interpretability</b>-techniques-explained-in-simple...", "snippet": "The best [<b>analogy</b>] I can think of is an indicator light in your car \u2014 [and the] <b>machine</b> that you plug in to tell you more about the readout. ANDREA: Do you see <b>interpretability</b>, primarily, as ...", "dateLastCrawled": "2021-03-22T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Economic Methodology Meets Interpretable Machine Learning</b> - Part I ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. Intro - Part ...", "dateLastCrawled": "2022-01-22T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Economic Methodology Meets Interpretable <b>Machine</b> <b>Learning</b> ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. But first ...", "dateLastCrawled": "2022-01-05T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "Neuroscience \u2194 <b>Interpretability</b>. <b>Analogy</b>: model=brain. Artificial neural networks are historically inspired by neuroscience, but I used to be pretty skeptical that the connection was anything more than superficial. I&#39;ve since come around: I now think this is a very deep connection. The thing that personally persuaded me was that, in my own investigations of what goes on inside neural networks, we kept finding things that were previously discovered by neuroscientists. The most recent ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "9.6 <b>SHAP</b> (SHapley Additive exPlanations) | Interpretable <b>Machine</b> <b>Learning</b>", "url": "https://christophm.github.io/interpretable-ml-book/shap.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpretable-ml-book/<b>shap</b>.html", "snippet": "9.6 <b>SHAP</b> (SHapley Additive exPlanations). This chapter is currently only available in this web version. ebook and print will follow. <b>SHAP</b> (SHapley Additive exPlanations) by Lundberg and Lee (2017) 69 is a method to explain individual predictions. <b>SHAP</b> is based on the game theoretically optimal Shapley values.. There are two reasons why <b>SHAP</b> got its own chapter and is not a subchapter of Shapley values.First, the <b>SHAP</b> authors proposed KernelSHAP, an alternative, kernel-based estimation ...", "dateLastCrawled": "2022-02-03T01:34:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chris Olah on what the hell is going on inside neural networks - 80,000 ...", "url": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/", "isFamilyFriendly": true, "displayUrl": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research", "snippet": "Chris is a <b>machine</b> <b>learning</b> researcher currently focused on neural network interpretability. Until last December he led OpenAI\u2019s interpretability team but along with some colleagues he recently moved on to help start a new AI lab focussed on large models and safety called Anthropic. Rob Wiblin: Before OpenAI he spent 4 years at Google Brain developing tools to visualize what\u2019s going on in neural networks. Chris was hugely impactful at Google Brain. He was second author on the launch of ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Marketing AI: Interpretability and Explainability</b> - Christopher S. Penn ...", "url": "https://www.christopherspenn.com/2021/03/marketing-ai-interpretability-and-explainability/", "isFamilyFriendly": true, "displayUrl": "https://www.christopherspenn.com/2021/03/<b>marketing-ai-interpretability-and-explainability</b>", "snippet": "<b>Interpretability is like</b> inspecting the baker\u2019s recipe for the cake. We look at the list of ingredients and the steps taken to bake the cake, and we verify that the recipe makes sense and the ingredients were good. This is a much more rigorous way of validating our results, but it\u2019s the most complete \u2013 and if we\u2019re in a high-stakes situation where we need to remove all doubt, this is the approach we take. Interpretability in AI is like that \u2013 we step through the code itself that ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Causal <b>Learning</b> From Predictive Modeling for Observational Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931928/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7931928", "snippet": "Given the recent success of <b>machine</b> <b>learning</b>, specifically deep <b>learning</b>, in several applications (Goodfellow et al., ... This statistical <b>interpretability is similar</b> in spirit to traditional interpretability. This allows to answer questions, such as \u201cdoes BMI influence susceptibility to Covid?\u201d Moreover, it has been argued that developing an effective CBN for practical applications requires expert knowledge when data collection is cumbersome (Fenton and Neil, 2012). This applies to ...", "dateLastCrawled": "2021-12-09T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimal <b>Predictive Clustering</b> - Dimitris Bertsimas", "url": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-predictive-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-<b>predictive-clustering</b>.pdf", "snippet": "Table 1 Comparison of major <b>machine</b> <b>learning</b> methods relative to each other across the metrics of performance (out-of-sample R2), scalability and interpretability. 1 is the best, while 5 is the worst. Optimal <b>Predictive Clustering</b> 3 From Table 1, we observe all existing methods have weakness in at least one category. We therefore seek to design a method that has strong performance in all three categories at the same time. Optimal <b>Predictive Clustering</b> (OPC) is an algorithm that uses mixed ...", "dateLastCrawled": "2021-11-24T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reviewing Challenges of Predicting Protein Melting Temperature Change ...", "url": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "snippet": "Predicting the effects of mutations on protein stability is a key problem in fundamental and applied biology, still unsolved even for the relatively simple case of small, soluble, globular, monomeric, two-state-folder proteins. Many articles discuss the limitations of prediction methods and of the datasets used to train them, which result in low reliability for actual applications despite globally capturing trends. Here, we review these and other issues by analyzing one of the most detailed ...", "dateLastCrawled": "2022-02-03T02:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "In my view, a shor t coming of interpretable <b>machine</b> <b>learning</b> is that it assumes to a degree that the data being fed into the model is always going to be suitable for human interpretation. This is not necessarily the case. For instance, let\u2019s say that a company is trying to implement interpretable <b>machine</b> <b>learning</b> to devise a credit scoring model, whereby prospective credit card applications are classified as approved or rejected based on numerous features. It is often the case that such ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Breaking the interpretability barrier - a</b> method for interpreting deep ...", "url": "http://www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "isFamilyFriendly": true, "displayUrl": "www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o between performance and inter-pretability. Graph classi cation is normally a domain which requires the ap-plication of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to in-terpret complex models post-hoc (brie y reviewed in section2). However, most ...", "dateLastCrawled": "2021-09-22T17:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Discovering Discriminative Nodes for Classi\ufb01cation with Deep Graph ...", "url": "http://muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "isFamilyFriendly": true, "displayUrl": "muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o\ufb00 between performance and inter-pretability. Graph classi\ufb01cation is normally a domain which requires the appli-cation of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to interpret complex models post-hoc (brie\ufb02y reviewed in Sect.2). However ...", "dateLastCrawled": "2021-09-02T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Confronting Abusive Language Online: A Survey from the Ethical and ...", "url": "https://www.arxiv-vanity.com/papers/2012.12305/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2012.12305", "snippet": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this ...", "dateLastCrawled": "2021-10-13T19:21:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(interpretability)  is like +(being able to read)", "+(interpretability) is similar to +(being able to read)", "+(interpretability) can be thought of as +(being able to read)", "+(interpretability) can be compared to +(being able to read)", "machine learning +(interpretability AND analogy)", "machine learning +(\"interpretability is like\")", "machine learning +(\"interpretability is similar\")", "machine learning +(\"just as interpretability\")", "machine learning +(\"interpretability can be thought of as\")", "machine learning +(\"interpretability can be compared to\")"]}