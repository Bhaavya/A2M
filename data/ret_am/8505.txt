{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to PyTorch Tensors \u2014 PyTorch Tutorials 1.10.1+cu102 ...", "url": "https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html", "isFamilyFriendly": true, "displayUrl": "https://pytorch.org/tutorials/beginner/introyt/<b>tensors</b>_deeper_tutorial.html", "snippet": "The first new thing in the code cell above is the use of the .<b>shape</b> property on a <b>tensor</b>. This property contains a list of the extent of each dimension of a <b>tensor</b> - in our case, x is a three-dimensional <b>tensor</b> with <b>shape</b> 2 x 2 x 3. Below that, we call the .empty_<b>like</b>(), .zeros_<b>like</b>(), .ones_<b>like</b>(), and .rand_<b>like</b>() methods. Using the .<b>shape</b> property, we can verify that each of these methods returns a <b>tensor</b> of identical dimensionality and extent.. The last way to create a <b>tensor</b> that will ...", "dateLastCrawled": "2022-01-31T11:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "3 Introduction to Machine Learning | Machine Learning and AI in ...", "url": "https://theoreticalecology.github.io/machinelearning/introduction.html", "isFamilyFriendly": true, "displayUrl": "https://theoreticalecology.github.io/machinelearning/introduction.html", "snippet": "## tf.<b>Tensor</b>(20.0, <b>shape</b>=(), dtype=float32) TensorFlow containers are objects, what means that they are not just simple variables of type numeric (class(5)), but they instead have so called methods. Methods are changing the state of a class (which for most of our purposes here is the values of the object). For instance, there is a method to ...", "dateLastCrawled": "2022-01-10T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Recommending Similar Fashion Images with Deep Learning", "url": "https://blog.floydhub.com/similar-fashion-images/", "isFamilyFriendly": true, "displayUrl": "https://blog.floydhub.com/similar-fashion-images", "snippet": "The overall network architecture looked <b>like</b> below, and our model will be similar to it. We represent each image with the values of the feature layer (the global pool layer), as this layer captures the most detailed information of the images. Full ResNet Architecture ResNet Implementation. Let\u2019s look at the implementation of the ResNet architecture in TensorFlow. The create_variables function takes in name (the name of the variable), <b>shape</b> (a list of dimensions), initializer (Xavier is the ...", "dateLastCrawled": "2022-02-02T22:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Advanced Convolutional Neural Networks \u2013 Deep Learning with TensorFlow ...", "url": "https://w3sdev.com/advanced-convolutional-neural-networks-deep-learning-with-tensorflow-2-and-keras-second-edition.html", "isFamilyFriendly": true, "displayUrl": "https://w3sdev.com/advanced-convolutional-neural-networks-deep-learning-with-<b>tensor</b>...", "snippet": "A third approach is to use a CNN encoder-decoder network, where the encoder decreases the <b>width</b> and <b>height</b> of the image but increases its <b>depth</b> (number of features), while the decoder uses transposed convolution operations to increase its size and decrease <b>depth</b>. Transpose convolution (or upsampling) is the process of going in the opposite direction of a normal convolution. The input to this network is the image and the output is the segmentation map.", "dateLastCrawled": "2021-12-18T18:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Image processing with numpy - PythonInformer", "url": "https://www.pythoninformer.com/python-libraries/numpy/numpy-and-images/", "isFamilyFriendly": true, "displayUrl": "https://www.pythoninformer.com/python-libraries/numpy/numpy-and-images", "snippet": "Notice that the first dimension is the <b>height</b>, and the second dimension is the <b>width</b>. That is because the data is ordered by lines, then each line is ordered by pixels, and finally, each pixel contains 3-byte values for RGB. Each colour is represented by an unsigned byte numpy type uint8). Now let&#39;s fill the array with orange pixels (red=255, green=128, blue=0). We use slices to do this, the three values are broadcast across all the rows and columns of the array: array [:,:] = [255, 128, 0 ...", "dateLastCrawled": "2022-02-03T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "\ud83d\udcd6 \ud83d\udc46\ud83c\udffb Making the Printed Links Clickable Using <b>TensorFlow</b> 2 Object ...", "url": "https://towardsdatascience.com/making-the-printed-links-clickable-using-tensorflow-2-object-detection-api-be42bd65488a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/making-the-printed-links-clickable-using-<b>tensorflow</b>-2...", "snippet": "git clone --<b>depth</b> 1 https: ... For example, we may locate the bounding box by setting the coordinate of its center point and its <b>width</b> and <b>height</b>. We might also use relative values (percentage of the <b>width</b> and <b>height</b> of the image) for setting up the coordinates. But you&#39;ve got the idea, the network needs to know what the image is and where on the image the objects are located. Now, how can we get the custom dataset for training? We have three options here: Re-use the existing dataset ...", "dateLastCrawled": "2022-01-09T12:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Multiple choice questions on engineering drwaing</b>", "url": "https://www.slideshare.net/VipinAhlawat1/multiple-choice-questions-on-engineering-drwaing", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/VipinAhlawat1/<b>multiple-choice-questions-on-engineering-drwaing</b>", "snippet": "The top and right side views have common dimensions of (a) <b>height</b> and <b>width</b> (b) <b>width</b> <b>and depth</b> (c) <b>height</b> (d) <b>depth</b> Ans: (a) 8. This type of projection is when projectors are parallel to each other, but are at an angle other than 90 degrees to the plane of projection: (a) perspective (b) oblique (c) aesthetic (d) angular Ans: (b) 9. This is how axonometric, oblique, and perspective sketches show objects (a) Orthographically (b) Pictorially (c) Obliquely (d) Parallel Ans: (b)", "dateLastCrawled": "2022-01-29T18:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "python - High accuracy in mode.fit but low precision and recall ...", "url": "https://datascience.stackexchange.com/questions/102767/high-accuracy-in-mode-fit-but-low-precision-and-recall-overfit-unbalanced-err", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/102767/high-accuracy-in-mode-fit-but...", "snippet": "Accuracy is not a good metric when you have an unbalanced Dataset. <b>Imagine</b> a binary classification with a dataset composed of 90% of &#39;0&#39; and 10% of &#39;1&#39;. If you make a model that always predict &#39;0&#39;, (so which is useless, because your goal is to identify ones), it&#39;ll have a 90% accuracy.", "dateLastCrawled": "2022-01-21T18:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to Code a Convolutional Neural Network Within an Hour Without Any ...", "url": "https://aarushimehrotra.medium.com/how-to-code-a-convolutional-neural-network-within-an-hour-without-any-machine-learning-experience-9cbfbac63371", "isFamilyFriendly": true, "displayUrl": "https://aarushimehrotra.medium.com/how-to-code-a-convolutional-neural-network-within...", "snippet": "The filter is <b>a square</b> matrix with a <b>height</b> and <b>width</b> less than the original image (in this case, 5x5, but it can be anywhere between 1x1 to 7x7 usually), but the <b>depth</b> is always the same as the image. The filter acts <b>like</b> the W weights matrix we had for normal neural networks since we take the dot product of the 5x5x3 filter and the 5x5x3 section of the image it\u2019s currently. The dot product basically takes each matrix and stretches it out into a row and a column vector of the same length ...", "dateLastCrawled": "2022-01-18T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Get image <b>size (width, height) with Python, OpenCV, Pillow</b> (PIL) | note ...", "url": "https://note.nkmk.me/en/python-opencv-pillow-image-size/", "isFamilyFriendly": true, "displayUrl": "https://note.nkmk.me/en/python-opencv-pillow-image-size", "snippet": "OpenCV: Get image size (<b>width</b>, <b>height</b>) with ndarray.<b>shape</b>. When an image file is read by OpenCV, it is treated as NumPy array ndarray.The size (<b>width</b>, <b>height</b>) of the image can be acquired from the attribute <b>shape</b> indicating the <b>shape</b> of ndarray.. Not limited to OpenCV, the size of the image represented by ndarray, such as when an image file is read by Pillow and converted to ndarray, is obtained by <b>shape</b>.. Image processing with Python, NumPy", "dateLastCrawled": "2022-01-25T00:24:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to PyTorch Tensors \u2014 PyTorch Tutorials 1.10.1+cu102 ...", "url": "https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html", "isFamilyFriendly": true, "displayUrl": "https://pytorch.org/tutorials/beginner/introyt/<b>tensors</b>_deeper_tutorial.html", "snippet": "The first new thing in the code cell above is the use of the .<b>shape</b> property on a <b>tensor</b>. This property contains a list of the extent of each dimension of a <b>tensor</b> - in our case, x is a three-dimensional <b>tensor</b> with <b>shape</b> 2 x 2 x 3. Below that, we call the .empty_like(), .zeros_like(), .ones_like(), and .rand_like() methods. Using the .<b>shape</b> property, we can verify that each of these methods returns a <b>tensor</b> of identical dimensionality and extent.. The last way to create a <b>tensor</b> that will ...", "dateLastCrawled": "2022-01-31T11:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "3 Introduction to Machine Learning | Machine Learning and AI in ...", "url": "https://theoreticalecology.github.io/machinelearning/introduction.html", "isFamilyFriendly": true, "displayUrl": "https://theoreticalecology.github.io/machinelearning/introduction.html", "snippet": "## tf.<b>Tensor</b>(20.0, <b>shape</b>=(), dtype=float32) TensorFlow containers are objects, what means that they are not just simple variables of type numeric (class(5)), but they instead have so called methods. Methods are changing the state of a class (which for most of our purposes here is the values of the object). For instance, there is a method to ...", "dateLastCrawled": "2022-01-10T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Recommending <b>Similar</b> Fashion Images with Deep Learning", "url": "https://blog.floydhub.com/similar-fashion-images/", "isFamilyFriendly": true, "displayUrl": "https://blog.floydhub.com/<b>similar</b>-fashion-images", "snippet": "It takes in input_layer (a 4D <b>tensor</b>), filter_<b>shape</b> (a list that contains [filter_<b>height</b>, filter_<b>width</b>, filter_<b>depth</b>, filter_number]), and stride (the stride size for our convolution). It returns a 4D <b>tensor</b> output.", "dateLastCrawled": "2022-02-02T22:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "6. Image Colorization \u2013 Deep Learning Projects Using TensorFlow 2 ...", "url": "https://goois.net/6-image-colorization-deep-learning-projects-using-tensorflow-2-neural-network-development-with-python-and-keras.html", "isFamilyFriendly": true, "displayUrl": "https://goois.net/6-image-colorization-deep-learning-projects-using-<b>tensor</b>flow-2...", "snippet": "<b>Imagine</b> we are in a dark room and we can view our surroundings using only a flashlight. The flashlight allows us to see only a small section of the room at a time. A CNN works in a <b>similar</b> manner. The flashlight is called the filter and the illuminated area that\u2019s covered by the flashlight and is called the receptive field. The filter moves to the right with a certain stride value until it parses the complete <b>width</b>. It then slides or convolves down to the beginning (left) of the image with ...", "dateLastCrawled": "2022-01-07T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Advanced Convolutional Neural Networks \u2013 Deep Learning with TensorFlow ...", "url": "https://w3sdev.com/advanced-convolutional-neural-networks-deep-learning-with-tensorflow-2-and-keras-second-edition.html", "isFamilyFriendly": true, "displayUrl": "https://w3sdev.com/advanced-convolutional-neural-networks-deep-learning-with-<b>tensor</b>...", "snippet": "A third approach is to use a CNN encoder-decoder network, where the encoder decreases the <b>width</b> and <b>height</b> of the image but increases its <b>depth</b> (number of features), while the decoder uses transposed convolution operations to increase its size and decrease <b>depth</b>. Transpose convolution (or upsampling) is the process of going in the opposite direction of a normal convolution. The input to this network is the image and the output is the segmentation map.", "dateLastCrawled": "2021-12-18T18:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "CHAPTER 4 FLOW IN CHANNELS - <b>MIT OpenCourseWare</b>", "url": "https://ocw.mit.edu/courses/earth-atmospheric-and-planetary-sciences/12-090-introduction-to-fluid-motions-sediment-transport-and-current-generated-sedimentary-structures-fall-2006/course-textbook/ch4.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/courses/earth-atmospheric-and-planetary-sciences/12-090...", "snippet": "<b>imagine</b> pouring water from a row of little faucets onto a plane a mile long and sloping a few degrees. 7 Obviously only liquids, not ... as the <b>width</b> increases relative to the <b>depth</b>. The right-hand sides of all three equations, 4.1, 4.2, and 4.3, become \u03b3 sin\u03b1RH. 13 Equation 4.3, or its special cases Equation 4.1 or Equation 4.2, is the basic resistance equation for steady uniform flow in an open channel. Not many useful results in fluid mechanics are so easily derived! It is the principal ...", "dateLastCrawled": "2022-02-03T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep Learning 101 Flashcards | Chegg.com", "url": "https://www.chegg.com/flashcards/deep-learning-101-7a1219c2-e3c9-4c21-aaed-2a187e49cdf0/deck", "isFamilyFriendly": true, "displayUrl": "https://www.chegg.com/flashcards/deep-learning-101-7a1219c2-e3c9-4c21-aaed-2a187e49cdf...", "snippet": "- Images\u20144D tensors of <b>shape</b> (samples, <b>height</b>, <b>width</b>, channels) or (samples, channels, <b>height</b>, <b>width</b>) -&gt; Images typically have three dimensions: <b>height</b>, <b>width</b>, and color <b>depth</b>. Although grayscale images (like our MNIST digits) have only a single color channel and could thus be stored in 2D tensors, by convention image tensors are always 3D, with a onedimensional color channel for grayscale images. A batch of 128 grayscale images of size 256 \u00d7 256 could thus be stored in a <b>tensor</b> of <b>shape</b> ...", "dateLastCrawled": "2021-12-30T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "An introduction to Convolutional Neural Networks | by Christopher ...", "url": "https://towardsdatascience.com/an-introduction-to-convolutional-neural-networks-eb0b60b58fd7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-introduction-to-<b>convolution</b>al-neural-networks-eb0b60...", "snippet": "With padding, the output from an input of <b>width</b> w, <b>height</b> h <b>and depth</b> 3 would be the ceiling of <b>width</b> w/2, <b>height</b> h/2 <b>and depth</b> 1, as the kernel outputs a single summed output from each stride. For example, with an input of 3x64x64 (say a 64x64 RGB three channel image), one kernel taking strides of two with padding the edge pixels, would produce a channel/feature map of 32x32.", "dateLastCrawled": "2022-02-02T15:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Convolutional Neural Network. Learn Convolutional Neural Network from ...", "url": "https://towardsdatascience.com/covolutional-neural-network-cb0883dd6529", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/covolutional-neural-network-cb0883dd6529", "snippet": "So the intensity of the red channel at each point with <b>width</b> and <b>height</b> can be represented into a matrix, the same goes for the blue and green channels, so we end up having three matrices, and when these are combined they form a <b>tensor</b>. 3.2 Edge Detection. Every image has vertical and horizontal edges which actually combining to form a image ...", "dateLastCrawled": "2022-02-02T20:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Get image <b>size (width, height) with Python, OpenCV, Pillow</b> (PIL) | note ...", "url": "https://note.nkmk.me/en/python-opencv-pillow-image-size/", "isFamilyFriendly": true, "displayUrl": "https://note.nkmk.me/en/python-opencv-pillow-image-size", "snippet": "OpenCV: Get image size (<b>width</b>, <b>height</b>) with ndarray.<b>shape</b>. When an image file is read by OpenCV, it is treated as NumPy array ndarray.The size (<b>width</b>, <b>height</b>) of the image can be acquired from the attribute <b>shape</b> indicating the <b>shape</b> of ndarray.. Not limited to OpenCV, the size of the image represented by ndarray, such as when an image file is read by Pillow and converted to ndarray, is obtained by <b>shape</b>.. Image processing with Python, NumPy", "dateLastCrawled": "2022-01-25T00:24:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Guide to <b>Deep Learning</b> Layers - ADG Efficiency", "url": "https://adgefficiency.com/guide-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://adgefficiency.com/guide-<b>deep-learning</b>", "snippet": "A neural network built of fully connected layers <b>can</b> <b>be thought</b> of as a blank canvas. The intuition is to impose no structure and let the network figure everything out. This lack of structure is what gives neural networks of fully connected layers (of sufficient <b>depth</b> &amp; <b>width</b>) the ability to approximate any function - known as the Universal Approximation Theorem. The ability to approximate any function at first sounds attractive. Why do we need any other architecture if a fully connected ...", "dateLastCrawled": "2022-01-29T00:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep Learning 101 Flashcards | Chegg.com", "url": "https://www.chegg.com/flashcards/deep-learning-101-7a1219c2-e3c9-4c21-aaed-2a187e49cdf0/deck", "isFamilyFriendly": true, "displayUrl": "https://www.chegg.com/flashcards/deep-learning-101-7a1219c2-e3c9-4c21-aaed-2a187e49cdf...", "snippet": "- Images\u20144D tensors of <b>shape</b> (samples, <b>height</b>, <b>width</b>, channels) or (samples, channels, <b>height</b>, <b>width</b>) -&gt; Images typically have three dimensions: <b>height</b>, <b>width</b>, and color <b>depth</b>. Although grayscale images (like our MNIST digits) have only a single color channel and could thus be stored in 2D tensors, by convention image tensors are always 3D, with a onedimensional color channel for grayscale images. A batch of 128 grayscale images of size 256 \u00d7 256 could thus be stored in a <b>tensor</b> of <b>shape</b> ...", "dateLastCrawled": "2021-12-30T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Deep Learning II L9: Generative Models</b> | by Wayne Polatkan | Towards ...", "url": "https://towardsdatascience.com/deep-learning-ii-l9-generative-models-dcd599ad6e0b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>deep-learning-ii-l9-generative-models</b>-dcd599ad6e0b", "snippet": "<b>Imagine</b> if the kilogram or meter changed. If you want to see live chaos, just take a look at FOREX markets. shp = arr_hr.<b>shape</b>[1:] vgg_inp = Input(shp) vgg = VGG16(include_top=False, input_<b>tensor</b>=vgg_\u03bb(vgg_inp)) for \u03bb in vgg.layers: \u03bb.trainable=False. The input <b>tensor</b> <b>shape</b> shp for the VGG network is the HiRes image dimensions. Hence: shp = arr_hr.<b>shape</b>[1:] and vgg_inp = Input(shp). arr_hr is a NumPy array created from a bcolz compressed array on disk, and its dimensions (<b>shape</b>) are: (num ...", "dateLastCrawled": "2022-02-03T15:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "9. Neural Network Collection \u2013 Deep Learning Projects Using TensorFlow ...", "url": "https://goois.net/9-neural-network-collection-deep-learning-projects-using-tensorflow-2-neural-network-development-with-python-and-keras.html", "isFamilyFriendly": true, "displayUrl": "https://goois.net/9-neural-network-collection-deep-learning-projects-using-<b>tensor</b>flow...", "snippet": "Due to its similar architecture, ResNet <b>can</b> <b>be thought</b> of as a special case of a highway network. However, highway networks themselves do not perform as well as ResNets. This tells us that it is more important to keep these \u201cgradient highways\u201d clear than to go for a larger solution space. Following this intuition, the authors refined the residual block and proposed a preactivation variant of residual block, in which the gradients <b>can</b> flow through the shortcut connections to any other ...", "dateLastCrawled": "2022-02-03T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "An introduction to Convolutional Neural Networks | by Christopher ...", "url": "https://towardsdatascience.com/an-introduction-to-convolutional-neural-networks-eb0b60b58fd7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-introduction-to-<b>convolution</b>al-neural-networks-eb0b60...", "snippet": "With padding, the output from an input of <b>width</b> w, <b>height</b> h <b>and depth</b> 3 would be the ceiling of <b>width</b> w/2, <b>height</b> h/2 <b>and depth</b> 1, as the kernel outputs a single summed output from each stride. For example, with an input of 3x64x64 (say a 64x64 RGB three channel image), one kernel taking strides of two with padding the edge pixels, would produce a channel/feature map of 32x32.", "dateLastCrawled": "2022-02-02T15:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Problems and Solutions on Atomic, Nuclear and Particle Physics</b> ...", "url": "https://www.academia.edu/36835743/Problems_and_Solutions_on_Atomic_Nuclear_and_Particle_Physics", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/36835743/<b>Problems_and_Solutions_on_Atomic_Nuclear_and</b>...", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-02T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A case study on <b>Malaria</b> detection using cell images and Deep ...", "url": "https://medium.com/@saugata.paul1010/a-case-study-on-malaria-detection-using-cell-images-and-deep-convolution-neural-networks-in-keras-8d07356a3d05", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@saugata.paul1010/a-case-study-on-<b>malaria</b>-detection-using-cell...", "snippet": "An input <b>tensor</b> with <b>shape</b> (number of images) x (image <b>width</b>) x (image <b>width</b>) x (number of channels). Feature detectors, whose <b>width</b> and <b>height</b> are hyper-parameters, and whose number of channels ...", "dateLastCrawled": "2022-01-31T14:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to Develop a Pix2Pix GAN <b>for Image-to-Image Translation</b>", "url": "https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-ima", "snippet": "We <b>can</b> prepare this dataset for training a Pix2Pix GAN model in Keras. We will just work with the images in the training dataset. Each image will be loaded, rescaled, and split into the satellite and Google map elements. The result will be 1,097 color image pairs with the <b>width</b> and <b>height</b> of 256\u00d7256 pixels.", "dateLastCrawled": "2022-02-02T18:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Can</b> our brains see the fourth dimension? | HowStuffWorks", "url": "https://science.howstuffworks.com/science-vs-myth/everyday-myths/see-the-fourth-dimension.htm", "isFamilyFriendly": true, "displayUrl": "https://<b>science.howstuffworks.com</b>/science-vs-myth/everyday-myths/see-the-fourth...", "snippet": "Most of us are accustomed to watching 2-D; even though characters on the screen appear to have <b>depth</b> and texture, the image is actually flat. But when we put on those 3-D glasses, we see a world that has <b>shape</b>, a world that we could walk in. We <b>can</b> <b>imagine</b> existing in such a world because we live in one. The things in our daily life have <b>height</b>, <b>width</b> and length. But for someone who&#39;s only known life in two dimensions, 3-D would be impossible to comprehend. And that, according to many ...", "dateLastCrawled": "2022-02-02T07:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Relativity (physics): &#39;Space-time is like a fabric of space and time ...", "url": "https://www.quora.com/Relativity-physics-Space-time-is-like-a-fabric-of-space-and-time-knit-together-This-statement-makes-no-sense-to-me-How-can-I-imagine-a-mass-bending-the-space-time-fabric", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Relativity-physics-Space-time-is-like-a-fabric-of-space-and-time...", "snippet": "Answer (1 of 9): It <b>can</b> be somewhat confusing to understand, but it&#39;s not that difficult. The real problem is, the words which are used to describe spacetime, are the words which are used in our daily lives for regular things. For example, knitting a sweater and knitting spacetime. Fabric of cott...", "dateLastCrawled": "2022-01-21T07:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "3 Introduction to Machine Learning | Machine Learning and AI in ...", "url": "https://theoreticalecology.github.io/machinelearning/introduction.html", "isFamilyFriendly": true, "displayUrl": "https://theoreticalecology.github.io/machinelearning/introduction.html", "snippet": "## tf.<b>Tensor</b>(20.0, <b>shape</b>=(), dtype=float32) TensorFlow containers are objects, what means that they are not just simple variables of type numeric (class(5)), but they instead have so called methods. Methods are changing the state of a class (which for most of our purposes here is the values of the object). For instance, there is a method to ...", "dateLastCrawled": "2022-01-10T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep Learning 101 Flashcards | Chegg.com", "url": "https://www.chegg.com/flashcards/deep-learning-101-7a1219c2-e3c9-4c21-aaed-2a187e49cdf0/deck", "isFamilyFriendly": true, "displayUrl": "https://www.chegg.com/flashcards/deep-learning-101-7a1219c2-e3c9-4c21-aaed-2a187e49cdf...", "snippet": "- Images\u20144D tensors of <b>shape</b> (samples, <b>height</b>, <b>width</b>, channels) or (samples, channels, <b>height</b>, <b>width</b>) -&gt; Images typically have three dimensions: <b>height</b>, <b>width</b>, and color <b>depth</b>. Although grayscale images (like our MNIST digits) have only a single color channel and could thus be stored in 2D tensors, by convention image tensors are always 3D, with a onedimensional color channel for grayscale images. A batch of 128 grayscale images of size 256 \u00d7 256 could thus be stored in a <b>tensor</b> of <b>shape</b> ...", "dateLastCrawled": "2021-12-30T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Harnessing the power of <b>transfer learning</b> for medical image ...", "url": "https://towardsdatascience.com/harnessing-the-power-of-transfer-learning-for-medical-image-classification-fd772054fdc7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/harnessing-the-power-of-<b>transfer-learning</b>-for-medical...", "snippet": "a) Left: Image data is stored as a 4D <b>tensor</b> with the <b>shape</b> of (samples, <b>height</b>, <b>width</b>, <b>depth</b>). <b>Depth</b> refers to the number of channels (1 for greyscale, 3 for RGB). b) Center: a sliding window (black <b>square</b>) moves across the feature map extracting information from every possible location. c) Right: Information learned from each convolution layer propagates forward until a loss function compares predicted and target responses which gives a loss score. This score is used by the optimizer to ...", "dateLastCrawled": "2022-02-02T19:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "CHAPTER 4 FLOW IN CHANNELS - <b>MIT OpenCourseWare</b>", "url": "https://ocw.mit.edu/courses/earth-atmospheric-and-planetary-sciences/12-090-introduction-to-fluid-motions-sediment-transport-and-current-generated-sedimentary-structures-fall-2006/course-textbook/ch4.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/courses/earth-atmospheric-and-planetary-sciences/12-090...", "snippet": "<b>imagine</b> pouring water from a row of little faucets onto a plane a mile long and sloping a few degrees. 7 Obviously only ... hydraulic radius of an infinitely wide channel flow is just the flow <b>depth</b> d. You <b>can</b> reason that as the <b>width</b> b increases relative to the <b>depth</b> d, the term 2d in the denominator 2d+b becomes a smaller and smaller part of the denominator, so the hydraulic radius bd/(2d+b) tends toward bd/b, or just d, as the <b>width</b> increases relative to the <b>depth</b>. The right-hand sides of ...", "dateLastCrawled": "2022-02-03T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "An introduction to Convolutional Neural Networks | by Christopher ...", "url": "https://towardsdatascience.com/an-introduction-to-convolutional-neural-networks-eb0b60b58fd7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-introduction-to-<b>convolution</b>al-neural-networks-eb0b60...", "snippet": "With padding, the output from an input of <b>width</b> w, <b>height</b> h <b>and depth</b> 3 would be the ceiling of <b>width</b> w/2, <b>height</b> h/2 <b>and depth</b> 1, as the kernel outputs a single summed output from each stride. For example, with an input of 3x64x64 (say a 64x64 RGB three channel image), one kernel taking strides of two with padding the edge pixels, would produce a channel/feature map of 32x32.", "dateLastCrawled": "2022-02-02T15:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to Code a Convolutional Neural Network Within an Hour Without Any ...", "url": "https://aarushimehrotra.medium.com/how-to-code-a-convolutional-neural-network-within-an-hour-without-any-machine-learning-experience-9cbfbac63371", "isFamilyFriendly": true, "displayUrl": "https://aarushimehrotra.medium.com/how-to-code-a-convolutional-neural-network-within...", "snippet": "The filter is <b>a square</b> matrix with a <b>height</b> and <b>width</b> less than the original image (in this case, 5x5, but it <b>can</b> be anywhere between 1x1 to 7x7 usually), but the <b>depth</b> is always the same as the image. The filter acts like the W weights matrix we had for normal neural networks since we take the dot product of the 5x5x3 filter and the 5x5x3 section of the image it\u2019s currently. The dot product basically takes each matrix and stretches it out into a row and a column vector of the same length ...", "dateLastCrawled": "2022-01-18T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "All about Structural Similarity Index (<b>SSIM</b>): Theory + Code in PyTorch ...", "url": "https://medium.com/srm-mic/all-about-structural-similarity-index-ssim-theory-code-in-pytorch-6551b455541e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/srm-mic/all-about-structural-similarity-index-<b>ssim</b>-theory-code-in-p...", "snippet": "Recently, while implementing a <b>depth</b> estimation paper, I came across the term Structural Similarity Index(<b>SSIM</b>).<b>SSIM</b> is used as a metric to measure the similarity between two given images.As this ...", "dateLastCrawled": "2022-02-03T02:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Introduction to Convolution Neural Network - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/introduction-convolution-neural-network/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/introduction-convolution-neural-network", "snippet": "Every filter has small <b>width</b> and <b>height</b> and the same <b>depth</b> as that of input volume (3 if the input layer is image input). For example, if we have to run convolution on an image with dimension 34x34x3. The possible size of filters <b>can</b> be axax3, where \u2018a\u2019 <b>can</b> be 3, 5, 7, etc but small as <b>compared</b> to image dimension.", "dateLastCrawled": "2022-02-01T01:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "9. Neural Network Collection \u2013 Deep Learning Projects Using TensorFlow ...", "url": "https://goois.net/9-neural-network-collection-deep-learning-projects-using-tensorflow-2-neural-network-development-with-python-and-keras.html", "isFamilyFriendly": true, "displayUrl": "https://goois.net/9-neural-network-collection-deep-learning-projects-using-<b>tensor</b>flow...", "snippet": "The weights of the output neurons (the readout layer) are trainable and <b>can</b> be learned so that the network <b>can</b> reproduce specific temporal patterns. The hidden layer (or the reservoir) is very sparsely connected (typically &lt;10% connectivity). The reservoir architecture creates a recurrent nonlinear embedding of the input, which <b>can</b> be then connected to the desired output. These final weights will be trainable. It is possible to connect the embedding to a different predictive model (such as a ...", "dateLastCrawled": "2022-02-03T02:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to <b>crop</b> an image in OpenCV using <b>Python</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/15589517/how-to-crop-an-image-in-opencv-using-python", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/15589517", "snippet": "@samkhan13, when I <b>crop</b> using this formula, all of my crops have <b>shape</b> (0, <b>width</b>, channels). Ie. I am not getting a y dimension at all \u2013 mLstudent33. Aug 28 &#39;19 at 6:13 . @mLstudent33 it is likely that the image im has not been read correctly and is empty. try using an IDE with breakpoints to diagnose your code step by step. you <b>can</b> use google colab to create code blocks and <b>can</b> share your jupytor notebook on <b>stackoverflow</b> <b>python</b> chat room to get someones help. \u2013 samkhan13. Aug 28 &#39;19 at ...", "dateLastCrawled": "2022-02-03T06:13:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understand Tensors and Matrices. Before <b>machine</b> <b>learning</b> and deep\u2026 | by ...", "url": "https://medium.com/data-science-bootcamp/understand-tensors-and-matrices-2ea361e303b8", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-bootcamp/understand-<b>tensors</b>-and-matrices-2ea361e303b8", "snippet": "Before <b>machine</b> <b>learning</b> and deep <b>learning</b> become super popular, <b>Tensor</b> is more of a Physics concept. In this case, <b>tensor</b> refers to high dimensional matrices (plural for matrix).", "dateLastCrawled": "2022-01-27T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Flatten, Reshape, and Squeeze Explained - Tensors for Deep <b>Learning</b> ...", "url": "https://deeplizard.com/learn/video/fCVuiW9AFzY", "isFamilyFriendly": true, "displayUrl": "https://deeplizard.com/learn/video/fCVuiW9AFzY", "snippet": "An <b>analogy</b> for tensors Suppose we are neural network programmers, and as such, we typically spend our days building neural networks. To do our job, we use various tools. We use math tools like calculus and linear algebra, computer science tools like Python and PyTorch, physics and engineering tools like CPUs and GPUs, and <b>machine</b> <b>learning</b> tools like neural networks, layers, activation functions, etc. Our task is to build neural networks that can transform or map input data to the correct ...", "dateLastCrawled": "2022-01-28T20:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Tensor</b>, <b>Tensor</b> Networks, Quantum <b>Tensor</b> Networks in <b>Machine</b> <b>Learning</b> ...", "url": "https://tensorworkshop.github.io/NeurIPS2020/accepted_papers/Tensor4ML_hourglass_shape_QTNML%20(3).pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>tensor</b>workshop.github.io/NeurIPS2020/accepted_papers/<b>Tensor</b>4ML_hourglass_<b>shape</b>...", "snippet": "The interplay between <b>tensor</b> networks, <b>machine</b> <b>learning</b> and quantum algorithms is rich. Indeed, this interplay is based not just on numerical methods but on the equivalence of <b>tensor</b> networks to various quantum circuits, rapidly developing algorithms from the mathematics and physics communities for optimizing and transforming <b>tensor</b> networks, and connections to low-rank methods for <b>learning</b>. A merger of <b>tensor</b> network algorithms with state-of-the-art approaches in deep <b>learning</b> is now taking ...", "dateLastCrawled": "2021-12-21T00:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>What is a Keras model</b> and how to use it to make ... - <b>ActiveState</b>", "url": "https://www.activestate.com/resources/quick-reads/what-is-a-keras-model/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>activestate</b>.com/resources/quick-reads/<b>what-is-a-keras-model</b>", "snippet": "input_<b>shape</b> argument creates a tuple containing one element. <b>Tensor</b> <b>shape</b> notation: N-dimensional <b>tensor</b>: (D0, D1, \u2026, Dn-1) Matrix <b>tensor</b> of size W x H: (W, H) Vector <b>tensor</b> of size W: (W,) Figure 4: <b>Tensor</b> <b>Shape</b>. <b>Tensor</b>. Generalization of vectors and matrices that are n-dimensional and contain the same type of data, eg. int32 or bool, etc. A ...", "dateLastCrawled": "2022-02-03T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>learning</b> for deep <b>elastic strain engineering of semiconductor</b> ...", "url": "https://www.nature.com/articles/s41524-021-00538-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41524-021-00538-0", "snippet": "Inspired by the wide adoption of deep <b>learning</b> in the field of computer vision 16, we draw an <b>analogy</b> between the color spectrum in a digital image and the band structure, regardless of whether it ...", "dateLastCrawled": "2022-01-30T04:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>Learning</b> for Economics and Finance in TensorFlow 2: Deep ...", "url": "https://dokumen.pub/machine-learning-for-economics-and-finance-in-tensorflow-2-deep-learning-models-for-research-and-industry-1st-ed-9781484263723-9781484263730.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/<b>machine</b>-<b>learning</b>-for-economics-and-finance-in-<b>tensor</b>flow-2-deep...", "snippet": "If each image had a different <b>shape</b>, it isn\u2019t obvious how we would specify the <b>shape</b> of the batch <b>tensor</b>. Furthermore, many <b>machine</b> <b>learning</b> frameworks will not be able to process non-rectangular tensors in a way that fully exploits the parallelization capabilities of a GPU or TPU. RANK-0 <b>TENSOR</b> (SCALAR) RANK-1 <b>TENSOR</b> (VECTOR) RANK-2 <b>TENSOR</b> (MATRIX) RANK-3 <b>TENSOR</b> (3-<b>TENSOR</b>) RANK-4 <b>TENSOR</b> (4-<b>TENSOR</b>) Figure 1-3. Decomposition of batch of color images into tensors 21 Chapter 1 TensorFlow 2 ...", "dateLastCrawled": "2021-11-30T03:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Complete Guide To Tensorflow Recommenders (with Python code)", "url": "https://analyticsindiamag.com/a-complete-guide-to-tensorflow-recommenders-with-python-code/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/a-complete-guide-to-<b>tensor</b>flow-recommenders-with-python-code", "snippet": "Developing comprehensive recommendation systems is a tedious and complicated effort for both novices and experts. It involves several steps starting with obtaining a dataset, embedding the vectors, and, most importantly, the complete coding technique To avoid the complexity in developing the recommender systems, TensorFlow has launched an open-source package called Tensorflow Recommenders.", "dateLastCrawled": "2022-02-02T22:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "python - Keras <b>input_tensor shape for transfer learning</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/50784756/keras-input-tensor-shape-for-transfer-learning", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/50784756", "snippet": "Keras <b>input_tensor shape for transfer learning</b>. Ask Question Asked 3 years, 6 months ago. Active 3 years, 3 months ago. Viewed 2k times 1 1. I am running a CNN for classification of medical scans using Keras and transfer <b>learning</b> with imagenet and InceptionV3. I am building the model with some practice data of size X_train = (624, 128, 128, 1) and Y_train = (624, 2). I am trying to resize the input_<b>tensor</b> to suit the <b>shape</b> of my images (128 x 128 x 1) using the below code. input_<b>tensor</b> ...", "dateLastCrawled": "2021-12-09T00:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Why, in <b>machine</b> <b>learning</b>, is the word &quot;<b>tensor</b>&quot; used so much? I don&#39;t ...", "url": "https://www.reddit.com/r/AskProgramming/comments/bzrl9g/why_in_machine_learning_is_the_word_tensor_used/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/bzrl9g/why_in_<b>machine</b>_<b>learning</b>_is_the_word_<b>tensor</b>_used", "snippet": "If you just want to arrange your data in 2D, then the term &quot;2D array&quot; is preferred. Likewise, in &quot;tensors&quot; you would also do <b>tensor</b> operations (I assume in <b>machine</b> <b>learning</b> you actually do). An <b>analogy</b>: complex numbers are just pairs of reals. But if you multiple your pairs of reals like (a,b) * (c,d) = (ac,bd) then probably you should not use ...", "dateLastCrawled": "2021-12-01T07:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the difference between a Vector and a <b>Tensor</b> in <b>Machine</b> <b>Learning</b>?", "url": "https://www.quora.com/What-is-the-difference-between-a-Vector-and-a-Tensor-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-a-Vector-and-a-<b>Tensor</b>-in-<b>Machine</b>...", "snippet": "Answer (1 of 2): A vector is a <b>tensor</b> of rank 1, a matrix is a <b>tensor</b> of rank 2. For a <b>tensor</b> with more than 2 dimensions, we refer to it as a <b>tensor</b>. Note that, rank of a matrix [1] from linear algebra is not the same as <b>tensor</b> rank [2] 1. Rank (linear algebra) - Wikipedia 2. <b>Tensor</b> - Wikipedia", "dateLastCrawled": "2022-01-13T06:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(shape (tensor))  is like +(imagine a square with height, width, and depth)", "+(shape (tensor)) is similar to +(imagine a square with height, width, and depth)", "+(shape (tensor)) can be thought of as +(imagine a square with height, width, and depth)", "+(shape (tensor)) can be compared to +(imagine a square with height, width, and depth)", "machine learning +(shape (tensor) AND analogy)", "machine learning +(\"shape (tensor) is like\")", "machine learning +(\"shape (tensor) is similar\")", "machine learning +(\"just as shape (tensor)\")", "machine learning +(\"shape (tensor) can be thought of as\")", "machine learning +(\"shape (tensor) can be compared to\")"]}