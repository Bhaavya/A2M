{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Design features with appropriate disclosures <b>built-in</b>: clarity and <b>control</b> is crucial to a good user experience. Consider augmentation and assistance: producing a single answer can be appropriate where there is a high probability that the answer satisfies a diversity of users and use cases. In other cases, it may be optimal for your system to suggest a few options to the user. Technically, it is much more difficult to achieve good precision at one answer (P@1) versus precision at a few ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Artificial Intelligence A Modern Approach</b> (4th Edition) | Fahim ...", "url": "https://www.academia.edu/45126798/Artificial_Intelligence_A_Modern_Approach_4th_Edition_", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/45126798/<b>Artificial_Intelligence_A_Modern_Approach</b>_4th_Edition_", "snippet": "Artificial Intelligence (AI) is a big field, and this is a big book. We have tried to explore the full breadth of the field, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; fairness,", "dateLastCrawled": "2022-02-02T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Balloon Juice</b> - <b>Both Sides of His Facebook</b>", "url": "https://www.balloon-juice.com/2017/09/28/both-sides-of-his-facebook/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>balloon-juice</b>.com/2017/09/28/<b>both-sides-of-his-facebook</b>", "snippet": "<b>Works</b>. Facebook, <b>like</b> most trad media, has never managed to grow a backbone\u2014not censorship or <b>bias</b>, but a backbone\u2014and defend <b>ethics &amp; fairness</b>. Hence Facebook keeps getting played. This is the same distortion/stupidity that made mass media cover both candidates badly before election. BS \u201cboth sides\u201d arguments and getting played and caving when someone flicks a finger: congrats. FB arrives as a traditional media company. As we discussed the other day, Facebook (and Twitter, Instagram ...", "dateLastCrawled": "2021-12-26T21:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Artificial Intelligence (AI): Multidisciplinary perspectives on</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S026840121930917X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S026840121930917X", "snippet": "The term loopthink is defined as a type of implicit <b>bias</b>, which does not perform correct reappraisal of information or revision of an ongoing plan of action. Thus, AI would disfavour qualitative human moral principles. Weak loopthink refers to the intrinsic inability of <b>computer</b> intelligence to redirect executive data flow because of its fixed internal hard writing, un-editable sectors of its operating system, or unalterable lines of its programme code. Strong loopthink refers to AI ...", "dateLastCrawled": "2022-01-29T18:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Morals/Ethics/Values Archives - <b>Socializing AI</b>", "url": "http://www.socializingai.com/category/moralsethicsvalues/", "isFamilyFriendly": true, "displayUrl": "www.<b>socializingai</b>.com/category/moralsethicsvalues", "snippet": "<b>Like</b> <b>computer</b> science as a whole, machine learning skews towards the white, male, and western. A parallel technical conference called Women in Machine Learning has run alongside NIPS for a decade. This Friday sees the first Black in AI workshop, intended to create a dedicated space for people of color in the field to present their work. Towards the end of her talk Tuesday, Crawford suggested civil disobedience could shape the uses of AI. She talked of French engineer Rene Carmille, who ...", "dateLastCrawled": "2022-01-18T19:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Digital Vision: Ethics - Global opinion paper - Atos", "url": "https://www.readkong.com/page/digital-vision-ethics-7693620", "isFamilyFriendly": true, "displayUrl": "https://www.readkong.com/page/digital-vision-ethics-7693620", "snippet": "Lack of explainability information are removed from application forms, people often arrive at different raises concerns around safety, <b>ethics, fairness</b>, reliability selection decisions. Provided they are well designed with ethical considerations and ultimately trust in the proposed solution. <b>built in</b> from the outset, digital applications could in principle vet applications with greater impartiality. AI Explainability is complicated. ML algorithms aim to detect patterns and hence insight from ...", "dateLastCrawled": "2021-10-10T12:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Where Programming, Ops, AI, and the</b> Cloud are Headed in 2021 \u2013 O\u2019Reilly", "url": "https://www.oreilly.com/radar/where-programming-ops-ai-and-the-cloud-are-headed-in-2021/", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/radar/<b>where-programming-ops-ai-and-the</b>-cloud-are-headed-in-2021", "snippet": "The distinction between languages with dynamic typing (<b>like</b> Ruby and JavaScript) and statically typed languages (<b>like</b> Java and Go) is arguably more important than the distinction between functional and object-oriented languages. Not long ago, the idea of adding static typing to dynamic languages would have started a brawl. No longer. Combining paradigms to form a hybrid is taking a hold here too. Python 3.5 added type hinting, and more recent versions have added additional static typing ...", "dateLastCrawled": "2022-02-01T09:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ITE302c Flashcards | Quizlet", "url": "https://quizlet.com/608594096/ite302c-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/608594096/ite302c-flash-cards", "snippet": "In PMI&#39;s Code of <b>Ethics, Fairness</b> is .... A. our duty to make decisions and act impartially and objectively. Our conduct must be free from competing self interest, prejudice, and favoritism. B. our duty to take ownership for the decisions we make or fail to make, the actions we take or fail to take, and the consequences that result. C. our duty to understand the truth and act in a truthful manner both in our communication D. our duty to show a high regard for ourselves, others, and the ...", "dateLastCrawled": "2021-12-11T15:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Socializing AI - Page 2 of 7 - <b>Where coders don&#39;t know to</b> go", "url": "http://www.socializingai.com/page/2/", "isFamilyFriendly": true, "displayUrl": "www.socializingai.com/page/2", "snippet": "Beneficial outcomes and protections against harms must be actively fought for and <b>built-in</b> from the beginning. But in a field as complex as AI, this is easier said than done. As scientists developing AI technologies, we have a responsibility to conduct and support open research and investigation into the wider implications of our work. At DeepMind, we start from the premise that all AI applications should remain under meaningful human <b>control</b>, and be used for socially beneficial purposes. So ...", "dateLastCrawled": "2021-12-03T07:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Artificial Intelligence: A Modern Approach (Pearson Series in Artifical ...", "url": "https://ebin.pub/artificial-intelligence-a-modern-approach-pearson-series-in-artifical-intelligence-4nbsped-0134610997-9780134610993.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/artificial-intelligence-a-modern-approach-pearson-series-in-artifical...", "snippet": "The most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence The long-anticipat...", "dateLastCrawled": "2021-11-29T17:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Design features with appropriate disclosures <b>built-in</b>: clarity and <b>control</b> is crucial to a good user experience. Consider augmentation and assistance: producing a single answer can be appropriate where there is a high probability that the answer satisfies a diversity of users and use cases. In other cases, it may be optimal for your system to suggest a few options to the user. Technically, it is much more difficult to achieve good precision at one answer (P@1) versus precision at a few ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Artificial Intelligence (AI): Multidisciplinary perspectives on</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S026840121930917X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S026840121930917X", "snippet": "The term loopthink is defined as a type of implicit <b>bias</b>, which does not perform correct reappraisal of information or revision of an ongoing plan of action. Thus, AI would disfavour qualitative human moral principles. Weak loopthink refers to the intrinsic inability of <b>computer</b> intelligence to redirect executive data flow because of its fixed internal hard writing, un-editable sectors of its operating system, or unalterable lines of its programme code. Strong loopthink refers to AI ...", "dateLastCrawled": "2022-01-29T18:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Artificial Intelligence A Modern Approach</b> (4th Edition) | Fahim ...", "url": "https://www.academia.edu/45126798/Artificial_Intelligence_A_Modern_Approach_4th_Edition_", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/45126798/<b>Artificial_Intelligence_A_Modern_Approach</b>_4th_Edition_", "snippet": "Artificial Intelligence (AI) is a big field, and this is a big book. We have tried to explore the full breadth of the field, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; fairness,", "dateLastCrawled": "2022-02-02T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Electoral Integrity", "url": "https://aceproject.org/ace-en/topics/ei/onePage", "isFamilyFriendly": true, "displayUrl": "https://aceproject.org/ace-en/topics/ei/onePage", "snippet": "Electoral Integrity. There is an ongoing debate over a single, universal definition of electoral integrity, but it can generally be defined as &quot;any election that is based on the democratic principles of universal suffrage and political equality as reflected in international standards and agreements, and is professional, impartial, and transparent in its preparation and administration throughout the electoral cycle.&quot;", "dateLastCrawled": "2022-01-30T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Digital Vision: Ethics - Global opinion paper - Atos", "url": "https://www.readkong.com/page/digital-vision-ethics-7693620", "isFamilyFriendly": true, "displayUrl": "https://www.readkong.com/page/digital-vision-ethics-7693620", "snippet": "Lack of explainability information are removed from application forms, people often arrive at different raises concerns around safety, <b>ethics, fairness</b>, reliability selection decisions. Provided they are well designed with ethical considerations and ultimately trust in the proposed solution. <b>built in</b> from the outset, digital applications could in principle vet applications with greater impartiality. AI Explainability is complicated. ML algorithms aim to detect patterns and hence insight from ...", "dateLastCrawled": "2021-10-10T12:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Where Programming, Ops, AI, and the</b> Cloud are Headed in 2021 \u2013 O\u2019Reilly", "url": "https://www.oreilly.com/radar/where-programming-ops-ai-and-the-cloud-are-headed-in-2021/", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/radar/<b>where-programming-ops-ai-and-the</b>-cloud-are-headed-in-2021", "snippet": "We\u2019ll certainly see sophisticated <b>computer</b>-aided coding as an aid to experienced programmers. Whether that means \u201c ... Both SRE and DevOps emphasize <b>similar</b> practices: version <b>control</b> (62% growth for GitHub, and 48% for Git), testing (high usage, though no year-over-year growth), continuous deployment (down 20%), monitoring (up 9%), and observability (up 128%). Terraform, HashiCorp\u2019s open source tool for automating the configuration of cloud infrastructure, also shows strong (53% ...", "dateLastCrawled": "2022-02-01T09:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Socializing AI - Page 2 of 7 - <b>Where coders don&#39;t know to</b> go", "url": "http://www.socializingai.com/page/2/", "isFamilyFriendly": true, "displayUrl": "www.socializingai.com/page/2", "snippet": "Beneficial outcomes and protections against harms must be actively fought for and <b>built-in</b> from the beginning. But in a field as complex as AI, this is easier said than done. As scientists developing AI technologies, we have a responsibility to conduct and support open research and investigation into the wider implications of our work. At DeepMind, we start from the premise that all AI applications should remain under meaningful human <b>control</b>, and be used for socially beneficial purposes. So ...", "dateLastCrawled": "2021-12-03T07:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ICCS 2020 Program \u2014 <b>New England Complex Systems Institute</b>", "url": "https://necsi.edu/iccs-2020-program", "isFamilyFriendly": true, "displayUrl": "https://necsi.edu/iccs-2020-program", "snippet": "It emerged as the most common theme discovered in a storytelling study of socio-material fractals, wherein nonprofit leaders were asked to describe any instances of self-<b>similar</b> repetition observed in their work (Wakefield, 2012). It was first defined as \u201cthe threefold, dynamic exercise of self-awareness, regard for others, and ecosystem knowledge\u201d (Wakefield, 2012, p. 114). The model was subsequently explored as \u201cfractal relationality,\u201d (Boje &amp; Henderson, 2015) and finally used in ...", "dateLastCrawled": "2021-12-22T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "ITE302c Flashcards | Quizlet", "url": "https://quizlet.com/608594096/ite302c-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/608594096/ite302c-flash-cards", "snippet": "The global surveillance <b>programs</b> leading by China and Russia governments. B. The global safety <b>programs</b> leading by US and Ukraine governments. C. The local surveillance <b>programs</b> leading by the cooperation of US and China governments. D. The global surveillance <b>programs</b> leading by US and UK governments. A. A gift may be considered a bribe if the gift is not made public. A. True B. False. A &#39;Humaneness&#39; is a political principle which is the main concept of operating a nation, connecting the ...", "dateLastCrawled": "2021-12-11T15:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Personal Blogs - Open University", "url": "https://learn1.open.ac.uk/mod/oublog/view.php?id=0&user=159031&page=2&tag", "isFamilyFriendly": true, "displayUrl": "https://learn1.open.ac.uk/mod/oublog/view.php?id=0&amp;user=159031&amp;page=2&amp;tag", "snippet": "Skip to main content. Page path", "dateLastCrawled": "2022-01-17T00:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Artificial Intelligence (AI): Multidisciplinary perspectives on</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S026840121930917X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S026840121930917X", "snippet": "Although, automation complacency and <b>bias</b> <b>can</b> speed up decision making when recommendations are correct, when the automation technology provides the incorrect recommendations it <b>can</b> lead to omission errors (the human does not respond to a critical situation) and commission errors (the human follows the recommendation of the automation, even though it is incorrect) (McBride et al., 2014, Parasuraman and Manzey, 2010). This presents an important research opportunity to explore and understand ...", "dateLastCrawled": "2022-01-29T18:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Morals/Ethics/Values Archives - <b>Socializing AI</b>", "url": "http://www.socializingai.com/category/moralsethicsvalues/", "isFamilyFriendly": true, "displayUrl": "www.<b>socializingai</b>.com/category/moralsethicsvalues", "snippet": "Some experts warn that algorithmic <b>bias</b> is already pervasive in many industries, and that almost no one is making an effort to identify or correct it. Karrie Karahalios, a professor of <b>computer</b> science at the University of Illinois, presented research highlighting how tricky it <b>can</b> be to spot <b>bias</b> in even the most commonplace algorithms.", "dateLastCrawled": "2022-01-18T19:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Electoral Integrity", "url": "https://aceproject.org/ace-en/topics/ei/onePage", "isFamilyFriendly": true, "displayUrl": "https://aceproject.org/ace-en/topics/ei/onePage", "snippet": "Electoral Integrity. There is an ongoing debate over a single, universal definition of electoral integrity, but it <b>can</b> generally be defined as &quot;any election that is based on the democratic principles of universal suffrage and political equality as reflected in international standards and agreements, and is professional, impartial, and transparent in its preparation and administration throughout the electoral cycle.&quot;", "dateLastCrawled": "2022-01-30T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Digital Vision: Ethics - Global opinion paper - Atos", "url": "https://www.readkong.com/page/digital-vision-ethics-7693620", "isFamilyFriendly": true, "displayUrl": "https://www.readkong.com/page/digital-vision-ethics-7693620", "snippet": "<b>built in</b> from the outset, digital applications could in principle vet applications with greater impartiality. AI Explainability is complicated. ML algorithms aim to detect patterns and hence insight from input data, but Nevertheless, humans consider themselves explainable because most of us <b>can</b> this process cannot be comprehended by simply listing articulate why we took a particular decision. And there is an incentive to be able to rules or instructions in human-readable format. The explain ...", "dateLastCrawled": "2021-10-10T12:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Artificial Intelligence A Modern Approach</b> (4th Edition) | Fahim ...", "url": "https://www.academia.edu/45126798/Artificial_Intelligence_A_Modern_Approach_4th_Edition_", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/45126798/<b>Artificial_Intelligence_A_Modern_Approach</b>_4th_Edition_", "snippet": "Artificial Intelligence (AI) is a big field, and this is a big book. We have tried to explore the full breadth of the field, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; fairness,", "dateLastCrawled": "2022-02-02T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "ITE302c Flashcards | Quizlet", "url": "https://quizlet.com/608594096/ite302c-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/608594096/ite302c-flash-cards", "snippet": "In PMI&#39;s Code of <b>Ethics, Fairness</b> is .... A. our duty to make decisions and act impartially and objectively. Our conduct must be free from competing self interest, prejudice, and favoritism. B. our duty to take ownership for the decisions we make or fail to make, the actions we take or fail to take, and the consequences that result. C. our duty to understand the truth and act in a truthful manner both in our communication D. our duty to show a high regard for ourselves, others, and the ...", "dateLastCrawled": "2021-12-11T15:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) From Policy-Making to Community Building: A Survey On 19 ...", "url": "https://www.academia.edu/30861143/From_Policy_Making_to_Community_Building_A_Survey_On_19_Experiences_of_eParticipation_Proceedings_of_the_12th_European_Conference_on_eGovernment_Institute_of_Public_Governance_and_Management_ESADE_Barcelona_2012", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30861143/From_Policy_Making_to_Community_Building_A_Survey_On...", "snippet": "This paper analyses the results of a survey on 19 experiences of eParticipation. It focuses on the different uses of technological tools regarding the communication needs of citizen participation processes. First, it offers an analytical framework of", "dateLastCrawled": "2022-02-03T03:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Artificial Intelligence - A Modern Approach - Stuart Russell, Peter ...", "url": "https://www.scribd.com/document/536338178/Artificial-Intelligence-a-Modern-Approach-Stuart-Russell-Peter-Norvig-2021", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/536338178/Artificial-Intelligence-a-Modern-Approach...", "snippet": "The subject matter Rationality itself also varies: some consider intelligence to be a property of internal <b>thought</b> processes and reasoning, while others focus on intelligent behavior, an external characterization.1 From these two dimensions\u2014human vs. rational2 and <b>thought</b> vs. behavior\u2014there are four possible combinations, and there have been adherents and research <b>programs</b> for all 1 In the public eye, there is sometimes confusion between the terms \u201cartificial intelligence\u201d and ...", "dateLastCrawled": "2022-01-22T04:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Artificial Intelligence A Modern Approach (4th Edition) (Pearson Series ...", "url": "https://www.scribd.com/document/531466588/Artificial-Intelligence-a-Modern-Approach-4th-Edition-Pearson-Series-in-Artifical-Intelligence-by-Stuart-Russell-Peter-Norvig-Z-lib-org", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/531466588/Artificial-Intelligence-a-Modern-Approach-4...", "snippet": "Of course, all <b>computer</b> <b>programs</b> do something, but <b>computer</b> agents are expected to do more: operate. autonomously, perceive their environment, persist over a prolonged time period, adapt to change, and create and pursue goals. A rational agent is one that acts so as to achieve the. best outcome or, when there is uncertainty, the best expected outcome. Rational agent. In the \u201claws of <b>thought</b>\u201d approach to AI, the emphasis was on correct inferences. Making. correct inferences is sometimes ...", "dateLastCrawled": "2022-01-25T20:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Socializing AI - Page 2 of 7 - <b>Where coders don&#39;t know to</b> go", "url": "http://www.socializingai.com/page/2/", "isFamilyFriendly": true, "displayUrl": "www.socializingai.com/page/2", "snippet": "In a statement broadcast live on Facebook on September 21 and subsequently posted to his profile page, Zuckerberg pledged to increase the resources of Facebook\u2019s security and election-integrity teams and to work \u201cproactively to strengthen the democratic process.\u201d It was an admirable commitment. But reading through it, I kept getting stuck on one line: \u201cWe have been working to ensure the integrity of the German elections this weekend,\u201d Zuckerberg writes.It\u2019s a comforting sentence ...", "dateLastCrawled": "2021-12-03T07:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Design features with appropriate disclosures <b>built-in</b>: clarity and <b>control</b> is crucial to a good user experience. Consider augmentation and assistance: producing a single answer <b>can</b> be appropriate where there is a high probability that the answer satisfies a diversity of users and use cases. In other cases, it may be optimal for your system to suggest a few options to the user. Technically, it is much more difficult to achieve good precision at one answer (P@1) versus precision at a few ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Reflection Paper</b> - Top Rated Tutors - sharpexperts.com", "url": "https://sharpexperts.com/requirements/reflection-paper-22836/", "isFamilyFriendly": true, "displayUrl": "https://sharpexperts.com/requirements/<b>reflection-paper</b>-22836", "snippet": "In <b>ethics, fairness</b> requires each person to be objective, unbiased, dispassionate, impartial, and consistent with the principles of <b>ethics. Fairness</b> is the ability to make judgments free from discrimination, dishonesty, or one\u2019s own <b>bias</b>. It is the ability to be objective without prejudice or <b>bias</b>. We often tolerate mediocrity. We sometimes forget to thank those who just do their jobs, and we often praise the extraordinary, sometimes despite questionable faults. To be fair, it is important ...", "dateLastCrawled": "2022-01-29T15:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Artificial Intelligence (AI): Multidisciplinary perspectives on</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S026840121930917X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S026840121930917X", "snippet": "Automation complacency is defined as the poorer detection of system malfunctions under automation <b>compared</b> with under manual <b>control</b> (Parasuraman &amp; Manzey, 2010). For example, human operators (e.g. pilots, air traffic controllers) not conducting enough checks of system state and assuming \u201call is well\u201d when in fact a dangerous condition is developing that leads to an accident. Automation <b>bias</b> has been defined as people using the outcome of a decision aid as a heuristic replacement for ...", "dateLastCrawled": "2022-01-29T18:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Morals/Ethics/Values Archives - <b>Socializing AI</b>", "url": "http://www.socializingai.com/category/moralsethicsvalues/", "isFamilyFriendly": true, "displayUrl": "www.<b>socializingai</b>.com/category/moralsethicsvalues", "snippet": "Some experts warn that algorithmic <b>bias</b> is already pervasive in many industries, and that almost no one is making an effort to identify or correct it. Karrie Karahalios, a professor of <b>computer</b> science at the University of Illinois, presented research highlighting how tricky it <b>can</b> be to spot <b>bias</b> in even the most commonplace algorithms.", "dateLastCrawled": "2022-01-18T19:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Electoral Integrity", "url": "https://aceproject.org/ace-en/topics/ei/onePage", "isFamilyFriendly": true, "displayUrl": "https://aceproject.org/ace-en/topics/ei/onePage", "snippet": "Electoral Integrity. There is an ongoing debate over a single, universal definition of electoral integrity, but it <b>can</b> generally be defined as &quot;any election that is based on the democratic principles of universal suffrage and political equality as reflected in international standards and agreements, and is professional, impartial, and transparent in its preparation and administration throughout the electoral cycle.&quot;", "dateLastCrawled": "2022-01-30T19:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Artificial Intelligence A Modern Approach</b> (4th Edition) | Fahim ...", "url": "https://www.academia.edu/45126798/Artificial_Intelligence_A_Modern_Approach_4th_Edition_", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/45126798/<b>Artificial_Intelligence_A_Modern_Approach</b>_4th_Edition_", "snippet": "Artificial Intelligence (AI) is a big field, and this is a big book. We have tried to explore the full breadth of the field, which encompasses logic, probability, and continuous mathematics; perception, reasoning, learning, and action; fairness,", "dateLastCrawled": "2022-02-02T22:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "ITE302c Flashcards | Quizlet", "url": "https://quizlet.com/608594096/ite302c-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/608594096/ite302c-flash-cards", "snippet": "In PMI&#39;s Code of <b>Ethics, Fairness</b> is .... A. our duty to make decisions and act impartially and objectively. Our conduct must be free from competing self interest, prejudice, and favoritism. B. our duty to take ownership for the decisions we make or fail to make, the actions we take or fail to take, and the consequences that result. C. our duty to understand the truth and act in a truthful manner both in our communication D. our duty to show a high regard for ourselves, others, and the ...", "dateLastCrawled": "2021-12-11T15:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ICCS 2020 Program \u2014 <b>New England Complex Systems Institute</b>", "url": "https://necsi.edu/iccs-2020-program", "isFamilyFriendly": true, "displayUrl": "https://necsi.edu/iccs-2020-program", "snippet": "We found that brain electrical activity from <b>control</b> sleeping animals showed a decrease in power at 30 Hz, as <b>compared</b> to walking animals that had high power in the entire frequency band analyzed, 0-60 Hz. Sleep deprived animals presented lower power in all EEG frequencies, even when they were allowed to sleep. On the other hand, we found that Fisher information and permutation entropy from <b>control</b> animals remains constant, however, in sleep deprived animals there is an increase in ...", "dateLastCrawled": "2021-12-22T08:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "JWT essay", "url": "https://studylib.net/doc/25698887/jwt-essay", "isFamilyFriendly": true, "displayUrl": "https://studylib.net/doc/25698887/jwt-essay", "snippet": "Free essays, homework help, flashcards, research papers, book reports, term papers, history, science, politics", "dateLastCrawled": "2022-02-01T03:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>The Rape of Blueberry</b>", "url": "http://www.blueberrysoftware.com/index.html", "isFamilyFriendly": true, "displayUrl": "www.blueberrysoftware.com/index.htm", "snippet": "The Thieves of Ann Arbor tells the true story of Accounting Fraud, software royalty fraud, and Intellectual Property Theft by Arbortext, Incorporated in Ann Arbor, Michigan. It names the company owner (Jim Sterken) and the executives (Ray Schiavone, Dave Peralta, Jim Haggarty, Cherie Van Allen, and Joyce Svechota) who conspired with him to commit these white collar crimes - the CEO, CFO, CIO, Controller, and Director of Product Management. It tells how their crimes were covered up by a ...", "dateLastCrawled": "2021-12-24T03:43:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Is Bias in Machine Learning all Bad</b>? - KDnuggets", "url": "https://www.kdnuggets.com/2019/07/bias-machine-learning-bad.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2019/07/<b>bias</b>-<b>machine</b>-<b>learning</b>-bad.html", "snippet": "<b>Analogy</b> with previously learned generalizations; If a system is <b>learning</b> a collection of related concepts, or generalizations, then a possible constraint on generalizing any one of them is to consider successful generalization of others. For example, consider a task of <b>learning</b> structural descriptions of blocks-world objects, such as \u201darch\u201d, \u201dtower\u201d, etc. After <b>learning</b> several concepts, the learned descriptions may reveal that certain features are more significant for describing ...", "dateLastCrawled": "2022-01-22T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Is it really fair or did you automate it?", "url": "https://deep1401.github.io/data-ethics-2", "isFamilyFriendly": true, "displayUrl": "https://deep1401.github.io/data-ethics-2", "snippet": "<b>Machine</b> <b>learning</b> can amplify <b>bias</b>. As proposed by (De-Arteaga et al.,2019) ,it was observed that the algorithms were clearly amplifying <b>bias</b> in an already biased dataset. For example, the proportion of females in an occupation dataset who were surgeons was 14.6%.", "dateLastCrawled": "2022-01-14T15:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Algorithmic injustice: a relational ethics approach", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7892355/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7892355", "snippet": "<b>Machine</b> classification and prediction are practices that act directly upon the world and result in tangible impact.64 Various companies, institutes, and governments use <b>machine</b>-<b>learning</b> systems across a variety of areas. These systems process people&#39;s behaviors, actions, and the social world at large. The <b>machine</b>-detected patterns often provide \u201canswers\u201d to fuzzy, contingent, and open-ended questions. These \u201canswers\u201d neither reveal any causal relations nor provide explanation on why ...", "dateLastCrawled": "2022-01-26T01:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Responsible AI practices \u2013 Google AI", "url": "https://ai.google/responsibilities/responsible-ai-practices/?category=fairness", "isFamilyFriendly": true, "displayUrl": "https://ai.google/responsibilities/responsible-ai-practices/?category=<b>fairness</b>", "snippet": "Data <b>bias</b> is another important consideration; learn more in practices on AI and <b>fairness</b>. Understand the limitations of your dataset and model . A model trained to detect correlations should not be used to make causal inferences, or imply that it can. E.g., your model may learn that people who buy basketball shoes are taller on average, but this does not mean that a user who buys basketball shoes will become taller as a result. <b>Machine</b> <b>learning</b> models today are largely a reflection of the ...", "dateLastCrawled": "2022-02-02T14:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) A review of some techniques for inclusion of domain-knowledge ...", "url": "https://www.researchgate.net/publication/357983755_A_review_of_some_techniques_for_inclusion_of_domain-knowledge_into_deep_neural_networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/357983755_A_review_of_some_techniques_for...", "snippet": "The <b>machine</b> <b>learning</b> system then conveys its explanations to the biologist. ... <b>ethics, fairness</b>, and explainability o ... <b>Analogy</b> Model 75 RNN. Transf orming Model. KBANN 86 MLP. Cascade-ARTMAP ...", "dateLastCrawled": "2022-01-21T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Algorithmic injustice: a relational ethics approach</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S2666389921000155", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2666389921000155", "snippet": "<b>Machine</b> classification and prediction are practices that act directly upon the world and result in tangible impact. 64 Various companies, institutes, and governments use <b>machine</b>-<b>learning</b> systems across a variety of areas. These systems process people&#39;s behaviors, actions, and the social world at large. The <b>machine</b>-detected patterns often provide \u201canswers\u201d to fuzzy, contingent, and open-ended questions. These \u201canswers\u201d neither reveal any causal relations nor provide explanation on why ...", "dateLastCrawled": "2022-01-29T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Human-centric Approach to Fairness in AI", "url": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "isFamilyFriendly": true, "displayUrl": "https://www.timlrx.com/blog/a-human-centric-approach-to-fairness-in-ai", "snippet": "A lot of what is discussed in the <b>machine</b> <b>learning</b> literature touches on fairness (or rather equivalence in certain outcomes) between groups, yet this narrowly constricts fairness to the notion of equality. Of course, we should think about fairness in the context of prejudiced groups, but we should also ask whether it is fair to an individual. Adding constraints in models might lead to worse outcomes for other individuals. If the decision making processs has serious consequences e.g. a fraud ...", "dateLastCrawled": "2022-02-03T02:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Algorithmic injustice: <b>a relational ethics approach</b>: <b>Patterns</b>", "url": "https://www.cell.com/patterns/fulltext/S2666-3899(21)00015-5", "isFamilyFriendly": true, "displayUrl": "https://www.cell.com/<b>patterns</b>/fulltext/S2666-3899(21)00015-5", "snippet": "Data science and <b>machine</b>-<b>learning</b> systems sit firmly within the rationalist tradition. The core of what <b>machine</b>-<b>learning</b> systems do can be exemplified as clustering similarities and differences, abstracting commonalities, and detecting <b>patterns</b>. <b>Machine</b>-<b>learning</b> systems \u201cwork\u201d by identifying <b>patterns</b> in vast amounts of data. Given immense, messy, and complex data, a <b>machine</b>-<b>learning</b> system can sort, classify, and cluster similarities based on seemingly shared features. Feed a neural ...", "dateLastCrawled": "2022-01-31T12:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>MATHEMATICS FOR MACHINE LEARNING</b> | g t - Academia.edu", "url": "https://www.academia.edu/41334219/MATHEMATICS_FOR_MACHINE_LEARNING", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/41334219", "snippet": "<b>MATHEMATICS FOR MACHINE LEARNING</b>. g t. Kong Yao Chee. fabio baca. book P D F services. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 37 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package ...", "dateLastCrawled": "2022-02-02T23:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Data Is the New What? Popular Metaphors &amp; Professional Ethics in ...", "url": "https://www.researchgate.net/publication/332828046_Data_Is_the_New_What_Popular_Metaphors_Professional_Ethics_in_Emerging_Data_Culture", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/332828046_Data_Is_the_New_What_Popular...", "snippet": "PDF | On Jan 1, 2019, Luke Stark and others published Data Is the New What? Popular Metaphors &amp; Professional Ethics in Emerging Data Culture | Find, read and cite all the research you need on ...", "dateLastCrawled": "2022-01-19T14:44:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bias (ethics/fairness))  is like +(built-in programs that control how a computer works)", "+(bias (ethics/fairness)) is similar to +(built-in programs that control how a computer works)", "+(bias (ethics/fairness)) can be thought of as +(built-in programs that control how a computer works)", "+(bias (ethics/fairness)) can be compared to +(built-in programs that control how a computer works)", "machine learning +(bias (ethics/fairness) AND analogy)", "machine learning +(\"bias (ethics/fairness) is like\")", "machine learning +(\"bias (ethics/fairness) is similar\")", "machine learning +(\"just as bias (ethics/fairness)\")", "machine learning +(\"bias (ethics/fairness) can be thought of as\")", "machine learning +(\"bias (ethics/fairness) can be compared to\")"]}