{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Ensemble Based Co-Training</b> | Hamideh Afsarmanesh - Academia.edu", "url": "https://www.academia.edu/7170674/Ensemble_Based_Co_Training", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/7170674/<b>Ensemble_Based_Co_Training</b>", "snippet": "In <b>co-training</b>, two classifiers based on different views of data or on different <b>learning</b> algorithms are trained in <b>parallel</b> and then unlabeled data that are classified differently by the classifiers but for which one classifier has large confidence are labeled and used as training data for the other. In this paper, a new form of <b>co-training</b>, called Ensemble-<b>Co-Training</b>, is proposed that uses an ensemble of different <b>learning</b> al- gorithms. Based on a theorem by Angluin and Laird that ...", "dateLastCrawled": "2022-01-18T23:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Ensemble Based <b>Co-Training</b> | Jafar Tanha - Academia.edu", "url": "https://www.academia.edu/33536005/Ensemble_Based_Co_Training", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/33536005/Ensemble_Based_<b>Co_Training</b>", "snippet": "In <b>co-training</b>, two classifiers based on different views of data or on different <b>learning</b> algorithms are trained in <b>parallel</b> and then unlabeled data that are classified differently by the classifiers but for which one classifier has large confidence are labeled and used as training data for the other. In this paper, a new form of <b>co-training</b>, called Ensemble-<b>Co-Training</b>, is proposed that uses an ensemble of different <b>learning</b> al- gorithms. Based on a theorem by Angluin and Laird that ...", "dateLastCrawled": "2021-12-24T06:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Multimodal Co-<b>learning</b>: Challenges, applications with datasets, recent ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "snippet": "<b>Co-training</b> is a form of multi-view <b>learning</b> algorithm of SSL methods and expects that two independent views represent every data point. The algorithm creates weak classifiers that utilize proxy labeling procedures to add more labeled data points using the threshold set on the prediction of classifiers. Blum and Mitchel", "dateLastCrawled": "2022-01-27T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Co-Training for Cross-Lingual Sentiment Classification</b>.", "url": "https://www.researchgate.net/publication/220873190_Co-Training_for_Cross-Lingual_Sentiment_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220873190_<b>Co-Training</b>_for_Cross-Lingual...", "snippet": "<b>Co\u2010training</b> algorithm is one of the main methods of semi\u2010supervised <b>learning</b> in machine <b>learning</b>, which explores the effective information in unlabeled data by multi\u2010learner collaboration ...", "dateLastCrawled": "2021-12-05T03:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "DoDNet: <b>Learning</b> to segment multi-organ and tumors from multiple ...", "url": "https://www.arxiv-vanity.com/papers/2011.10217/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2011.10217", "snippet": "The main component of DoDNet is the shared encoder-decoder that has an U-<b>like</b> architecture ... Multi-organ segmentation via <b>co-training</b> weight-averaged models from few-organ datasets. In Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., pages 146\u2013155. Springer, 2020. [16] Fabian Isensee, Paul F J\u00e4ger, Simon AA Kohl, Jens Petersen, and Klaus H Maier-Hein. Automated design of deep <b>learning</b> methods for biomedical image segmentation. arXiv preprint arXiv:1904.08128, 2019. [17 ...", "dateLastCrawled": "2022-01-27T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards the Interpretability of Machine <b>Learning</b> Predictions for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8122817/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8122817", "snippet": "In the same line of detecting recurrent BC, <b>Park</b> et al. used genetic information to create a graphical model based on semi-supervised <b>learning</b> (SSL) through gene pairs that indicate strong biological interactions, in this case for both breast and colon cancer. This graphic model proved to be quite accurate in predicting the recurrence of breast and colon cancer (80.7% and 76.7%, respectively). This SSL technique was seen to very interesting when very few labelled samples are available, which ...", "dateLastCrawled": "2022-01-27T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Parallel implementation of multilayered neural networks</b> based on Map ...", "url": "https://link.springer.com/article/10.1007/s00500-015-1599-3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00500-015-1599-3", "snippet": "This paper presents a general MLP network with <b>parallel</b> BP <b>learning</b> algorithm based on Map-Reduce on cloud computing clusters. One removes the restriction of speed and storage capacity on uniprocessor computers, the other surmounts the restriction of not being viable and finding optimal mapping of ANNs, not being to guarantee the synchronous calculation on NOWs. There are three main contributions of the algorithm in this paper: (1) taking advantage of cloud computing clusters, the algorithm ...", "dateLastCrawled": "2021-11-15T14:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>GitHub</b> - dkozlov/awesome-<b>knowledge-distillation</b>: Awesome Knowledge ...", "url": "https://github.com/dkozlov/awesome-knowledge-distillation", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/dkozlov/awesome-<b>knowledge-distillation</b>", "snippet": "<b>Like</b> What You <b>Like</b>: Knowledge Distill via Neuron Selectivity Transfer, Zehao Huang, Naiyan Wang, ... Kai Xu, Dae Hoon <b>Park</b>, Chang Yi, Charles Sutton, 2018; Efficient Neural Architecture Search via Parameters Sharing, Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean, 2018; Transparent Model Distillation, Sarah Tan, Rich Caruana, Giles Hooker, Albert Gordo, 2018; Defensive Collaborative Multi-task Training - Defending against Adversarial Attack towards Deep Neural Networks, Derek ...", "dateLastCrawled": "2022-02-02T09:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Best <b>SAP FICO</b> Online Training Bangalore BTM | IQ Stream Technologies", "url": "https://www.iqstreamtech.com/sap-fico-online-training/", "isFamilyFriendly": true, "displayUrl": "https://www.iqstreamtech.com/<b>sap-fico</b>-online-training", "snippet": "This course is very much suitable for the students coming from commerce and finance background <b>like</b> B.Com, MBA Finance, M.Com etc. Most of those students are not much exposed to ERP software and hence they land in low paying jobs. Either you are a freshers with such background or already working in a company with such background <b>learning</b> SAP ERP (FICO) will help you in making better career and sustain in the market with good job security.", "dateLastCrawled": "2022-01-24T02:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>SAP</b> FI Module Tutorial - Free PDF training materials for <b>learning</b> <b>SAP</b> ERP", "url": "https://sapbrainsonline.com/fi-tutorial", "isFamilyFriendly": true, "displayUrl": "https://<b>sap</b>brainsonline.com/fi-tutorial", "snippet": "<b>SAP</b> Financial Accounting is one of the important module in <b>SAP</b> software. Here you will get <b>SAP</b> FI tutorials and PDF training materials to download. Also refer about <b>SAP</b> FI tables &amp; tcodes. <b>SAP</b> FI module mainly deals with Fixed asset, accrual, bank, cash journal, inventory, and tax accounting , General ledger,Accounts receivable/accounts payable AR/AP, Fast close functions,Financial statements,<b>Parallel</b> valuations,Master data governance", "dateLastCrawled": "2022-02-02T05:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Ensemble Based <b>Co-Training</b> | Jafar Tanha - Academia.edu", "url": "https://www.academia.edu/33536005/Ensemble_Based_Co_Training", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/33536005/Ensemble_Based_<b>Co_Training</b>", "snippet": "In <b>co-training</b>, two classifiers based on different views of data or on different <b>learning</b> algorithms are trained in <b>parallel</b> and then unlabeled data that are classified differently by the classifiers but for which one classifier has large confidence are labeled and used as training data for the other. In this paper, a new form of <b>co-training</b>, called Ensemble-<b>Co-Training</b>, is proposed that uses an ensemble of different <b>learning</b> al- gorithms. Based on a theorem by Angluin and Laird that ...", "dateLastCrawled": "2021-12-24T06:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Ensemble Based Co-Training</b> | Hamideh Afsarmanesh - Academia.edu", "url": "https://www.academia.edu/7170674/Ensemble_Based_Co_Training", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/7170674/<b>Ensemble_Based_Co_Training</b>", "snippet": "In <b>co-training</b>, two classifiers based on different views of data or on different <b>learning</b> algorithms are trained in <b>parallel</b> and then unlabeled data that are classified differently by the classifiers but for which one classifier has large confidence are labeled and used as training data for the other. In this paper, a new form of <b>co-training</b>, called Ensemble-<b>Co-Training</b>, is proposed that uses an ensemble of different <b>learning</b> al- gorithms. Based on a theorem by Angluin and Laird that ...", "dateLastCrawled": "2022-01-18T23:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Multimodal Co-<b>learning</b>: Challenges, applications with datasets, recent ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "snippet": "An approach <b>similar</b> to <b>co-training</b> is adopted to classify images using images and their tags in a semi-supervised manner with a small set of labeled and rest unlabeled image-tag pairs . Images and tags are treated as two modalities, and tags are used as a supporting modality to classify the images using a multiple kernel <b>learning</b> classifier. Deep Visual Semantic Embedding (DeViSE)", "dateLastCrawled": "2022-01-27T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Development of semi-supervised multiple-output soft-sensors</b> with Co ...", "url": "https://www.sciencedirect.com/science/article/pii/S0169743919306379", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0169743919306379", "snippet": "Also, it is noticed necessarily that when the regression algorithm is the same, the time consumption <b>is similar</b> for both of <b>co-training</b> and tri-training models and the tri-training models achieve better prediction results, even though tri-training models are more complex than <b>co-training</b> models, Finally, we found that single-output models are more time-consuming than multi-output models, which further proves that the proposed multi-output models can improve the prediction efficiency.", "dateLastCrawled": "2021-12-29T17:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "6 Achieving Intelligence | <b>Computer Science: Reflections on the Field</b> ...", "url": "https://www.nap.edu/read/11106/chapter/8", "isFamilyFriendly": true, "displayUrl": "https://www.nap.edu/read/11106/chapter/8", "snippet": "Intuitively, the reason <b>co-training</b> works when <b>learning</b> to classify Web pages is that (1) the examples can be described by two different sets of features (hyperlink words, page words) that are redundantly sufficient, and (2) the two features are distributed somewhat independently, so that an example with an easy-to-classify hyperlink is likely to point to a Web page of average classification difficulty. We can . 1 . A. Blum and T. Mitchell, 1998, \u201cCombining Labeled and Unlabeled Data with ...", "dateLastCrawled": "2021-11-07T07:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Transductive learning for spatial regression</b> with <b>co-training</b>", "url": "https://www.researchgate.net/publication/221001770_Transductive_learning_for_spatial_regression_with_co-training", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221001770_Transductive_<b>learning</b>_for_spatial...", "snippet": "There are several examples of methods based on self-training (or based on closely related <b>co-training</b>) implemented for solving the task of (singletarget) regression [17][18][19] [20] [21]. To the ...", "dateLastCrawled": "2022-01-12T22:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Bootstrapping Parsers via Syntactic Projection across <b>Parallel</b> Texts", "url": "https://people.cs.pitt.edu/~hwa/nle04draft.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.cs.pitt.edu/~hwa/nle04draft.pdf", "snippet": "\u00a7Institute for Advanced Computer Studies, Univ. of Maryland, College <b>Park</b>, MD USA 20742 ... and <b>co-training</b> (Sarkar 2001; Steedman et al. 2003). In this article, we explore an alternative: using <b>parallel</b> text as a means for transferring syntactic knowledge from a resource-rich language to a language with fewer resources. The central idea is to annotate the English side of a <b>parallel</b> corpus, project the analysis to the second language, and then train a statistical parser on the resulting ...", "dateLastCrawled": "2021-07-18T22:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Towards the Interpretability of Machine <b>Learning</b> Predictions for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8122817/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8122817", "snippet": "In the same line of detecting recurrent BC, <b>Park</b> et al. used genetic information to create a graphical model based on semi-supervised <b>learning</b> (SSL) through gene pairs that indicate strong biological interactions, in this case for both breast and colon cancer. This graphic model proved to be quite accurate in predicting the recurrence of breast and colon cancer (80.7% and 76.7%, respectively). This SSL technique was seen to very interesting when very few labelled samples are available, which ...", "dateLastCrawled": "2022-01-27T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Placing <b>learning</b> needs in context: Distance <b>learning</b> for clinical ...", "url": "https://www.tandfonline.com/doi/pdf/10.1080/01421590802590546", "isFamilyFriendly": true, "displayUrl": "https://www.tandfonline.com/doi/pdf/10.1080/01421590802590546", "snippet": "Placing <b>learning</b> needs in context: Distance <b>learning</b> for clinical officers in Tanzania STEPHEN BRIGLEY1, IAN HOSEIN2 &amp; IRNEI MYEMBA3 1Cardiff University, UK, 2Cardiff and Vale NHS Trust, UK, 3Tanzanian Ministry of Health, Centre for Distance Education, Tanzania Abstract Background: Poor public health indicators in Tanzania have led to the upgrading of nursing and clinical personnel who currently have just core training. Clinical officers (COs) have 3 years training in basic and applied ...", "dateLastCrawled": "2021-05-21T18:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Multiview <b>learning</b> for understanding functional multiomics", "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371%2Fjournal.pcbi.1007677", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007677", "snippet": "<b>Similar</b> to MATCHER, ManiNetCluster is another method for multiview <b>learning</b> that attempts to identify conserved or specific gene modules across species via manifold alignment. Although the data used in their studies are merely transcriptomic profiled from bulk samples, the method is general sufficient to apply to single-cell multiomics data to identify cell types, cell states, and even the functional linkage between various omics. It is worth noting that not all NMF methods used in single ...", "dateLastCrawled": "2020-08-05T22:32:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "MiCo: Mixup <b>Co-Training for Semi-Supervised Domain Adaptation</b> | Request PDF", "url": "https://www.researchgate.net/publication/343228494_MiCo_Mixup_Co-Training_for_Semi-Supervised_Domain_Adaptation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343228494_MiCo_Mixup_<b>Co-Training</b>_for_Semi...", "snippet": "<b>Co-training</b> is a method for combining labeled and unlabeled data when examples <b>can</b> <b>be thought</b> of as containing two distinct sets of features. It has had a number of practical successes, yet ...", "dateLastCrawled": "2022-01-22T14:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 Achieving Intelligence | <b>Computer Science: Reflections on the Field</b> ...", "url": "https://www.nap.edu/read/11106/chapter/8", "isFamilyFriendly": true, "displayUrl": "https://www.nap.edu/read/11106/chapter/8", "snippet": "Intuitively, the reason <b>co-training</b> works when <b>learning</b> to classify Web pages is that (1) the examples <b>can</b> be described by two different sets of features (hyperlink words, page words) that are redundantly sufficient, and (2) the two features are distributed somewhat independently, so that an example with an easy-to-classify hyperlink is likely to point to a Web page of average classification difficulty. We <b>can</b> . 1 . A. Blum and T. Mitchell, 1998, \u201cCombining Labeled and Unlabeled Data with ...", "dateLastCrawled": "2021-11-07T07:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Multimodal Co-<b>learning</b>: Challenges, applications with datasets, recent ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "snippet": "As shown in Fig. 3, we established the co-<b>learning</b> objectives that <b>can</b> include existing co-<b>learning</b> work and are specific enough to clarify the purpose of co-<b>learning</b>. We expand the initial co-<b>learning</b> taxonomy to a comprehensive taxonomy, as shown in Fig. 1 , which helps set future research directions in multimodal co-<b>learning</b>.", "dateLastCrawled": "2022-01-27T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Improving Machine Reading Comprehension with Multi-Task <b>Learning</b> and ...", "url": "https://www.mdpi.com/2227-7390/10/3/310/html", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2227-7390/10/3/310/html", "snippet": "Multi-task <b>learning</b> is a field of machine <b>learning</b> in which multiple tasks are learned in <b>parallel</b> while using a shared representation [9,10,11]. Compared with <b>learning</b> multiple tasks individually, this joint <b>learning</b> effectively increases the sample size for training the model, thus leading to performance improvement by increasing the generalization of the model [ 12 ].", "dateLastCrawled": "2022-01-27T13:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "SFIM: Identify user behavior based on stable features | SpringerLink", "url": "https://link.springer.com/article/10.1007/s12083-021-01214-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12083-021-01214-2", "snippet": "The emergence of machine <b>learning</b> broke through this bottleneck, and ... They adopted the method of <b>co-training</b> to build a classifier that <b>can</b> recognize a variety of user behaviors performed by users in completely unlabeled different versions of the software, thus achieving an F1 metric of more than 0.8. Existing research also has some results on the identification of multiple service types. Fu et al. combined user behavior patterns, network traffic features, and time features to classify ...", "dateLastCrawled": "2022-01-27T11:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Semi-Supervised Sequence Modeling with Cross-View Training | DeepAI", "url": "https://deepai.org/publication/semi-supervised-sequence-modeling-with-cross-view-training", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/semi-supervised-sequence-modeling-with-cross-view-training", "snippet": "Furthermore, CVT <b>can</b> easily and effectively be combined with multi-task <b>learning</b>: we just add additional prediction modules for the different tasks on top of the shared Bi-LSTM encoder. Training a unified model to jointly perform all of the tasks except machine translation improves results (outperforming a multi-task ELMo model) while decreasing the total training time.", "dateLastCrawled": "2021-12-22T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) Syntax-driven <b>learning</b> of sub-sentential translation equivalents ...", "url": "https://www.academia.edu/2807089/Syntax_driven_learning_of_sub_sentential_translation_equivalents_and_translation_rules_from_parsed_parallel_corpora", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2807089/Syntax_driven_<b>learning</b>_of_sub_sentential_translation...", "snippet": "Syntax-driven <b>learning</b> of sub-sentential translation equivalents and translation rules from parsed <b>parallel</b> corpora. 2008. Vamshi Ambati. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 37 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package. Translate PDF ...", "dateLastCrawled": "2022-01-31T21:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Multimodal Machine Learning: A Survey</b> and Taxonomy", "url": "https://www.researchgate.net/publication/317185818_Multimodal_Machine_Learning_A_Survey_and_Taxonomy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/317185818_Multimodal_Machine_<b>Learning</b>_A...", "snippet": "Multimodal machine <b>learning</b> aims to build models that <b>can</b> process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with ...", "dateLastCrawled": "2022-02-02T10:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Overcoming the Domain Gap in Contrastive <b>Learning</b> of Neural Action ...", "url": "https://deepai.org/publication/overcoming-the-domain-gap-in-contrastive-learning-of-neural-action-representations", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/overcoming-the-domain-gap-in-contrastive-<b>learning</b>-of...", "snippet": "11/29/21 - A fundamental goal in neuroscience is to understand the relationship between neural activity and behavior. For example, the abilit...", "dateLastCrawled": "2022-01-26T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Declarative Memory Vs Nondeclarative Memory", "url": "https://groups.google.com/g/nvibsq/c/b3YyhmqtNU4", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/nvibsq/c/b3YyhmqtNU4", "snippet": "All groups and messages ... ...", "dateLastCrawled": "2021-12-27T11:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Co-training</b> using prosodic and lexical information for sentence ...", "url": "https://www.researchgate.net/publication/221491011_Co-training_using_prosodic_and_lexical_information_for_sentence_segmentation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221491011_<b>Co-training</b>_using_prosodic_and...", "snippet": "Soon, <b>co-training</b> was shown to outperform other stateof-the-art methods including self-training [27], and the conditional independence assumption was shown not to be essential in practice [4,44,45].", "dateLastCrawled": "2022-01-22T23:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Semi-supervised protein subcellular localization", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2648770/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2648770", "snippet": "<b>Co-training</b> has been successfully applied in many applications, including statistical parsing , visual detection , etc. Therefore, we believe it would be interesting to apply semi-supervised algorithm based on the <b>co-training</b> framework to the problem of protein subcellular localization. To our best knowledge, there has been no work that tries to solve the protein subcellular localization problem via a semi-supervised <b>learning</b> approach. Ensemble <b>learning</b> is a very important machine <b>learning</b> ...", "dateLastCrawled": "2021-10-30T17:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Improving Machine Reading Comprehension with Multi-Task <b>Learning</b> and ...", "url": "https://www.mdpi.com/2227-7390/10/3/310/html", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2227-7390/10/3/310/html", "snippet": "Multi-task <b>learning</b> is a field of machine <b>learning</b> in which multiple tasks are learned in <b>parallel</b> while using a shared representation [9,10,11]. <b>Compared</b> with <b>learning</b> multiple tasks individually, this joint <b>learning</b> effectively increases the sample size for training the model, thus leading to performance improvement by increasing the generalization of the model [ 12 ].", "dateLastCrawled": "2022-01-27T13:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Improving multi-label classification using semi-supervised <b>learning</b> and ...", "url": "https://dl.acm.org/doi/10.1007/978-3-642-32695-0_38", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/10.1007/978-3-642-32695-0_38", "snippet": "For both approaches, the <b>co-training</b> regression method is used to predict the values in the lower-dimensional spaces and then the original space <b>can</b> be reconstructed using the orthogonal property of SVD with adaptive threshold setting. Additionally, we also introduce a method of <b>parallel</b> computation to fasten the <b>co-training</b> regression. By a set of experiments on three real world datasets, the results show that our semi-supervised <b>learning</b> methods gain better performance, <b>compared</b> to the ...", "dateLastCrawled": "2021-10-19T04:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Fault Detection and Classification based on <b>Co-Training</b> of Semi ...", "url": "https://www.researchgate.net/publication/318691733_Fault_Detection_and_Classification_based_on_Co-Training_of_Semi-Supervised_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/318691733_Fault_Detection_and_Classification...", "snippet": "In [14], a semi-supervised <b>learning</b> method based on <b>co-training</b> [15,16] was proposed, which <b>can</b> be used in transmission and distribution systems of micro-grids to solve the fault classification ...", "dateLastCrawled": "2022-01-31T20:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Multimodal Co-<b>learning</b>: Challenges, applications with datasets, recent ...", "url": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1566253521002530", "snippet": "In this section, we set the context by explaining how objectives promised by multimodal co-<b>learning</b> are achieved in unimodal settings and multi-view <b>learning</b>. <b>Co-training</b> is well suited for multimodal data as each modality <b>can</b> be considered as different views. One modality <b>can</b> assist other modalities during training that may not be present ...", "dateLastCrawled": "2022-01-27T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Towards the Interpretability of Machine <b>Learning</b> Predictions for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8122817/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8122817", "snippet": "In the same line of detecting recurrent BC, <b>Park</b> et al. used genetic information to create a graphical model based on semi-supervised <b>learning</b> (SSL) through gene pairs that indicate strong biological interactions, in this case for both breast and colon cancer. This graphic model proved to be quite accurate in predicting the recurrence of breast and colon cancer (80.7% and 76.7%, respectively). This SSL technique was seen to very interesting when very few labelled samples are available, which ...", "dateLastCrawled": "2022-01-27T15:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "TransGAN: Two Transformers <b>Can</b> Make One Strong GAN | DeepAI", "url": "https://deepai.org/publication/transgan-two-transformers-can-make-one-strong-gan", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/transgan-two-<b>transformer</b>s-<b>can</b>-make-one-strong-gan", "snippet": "We then demonstrate TransGAN to notably benefit from data augmentations (more than standard GANs), a multi-task <b>co-training</b> strategy for the generator, and a locally initialized self-attention that emphasizes the neighborhood smoothness of natural images. Equipped with those findings, TransGAN <b>can</b> effectively scale up with bigger models and high-resolution image datasets. Specifically, our best architecture achieves highly competitive performance <b>compared</b> to current state-of-the-art GANs ...", "dateLastCrawled": "2022-01-26T02:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Comparative Study on Machine <b>Learning</b> Algorithms for Smart ...", "url": "https://asmedigitalcollection.asme.org/manufacturingscience/article/139/7/071018/454654/A-Comparative-Study-on-Machine-Learning-Algorithms", "isFamilyFriendly": true, "displayUrl": "https://asmedigitalcollection.asme.org/manufacturingscience/article/139/7/071018/454654", "snippet": "University <b>Park</b>, PA 16802 e-mail: dxw279@psu ... our future work will focus on designing the <b>parallel</b> implementation of machine <b>learning</b> algorithms that <b>can</b> be applied to large-scale and real-time prognosis. Acknowledgment. The research reported in this paper is partially supported by NSF under Grant Nos. IIP-1238335 and DMDII-15-14-01. Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the ...", "dateLastCrawled": "2022-01-28T22:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Cross-<b>modal recipe retrieval via parallel- and cross-attention networks</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0950705119306562", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0950705119306562", "snippet": "The inputs are embedding <b>learning</b> results from the <b>parallel</b>-attention network ... we <b>compared</b> PROTEIN to its two variants PAN and <b>CAN</b>. As illustrated in Section 4.1.3, PAN and <b>CAN</b> represent the PROTEIN solution employing only the <b>parallel</b>-attention network and cross-attention network, respectively. Table 3, Table 4 show the experimental results of PROTEIN and its two simplified variants. The conclusions are twofold: (1) PROTEIN consistently and significantly outperforms PAN and <b>CAN</b> with ...", "dateLastCrawled": "2022-01-10T22:22:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Supervised Learning and Co-training</b> | Request PDF", "url": "https://www.researchgate.net/publication/268809884_Supervised_Learning_and_Co-training", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/268809884_<b>Supervised_Learning_and_Co-training</b>", "snippet": "\u2022 <b>Co-Training</b> [2]: It is a <b>machine</b> <b>learning</b> algorithm used when there are only some labeled data and large amounts of unlabeled data. One of its uses is in text mining for search engines. ...", "dateLastCrawled": "2021-10-24T01:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Self-Supervised Graph <b>Co-Training</b> for Session-based Recommendation | DeepAI", "url": "https://deepai.org/publication/self-supervised-graph-co-training-for-session-based-recommendation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/self-supervised-graph-<b>co-training</b>-for-session-based...", "snippet": "<b>Co-Training</b> is a classical semi-supervised <b>learning</b> paradigm to exploit unlabeled data (Blum and Mitchell, 1998; Da Costa et al., 2018; Han et al., 2020). Under this regime, two classifiers are separately trained on two views and then exchange confident pseudo labels of unlabeled instances to construct additional labeled training data for each other. Typically, the two views are two disjoint sets of features and can provide complementary information to each other. Blum", "dateLastCrawled": "2022-02-01T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Cooperative <b>Learning</b> of Energy-Based Model and Latent Variable Model ...", "url": "http://www.stat.ucla.edu/~ywu/CoopNets/doc/CoopNets_AAAI.pdf", "isFamilyFriendly": true, "displayUrl": "www.stat.ucla.edu/~ywu/CoopNets/doc/CoopNets_AAAI.pdf", "snippet": "3Amazon RSML (Retail System <b>Machine</b> <b>Learning</b>) Group Abstract This paper proposes a cooperative <b>learning</b> algorithm to train both the undirected energy-based model and the directed latent variable model jointly. The <b>learning</b> algorithm interweaves the maximum likelihood algorithms for <b>learning</b> the two models, and each iteration consists of the following two steps: (1) Modi\ufb01ed contrastive divergence for energy-based model: The <b>learning</b> of the energy-based model is based on the contrastive ...", "dateLastCrawled": "2022-02-03T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interacting meaningfully with machine learning systems</b>: Three ...", "url": "https://dl.acm.org/doi/10.1016/j.ijhcs.2009.03.004", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/10.1016/j.ijhcs.2009.03.004", "snippet": "Although <b>machine</b> <b>learning</b> is becoming commonly used in today&#39;s software, there has been little research into how end users might interact with <b>machine</b> <b>learning</b> systems, beyond communicating simple &#39;&#39;right/wrong&#39;&#39; judgments. If the users themselves could work hand-in-hand with <b>machine</b> <b>learning</b> systems, the users&#39; understanding and trust of the system could improve and the accuracy of <b>learning</b> systems could be improved as well. We conducted three experiments to understand the potential for ...", "dateLastCrawled": "2022-01-28T03:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Classification Algorithm</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/classification-algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>classification-algorithm</b>", "snippet": "Two of the most popular methods for semi-supervised <b>learning</b> are <b>Co-Training</b> (Blum and Mitchell, 1998) and Semi-Supervised Support Vector Machines (S3VM) (Sindhwani and Keerthi, 2006). <b>Co-Training</b> assumes the presence of multiple views for each feature and uses the confident samples in one view to update the other. However, in applications such as image classification, one often has just a single feature vector and hence it is difficult to apply <b>Co-Training</b>. Semi-supervised support vector ...", "dateLastCrawled": "2022-01-18T09:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) CoSpa: A <b>Co-training</b> <b>Approach for Spam Review Identification</b> with ...", "url": "https://www.researchgate.net/publication/297724912_CoSpa_A_Co-training_Approach_for_Spam_Review_Identification_with_Support_Vector_Machine", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/297724912_CoSpa_A_<b>Co-training</b>_Approach_for...", "snippet": "<b>Co-training</b> is one of the semi-supervised techniques, \ufb01rst proposed by Blum and Mitchell 15 and has recently been extended into three categories: <b>co-training</b> with multiple views, <b>co-training</b> with", "dateLastCrawled": "2021-12-22T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Enhancement to <b>Selective Incremental Approach for Transductive</b> ...", "url": "https://www.grin.com/document/205436", "isFamilyFriendly": true, "displayUrl": "https://www.grin.com/document/205436", "snippet": "2.5 <b>Co-Training</b> and Multi view <b>Learning</b> 2.5.1 <b>Co-Training</b>. <b>Co-training</b> (Blum &amp; Mitchell, 1998) (Mitchell, 1999) assumes that (i) features can be split into two sets; (ii) each sub-feature set is sufficient to train a good classifier; (iii) the two sets are conditionally independent given the class. Initially two separate classifiers are trained ...", "dateLastCrawled": "2020-05-16T11:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>VICTORIA&#39;s MACHINE LEARNING NOTES</b> - Persagen Consulting", "url": "https://persagen.com/files/ml.html", "isFamilyFriendly": true, "displayUrl": "https://persagen.com/files/ml.html", "snippet": "<b>Machine</b> <b>learning</b> (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration ...", "dateLastCrawled": "2022-02-01T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>100 Must-Read</b> NLP Papers | This is a list of 100 important natural ...", "url": "http://masatohagiwara.net/100-nlp-papers/", "isFamilyFriendly": true, "displayUrl": "masatohagiwara.net/100-nlp-papers", "snippet": "<b>Machine</b> <b>Learning</b>. Avrim Blum and Tom Mitchell: Combining Labeled and Unlabeled Data with <b>Co-Training</b>, 1998. John Lafferty, Andrew McCallum, Fernando C.N. Pereira: Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data, ICML 2001. Charles Sutton, Andrew McCallum. An Introduction to Conditional Random Fields for Relational <b>Learning</b>. Kamal Nigam, et al.: Text Classification from Labeled and Unlabeled Documents using EM. <b>Machine</b> <b>Learning</b>, 1999. Kevin Knight ...", "dateLastCrawled": "2022-01-31T22:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Hui&#39;s Homepage", "url": "https://layneins.github.io/", "isFamilyFriendly": true, "displayUrl": "https://layneins.github.io", "snippet": "My main research interests include natural language processing, text mining and <b>machine</b> <b>learning</b>. News [2021.12] ... Unsupervised Conversation Disentanglement through <b>Co-Training</b> Hui Liu, Zhan Shi, Xiaodan Zhu EMNLP 2021 main conference, long paper Retrieval, <b>Analogy</b>, and Composition: A framework for Compositional Generalization in Image Captioning Zhan Shi, Hui Liu, Martin Renqiang Min, Christopher Malon, Li Erran Li and Xiaodan Zhu Findings of EMNLP 2021, long paper Enhancing Descriptive ...", "dateLastCrawled": "2022-02-02T14:08:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) A <b>literature survey of active machine learning</b> in the context of ...", "url": "https://www.researchgate.net/publication/228682097_A_literature_survey_of_active_machine_learning_in_the_context_of_natural_language_processing", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228682097_A_literature_survey_of_active...", "snippet": "Active <b>machine</b> <b>learning</b> is a supervised <b>learning</b> method in which the learner. is in control of the data from which it learns. That control is used by. the learner to ask an oracle, a teacher ...", "dateLastCrawled": "2022-02-01T01:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Deep <b>Learning</b> for Sensor-based Human Activity Recognition ...", "url": "https://www.researchgate.net/publication/338737352_Deep_Learning_for_Sensor-based_Human_Activity_Recognition_Overview_Challenges_and_Opportunities", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338737352_Deep_<b>Learning</b>_for_Sensor-based...", "snippet": "Many <b>machine</b> <b>learning</b> methods have been employed in human activity recognition. However ... The process of <b>co-training is like</b> the process of human <b>learning</b>. People can learn new knowledge. from ...", "dateLastCrawled": "2022-01-09T11:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Deep <b>Learning</b> for Sensor-based Human Activity Recognition: Overview ...", "url": "https://deepai.org/publication/deep-learning-for-sensor-based-human-activity-recognition-overview-challenges-and-opportunities", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/deep-<b>learning</b>-for-sensor-based-human-activity...", "snippet": "Transfer <b>learning</b> is a common <b>machine</b> <b>learning</b> technique that transfers the classification ability of the <b>learning</b> model from one predefined setting to a dynamic setting. Transfer <b>learning</b> is particularly effective in solving heterogeneity problems. It avoids the decline in the performance of <b>learning</b> models when the training data and the test data follow different distributions. In the activity recognition context, this problem appears when activity recognition models are deployed for ...", "dateLastCrawled": "2022-01-11T03:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Instance labeling in semi-supervised <b>learning</b> with meaning values of ...", "url": "https://www.sciencedirect.com/science/article/pii/S0952197617300672", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0952197617300672", "snippet": "In <b>machine</b> <b>learning</b> applications, especially in the field of text classification there are two conventional strategies; supervised <b>learning</b> and unsupervised <b>learning</b>. A sufficient amount of labeled data is required as training corpus to build the classifier in conventional supervised classification methods, which will be helpful to guess the class labels of the unlabeled instances. Conversely, unsupervised <b>learning</b>, only depends on unlabeled instances, and doesn\u2019t require class labels to ...", "dateLastCrawled": "2022-01-11T19:09:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(co-training)  is like +(learning to parallel park)", "+(co-training) is similar to +(learning to parallel park)", "+(co-training) can be thought of as +(learning to parallel park)", "+(co-training) can be compared to +(learning to parallel park)", "machine learning +(co-training AND analogy)", "machine learning +(\"co-training is like\")", "machine learning +(\"co-training is similar\")", "machine learning +(\"just as co-training\")", "machine learning +(\"co-training can be thought of as\")", "machine learning +(\"co-training can be compared to\")"]}