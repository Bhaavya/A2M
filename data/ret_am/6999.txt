{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse</b> <b>Linear Algebra</b> on AMD and NVIDIA GPUs \u2013 The Race Is On ...", "url": "https://link.springer.com/chapter/10.1007/978-3-030-50743-5_16", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-50743-5_16", "snippet": "The <b>sparse</b> matrix <b>vector</b> product (SpMV) ... Up to our knowledge, Ginkgo is the first open-source <b>sparse</b> <b>linear algebra</b> <b>library</b> based on C++ that features multiple SpMV kernels suitable for irregular matrices with back ends for both, AMD\u2019s and NVIDIA\u2019s GPUs. We ensure full result reproducibility by making all kernels publicly available as part of the Ginkgo <b>library</b>, and archiving the performance results in a public repository 2. Before providing more details about the <b>sparse</b> matrix ...", "dateLastCrawled": "2022-01-25T17:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Sparse Matrix-Vector Multiplication</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/sparse-matrix-vector-multiplication", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>sparse-matrix-vector-multiplication</b>", "snippet": "<b>Sparse matrix-vector multiplication</b> (SpMV) is a fundamental computational kernel used in scientific and engineering applications. The nonzero elements of <b>sparse</b> matrices are represented in different formats, and a single <b>sparse</b> matrix representation is not suitable for all <b>sparse</b> matrices with different sparsity patterns. Extensive studies have been done on improving the performance of <b>sparse</b> matrices processing on different platforms. Graphics processing units (GPUs) are very well suited ...", "dateLastCrawled": "2022-01-28T06:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Sparse</b> Matrix Libraries for C++: A Tour", "url": "http://jefftrull.github.io/c++/eigen/csparse/suitesparse/2017/02/10/a-tour-of-sparse-matrices-for-cplusplus.html", "isFamilyFriendly": true, "displayUrl": "jefftrull.github.io/c++/eigen/c<b>sparse</b>/suite<b>sparse</b>/2017/02/10/a-tour-of-<b>sparse</b>-matrices...", "snippet": "<b>Sparse</b> Matrix Libraries for C++: A Tour. Feb 10, 2017. In my last post I described my ideal <b>sparse</b> matrix <b>library</b>. In this post I\u2019ll demonstrate the use of some real life libraries. The Test Case. In days past I was a VLSI circuit designer, and later, an EDA software engineer. On-chip electrical circuits are naturally represented as <b>sparse</b> ...", "dateLastCrawled": "2022-02-03T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Review on <b>Sparse</b> Matrix Storage Formats With Space Complexity Analysis ...", "url": "https://www.igi-global.com/chapter/review-on-sparse-matrix-storage-formats-with-space-complexity-analysis/265582", "isFamilyFriendly": true, "displayUrl": "https://www.igi-global.com/chapter/review-on-<b>sparse</b>-matrix-storage-formats-with-space...", "snippet": "<b>Sparse</b> matrix-<b>vector</b> multiplication (SpMV) is a challenging computational kernel in linear algebra applications, <b>like</b> data mining, image processing, and machine learning. The performance of this kernel is greatly dependent on the size of the input matrix and the underlying hardware features. Various <b>sparse</b> matrix storage formats referred to commonly as <b>sparse</b> formats have been proposed in the literature to reduce the size of the matrix. In modern multi-core and many-core architectures, the ...", "dateLastCrawled": "2022-01-01T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Sparse</b> <b>Linear Algebra</b> \u2014 Scientific Computing with Python", "url": "https://caam37830.github.io/book/02_linear_algebra/sparse_linalg.html", "isFamilyFriendly": true, "displayUrl": "https://caam37830.github.io/<b>book</b>/02_<b>linear_algebra</b>/<b>sparse</b>_linalg.html", "snippet": "<b>Sparse</b> iterative methods are another class of methods you can use for solving linear systems built on Krylov subspaces. They only require matrix-<b>vector</b> products, and are ideally used with <b>sparse</b> matrices and fast linear operators. You can typically learn the theory behind these methods in a numerical <b>linear algebra</b> course - we\u2019ll just talk ...", "dateLastCrawled": "2022-02-01T19:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "gpu - Vectors, gather/scatter and <b>sparse</b> arrays - Stack Overflow", "url": "https://stackoverflow.com/questions/64877339/vectors-gather-scatter-and-sparse-arrays", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/64877339/<b>vectors</b>-gather-scatter-and-<b>sparse</b>-arrays", "snippet": "According to Computer Architecture: A Quantitative Approach, <b>vector</b> processors, both classic ones <b>like</b> Cray and modern ones <b>like</b> Nvidia, provide gather/scatter to improve performance on <b>sparse</b> arrays, where the array is in <b>sparse</b> form in memory and gathered to dense form in <b>vector</b> registers.. It seems to me if the array is so <b>sparse</b> \u2013 the density of nonzero elements so low \u2013 that it would be inefficient to represent it in dense form in memory, then it must also be inefficient to ...", "dateLastCrawled": "2022-01-11T13:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Gentle Introduction to <b>Sparse</b> Matrices for Machine Learning", "url": "https://machinelearningmastery.com/sparse-matrices-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>sparse</b>-matrices-for-machine-learning", "snippet": "An example of a smaller <b>sparse</b> matrix might be a word or term occurrence matrix for words in one <b>book</b> against all known words in English. ... It provides self-study tutorials on topics <b>like</b>: <b>Vector</b> Norms, Matrix Multiplication, Tensors, Eigendecomposition, SVD, PCA and much more... Finally Understand the Mathematics of Data . Skip the Academics. Just Results. See What&#39;s Inside. Tweet Tweet Share Share. More On This Topic. A Gentle Introduction to Activation Regularization\u2026 Introduction to ...", "dateLastCrawled": "2022-02-02T09:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>cuSPARSE</b> :: CUDA Toolkit Documentation", "url": "https://docs.nvidia.com/cuda/cusparse/index.html", "isFamilyFriendly": true, "displayUrl": "https://docs.nvidia.com/cuda/<b>cusparse</b>", "snippet": "The <b>cuSPARSE</b> <b>library</b> supports dense and <b>sparse</b> <b>vector</b>, and dense and <b>sparse</b> matrix formats. 3.1. Index Base Format. The <b>library</b> supports zero- and one-based indexing. The index base is selected through the cusparseIndexBase_t type, which is passed as a standalone parameter or as a field in the matrix descriptor cusparseMatDescr_t type. 3.1.1. <b>Vector</b> Formats. This section describes dense and <b>sparse</b> <b>vector</b> formats. 3.1.1.1. Dense Format. Dense vectors are represented with a single data array ...", "dateLastCrawled": "2022-02-03T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Introduction to Sparse Matrices in</b> R - Python and R Tips", "url": "https://cmdlinetips.com/2019/05/introduction-to-sparse-matrices-in-r/", "isFamilyFriendly": true, "displayUrl": "https://cmdlinetips.com/2019/05/<b>introduction-to-sparse-matrices-in</b>-r", "snippet": "Let us create a matrix with <b>sparse</b> data from scratch. We will first create data, a <b>vector</b> with million random numbers from normal distribution with zero mean and unit variance. data &lt;- rnorm(1e6) The above data <b>vector</b> is not <b>sparse</b> and contains data in all elements. Let us randomly select the indices and make them to contain zeroes. data &lt;- rnorm(1e6) zero_index &lt;- sample(1e6)[1:9e5] data[zero_index] &lt;- 0 Now we have created a <b>vector</b> of million elements, but 90% of the elements are zeros ...", "dateLastCrawled": "2022-01-28T12:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>An Introduction to SuanShu</b> | Baeldung", "url": "https://www.baeldung.com/suanshu", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/suanshu", "snippet": "The implementation of a dense <b>vector</b> simply uses a Java array of real/complex numbers while the implementation of a <b>sparse</b> <b>vector</b> uses a Java array of entries, where each entry has an index and a real/complex value.. We can see how that would make a huge difference in storage when we have a large <b>vector</b> where most values are zero. Most mathematical libraries use an approach <b>like</b> this when they need to support vectors of large sizes.", "dateLastCrawled": "2022-02-02T06:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse Matrix-Vector Multiplication</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/sparse-matrix-vector-multiplication", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>sparse-matrix-vector-multiplication</b>", "snippet": "<b>Sparse matrix-vector multiplication</b> (SpMV) is a fundamental computational kernel used in scientific and engineering applications. The nonzero elements of <b>sparse</b> matrices are represented in different formats, and a single <b>sparse</b> matrix representation is not suitable for all <b>sparse</b> matrices with different sparsity patterns. Extensive studies have been done on improving the performance of <b>sparse</b> matrices processing on different platforms. Graphics processing units (GPUs) are very well suited ...", "dateLastCrawled": "2022-01-28T06:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Plotting <b>Library</b> Catalog Subjects | Data Science Portfolio", "url": "https://sourestdeeds.github.io/blog/library-catalog-subject/", "isFamilyFriendly": true, "displayUrl": "https://sourestdeeds.github.io/blog/<b>library</b>-catalog-subject", "snippet": "Primarily I wanted to use the vectors to plot the <b>library</b> <b>book</b> subjects. I\u2019m curious if I\u2019d see a dimension representing the \u201cchildren\u2019s books - young adult - grown up\u201d, or if science subjects cluster together. Word vectors are also useful in Information Retrieval. With a <b>vector</b> representation, I can use math to measure how <b>similar</b> two subjects are. For example, if I\u2019m searching the catalog for \u201cFriendship Fiction\u201d, I wouldn\u2019t mind also seeing \u201cBest friends Fiction ...", "dateLastCrawled": "2022-01-29T17:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>cuSPARSE</b> :: CUDA Toolkit Documentation", "url": "https://docs.nvidia.com/cuda/cusparse/index.html", "isFamilyFriendly": true, "displayUrl": "https://docs.nvidia.com/cuda/<b>cusparse</b>", "snippet": "The <b>cuSPARSE</b> <b>library</b> supports dense and <b>sparse</b> <b>vector</b>, and dense and <b>sparse</b> matrix formats. 3.1. Index Base Format. The <b>library</b> supports zero- and one-based indexing. The index base is selected through the cusparseIndexBase_t type, which is passed as a standalone parameter or as a field in the matrix descriptor cusparseMatDescr_t type. 3.1.1. <b>Vector</b> Formats. This section describes dense and <b>sparse</b> <b>vector</b> formats. 3.1.1.1. Dense Format. Dense vectors are represented with a single data array ...", "dateLastCrawled": "2022-02-03T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Introduction to compressive sensing</b> \u2014 <b>sparse</b>-plex v2019.02", "url": "https://sparse-plex.readthedocs.io/en/latest/book/compressive_sensing/introduction.html", "isFamilyFriendly": true, "displayUrl": "https://<b>sparse</b>-plex.readthedocs.io/en/latest/<b>book</b>/compressive_sensing/introduction.html", "snippet": "If the \\(K\\)-column sub matrices of \\(\\Phi\\) are badly conditioned, then it is possible that some <b>sparse</b> signals get mapped to very <b>similar</b> measurement vectors. Thus it is numerically unstable to recover the signal. Moreover, if noise is present, stability further degrades. In Cand`es and Tao showed that the geometry of <b>sparse</b> signals should be preserved under the action of a sensing matrix. In particular the distance between two <b>sparse</b> signals shouldn\u2019t change by much during sensing.", "dateLastCrawled": "2022-02-02T09:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Sparse methods for direction-of-arrival estimation</b>", "url": "https://www.researchgate.net/publication/322186937_Sparse_methods_for_direction-of-arrival_estimation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/322186937_<b>Sparse_methods_for_direction-of</b>...", "snippet": "In compressed sensing, a <b>sparse</b> signal, represented by the <b>sparse</b> <b>vector</b> x, is recovered from undersampled linear measurements y , i.e., the system model (16) applies with M N . In this context, y", "dateLastCrawled": "2021-12-28T22:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "4. Text Vectorization and Transformation Pipelines - Applied Text ...", "url": "https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/<b>library</b>/view/applied-text-analysis/9781491963036/ch04.html", "snippet": "Moreover, the paragraph <b>vector</b> takes into consideration the ordering of words within a narrow context, <b>similar</b> to an n-gram model. The combined result is much more effective than a bag-of-words or bag-of- n -grams model because it generalizes better and has a lower dimensionality but still is of a fixed length so it can be used in common machine learning algorithms.", "dateLastCrawled": "2022-02-01T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>An Introduction to SuanShu</b> | Baeldung", "url": "https://www.baeldung.com/suanshu", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/suanshu", "snippet": "The implementation of a dense <b>vector</b> simply uses a Java array of real/complex numbers while the implementation of a <b>sparse</b> <b>vector</b> uses a Java array of entries, where each entry has an index and a real/complex value.. We can see how that would make a huge difference in storage when we have a large <b>vector</b> where most values are zero. Most mathematical libraries use an approach like this when they need to support vectors of large sizes.", "dateLastCrawled": "2022-02-02T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "cr-<b>sparse</b>/paper.md at master \u00b7 carnotresearch/cr-<b>sparse</b> \u00b7 GitHub", "url": "https://github.com/carnotresearch/cr-sparse/blob/master/paper/paper.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/carnotresearch/cr-<b>sparse</b>/blob/master/paper/paper.md", "snippet": "Summary. We introduce CR-<b>Sparse</b>, a Python <b>library</b> that enables efficiently solving a wide variety of <b>sparse</b> representation based signal processing problems.It is a cohesive collection of sub-libraries working together. Individual sub-libraries provide functionalities for: wavelets, linear operators, greedy and convex optimization based <b>sparse</b> recovery algorithms, subspace clustering, standard signal processing transforms, and linear algebra subroutines for solving <b>sparse</b> linear systems.", "dateLastCrawled": "2021-11-03T18:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Atom extraction and dictionary learning</b> | Machine Learning Algorithms", "url": "https://subscription.packtpub.com/book/big-data-and-business-intelligence/9781785889622/3/ch03lvl1sec27/atom-extraction-and-dictionary-learning", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/<b>book</b>/big-data-and-business-intelligence/...", "snippet": "<b>Atom extraction and dictionary learning</b>. Dictionary learning is a technique which allows rebuilding a sample starting from a <b>sparse</b> dictionary of atoms (<b>similar</b> to principal components). In Mairal J., Bach F., Ponce J., Sapiro G., Online Dictionary Learning for <b>Sparse</b> Coding, Proceedings of the 29th International Conference on Machine Learning ...", "dateLastCrawled": "2022-01-07T15:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "r - How to explicitly build <b>sparse</b> stringdistmatrix to avoid running ...", "url": "https://stackoverflow.com/questions/56727595/how-to-explicitly-build-sparse-stringdistmatrix-to-avoid-running-out-of-memory", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/56727595", "snippet": "Match large number of slightly varying restaurant names in &quot;data&quot; <b>vector</b> to appropriate &quot;match&quot; <b>vector</b>: The stringdistmatrix function in stringdist package is great, but runs out of memory for a few 10k x 10k and my data is larger.", "dateLastCrawled": "2022-01-08T09:48:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Gentle Introduction to <b>Sparse</b> Matrices for Machine Learning", "url": "https://machinelearningmastery.com/sparse-matrices-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>sparse</b>-matrices-for-machine-learning", "snippet": "A <b>sparse</b> matrix is a matrix that is comprised of mostly zero values. <b>Sparse</b> matrices are distinct from matrices with mostly non-zero values, which are referred to as dense matrices. A matrix is <b>sparse</b> if many of its coefficients are zero. The interest in sparsity arises because its exploitation <b>can</b> lead to enormous computational savings and ...", "dateLastCrawled": "2022-02-02T09:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Algebraic Geometry Review \u2014 <b>sparse</b>-plex v2019.02", "url": "https://sparse-plex.readthedocs.io/en/latest/book/geometry/algebraic_geometry.html", "isFamilyFriendly": true, "displayUrl": "https://<b>sparse</b>-plex.readthedocs.io/en/latest/<b>book</b>/geometry/algebraic_geometry.html", "snippet": "<b>sparse</b>-plex. Docs \u00bb Geometry \u00bb ... A data set being studied <b>can</b> <b>be thought</b> of as a collection of sample points from a geometrical object (e.g. a union of subspaces). The objective is to infer the said geometrical object from the given data set and decompose the object into simpler objects which help in better understanding of the data set. Polynomial Rings\u00b6 Let \\(\\FF^m\\) be \\(m\\)-dimensional <b>vector</b> space where \\(\\FF\\) is either \\(\\RR\\) or \\(\\CC\\) (a field of characteristic 0). For \\(x ...", "dateLastCrawled": "2021-12-10T22:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Doing Linear Algebra using Tensorflow 2</b> | Biswajit Sahoo", "url": "https://biswajitsahoo1111.github.io/post/doing-linear-algebra-using-tensorflow-2/", "isFamilyFriendly": true, "displayUrl": "https://biswajitsahoo1111.github.io/post/<b>doing-linear-algebra-using-tensorflow-2</b>", "snippet": "<b>Sparse</b> matrices are within tf.<b>sparse</b> <b>library</b>. There are several functions specifically designed for <b>sparse</b> matrices. Full list of function in tf.<b>sparse</b> <b>library</b> <b>can</b> be found at this link. In this section, we will see how <b>sparse</b> matrices are created. The first argument is set of indices (rows and columns), second argument is the values at those ...", "dateLastCrawled": "2022-02-01T20:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "optimization - Sum of product: <b>can</b> we vectorize the following in C++ ...", "url": "https://stackoverflow.com/questions/40345524/sum-of-product-can-we-vectorize-the-following-in-c-using-eigen-or-other-lib", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/40345524", "snippet": "I <b>thought</b> that with this additional information, I could already get a significant speed-up by doing the following: Remark: v contains duplicate values (a triplet (i,j,k) has 6 permutations, and the values of v for these 6 are the same). So I defined a more compact matrix uthat contains only non-duplicates of v. The indices of u are (i1,i2,i3) where i1 &lt; i2 &lt; i3. The length of u is equal to the length of v divided by 6. I computed the sum by iterating over the new value <b>vector</b> and the new ...", "dateLastCrawled": "2022-01-09T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Mahout</b> - SlideShare", "url": "https://www.slideshare.net/EdurekaIN/mahout-36625358", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/EdurekaIN/<b>mahout</b>-36625358", "snippet": "Vectors implementation in <b>Mahout</b> Dense <b>Vector</b> Sequential Access <b>Sparse</b> <b>Vector</b> Random Access <b>Sparse</b> <b>Vector</b> Vectors implementation in <b>Mahout</b> It <b>can</b> <b>be thought</b> of as an array of doubles, whose size is the number of features in the data. Because all the entries in the array are preallocated regardless of whether the value is 0 or not, we call it dense. It is implemented as a HashMap between an integer and a double, where only nonzero valued features are allocated. Hence, they\u2019re called as ...", "dateLastCrawled": "2022-02-03T03:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Sparse Coding in a Nutshell</b> | the Serious Computer Vision Blog", "url": "https://computervisionblog.wordpress.com/2014/05/24/sparse-coding-in-a-nutshell/", "isFamilyFriendly": true, "displayUrl": "https://computervisionblog.wordpress.com/2014/05/24/<b>sparse-coding-in-a-nutshell</b>", "snippet": "However, the community <b>thought</b> the Gabor like filters are some sort of edge detectors. This discovery leads to a series of work done on edge detection in the 80\u2019s when digital image processing became possible on computers. Edge detectors such as Canny, Harris, Sobel, Prewitt, etc are all based on the concept of detecting edges before recognizing objects. More recent algorithms such as Histogram of Oriented Gradient (HOG) are an extension of these edge detectors. An example of HOG is the ...", "dateLastCrawled": "2021-12-25T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Sparse autoencoder</b> - SlideShare", "url": "https://www.slideshare.net/DevashishPatel/sparse-autoencoder-95661509", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/DevashishPatel/<b>sparse-autoencoder</b>-95661509", "snippet": "Here, y <b>can</b> be <b>vector</b> valued. In the case of an autoencoder, y = x. (x(i) , y(i) ) The i-th training example hW,b(x) Output of our hypothesis on input x, using parameters W, b. This should be a <b>vector</b> of the same dimension as the target value y. W (l) ij The parameter associated with the connection between unit j in layer l, and unit i in layer l + 1. b (l) i The bias term associated with unit i in layer l + 1. <b>Can</b> also <b>be thought</b> of as the parameter associated with the connection between ...", "dateLastCrawled": "2022-01-08T07:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Sparse</b> Matrix Technology | Download Books PDF/ePub and Read Online", "url": "https://www.seecoalharbour.com/book/sparse-matrix-technology/", "isFamilyFriendly": true, "displayUrl": "https://www.seecoalharbour.com/<b>book</b>/<b>sparse</b>-matrix-technology", "snippet": "<b>Sparse</b> Matrix Technology. Download <b>Sparse</b> Matrix Technology <b>Book</b> For Free in PDF, EPUB. In order to read online <b>Sparse</b> Matrix Technology textbook, you need to create a FREE account. Read as many books as you like (Personal use) and Join Over 150.000 Happy Readers. We cannot guarantee that every <b>book</b> is in the <b>library</b>.", "dateLastCrawled": "2022-02-01T02:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to do matrix operations with this way of storing <b>sparse</b> matrices ...", "url": "https://scicomp.stackexchange.com/questions/27381/how-to-do-matrix-operations-with-this-way-of-storing-sparse-matrices", "isFamilyFriendly": true, "displayUrl": "https://scicomp.stackexchange.com/questions/27381/how-to-do-matrix-operations-with...", "snippet": "I read the way of storing the five or seven point laplace matrix for some poisson problem but I don&#39;t understand how <b>can</b> i multiply, add and subtract this stored <b>sparse</b> matrix by a <b>vector</b> or another . Stack Exchange Network. Stack Exchange network consists of 178 Q&amp;A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers. Visit Stack Exchange. Loading\u2026 0 +0; Tour Start here for a quick ...", "dateLastCrawled": "2022-01-16T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>how much memory</b> does <b>vector</b>&lt;bool&gt; take? - C / C++", "url": "https://bytes.com/topic/c/answers/493029-how-much-memory-does-vector-bool-take", "isFamilyFriendly": true, "displayUrl": "https://bytes.com/topic/c/answers/493029-<b>how-much-memory</b>-does-<b>vector</b>-bool-take", "snippet": "designing the C++ standard <b>library</b>. Technically, even though <b>vector</b>&lt;bool&gt; is mentioned in the Standard, its use is unspecified. Quoting from the second article: Curiously, <b>vector</b>&lt;bool&gt; is not actually specified, so no current use of it invokes well specified behavior. Its declaration appears in the standard, but not a single function is specified. Note that the argument &quot;it&#39;s just the same as <b>vector</b>&quot; fails because a <b>vector</b>&lt;bool&gt; is demonstrably not a <b>vector</b>: it has a different interface (i.e ...", "dateLastCrawled": "2022-01-06T00:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) A <b>library</b> for parallel <b>sparse</b> matrix-<b>vector</b> multiplies", "url": "https://www.researchgate.net/publication/228544585_A_library_for_parallel_sparse_matrix-vector_multiplies", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228544585_A_<b>library</b>_for_parallel_<b>sparse</b>...", "snippet": "Aztec is an iterative <b>library</b> that greatly simplifies the parallelization process when solving the linear systems of equations Ax = b where A is a user supplied n x n <b>sparse</b> matrix, b is a user ...", "dateLastCrawled": "2022-01-18T16:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Sparse Matrix-Vector Multiplication</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/sparse-matrix-vector-multiplication", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>sparse-matrix-vector-multiplication</b>", "snippet": "<b>Sparse matrix-vector multiplication</b> (SpMV) is a fundamental computational kernel used in scientific and engineering applications. The nonzero elements of <b>sparse</b> matrices are represented in different formats, and a single <b>sparse</b> matrix representation is not suitable for all <b>sparse</b> matrices with different sparsity patterns. Extensive studies have been done on improving the performance of <b>sparse</b> matrices processing on different platforms. Graphics processing units (GPUs) are very well suited ...", "dateLastCrawled": "2022-01-28T06:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Sparse</b> Matrix-<b>Vector</b> Multiplication on Multicore and Accelerators (<b>Book</b> ...", "url": "https://www.osti.gov/biblio/1407092-sparse-matrix-vector-multiplication-multicore-accelerators", "isFamilyFriendly": true, "displayUrl": "https://www.osti.gov/biblio/1407092-<b>sparse</b>-matrix-<b>vector</b>-multiplication-multicore...", "snippet": "OSTI.GOV <b>Book</b>: <b>Sparse</b> Matrix-<b>Vector</b> Multiplication on Multicore and Accelerators Title: <b>Sparse</b> Matrix-<b>Vector</b> Multiplication on Multicore and Accelerators Full Record", "dateLastCrawled": "2021-07-12T17:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Sparse</b> Linear Algebra vs Dense Linear Algebra - Computational Science ...", "url": "https://scicomp.stackexchange.com/questions/20043/sparse-linear-algebra-vs-dense-linear-algebra", "isFamilyFriendly": true, "displayUrl": "https://scicomp.stackexchange.com/questions/20043", "snippet": "$\\begingroup$ Also, how do you want to amortize the cost of setting up your <b>sparse</b> data structures? Are you going to setup a <b>sparse</b> matrix once and then do millions of <b>sparse</b> matrix-<b>vector</b> multiplications? Even after you&#39;ve specified the benchmark tasks, you&#39;ll still find that the results depend a lot on the particular computer that you use (e.g. number of processor cores and memory bandwidth) and on the particular implementations of the <b>sparse</b> blas and blas <b>library</b> routines that you use ...", "dateLastCrawled": "2022-02-02T22:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "ParseSVM: <b>A Simple C++ Library to read</b> LIBSVM files", "url": "https://www.cgudapati.com/sparsematrices/svm/machine-learning/2019/01/19/A-Simple-C++-Library-to-Parse-LIBSVM-files.html", "isFamilyFriendly": true, "displayUrl": "https://www.cgudapati.com/<b>sparse</b>matrices/svm/machine-learning/2019/01/19/A-Simple-C...", "snippet": "I followed the instructions in Tim Davis\u2019s excellent <b>book</b> Direct methods for <b>Sparse</b> Linear Systems to transpose a <b>sparse</b> matrix. The complete code <b>can</b> be found at my GitHub repository The code might not be very fast <b>compared</b> to an efficient implemenation in languages like C but I think it is decently fast.", "dateLastCrawled": "2022-01-23T08:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "matlab - <b>Sparse matrix and linear algebra with</b> c++ - Stack Overflow", "url": "https://stackoverflow.com/questions/31721720/sparse-matrix-and-linear-algebra-with-c", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/31721720", "snippet": "where A is a column <b>vector</b> of length 1000. W is a 1000*1000 <b>Sparse</b> matrix. Z is a 1000*30 Full matrix. y is a 30*1 <b>vector</b>. So i need good functions for: Padding matrix ; Cropping matrix; down-sampling matrix; Multiplying and Adding matrices and <b>Sparse</b> matrices. What specific <b>library</b> / functions would you recommend? keep in mind that i know very little C++ so please give URLs if needed. c++ matlab matrix <b>sparse</b>-matrix. Share. Improve this question. Follow asked Jul 30 &#39;15 at 10:48. alonhzn ...", "dateLastCrawled": "2022-01-17T00:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) FastSpMM: An efficient <b>library</b> for <b>sparse</b> matrix matrix product ...", "url": "https://www.researchgate.net/publication/236658267_FastSpMM_An_efficient_library_for_sparse_matrix_matrix_product_on_GPUs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/236658267_FastSpMM_An_efficient_<b>library</b>_for...", "snippet": "Algorithm 1 Pseudocode of SSFastSpMM to compute SpMM on GPUs. It computes the product C L c = AB L c where A is <b>sparse</b>. matrix of dimensions N \u00d7 M, B L c and C L c are dense matrices of ...", "dateLastCrawled": "2021-12-19T08:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Sparse</b> Solutions of Underdetermined Linear Systems and Their ...", "url": "https://epubs.siam.org/doi/book/10.1137/1.9781611976519", "isFamilyFriendly": true, "displayUrl": "https://epubs.siam.org/doi/<b>book</b>/10.1137/1.9781611976519", "snippet": "A linear system of equations consists of a known matrix A and a known <b>vector</b> b such that Ax = b for an unknown <b>vector</b> x, where A is of size m \u00d7 n.When m = n and m &gt; n, methods of solving for x are well known and are discussed in standard numerical analysis textbooks.However, when m &lt; n, Ax = b is called an underdetermined linear system.Such a linear system has become a subject of research in the last 15 years as part of an extremely active study in the community of compressive sensing.", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "linear algebra - <b>Sparse matrix-matrix multiplication using AVX2</b> ...", "url": "https://scicomp.stackexchange.com/questions/34713/sparse-matrix-matrix-multiplication-using-avx2", "isFamilyFriendly": true, "displayUrl": "https://scicomp.stackexchange.com/questions/34713/<b>sparse</b>-matrix-matrix-multiplication...", "snippet": "You generally don&#39;t gain much for <b>sparse</b> matrix-matrix and <b>sparse</b> matrix-<b>vector</b> products using things such as SSE/AVX/... if the matrices are large. That&#39;s because these instructions offer the ability to do some floating point operations in parallel -- but for large <b>sparse</b> matrices, you are limited by the time it takes to get data from memory onto the processors, not by the time it takes to actually do the computations. As a consequence, the way you actually implement the multiplication ...", "dateLastCrawled": "2022-01-23T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "references - <b>What is a sparse estimator</b>? - Cross Validated", "url": "https://stats.stackexchange.com/questions/44188/what-is-a-sparse-estimator", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/44188/<b>what-is-a-sparse-estimator</b>", "snippet": "In a two dimensional plane this <b>can</b> occur to y-axis which implies a solution of the form $\\hat{\\beta}=\\{0,\\hat{\\beta_y}\\}$, a kind of variable selection. I think the most extensive treatise of the <b>sparse</b> estimation methods is on the <b>book</b> &quot;Statistics for High Dimensional Data&quot; by Peter B\u00fchlmann.", "dateLastCrawled": "2022-01-24T13:24:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Gentle Introduction to Vectors for <b>Machine</b> <b>Learning</b>", "url": "https://machinelearningmastery.com/gentle-introduction-vectors-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>vectors</b>-<b>machine</b>-<b>learning</b>", "snippet": "It is common to introduce vectors using a geometric <b>analogy</b>, where a <b>vector</b> represents a point or coordinate in an n-dimensional space, where n is the number of dimensions, such as 2. The <b>vector</b> can also be thought of as a line from the origin of the <b>vector</b> space with a direction and a magnitude. These analogies are good as a starting point, but should not be held too tightly as we often consider very high dimensional vectors in <b>machine</b> <b>learning</b>. I find the <b>vector</b>-as-coordinate the most ...", "dateLastCrawled": "2022-02-01T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Word Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond king - man ...", "url": "https://aclanthology.org/C16-1332.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/C16-1332.pdf", "snippet": "Word Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond King - Man + Woman = Queen Aleksandr Drozd y, Anna Gladkova z, Satoshi Matsuoka y yTokyo Institute of Technology, Meguro-ku, Tokyo 152-8550, Japan alex@smg.is.titech.ac.jp, matsu@is.titech.ac.jp z The University of Tokyo, Meguro-ku, Tokyo 153-8902 Japan gladkova@phiz.c.u-tokyo.ac.jp Abstract Solving word analogies became one of the most popular benchmarks for word embeddings on the assumption that linear relations between word pairs ...", "dateLastCrawled": "2022-01-20T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Introduction to Matrices and Matrix Arithmetic for <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/introduction-matrices-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/introduction-matrices-<b>machine-learning</b>", "snippet": "The geometric <b>analogy</b> used to help understand vectors and some of their operations does not hold with matrices. Further, a <b>vector</b> itself may be considered a matrix with one column and multiple rows. Often the dimensions of the matrix are denoted as m and n for the number of rows and the number of columns. Now that we know what a matrix is, let\u2019s look at defining one in Python. Defining a Matrix. We can represent a matrix in Python using a two-dimensional NumPy array. A NumPy array can be ...", "dateLastCrawled": "2022-02-02T11:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning :: Cosine Similarity for Vector</b> Space Models (Part III ...", "url": "https://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/", "isFamilyFriendly": true, "displayUrl": "https://blog.christianperone.com/2013/09/<b>machine</b>-<b>learning</b>-", "snippet": "<b>Machine Learning :: Cosine Similarity for Vector</b> Space Models (Part III) 12/09/2013 19/01/2020 Christian S. Perone <b>Machine</b> <b>Learning</b> , Programming , Python * It has been a long time since I wrote the TF-IDF tutorial ( Part I and Part II ) and as I promissed, here is the continuation of the tutorial.", "dateLastCrawled": "2022-01-29T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Word Embedding: Syntactics or Semantics</b> \u00b7 Shengbin&#39;s Studio", "url": "https://wushbin.github.io/2017/10/09/Word-Embedding-Syntactics-or-Semantics/", "isFamilyFriendly": true, "displayUrl": "https://wushbin.github.io/2017/10/09/<b>Word-Embedding-Syntactics-or-Semantics</b>", "snippet": "From all the result of the two method, we know that the dense <b>vector</b> method get a better result than the <b>sparse</b> PPMI method in <b>analogy</b> analysis and similar word search. In addition, the computational efficiency of the dense <b>vector</b> is also better than the PPMI. Short vectors may be easier to use as features in <b>machine</b> <b>learning</b>. Dense vectors may generalize better than storing explicit counts. In addition, dense vectors may perform better in capturing synonymy than <b>sparse</b> vectors.", "dateLastCrawled": "2022-01-09T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Word Embeddings in NLP - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/word-embeddings-in-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/word-embeddings-in-nlp", "snippet": "Word Embeddings are a method of extracting features out of text so that we can input those features into a <b>machine</b> <b>learning</b> model to work with text data. They try to preserve syntactical and semantic information. The methods such as Bag of Words(BOW), CountVectorizer and TFIDF rely on the word count in a sentence but do not save any syntactical or semantic information. In these algorithms, the size of the <b>vector</b> is the number of elements in the vocabulary. We can get a <b>sparse</b> matrix if most ...", "dateLastCrawled": "2022-01-30T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the difference between a <b>Vector</b> and a Tensor in <b>Machine</b> <b>Learning</b>?", "url": "https://www.quora.com/What-is-the-difference-between-a-Vector-and-a-Tensor-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-a-<b>Vector</b>-and-a-Tensor-in-<b>Machine</b>...", "snippet": "Answer (1 of 2): A <b>vector</b> is a tensor of rank 1, a matrix is a tensor of rank 2. For a tensor with more than 2 dimensions, we refer to it as a tensor. Note that, rank of a matrix [1] from linear algebra is not the same as tensor rank [2] 1. Rank (linear algebra) - Wikipedia 2. Tensor - Wikipedia", "dateLastCrawled": "2022-01-13T06:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(sparse vector)  is like +(library book)", "+(sparse vector) is similar to +(library book)", "+(sparse vector) can be thought of as +(library book)", "+(sparse vector) can be compared to +(library book)", "machine learning +(sparse vector AND analogy)", "machine learning +(\"sparse vector is like\")", "machine learning +(\"sparse vector is similar\")", "machine learning +(\"just as sparse vector\")", "machine learning +(\"sparse vector can be thought of as\")", "machine learning +(\"sparse vector can be compared to\")"]}