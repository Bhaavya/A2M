{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of model <b>interpretability</b> and how it relates to interpretable and explainable machine learning. To summarise, <b>interpretability</b> is the degree to which a model can be understood ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "<b>Interpretability</b> is difficult to define because models can be easy to <b>understand</b> in some aspects but not in others. The desired aspects in particular cases may also often be domain- or problem-specific, and while many papers have claimed interpretable models in various domains or applications, the machine learning community lacks a unifying framework for discussing what properties make a model interpretable and what we hope to do with interpretable results. Lipton (2016) presents such a ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "<b>Interpretability</b> has to do with how accurate a machine learning model can associate a cause to an effect. Explainability has to do with the ability of the parameters, often hidden in Deep Nets, to justify the results. This is a long article. Hang in there and, by the end, you will <b>understand</b>: How <b>interpretability</b> is different from explainability.", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretability</b> Models with Hermione | by Gustavo Resende | A3data ...", "url": "https://medium.com/a3data/interpretability-models-with-hermione-6f02e1bb4e43", "isFamilyFriendly": true, "displayUrl": "https://medium.com/a3data/<b>interpretability</b>-models-with-hermione-6f02e1bb4e43", "snippet": "<b>Interpretability</b> Models with Hermione. Hermione is an open-source library released in 2020 that helps Data Scientists on setting up more organized codes, quickly and simply. Besides, there are ...", "dateLastCrawled": "2021-12-30T16:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Understanding the difference between <b>interpretability</b> and ...", "url": "https://subscription.packtpub.com/book/data/9781800203907/2/ch02lvl1sec05/understanding-the-difference-between-interpretability-and-explainability", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/<b>book</b>/data/9781800203907/2/ch02lvl1sec05/...", "snippet": "Design transparency: <b>Being</b> <b>able</b> to explain choices made, such as model architecture and hyperparameters. For instance, we could justify these choices based on the size or nature of the training data. If we were performing a sales forecast and we knew that our sales had a seasonality of 12 months, this could be a sound parameter choice. If we had doubts, we could always use some well-established statistical method to find the right seasonality.", "dateLastCrawled": "2021-12-29T16:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What everyone <b>needs to know about interpretability in machine learning</b> ...", "url": "https://dallascard.medium.com/what-everyone-needs-to-know-about-interpretability-in-machine-learning-d5ce16730407", "isFamilyFriendly": true, "displayUrl": "https://dallascard.medium.com/what-everyone-<b>needs-to-know-about-interpretability</b>-in...", "snippet": "This means that it is much easier for humans to feel <b>like</b> they <b>understand</b> how the model is making predictions. An even simpler case is a decision list, which takes the form of a series of yes/no question. Although such a model has a simple interpretation that is easy for us as humans to process and describe in words, it is the same as any other model in that it takes a set of numbers (a set of 1s and 0s for yes and no), and returns another number as a prediction. For any machine learning ...", "dateLastCrawled": "2022-01-12T04:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Understanding model predictions with <b>LIME</b> | by Lars Hulstaert | Towards ...", "url": "https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>understand</b>ing-model-predictions-with-<b>lime</b>-a582fdff3a3b", "snippet": "Why is it necessary to <b>understand</b> <b>interpretability</b> methods? If you trust a technique with explaining the predictions of your model, it is important to <b>understand</b> the underlying mechanics of that technique, and any potential pitfalls associated with it. <b>Interpretability</b> techniques are not fault proof, and without a good understanding of the method, you are very likely to base your assumptions on falsehoods. A similar but significantly more thorough investigation was done in the following blog ...", "dateLastCrawled": "2022-02-03T00:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>How important is interpretability for a</b> model in Machine Learning? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-model-in-Machine-Learning", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Chapter 6 Model-<b>Agnostic</b> Methods | Interpretable Machine Learning", "url": "https://christophm.github.io/interpretable-ml-book/agnostic.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpret<b>able</b>-ml-<b>book</b>/<b>agnostic</b>.html", "snippet": "But overall it is a useful abstraction to <b>understand</b> how <b>interpretability</b> becomes this new layer on top of machine learning models. Model-<b>agnostic</b> interpretation methods can be further distinguished into local and global methods. The <b>book</b> is also organized according to this distinction.", "dateLastCrawled": "2022-02-02T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Interpreting an NLP model with LIME and SHAP | by Kalia Barkai | Medium", "url": "https://medium.com/@kalia_65609/interpreting-an-nlp-model-with-lime-and-shap-834ccfa124e4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@kalia_65609/interpreting-an-nlp-model-with-lime-and-shap-834ccfa124e4", "snippet": "Interpreting an NLP model with LIME and SHAP. Kalia Barkai. Mar 9, 2020 \u00b7 16 min <b>read</b>. In this tutorial, I will provide a brief overview of model <b>interpretability</b> and how it can be used to ...", "dateLastCrawled": "2022-01-28T21:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "A model that provided <b>similar</b> explanations would be more useful than one that just provided predictions. ... we\u2019ll explain in more detail what is meant by <b>interpretability</b>. We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "<b>Interpretability</b> has to do with how accurate a machine learning model can associate a cause to an effect. Explainability has to do with the ability of the parameters, often hidden in Deep Nets, to justify the results. This is a long article. Hang in there and, by the end, you will <b>understand</b>: How <b>interpretability</b> is different from explainability.", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "<b>Interpretability</b> is difficult to define because models can be easy to <b>understand</b> in some aspects but not in others. The desired aspects in particular cases may also often be domain- or problem-specific, and while many papers have claimed interpretable models in various domains or applications, the machine learning community lacks a unifying framework for discussing what properties make a model interpretable and what we hope to do with interpretable results. Lipton (2016) presents such a ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Model <b>Interpretability</b>. With the advancement in Machine\u2026 | by Sumedh ...", "url": "https://smdhtelang2.medium.com/model-interpretability-da57f807c42a", "isFamilyFriendly": true, "displayUrl": "https://smdhtelang2.medium.com/model-<b>interpretability</b>-da57f807c42a", "snippet": "Model <b>Interpretability</b>. With the advancement in Machine Learning where machine learning is <b>able</b> to solve the most complex problems in the world highly accurately, the need to <b>understand</b> the complexity of the black-box model working is increasing every day. In this article, I will be shedding light on some of the model agnostic methods like SHAP ...", "dateLastCrawled": "2022-01-21T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretability Analysis for Named Entity</b> Recognition to <b>Understand</b> ...", "url": "https://direct.mit.edu/coli/article/47/1/117/97335/Interpretability-Analysis-for-Named-Entity", "isFamilyFriendly": true, "displayUrl": "https://direct.mit.edu/coli/article/47/1/117/97335/<b>Interpretability</b>-Analysis-for-Named...", "snippet": "To <b>understand</b> the performance of NER systems, we should be <b>able</b> to probe the justification for the predictions: Did they recognize a context that strongly indicates that whatever follows is a name of a given type (as in \u201cCzech Vice-PM _\u201d), or did they recognize a word that is typically a name of a given type (\u201cJane\u201d), or a combination of the two? In this article, we present experiments designed to disentangle to the extent possible the contribution of the two sources of confidence in ...", "dateLastCrawled": "2022-01-06T20:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>How important is interpretability for a</b> model in Machine Learning? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-model-in-Machine-Learning", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Interpretability</b> in the medical field: A systematic mapping and review ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "snippet": "<b>Interpretability</b> can be defined as the degree to which a human can <b>understand</b> the cause of a decision ... <b>Book</b> regrouping papers published at three different conferences were selected from the reference scan. After discussion, the authors agreed to scan each conference paper and include those that satisfied the selection criteria. The study selection took approximately 4 months. Table 4. QA questions. Id Question Possible answers; QA1: The study presents empirical evidence (about ...", "dateLastCrawled": "2022-01-23T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Chapter 16 Interpretable Machine Learning</b> | Hands-On Machine Learning ...", "url": "https://bradleyboehmke.github.io/HOML/iml.html", "isFamilyFriendly": true, "displayUrl": "https://bradleyboehmke.github.io/HOML/iml.html", "snippet": "<b>Being</b> <b>able</b> to answer such questions and provide both levels of explanation is key to any ML project becoming accepted, adopted, embedded, and properly utilized. 16.2.1 Global interpretation. Global <b>interpretability</b> is about understanding how the model makes predictions, based on a holistic view of its features and how they influence the underlying model structure. It answers questions regarding which features are relatively influential, how these features influence the response variable, and ...", "dateLastCrawled": "2022-02-01T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Understanding model predictions with <b>LIME</b> | by Lars Hulstaert | Towards ...", "url": "https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>understand</b>ing-model-predictions-with-<b>lime</b>-a582fdff3a3b", "snippet": "Why is it necessary to <b>understand</b> <b>interpretability</b> methods? If you trust a technique with explaining the predictions of your model, it is important to <b>understand</b> the underlying mechanics of that technique, and any potential pitfalls associated with it. <b>Interpretability</b> techniques are not fault proof, and without a good understanding of the method, you are very likely to base your assumptions on falsehoods. A <b>similar</b> but significantly more thorough investigation was done in the following blog ...", "dateLastCrawled": "2022-02-03T00:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "GitHub - jyshtty/Data-Science-and-ML-Preparations", "url": "https://github.com/jyshtty/Data-Science-and-ML-Preparations", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/jyshtty/Data-Science-and-ML-Preparations", "snippet": "Literature Review(must for Research based roles) : <b>Being</b> <b>able</b> <b>to read</b> <b>and understand</b> a new research paper is one of the most essential and demanding skills needed in the industry today, as the culture of Research and Development, and innovation grows across most good organizations. Communication Skills - <b>Being</b> <b>able</b> to explain the analysis and results to business stakeholders and executives is becoming a really important skill for Data Scientists these days; Some Engineering knowledge(Not ...", "dateLastCrawled": "2022-01-23T20:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of model <b>interpretability</b> and how it relates to interpretable and explainable machine learning. To summarise, <b>interpretability</b> is the degree to which a model <b>can</b> be understood ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "<b>Interpretability</b> has to do with how accurate a machine learning model <b>can</b> associate a cause to an effect. Explainability has to do with the ability of the parameters, often hidden in Deep Nets, to justify the results. This is a long article. Hang in there and, by the end, you will <b>understand</b>: How <b>interpretability</b> is different from explainability.", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "<b>Interpretability</b> is difficult to define because models <b>can</b> be easy to <b>understand</b> in some aspects but not in others. The desired aspects in particular cases may also often be domain- or problem-specific, and while many papers have claimed interpretable models in various domains or applications, the machine learning community lacks a unifying framework for discussing what properties make a model interpretable and what we hope to do with interpretable results. Lipton (2016) presents such a ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What everyone <b>needs to know about interpretability in machine learning</b> ...", "url": "https://dallascard.medium.com/what-everyone-needs-to-know-about-interpretability-in-machine-learning-d5ce16730407", "isFamilyFriendly": true, "displayUrl": "https://dallascard.medium.com/what-everyone-<b>needs-to-know-about-interpretability</b>-in...", "snippet": "However, given how much confusion seems to be taking place, I <b>thought</b> it would be useful to outline a few essential ideas that everyone should know about this area. 1. Machine learning systems make predictions based on a set of input features (i.e. a bunch of numbers). This point is in some sense so obvious that it\u2019s rarely discussed, but it is actually quite important. Although machine learning is <b>being</b> used for all kinds of data, including images, videos, and natural language, the first ...", "dateLastCrawled": "2022-01-12T04:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>How important is interpretability for a</b> model in Machine Learning? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-model-in-Machine-Learning", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Against <b>Interpretability</b>: a Critical Examination of the ...", "url": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "snippet": "<b>Interpretability</b> is often <b>thought</b> to play an important role in justification in an ML context. It <b>can</b> seem outright irresponsible to believe algorithmic outputs regarding unseen real-world data in the absence of detailed knowledge of the algorithm\u2019s inner workings. However, in some contexts, there are ways of achieving the desired assurance in the absence of knowledge about inner workings of tools. People were both responsible and justified in relying on the deliverances of their eyes ...", "dateLastCrawled": "2021-12-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How important is <b>interpretability</b> for a model in Machine Learning ...", "url": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-<b>interpretability</b>-for...", "snippet": "It <b>can</b> be even used by systems without operating system, example <b>being</b> compiled and fabricated as a neuromorphic chip (Qualc Continue Reading After the long training on a powerful computer, you <b>can</b> export the model (set of already trained weights for all neurons + description of the topology network) to a lightweights executable eg. using our library TensorRT.", "dateLastCrawled": "2022-01-10T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Model Interpretability for Predicting Wine Prices</b> | by Rachel Woods ...", "url": "https://medium.com/the-wine-nerd/model-interpretability-for-predicting-wine-prices-ddd40766ce2b", "isFamilyFriendly": true, "displayUrl": "https://medium.com/the-wine-nerd/<b>model-interpretability-for-predicting-wine-prices</b>-ddd...", "snippet": "Methods used to <b>understand</b> depend on applications and end goals. Beyond the importance of model <b>interpretability</b> in general, there is also value in applying multiple methods and comparing outputs ...", "dateLastCrawled": "2022-02-02T19:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Explain Your Model with the <b>SHAP</b> Values | by Dr. Dataman | Towards Data ...", "url": "https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/explain-your-model-with-the-<b>shap</b>-values-bc36aac4de3d", "snippet": "The first one is global <b>interpretability</b> \u2014 the collective <b>SHAP</b> values <b>can</b> show how much each predictor contributes, either positively or negatively, to the target variable. This is like the variable importance plot but it is <b>able</b> to show the positive or negative relationship for each variable with the target (see the <b>SHAP</b> value plot below).", "dateLastCrawled": "2022-02-02T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What makes <b>interpretability</b> in neural networks difficult? - Quora", "url": "https://www.quora.com/What-makes-interpretability-in-neural-networks-difficult", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-makes-<b>interpretability</b>-in-neural-networks-difficult", "snippet": "Answer (1 of 2): The ultimate goal of machine learning (or statistics), many would argue, is to build insight into some phenomenon. Thus far, the ML community has largely been obsessed with predictive accuracy. If you <b>read</b> the many papers in different subfields of ML at leading conferences, like ...", "dateLastCrawled": "2022-01-13T06:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "<b>Interpretability</b> has to do with how accurate a machine learning model <b>can</b> associate a cause to an effect. Explainability has to do with the ability of the parameters, often hidden in Deep Nets, to justify the results. This is a long article. Hang in there and, by the end, you will <b>understand</b>: How <b>interpretability</b> is different from explainability.", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "<b>Interpretability</b> is difficult to define because models <b>can</b> be easy to <b>understand</b> in some aspects but not in others. The desired aspects in particular cases may also often be domain- or problem-specific, and while many papers have claimed interpretable models in various domains or applications, the machine learning community lacks a unifying framework for discussing what properties make a model interpretable and what we hope to do with interpretable results. Lipton (2016) presents such a ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Comparison and improvement of the predictability and <b>interpretability</b> ...", "url": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0417-9", "isFamilyFriendly": true, "displayUrl": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0417-9", "snippet": "Ensemble learning helps improve machine learning results by combining several models and allows the production of better predictive performance <b>compared</b> to a single model. It also benefits and accelerates the researches in quantitative structure\u2013activity relationship (QSAR) and quantitative structure\u2013property relationship (QSPR). With the growing number of ensemble learning models such as random forest, the effectiveness of QSAR/QSPR will be limited by the machine\u2019s inability to ...", "dateLastCrawled": "2022-02-01T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretability Analysis for Named Entity</b> Recognition to <b>Understand</b> ...", "url": "https://direct.mit.edu/coli/article/47/1/117/97335/Interpretability-Analysis-for-Named-Entity", "isFamilyFriendly": true, "displayUrl": "https://direct.mit.edu/coli/article/47/1/117/97335/<b>Interpretability</b>-Analysis-for-Named...", "snippet": "<b>Interpretability Analysis for Named Entity Recognition to Understand System Predictions</b> and How They <b>Can</b> Improve Oshin ... A system should be <b>able</b> to recognize any named entity in a predictive context correctly and our experiments indicate that current systems may be improved by such capability. Our human study also revealed that systems and humans do not always learn the same contextual clues, and context-only systems are sometimes correct even when humans fail to recognize the entity type ...", "dateLastCrawled": "2022-01-06T20:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretability</b> in the medical field: A systematic mapping and review ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "snippet": "<b>Interpretability</b> <b>can</b> be defined as the degree to which a human <b>can</b> <b>understand</b> the cause of a decision ... which <b>can</b> be explained by the fact that the results <b>can</b> <b>be compared</b> with other techniques evaluated on the same datasets and the availability of public datasets in the medical domain. Additionally, it is preferred to evaluate and interpret ML models on historical data before using real-time evaluation. 23% of the qualified studies were empirically evaluated using case study methods that ...", "dateLastCrawled": "2022-01-23T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Improving the accuracy while preserving the <b>interpretability</b> of ...", "url": "https://www.academia.edu/70829354/Improving_the_accuracy_while_preserving_the_interpretability_of_fuzzy_function_approximators_by_means_of_multi_objective_evolutionary_algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/70829354/Improving_the_accuracy_while_preserving_the...", "snippet": "Fuzzy systems provide an attractive alternative to the \u2018\u2018black boxes\u2019\u2019 characteristic of neural network models, because their behavior <b>can</b> be easily explained by a human <b>being</b>. In fact, the popularity and practicality of fuzzy systems derives from their ability to express relations that are either complex or not su\ufb03ciently understood, in terms of linguistic rules. Although one of the most widely used approaches for the design of a fuzzy system is the use of a complete table of ...", "dateLastCrawled": "2022-02-07T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Evaluation of <b>interpretability</b> methods for multivariate time series ...", "url": "https://link.springer.com/article/10.1007/s10489-021-02662-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10489-021-02662-2", "snippet": "<b>Being</b> <b>able</b> to interpret a model\u2019s predictions is a crucial task in many machine learning applications. Specifically, local <b>interpretability</b> is important in determining why a model makes particular predictions. Despite the recent focus on interpretable Artificial Intelligence (AI), there have been few studies on local <b>interpretability</b> methods for time series forecasting, while existing approaches mainly focus on time series classification tasks. In this study, we propose two novel ...", "dateLastCrawled": "2022-02-03T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Chapter 16 Interpretable Machine Learning</b> | Hands-On Machine Learning ...", "url": "https://bradleyboehmke.github.io/HOML/iml.html", "isFamilyFriendly": true, "displayUrl": "https://bradleyboehmke.github.io/HOML/iml.html", "snippet": "<b>Being</b> <b>able</b> to answer such questions and provide both levels of explanation is key to any ML project becoming accepted, adopted, embedded, and properly utilized. 16.2.1 Global interpretation. Global <b>interpretability</b> is about understanding how the model makes predictions, based on a holistic view of its features and how they influence the underlying model structure. It answers questions regarding which features are relatively influential, how these features influence the response variable, and ...", "dateLastCrawled": "2022-02-01T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Chapter 6 Model-<b>Agnostic</b> Methods | Interpretable Machine Learning", "url": "https://christophm.github.io/interpretable-ml-book/agnostic.html", "isFamilyFriendly": true, "displayUrl": "https://christophm.github.io/interpret<b>able</b>-ml-<b>book</b>/<b>agnostic</b>.html", "snippet": "But overall it is a useful abstraction to <b>understand</b> how <b>interpretability</b> becomes this new layer on top of machine learning models. Model-<b>agnostic</b> interpretation methods <b>can</b> be further distinguished into local and global methods. The <b>book</b> is also organized according to this distinction.", "dateLastCrawled": "2022-02-02T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Understanding model predictions with <b>LIME</b> | by Lars Hulstaert | Towards ...", "url": "https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>understand</b>ing-model-predictions-with-<b>lime</b>-a582fdff3a3b", "snippet": "Why is it necessary to <b>understand</b> <b>interpretability</b> methods? If you trust a technique with explaining the predictions of your model, it is important to <b>understand</b> the underlying mechanics of that technique, and any potential pitfalls associated with it. <b>Interpretability</b> techniques are not fault proof, and without a good understanding of the method, you are very likely to base your assumptions on falsehoods. A similar but significantly more thorough investigation was done in the following blog ...", "dateLastCrawled": "2022-02-03T00:26:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "snippet": "This provides a novel <b>analogy</b> between data compression and regularization. Qualitative and quantitative state-of-the-art results on three datasets. 20 / 33. Interpretable Lens Variable Model (ILVM) 21 / 33. Interactive <b>Interpretability</b> via Active <b>Learning</b> Interactive \u2018human-in-the-loop\u2019 <b>interpretability</b> Choose the point with index j that maximizes : ^j = argmax jI(s ; ) = H(s ) E q \u02da(z js)[H(s jz j)] = Z p(s j)log p(s j)ds + E q \u02da(z js) Z p (s jjz)log p (s jjz)ds : (5) Choose the point ...", "dateLastCrawled": "2022-01-19T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "There is increasing emphasis on interpretable <b>machine</b> <b>learning</b> in the world of data. Models have been growing ever more complex with the use of neural networks becoming more mainstream, along with the sheer size of data being analysed today. In many cases, such complex models may not be fit for human interpretation in their own right. Therefore, there has been a push to make the model interpretable, whereby both the results and the process in achieving those results are understood by humans ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Figure 1: <b>Interpretability</b> for <b>machine</b> <b>learning</b> models bridges the concrete objectives models optimize for and the real-world (and less easy to define) desiderata that ML applications aim to achieve. Introduction . The objectives <b>machine</b> <b>learning</b> models optimize for do not always reflect the actual desiderata of the task at hand. <b>Interpretability</b> in models allows us to evaluate their decisions and obtain information that the objective alone cannot confer. <b>Interpretability</b> takes many forms ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Economic Methodology Meets Interpretable Machine Learning</b> - Part I ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. Intro - Part ...", "dateLastCrawled": "2022-01-22T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-16T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://arxiv.org/abs/2005.12800", "isFamilyFriendly": true, "displayUrl": "https://<b>arxiv</b>.org/abs/2005.12800", "snippet": "Principles of analogical reasoning have recently been applied in the context of <b>machine</b> <b>learning</b>, for example to develop new methods for classification and preference <b>learning</b>. In this paper, we argue that, while analogical reasoning is certainly useful for constructing new <b>learning</b> algorithms with high predictive accuracy, is is arguably not less interesting from an <b>interpretability</b> and explainability point of view. More specifically, we take the view that an <b>analogy</b>-based approach is a ...", "dateLastCrawled": "2021-10-24T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Economic Methodology Meets Interpretable <b>Machine</b> <b>Learning</b> ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. But first ...", "dateLastCrawled": "2022-01-05T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>SHAP</b>: A reliable way to analyze model <b>interpretability</b> | by Sharayu ...", "url": "https://towardsdatascience.com/shap-a-reliable-way-to-analyze-your-model-interpretability-874294d30af6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>shap</b>-a-reliable-way-to-analyze-your-model...", "snippet": "The balance: Accuracy vs. <b>Interpretability</b>. 2. How to interpret <b>machine</b> <b>learning</b> models? 3. LIME: Explaining predictions of <b>machine</b> <b>learning</b> models. In this blog, I wil l be talking about one of the most popular model agnostic technique that is used to explain predictions. <b>SHAP</b> stands for SHapley Additive exPlanations. Shapely values are obtained by incorporating concepts from Cooperative Game Theory and local explanations. Given a set of palyers, Cooperative Game Theory defines how well and ...", "dateLastCrawled": "2022-01-31T17:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "Neuroscience \u2194 <b>Interpretability</b>. <b>Analogy</b>: model=brain. Artificial neural networks are historically inspired by neuroscience, but I used to be pretty skeptical that the connection was anything more than superficial. I&#39;ve since come around: I now think this is a very deep connection. The thing that personally persuaded me was that, in my own investigations of what goes on inside neural networks, we kept finding things that were previously discovered by neuroscientists. The most recent ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chris Olah on what the hell is going on inside neural networks - 80,000 ...", "url": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/", "isFamilyFriendly": true, "displayUrl": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research", "snippet": "Chris is a <b>machine</b> <b>learning</b> researcher currently focused on neural network interpretability. Until last December he led OpenAI\u2019s interpretability team but along with some colleagues he recently moved on to help start a new AI lab focussed on large models and safety called Anthropic. Rob Wiblin: Before OpenAI he spent 4 years at Google Brain developing tools to visualize what\u2019s going on in neural networks. Chris was hugely impactful at Google Brain. He was second author on the launch of ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Marketing AI: Interpretability and Explainability</b> - Christopher S. Penn ...", "url": "https://www.christopherspenn.com/2021/03/marketing-ai-interpretability-and-explainability/", "isFamilyFriendly": true, "displayUrl": "https://www.christopherspenn.com/2021/03/<b>marketing-ai-interpretability-and-explainability</b>", "snippet": "<b>Interpretability is like</b> inspecting the baker\u2019s recipe for the cake. We look at the list of ingredients and the steps taken to bake the cake, and we verify that the recipe makes sense and the ingredients were good. This is a much more rigorous way of validating our results, but it\u2019s the most complete \u2013 and if we\u2019re in a high-stakes situation where we need to remove all doubt, this is the approach we take. Interpretability in AI is like that \u2013 we step through the code itself that ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Causal <b>Learning</b> From Predictive Modeling for Observational Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931928/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7931928", "snippet": "Given the recent success of <b>machine</b> <b>learning</b>, specifically deep <b>learning</b>, in several applications (Goodfellow et al., ... This statistical <b>interpretability is similar</b> in spirit to traditional interpretability. This allows to answer questions, such as \u201cdoes BMI influence susceptibility to Covid?\u201d Moreover, it has been argued that developing an effective CBN for practical applications requires expert knowledge when data collection is cumbersome (Fenton and Neil, 2012). This applies to ...", "dateLastCrawled": "2021-12-09T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimal <b>Predictive Clustering</b> - Dimitris Bertsimas", "url": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-predictive-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-<b>predictive-clustering</b>.pdf", "snippet": "Table 1 Comparison of major <b>machine</b> <b>learning</b> methods relative to each other across the metrics of performance (out-of-sample R2), scalability and interpretability. 1 is the best, while 5 is the worst. Optimal <b>Predictive Clustering</b> 3 From Table 1, we observe all existing methods have weakness in at least one category. We therefore seek to design a method that has strong performance in all three categories at the same time. Optimal <b>Predictive Clustering</b> (OPC) is an algorithm that uses mixed ...", "dateLastCrawled": "2021-11-24T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reviewing Challenges of Predicting Protein Melting Temperature Change ...", "url": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "snippet": "Predicting the effects of mutations on protein stability is a key problem in fundamental and applied biology, still unsolved even for the relatively simple case of small, soluble, globular, monomeric, two-state-folder proteins. Many articles discuss the limitations of prediction methods and of the datasets used to train them, which result in low reliability for actual applications despite globally capturing trends. Here, we review these and other issues by analyzing one of the most detailed ...", "dateLastCrawled": "2022-02-03T02:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "In my view, a shor t coming of interpretable <b>machine</b> <b>learning</b> is that it assumes to a degree that the data being fed into the model is always going to be suitable for human interpretation. This is not necessarily the case. For instance, let\u2019s say that a company is trying to implement interpretable <b>machine</b> <b>learning</b> to devise a credit scoring model, whereby prospective credit card applications are classified as approved or rejected based on numerous features. It is often the case that such ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Breaking the interpretability barrier - a</b> method for interpreting deep ...", "url": "http://www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "isFamilyFriendly": true, "displayUrl": "www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o between performance and inter-pretability. Graph classi cation is normally a domain which requires the ap-plication of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to in-terpret complex models post-hoc (brie y reviewed in section2). However, most ...", "dateLastCrawled": "2021-09-22T17:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Discovering Discriminative Nodes for Classi\ufb01cation with Deep Graph ...", "url": "http://muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "isFamilyFriendly": true, "displayUrl": "muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o\ufb00 between performance and inter-pretability. Graph classi\ufb01cation is normally a domain which requires the appli-cation of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to interpret complex models post-hoc (brie\ufb02y reviewed in Sect.2). However ...", "dateLastCrawled": "2021-09-02T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Confronting Abusive Language Online: A Survey from the Ethical and ...", "url": "https://www.arxiv-vanity.com/papers/2012.12305/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2012.12305", "snippet": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this ...", "dateLastCrawled": "2021-10-13T19:21:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(interpretability)  is like +(being able to read and understand a book)", "+(interpretability) is similar to +(being able to read and understand a book)", "+(interpretability) can be thought of as +(being able to read and understand a book)", "+(interpretability) can be compared to +(being able to read and understand a book)", "machine learning +(interpretability AND analogy)", "machine learning +(\"interpretability is like\")", "machine learning +(\"interpretability is similar\")", "machine learning +(\"just as interpretability\")", "machine learning +(\"interpretability can be thought of as\")", "machine learning +(\"interpretability can be compared to\")"]}