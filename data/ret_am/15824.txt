{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of model <b>interpretability</b> and how it relates to interpretable and explainable machine learning. To summarise, <b>interpretability</b> is the degree to which a model can be understood ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High model <b>interpretability</b> wins arguments. Risk and responsibility. A model with high <b>interpretability</b> is desirable on a high-risk stakes game. High interpretable models equate to <b>being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Interpretability</b> Models with Hermione | by Gustavo Resende | A3data ...", "url": "https://medium.com/a3data/interpretability-models-with-hermione-6f02e1bb4e43", "isFamilyFriendly": true, "displayUrl": "https://medium.com/a3data/<b>interpretability</b>-models-with-hermione-6f02e1bb4e43", "snippet": "<b>Interpretability</b> Models with Hermione. Hermione is an open-source library released in 2020 that helps Data Scientists on setting up more organized codes, quickly and simply. Besides, there are ...", "dateLastCrawled": "2021-12-30T16:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Teaching Machines <b>to Read</b> <b>Movie Reviews: Thinking About Interpretability</b>", "url": "https://towardsdatascience.com/teaching-machines-to-read-movie-reviews-thinking-about-interpretability-63c12248b8e5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/teaching-machines-<b>to-read</b>-movie-reviews-thinking-about...", "snippet": "Model Accuracy vs <b>Interpretability</b>. Using stance categories (the lexicogramatical level of language) as features doesn\u2019t improve performance over a word-based model: Random Forest using stance vectors (image by author) Again reading diagonally from left to right, the stance-based model is about 80% accurate predicting positive reviews, and around 73% accurate with negative reviews. So from a pure performance perspective, using stance hurts performance. But insight is a very different story ...", "dateLastCrawled": "2022-01-19T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretability, Explainability, and Machine Learning</b> | Insights ...", "url": "https://www.insightsassociation.org/article/interpretability-explainability-and-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.insightsassociation.org/article/<b>interpretability</b>-explainability-and...", "snippet": "Let\u2019s take a closer look at <b>interpretability</b> and explainability with regard to machine learning models. Imagine I were to create a highly accurate model for predicting a disease diagnosis based on symptoms, family history and so forth. If I created a logistic regression model for this purpose, you would be <b>able</b> to see exactly what weights ...", "dateLastCrawled": "2022-01-17T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Understanding the difference between <b>interpretability</b> and ...", "url": "https://subscription.packtpub.com/book/data/9781800203907/2/ch02lvl1sec05/understanding-the-difference-between-interpretability-and-explainability", "isFamilyFriendly": true, "displayUrl": "https://subscription.packtpub.com/<b>book</b>/data/9781800203907/2/ch02lvl1sec05/...", "snippet": "Design transparency: <b>Being</b> <b>able</b> to explain choices made, such as model architecture and hyperparameters. For instance, we could justify these choices based on the size or nature of the training data. If we were performing a sales forecast and we knew that our sales had a seasonality of 12 months, this could be a sound parameter choice. If we had doubts, we could always use some well-established statistical method to find the right seasonality.", "dateLastCrawled": "2021-12-29T16:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Best Machine Learning Books</b> (Updated for 2020)", "url": "https://blog.floydhub.com/best-machine-learning-books/", "isFamilyFriendly": true, "displayUrl": "https://blog.floydhub.com/<b>best-machine-learning-books</b>", "snippet": "Why you should <b>read</b> it: <b>Interpretability</b> is rapidly becoming a hot topic to solve in Deep Learning. Unboxing the black box is still an active research area for Deep Learning, but luckily for Machine Learning models, we actually have more tools available \u2014 this <b>being</b> one of the best ones. Where you can get it: Buy on LeanPub or Lulu (paperback version). You can also <b>read</b> it for free, but if you <b>like</b> it, please support the author. 2 years, 250 pages, 1,219 commits, and 78,480 words: I am ...", "dateLastCrawled": "2022-02-02T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How important is <b>interpretability</b> for a model in Machine Learning ...", "url": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-<b>interpretability</b>-for...", "snippet": "Hofstadter\u2019s first <b>book</b>, and in my opinion, still his best, was an utter revelation to me. It opened up a whole new world of imagination of what deep links there are between art, music and abstract math, realized by the three central characters \u2014 Johann Sebastian Bach, Maurice Escher, Kurt G\u00f6del \u2014 and computing, including of course AI and ML.", "dateLastCrawled": "2022-01-10T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Model <b>Interpretability</b>. With the advancement in Machine\u2026 | by Sumedh ...", "url": "https://smdhtelang2.medium.com/model-interpretability-da57f807c42a", "isFamilyFriendly": true, "displayUrl": "https://smdhtelang2.medium.com/model-<b>interpretability</b>-da57f807c42a", "snippet": "Model <b>Interpretability</b>. With the advancement in Machine Learning where machine learning is <b>able</b> to solve the most complex problems in the world highly accurately, the need to understand the complexity of the black-box model working is increasing every day. In this article, I will be shedding light on some of the model agnostic methods <b>like</b> SHAP ...", "dateLastCrawled": "2022-01-21T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Model interpretation and data valuation for machine learning (<b>Book</b> ...", "url": "https://www.worldcat.org/title/model-interpretation-and-data-valuation-for-machine-learning/oclc/1255184724", "isFamilyFriendly": true, "displayUrl": "https://www.worldcat.org/title/model-interpretation-and-data-valuation-for-machine...", "snippet": "Machine learning is <b>being</b> applied in various critical applications <b>like</b> healthcare. In order to be <b>able</b> to trust a machine learning model and to repair it once it malfunctions, it is important to be <b>able</b> to interpret its decision-making. For example, if a model&#39;s performance is poor on a specific subgroup (gender, race, etc), it is important to find out why and fix it. In this thesis, we examine the drawbacks of existing <b>interpretability</b> methods and introduce new ML <b>interpretability</b> ...", "dateLastCrawled": "2021-10-17T14:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "A model that provided <b>similar</b> explanations would be more useful than one that just provided predictions. ... we\u2019ll explain in more detail what is meant by <b>interpretability</b>. We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High model <b>interpretability</b> wins arguments. Risk and responsibility. A model with high <b>interpretability</b> is desirable on a high-risk stakes game. High interpretable models equate <b>to being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "As such, we believe that the true benefit of an <b>interpretability</b> framework is <b>being</b> <b>able</b> to formalize these different aspects of <b>interpretability</b>, then pick the most relevant method. The claim \u201cyou should use SHAP because it makes your model more interpretable\u201d is largely useless. However, the claim \u201cyou should use SHAP because the decomposability it offers is worth the risk of using a post-hoc explanation\u201d makes clear both the benefits and risks of SHAP.", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Model <b>Interpretability</b>. With the advancement in Machine\u2026 | by Sumedh ...", "url": "https://smdhtelang2.medium.com/model-interpretability-da57f807c42a", "isFamilyFriendly": true, "displayUrl": "https://smdhtelang2.medium.com/model-<b>interpretability</b>-da57f807c42a", "snippet": "Model <b>Interpretability</b>. Sumedh Telang. Dec 20, 2020 \u00b7 6 min <b>read</b>. Source: Majemo/GettyImages. With the advancement in Machine Learning where machine learning is <b>able</b> to solve the most complex problems in the world highly accurately, the need to understand the complexity of the black-box model working is increasing every day. In this article, I will be shedding light on some of the model agnostic methods like SHAP, LIME, Anchor, etc on the tabular dataset. In this article, I used Adult ...", "dateLastCrawled": "2022-01-21T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Best Machine Learning Books</b> (Updated for 2020)", "url": "https://blog.floydhub.com/best-machine-learning-books/", "isFamilyFriendly": true, "displayUrl": "https://blog.floydhub.com/<b>best-machine-learning-books</b>", "snippet": "Why you should <b>read</b> it: <b>Interpretability</b> is rapidly becoming a hot topic to solve in Deep Learning. Unboxing the black box is still an active research area for Deep Learning, but luckily for Machine Learning models, we actually have more tools available \u2014 this <b>being</b> one of the best ones. Where you can get it: Buy on LeanPub or Lulu (paperback version). You can also <b>read</b> it for free, but if you like it, please support the author. 2 years, 250 pages, 1,219 commits, and 78,480 words: I am ...", "dateLastCrawled": "2022-02-02T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Interpretability</b> - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/computer-science/interpretability", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/computer-science/<b>interpretability</b>", "snippet": "5.2.10 <b>Interpretability</b> of radiomics. Every step of the radiomics pipeline should be clinically interpretable, including feature extraction, feature selection, and model establishment. <b>Interpretability</b> is an urgent focus in AI-based research, especially in medical applications. Although the radiomics method has demonstrated its ability to quantitatively characterize lesions in many clinical problems, it failed to establish the correlation between most texture features and biomarkers. So far ...", "dateLastCrawled": "2022-01-30T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Chapter 16 Interpretable Machine Learning</b> | Hands-On Machine Learning ...", "url": "https://bradleyboehmke.github.io/HOML/iml.html", "isFamilyFriendly": true, "displayUrl": "https://bradleyboehmke.github.io/HOML/iml.html", "snippet": "<b>Being</b> <b>able</b> to answer such questions and provide both levels of explanation is key to any ML project becoming accepted, adopted, embedded, and properly utilized. 16.2.1 Global interpretation Global <b>interpretability</b> is about understanding how the model makes predictions, based on a holistic view of its features and how they influence the underlying model structure.", "dateLastCrawled": "2022-02-01T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>How important is interpretability for a</b> model in Machine Learning? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-model-in-Machine-Learning", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Interpretability</b> in the medical field: A systematic mapping and review ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "snippet": "<b>Book</b> regrouping papers published at three different conferences were selected from the reference scan. After discussion, the authors agreed to scan each conference paper and include those that satisfied the selection criteria. The study selection took approximately 4 months. Table 4. QA questions. Id Question Possible answers; QA1: The study presents empirical evidence (about <b>interpretability</b>) that is analyzed quantitatively or qualitatively \u201cQuantitatively\u201d or \u201cQualitatively\u201d QA2 ...", "dateLastCrawled": "2022-01-23T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Against <b>Interpretability</b>: a Critical Examination of the ...", "url": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "snippet": "The first section argued that the concepts of <b>interpretability</b> and cognates lack the kind of definition that would render them adequate to the kind of work that their proponents want them to do, and also suggested that <b>interpretability</b> may end up <b>being</b> of more limited use than is often thought. The second section argued that since <b>interpretability</b> is most often proposed as a means to further ends rather than an end in itself, it would be more perspicuous to organize discussion around the ...", "dateLastCrawled": "2021-12-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability</b> in Machine Learning | by Conor O&#39;Sullivan | Towards ...", "url": "https://towardsdatascience.com/interpretability-in-machine-learning-ab0cf2e66e1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretability</b>-in-machine-learning-ab0cf2e66e1", "snippet": "We\u2019ll then move on to the importance and benefits of <b>being</b> <b>able</b> to interpret your models. There are, however, still some downsides. We\u2019ll end off by discussing these and why, in some cases, you may prefer a less interpretable model. What do we mean by <b>interpretability</b>? In a previous article, I discuss the concept of model <b>interpretability</b> and how it relates to interpretable and explainable machine learning. To summarise, <b>interpretability</b> is the degree to which a model <b>can</b> be understood ...", "dateLastCrawled": "2022-01-28T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High interpretable models equate to <b>being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was made. Highly interpretable models, and maintaining high <b>interpretability</b> as a design standard, <b>can</b> help build trust between engineers and users. It\u2019s bad enough when the chain of command prevents a person from <b>being</b> <b>able</b> to speak to the party responsible for making the decision. It is much worse ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "These explanations help us and others determine whether a decision or <b>thought</b> was fair, logical, or well-<b>thought</b>-out. This form of post-hoc explanation applies to model <b>interpretability</b> as well. Post-hoc explanations are methods by which what models have learned <b>can</b> be visualized. Common examples are: Text explanations: Similar to how humans justify decisions verbally. An explanation- or text-generating model is trained in tandem with the prediction model. Visualization: Qualitative ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Neural Network <b>Interpretability</b> Fundamentals | by Andre Ye | Towards ...", "url": "https://towardsdatascience.com/every-ml-engineer-needs-to-know-neural-network-interpretability-afea2ac0824e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/every-ml-engineer-needs-to-know-neural-network...", "snippet": "By <b>being</b> <b>able</b> to interpret this powerful modeler, you will be <b>able</b> to stop serious problems reflected in the data before they become a bigger problem and gain human-understandable knowledge on, say, symptoms of lung cancer, which <b>can</b> be immensely valuable to applications and locations that do not have access to advanced technology. The interpretation of neural networks brings the human component into such an artificial construct. This article will cover three methods of explaining the ...", "dateLastCrawled": "2022-02-03T04:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Against <b>Interpretability</b>: a Critical Examination of the ...", "url": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-019-00372-9", "snippet": "<b>Interpretability</b> is often <b>thought</b> to play an important role in justification in an ML context. It <b>can</b> seem outright irresponsible to believe algorithmic outputs regarding unseen real-world data in the absence of detailed knowledge of the algorithm\u2019s inner workings. However, in some contexts, there are ways of achieving the desired assurance in the absence of knowledge about inner workings of tools. People were both responsible and justified in relying on the deliverances of their eyes ...", "dateLastCrawled": "2021-12-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Model interpretation and data valuation for machine learning (<b>Book</b> ...", "url": "https://www.worldcat.org/title/model-interpretation-and-data-valuation-for-machine-learning/oclc/1255184724", "isFamilyFriendly": true, "displayUrl": "https://www.worldcat.org/title/model-interpretation-and-data-valuation-for-machine...", "snippet": "In order to be <b>able</b> to trust a machine learning model and to repair it once it malfunctions, it is important to be <b>able</b> to interpret its decision-making. For example, if a model&#39;s performance is poor on a specific subgroup (gender, race, etc), it is important to find out why and fix it. In this thesis, we examine the drawbacks of existing <b>interpretability</b> methods and introduce new ML <b>interpretability</b> algorithms that are designed to tackle some of the shortcomings. Data is the labor that ...", "dateLastCrawled": "2021-10-17T14:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How important is <b>interpretability</b> for a model in Machine Learning ...", "url": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://quorasessionwithiangoodfellow.quora.com/How-important-is-<b>interpretability</b>-for...", "snippet": "It <b>can</b> be even used by systems without operating system, example <b>being</b> compiled and fabricated as a neuromorphic chip (Qualc Continue Reading After the long training on a powerful computer, you <b>can</b> export the model (set of already trained weights for all neurons + description of the topology network) to a lightweights executable eg. using our library TensorRT.", "dateLastCrawled": "2022-01-10T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Chapter 2 Statistical Learning</b> | A Tidy Introduction To ... - GitHub Pages", "url": "https://beaulucas.github.io/tidy_islr/statistical-learning.html", "isFamilyFriendly": true, "displayUrl": "https://beaulucas.github.io/tidy_islr/<b>statistical-learning</b>.html", "snippet": "2.2.3 The Trade-Off Between Prediction Accuracy and Model <b>Interpretability</b>. Restrictive models are much more intepretable than flexible ones. Flexible approaches <b>can</b> be so complicated that it is hard to understand how predictors affect the response. If inference is the goal, simple and inflexible methods are easier to interpret. For prediction, accuracy is the biggest concern. However, flexible models are more prone to overfitting. 2.2.4 Supervised Versus Unsupervised Learning. Most machine ...", "dateLastCrawled": "2022-01-28T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>How important is interpretability for a</b> model in Machine Learning? - Quora", "url": "https://www.quora.com/How-important-is-interpretability-for-a-model-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>How-important-is-interpretability-for-a</b>-model-in-Machine-Learning", "snippet": "Answer (1 of 29): Imagine you have abdominal pain and see a doctor. Doc: You have cancer but don&#39;t worry this black box here will cure you. You: Oh no! Doc what do I have? What are my options? How does the black box work? Doc: Trust the black box. We have no idea what it does nor how it works,...", "dateLastCrawled": "2022-01-23T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What makes <b>interpretability</b> in neural networks difficult? - Quora", "url": "https://www.quora.com/What-makes-interpretability-in-neural-networks-difficult", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-makes-<b>interpretability</b>-in-neural-networks-difficult", "snippet": "Answer (1 of 2): The ultimate goal of machine learning (or statistics), many would argue, is to build insight into some phenomenon. Thus far, the ML community has largely been obsessed with predictive accuracy. If you <b>read</b> the many papers in different subfields of ML at leading conferences, like ...", "dateLastCrawled": "2022-01-13T06:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretability vs Explainability: The Black</b> Box of Machine Learning ...", "url": "https://www.bmc.com/blogs/machine-learning-interpretability-vs-explainability/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.bmc.com</b>/blogs/machine-learning-<b>interpretability</b>-vs-explainability", "snippet": "High interpretable models equate <b>to being</b> <b>able</b> to hold another party liable. And when models are predicting whether a person has cancer, people need to be held accountable for the decision that was made. Highly interpretable models, and maintaining high <b>interpretability</b> as a design standard, <b>can</b> help build trust between engineers and users. It\u2019s bad enough when the chain of command prevents a person from <b>being</b> <b>able</b> to speak to the party responsible for making the decision. It is much worse ...", "dateLastCrawled": "2022-01-30T19:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "6 \u2013 <b>Interpretability</b> \u2013 Machine Learning Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "<b>Interpretability</b> takes many forms and <b>can</b> be difficult to define; we first explore general frameworks and sets of definitions in which model <b>interpretability</b> <b>can</b> be evaluated and <b>compared</b> (Lipton 2016, Doshi-Velez &amp; Kim 2017). Next, we analyze several well-known examples of <b>interpretability</b> methods\u2013LIME (Ribeiro et al. 2016), SHAP (Lundberg &amp; Lee 2017), and convolutional neural network visualization (Olah et al. 2018)\u2013in the context of this framework. Model <b>interpretability</b> has no ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Interpretable Machine Learning. Extracting human understandable\u2026 | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-1dec0f2f3e6b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/interpret<b>able</b>-machine-learning-1dec0f2f3e6b", "snippet": "<b>Interpretability</b> is as important as creating a model. To achieve wider acceptance among the population, it is crucial that Machine learning systems are <b>able</b> to provide satisfactory explanations for their decisions. As Albert Einstein said,\u201d If you <b>can</b>\u2019t explain it simply, you don\u2019t understand it well enough\u201d.", "dateLastCrawled": "2022-02-03T11:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Comparison and improvement of the predictability and <b>interpretability</b> ...", "url": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0417-9", "isFamilyFriendly": true, "displayUrl": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0417-9", "snippet": "Ensemble learning helps improve machine learning results by combining several models and allows the production of better predictive performance <b>compared</b> to a single model. It also benefits and accelerates the researches in quantitative structure\u2013activity relationship (QSAR) and quantitative structure\u2013property relationship (QSPR). With the growing number of ensemble learning models such as random forest, the effectiveness of QSAR/QSPR will be limited by the machine\u2019s inability to ...", "dateLastCrawled": "2022-02-01T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Interpretability</b> in the medical field: A systematic mapping and review ...", "url": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1568494621011522", "snippet": "FR (seven articles with 20 evaluations) was <b>compared</b> against white-box models or other <b>interpretability</b> techniques by comparing the shifts in attribute ranks (a mean rank shift of 1.24), and expert knowledge was discussed qualitatively and was generally in favor of the <b>interpretability</b> technique in question. Moreover, 11 articles with 104 evaluations <b>compared</b> tree explanations to other techniques, and interpretable models using accuracy, the mean accuracy improvement over these articles was ...", "dateLastCrawled": "2022-01-23T08:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Chapter 16 Interpretable Machine Learning</b> | Hands-On Machine Learning ...", "url": "https://bradleyboehmke.github.io/HOML/iml.html", "isFamilyFriendly": true, "displayUrl": "https://bradleyboehmke.github.io/HOML/iml.html", "snippet": "Approaches to model <b>interpretability</b> to answer the exemplar questions above <b>can</b> be broadly categorized as providing global or local explanations. It is important to understand the entire model that you\u2019ve trained on a global scale, and also to zoom in on local regions of your data or your predictions and derive explanations. <b>Being</b> <b>able</b> to answer such questions and provide both levels of explanation is key to any ML project becoming accepted, adopted, embedded, and properly utilized.", "dateLastCrawled": "2022-02-01T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Push the limits of explainability", "url": "https://urszulaczerwinska.github.io/works/interpretability-shap", "isFamilyFriendly": true, "displayUrl": "https://urszulaczerwinska.github.io/works/<b>interpretability</b>-shap", "snippet": "<b>Interpretability</b>: the ability to explain or provide meaning in terms that are understandable by a human <b>being</b>. ... A good explanation on how <b>to read</b> the colors of the summary plot <b>can</b> be found in this medium article [14]. A summary of graphical visualizations to analyze global explanations . The summary plot shows the most important features and the magnitude of their impact on the model. It <b>can</b> take several graphical forms and for the models explained by TreeExplainer we <b>can</b> also observe ...", "dateLastCrawled": "2021-10-22T21:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Understanding model predictions with <b>LIME</b> | by Lars Hulstaert | Towards ...", "url": "https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-model-predictions-with-<b>lime</b>-a582fdff3a3b", "snippet": "The authors show that permutation importance provides more robust estimates when variables are strongly correlated, <b>compared</b> to random forest importance\u2019s. I highly recommend <b>to read</b> their blog post for a thorough understanding of the findings. <b>LIME</b>. <b>LIME</b> is model-agnostic, meaning that it <b>can</b> be applied to any machine learning model. The ...", "dateLastCrawled": "2022-02-03T00:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Stock Market Prediction Using Machine Learning Techniques | AnalytixLabs", "url": "https://www.analytixlabs.co.in/blog/stock-market-prediction-using-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analytixlabs.co.in/blog/stock-market-prediction-using-machine-learning", "snippet": "The major advantage of this method is that it is high in <b>interpretability</b> as the user <b>can</b> know which factor influences the price of stock more and by how much. The disadvantage includes that it is highly limited in its scope. Many predictors cannot be used, which is required to solve the stock price prediction problem. Machine Learning-based packages such as sci-kit learn to allow the user to use Linear Regression in a Machine Learning framework. Some libraries in R also allow the same, but ...", "dateLastCrawled": "2022-02-02T17:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Understanding SHAP(XAI) through LEAPS</b> - Analyttica", "url": "https://analyttica.com/understanding-shap-xai-through-leaps/", "isFamilyFriendly": true, "displayUrl": "https://analyttica.com/<b>understanding-shap-xai-through-leaps</b>", "snippet": "Apart from <b>being</b> <b>able</b> to provide an explanation for a particular observation or data point, SHAP <b>can</b> also be used to explain on how the model behaves at a global level. For this the complete test data is used by SHAP to identify the most influencing features. The graphs showing the feature importance at global level are plotted as below. Red indicate a inclination towards class 1 and blue towards class 0. Limitations of SHAP . Computation Time: As the number of features increase, the number ...", "dateLastCrawled": "2022-02-01T18:05:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Interpretability</b> in <b>Machine</b> <b>Learning</b>", "url": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cl.cam.ac.uk/teaching/1819/P230/IWML-Lecture-4.pdf", "snippet": "This provides a novel <b>analogy</b> between data compression and regularization. Qualitative and quantitative state-of-the-art results on three datasets. 20 / 33. Interpretable Lens Variable Model (ILVM) 21 / 33. Interactive <b>Interpretability</b> via Active <b>Learning</b> Interactive \u2018human-in-the-loop\u2019 <b>interpretability</b> Choose the point with index j that maximizes : ^j = argmax jI(s ; ) = H(s ) E q \u02da(z js)[H(s jz j)] = Z p(s j)log p(s j)ds + E q \u02da(z js) Z p (s jjz)log p (s jjz)ds : (5) Choose the point ...", "dateLastCrawled": "2022-01-19T17:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "6 \u2013 <b>Interpretability</b> \u2013 <b>Machine</b> <b>Learning</b> Blog | ML@CMU | Carnegie Mellon ...", "url": "https://blog.ml.cmu.edu/2020/08/31/6-interpretability/", "isFamilyFriendly": true, "displayUrl": "https://blog.ml.cmu.edu/2020/08/31/6-<b>interpretability</b>", "snippet": "Figure 1: <b>Interpretability</b> for <b>machine</b> <b>learning</b> models bridges the concrete objectives models optimize for and the real-world (and less easy to define) desiderata that ML applications aim to achieve. Introduction . The objectives <b>machine</b> <b>learning</b> models optimize for do not always reflect the actual desiderata of the task at hand. <b>Interpretability</b> in models allows us to evaluate their decisions and obtain information that the objective alone cannot confer. <b>Interpretability</b> takes many forms ...", "dateLastCrawled": "2022-02-03T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "There is increasing emphasis on interpretable <b>machine</b> <b>learning</b> in the world of data. Models have been growing ever more complex with the use of neural networks becoming more mainstream, along with the sheer size of data being analysed today. In many cases, such complex models may not be fit for human interpretation in their own right. Therefore, there has been a push to make the model interpretable, whereby both the results and the process in achieving those results are understood by humans ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-57524-3_17", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-16T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Towards <b>Analogy</b>-Based Explanations in <b>Machine</b> <b>Learning</b>", "url": "https://arxiv.org/abs/2005.12800", "isFamilyFriendly": true, "displayUrl": "https://<b>arxiv</b>.org/abs/2005.12800", "snippet": "Principles of analogical reasoning have recently been applied in the context of <b>machine</b> <b>learning</b>, for example to develop new methods for classification and preference <b>learning</b>. In this paper, we argue that, while analogical reasoning is certainly useful for constructing new <b>learning</b> algorithms with high predictive accuracy, is is arguably not less interesting from an <b>interpretability</b> and explainability point of view. More specifically, we take the view that an <b>analogy</b>-based approach is a ...", "dateLastCrawled": "2021-10-24T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Economic Methodology Meets Interpretable <b>Machine</b> <b>Learning</b> ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_intro", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. But first ...", "dateLastCrawled": "2022-01-05T13:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Economic Methodology Meets Interpretable Machine Learning</b> - Part I ...", "url": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes/", "isFamilyFriendly": true, "displayUrl": "https://bcmullins.github.io/economic_methodology_interpretable_ml_blackboxes", "snippet": "In this series of posts, we will develop an <b>analogy</b> between the realistic assumptions debate in economic methodology and the current discussion over <b>interpretability</b> when using <b>machine</b> <b>learning</b> models in the wild. While this connection may seem fuzzy at first, the past seventy years or so of economic methodology offers many lessons for <b>machine</b> <b>learning</b> theorists and practitioners to avoid analysis paralysis and make progress on the <b>interpretability</b> issue - one way or the other. Intro - Part ...", "dateLastCrawled": "2022-01-22T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Analogies between Biology and Deep <b>Learning</b> [rough note] -- colah&#39;s blog", "url": "http://colah.github.io/notes/bio-analogies/", "isFamilyFriendly": true, "displayUrl": "colah.github.io/notes/bio-analogies", "snippet": "Neuroscience \u2194 <b>Interpretability</b>. <b>Analogy</b>: model=brain. Artificial neural networks are historically inspired by neuroscience, but I used to be pretty skeptical that the connection was anything more than superficial. I&#39;ve since come around: I now think this is a very deep connection. The thing that personally persuaded me was that, in my own investigations of what goes on inside neural networks, we kept finding things that were previously discovered by neuroscientists. The most recent ...", "dateLastCrawled": "2022-01-30T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>SHAP</b>: A reliable way to analyze model <b>interpretability</b> | by Sharayu ...", "url": "https://towardsdatascience.com/shap-a-reliable-way-to-analyze-your-model-interpretability-874294d30af6", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>shap</b>-a-reliable-way-to-analyze-your-model...", "snippet": "The balance: Accuracy vs. <b>Interpretability</b>. 2. How to interpret <b>machine</b> <b>learning</b> models? 3. LIME: Explaining predictions of <b>machine</b> <b>learning</b> models. In this blog, I wil l be talking about one of the most popular model agnostic technique that is used to explain predictions. <b>SHAP</b> stands for SHapley Additive exPlanations. Shapely values are obtained by incorporating concepts from Cooperative Game Theory and local explanations. Given a set of palyers, Cooperative Game Theory defines how well and ...", "dateLastCrawled": "2022-01-31T17:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Chris Olah on what the hell is going on inside neural networks - 80,000 ...", "url": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research/", "isFamilyFriendly": true, "displayUrl": "https://80000hours.org/podcast/episodes/chris-olah-interpretability-research", "snippet": "Chris is a <b>machine</b> <b>learning</b> researcher currently focused on neural network interpretability. Until last December he led OpenAI\u2019s interpretability team but along with some colleagues he recently moved on to help start a new AI lab focussed on large models and safety called Anthropic. Rob Wiblin: Before OpenAI he spent 4 years at Google Brain developing tools to visualize what\u2019s going on in neural networks. Chris was hugely impactful at Google Brain. He was second author on the launch of ...", "dateLastCrawled": "2022-02-01T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Marketing AI: Interpretability and Explainability</b> - Christopher S. Penn ...", "url": "https://www.christopherspenn.com/2021/03/marketing-ai-interpretability-and-explainability/", "isFamilyFriendly": true, "displayUrl": "https://www.christopherspenn.com/2021/03/<b>marketing-ai-interpretability-and-explainability</b>", "snippet": "<b>Interpretability is like</b> inspecting the baker\u2019s recipe for the cake. We look at the list of ingredients and the steps taken to bake the cake, and we verify that the recipe makes sense and the ingredients were good. This is a much more rigorous way of validating our results, but it\u2019s the most complete \u2013 and if we\u2019re in a high-stakes situation where we need to remove all doubt, this is the approach we take. Interpretability in AI is like that \u2013 we step through the code itself that ...", "dateLastCrawled": "2022-01-29T12:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Causal <b>Learning</b> From Predictive Modeling for Observational Data", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7931928/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7931928", "snippet": "Given the recent success of <b>machine</b> <b>learning</b>, specifically deep <b>learning</b>, in several applications (Goodfellow et al., ... This statistical <b>interpretability is similar</b> in spirit to traditional interpretability. This allows to answer questions, such as \u201cdoes BMI influence susceptibility to Covid?\u201d Moreover, it has been argued that developing an effective CBN for practical applications requires expert knowledge when data collection is cumbersome (Fenton and Neil, 2012). This applies to ...", "dateLastCrawled": "2021-12-09T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimal <b>Predictive Clustering</b> - Dimitris Bertsimas", "url": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-predictive-clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://dbertsim.mit.edu/pdfs/papers/2020-sobiesk-optimal-<b>predictive-clustering</b>.pdf", "snippet": "Table 1 Comparison of major <b>machine</b> <b>learning</b> methods relative to each other across the metrics of performance (out-of-sample R2), scalability and interpretability. 1 is the best, while 5 is the worst. Optimal <b>Predictive Clustering</b> 3 From Table 1, we observe all existing methods have weakness in at least one category. We therefore seek to design a method that has strong performance in all three categories at the same time. Optimal <b>Predictive Clustering</b> (OPC) is an algorithm that uses mixed ...", "dateLastCrawled": "2021-11-24T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reviewing Challenges of Predicting Protein Melting Temperature Change ...", "url": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12033-021-00349-0", "snippet": "Predicting the effects of mutations on protein stability is a key problem in fundamental and applied biology, still unsolved even for the relatively simple case of small, soluble, globular, monomeric, two-state-folder proteins. Many articles discuss the limitations of prediction methods and of the datasets used to train them, which result in low reliability for actual applications despite globally capturing trends. Here, we review these and other issues by analyzing one of the most detailed ...", "dateLastCrawled": "2022-02-03T02:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Interpretable Machine Learning: Advantages and Disadvantages</b> | by ...", "url": "https://towardsdatascience.com/interpretable-machine-learning-advantages-and-disadvantages-901769f48c43", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>interpretable-machine-learning-advantages-and</b>...", "snippet": "In my view, a shor t coming of interpretable <b>machine</b> <b>learning</b> is that it assumes to a degree that the data being fed into the model is always going to be suitable for human interpretation. This is not necessarily the case. For instance, let\u2019s say that a company is trying to implement interpretable <b>machine</b> <b>learning</b> to devise a credit scoring model, whereby prospective credit card applications are classified as approved or rejected based on numerous features. It is often the case that such ...", "dateLastCrawled": "2022-01-19T03:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Breaking the interpretability barrier - a</b> method for interpreting deep ...", "url": "http://www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "isFamilyFriendly": true, "displayUrl": "www.di.uniba.it/~loglisci/NFMCP2019/NFMCP/nfMCP2019_paper_17.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o between performance and inter-pretability. Graph classi cation is normally a domain which requires the ap-plication of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to in-terpret complex models post-hoc (brie y reviewed in section2). However, most ...", "dateLastCrawled": "2021-09-22T17:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Discovering Discriminative Nodes for Classi\ufb01cation with Deep Graph ...", "url": "http://muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "isFamilyFriendly": true, "displayUrl": "muresanlab.tins.ro/publications/preprints/Palcu_et_al_LNAI_2020.pdf", "snippet": "Last, but not least, <b>interpretability can be thought of as</b> a useful tool for understanding and correcting model errors. In general, we are faced with a trade-o\ufb00 between performance and inter-pretability. Graph classi\ufb01cation is normally a domain which requires the appli-cation of complex <b>learning</b> models, such as deep neural networks, which are not interpretable by nature. Several relevant attempts have been made to interpret complex models post-hoc (brie\ufb02y reviewed in Sect.2). However ...", "dateLastCrawled": "2021-09-02T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Confronting Abusive Language Online: A Survey from the Ethical and ...", "url": "https://www.arxiv-vanity.com/papers/2012.12305/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2012.12305", "snippet": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this ...", "dateLastCrawled": "2021-10-13T19:21:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(interpretability)  is like +(being able to read a book)", "+(interpretability) is similar to +(being able to read a book)", "+(interpretability) can be thought of as +(being able to read a book)", "+(interpretability) can be compared to +(being able to read a book)", "machine learning +(interpretability AND analogy)", "machine learning +(\"interpretability is like\")", "machine learning +(\"interpretability is similar\")", "machine learning +(\"just as interpretability\")", "machine learning +(\"interpretability can be thought of as\")", "machine learning +(\"interpretability can be compared to\")"]}