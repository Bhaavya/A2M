{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Human</b> Emotion <b>Recognition</b>: Review of Sensors and Methods", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7037130/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7037130", "snippet": "Based on the analyzed <b>human</b> emotion <b>recognition</b> sensors and methods, we developed some practical applications for humanizing the Internet of Things (IoT) and affective computing systems. Keywords: <b>human</b> emotions, emotion perception, physiologic sensors. 1. Introduction. With the rapid increase in the use of smart technologies in society and the development of the industry, the need for technologies capable to assess the needs of a potential customer and choose the most appropriate solution ...", "dateLastCrawled": "2022-02-02T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Self-Supervised Feature Learning by Cross-<b>Modality</b> and Cross-View ...", "url": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Jing_Self-Supervised_Feature_Learning_by_Cross-Modality_and_Cross-View_Correspondences_CVPRW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Jing_Self-Supervised...", "snippet": "<b>different</b> <b>objects</b>. \u2022 The discriminative 2D and 3D features learned by the self-supervised schema are used as pre-trained models for other down-stream tasks such as classi\ufb01cation, re-trieval, and 3D part segmentation, etc. \u2022 Extensive experiments on \ufb01ve <b>different</b> tasks (i.e. multi-view 2D shape <b>recognition</b>, 3D shape <b>recog-nition</b>, multi-view 2D shape retrieval, 3D shape re-trieval, and 3D part-segmentation) demonstrate the ef-fectiveness and generalization of the proposed frame-work ...", "dateLastCrawled": "2022-01-25T17:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Functional <b>imaging of human crossmodal identification and object</b> ...", "url": "https://www.researchgate.net/publication/7716959_Functional_imaging_of_human_crossmodal_identification_and_object_recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/7716959_Functional_imaging_of_<b>human</b>_cross...", "snippet": "The <b>different</b> sensory modalities provide both complementary and redundant information about <b>objects</b>, which may improve <b>recognition</b> speed and accuracy in many circumstances. We review crossmodal ...", "dateLastCrawled": "2022-02-01T17:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Neural Substrates of Tactile Object <b>Recognition</b>: An fMRI Study", "url": "https://nielaborg.files.wordpress.com/2019/04/human_brain_mapping_2004.pdf", "isFamilyFriendly": true, "displayUrl": "https://nielaborg.files.wordpress.com/2019/04/<b>human</b>_brain_mapping_2004.pdf", "snippet": "sensory and motor integration characteristic of object <b>recognition</b> in the tactile <b>modality</b>. Activation in a lateral occipitotemporal area associated previously with visual object <b>recognition</b> may support cross- modal collateral activation. Finally, activation in medial temporal and prefrontal areas may re\ufb02ect a common \ufb01nal pathway of <b>modality</b>-independent object <b>recognition</b>. This study suggests that TOR involves a complex network including parietal and insular somatosensory association ...", "dateLastCrawled": "2022-01-07T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Instagram teaches AI to recognize rooms", "url": "https://techxplore.com/news/2022-01-instagram-ai-rooms.html", "isFamilyFriendly": true, "displayUrl": "https://techxplore.com/news/2022-01-instagram-ai-rooms.html", "snippet": "&quot;One of the reasons for this is that most systems are trained using just one <b>modality</b>, usually <b>recognition</b> of <b>objects</b> in a room.&quot; Therefore, Talavera Mart\u00ednez decided to train her system using a second <b>modality</b>: transcribed texts of speech recorded in the videos. She used real-world videos from Instagram to train her AI system. This was achieved using the images and speech. The spoken texts were transcribed using standard Google speech <b>recognition</b> software. Talavera Mart\u00ednez and her then ...", "dateLastCrawled": "2022-02-03T04:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Semantic Event Fusion <b>of Different</b> Visual <b>Modality</b> Concepts for ...", "url": "https://hal.inria.fr/hal-01399025/file/crispim_etal_pami_spec_issu_v7.2%20%281%29.pdf", "isFamilyFriendly": true, "displayUrl": "https://hal.inria.fr/hal-01399025/file/crispim_etal_pami_spec_issu_v7.2 (1).pdf", "snippet": "Semantic Event Fusion <b>of Different</b> Visual <b>Modality</b> Concepts for Activity <b>Recognition</b> Carlos Crispim-Junior, Vincent Buso, Konstantinos Avgerinakis, Georgios Meditskos, Alexia Briassouli, Jenny Benois-Pineau, Yiannis Kompatsiaris, Francois Bremond To cite this version: Carlos Crispim-Junior, Vincent Buso, Konstantinos Avgerinakis, Georgios Meditskos, Alexia Brias-souli, et al.. Semantic Event Fusion <b>of Different</b> Visual <b>Modality</b> Concepts for Activity <b>Recognition</b>. IEEE Transactions on Pattern ...", "dateLastCrawled": "2022-01-26T19:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Data-Driven Thermal <b>Recognition</b> of Contact with People and <b>Objects</b>", "url": "https://cpb-us-w2.wpmucdn.com/sites.gatech.edu/dist/9/231/files/2015/10/data-driven-thermal.pdf", "isFamilyFriendly": true, "displayUrl": "https://cpb-us-w2.wpmucdn.com/sites.gatech.edu/dist/9/231/files/2015/10/data-driven...", "snippet": "Thermal <b>recognition</b> of <b>objects</b> in situ entails distinct chal-lenges from material <b>recognition</b> and laboratory-based stud-ies. In contrast to <b>recognition</b> of material samples, <b>objects</b> will often be composed of multiple materials with distinct thermal properties, such as <b>different</b> thermal effusivities. <b>Objects</b> will also have geometries that affect heat transfer, such as by altering the contact area between thermal sensors and the object. Also, <b>different</b> <b>objects</b> in the same object category can be ...", "dateLastCrawled": "2021-11-19T04:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deep <b>Learning Models for Human Activity Recognition</b>", "url": "https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/deep-<b>learning-models-for-human-activity-recognition</b>", "snippet": "<b>Human</b> Activity <b>Recognition</b>. <b>Human</b> activity <b>recognition</b>, or HAR for short, is a broad field of study concerned with identifying the specific movement or action of a person based on sensor data. Movements are often typical activities performed indoors, such as walking, talking, standing, and sitting. They may also be more focused activities such as those types of activities performed in a kitchen or on a factory floor. The sensor data may be remotely recorded, such as video, radar, or other ...", "dateLastCrawled": "2022-02-02T16:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Literature Review of Designing, <b>Modality</b> and Psychological ...", "url": "http://www.ijesi.org/papers/Vol(3)5/Version-3/C0353018026.pdf", "isFamilyFriendly": true, "displayUrl": "www.ijesi.org/papers/Vol(3)5/Version-3/C0353018026.pdf", "snippet": "approach. However, in this paper it is proposed that using same or <b>different</b> <b>modality</b> (such as camera for vision) to track <b>different</b> visualisation techniques (<b>like</b> object movement and gesture <b>recognition</b>) is considered as multimodal. This proposal is opposite to that of Sebe (2009) where system is considered to be multimodal only", "dateLastCrawled": "2021-09-03T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Literature Survey: Human Action Recognition</b> | Vivek Maskara", "url": "https://www.maskaravivek.com/post/survey-of-human-action-recognition/", "isFamilyFriendly": true, "displayUrl": "https://www.maskaravivek.com/post/survey-of-<b>human</b>-action-<b>recognition</b>", "snippet": "<b>Human</b> action <b>recognition</b> is a standard Computer Vision problem and has been well studied. The fundamental goal is to analyze a video to identify the actions taking place in the video. Essentially a video has a spatial aspect to it ie. the individual frames and a temporal aspect ie. the ordering of the frames. Some actions (eg. standing, running, etc.) can probably be identified by using just a single frame but for more complex actions(eg. walking vs running, bending vs falling) might require ...", "dateLastCrawled": "2022-01-30T01:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Cross-Modal Object <b>Recognition</b> Is Viewpoint-Independent", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1964535/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC1964535", "snippet": "<b>Recognition</b> of rotated <b>objects</b> involves complex mental spatial transformations. In visual within-modal object <b>recognition</b>, mental rotation and <b>recognition</b> of rotated <b>objects</b> have behaviorally <b>similar</b> signatures (in both, errors and latencies increase with angle of rotation) but rely on <b>different</b> neural networks .The relationships between the spatial transformations underlying mental rotation and cross-modal <b>recognition</b> of rotated <b>objects</b> are unclear.", "dateLastCrawled": "2021-11-04T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Functional <b>imaging of human crossmodal identification and object</b> ...", "url": "https://www.researchgate.net/publication/7716959_Functional_imaging_of_human_crossmodal_identification_and_object_recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/7716959_Functional_imaging_of_<b>human</b>_cross...", "snippet": "The <b>recognition</b> of <b>objects</b> could be manipulated through the coordinated cross-modal interactions <b>of different</b> modalities, such as vision, touch and audition ( Amedi et al., 2005; Dormal et al ...", "dateLastCrawled": "2022-02-01T17:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Interactive Object <b>Recognition</b> Using Proprioceptive and Auditory Feedback", "url": "https://www.ece.iastate.edu/~alexs/papers/IJRR_2011/IJRR_2011_preprint.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ece.iastate.edu/~alexs/papers/IJRR_2011/IJRR_2011_preprint.pdf", "snippet": "The <b>human</b> visual system is also subject to these same limitations - not surprisingly, humans need other sensory modalities to capture knowledge about <b>objects</b> [21], [35], [11]. To address the inherent limitations of the visual sensory <b>modality</b>, this paper proposes a novel behavior-grounded method for interactive <b>recognition</b> of household <b>objects</b> ...", "dateLastCrawled": "2021-11-18T09:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "SOMA: Subject-, object-, and <b>modality</b>-adapted precision atlas approach ...", "url": "https://europepmc.org/article/PMC/PMC8678400", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC8678400", "snippet": "In this paper, we propose a method called SOMA to select subject-, object-, and <b>modality</b>-adapted precision atlases for automatic anatomy <b>recognition</b> in medical images with pathology, following the idea that <b>different</b> regions of the target object in a novel image can be recognized by <b>different</b> atlases with regionally best similarity, so that effective atlases have no need to be globally <b>similar</b> to the target subject and also have no need to be overall <b>similar</b> to the target object.", "dateLastCrawled": "2022-01-06T07:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Conditional Convolutional Neural Network for Modality</b>-Aware Face ...", "url": "https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Xiong_Conditional_Convolutional_Neural_ICCV_2015_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Xiong_Conditional...", "snippet": "<b>different</b> views or styles in computer vision. For example, <b>objects</b> of the same class may have <b>different</b> types in object <b>recognition</b>, e.g., cars may be of various types and brands; or in <b>human</b> pose estimation, people with the same pose may have <b>different</b> identities. Similarly, many face related tasks deal with images with variations in terms of ...", "dateLastCrawled": "2022-02-03T17:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A comparative review of graph convolutional networks for <b>human</b> skeleton ...", "url": "https://link.springer.com/article/10.1007/s10462-021-10107-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10462-021-10107-y", "snippet": "<b>Human</b> action <b>recognition</b> is one of the hottest topics in the research field, so there are many relevant review papers illustrating the multi-<b>modality</b> of data, the selection of feature vectors, and the pros and cons of classification networks. With the continuous development of relational networks, graph convolutional networks (GCNs) have been applied to many <b>different</b> fields, including <b>human</b> action <b>recognition</b>. Although the graph convolutional networks have been demonstrated the powerful ...", "dateLastCrawled": "2022-01-29T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Review on Computer Vision-Based Methods for <b>Human</b> Action <b>Recognition</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321068/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8321068", "snippet": "<b>Human</b> action <b>recognition</b> targets recognising <b>different</b> actions from a sequence of observations and <b>different</b> environmental conditions. A wide <b>different</b> applications is applicable to vision based action <b>recognition</b> research. This can include video surveillance, tracking, health care, and <b>human</b>\u2013computer interaction. However, accurate and effective vision based <b>recognition</b> systems continue to be a big challenging area of research in the field of computer vision. This review introduces the ...", "dateLastCrawled": "2022-01-24T15:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Semantic Event Fusion <b>of Different</b> Visual <b>Modality</b> Concepts for ...", "url": "https://hal.inria.fr/hal-01399025/file/crispim_etal_pami_spec_issu_v7.2%20%281%29.pdf", "isFamilyFriendly": true, "displayUrl": "https://hal.inria.fr/hal-01399025/file/crispim_etal_pami_spec_issu_v7.2 (1).pdf", "snippet": "Semantic Event Fusion <b>of Different</b> Visual <b>Modality</b> Concepts for Activity <b>Recognition</b> Carlos Crispim-Junior, Vincent Buso, Konstantinos Avgerinakis, Georgios Meditskos, Alexia Briassouli, Jenny Benois-Pineau, Yiannis Kompatsiaris, Francois Bremond To cite this version: Carlos Crispim-Junior, Vincent Buso, Konstantinos Avgerinakis, Georgios Meditskos, Alexia Brias-souli, et al.. Semantic Event Fusion <b>of Different</b> Visual <b>Modality</b> Concepts for Activity <b>Recognition</b>. IEEE Transactions on Pattern ...", "dateLastCrawled": "2022-01-26T19:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Neural Substrates of Tactile Object <b>Recognition</b>: An fMRI Study", "url": "https://nielaborg.files.wordpress.com/2019/04/human_brain_mapping_2004.pdf", "isFamilyFriendly": true, "displayUrl": "https://nielaborg.files.wordpress.com/2019/04/<b>human</b>_brain_mapping_2004.pdf", "snippet": "subjects carried out naturalistic tactile object <b>recognition</b> (TOR) of real <b>objects</b>. Activation maps, conjunc-tions across subjects, were compared between tasks involving TOR of common real <b>objects</b>, palpation of \u201cnonsense\u201d <b>objects</b>, and rest. The tactile tasks involved <b>similar</b> motor and sensory stimulation, allowing higher tactile <b>recognition</b> processes to be isolated. Compared to nonsense object palpation, the most prominent activation evoked by TOR was in secondary somatosensory areas in ...", "dateLastCrawled": "2022-01-07T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Literature Survey: Human Action Recognition</b> | Vivek Maskara", "url": "https://www.maskaravivek.com/post/survey-of-human-action-recognition/", "isFamilyFriendly": true, "displayUrl": "https://www.maskaravivek.com/post/survey-of-<b>human</b>-action-<b>recognition</b>", "snippet": "<b>Human</b> action <b>recognition</b> is a standard Computer Vision problem and has been well studied. The fundamental goal is to analyze a video to identify the actions taking place in the video. Essentially a video has a spatial aspect to it ie. the individual frames and a temporal aspect ie. the ordering of the frames. Some actions (eg. standing, running, etc.) can probably be identified by using just a single frame but for more complex actions(eg. walking vs running, bending vs falling) might require ...", "dateLastCrawled": "2022-01-30T01:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Modalities of Sensation</b> - Nociceptors - Hyperalgesia - TeachMePhysiology", "url": "https://teachmephysiology.com/nervous-system/sensory-system/modalities-of-sensation/", "isFamilyFriendly": true, "displayUrl": "https://teachmephysiology.com/nervous-system/sensory-system/<b>modalities-of-sensation</b>", "snippet": "Sensory <b>Modality</b>. Sensory modalities <b>can</b> <b>be thought</b> of as subtypes of sensory experiences, such as pain, temperature, pressure etc. Each sensory <b>modality</b> is perceived by a class of specialised receptors: Nociceptors. Nociceptors are receptors, which respond to noxious stimuli (stimuli that would cause tissue injury if they were to persist) and their activation results in the sensation of pain. The receptors are free nerve endings, found on the ends of the type A\u03b4 fibres and type C fibres ...", "dateLastCrawled": "2022-02-02T10:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Epistemology of <b>Modality</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/modality-epistemology/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/<b>modality</b>-epistemology", "snippet": "Sentences (1)\u2013(10) instantiate <b>different</b> kinds of <b>modality</b>. (1\u20133) are most naturally interpreted to be about ... Other kinds of <b>modality</b> <b>can</b> be suitably added to the model, as well, such as practical possibility. Practical possibilities would be within the physical possibilities. Importantly, some philosophers question whether metaphysical <b>modality</b> is a distinct and irreducible <b>modality</b>. Alternative accounts include inflationism, deflationism, and skepticism. Inflationists, such as David ...", "dateLastCrawled": "2022-02-03T06:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Study: Bumblebees Recognize Objects through Sight</b> and Touch | Sci-News.com", "url": "http://www.sci-news.com/biology/bumblebees-cross-modal-recognition-08156.html", "isFamilyFriendly": true, "displayUrl": "www.sci-news.com/biology/bumblebees-cross-modal-<b>recognition</b>-08156.html", "snippet": "Cross-modal <b>recognition</b> is the ability to recognize <b>objects</b> across <b>different</b> senses. For example, humans <b>can</b> easily recognize something they\u2019ve previously seen through touch alone.", "dateLastCrawled": "2022-01-22T22:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Human</b> Emotion <b>Recognition</b>: Review of Sensors and Methods", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7037130/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7037130", "snippet": "2. Emotions Evaluation Methods. Emotion evaluations methods which are presented in the literature <b>can</b> be classified into two main groups according to the basic techniques used for emotions <b>recognition</b>: self-repot techniques based on emotions self-assessment by filing various questionnaires [30,31,32]; machine assessment techniques based on measurements of various parameters of <b>human</b> body [33,34,35].In addition, there are frequent cases of simultaneous use of several methods in order to ...", "dateLastCrawled": "2022-02-02T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "From Sensory Signals to <b>Modality</b>-Independent Conceptual Representations ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640543/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4640543", "snippet": "We also report the results of an experiment in which <b>different</b> subjects rated the similarity of pairs of <b>objects</b> in <b>different</b> sensory conditions, and show that the model provides a very accurate account of subjects\u2019 ratings. Conceptually, this research significantly contributes to our understanding of <b>modality</b> invariance, an important type of perceptual constancy, by demonstrating how <b>modality</b>-independent representations <b>can</b> be acquired and used. Methodologically, it provides an important ...", "dateLastCrawled": "2021-08-02T15:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Visual, <b>haptic and cross-modal recognition of objects and scenes</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0928425704000774", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0928425704000774", "snippet": "An outstanding achievement of <b>human</b> vision is the capacity for rapid and seemingly effortless <b>recognition</b> of <b>objects</b>. Generally, the problem for the visual system is that <b>recognition</b> has to be achieved despite variation in the sensory information about an object. Sources of variation in an <b>object&#39;s</b> image on the retina, for example, <b>can</b> include changes in viewpoint, changes in shape with non-rigid movement, or changes in illumination. Yet the visual system must allow for such changes whilst ...", "dateLastCrawled": "2021-10-13T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Object Recognition in Humans and Machines</b>", "url": "https://www.researchgate.net/publication/228379736_Object_Recognition_in_Humans_and_Machines", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228379736_<b>Object_Recognition_in_Humans_and</b>...", "snippet": "<b>human</b> <b>recognition</b> could be better explained in terms of a view-based account, in which object representation consists of snapshot-like views (B\u00fclthoff and. Edelman 1992) instead of a full, 3D ...", "dateLastCrawled": "2021-11-23T22:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "1. How Humans Interact with Computers - Creating Augmented and Virtual ...", "url": "https://www.oreilly.com/library/view/creating-augmented-and/9781492044185/ch01.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/creating-augmented-and/9781492044185/ch01.html", "snippet": "I use the following terms in these specific ways that assume a <b>human</b>-perceivable element: <b>Modality</b>. A channel of sensory input and output between a computer and a <b>human</b>. Affordances . Attributes or characteristics of an object that define that object\u2019s potential uses. Inputs. How you do those things; the data sent to the computer. Outputs. A perceivable reaction to an event; the data sent from the computer. Feedback. A type of output; a confirmation that what you did was noticed and acted ...", "dateLastCrawled": "2022-02-01T10:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Perception - summary of chapter 2 of Cognitive Psychology by Gilhooly ...", "url": "https://www.worldsupporter.org/en/chapter/66864-perception-summary-chapter-2-cognitive-psychology-gilhooly-k-lyddy-f-m", "isFamilyFriendly": true, "displayUrl": "https://www.worldsupporter.org/en/chapter/66864-perception-summary-chapter-2-cognitive...", "snippet": "The heart of <b>recognition</b> by components: <b>objects</b> <b>can</b> <b>be thought</b> of as composed of a collection of geons. Since every geon in an object <b>can</b> be recovered by its unique collection of viewpoint invariant properties, this allows the entire object to be recognized. Multiple views theory; <b>Recognition</b> is fundamentally image-based.", "dateLastCrawled": "2022-02-01T17:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Chapter 7: Object Recognition</b> Flashcards | Quizlet", "url": "https://quizlet.com/202956628/chapter-7-object-recognition-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/202956628/<b>chapter-7-object-recognition</b>-flash-cards", "snippet": "Inability to recognize or identify a certain category of <b>objects</b> even though the ability to recognize other categories of items in that same <b>modality</b> is retained. Developmental (congenital) prosopagnosia", "dateLastCrawled": "2018-09-18T15:21:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Multi-modality learning for human action recognition</b> | Request PDF", "url": "https://www.researchgate.net/publication/339633019_Multi-modality_learning_for_human_action_recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339633019_<b>Multi-modality_learning_for_human</b>...", "snippet": "The multi-<b>modality</b> based <b>human</b> action <b>recognition</b> is an increasing topic. Multi-<b>modality</b> <b>can</b> provide more abundant and complementary information than single <b>modality</b>. However, it is difficult for ...", "dateLastCrawled": "2021-08-10T09:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Multi-<b>modality</b> learning <b>for human action recognition</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s11042-019-08576-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11042-019-08576-z", "snippet": "The multi-<b>modality</b> based <b>human action recognition</b> is an increasing topic. Multi-<b>modality</b> <b>can</b> provide more abundant and complementary information than single <b>modality</b>. However, it is difficult for multi-<b>modality</b> learning to capture the spatial-temporal information from the entire RGB and depth sequence effectively. In this paper, to obtain better representation of spatial-temporal information, we propose a bidirectional rank pooling method to construct the RGB Visual Dynamic Images (VDIs) and ...", "dateLastCrawled": "2022-01-09T16:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Transfer learning, and multi-<b>modality</b> <b>recognition</b>", "url": "https://dshao.sites.umassd.edu/research/transfer-learning-and-multi-modality-recognition/", "isFamilyFriendly": true, "displayUrl": "https://dshao.sites.umassd.edu/research/transfer-learning-and-multi-<b>modality</b>-<b>recognition</b>", "snippet": "Recent face <b>recognition</b> work has concentrated on <b>different</b> spectral, i.e., near infrared, that <b>can</b> only be perceived by specifically designed device to avoid the illumination problem. This makes great sense in fighting off the lighting factors in face <b>recognition</b>. However, using near infrared for face <b>recognition</b> inevitably introduces a new problem, namely, cross-<b>modality</b> classification. In brief, images registered in the system are in one <b>modality</b> while images that captured momentarily used ...", "dateLastCrawled": "2022-01-17T10:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Auditory-Visual Object <b>Recognition</b> Time Suggests Specific Processing ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2668178/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2668178", "snippet": "We <b>compared</b> <b>recognition</b> times for two categories: a biologically relevant one (animals) and a non-biologically relevant one (means of transport). Participants were asked to react as fast as possible to target <b>objects</b>, presented in the visual and/or the auditory <b>modality</b>, and to withhold their response for distractor <b>objects</b>. A first main finding was that, when participants were presented with unimodal or bimodal congruent stimuli (an image and a sound from the same object), similar reaction ...", "dateLastCrawled": "2017-01-07T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "1 <b>Human Action Recognition from Various Data Modalities</b>: A Review", "url": "https://eprints.lancs.ac.uk/id/eprint/150821/1/2012.11866v2.pdf", "isFamilyFriendly": true, "displayUrl": "https://eprints.lancs.ac.uk/id/eprint/150821/1/2012.11866v2.pdf", "snippet": "<b>Human Action Recognition from Various Data Modalities</b>: A Review Zehua Sun, Jun Liu, Qiuhong Ke, Hossein Rahmani, Mohammed Bennamoun, and Gang Wang Abstract\u2014<b>Human</b> Action <b>Recognition</b> (HAR), aiming to understand <b>human</b> behaviors and then assign category labels, has a wide range of applications, and thus has been attracting increasing attention in the \ufb01eld of computer vision. Generally, <b>human</b> actions <b>can</b> be represented using various data modalities, such as RGB, skeleton, depth, infrared ...", "dateLastCrawled": "2022-01-18T19:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Neural Substrates of Tactile Object <b>Recognition</b>: An fMRI Study", "url": "https://nielaborg.files.wordpress.com/2019/04/human_brain_mapping_2004.pdf", "isFamilyFriendly": true, "displayUrl": "https://nielaborg.files.wordpress.com/2019/04/<b>human</b>_brain_mapping_2004.pdf", "snippet": "cortex; <b>human</b>; object <b>recognition</b> INTRODUCTION People <b>can</b> recognize many common <b>objects</b> by touch in less than 2 sec [Klatzky et al., 1985]. Despite our pro\ufb01ciency, very little is known about the neural substrates underlying naturalistic tactile object <b>recognition</b> (TOR). Behavioral and neuroimaging studies have debated whether touch has a viable object <b>recognition</b> system independent from that of vision [e.g., Deibert et al., 1999; Klatzky et al., 1987]. In other words, to what extent does ...", "dateLastCrawled": "2022-01-07T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Human</b> Emotion <b>Recognition</b>: Review of Sensors and Methods", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7037130/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7037130", "snippet": "Based on the analyzed <b>human</b> emotion <b>recognition</b> sensors and methods, we developed some practical applications for humanizing the Internet of Things (IoT) and affective computing systems. Keywords: <b>human</b> emotions, emotion perception, physiologic sensors. 1. Introduction. With the rapid increase in the use of smart technologies in society and the development of the industry, the need for technologies capable to assess the needs of a potential customer and choose the most appropriate solution ...", "dateLastCrawled": "2022-02-02T11:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Role of Landmark <b>Modality</b> and Familiarity in <b>Human</b> Wayfinding ...", "url": "https://econtent.hogrefe.com/doi/full/10.1024/1421-0185/a000139", "isFamilyFriendly": true, "displayUrl": "https://econtent.hogrefe.com/doi/full/10.1024/1421-0185/a000139", "snippet": "It is not very surprising that the acoustic landmarks resulted in good <b>recognition</b> performance: According to Baddeley\u2019s (e.g., Baddeley, 2003) working memory model, it uses a <b>different</b> sensory channel and therefore another processing <b>modality</b> (phonological loop). Furthermore, acoustic landmarks provided a strong \u201ccontrast to the surrounding,\u201d since the animal sounds were the only sounds the participants heard during the experiment.", "dateLastCrawled": "2021-12-14T21:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Literature Survey: Human Action Recognition</b> | Vivek Maskara", "url": "https://www.maskaravivek.com/post/survey-of-human-action-recognition/", "isFamilyFriendly": true, "displayUrl": "https://www.maskaravivek.com/post/survey-of-<b>human</b>-action-<b>recognition</b>", "snippet": "<b>Human</b> action <b>recognition</b> is a standard Computer Vision problem and has been well studied. The fundamental goal is to analyze a video to identify the actions taking place in the video. Essentially a video has a spatial aspect to it ie. the individual frames and a temporal aspect ie. the ordering of the frames. Some actions (eg. standing, running, etc.) <b>can</b> probably be identified by using just a single frame but for more complex actions(eg. walking vs running, bending vs falling) might require ...", "dateLastCrawled": "2022-01-30T01:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>International Journal of Advanced</b> <b>Recent progress on tactile object</b> ...", "url": "https://journals.sagepub.com/doi/pdf/10.1177/1729881417717056", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/pdf/10.1177/1729881417717056", "snippet": "<b>compared</b> the advantages and disadvantages of 28 kinds of tactile sensors in detail, ... fingered dexterous hand to catch <b>objects</b> <b>of different</b> shapes. A tactile model built from the hidden Markov model was used to judge object-grasping stability. Addi- tionally, tactile perception technology has also been appliedtoslidingdetection,9 objectlocalization,10,11 tactile servo,12 and 3-D modeling.13 Object <b>recognition</b> has always been a key problem in robotics and also important for environment ...", "dateLastCrawled": "2021-10-18T12:13:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Types of Machine Learning</b> | Different Methods and Kinds of Model", "url": "https://www.educba.com/types-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>types-of-machine-learning</b>", "snippet": "<b>Machine</b> <b>learning</b> is further classified as Supervised, Unsupervised, Reinforcement, and Semi-Supervised <b>Learning</b> algorithms; all these types of <b>learning</b> techniques are used in different applications. What is <b>Machine</b> <b>Learning</b>? <b>Machine</b> <b>learning</b> is a small application area of Artificial Intelligence in which machines automatically learn from the operations and finesse themselves to give better output. Based on the data collected, the machines improve the computer programs aligning with the ...", "dateLastCrawled": "2022-02-02T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b> and Theological Traditions of <b>Analogy</b> - Davison - 2021 ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "snippet": "12 <b>Machine</b> <b>Learning</b>, <b>Analogy</b>, and God. The texts considered in this article come from theological sources. They have offered ways to think analogically about features of the world, in this case the similarities we are beginning to see between capacities in <b>machine</b> <b>learning</b> and those in human beings and other animals. Much of the mediaeval ...", "dateLastCrawled": "2021-04-16T10:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Machine</b> <b>Learning</b> and Theological Traditions of <b>Analogy</b>", "url": "https://www.researchgate.net/publication/349470559_Machine_Learning_and_Theological_Traditions_of_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/349470559_<b>Machine</b>_<b>Learning</b>_and_Theological...", "snippet": "theories of <b>analogy</b> to <b>machine</b> <b>learning</b> has brought us here, since much of it was developed, in the first place, in thinking about the use of shared vocabulary for creature and creator.", "dateLastCrawled": "2021-11-04T23:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Modality and representation in analogy</b> | AI EDAM | Cambridge Core", "url": "https://www.cambridge.org/core/journals/ai-edam/article/modality-and-representation-in-analogy/F567723948DE2E845EDF1E048C87D9EF", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/ai-edam/article/<b>modality</b>-and-representation-in...", "snippet": "<b>Modality and representation in analogy</b> - Volume 22 Issue 2. Design by <b>analogy</b> is a powerful part of the design process across the wide variety of modalities used by designers such as linguistic descriptions, sketches, and diagrams.", "dateLastCrawled": "2022-01-19T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Modality and representation in analogy</b> | Julie Linsey - Academia.edu", "url": "https://www.academia.edu/2838157/Modality_and_representation_in_analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2838157/<b>Modality_and_representation_in_analogy</b>", "snippet": "(a) The percentage of participants with a solution based on the target analogous product at each phase for design problem 1, and (b) 1215 the percentage of participants who had a solution based on the target analogous product and also identified the <b>analogy</b> at each phase for 1155 1216 design problem 1. 1156 1217 1157 1218 1158 1219 1159 1220 <b>Modality and representation in analogy</b> 95 1221 1282 1222 1283 1223 1284 1224 1285 1225", "dateLastCrawled": "2021-09-07T15:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Effects of <b>Analogical Learning Approaches and Presentation Modalities</b> ...", "url": "https://link.springer.com/article/10.1007/s10956-020-09835-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10956-020-09835-7", "snippet": "Regardless of being in the <b>analogy</b> or metaphor group, the students who learned with the picture <b>modality</b> allocated greater TMD than those learned with the text <b>modality</b> (Fig. 4). The results also showed that students <b>learning</b> with the textual analogies not only provided more frequent mapping behaviors and longer mapping durations but also built more complete relationships between the water wheel system and the electric circuit system than those <b>learning</b> with the textual metaphors.", "dateLastCrawled": "2022-01-06T22:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Modality</b> and representation in <b>analogy</b>", "url": "https://www.researchgate.net/publication/231787416_Modality_and_representation_in_analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/231787416_<b>Modality</b>_and_representation_in_<b>analogy</b>", "snippet": "cognitive mechanisms underlying design and <b>analogy</b> is a crucial step in developing these. tools. This paper presents an experiment that explores the effects of representation within the. <b>modality</b> ...", "dateLastCrawled": "2022-01-19T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Analogical mapping across sensory modalities and evidence for a general ...", "url": "https://www.sciencedirect.com/science/article/pii/S0010027722000178", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0010027722000178", "snippet": "Example within-<b>modality</b> and cross-<b>modality</b> <b>analogy</b> trials. All <b>analogy</b> trials were of the form, \u201cA is to B as C is to D.\u201d Participants were instructed to indicate by button press whether each <b>analogy</b> was True or False. For example, in the True lines-to-sounds trial depicted in the figure, both the line analog (A-B) and sound analog (CD) were devised to convey the relation of paired elements (A: paired visual elements of an image; C: paired notes of a two-note chord) to a feature that ...", "dateLastCrawled": "2022-01-26T17:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep <b>Learning Models for Human Activity Recognition</b>", "url": "https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/deep-<b>learning-models-for-human-activity-recognition</b>", "snippet": "Statistical and <b>machine</b> <b>learning</b> models were then trained on the processed version of the data. A limitation of this approach is the signal processing and domain expertise required to analyze the raw data and engineer the features required to fit a model. This expertise would be required for each new dataset or sensor <b>modality</b>. In essence, it is expensive and not scalable. However, in most daily HAR tasks, those methods may heavily rely on heuristic handcrafted feature extraction, which is ...", "dateLastCrawled": "2022-02-02T16:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "About generalization, abstraction and analogies | by Tudor Surdoiu ...", "url": "https://dacus-augustus.medium.com/about-generalization-abstraction-and-analogies-e59aa16e7871", "isFamilyFriendly": true, "displayUrl": "https://dacus-augustus.medium.com/about-generalization-abstraction-and-analogies-e59aa...", "snippet": "A presentation of essential cognition concepts inspired by the book Deep <b>Learning</b> with Python, second edition by Fran\u00e7ois Chollet. The pursuit of better generalization is probably the underlining\u2026 Get started. Open in app. Tudor Surdoiu. Sign in. Get started. Follow. 78 Followers. About. Get started. Open in app. About generalization, abstraction and analogies. Tudor Surdoiu. Just now \u00b7 4 min read. A presentation of essential cognition concepts inspired by the book Deep <b>Learning</b> with ...", "dateLastCrawled": "2022-01-30T15:43:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Ensemble of deep convolutional neural networks based</b> multi\u2010modality ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2019.0617", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-ipr.2019.0617", "snippet": "In the last decades, pattern recognition and <b>machine</b> <b>learning</b> methods have been widely used in brain disease diagnosis, which extracts different kinds of the features from neuroimaging modalities to learn a model and predict class labels on an unknown object. In general, these feature extraction methods can be summarised into four categories: voxel-based morphometry (VBM) approach, region of interest (ROI)-based approach, patch-based approach and landmark-based approach. The VBM approach is ...", "dateLastCrawled": "2022-02-01T16:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How Electrical Stimulation Is Used in Physical Therapy", "url": "https://www.verywellhealth.com/electrical-stimulation-2696122", "isFamilyFriendly": true, "displayUrl": "https://www.verywellhealth.com/electrical-stimulation-2696122", "snippet": "<b>Learning</b> the right movements and exercises for your specific condition is extremely important. Some professionals debate whether e-stim is something of value in physical therapy. And some research shows that electrical stim doesn&#39;t help injured people very much. Other research indicates that some types of stimulation can be useful. Despite the ongoing debate on whether e-stim truly helps, you may encounter it if you go to physical therapy. So knowing what it is and what to expect can be ...", "dateLastCrawled": "2022-02-02T07:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Partnership - <b>Standigm</b> - <b>Standigm</b>", "url": "https://www.standigm.com/partnership/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>standigm</b>.com/partnership", "snippet": "*GPN (Graph Point Network) : A deep <b>learning</b> architecture that can use both graph-based 2d structural information and 3d information expressed by point net technique *Monet (Moiety based molecular Networks) : Proprietary deep <b>learning</b> model, which learns both whole structure and substructure, used to enumerate various derivative compounds from a seed molecule *NoSH (Novel Scaffold Hopping) : Module for scaffold hopping focused on novelty *IDEA-STAR : STAR is our proprietary <b>machine</b> <b>learning</b> ...", "dateLastCrawled": "2022-02-02T22:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Action science: Foundations of an emerging discipline | Request PDF", "url": "https://www.researchgate.net/publication/236625110_Action_science_Foundations_of_an_emerging_discipline", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/236625110_Action_science_Foundations_of_an...", "snippet": "Over the past decade, embodied cognition has become an influential paradigm in music research. Embodied music cognition is representative of the so-called &quot;pragmatic turn in cognitive science ...", "dateLastCrawled": "2022-01-06T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Datives and Other Cases</b> | LAURISRAEL ADOU - Academia.edu", "url": "https://www.academia.edu/38665770/Datives_and_Other_Cases", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/38665770", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-27T11:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Schellings Naturalism</b> | German Idealism | Georg Wilhelm Friedrich Hegel", "url": "https://www.scribd.com/document/386463765/Schellings-Naturalism", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/386463765/<b>Schellings-Naturalism</b>", "snippet": "up as a form of categorization at worst, and, as a simultaneously exploratory, and simplifying <b>machine</b>. of reason, at best.31 While I believe this view potentially sells Kant&#39;s notion of judgment short, it is. somewhat easy to see the troubling legislative aspect of Kant&#39;s transcendental conditions as they apply . 31 I will take up this issue in the following chapter in relationship to Kant&#39;s \u201cWhat is Called Orientation in Thinking?\u201d 30 to nature. In The Critique of the Power of Judgment ...", "dateLastCrawled": "2022-02-02T21:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Defining <b>Next-Generation Multi-Modal Communication in</b> Human Robot ...", "url": "https://www.researchgate.net/publication/273346003_Defining_Next-Generation_Multi-Modal_Communication_in_Human_Robot_Interaction", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/273346003_Defining_Next-Generation_Multi...", "snippet": "Alternatively, robotic <b>learning</b> techniques such as: gradual mutual adaptation (Ikemoto et al. 2012;Peternel et al. 2016a), reinforcement <b>learning</b> Palunko et al. (2014) or <b>learning</b> from ...", "dateLastCrawled": "2021-10-21T00:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Towards a typology of meaningful signals and</b> cues in social robotics", "url": "https://www.researchgate.net/publication/224256262_Towards_a_typology_of_meaningful_signals_and_cues_in_social_robotics", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/224256262_<b>Towards_a_typology_of_meaningful</b>...", "snippet": "Typologies and taxonomies have been proposed to classify signs and cues for HRI and conversational agents. For instance, Hegel et al. [43] propose a typology of signals and cues in HRI, and ...", "dateLastCrawled": "2021-10-19T19:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) [Wolf-Andreas Liebert, Gisela Redeker and Linda R 1997 Discourse ...", "url": "https://www.academia.edu/34526397/_Wolf_Andreas_Liebert_Gisela_Redeker_and_Linda_R_1997_Discourse_and_Perspectives_in_Cognitive_Linguistics", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/34526397/_Wolf_Andreas_Liebert_Gisela_Redeker_and_Linda_R...", "snippet": "[Wolf-Andreas Liebert, Gisela Redeker and Linda R 1997 Discourse and Perspectives in Cognitive Linguistics", "dateLastCrawled": "2022-02-03T13:59:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(modality)  is like +(human recognition of different objects)", "+(modality) is similar to +(human recognition of different objects)", "+(modality) can be thought of as +(human recognition of different objects)", "+(modality) can be compared to +(human recognition of different objects)", "machine learning +(modality AND analogy)", "machine learning +(\"modality is like\")", "machine learning +(\"modality is similar\")", "machine learning +(\"just as modality\")", "machine learning +(\"modality can be thought of as\")", "machine learning +(\"modality can be compared to\")"]}