{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The Sociology of Discrimination: Racial Discrimination in Employment ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2915460/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2915460", "snippet": "<b>Disparate</b> <b>impact</b> occurs when individuals are treated equally according to a given set of rules and procedures but when the latter are constructed in ways that favor members of one group over another (Reskin 1998, p. 32; National Research Council 2004, pp. 39\u201340). The second component of this definition broadens its scope to include decisions and processes that may not themselves have any explicit racial content but that have the consequence of producing or reinforcing racial disadvantage ...", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Tutorial on <b>Fairness</b> in Machine Learning | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-machine-learning-3ff8ba1040cb", "snippet": "These laws typically evaluate the <b>fairness</b> of a decision making process using two distinct notions (Barocas and Selbst, 2016): <b>disparate</b> <b>treatment</b> and <b>disparate</b> <b>impact</b>. A decision making process suffers from <b>disparate</b> <b>treatment</b> if its decisions are (partly) based on the subject\u2019s sensitive attribute, and it has <b>disparate</b> <b>impact</b> if its outcomes disproportionately hurt (or benefit) people with certain sensitive attribute values (e.g., females, blacks). These two definitions, however, are too ...", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Chapter Four: Racial, Ethnic, and Gender Disparities in Federal ...", "url": "https://www.ussc.gov/sites/default/files/pdf/research-and-publications/research-projects-and-surveys/miscellaneous/15-year-study/chap4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ussc.gov/sites/default/files/pdf/research-and-publications/research...", "snippet": "<b>treatment</b> of individual offenders who are similar in relevant ways, ... their adverse <b>impact</b> on minority groups should be carefully considered by policymakers. B. Studying Racial, Ethnic, and Gender Discrimination in Sentencing 1. Continuing Concern in the Guidelines Era Concern over possible racial or ethnic discrimination in federal sentencing remains strong today, fifteen years after implementation of guidelines designed to eliminate it. No sentencing issue has received more attention ...", "dateLastCrawled": "2022-02-02T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The 4 types of discrimination: what every employer needs to know | HR", "url": "https://www.hrsolutions-uk.com/4-types-of-discrimination/", "isFamilyFriendly": true, "displayUrl": "https://www.hrsolutions-uk.com/4-types-of-discrimination", "snippet": "The employer must show that the less favourable <b>treatment</b> or PCP was appropriate and necessary (this must be objective and usually involves a business need). What is \u2018proportionate\u2019 will vary from case to case and can also depend on the size and resources of the business. For example, a large employer with many staff may find it easier to approve flexible working requests, which may come mostly from women with childcare responsibilities, than a small firm may be able to if they only have ...", "dateLastCrawled": "2022-02-02T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Fight <b>Discrimination</b> in AI - <b>Harvard Business Review</b>", "url": "https://hbr.org/2020/08/how-to-fight-discrimination-in-ai", "isFamilyFriendly": true, "displayUrl": "https://<b>hbr.org</b>/2020/08/how-to-fight-<b>discrimination</b>-in-ai", "snippet": "Avoiding unintentional <b>discrimination</b>, or <b>disparate</b> <b>impact</b>, however, is an altogether more complex undertaking. It occurs when a seemingly neutral variable (<b>like</b> the level of home ownership) acts ...", "dateLastCrawled": "2022-01-30T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Modeling Techniques for Machine Learning Fairness: A Survey | DeepAI", "url": "https://deepai.org/publication/modeling-techniques-for-machine-learning-fairness-a-survey", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/modeling-techniques-for-machine-learning-fairness-a-survey", "snippet": "The problem is partly <b>caused</b> by the bias that already exists in datasets and could be further amplified by models ... From the computational perspective, the fairness problem can be generally grouped into two categories: <b>disparate</b> <b>impact</b> and <b>disparate</b> <b>treatment</b>, which approach the fairness problem from the group- and the individual-level, respectively (Zafar et al., 2017a). Figure 1. <b>Disparate</b> <b>impact</b> (left) and <b>disparate</b> <b>treatment</b> (right) on the Adult. dataset, where a binary classifier is ...", "dateLastCrawled": "2021-12-14T02:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "fairMLHealth/Evaluating_Fairness.md at integration \u00b7 KenSciResearch ...", "url": "https://github.com/KenSciResearch/fairMLHealth/blob/integration/docs/resources/Evaluating_Fairness.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/KenSciResearch/fairMLHealth/blob/integration/docs/resources/...", "snippet": "Returning to the example: the <b>Disparate</b> <b>Impact</b> Ratio and Statistical Parity <b>Difference</b> are two related measures that compare the selection rates between the protected and unprotected groups. Although the <b>Disparate</b> <b>Impact</b> Ratio in our example is outside of the &quot;fair&quot; range for ratios (it&#39;s above 1.2), the Statistical Parity <b>Difference</b> is well within range for differences. We can see why more clearly by examining the Stratified Performance Table (also above). Here we see that the selection ...", "dateLastCrawled": "2022-02-02T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "When School Doesn&#39;t Seem <b>Fair, Students May Suffer Lasting Effects</b>", "url": "https://www.edweek.org/leadership/when-school-doesnt-seem-fair-students-may-suffer-lasting-effects/2017/02", "isFamilyFriendly": true, "displayUrl": "https://<b>www.edweek.org</b>/leadership/when-school-doesnt-seem-fair-students-may-suffer...", "snippet": "Students who perceive a lack of justice or <b>disparate</b> <b>treatment</b> for certain racial groups may respond with defiant behavior. And discipline for that behavior may cause them to become further ...", "dateLastCrawled": "2022-02-03T07:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fact Sheet: Racial Fairness in the Advisory Guidelines System", "url": "https://www.fd.org/sites/default/files/criminal_defense_topics/essential_topics/sentencing_resources/bookerfix_factsheet_3.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.fd.org/sites/default/files/criminal_defense_topics/essential_topics/...", "snippet": "differences in the <b>treatment</b> that offenders of specific racial groups received at sentencing. ... and has a racially <b>disparate</b> <b>impact</b>.8 After Booker, judges have been better able to compensate for unfair and unnecessarily harsh rules that create racial disparity. In fiscal year 2010, judges imposed below-guideline sentences in 26.5% of crack cases (a rate that would likely have been higher but for trumping mandatory minimums), and 79.8% of these offenders were African American. Only 4.5% of ...", "dateLastCrawled": "2021-11-19T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Nerdy comments about measuring disparate impact</b> | mathbabe", "url": "https://mathbabe.org/2015/10/07/nerdy-comments-about-measuring-disparate-impact/", "isFamilyFriendly": true, "displayUrl": "https://mathbabe.org/2015/10/07/<b>nerdy-comments-about-measuring-disparate-impact</b>", "snippet": "To begin to talk about measuring <b>disparate</b> <b>impact</b>, one needs to understand patterns by which measures tend to be affected by the frequency of an outcome, including the pattern whereby the rarer an outcome the greater tends to be the relative <b>difference</b> in experiencing it and the smaller tends to be the relative <b>difference</b> in avoiding it. Commonly observers measure <b>disparate</b> <b>impact</b> in terms of relative differences in favorable outcome <b>like</b> test passage (as with the four-fifths rule of the ...", "dateLastCrawled": "2022-01-19T08:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What Is <b>The Difference Between Disparate Impact and Disparate Treatment</b> ...", "url": "https://rayneslaw.com/what-is-the-difference-between-disparate-impact-and-disparate-treatment-discrimination/", "isFamilyFriendly": true, "displayUrl": "https://rayneslaw.com/what-is-<b>the-difference-between-disparate-impact</b>-and-<b>disparate</b>-", "snippet": "<b>Disparate</b> <b>impact</b> refers to discrimination that is unintentional. The procedures are the same for everyone, but people in a protected class are negatively affected. For example, say that job applicants for a certain job are tested on their reaction times, and only people with a high score are hired. This test will discriminate against older workers, who are less likely to have fast reaction times. Whether this test is illegal will depend on whether fast reaction times are necessary for the ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "FairDEA\u2014Removing <b>disparate</b> <b>impact</b> from efficiency scores - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0377221721010092", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0377221721010092", "snippet": "<b>Disparate</b> <b>impact</b> can be presented in a different manner using a <b>similar</b> <b>unfairness</b> measure called ... r = 1 s u r d y r d \u2265 D I v i d \u2265 \u03f5, i = 1, \u2026, m \u2227 d = 1, \u2026, n u r d \u2265 \u03f5, r = 1, \u2026, s \u2227 d = 1, \u2026, n where D I represents a parameter of acceptable <b>disparate</b> <b>impact</b>, i.e. the average <b>difference</b> in efficiency scores between the unprivileged and privileged groups. For example, if an average <b>difference</b> of 5% was allowed in efficiency scores, then the value of the parameter ...", "dateLastCrawled": "2022-01-30T22:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Fairness metrics and bias mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "<b>Similar</b> to statistical parity, the concept of <b>Disparate</b> <b>Impact</b> (Feldman et al., 2015) compares the probability of favorable outcome between two groups. However, it uses a relative instead of an absolute comparison and has its background in a legal doctrine that aims to avoid unintended consequences and <b>unfairness</b> based on group membership. Formally, <b>Disparate</b> <b>Impact</b> is defined as:", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Tutorial on <b>Fairness</b> in Machine Learning | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-machine-learning-3ff8ba1040cb", "snippet": "These laws typically evaluate the <b>fairness</b> of a decision making process using two distinct notions (Barocas and Selbst, 2016): <b>disparate</b> <b>treatment</b> and <b>disparate</b> <b>impact</b>. A decision making process suffers from <b>disparate</b> <b>treatment</b> if its decisions are (partly) based on the subject\u2019s sensitive attribute, and it has <b>disparate</b> <b>impact</b> if its outcomes disproportionately hurt (or benefit) people with certain sensitive attribute values (e.g., females, blacks). These two definitions, however, are too ...", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The 4 types of discrimination: what every employer needs to know | HR", "url": "https://www.hrsolutions-uk.com/4-types-of-discrimination/", "isFamilyFriendly": true, "displayUrl": "https://www.hrsolutions-uk.com/4-types-of-discrimination", "snippet": "The employer must show that the less favourable <b>treatment</b> or PCP was appropriate and necessary (this must be objective and usually involves a business need). What is \u2018proportionate\u2019 will vary from case to case and can also depend on the size and resources of the business. For example, a large employer with many staff may find it easier to approve flexible working requests, which may come mostly from women with childcare responsibilities, than a small firm may be able to if they only have ...", "dateLastCrawled": "2022-02-02T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Disparate Vulnerability: on the Unfairness of Privacy Attacks Against</b> ...", "url": "https://deepai.org/publication/disparate-vulnerability-on-the-unfairness-of-privacy-attacks-against-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>disparate-vulnerability-on-the-unfairness</b>-of-privacy...", "snippet": "First, we introduce a new notion: <b>disparate</b> vulnerability, which, similarly to <b>disparate</b> <b>impact</b> Feldman et al. (2015) and <b>disparate</b> mistreatment Zafar et al. (2017) in fairness, captures the differential <b>impact</b> that privacy attacks have on subgroups. We propose a framework to quantify <b>disparate</b> vulnerability in an efficient manner, i.e., without requiring iterative training and testing of expensive models.", "dateLastCrawled": "2021-12-07T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Pay or Compensation Discrimination - Workplace Fairness", "url": "https://www.workplacefairness.org/pay-discrimination", "isFamilyFriendly": true, "displayUrl": "https://www.workplacefairness.org/pay-discrimination", "snippet": "An employer maintains a neutral compensation policy or practice that has a negative <b>impact</b> on employees in a protected class and cannot be justified as job-related and consistent with business necessity. For example, if an employer provides extra compensation to employees who are the head of household,i.e., married with dependents and the primary financial contributor to the household, the practice may have an unlawful <b>disparate</b> <b>impact</b> on women.", "dateLastCrawled": "2022-02-02T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Chapter Four: Racial, Ethnic, and Gender Disparities in Federal ...", "url": "https://www.ussc.gov/sites/default/files/pdf/research-and-publications/research-projects-and-surveys/miscellaneous/15-year-study/chap4.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ussc.gov/sites/default/files/pdf/research-and-publications/research...", "snippet": "<b>treatment</b> of individual offenders who are <b>similar</b> in relevant ways, or <b>similar</b> <b>treatment</b> of individual offenders who differ in characteristics that are relevant to the purposes of sentencing. Membership in a particular demographic group is not relevant to the purposes of sentencing, and there is no reason to expect\u2014and some might argue no to reason to care\u2014if the average sentence of different demographic groups are the same or different. As long as the individuals in each group are ...", "dateLastCrawled": "2022-02-02T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "fairMLHealth/Evaluating_Fairness.md at integration \u00b7 KenSciResearch ...", "url": "https://github.com/KenSciResearch/fairMLHealth/blob/integration/docs/resources/Evaluating_Fairness.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/KenSciResearch/fairMLHealth/blob/integration/docs/resources/...", "snippet": "Returning to the example: the <b>Disparate</b> <b>Impact</b> Ratio and Statistical Parity <b>Difference</b> are two related measures that compare the selection rates between the protected and unprotected groups. Although the <b>Disparate</b> <b>Impact</b> Ratio in our example is outside of the &quot;fair&quot; range for ratios (it&#39;s above 1.2), the Statistical Parity <b>Difference</b> is well within range for differences. We can see why more clearly by examining the Stratified Performance Table (also above). Here we see that the selection ...", "dateLastCrawled": "2022-02-02T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "When School Doesn&#39;t Seem <b>Fair, Students May Suffer Lasting Effects</b>", "url": "https://www.edweek.org/leadership/when-school-doesnt-seem-fair-students-may-suffer-lasting-effects/2017/02", "isFamilyFriendly": true, "displayUrl": "https://<b>www.edweek.org</b>/leadership/when-school-doesnt-seem-fair-students-may-suffer...", "snippet": "Students who perceive a lack of justice or <b>disparate</b> <b>treatment</b> for certain racial groups may respond with defiant behavior. And discipline for that behavior may cause them to become further ...", "dateLastCrawled": "2022-02-03T07:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Disparate Vulnerability: on the Unfairness of Privacy Attacks Against</b> ...", "url": "https://deepai.org/publication/disparate-vulnerability-on-the-unfairness-of-privacy-attacks-against-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>disparate-vulnerability-on-the-unfairness</b>-of-privacy...", "snippet": "First, we introduce a new notion: <b>disparate</b> vulnerability, which, similarly to <b>disparate</b> <b>impact</b> Feldman et al. (2015) and <b>disparate</b> mistreatment Zafar et al. (2017) in fairness, captures the differential <b>impact</b> that privacy attacks have on subgroups. We propose a framework to quantify <b>disparate</b> vulnerability in an efficient manner, i.e., without requiring iterative training and testing of expensive models.", "dateLastCrawled": "2021-12-07T12:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Sociology of Discrimination: Racial Discrimination in Employment ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2915460/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2915460", "snippet": "In defining racial discrimination, many scholars and legal advocates distinguish between differential <b>treatment</b> and <b>disparate</b> <b>impact</b>, creating a two-part definition: Differential <b>treatment</b> occurs when individuals are treated unequally because of their race. <b>Disparate</b> <b>impact</b> occurs when individuals are treated equally according to a given set of rules and procedures but when the latter are constructed in ways that favor members of one group over another ...", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Test fairness</b>", "url": "https://www.researchgate.net/publication/265086461_Test_fairness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/265086461_<b>Test_fairness</b>", "snippet": "<b>Disparate</b> <b>impact</b>, to give a simple example, <b>can</b> <b>be thought</b> of as the <b>difference</b> in average running speeds o ver a \ufb01 xed distance for two groups using an accurate stop-", "dateLastCrawled": "2022-01-30T03:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Health inequities and their causes</b>", "url": "https://www.who.int/news-room/facts-in-pictures/detail/health-inequities-and-their-causes", "isFamilyFriendly": true, "displayUrl": "https://<b>www.who.int</b>/news-room/facts-in-pictures/detail/<b>health-inequities-and-their-causes</b>", "snippet": "<b>Health inequities and their causes</b>. There is ample evidence that social factors, including education, employment status, income level, gender and ethnicity have a marked influence on how healthy a person is. In all countries \u2013 whether low-, middle- or high-income \u2013 there are wide disparities in the health status of different social groups.", "dateLastCrawled": "2022-02-03T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Fact Sheet: Racial Fairness in the Advisory Guidelines System", "url": "https://www.fd.org/sites/default/files/criminal_defense_topics/essential_topics/sentencing_resources/bookerfix_factsheet_3.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.fd.org/sites/default/files/criminal_defense_topics/essential_topics/...", "snippet": "Differences clearly <b>thought</b> to be unwarranted (e.g., by the offender\u2019s ... and has a racially <b>disparate</b> <b>impact</b>.8 After Booker, judges have been better able to compensate for unfair and unnecessarily harsh rules that create racial disparity. In fiscal year 2010, judges imposed below-guideline sentences in 26.5% of crack cases (a rate that would likely have been higher but for trumping mandatory minimums), and 79.8% of these offenders were African American. Only 4.5% of crack offenders ...", "dateLastCrawled": "2021-11-19T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "CONFAIR: Configurable and Interpretable Algorithmic Fairness | DeepAI", "url": "https://deepai.org/publication/confair-configurable-and-interpretable-algorithmic-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/confair-configurable-and-interpretable-algorithmic-fairness", "snippet": "The different definitions of statistical fairness lead to the evaluation of an algorithm\u2019s performance in fundamentally different ways. For instance, the <b>disparate</b> <b>impact</b> measures the ratio of true positive rates across groups while equal opportunity measures the <b>difference</b> between the true positive rates and false positive rates across groups with the restriction that they are less than a specified threshold. It has been shown that the different fairness metrics are often incompatible ...", "dateLastCrawled": "2022-01-22T16:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Nerdy comments about measuring disparate impact</b> | mathbabe", "url": "https://mathbabe.org/2015/10/07/nerdy-comments-about-measuring-disparate-impact/", "isFamilyFriendly": true, "displayUrl": "https://mathbabe.org/2015/10/07/<b>nerdy-comments-about-measuring-disparate-impact</b>", "snippet": "To begin to talk about measuring <b>disparate</b> <b>impact</b>, one needs to understand patterns by which measures tend to be affected by the frequency of an outcome, including the pattern whereby the rarer an outcome the greater tends to be the relative <b>difference</b> in experiencing it and the smaller tends to be the relative <b>difference</b> in avoiding it. Commonly observers measure <b>disparate</b> <b>impact</b> in terms of relative differences in favorable outcome like test passage (as with the four-fifths rule of the ...", "dateLastCrawled": "2022-01-19T08:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The 4 types of discrimination: what every employer needs to know | HR", "url": "https://www.hrsolutions-uk.com/4-types-of-discrimination/", "isFamilyFriendly": true, "displayUrl": "https://www.hrsolutions-uk.com/4-types-of-discrimination", "snippet": "A protected characteristic they are <b>thought</b> to possess, regardless of whether the perception is correct or not. This is direct discrimination by perception. Although there is normally a deliberate act or exclusion, direct discrimination does not have to be intentional. This means that even if discrimination occurred unintentionally, a claim <b>can</b> still succeed. 2) Indirect discrimination. Indirect discrimination is usually less obvious than direct discrimination and is normally unintended ...", "dateLastCrawled": "2022-02-02T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fairness metrics and bias mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "This <b>difference</b> \u03b4 <b>can</b> represent different types of <b>unfairness</b>, e.g., if \u03b4 is different for subgroups of users (thus indicating potential <b>unfairness</b> in predicted ratings). Assuming that the data used for training the recommender system is comparable to the test data/new data the recommender system is applied on, the ratings <b>can</b> be actively adjusted using the learned differences \u03b4 .", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "On Views of <b>Race and Inequality, Blacks and Whites Are</b> Worlds Apart ...", "url": "https://www.pewresearch.org/social-trends/2016/06/27/on-views-of-race-and-inequality-blacks-and-whites-are-worlds-apart/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pewresearch.org</b>/social-trends/2016/06/27/on", "snippet": "When asked specifically about the <b>impact</b> President Barack Obama has had on race relations in the U.S., a majority of Americans give the president credit for at least trying to make things better, but a quarter say he has made race relations worse. Blacks and whites differ significantly in their assessments. Some 51% of blacks say Obama has made progress toward improving race relations, and an additional 34% say he has tried but failed to make progress. Relatively few blacks (5%) say Obama ...", "dateLastCrawled": "2022-01-29T07:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What Is <b>The Difference Between Disparate Impact and Disparate Treatment</b> ...", "url": "https://rayneslaw.com/what-is-the-difference-between-disparate-impact-and-disparate-treatment-discrimination/", "isFamilyFriendly": true, "displayUrl": "https://rayneslaw.com/what-is-<b>the-difference-between-disparate-impact</b>-and-<b>disparate</b>-", "snippet": "<b>Disparate</b> <b>impact</b> refers to discrimination that is unintentional. The procedures are the same for everyone, but people in a protected class are negatively affected. For example, say that job applicants for a certain job are tested on their reaction times, and only people with a high score are hired. This test will discriminate against older workers, who are less likely to have fast reaction times. Whether this test is illegal will depend on whether fast reaction times are necessary for the ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "FairDEA\u2014Removing <b>disparate</b> <b>impact</b> from efficiency scores - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0377221721010092", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0377221721010092", "snippet": "<b>Disparate</b> <b>impact</b> <b>can</b> be presented in a different manner using a similar <b>unfairness</b> measure called ... r = 1 s u r d y r d \u2265 D I v i d \u2265 \u03f5, i = 1, \u2026, m \u2227 d = 1, \u2026, n u r d \u2265 \u03f5, r = 1, \u2026, s \u2227 d = 1, \u2026, n where D I represents a parameter of acceptable <b>disparate</b> <b>impact</b>, i.e. the average <b>difference</b> in efficiency scores between the unprivileged and privileged groups. For example, if an average <b>difference</b> of 5% was allowed in efficiency scores, then the value of the parameter ...", "dateLastCrawled": "2022-01-30T22:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The Sociology of Discrimination: Racial Discrimination in Employment ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2915460/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2915460", "snippet": "<b>Disparate</b> <b>impact</b> occurs when individuals are treated equally according to a given set of rules and procedures but when the latter are constructed in ways that favor members of one group over another (Reskin 1998, p. 32; National Research Council 2004, pp. 39\u201340). The second component of this definition broadens its scope to include decisions and processes that may not themselves have any explicit racial content but that have the consequence of producing or reinforcing racial disadvantage ...", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Health care disparities during the COVID-19 pandemic", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8349792/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8349792", "snippet": "Coronavirus disease 2019 (COVID-19), <b>caused</b> by severe acute respiratory syndrome coronavirus 2, is a pandemic with more than 32 million cases and more than 500,000 deaths nationwide. With the significant health consequences seen secondary to COVID-19, health care disparities have been further exacerbated. Mechanisms that have been proposed to account for the increased disparity seen during the COVID-19 pandemic are multifactorial. This review of the literature outlines the unique barriers to ...", "dateLastCrawled": "2022-02-03T02:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The <b>Impact</b> of <b>Data Preparation on the Fairness of Software Systems</b> | DeepAI", "url": "https://deepai.org/publication/the-impact-of-data-preparation-on-the-fairness-of-software-systems", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/the-<b>impact</b>-of-<b>data-preparation-on-the-fairness-of</b>...", "snippet": "We applied each data preparation technique individually to analyse the <b>difference</b> in predictive performance and fairness, using statistical parity <b>difference</b>, <b>disparate</b> <b>impact</b>, and the normalised prejudice index. The results show that fairness is affected by transformations made to the training data, particularly in imbalanced datasets. Removing the sensitive attribute is insufficient to eliminate all the <b>unfairness</b> in the predictions, as expected, but it is key to achieve fairer models ...", "dateLastCrawled": "2021-12-08T15:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Health inequities and their causes</b>", "url": "https://www.who.int/news-room/facts-in-pictures/detail/health-inequities-and-their-causes", "isFamilyFriendly": true, "displayUrl": "https://<b>www.who.int</b>/news-room/facts-in-pictures/detail/<b>health-inequities-and-their-causes</b>", "snippet": "<b>Health inequities and their causes</b>. There is ample evidence that social factors, including education, employment status, income level, gender and ethnicity have a marked influence on how healthy a person is. In all countries \u2013 whether low-, middle- or high-income \u2013 there are wide disparities in the health status of different social groups.", "dateLastCrawled": "2022-02-03T06:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Statistical Issues Arising in Disparate Impact</b> Cases and the Use of the ...", "url": "https://www.researchgate.net/publication/29654651_Statistical_Issues_Arising_in_Disparate_Impact_Cases_and_the_Use_of_the_Expectancy_Curve_in_Assessing_the_Validity_of_Pre-Employment_Tests", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/29654651_Statistical_Issues_Arising_in...", "snippet": "Then the observed number, O, of units with a significant disparity <b>can</b> <b>be compared</b> to E, to see whether data are consistent with a pattern, O close to E, indicating <b>unfairness</b> or O clearly less ...", "dateLastCrawled": "2021-12-24T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "fairMLHealth/Evaluating_Fairness.md at integration \u00b7 KenSciResearch ...", "url": "https://github.com/KenSciResearch/fairMLHealth/blob/integration/docs/resources/Evaluating_Fairness.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/KenSciResearch/fairMLHealth/blob/integration/docs/resources/...", "snippet": "And unawareness does not always reduce <b>Disparate</b> <b>Impact</b>; in fact it <b>can</b> increase it, as we showed in the KDD 2020 Tutorial which <b>compared</b> fairness relative to gender using this same general setup. This goes to say that the field has not yet found a panacea which <b>can</b> correct all fairness issues for every model, so it&#39;s important to test different approaches. Also remember to consider the effects of biased data collection processes or biased application of model results before deciding whether ...", "dateLastCrawled": "2022-02-02T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fairness metrics and bias mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "This <b>difference</b> \u03b4 <b>can</b> represent different types of <b>unfairness</b>, e.g., if \u03b4 is different for subgroups of users (thus indicating potential <b>unfairness</b> in predicted ratings). Assuming that the data used for training the recommender system is comparable to the test data/new data the recommender system is applied on, the ratings <b>can</b> be actively adjusted using the learned differences \u03b4 .", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Equal Pay</b> for Work of <b>Equal</b> Value | Labour Guide", "url": "https://labourguide.co.za/equal-pay-for-work-of-equal-value", "isFamilyFriendly": true, "displayUrl": "https://labourguide.co.za/<b>equal-pay</b>-for-work-of-<b>equal</b>-value", "snippet": "The \u2018 second stage\u2019 of the South African test \u2013 that is, the inquiry into \u2018<b>unfairness</b> \u2019 (discussed below) \u2013 corresponds to ascertaining whether discrimination is on a prohibited ground equivalent to those proscribed by the Convention. [Emphasis added]. The importance of Convention 111 as a point of reference in defining the meaning of \u2018discrimination\u2019 was accepted even prior to its ratification by South Africa in 1997. With the enactment of the EEA its status as a codified ...", "dateLastCrawled": "2022-01-30T06:22:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A New Metric for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare ...", "url": "https://towardsdatascience.com/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare-closedloop-ai-fc07b9c83487", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-new-metric-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "<b>Disparate</b> <b>impact</b> occurs when the predicted outcomes are different for different groups. Some examples of when this metric is used are recidivism[4], hiring[5][6], and loan applications[2]. This standard metric accounts for only one factor: the rate at which the algorithm predicts a person should benefit from a particular classification. In the context of healthcare, the standard of <b>disparate</b> <b>impact</b> is entirely inappropriate. The above examples have a common characteristic; every individual ...", "dateLastCrawled": "2022-01-17T14:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Assessing <b>Disparate</b> <b>Impact</b> of Personalized Interventions ...", "url": "https://par.nsf.gov/servlets/purl/10168517", "isFamilyFriendly": true, "displayUrl": "https://par.nsf.gov/servlets/purl/10168517", "snippet": "result in <b>disparate</b> <b>impact</b> (with regards to social welfare) for the same reasons that these disparities occur in <b>machine</b> <b>learning</b> classi\ufb01cation models [21]. (See Appendix C for an expanded discussion on our use of the term \u201c<b>disparate</b> <b>impact</b>.\u201d) However, in the problem of personalized interventions, the \u201cfundamental problem of causal inference,\u201d that outcomes are not observed for interventions not administered, poses a fundamental challenge for evaluating the fairness of any ...", "dateLastCrawled": "2022-01-20T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A New Metric for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare", "url": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "Often, the approach to fairness draws upon the legal standard of <b>disparate</b> <b>impact</b>[2][3]. <b>Disparate</b> <b>impact</b> occurs when the predicted outcomes are different for different groups. Some examples of when this metric is used are recidivism[4], hiring[5][6], and loan applications[2]. This standard metric accounts for only one factor: the rate at which the algorithm predicts a person should benefit from a particular classification.", "dateLastCrawled": "2022-02-01T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine learning</b>, artificial neural networks and social research ...", "url": "https://link.springer.com/article/10.1007/s11135-020-01037-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11135-020-01037-y", "snippet": "<b>Machine learning</b> (ML), and particularly algorithms based on artificial neural networks (ANNs), constitute a field of research lying at the intersection of different disciplines such as mathematics, statistics, computer science and neuroscience. This approach is characterized by the use of algorithms to extract knowledge from large and heterogeneous data sets. In addition to offering a brief introduction to ANN algorithms-based ML, in this paper we will focus our attention on its possible ...", "dateLastCrawled": "2022-01-27T04:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Feature Engineering for Machine Learning</b>: Why and How | by ...", "url": "https://medium.com/analytics-vidhya/feature-engineering-for-machine-learning-stem-to-shtem-submission-76903112e437", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>feature-engineering-for-machine-learning</b>-stem-to...", "snippet": "Here\u2019s a simple <b>analogy</b>: a student named Timmy, analogous to a supervised <b>machine</b> <b>learning</b> model, has spent the last few weeks studying for a math test so that he can answer questions correctly ...", "dateLastCrawled": "2021-09-13T20:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Removing <b>Disparate</b> <b>Impact</b> on Model Accuracy in Differentially Private ...", "url": "https://www.researchgate.net/publication/353907927_Removing_Disparate_Impact_on_Model_Accuracy_in_Differentially_Private_Stochastic_Gradient_Descent", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353907927_Removing_<b>Disparate</b>_<b>Impact</b>_on_Model...", "snippet": "<b>Machine</b> <b>learning</b> is a tool for building models that accurately represent input training data. When undesired biases concerning demographic groups are in the training data, well-trained models will ...", "dateLastCrawled": "2022-01-28T09:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Responsible machine learning</b> protects intellectual property | World ...", "url": "https://www.weforum.org/agenda/2021/03/responsible-machine-learning-that-protects-intellectual-property/", "isFamilyFriendly": true, "displayUrl": "https://www.weforum.org/agenda/2021/03/<b>responsible-machine-learning</b>-that-protects...", "snippet": "Given <b>machine</b> <b>learning</b>\u2019s complexity and interdisciplinary nature, executives should employ a wide variety of approaches to manage the associated risks, which include building risk management into model development and applying holistic risk frameworks that leverage and adapt principles used in managing other types of enterprise risk. Executives must also simply step back regularly to consider the broad implications for employees and society when using ML.", "dateLastCrawled": "2022-01-29T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Learning is Popular</b> Right Now", "url": "https://machinelearningmastery.com/machine-learning-is-popular/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>machine-learning-is-popular</b>", "snippet": "Abundant and cheap computation has driven the abundance of data we are collecting and the increase in capability of <b>machine learning</b> methods. In this post you learned that <b>machine learning is popular</b> now for three reasons: The field has matured both in terms of identity and in terms of methods and tools. There is an abundance of data to learn from.", "dateLastCrawled": "2022-02-03T09:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Structural disconnects between algorithmic decision-making</b> and the law ...", "url": "https://blogs.icrc.org/law-and-policy/2019/04/25/structural-disconnects-algorithmic-decision-making-law/", "isFamilyFriendly": true, "displayUrl": "https://blogs.icrc.org/law-and-policy/2019/04/25/structural-disconnects-algorithmic...", "snippet": "And the definition of \u2018works\u2019 is based on (in the case of <b>machine</b> <b>learning</b>) compliance with some prespecified examples of scenarios that \u2018work\u2019 and scenarios that \u2018don\u2019t\u2019. To use a legal <b>analogy</b>, this would be analogous to defining a fair decision by coming up with a rule based on past decisions that someone decided were \u2018right\u2019 or \u2018wrong\u2019 based on past outcomes. In one sense this is entirely circular: we are deciding what is \u2018right\u2019 based on someone deciding what ...", "dateLastCrawled": "2022-01-25T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Data lineage: Making artificial intelligence smarter</b> | <b>SAS</b> India", "url": "https://www.sas.com/en_in/insights/articles/data-management/data-lineage--making-artificial-intelligence-smarter.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.sas.com</b>/en_in/insights/articles/data-management/data-lineage--making...", "snippet": "Data lineage enables you to trace data quality issues and other errors back to their root cause and perform <b>impact</b> analysis on proposed changes. As it links data in <b>disparate</b> systems at a logical level by showing how metadata is connected, data lineage helps identify business rule discrepancies and data incompleteness. Data lineage also helps data stewards react to issues before they become a problem, define strategies for data quality improvement and promote effective reuse of existing ...", "dateLastCrawled": "2022-01-30T19:31:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(disparate impact)  is like +(unfairness caused by a difference in treatment)", "+(disparate impact) is similar to +(unfairness caused by a difference in treatment)", "+(disparate impact) can be thought of as +(unfairness caused by a difference in treatment)", "+(disparate impact) can be compared to +(unfairness caused by a difference in treatment)", "machine learning +(disparate impact AND analogy)", "machine learning +(\"disparate impact is like\")", "machine learning +(\"disparate impact is similar\")", "machine learning +(\"just as disparate impact\")", "machine learning +(\"disparate impact can be thought of as\")", "machine learning +(\"disparate impact can be compared to\")"]}