{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "SomaticCombiner: improving the performance of somatic variant calling ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393490/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7393490", "snippet": "For the ensemble evaluations, we first investigated whether a simple majority voting process can <b>improve</b> the performance in WGS <b>data</b>. For SNV calling, we used two caller sets with stringent cutoffs in each: one used four callers (LoFreq, MuSE, MuTect2 and Strelka) with called by (&gt; = 2) and (&gt; = 3) callers as two cutoffs; the other used seven callers (LoFreq, MuSE, MuTect2, SomaticSniper, Strelka, VarDict and VarScan) with cutoffs when called by (&gt; = 3) and (&gt; = 4) callers. We also included ...", "dateLastCrawled": "2022-01-06T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "3.1. <b>Cross-validation</b>: evaluating estimator performance \u2014 scikit-learn ...", "url": "https://scikit-learn.org/stable/modules/cross_validation.html", "isFamilyFriendly": true, "displayUrl": "https://scikit-learn.org/stable/modules/<b>cross_validation</b>.html", "snippet": "While <b>i.i.d</b>. <b>data</b> is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it is safer to use a time-series aware <b>cross-validation</b> scheme. Similarly, if we know that the generative process has a group structure (samples collected from different subjects, experiments, measurement devices), it is safer to use group-wise <b>cross-validation</b>. 3.1.2.1.1. K-fold\u00b6 KFold divides all the samples in ...", "dateLastCrawled": "2022-02-02T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Why Global Artificial Intelligence is the Next Big Thing", "url": "https://www.bbntimes.com/science/why-global-artificial-intelligence-is-the-next-big-thing", "isFamilyFriendly": true, "displayUrl": "https://www.bbntimes.com/science/why-global-artificial-intelligence-is-the-next-big-thing", "snippet": "In general, Narrow ML/AI systems work by inputting large amounts of labelled training <b>data</b>, analyzing the <b>data</b> for correlations and patterns, and using these patterns to output <b>predictions</b> about <b>future</b> states. NAI requires a large corpora of examples by training its ML models to encode the general distribution of the problem into its parameters on a specialized hardware and software for writing and training machine learning algorithms in terms of high-level programming language such as ...", "dateLastCrawled": "2022-01-26T08:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Class-incremental learning: survey and performance evaluation</b>", "url": "https://www.researchgate.net/publication/344971212_Class-incremental_learning_survey_and_performance_evaluation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344971212_Class-incremental_learning_survey...", "snippet": "For <b>future</b> learning systems incremental learning is desirable, because it allows for: efficient resource usage by eliminating the need to retrain from scratch at the arrival of new <b>data</b>; reduced ...", "dateLastCrawled": "2022-01-29T22:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Time Series Recipe - Retail Sales Forecasting", "url": "https://h2oai.github.io/tutorials/time-series-recipe-retail-sales-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://h2oai.github.io/tutorials/time-series-recipe-retail-sales-forecasting", "snippet": "The periodicity of updating the <b>data</b> may require model <b>predictions</b> to account for a significant time in the <b>future</b>. In an ideal world where <b>data</b> can be updated very quickly, <b>predictions</b> can always be made having the most recent <b>data</b> available. In this scenario, there is no need for a model to predict cases that are well into the <b>future</b> but instead focus on maximizing its ability to predict the short term. However, this is not always the case, and a model needs to be able to make <b>predictions</b> ...", "dateLastCrawled": "2022-02-03T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Time Series Analysis for Business Forecasting", "url": "https://home.ubalt.edu/ntsbarsh/Business-stat/STAT-DATA/Forecast.htm", "isFamilyFriendly": true, "displayUrl": "https://home.ubalt.edu/ntsbarsh/Business-stat/STAT-<b>DATA</b>/Forecast.htm", "snippet": "Either the estimate of <b>future</b> value is based on an analysis of factors which are believed to influence <b>future</b> values, i.e., the explanatory method, or else the prediction is based on an inferred study of <b>past</b> general <b>data</b> behavior over time, i.e., the extrapolation method. For example, the belief that the sale of doll clothing will increase from current levels because of a recent advertising blitz rather than proximity to Christmas illustrates the difference between the two philosophies. It ...", "dateLastCrawled": "2022-01-29T14:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Techniques for Time Series Prediction</b>", "url": "https://iq.opengenus.org/time-series-prediction-techniques/", "isFamilyFriendly": true, "displayUrl": "https://iq.opengenus.org/time-series-prediction-techniques", "snippet": "We have covered different <b>techniques for Time series prediction</b> which involves using Artificial Neural Networks <b>like</b> Single Layer NN, RNN, LSTM, using Stochastic models <b>like</b> ARMA, ARIMA, SAIMA and using Support Vector Machines. \u00d7. Home Discussions Write at Opengenus IQ. \u00d7 \u2630 RANDOM; Join our Internship \ud83c\udf93; 100+ Graph Algorithms; 100+ DP Problems; 50+ Linked List Problems; 50+ Array Problems; One Liner; 50+ Binary Tree problems #7daysOfCode; Linux \ud83d\udcbd; \ud83d\udd0a <b>Data</b> Structures; Graph ...", "dateLastCrawled": "2022-01-31T15:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "On climate prediction: how much can we expect from <b>climate memory</b> ...", "url": "https://link.springer.com/article/10.1007/s00382-018-4168-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00382-018-4168-5", "snippet": "In view of the non-negligible contributions of <b>climate memory</b> to climate variability, our work emphasized the importance of <b>past</b> climate states in <b>future</b> climate <b>predictions</b>. Similar to the concept \u201cinertia\u201d in physics, long-term <b>climate memory</b> is a measure in climate science that quantifies how <b>past</b> climate states are memorized. Traditionally, for processes with memory (or auto-correlation), the simplest prediction method is linear extrapolation, while the widely used methods are ...", "dateLastCrawled": "2021-12-17T01:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Generalization</b> - Patterns, <b>Predictions</b>, and Actions", "url": "https://mlstory.org/generalization.html", "isFamilyFriendly": true, "displayUrl": "https://mlstory.org/<b>generalization</b>.html", "snippet": "However, <b>past</b> a certain point the risk begins to increase again, while empirical risk decreases. Traditional view of <b>generalization</b>. The graphic shown in many textbooks is a u-shaped risk curve. The complexity range below the minimum of the curve is called underfitting. The range above is called overfitting. This picture is often justified using the bias-variance trade-off, motivated by a least squares regression analysis. However, it does not seem to bear much resemblance to what is ...", "dateLastCrawled": "2022-01-30T00:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "prediction - How can I go about applying machine learning algorithms to ...", "url": "https://quant.stackexchange.com/questions/111/how-can-i-go-about-applying-machine-learning-algorithms-to-stock-markets", "isFamilyFriendly": true, "displayUrl": "https://quant.stackexchange.com/questions/111/how-can-i-go-about-applying-machine...", "snippet": "If there is historical <b>data</b> available (so-called training or in-sample <b>data</b>) and you would <b>like</b> to feed that into the algorithm to get back for outputs parameters that, when applied to unseen, <b>future</b> <b>data</b> (called testing or out-of-sample <b>data</b>), make quantitative <b>predictions</b>, then this is called &quot;supervised learning&quot; and you would want to look for supervised learning models from machine learning to solve the problem.", "dateLastCrawled": "2022-01-24T21:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "SomaticCombiner: improving the performance of somatic variant calling ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393490/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7393490", "snippet": "For the ensemble evaluations, we first investigated whether a simple majority voting process can <b>improve</b> the performance in WGS <b>data</b>. For SNV calling, we used two caller sets with stringent cutoffs in each: one used four callers (LoFreq, MuSE, MuTect2 and Strelka) with called by (&gt; = 2) and (&gt; = 3) callers as two cutoffs; the other used seven callers (LoFreq, MuSE, MuTect2, SomaticSniper, Strelka, VarDict and VarScan) with cutoffs when called by (&gt; = 3) and (&gt; = 4) callers. We also included ...", "dateLastCrawled": "2022-01-06T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Just-in-Time but Not Too Much: Determining Treatment Timing in Mobile ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6380673/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6380673", "snippet": "3. <b>DATA</b> COLLECTED FROM WEARABLE DEVICES. Write the user\u2019s longitudinal <b>data</b> recorded via mobile devices as the sequence {O 0, O 1, A 1, O 2, \u2026, O t, A t, O t + 1, \u2026}, where t indexes regularly-spaced times (e.g., every minute, five-minutes, thirty-minutes, hour, etc.); O 0 contains the baseline information; the observation O t (t \u2265 1) is the vector of sensed and self-report observations collected between time t \u2212 1 and t; and A t is the treatment at time t.Choice of time-scale is ...", "dateLastCrawled": "2021-12-15T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Why Global Artificial Intelligence is the Next Big Thing", "url": "https://www.bbntimes.com/science/why-global-artificial-intelligence-is-the-next-big-thing", "isFamilyFriendly": true, "displayUrl": "https://www.bbntimes.com/science/why-global-artificial-intelligence-is-the-next-big-thing", "snippet": "In general, Narrow ML/AI systems work by inputting large amounts of labelled training <b>data</b>, analyzing the <b>data</b> for correlations and patterns, and using these patterns to output <b>predictions</b> about <b>future</b> states. NAI requires a large corpora of examples by training its ML models to encode the general distribution of the problem into its parameters on a specialized hardware and software for writing and training machine learning algorithms in terms of high-level programming language such as ...", "dateLastCrawled": "2022-01-26T08:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Techniques for Time Series Prediction</b>", "url": "https://iq.opengenus.org/time-series-prediction-techniques/", "isFamilyFriendly": true, "displayUrl": "https://iq.opengenus.org/time-series-prediction-techniques", "snippet": "Auto Regressive Integrated Moving Average(ARIMA) models explains a given time series <b>data</b> based on its <b>past</b> values, lagged errors and crust and troughs and uses that equation to predict <b>future</b> values. Any time series which is non-seasonal can be modeled using ARIMA models.An ARIMA model is characterized by 3 terms: p, d, q where, p is the order of the AR term. q is the order of the MA term. d is the number of differencing required to make the time series stationary The first step of ARIMA ...", "dateLastCrawled": "2022-01-31T15:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Contrastive Representation Learning", "url": "https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html", "isFamilyFriendly": true, "displayUrl": "https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html", "snippet": "The main idea of <b>contrastive learning</b> is to learn representations such that <b>similar</b> samples stay close to each other, while dissimilar ones are far apart. <b>Contrastive learning</b> can be applied to both supervised and unsupervised <b>data</b> and has been shown to achieve good performance on a variety of vision and language tasks. Lil&#39;Log \uf984 Contact FAQ \u231b Archive. Contrastive Representation Learning. May 31, 2021 by Lilian Weng representation-learning long-read language-model unsupervised-learning ...", "dateLastCrawled": "2022-02-02T19:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Time Series Recipe - Retail Sales Forecasting", "url": "https://h2oai.github.io/tutorials/time-series-recipe-retail-sales-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://h2oai.github.io/tutorials/time-series-recipe-retail-sales-forecasting", "snippet": "The periodicity of updating the <b>data</b> may require model <b>predictions</b> to account for a significant time in the <b>future</b>. In an ideal world where <b>data</b> can be updated very quickly, <b>predictions</b> can always be made having the most recent <b>data</b> available. In this scenario, there is no need for a model to predict cases that are well into the <b>future</b> but instead focus on maximizing its ability to predict the short term. However, this is not always the case, and a model needs to be able to make <b>predictions</b> ...", "dateLastCrawled": "2022-02-03T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "3.1. <b>Cross-validation</b>: evaluating estimator performance \u2014 scikit-learn ...", "url": "https://scikit-learn.org/stable/modules/cross_validation.html", "isFamilyFriendly": true, "displayUrl": "https://scikit-learn.org/stable/modules/<b>cross_validation</b>.html", "snippet": "3.1. <b>Cross-validation</b>: evaluating estimator performance\u00b6. Learning the parameters of a prediction function and testing it on the same <b>data</b> is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen <b>data</b>.", "dateLastCrawled": "2022-02-02T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "prediction - How can I go about applying machine learning algorithms to ...", "url": "https://quant.stackexchange.com/questions/111/how-can-i-go-about-applying-machine-learning-algorithms-to-stock-markets", "isFamilyFriendly": true, "displayUrl": "https://quant.stackexchange.com/questions/111/how-can-i-go-about-applying-machine...", "snippet": "If there is historical <b>data</b> available (so-called training or in-sample <b>data</b>) and you would like to feed that into the algorithm to get back for outputs parameters that, when applied to unseen, <b>future</b> <b>data</b> (called testing or out-of-sample <b>data</b>), make quantitative <b>predictions</b>, then this is called &quot;supervised learning&quot; and you would want to look for supervised learning models from machine learning to solve the problem.", "dateLastCrawled": "2022-01-24T21:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Time Series Analysis for Business Forecasting", "url": "https://home.ubalt.edu/ntsbarsh/Business-stat/STAT-DATA/Forecast.htm", "isFamilyFriendly": true, "displayUrl": "https://home.ubalt.edu/ntsbarsh/Business-stat/STAT-<b>DATA</b>/Forecast.htm", "snippet": "Either the estimate of <b>future</b> value is based on an analysis of factors which are believed to influence <b>future</b> values, i.e., the explanatory method, or else the prediction is based on an inferred study of <b>past</b> general <b>data</b> behavior over time, i.e., the extrapolation method. For example, the belief that the sale of doll clothing will increase from current levels because of a recent advertising blitz rather than proximity to Christmas illustrates the difference between the two philosophies. It ...", "dateLastCrawled": "2022-01-29T14:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Class-incremental learning: survey and performance evaluation</b>", "url": "https://www.researchgate.net/publication/344971212_Class-incremental_learning_survey_and_performance_evaluation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344971212_Class-incremental_learning_survey...", "snippet": "For <b>future</b> learning systems incremental learning is desirable, because it allows for: efficient resource usage by eliminating the need to retrain from scratch at the arrival of new <b>data</b>; reduced ...", "dateLastCrawled": "2022-01-29T22:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Bounded Rationality</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/bounded-rationality/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/<b>bounded-rationality</b>", "snippet": "This effect is <b>thought</b> to explain the gambler\u2019s fallacy, the false belief that a run of heads from an <b>i.i.d</b>. sequence of fair coin tosses will make the next flip more likely to land tails. Hahn and Warren argue that the limited nature of people\u2019s experiences with random sequences is a better explanation than to view them as cognitive deficiencies. Specifically, people only ever experience finite sequence of outputs from a randomizer, such as a sequence of fair coin tosses, and the limits ...", "dateLastCrawled": "2022-02-03T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Causality for Machine Learning", "url": "https://ff13.fastforwardlabs.com/", "isFamilyFriendly": true, "displayUrl": "https://ff13.fastforwardlabs.com", "snippet": "That performance is gained by exploiting subtle correlations in the <b>data</b>. To understand the <b>predictions</b> made, we apply LIME. This returns a feature importance at the local level: which features contributed to each individual prediction. To accompany the analysis, we built Refractor, an interface for exploring the feature importances. Examining these is interesting, and highlights the factors that are correlated with a customer being likely to churn. Refractor suggests which features most ...", "dateLastCrawled": "2022-02-01T19:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Contrastive Representation Learning", "url": "https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html", "isFamilyFriendly": true, "displayUrl": "https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html", "snippet": "Using contrastive objective instead of trying to predict the exact words associated with images (i.e. a method commonly adopted by image caption prediction tasks) <b>can</b> further <b>improve</b> the <b>data</b> efficiency another 4x. Fig. 18. Using bag-of-words text encoding and contrastive training objectives <b>can</b> bring in multiple folds of <b>data</b> efficiency ...", "dateLastCrawled": "2022-02-02T19:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Introduction to <b>linear regression</b> analysis", "url": "https://people.duke.edu/~rnau/regintro.htm", "isFamilyFriendly": true, "displayUrl": "https://people.duke.edu/~rnau/regintro.htm", "snippet": "<b>Linear regression</b> analysis is the most widely used of all statistical techniques: it is the study of linear, additive relationships between variables. Let Y denote the \u201cdependent\u201d variable whose values you wish to predict, and let X 1, \u2026,X k denote the \u201cindependent\u201d variables from which you wish to predict it, with the value of variable X i in period t (or in row t of the <b>data</b> set) denoted by X it. Then the equation for computing the predicted value of Y t is:. This formula has the ...", "dateLastCrawled": "2022-02-03T03:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Frontiers | The Role of Machine Learning in Knowledge-Based Response ...", "url": "https://www.frontiersin.org/articles/10.3389/fonc.2018.00266/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fonc.2018.00266", "snippet": "The proposed KBR-ART framework <b>can</b> <b>be thought</b> of as being comprised of four ... beyond such simple formalisms. Therefore, more <b>data</b>-driven approaches are being sought to achieve more accurate <b>predictions</b> of TCP/NTCP. 3.2. <b>Data</b>-Driven Models. By definition, <b>data</b>-driven models are approximations built based on observation of <b>data</b>. However, one drawback is that such modeling is likely not unique even from the same dataset and, therefore, one needs to choose a suitable technique that fits one ...", "dateLastCrawled": "2022-01-29T22:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Why Global Artificial Intelligence is the Next Big Thing", "url": "https://www.bbntimes.com/science/why-global-artificial-intelligence-is-the-next-big-thing", "isFamilyFriendly": true, "displayUrl": "https://www.bbntimes.com/science/why-global-artificial-intelligence-is-the-next-big-thing", "snippet": "In general, Narrow ML/AI systems work by inputting large amounts of labelled training <b>data</b>, analyzing the <b>data</b> for correlations and patterns, and using these patterns to output <b>predictions</b> about <b>future</b> states. NAI requires a large corpora of examples by training its ML models to encode the general distribution of the problem into its parameters on a specialized hardware and software for writing and training machine learning algorithms in terms of high-level programming language such as ...", "dateLastCrawled": "2022-01-26T08:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Preregistration: what\u2019s</b> in it for you? | Statistical Modeling, Causal ...", "url": "https://statmodeling.stat.columbia.edu/2014/03/10/preregistration-whats/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2014/03/10/<b>preregistration-whats</b>", "snippet": "Splitting the <b>data</b> <b>can</b> work but sometimes in political science the datasets are small and we <b>can</b>\u2019t afford to split. Also often the <b>data</b> are public so you <b>can</b>\u2019t really hide any of the <b>data</b>. In such settings (and more generally) I think a better approach is to analyze all the <b>data</b> (as discussed in my paper with Jennifer and Masanao) and do partial pooling of all the estimates. I much prefer this to performing a single estimate and then giving it a flat prior that I don\u2019t believe. That ...", "dateLastCrawled": "2022-01-22T18:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Time Series Analysis for Business Forecasting", "url": "https://home.ubalt.edu/ntsbarsh/Business-stat/STAT-DATA/Forecast.htm", "isFamilyFriendly": true, "displayUrl": "https://home.ubalt.edu/ntsbarsh/Business-stat/STAT-<b>DATA</b>/Forecast.htm", "snippet": "Either the estimate of <b>future</b> value is based on an analysis of factors which are believed to influence <b>future</b> values, i.e., the explanatory method, or else the prediction is based on an inferred study of <b>past</b> general <b>data</b> behavior over time, i.e., the extrapolation method. For example, the belief that the sale of doll clothing will increase from current levels because of a recent advertising blitz rather than proximity to Christmas illustrates the difference between the two philosophies. It ...", "dateLastCrawled": "2022-01-29T14:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep Reinforcement Learning Hands-On - Second Edition | Packt", "url": "https://www.packtpub.com/product/deep-reinforcement-learning-hands-on/9781838826994", "isFamilyFriendly": true, "displayUrl": "https://www.packtpub.com/product/deep-reinforcement-learning-hands-on/9781838826994", "snippet": "Deep Reinforcement Learning Hands-On - Second Edition. 3.7 (6 reviews total) By Maxim Lapan. $5/mo for 5 months Subscribe Access now. $39.99 Print + eBook Buy. $5.00 Was 27.99 eBook Buy. Advance your knowledge in tech with a Packt subscription. Instant online access to over 7,500+ books and videos.", "dateLastCrawled": "2022-01-28T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A new <b>transfer learning framework with application to</b> model-agnostic ...", "url": "https://link.springer.com/article/10.1007/s10115-016-0926-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10115-016-0926-z", "snippet": "The experiments with synthetic <b>data</b> enables us to control the <b>data</b> generation process and thus helps <b>studying</b> the behavior of the proposed ssMTTL vis-\u00e0-vis other MTL methods. The experiments using real <b>data</b> demonstrate the effectiveness of the ssMTTL for MTL on real-world problems. We compare ssMTTL with a variety of relevant baselines and validate its effectiveness for both classification and regression problems.", "dateLastCrawled": "2021-10-13T20:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "3.1. <b>Cross-validation</b>: evaluating estimator performance \u2014 scikit-learn ...", "url": "https://scikit-learn.org/stable/modules/cross_validation.html", "isFamilyFriendly": true, "displayUrl": "https://scikit-learn.org/stable/modules/<b>cross_validation</b>.html", "snippet": "While <b>i.i.d</b>. <b>data</b> is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it is safer to use a time-series aware <b>cross-validation</b> scheme. Similarly, if we know that the generative process has a group structure (samples collected from different subjects, experiments, measurement devices), it is safer to use group-wise <b>cross-validation</b>. 3.1.2.1.1. K-fold\u00b6 KFold divides all the samples in ...", "dateLastCrawled": "2022-02-02T22:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "SomaticCombiner: improving the performance of somatic variant calling ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393490/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7393490", "snippet": "Our tests have demonstrated that two ensemble settings <b>can</b> <b>improve</b> performance for somatic SNV calling, i.e., the VAF adaptive consensus approach with four callers (LoFreq, MuTect2, Strelka and VarDict) for deep targeted sequencing and WES <b>data</b> and the regular majority voting with four callers (LoFreq, MuSE, MuTect2 and Strelka) for WGS datasets. For INDEL calling, we recommend using the majority voting with three callers (LoFreq, MuTect2 and VarDict) for deep targeted sequencing and WES ...", "dateLastCrawled": "2022-01-06T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Just-in-Time but Not Too Much: Determining Treatment Timing in Mobile ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6380673/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6380673", "snippet": "3. <b>DATA</b> COLLECTED FROM WEARABLE DEVICES. Write the user\u2019s longitudinal <b>data</b> recorded via mobile devices as the sequence {O 0, O 1, A 1, O 2, \u2026, O t, A t, O t + 1, \u2026}, where t indexes regularly-spaced times (e.g., every minute, five-minutes, thirty-minutes, hour, etc.); O 0 contains the baseline information; the observation O t (t \u2265 1) is the vector of sensed and self-report observations collected between time t \u2212 1 and t; and A t is the treatment at time t.Choice of time-scale is ...", "dateLastCrawled": "2021-12-15T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "One\u2010day ahead wind <b>speed/power prediction</b> based on polynomial ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-rpg.2016.0972", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-rpg.2016.0972", "snippet": "The non-linear LS (NLS) estimation generates optimal PAR coefficient estimates under the assumption that the excitation, , are <b>i.i.d</b>. Gaussian random variables.PAR model coefficients, which are defined in have been estimated by using the training <b>data</b> for all <b>data</b> sets by employing the NLS method, since the <b>data</b> matrix X includes polynomial products of <b>past</b> <b>data</b> samples. Under the assumption that the model orders p and k are known initially, NLS estimates of PAR model coefficients by []", "dateLastCrawled": "2022-01-26T23:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Class-incremental learning: survey and performance evaluation</b>", "url": "https://www.researchgate.net/publication/344971212_Class-incremental_learning_survey_and_performance_evaluation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/344971212_Class-incremental_learning_survey...", "snippet": "For <b>future</b> learning systems incremental learning is desirable, because it allows for: efficient resource usage by eliminating the need to retrain from scratch at the arrival of new <b>data</b>; reduced ...", "dateLastCrawled": "2022-01-29T22:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Techniques for Time Series Prediction</b>", "url": "https://iq.opengenus.org/time-series-prediction-techniques/", "isFamilyFriendly": true, "displayUrl": "https://iq.opengenus.org/time-series-prediction-techniques", "snippet": "In the above model we are using two bidirectional LSTM layers of 32 neurons each along with the dense layer with 1 output. Bidirectional LSTMs are able to update weights in both direction and <b>can</b> not only pass previous information to forecast <b>future</b> values but <b>can</b> also pass values in the <b>past</b> to forecast the missing time series <b>data</b> values.", "dateLastCrawled": "2022-01-31T15:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Time Series Recipe - Retail Sales Forecasting", "url": "https://h2oai.github.io/tutorials/time-series-recipe-retail-sales-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://h2oai.github.io/tutorials/time-series-recipe-retail-sales-forecasting", "snippet": "The periodicity of updating the <b>data</b> may require model <b>predictions</b> to account for a significant time in the <b>future</b>. In an ideal world where <b>data</b> <b>can</b> be updated very quickly, <b>predictions</b> <b>can</b> always be made having the most recent <b>data</b> available. In this scenario, there is no need for a model to predict cases that are well into the <b>future</b> but instead focus on maximizing its ability to predict the short term. However, this is not always the case, and a model needs to be able to make <b>predictions</b> ...", "dateLastCrawled": "2022-02-03T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Contrastive Representation Learning", "url": "https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html", "isFamilyFriendly": true, "displayUrl": "https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html", "snippet": "Using contrastive objective instead of trying to predict the exact words associated with images (i.e. a method commonly adopted by image caption prediction tasks) <b>can</b> further <b>improve</b> the <b>data</b> efficiency another 4x. Fig. 18. Using bag-of-words text encoding and contrastive training objectives <b>can</b> bring in multiple folds of <b>data</b> efficiency ...", "dateLastCrawled": "2022-02-02T19:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "prediction - How <b>can</b> I go about applying machine learning algorithms to ...", "url": "https://quant.stackexchange.com/questions/111/how-can-i-go-about-applying-machine-learning-algorithms-to-stock-markets", "isFamilyFriendly": true, "displayUrl": "https://quant.stackexchange.com/questions/111/how-<b>can</b>-i-go-about-applying-machine...", "snippet": "If there is historical <b>data</b> available (so-called training or in-sample <b>data</b>) and you would like to feed that into the algorithm to get back for outputs parameters that, when applied to unseen, <b>future</b> <b>data</b> (called testing or out-of-sample <b>data</b>), make quantitative <b>predictions</b>, then this is called &quot;supervised learning&quot; and you would want to look for supervised learning models from machine learning to solve the problem.", "dateLastCrawled": "2022-01-24T21:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Rising Stars in <b>Data</b> Science | DSI", "url": "http://datascience.uchicago.edu/rising-stars/", "isFamilyFriendly": true, "displayUrl": "<b>data</b>science.uchicago.edu/rising-stars", "snippet": "In this talk, I will present a <b>data</b> science research program demonstrating how we <b>can</b> bring digitally invisible communities to the center of designing <b>data</b>-intensive public interest computing systems for collaborative public policy decision-making concerning sustainable development. During the talk, I will discuss resilience and adaptation mechanisms required to address climate disasters and agricultural market failures that have led to over 300000 farmer suicides, food systems crises, and ...", "dateLastCrawled": "2022-01-02T14:39:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Learning</b>? <b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "<b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b> Chapter 18.1, 18.2, 18.8.1 and \u201cIntroduction to Statistical <b>Machine</b> <b>Learning</b>\u201d 1 What is <b>Learning</b>? \u2022\u201c<b>Learning</b> is making useful changes in our minds\u201d \u2013Marvin Minsky \u2022\u201c<b>Learning</b> is constructing or modifying representations of what is being experienced\u201c \u2013RyszardMichalski \u2022\u201c<b>Learning</b> denotes changes in a system that ... enable a system to do the same task more efficiently the next time\u201d \u2013Herbert Simon 3 Why do Mach", "dateLastCrawled": "2022-02-03T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~bgibson/cs540/handouts/learning_intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~bgibson/cs540/handouts/<b>learning</b>_intro.pdf", "snippet": "<b>learning</b> process \u2022x i = (x i1, . . . , x iD) \u2022Assume these instances are sampled independently from an unknown (population) distribution, P(x) \u2022We denote this by x i \u223c P(x), where <b>i.i.d</b>. stands for independent and identically distributed <b>i.i.d</b>. Training Sample \u2022A training sample is the \u201cexperience\u201d given to a <b>learning</b> algorithm", "dateLastCrawled": "2021-08-25T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "11._Intro_to_<b>Machine</b>_<b>Learning</b>.pdf - CMPSC 442 Artificial Intelligence ...", "url": "https://www.coursehero.com/file/121916721/11-Intro-to-Machine-Learningpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/121916721/11-Intro-to-<b>Machine</b>-<b>Learning</b>pdf", "snippet": "Outline Data-Driven Problem Solving Types of <b>Machine</b> <b>Learning</b> <b>I.I.D</b> Assumption and Generalization The Fundamental Tradeoff between Bias and Variance Bias and Variance Overfitting and Underfitting Regularization Hyperparameters, Three-fold split, Cross-Validation Example of Polynomial Regression 2. Minimum Spanning Tree A classical problem in algorithm design: Minimum Spanning Tree Input: A graph with cost for edges Output: A spanning tree with minimum cost Prim&#39;s algorithm, Kruskal&#39;s ...", "dateLastCrawled": "2022-01-15T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> for Drug <b>Discovery</b> in a Nutshell \u2014 Part I | by Stefan ...", "url": "https://medium.com/atomwise/machine-learning-for-drug-discovery-in-a-nutshell-part-i-24ae3f65c135", "isFamilyFriendly": true, "displayUrl": "https://medium.com/atomwise/<b>machine</b>-<b>learning</b>-for-drug-<b>discovery</b>-in-a-nutshell-part-i...", "snippet": "Classical <b>machine</b> <b>learning</b> literature spends little attention to this aspect. Most often, the underlying assumption is that training and test examples are drawn <b>i.i.d</b>. from the same distribution ...", "dateLastCrawled": "2022-01-26T14:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Lecture 16: Reinforcement <b>Learning</b>, Part 1 | Lecture Videos | <b>Machine</b> ...", "url": "https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s897-machine-learning-for-healthcare-spring-2019/lecture-videos/lecture-16-reinforcement-learning-part-1/", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/courses/electrical-engineering-and-computer-science/6-s897-<b>machine</b>...", "snippet": "So that S0, 1, et cetera, up to St are all <b>i.i.d</b>. draws of the same distribution. Then we have, essentially, a model for t different patients with a single time step or single action, instead of them being dependent in some way. So we can see that by going backwards through my slides, this is essentially what we had last week.", "dateLastCrawled": "2022-02-02T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning for Market Microstructure and</b> High Frequency Trading", "url": "https://www.cis.upenn.edu/~mkearns/papers/KearnsNevmyvakaHFTRiskBooks.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cis.upenn.edu/~mkearns/papers/KearnsNevmyvakaHFTRiskBooks.pdf", "snippet": "<b>Machine</b> <b>learning</b> is a vibrant sub\ufb01eld of computer science that draws on models and methods from statistics, algorithms, computational complexity, arti\ufb01cial intelli- gence, control theory, and a variety of other disciplines. Its primary focus is on computationally and informationally ef\ufb01cient algorithms for inferring good predictive models from large data sets, and thus is a natural candidate for application to problems arising in HFT, both for trade execution and the generation of ...", "dateLastCrawled": "2022-02-01T08:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Shortcut <b>learning</b> in deep neural networks | Nature <b>Machine</b> Intelligence", "url": "https://www.nature.com/articles/s42256-020-00257-z", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42256-020-00257-z", "snippet": "In <b>analogy</b> to <b>machine</b> <b>learning</b>, we have a striking discrepancy between intended and actual <b>learning</b> outcome. Shortcut <b>learning</b> in education (surface <b>learning</b>) Alice loves history\u2014but at this ...", "dateLastCrawled": "2022-02-03T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Time Series Forecasting as Supervised Learning</b> - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/time-series-forecasting-supervised-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/time-series-forecasting-su", "snippet": "Time series forecasting can be framed as a supervised <b>learning</b> problem. This re-framing of your time series data allows you access to the suite of standard linear and nonlinear <b>machine</b> <b>learning</b> algorithms on your problem. In this post, you will discover how you can re-frame your time series problem as a supervised <b>learning</b> problem for <b>machine</b> <b>learning</b>. After reading this post, you", "dateLastCrawled": "2022-02-02T19:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Learning from positive</b> and unlabeled data: a survey - <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "<b>Learning from positive</b> and unlabeled data or PU <b>learning</b> is the setting where a learner only has access to positive examples and unlabeled data. The assumption is that the unlabeled data can contain both positive and negative examples. This setting has attracted increasing interest within the <b>machine</b> <b>learning</b> literature as this type of data naturally arises in applications such as medical diagnosis and knowledge base completion. This article provides a survey of the current state of the art ...", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[1910.07796] Overcoming Forgetting in <b>Federated Learning</b> on Non-<b>IID</b> Data", "url": "https://arxiv.org/abs/1910.07796", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/1910.07796", "snippet": "We tackle the problem of <b>Federated Learning</b> in the non <b>i.i.d</b>. case, in which local models drift apart, inhibiting <b>learning</b>. Building on an <b>analogy</b> with Lifelong <b>Learning</b>, we adapt a solution for catastrophic forgetting to <b>Federated Learning</b>. We add a penalty term to the loss function, compelling all local models to converge to a shared optimum. We show that this can be done efficiently for communication (adding no further privacy risks), scaling with the number of nodes in the distributed ...", "dateLastCrawled": "2022-01-28T12:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Pearson\u2019s Correlation, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black-swans-in-your-market-neutral-portfolios-part-1-e17fc18a42a7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/kxytechnologies/https-medium-com-pit-ai-technologies-the-black...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum ...", "dateLastCrawled": "2021-05-27T10:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Pearson\u2019s <b>Correlation</b>, Linear Regression, And Why \u2018Beta\u2019 Grossly ...", "url": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part-i-7521683a7317", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-black-swans-in-your-market-neutral-portfolios-part...", "snippet": "To <b>machine</b> <b>learning</b> researchers, the Gaussian distribution arises naturally as the solution to some important optimization problems over probability distributions. One such problem is the maximum-entropy problem , which aims at finding among all probability distributions that are consistent with observed empirical evidence, the one the is the most ignorant about everything else.", "dateLastCrawled": "2022-02-02T09:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(i.i.d.)  is like +(studying past data to improve future predictions)", "+(i.i.d.) is similar to +(studying past data to improve future predictions)", "+(i.i.d.) can be thought of as +(studying past data to improve future predictions)", "+(i.i.d.) can be compared to +(studying past data to improve future predictions)", "machine learning +(i.i.d. AND analogy)", "machine learning +(\"i.i.d. is like\")", "machine learning +(\"i.i.d. is similar\")", "machine learning +(\"just as i.i.d.\")", "machine learning +(\"i.i.d. can be thought of as\")", "machine learning +(\"i.i.d. can be compared to\")"]}