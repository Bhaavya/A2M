{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "mCAF: a multi-dimensional <b>clustering</b> algorithm for <b>friends</b> of social ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4912517/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4912517", "snippet": "The automated <b>friends</b> <b>clustering</b> or grouping algorithms used for online social networks are discussed in reference ... The users of social media platforms such as Facebook often <b>like</b> several brands, which can be clustered into several groups and then analyzed. Reference (Wallace et al. 2014) describes multi-dimensional cluster analysis as a strategy for identifying different Facebook users\u2019 fan groups and provides insights to prompt further research analytics. Reference (Mcauley and ...", "dateLastCrawled": "2022-01-15T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Defining the Clustering Coefficient</b> | networkscience", "url": "https://networkscience.wordpress.com/2013/09/08/defining-the-clustering-coefficient/", "isFamilyFriendly": true, "displayUrl": "https://networkscience.wordpress.com/2013/09/08/<b>defining-the-clustering-coefficient</b>", "snippet": "<b>Clustering</b> is an important property of social networks: People tend to have <b>friends</b> who are also <b>friends</b> with each other, resulting in sets of people among which many edges exist, while a set made from randomly chosen people would have a much smaller number of edges between them. To measure the <b>clustering</b> in a social (or other type of) network, a common measure is the <b>clustering</b> coefficient. The <b>clustering</b> coefficient is a real number between zero and one that is zero when there is no ...", "dateLastCrawled": "2022-02-03T17:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Friends</b> <b>of Friends</b> (FOF) <b>clustering</b>. | Download Scientific Diagram", "url": "https://researchgate.net/figure/Friends-of-Friends-FOF-clustering_fig1_220717657", "isFamilyFriendly": true, "displayUrl": "https://researchgate.net/figure/<b>Friends</b>-<b>of-Friends</b>-FOF-<b>clustering</b>_fig1_220717657", "snippet": "Download scientific diagram | <b>Friends</b> <b>of Friends</b> (FOF) <b>clustering</b>. from publication: DiscFinder: A Data-Intensive Scalable Cluster Finder for Astrophysics | DiscFinder is a scalable approach for ...", "dateLastCrawled": "2021-08-19T14:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Introduction to <b>Clustering</b> \u2014 Using Astrology and Data Science to Make ...", "url": "https://medium.com/@kevincasasola/introduction-to-clustering-using-astrology-and-data-science-to-make-sense-of-your-friends-7c0bcf0277f7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@kevincasasola/introduction-to-<b>clustering</b>-using-astrology-and-data...", "snippet": "Each <b>group</b> has different patterns and characteristics that they share. The objective of any <b>clustering</b> is to minimize the distance between data points around a center. The best way I can minimize ...", "dateLastCrawled": "2021-08-20T20:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Clustering</b> User Histograms: A novel idea for grouping demographics ...", "url": "https://leyankoh.wordpress.com/2019/02/11/clustering-user-histograms-a-novel-idea-for-grouping-demographics-part-3/", "isFamilyFriendly": true, "displayUrl": "https://leyankoh.wordpress.com/2019/02/11/<b>clustering</b>-user-histograms-a-novel-idea-for...", "snippet": "I hence propose a novel method \u2013 layered <b>clustering</b> approach ... so we can simply apply k-means <b>clustering</b> to the <b>group</b> of histograms to cluster users. Hence, to reiterate, this method has a few key strengths, namely it: Takes into account semantic associations of a user\u2019s check-in at a location. A check-in into a restaurant in an entertainment district would better signal the user is here to participate in entertainment-related social activities. A check-in to a restaurant in the CBD ...", "dateLastCrawled": "2022-01-08T09:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "4. Cliques, Clusters and Components - Social Network Analysis for ...", "url": "https://www.oreilly.com/library/view/social-network-analysis/9781449311377/ch04.html", "isFamilyFriendly": true, "displayUrl": "https://www.oreilly.com/library/view/social-network-analysis/9781449311377/ch04.html", "snippet": "The other metric is called <b>clustering</b> coefficient \u2014essentially, it measures the proportion of your <b>friends</b> that are also <b>friends</b> with each other (i.e., what amount of mutual trust people have for each other). This metric can be applied to entire networks\u2014but in a large network with widely varying densities and multiple cores, average <b>clustering</b> is difficult to interpret. In ego networks, the interpretation is simple\u2014dense ego networks with a lot of mutual trust have a high <b>clustering</b> ...", "dateLastCrawled": "2022-01-31T21:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Fast <b>Group</b> <b>Recommendations</b> by Applying User <b>Clustering</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-642-34002-4_10", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-642-34002-4_10", "snippet": "For example, assume a <b>group</b> <b>of friends</b> or a family that is planning to watch a movie or visit a restaurant. In this paper, we propose an extensive model for <b>group</b> <b>recommendations</b> that exploits <b>recommendations</b> for items that similar users to the <b>group</b> members liked in the past. We do not exhaustively search for similar users in the whole user base, but we pre-partition users into clusters of similar ones and use the cluster members for <b>recommendations</b>. We efficiently aggregate the single user ...", "dateLastCrawled": "2022-01-25T15:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What <b>is the benefit of clustering data? - Quora</b>", "url": "https://www.quora.com/What-is-the-benefit-of-clustering-data", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-<b>is-the-benefit-of-clustering-data</b>", "snippet": "Answer: Let me draw an analogy here. Each one of us have different groups <b>of friends</b> such as old school/college <b>friends</b>, colleagues, people from the same locality, <b>friends</b> with common interests etc. Our interaction, attitude etc. with them becomes different for each <b>group</b>. Similarly, when we ha...", "dateLastCrawled": "2022-01-23T23:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is the <b>clustering</b> coefficient of a clique? - Quora", "url": "https://www.quora.com/What-is-the-clustering-coefficient-of-a-clique", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-<b>clustering</b>-coefficient-of-a-clique", "snippet": "Answer: The <b>clustering</b> coefficient of a vertex v in a graph is found by: (1) counting the number k of vertices adjacent to v; (2) counting the number e of edges occurring between the vertices adjacent to v; and (3) forming the quotient q=e/K, where K is k(k-1) in the case of directed graphs, and ...", "dateLastCrawled": "2022-01-21T03:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the difference between <b>clustering</b> and <b>brainstorming</b>?", "url": "https://findanyanswer.com/what-is-the-difference-between-clustering-and-brainstorming", "isFamilyFriendly": true, "displayUrl": "https://findanyanswer.com/what-is-the-difference-between-<b>clustering</b>-and-<b>brainstorming</b>", "snippet": "1) In a computer system, a cluster is a <b>group</b> of servers and other resources that act <b>like</b> a single system and enable high availability and, in some cases, load balancing and parallel processing. See <b>clustering</b>. The maximum number of clusters on a hard disk depends on the size of a FAT table entry.", "dateLastCrawled": "2022-01-13T09:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Friends</b> <b>of Friends</b> (FOF) <b>clustering</b>. | Download Scientific Diagram", "url": "https://researchgate.net/figure/Friends-of-Friends-FOF-clustering_fig1_220717657", "isFamilyFriendly": true, "displayUrl": "https://researchgate.net/figure/<b>Friends</b>-<b>of-Friends</b>-FOF-<b>clustering</b>_fig1_220717657", "snippet": "Download scientific diagram | <b>Friends</b> <b>of Friends</b> (FOF) <b>clustering</b>. from publication: DiscFinder: A Data-Intensive Scalable Cluster Finder for Astrophysics | DiscFinder is a scalable approach for ...", "dateLastCrawled": "2021-08-19T14:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "mCAF: a multi-dimensional <b>clustering</b> algorithm for <b>friends</b> of social ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4912517/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4912517", "snippet": "The automated <b>friends</b> <b>clustering</b> or grouping algorithms used for online social networks are discussed in reference (Eslami et al. 2014).In that study (Eslami et al. 2014), the researchers propose that manual <b>clustering</b> of large numbers <b>of friends</b> overburdens social network users; thus, interested social network users may use automatic <b>clustering</b> algorithms to create quick groupings of their large numbers of social-network <b>friends</b> with minimal effort.Integrated interfaces are suggested to ...", "dateLastCrawled": "2022-01-15T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Community detection and <b>clustering</b>", "url": "https://www.inf.ed.ac.uk/teaching/courses/stn/files1920/slides/community.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.inf.ed.ac.uk/teaching/courses/stn/files1920/slides/community.pdf", "snippet": "be <b>similar</b>/<b>friends</b>/trusted \u2022 marked \u201c+\u201d \u2022 Some edges are known to be dissimilar/enemies/distrus ted \u2022 marked \u201c-\u201d \u2022 Maximize the number of + edges inside clusters and \u2022 Minimize the number of - edges between clusters. Applications \u2022 Community detection based on <b>similar</b> people/users \u2022 Document <b>clustering</b> based on known similarity or dissimilarity between documents \u2022 Use of sentiments and/or other divisive attributes. Features \u2022 <b>Clustering</b> without need to know number ...", "dateLastCrawled": "2021-08-11T12:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 15 <b>CLUSTERING</b> METHODS - Swarthmore College", "url": "https://www.cs.swarthmore.edu/~meeden/cs63/s16/reading/Clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.swarthmore.edu/~meeden/cs63/s16/reading/<b>Clustering</b>.pdf", "snippet": "medical \u201csyndromes\u201d and genetic \u201cgenotypes\u201d to manufacturing \u201d<b>group</b> tech-nology\u201d \u2014 the problem is identical: forming categories of entities and assign- ing individuals to the proper groups within it. 2. Distance Measures Since <b>clustering</b> is the grouping of <b>similar</b> instances/objects, some sort of measure that can determine whether two objects are <b>similar</b> or dissimilar is required. There are two main type of measures used to estimate this relation: distance measures and ...", "dateLastCrawled": "2022-01-31T22:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Fast <b>Group</b> Recommendations by Applying User <b>Clustering</b>", "url": "https://www.researchgate.net/publication/230898599_Fast_Group_Recommendations_by_Applying_User_Clustering", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/230898599_Fast_<b>Group</b>_Recommendations_by...", "snippet": "Besides, <b>clustering</b> tries to insert the new object in the best <b>similar</b> class, like using the k-nearest neighbor algorithm as a classifier. The proposing approach focuses on modeling categories by ...", "dateLastCrawled": "2022-01-06T15:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>CLUSTERING</b> Synonyms: 37 Synonyms &amp; Antonyms for <b>CLUSTERING</b> | Thesaurus.com", "url": "https://www.thesaurus.com/browse/clustering", "isFamilyFriendly": true, "displayUrl": "https://www.thesaurus.com/browse/<b>clustering</b>", "snippet": "Find 37 ways to say <b>CLUSTERING</b>, along with antonyms, related words, and example sentences at Thesaurus.com, the world&#39;s most trusted free thesaurus.", "dateLastCrawled": "2022-02-02T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Fast <b>Group</b> Recommendations by Applying User <b>Clustering</b>", "url": "https://folk.idi.ntnu.no/noervaag/papers/ER2012.pdf", "isFamilyFriendly": true, "displayUrl": "https://folk.idi.ntnu.no/noervaag/papers/ER2012.pdf", "snippet": "assume a <b>group</b> <b>of friends</b> or a family that is planning to watch a movie or visit a restaurant. In this paper, we propose an extensive model for <b>group</b> recommendations that exploits recommendations for items that <b>similar</b> users to the <b>group</b> members liked in the past. We do not exhaustively search for <b>similar</b> users in the whole user base, but we pre-partition users into clusters of <b>similar</b> ones and use the cluster members for recommen-dations. We e ciently aggregate the single user ...", "dateLastCrawled": "2021-09-28T16:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fast <b>Group</b> <b>Recommendations</b> by Applying User <b>Clustering</b>", "url": "https://link.springer.com/chapter/10.1007/978-3-642-34002-4_10", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-642-34002-4_10", "snippet": "For example, assume a <b>group</b> <b>of friends</b> or a family that is planning to watch a movie or visit a restaurant. In this paper, we propose an extensive model for <b>group</b> <b>recommendations</b> that exploits <b>recommendations</b> for items that <b>similar</b> users to the <b>group</b> members liked in the past. We do not exhaustively search for <b>similar</b> users in the whole user base, but we pre-partition users into clusters of <b>similar</b> ones and use the cluster members for <b>recommendations</b>. We efficiently aggregate the single user ...", "dateLastCrawled": "2022-01-25T15:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "gRecs: A <b>Group</b> Recommendation System based on User <b>Clustering</b>", "url": "https://folk.idi.ntnu.no/noervaag/papers/DASFAA2012.pdf", "isFamilyFriendly": true, "displayUrl": "https://folk.idi.ntnu.no/noervaag/papers/DASFAA2012.pdf", "snippet": "not intended for personal usage but for a <b>group</b> of users. For example, a <b>group</b> <b>of friends</b> is planning to watch a movie or to visit a restaurant. For this reason some recent works have addressed the problem of identifying recommendations for a <b>group</b> of users, trying to satisfy the preferences of all the <b>group</b> members. Our work falls into the collaborative ltering approach, i.e., we o er user recommendations for items that <b>similar</b> users liked in the past. We introduce the notion of support in ...", "dateLastCrawled": "2021-09-08T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What <b>is the benefit of clustering data? - Quora</b>", "url": "https://www.quora.com/What-is-the-benefit-of-clustering-data", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-<b>is-the-benefit-of-clustering-data</b>", "snippet": "Answer: Let me draw an analogy here. Each one of us have different groups <b>of friends</b> such as old school/college <b>friends</b>, colleagues, people from the same locality, <b>friends</b> with common interests etc. Our interaction, attitude etc. with them becomes different for each <b>group</b>. Similarly, when we ha...", "dateLastCrawled": "2022-01-23T23:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to <b>Clustering</b> \u2014 Using Astrology and Data Science to Make ...", "url": "https://medium.com/@kevincasasola/introduction-to-clustering-using-astrology-and-data-science-to-make-sense-of-your-friends-7c0bcf0277f7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@kevincasasola/introduction-to-<b>clustering</b>-using-astrology-and-data...", "snippet": "Each <b>group</b> has different patterns and characteristics that they share. The objective of any <b>clustering</b> is to minimize the distance between data points around a center. The best way I <b>can</b> minimize ...", "dateLastCrawled": "2021-08-20T20:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Beyond ``Local&#39;&#39;, ``Categories&#39;&#39; and ``<b>Friends</b>&#39;&#39;: <b>Clustering</b> foursquare ...", "url": "http://www.casos.cs.cmu.edu/publications/papers/2012BeyondLocal.pdf", "isFamilyFriendly": true, "displayUrl": "www.casos.cs.cmu.edu/publications/papers/2012BeyondLocal.pdf", "snippet": "the latent variables which <b>group</b> users <b>can</b> <b>be thought</b> of not as themes but rather as factors which drive check in behav-iors, allowing for a qualitative understanding of in\ufb02uences on user check ins. Our model is agnostic of geo-spatial lo-cation, time, users\u2019 <b>friends</b> on social networking sites and the venue categories- we treat the existence of and intricate interactions between these factors as being latent, allowing them to emerge entirely from the data. We instantiate our model on ...", "dateLastCrawled": "2022-01-29T08:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Unsupervised Machine Learning: <b>Clustering</b> with k-means | by Manoj Singh ...", "url": "https://medium.com/nerd-for-tech/unsupervised-machine-learning-clustering-with-k-means-13129f07ef2e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/nerd-for-tech/unsupervised-machine-learning-<b>clustering</b>-with-k-means...", "snippet": "It <b>can</b> <b>be thought</b> of as a teacher supervising the learning process, Here given a training dataset with some feature value as (x) and target/output (y), algorithms try to learn from it and create a\u2026", "dateLastCrawled": "2020-12-27T00:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Human social preferences cluster and spread in the field | <b>PNAS</b>", "url": "https://www.pnas.org/content/117/37/22787", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/117/37/22787", "snippet": "Cooperative <b>clustering</b> <b>can</b> be found on different nested layers of the social structure\u2014classmates, clique members, and <b>friends</b>. With increasing strength of the relationships, people\u2019s social preferences become more and more alike. The resulting clusters protect cooperative individuals from exploitation and provide their members with advantages over self-regarding individuals. Recent evidence has found similar structural properties in reciprocal collaboration behavior among hunter-gatherers", "dateLastCrawled": "2022-01-19T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>GitHub</b> - Ritik2703/K-means-<b>Clustering</b>: #hare krishna", "url": "https://github.com/Ritik2703/K-means-Clustering", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/Ritik2703/K-means-<b>Clustering</b>", "snippet": "We <b>can</b> apply <b>clustering</b> to create clusters having similar pixels in the same <b>group</b>. image segmentation using <b>clustering</b>. You <b>can</b> refer to this article to see how we <b>can</b> make use of <b>clustering</b> for image segmentation tasks. Recommendation Engines <b>Clustering</b> <b>can</b> also be used in recommendation engines. Let\u2019s say you want to recommend songs to your <b>friends</b>. You <b>can</b> look at the songs liked by that person and then use <b>clustering</b> to find similar songs and finally recommend the most similar songs ...", "dateLastCrawled": "2022-01-18T08:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Scalable Clustering of Signed Networks Using Balance Normalized Cut</b>", "url": "https://www.cs.utexas.edu/users/inderjit/public_papers/sign_clustering_cikm12.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.utexas.edu/users/inderjit/public_papers/sign_<b>clustering</b>_cikm12.pdf", "snippet": "social networks where relationships between entities <b>can</b> be either positive or negative. Motivated by social balance the-ory, the <b>clustering</b> problem in signed networks aims to \ufb01nd mutually antagonistic groups such that entities within the same <b>group</b> are <b>friends</b> with each other. A recent method proposed in [13] extended the spectral <b>clustering</b> ...", "dateLastCrawled": "2022-01-24T05:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Ensemble <b>Clustering</b> using Semidefinite Programming", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3992703/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3992703", "snippet": "We consider the ensemble <b>clustering</b> problem where the task is to \u2018aggregate\u2019 multiple <b>clustering</b> solutions into a single consolidated <b>clustering</b> that maximizes the shared information among given <b>clustering</b> solutions. We obtain several new results for this problem. First, we note that the notion of agreement under such circumstances <b>can</b> be better captured using an agreement measure based on a 2 D string encoding rather than voting strategy based methods proposed in literature. Using this ...", "dateLastCrawled": "2017-01-31T11:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "GitHub - MichiganDataScienceTeam/wine_<b>clustering</b>", "url": "https://github.com/MichiganDataScienceTeam/wine_clustering", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/MichiganDataScienceTeam/wine_<b>clustering</b>", "snippet": "In this project, we will be trying to <b>group</b> the wines based on their features. Why it\u2019s important: <b>Clustering</b> is used in all industries and <b>can</b> broadly be used to find patterns and trends in data. We <b>can</b> also learn more about wine in the process! Impress your <b>friends</b> with your palate! And parents! Description The goal of this project is to cluster wines based on several chemical constituents such as alcohol, malic acid, ash, etc. Questions that we hope to answer include, but are not ...", "dateLastCrawled": "2022-02-05T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Consensus and <b>clustering</b> in opinion formation on networks ...", "url": "https://royalsocietypublishing.org/doi/10.1098/rsta.2017.0186", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rsta.2017.0186", "snippet": "These extended ODE models <b>can</b> <b>be thought</b> of as being ODEs on directed graphs. We study in detail these models to determine conditions under which there will be consensus and pluralism within the system. Most of the consensus/pluralism analysis is done for the case of one and two cities. However, we numerically show for the case of a symmetric cycle graph that an elementary bifurcation analysis provides insight into the phenomena of <b>clustering</b>. Moreover, for the case of a cycle graph with a ...", "dateLastCrawled": "2022-01-30T11:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "PRICE <b>CLUSTERING</b> IN THE NORD POOL ELECTRICITY MARKET", "url": "https://repositorio-aberto.up.pt/bitstream/10216/139345/2/527680.pdf", "isFamilyFriendly": true, "displayUrl": "https://repositorio-aberto.up.pt/bitstream/10216/139345/2/527680.pdf", "snippet": "Price <b>clustering</b> <b>can</b> be defined as the tendency for prices to accumulate around specific values, and several studies have already been done regarding this phenomenon finding supportive evidence in a wide array of asset classes, that go from the stock market to the real estate and even cryptocurrencies. Nevertheless, research focused on utility markets is still relatively small in volume, thus making studies like the present important to develop this field within the academic literature. To ...", "dateLastCrawled": "2022-01-27T01:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "mCAF: a multi-dimensional <b>clustering</b> algorithm for <b>friends</b> of social ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4912517/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4912517", "snippet": "The automated <b>friends</b> <b>clustering</b> or grouping algorithms used for online social networks are discussed in reference ... we used the SCAN algorithm to cluster the data from Facebook. Finally, we <b>compared</b> the similarity of the results provided by the card-sorting method and the SCAN method (1). First, we defined the card-sorting <b>clustering</b> results as set C = {C 1, C 2, C 3,\u2026, C m} and the SCAN <b>clustering</b> results as set G = {G 1, G 2, G 3,\u2026, G n}. The similarity between C i (1 \u2266 i \u2266 m ...", "dateLastCrawled": "2022-01-15T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Document Clustering</b> - IITKGP", "url": "https://cse.iitkgp.ac.in/~abhij/facad/03UG/Report/03CS3024_Pankaj_Jajoo.pdf", "isFamilyFriendly": true, "displayUrl": "https://cse.iitkgp.ac.in/~abhij/facad/03UG/Report/03CS3024_Pankaj_Jajoo.pdf", "snippet": "Each <b>group</b>, called cluster, consists of objects that are similar between themselves and dissimilar to objects of other groups. In other words, the goal of a good <b>document clustering</b> scheme is to minimize intra-cluster distances between documents, while maximizing inter-cluster distances (using an appropriate distance measure between documents). A distance measure (or, dually, similarity measure) thus lies at the heart of <b>document clustering</b>. <b>Clustering</b> is the most common form of unsupervised ...", "dateLastCrawled": "2022-01-25T08:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Clustering</b>. with K-mean Algorithm | by Iprathore | Medium", "url": "https://iprathore71.medium.com/clustering-975f8bc58af0", "isFamilyFriendly": true, "displayUrl": "https://iprathore71.medium.com/<b>clustering</b>-975f8bc58af0", "snippet": "Let\u2019s say you want to recommend songs to your <b>friends</b>. You <b>can</b> look at the songs liked by that person and then use <b>clustering</b> to find similar songs and finally recommend the most similar songs. Image Segmentation: We <b>can</b> also use <b>clustering</b> to perform image segmentation. Here, we try to club similar pixels in the image together. We <b>can</b> apply <b>clustering</b> to create clusters having similar pixels in the same <b>group</b>. <b>Clustering</b> <b>can</b> be divided into two subgroups : Hard <b>Clustering</b>: In hard ...", "dateLastCrawled": "2022-01-12T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Some <b>friends</b> matter more than others: BMI <b>clustering</b> among adolescents ...", "url": "https://www.cambridge.org/core/journals/network-science/article/abs/some-friends-matter-more-than-others-bmi-clustering-among-adolescents-in-four-european-countries/48D058C006FD01BE8E5F95F7E608F208", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/network-science/article/abs/some-<b>friends</b>...", "snippet": "Our study reveals strong evidence for BMI <b>clustering</b> in England, Germany, the Netherlands, and Sweden; adolescents tend to be <b>friends</b> with others who have a similar BMI. Furthermore, we extend current debate and explore friendship characteristics that moderate the relationship between social networks and BMI. We demonstrate that BMI <b>clustering</b> is more pronounced in (1) strong <b>compared</b> to weak friendships and (2) between adolescents of the same biological sex. These findings indicate thatmore ...", "dateLastCrawled": "2022-01-29T15:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Clustering User Histograms: A novel idea for grouping demographics</b> ...", "url": "https://leyankoh.wordpress.com/2018/12/28/clustering-user-histograms-a-novel-idea-for-grouping-demographics-part-1/", "isFamilyFriendly": true, "displayUrl": "https://leyankoh.wordpress.com/2018/12/28/<b>clustering-user-histograms-a-novel</b>-idea-for...", "snippet": "The purpose of <b>clustering</b> is <b>to group</b> data into groups such that 1) similarity between data points in a set are maximised and 2) similarity between each set of data points are minimised. In other words, given a data matrix D with M objects and N attributes, <b>clustering</b> typically finds an optimal partitioning of M objects using features described by N attributes or vice versa. Not all N attributes are useful for finding the partitions, thus dimensionality reduction methods <b>can</b> reduce the ...", "dateLastCrawled": "2022-01-30T00:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Tweets Classification and <b>Clustering</b> in Python. | by Ada kibet | The ...", "url": "https://medium.com/swlh/tweets-classification-and-clustering-in-python-b107be1ba7c7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/tweets-classification-and-<b>clustering</b>-in-python-b107be1ba7c7", "snippet": "We will work with 2D <b>clustering</b>, i.e <b>clustering</b> between 2 variables. There are different methods to determine the optimal number of clusters and one of them is the elbow method.", "dateLastCrawled": "2022-01-31T19:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Social and Spatial <b>Clustering</b> of People at Humanity\u2019s Largest Gathering", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0156794", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0156794", "snippet": "To see the reason for this, consider the case where state A sends only a single <b>group</b> <b>of friends</b> to the Kumbh, whereas state B sends 100 different groups <b>of friends</b>. A random pair selected from state A will have a much higher likelihood of being <b>friends</b> than will a random pair from state B, even if social homophily is equally strong within the friendship groups of the two states. The biases of both these methods are discussed in further detail in S1 Text. To circumvent these problems, we ...", "dateLastCrawled": "2020-09-08T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "MR-DBSCAN: An Efficient Parallel Density-based <b>Clustering</b> Algorithm ...", "url": "https://csc.csudh.edu/btang/seminar/slides/06121313.pdf", "isFamilyFriendly": true, "displayUrl": "https://csc.csudh.edu/btang/seminar/slides/06121313.pdf", "snippet": "<b>Compared</b> with other <b>clustering</b> methods, DBSCAN possesses several attractive properties. First, it <b>can</b> divide data into clusters with arbitrary shapes. For example, it <b>can</b> \ufb01nd clusters totally surrounded by another cluster. Second, DBSCAN does not require the number of the clusters a priori. Third, it is insensitive to the order of the points in the dataset. As a result, DBSCAN has achieved great success and become the most cited <b>clustering</b> method in the scienti\ufb01c literature. However ...", "dateLastCrawled": "2022-01-28T17:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Extended <b>clustering</b> coefficients:Generalization of <b>clustering</b> ...", "url": "https://web.ece.ucsb.edu/~parhami/pubs_folder/parh07-jssse-ext-clustering-coeff.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.ece.ucsb.edu/~parhami/pubs_folder/parh07-jssse-ext-<b>clustering</b>-coeff.pdf", "snippet": "EXTENDED <b>CLUSTERING</b> COEFFICIENTS:GENERALIZATION OF ... Let G be a finite <b>group</b> and S a subset of G. The subset S is said to be a generating set for G, and the elements of S are called generators of G, if every element of G <b>can</b> be expressed as a finite product of the powers of the elements in S. In this case, we also say that G is generated by S. The Cayley digraph of a <b>group</b> G and the subset S of G, denoted by Cay(G, S), has the vertex set that is G and the arc set that is {(g, gs) | g \u2208 G ...", "dateLastCrawled": "2022-01-28T12:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Temporal Bias in the <b>Clustering</b> of Massive Cosmological Objects", "url": "https://www.slac.stanford.edu/econf/C030908/papers/WEMT001.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.slac.stanford.edu/econf/C030908/papers/WEMT001.pdf", "snippet": "<b>group</b> nding methods in Fig. 1 we plot the mass of the most massive progenitor at t1(z = 3:059), versus the mass at t2(z = 3), such that t = 5 107 years. As <b>compared</b> to the FOF groups, the smaller frac-tion of HOP groups lying above the equal mass line shows that the HOP algorithm identi es groups that are more likely to be massive at later ...", "dateLastCrawled": "2021-09-08T00:28:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>What is Machine Learning</b>? | <b>Oracle</b> India", "url": "https://www.oracle.com/in/data-science/machine-learning/what-is-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.oracle.com</b>/in/data-science/<b>machine</b>-<b>learning</b>/<b>what-is-machine-learning</b>", "snippet": "To continue the childhood teaching <b>analogy</b>, unsupervised <b>machine</b> <b>learning</b> is akin to a child <b>learning</b> to identify fruit by observing colors and patterns, rather than memorizing the names with a teacher\u2019s help. The child would look for similarities between images and separate them into groups, assigning each group its own new label. Examples of unsupervised <b>machine</b> <b>learning</b> algorithms include k-means <b>clustering</b>, principal and independent component analysis, and association rules. Choosing ...", "dateLastCrawled": "2022-02-03T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Analogy</b> of the Application of <b>Clustering</b> and K-Means Techniques for the ...", "url": "https://thesai.org/Downloads/Volume12No9/Paper_59-Analogy_of_the_Application_of_Clustering.pdf", "isFamilyFriendly": true, "displayUrl": "https://thesai.org/.../Volume12No9/Paper_59-<b>Analogy</b>_of_the_Application_of_<b>Clustering</b>.pdf", "snippet": "<b>Machine</b> <b>Learning</b> algorithms (K-Means and <b>Clustering</b>) to observe the formation of clusters, with their respective indicators, grouping the departments of Peru into four clusters, according to the similarities between them, to measure human development through life expectancy, access to education and income level. In this research, unsupervised <b>learning</b> algorithms were proposed to group the departments into clusters, according to optimization criteria; being one of the most used the K-Means ...", "dateLastCrawled": "2021-12-29T17:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "<b>Machine</b> <b>learning</b> terminology for model building and validation There seems to be an <b>analogy</b> between statistical modeling and <b>machine</b> <b>learning</b> that we will cover in subsequent chapters in depth. However, a quick view has been provided as follows: in statistical modeling, linear regression with two independent variables is trying to fit the best plane with\u2026", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Unsupervised <b>Machine</b> <b>Learning</b>: Examples and Use Cases | <b>AltexSoft</b>", "url": "https://www.altexsoft.com/blog/unsupervised-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>altexsoft</b>.com/blog/unsupervised-<b>machine</b>-<b>learning</b>", "snippet": "Unsupervised <b>machine</b> <b>learning</b> is the process of inferring underlying hidden patterns from historical data. Within such an approach, a <b>machine</b> <b>learning</b> model tries to find any similarities, differences, patterns, and structure in data by itself. No prior human intervention is needed. Let\u2019s get back to our example of a child\u2019s experiential <b>learning</b>. Picture a toddler. The child knows what the family cat looks like (provided they have one) but has no idea that there are a lot of other cats ...", "dateLastCrawled": "2022-02-03T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning</b> With Spark. A distributed <b>Machine Learning</b>\u2026 | by MA ...", "url": "https://towardsdatascience.com/machine-learning-with-spark-f1dbc1363986", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine-learning</b>-with-spark-f1dbc1363986", "snippet": "<b>Machine learning</b> is getting popular in solving real-wor l d problems in almost every business domain. It helps solve the problems using the data which is often unstructured, noisy, and in huge size. With the increase in data sizes and various sources of data, solving <b>machine learning</b> problems using standard techniques pose a big challenge ...", "dateLastCrawled": "2022-02-02T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "MaxMin <b>clustering</b> for <b>historical analogy</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s42452-020-03202-2", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42452-020-03202-2", "snippet": "<b>Historical analogy</b> is the ability to use historical knowledge to consider solutions for a present event, and it can be promoted by group <b>learning</b>. However, group creation for promoting the ability has been unexplored. This study proposes a novel <b>clustering</b> algorithm, named MaxMin <b>clustering</b> (MMC), to enhance discussions of group <b>learning</b> toward promoting <b>historical analogy</b>. The key concept is group formation by aggregating similar and different users. MMC uses aspects provided by users for ...", "dateLastCrawled": "2021-12-27T01:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to <b>Machine</b> <b>Learning</b> with Spark (Clustering) - Knoldus Blogs", "url": "https://blog.knoldus.com/introduction-to-machine-learning-with-spark-clustering/", "isFamilyFriendly": true, "displayUrl": "https://blog.knoldus.com/introduction-to-<b>machine</b>-<b>learning</b>-with-spark-clustering", "snippet": "In this blog, we will learn how to group similar data objects using K-means clustering offered by Spark <b>Machine</b> <b>Learning</b> Library. Prerequisites. The code example needs only Spark Shell to execute. What is Clustering. <b>Clustering is like</b> grouping data objects in some random clusters (with no initial class of group defined) on the basis of similarity or the natural closeness to each other. The \u201ccloseness\u201d will be clear later in the blog. Why Clustering. The reason I chose Clustering as ...", "dateLastCrawled": "2022-01-31T16:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "CS771: Introduction to <b>Machine</b> <b>Learning</b> Nisheeth", "url": "https://hello.iitk.ac.in/sites/default/files/cs771a21/lec21.pdf", "isFamilyFriendly": true, "displayUrl": "https://hello.iitk.ac.in/sites/default/files/cs771a21/lec21.pdf", "snippet": "CS771: Introduction to <b>Machine</b> <b>Learning</b> Nisheeth . CS771: Intro to ML K-means algorithm: recap 2 . CS771: Intro to ML K-means loss function: recap 3 N . X . Z . K K . K . CS771: Intro to ML K-means++ 4 Desired clustering . Poor initialization: bad clustering . CS771: Intro to ML . K-means++ . 5 . Thus farthest points are most likely to be selected as cluster means . CS771: Intro to ML . K-means: Soft Clustering . 6 . A more principled extension of K-means for doing soft-clustering is via ...", "dateLastCrawled": "2022-01-28T07:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Episode 493: Ram Sriharsha on Vectors in <b>Machine</b> <b>Learning</b> : Software ...", "url": "https://www.se-radio.net/2022/01/episode-493-ram-sriharsha-on-vectors-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.se-radio.net/2022/01/episode-493-ram-sriharsha-on-vectors-in-<b>machine</b>-<b>learning</b>", "snippet": "Ram Sriharsha 00:14:05 Yeah. Yeah. <b>Clustering is like</b> an unsupervised technique. Classification means you have labels here, labeled it for you and you want to give it a new point detect whether it has a certain label. Interesting , you\u2019re just looking at things that are close to each other. It\u2019s an unsupervised technique and it\u2019s very common either as a people processing technique or just to identify patterns in your data. Philip Winston 00:14:25 Okay. That\u2019s interesting. So, there ...", "dateLastCrawled": "2022-01-31T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Three Popular <b>Machine</b> <b>Learning</b> Methods | by Mike Wolfe | Towards Data ...", "url": "https://towardsdatascience.com/three-popular-machine-learning-methods-7cb2dcb40bd0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/three-popular-<b>machine</b>-<b>learning</b>-methods-7cb2dcb40bd0", "snippet": "<b>Machine</b> <b>Learning</b> is a combination of computer science and artificial intelligence (AI). This combination uses complex calculations and problem solving that create and follow patterns to make decisions. These decisions are made to mimic how a human thinks, which over time improves the models and decision-making process. As big data continues to expand, so does the importance of data science and the need for <b>machine</b> <b>learning</b>. <b>Machine</b> <b>Learning</b> is important because it can be used to aid in ...", "dateLastCrawled": "2022-01-27T01:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>learning</b> definition and common algorithms", "url": "https://topic.alibabacloud.com/a/machine-learning-definition-and-common-algorithms_8_8_30425809.html", "isFamilyFriendly": true, "displayUrl": "https://topic.alibabacloud.com/a/<b>machine</b>-<b>learning</b>-definition-and-common-algorithms_8_8...", "snippet": "<b>Machine</b> <b>Learning</b> Concept1.1 Definition of <b>machine</b> <b>learning</b> Here are some definitions of <b>machine</b> <b>learning</b> on Wikipedia: L &quot;<b>Machine</b> <b>learning</b> is a science of artificial intelligence, and the main research object in this field is artificial intelligence, especially how to improve the performance of specific algorithms in experiential <b>learning</b> .&quot;", "dateLastCrawled": "2021-11-12T19:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning With Tensorflow - Nishant Shukla</b> [3no7jwm5w3ld]", "url": "https://idoc.pub/documents/machine-learning-with-tensorflow-nishant-shukla-3no7jwm5w3ld", "isFamilyFriendly": true, "displayUrl": "https://idoc.pub/documents/<b>machine-learning-with-tensorflow-nishant-shukla</b>-3no7jwm5w3ld", "snippet": "Two of the most powerful tools that <b>machine</b> <b>learning</b> practitioners use to learn from data alone are clustering and dimensionality reduction. Clustering is the process of splitting the data into individual buckets of similar items. In a sense, <b>clustering is like</b> classification of data without knowing any corresponding labels. For instance, when ...", "dateLastCrawled": "2022-01-17T01:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning with Tensorflow - Nishant Shukla</b> - Programa\u00e7\u00e3o I - 5", "url": "https://www.passeidireto.com/arquivo/52777201/machine-learning-with-tensorflow-nishant-shukla/5", "isFamilyFriendly": true, "displayUrl": "https://www.passeidireto.com/arquivo/52777201/<b>machine-learning-with-tensorflow-nishant</b>...", "snippet": "Two of the most powerful tools that <b>machine</b> <b>learning</b> practitioners use to learn from data alone are clustering and dimensionality reduction. Clustering is the process of splitting the data into individual buckets of similar items. In a sense, <b>clustering is like</b> classification of data without knowing any corresponding labels. For instance, when ...", "dateLastCrawled": "2021-01-09T20:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Classification of common <b>machine</b> <b>learning</b> algorithms - \u7f16\u7a0b\u77e5\u8bc6", "url": "https://cdmana.com/2021/04/20210405141123881z.html", "isFamilyFriendly": true, "displayUrl": "https://cdmana.com/2021/04/20210405141123881z.html", "snippet": "1.2 Classification of <b>machine</b> <b>learning</b> . 1.2.1 Supervised <b>learning</b> . Supervision is <b>learning</b> a function from a given set of training data \uff08 Model \uff09, When new data comes , According to this function \uff08 Model \uff09 Predicted results . The training set of supervised <b>learning</b> includes input and output , It can also be said to be characteristics and goals . The goal of the training set is marked by people \uff08 Scalar \uff09 Of . Under supervised <b>learning</b> , The input data is called \u201c Training ...", "dateLastCrawled": "2021-09-16T20:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Definition and Examples of <b>Clustering</b> in Composition", "url": "https://www.thoughtco.com/clustering-discovery-strategy-in-composition-1689857", "isFamilyFriendly": true, "displayUrl": "https://www.thoughtco.com/<b>clustering</b>-discovery-strategy-in-composition-1689857", "snippet": "<b>Clustering</b> &quot;<b>Clustering</b> (sometimes also known as &#39;branching&#39; or &#39;mapping&#39;) is a structured technique based on the same associative principles as brainstorming and listing.<b>Clustering</b> is distinct, however, because it involves a slightly more developed heuristic (Buzan &amp; Buzan, 1993; Glenn et al., 2003; Sharples, 1999; Soven, 1999). <b>Clustering</b> procedures vary considerably, although the fundamental objective is to equip students with tools for arranging words, phrases, concepts, memories, and ...", "dateLastCrawled": "2022-02-02T02:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING</b> AS A DOUBLE-EDGE SWORD IN ...", "url": "https://www.ripublication.com/ijaerspl2019/ijaerv14n7spl_03.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ripublication.com/ijaerspl2019/ijaerv14n7spl_03.pdf", "snippet": "<b>Machine</b> <b>learning</b> has turned out to be increasingly refined in the recent years and will keep on doing as such as its <b>learning</b> are compounded and computing power increments. Artificial intelligence based digital security is genuinely an ocean change in the security business. But, In response to the increasing use of artificial intelligence (AI) technologies to defend against cyber attacks, malicious actors are now discussing their potential application for criminal use. This paper is an ...", "dateLastCrawled": "2021-11-05T06:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning: Definition, Explanation</b>, and Examples", "url": "https://www.wgu.edu/blog/machine-learning-definition-explanation-examples2007.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.wgu.edu</b>/blog/<b>machine-learning-definition-explanation</b>-examples2007.html", "snippet": "Clustering. <b>Clustering is similar</b> to classifying in that it separates similar elements, but it is used in unsupervised training, so the groups are not separated based on your requirements. Clustering is commonly used in <b>machine</b> <b>learning</b> models when researchers are trying to find the differences between sets of data and learn more about them. In ...", "dateLastCrawled": "2022-02-02T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>machine</b> <b>learning</b> - <b>clustering</b> with cosine similarity - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/11150523/clustering-with-cosine-similarity", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/11150523", "snippet": "Browse other questions tagged <b>machine</b>-<b>learning</b> cluster-analysis distance cosine-similarity or ask your own question. The Overflow Blog A chat with the folks who lead training and certification at AWS", "dateLastCrawled": "2022-01-20T01:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Hands-on practice on machine learning</b> - Blogger", "url": "https://vivek2509.blogspot.com/2020/10/hands-on-practice-on-machine-learning.html", "isFamilyFriendly": true, "displayUrl": "https://vivek2509.blogspot.com/2020/10/<b>hands-on-practice-on-machine-learning</b>.html", "snippet": "3.1 Clustering. <b>Clustering is similar</b> to classification, but the basis is different. In clustering, you don&#39;t know what you are looking for, and you are trying to identify some segments or clusters in your data. Learn how to implement the following <b>Machine</b> <b>learning</b> Clustering models: K-mean Clustering. Hierarchical Clustering.", "dateLastCrawled": "2021-12-03T05:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>machine</b> <b>learning</b> - Difference between <b>classification</b> and clustering in ...", "url": "https://stackoverflow.com/questions/5064928/difference-between-classification-and-clustering-in-data-mining", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/5064928", "snippet": "Because of this difference in <b>learning</b>, Clustering is called an unsupervised <b>learning</b> method and <b>Classification</b> is called a supervised <b>learning</b> method. They are very different in the <b>machine</b> <b>learning</b> world, and are often dictated by the kind of data present. Obtaining labelled data (or things that help us learn , like stormtrooper,elephant and cat in Kylo\u2019s case) is often not easy and becomes very complicated when the data to be differentiated is large. On the other hand, <b>learning</b> without ...", "dateLastCrawled": "2022-01-26T12:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> Applications using Seismic Attributes A Hands-On ...", "url": "http://mcee.ou.edu/aaspi/hands-on_short_courses/Exercises-Machine_learning/Hands-on_ML_short_course-Part_5a.-Unsupervised_classification_using_kmeans_and_GMM.pdf", "isFamilyFriendly": true, "displayUrl": "mcee.ou.edu/aaspi/hands-on_short_courses/Exercises-<b>Machine</b>_<b>learning</b>/Hands-on_ML_short...", "snippet": "<b>Machine</b> <b>Learning</b> Applications using Seismic Attributes ... A typical workflow of k-means <b>clustering is similar</b> to a projection workflow, and thus consists of the following steps: 1. Generate training data 2. Analyze clustering algorithms 3. Create a k-means clustering model 4. Apply the k-means model to the entire input volumes 5. Display the results using crossplot or corendering. Our k-means algorithm is very similar to the popular kmeans++ algorithm, with one additional step in the ...", "dateLastCrawled": "2022-01-16T17:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>Learning</b> for <b>Cybersecurity</b> 101 | by Alex Polyakov | Towards ...", "url": "https://towardsdatascience.com/machine-learning-for-cybersecurity-101-7822b802790b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-for-<b>cybersecurity</b>-101-7822b802790b", "snippet": "<b>Clustering is similar</b> to classification with the only but major difference. The information about the classes of the data is unknown. There is no idea whether this data can be classified. This is unsupervised <b>learning</b>. Supposedly, the best task for clustering is forensic analysis. The reasons, course, and consequences of an incident are obscure. It\u2019s required to classify all activities to find anomalies. Solutions to malware analysis (i.e., malware protection or secure email gateways) may ...", "dateLastCrawled": "2022-02-01T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "An overview of different <b>unsupervised learning</b> techniques | by Abhishek ...", "url": "https://towardsdatascience.com/an-overview-of-different-unsupervised-learning-techniques-facb1e1f3a27", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-overview-of-different-<b>unsupervised-learning</b>...", "snippet": "In this article, I want to walk you through the different <b>unsupervised learning</b> methods in <b>machine</b> <b>learning</b> with relevant codes. We will take a look at the k-means clustering algorithm, the Latent Dirichlet Allocation(LDA) for text data, Hierarchical and Density based clustering, Gaussian Mixture Models, Dimensionality Reduction techniques like PCA, Random Projections, Independent component Analysis and finally about cluster validation.", "dateLastCrawled": "2022-01-31T16:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Lecture 16. Manifold <b>Learning</b> - GitHub Pages", "url": "https://trevorcohn.github.io/comp90051-2017/slides/16_manifold_learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://trevorcohn.github.io/comp90051-2017/slides/16_manifold_<b>learning</b>.pdf", "snippet": "\u2022 Spectral <b>clustering is similar</b> to Isomap in that it also comprises a few standard blocks, including k-means clustering \u2022 In contrast to Isomap, spectral clustering uses a different non-linear mapping technique called Laplacian eigenmap 21. Statistical <b>Machine</b> <b>Learning</b> (S2 2017) Deck 16 Spectral clustering algorithm. 1. Construct similarity graph, use the corresponding adjacency matrix as a new similarity matrix \u2217 Just as in Isomap, the graph captures local geometry and breaks long ...", "dateLastCrawled": "2022-01-20T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is there any <b>machine</b> <b>learning</b> cheat sheet, like based on the data set ...", "url": "https://www.quora.com/Is-there-any-machine-learning-cheat-sheet-like-based-on-the-data-set-type-of-regression-classification-or-clustering-algorithm-which-should-be-used", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-there-any-<b>machine</b>-<b>learning</b>-cheat-sheet-like-based-on-the-data...", "snippet": "Answer: The key is to understand first what type of business problem are you solving? I follow below cheat sheet in order to break down a problem and then use the relevant algorithm. Based on the type of problem, the algorithms are selected. I am listing some of the important algorithms and bus...", "dateLastCrawled": "2022-01-03T09:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Difference Between <b>Classification</b> and <b>Clustering</b> (with Comparison Chart ...", "url": "https://techdifferences.com/difference-between-classification-and-clustering.html", "isFamilyFriendly": true, "displayUrl": "https://techdifferences.com/difference-between-<b>classification</b>-and-<b>clustering</b>.html", "snippet": "On the other hand, <b>Clustering is similar</b> to <b>classification</b> but there are no predefined class labels. <b>Classification</b> is geared with supervised <b>learning</b>. As against, <b>clustering</b> is also known as unsupervised <b>learning</b>. Training sample is provided in <b>classification</b> method while in case of <b>clustering</b> training data is not provided. Conclusion. <b>Classification</b> and <b>clustering</b> are the methods used in data mining for analysing the data sets and divide them on the basis of some particular <b>classification</b> ...", "dateLastCrawled": "2022-02-01T19:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Learning Predictive Clustering Rules</b>", "url": "https://www.researchgate.net/publication/225362870_Learning_Predictive_Clustering_Rules", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/225362870_<b>Learning_Predictive_Clustering_Rules</b>", "snippet": "framew ork predictiv e clustering rules (PCRs). The task of <b>learning</b> PCRs gener-. alizes the task of rule induction, on one hand, and clustering, and in particular. item set constrained clustering ...", "dateLastCrawled": "2021-09-30T21:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Novelty and Outlier Detection</b> | Linux Journal", "url": "https://www.linuxjournal.com/content/novelty-and-outlier-detection", "isFamilyFriendly": true, "displayUrl": "https://www.linuxjournal.com/content/<b>novelty-and-outlier-detection</b>", "snippet": "But as you&#39;ve also seen, <b>machine</b> <b>learning</b> can be used to &quot;cluster&quot; data\u2014that is, to find patterns that humans either can&#39;t or won&#39;t see, and to try to put the data into various &quot;clusters&quot;, or <b>machine</b>-driven categories. By asking the computer to divide data into distinct groups, you gain the opportunity to find and make use of previously undetected patterns. <b>Just as clustering</b> can be used to divide data into a number of coherent groups, it also can be used to decide which data points belong ...", "dateLastCrawled": "2022-01-25T17:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Bootstrap Method for Goodness of Fit and Model Selection with a ...", "url": "https://www.nature.com/articles/s41598-019-53166-6", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-019-53166-6", "snippet": "The training data can be used to train any <b>learning</b> algorithm for prediction of the model index. Examples include random forest, support vector <b>machine</b>, and ensemble <b>learning</b> algorithms like the ...", "dateLastCrawled": "2022-01-17T18:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Novelty Detection <b>Machine</b> <b>Learning</b> - XpCourse", "url": "https://www.xpcourse.com/novelty-detection-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.xpcourse.com/novelty-detection-<b>machine</b>-<b>learning</b>", "snippet": "novelty detection <b>machine</b> <b>learning</b> provides a comprehensive and comprehensive pathway for students to see progress after the end of each module. With a team of extremely dedicated and quality lecturers, novelty detection <b>machine</b> <b>learning</b> will not only be a place to share knowledge but also to help students get inspired to explore and discover many creative ideas from themselves.Clear and detailed training methods for each lesson will ensure that students can acquire and apply knowledge into ...", "dateLastCrawled": "2022-01-08T05:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Federated Learning through Distance-Based Clustering</b> | by Phani Rohith ...", "url": "https://towardsdatascience.com/federated-learning-through-distance-based-clustering-5b09c3700b3c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>federated-learning-through-distance-based-clustering</b>-5b...", "snippet": "<b>Clustering can be thought of as</b> combining similar devices. It allows the devices to benefit from an added layer of collaboration from devices with similar <b>learning</b> traits. For example, assume that the EMNIST dataset was being used for training, and two devices can likely have a great deal of experience <b>learning</b> to identify the number 5 class label. By sharing their weights, they can ideally help each other learn at a faster rate. Clustering occurs during the second phase of our model and ...", "dateLastCrawled": "2022-01-28T11:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Federated Learning through Distance-Based Clustering</b> - FIAKS", "url": "https://fiaks.com/federated-learning-through-distance-based-clustering/", "isFamilyFriendly": true, "displayUrl": "https://fiaks.com/<b>federated-learning-through-distance-based-clustering</b>", "snippet": "<b>Clustering can be thought of as</b> combining similar devices. It allows the devices to benefit from an added layer of collaboration from devices with similar <b>learning</b> traits. For example, assume that the EMNIST dataset was being used for training, and two devices can likely have a great deal of experience <b>learning</b> to identify the number 5 class label. By sharing their weights, they can ideally help each other learn at a faster rate. Clustering occurs during the second phase of our model and ...", "dateLastCrawled": "2022-01-18T04:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "1.4 - Sampling Schemes | STAT 504", "url": "https://online.stat.psu.edu/stat504/lesson/1/1.4", "isFamilyFriendly": true, "displayUrl": "https://online.stat.psu.edu/stat504/lesson/1/1.4", "snippet": "<b>Clustering can be thought of as</b> a violation of either (a) or (b). Example: Eye Color. In this example, eye color was recorded for n = 96 persons. Eye color Count; Brown: 46: Blue: 22: Green: 26: Other: 2: Total: 96: Suppose that the sample included members from the same family as well as unrelated individuals. Persons from the same family are more likely to have similar eye color than unrelated persons, so the assumptions of the multinomial model would be violated. If both parents have brown ...", "dateLastCrawled": "2022-01-31T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Hybrid Inductive Machine Learning: An Overview</b> of CLIP Algorithms", "url": "http://biomine.cs.vcu.edu/papers/chapterCLIP42001.pdf", "isFamilyFriendly": true, "displayUrl": "biomine.cs.vcu.edu/papers/chapterCLIP42001.pdf", "snippet": "each found cluster, a concept description is generated. Conceptual <b>clustering can be thought of as</b> a hybrid of unsupervised (clustering) and supervised (characterization) <b>learning</b>. In theory, it is possible to transform a supervised <b>machine</b> <b>learning</b> algorithm into an unsupervised one (Langley, 1996) by running the supervised algorithm as many times as there are features describing the examples, each time with a different feature playing the role of the class attribute. Two basic techniques ...", "dateLastCrawled": "2022-01-30T00:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Clustering | SpringerLink", "url": "https://link.springer.com/chapter/10.1007/978-1-4842-6543-7_6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-1-4842-6543-7_6", "snippet": "Clustering is an unsupervised <b>machine</b> <b>learning</b> technique to automatically categorize datasets like these customers/buyers are for the store. In more general terms, <b>clustering can be thought of as</b> automatic grouping of things, behaviors, and so on. There is obviously a known right answer to the number of groups present in a dataset, but it is impossible to be known for each and every dataset in prior.", "dateLastCrawled": "2022-01-19T02:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "CSE 446 <b>Machine</b> <b>Learning</b>, Spring 2016 Homework 4", "url": "https://courses.cs.washington.edu/courses/cse446/16sp/homework/CSE446_HW4.pdf", "isFamilyFriendly": true, "displayUrl": "https://courses.cs.washington.edu/courses/cse446/16sp/homework/CSE446_HW4.pdf", "snippet": "Please be reminded that you are NOT allowed to use existing <b>machine</b> <b>learning</b> libraries such as scikitlearn. 4.3 Within group sum of squares The goal of <b>clustering can be thought of as</b> minimizing the variation within groups and consequently maximizing the variation between groups. A good model has low sum of squares within each group. We de ne sum of squares in the traditional way. Let C k be the kth cluster and let k be the empirical mean of the observations x i in cluster C k. Then the ...", "dateLastCrawled": "2021-11-01T09:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Cx <b>Interactive Tools for Fantasy Football</b> ... Predictions using <b>Machine</b> ...", "url": "https://studylib.net/doc/10595529/cx-interactive--tools--for--fantasy--football-...-predict...", "isFamilyFriendly": true, "displayUrl": "https://studylib.net/doc/10595529/cx-<b>interactive--tools--for--fantasy--football</b>...", "snippet": "<b>Clustering can be thought of as</b> the unsupervised <b>learning</b> equivalent of classification, because the groups of the input data points are not known beforehand. Clustering involves grouping data into categories based on some measure of inherent similarity or distance, such that objects or data points within the same group or cluster are morse similar to each other than to those in other clusters. Regression is a supervised <b>learning</b> problem in which the outputs are continuous values, rather than ...", "dateLastCrawled": "2021-12-06T17:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Utility of Clustering in Prediction Tasks", "url": "https://home.ttic.edu/~shubhendu/Papers/clustering_bagging.pdf", "isFamilyFriendly": true, "displayUrl": "https://home.ttic.edu/~shubhendu/Papers/clustering_bagging.pdf", "snippet": "Aggregation, <b>Machine</b> <b>Learning</b> I. INTRODUCTION ne of the motivations to this work is one of the author\u2019s (Zachary A. Pardos) successful participation in the 2010 KDD Cup, which involved a prediction task on an educational dataset. Methods such as Bagged Decision Trees were used to get the second position in the student category. The dataset had instances for a number of students. Since students can be crudely binned into categories in terms of <b>learning</b> rate, forgetting rate etc., a natural ...", "dateLastCrawled": "2022-02-03T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is <b>the difference between classification and clustering? can</b> we ...", "url": "https://www.researchgate.net/post/What_is_the_difference_between_classification_and_clustering_can_we_make_a_combination_between_them3", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What_is_<b>the_difference_between_classification_and</b>...", "snippet": "Classification is supervised <b>machine</b> <b>learning</b> techniques, while clustering is unsupervised <b>machine</b> <b>learning</b>. Both can used to predict the class of given data (i.e., process related to categorization).", "dateLastCrawled": "2022-01-22T14:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>GitHub</b> - <b>SberProcessMining/Sber_Process_Mining</b>", "url": "https://github.com/SberProcessMining/Sber_Process_Mining", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/SberProcessMining/Sber_Process_Mining", "snippet": "Apply <b>machine</b> <b>learning</b> to vectorize and cluster the process The idea to combine process mining and <b>machine</b> <b>learning</b> techniques aims to take the process analysis to a whole new level. In this way, process vectorization and process <b>clustering can be thought of as</b> the starting point of process analysis enhancement.", "dateLastCrawled": "2022-02-01T10:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Single-phase high-entropy alloys \u2013 A critical update - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S1044580319329134", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1044580319329134", "snippet": "Local <b>clustering can be compared to</b> nanoparticle precipitation in some way. Therefore, physical and mechanical properties should be measured on thermally equilibrated samples, only, to be reliable. And, if possible, as a function of temperature within the stability region of the HEA. In contrast to the predictions of the existence of thousands or even millions of HEAs (see, e.g., Widom [13,33], Senkov et al. ), only a very limited number (\u224880) of intermetallic systems has been identified ...", "dateLastCrawled": "2022-01-11T04:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Viruses | Free Full-Text | <b>Spatiotemporal Analysis of COVID-19</b> ...", "url": "https://www.mdpi.com/1999-4915/13/3/463/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1999-4915/13/3/463/htm", "snippet": "(1) Background: A better understanding of COVID-19 dynamics in terms of interactions among individuals would be of paramount importance to increase the effectiveness of containment measures. Despite this, the research lacks spatiotemporal statistical and mathematical analysis based on large datasets. We describe a novel methodology to extract useful spatiotemporal information from COVID-19 pandemic data. (2) Methods: We perform specific analyses based on mathematical and statistical tools ...", "dateLastCrawled": "2021-12-25T05:36:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(clustering)  is like +(group of friends)", "+(clustering) is similar to +(group of friends)", "+(clustering) can be thought of as +(group of friends)", "+(clustering) can be compared to +(group of friends)", "machine learning +(clustering AND analogy)", "machine learning +(\"clustering is like\")", "machine learning +(\"clustering is similar\")", "machine learning +(\"just as clustering\")", "machine learning +(\"clustering can be thought of as\")", "machine learning +(\"clustering can be compared to\")"]}