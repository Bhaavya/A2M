{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Google AI Blog: <b>Equality</b> <b>of Opportunity</b> in <b>Machine</b> <b>Learning</b>", "url": "https://ai.googleblog.com/2016/10/equality-of-opportunity-in-machine.html", "isFamilyFriendly": true, "displayUrl": "https://ai.googleblog.com/2016/10/<b>equality</b>-<b>of-opportunity</b>-in-<b>machine</b>.html", "snippet": "As <b>machine</b> <b>learning</b> technology progresses rapidly, there is much interest in understanding its societal impact. A particularly successful branch of <b>machine</b> <b>learning</b> is supervised <b>learning</b>. With enough past data and computational resources, <b>learning</b> algorithms often produce surprisingly effective predictors of future events. To take one hypothetical example: an <b>algorithm</b> could, for example, be used to predict with high accuracy who will pay back their loan. Lenders might then use such a ...", "dateLastCrawled": "2022-02-02T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Equality of Opportunity in Machine Learning</b> | googblogs.com", "url": "https://www.googblogs.com/equality-of-opportunity-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.googblogs.com/<b>equality-of-opportunity-in-machine-learning</b>", "snippet": "<b>Equality of Opportunity in Machine Learning</b>. Posted by Moritz Hardt, Research Scientist, Google Brain Team As <b>machine</b> <b>learning</b> technology progresses rapidly, there is much interest in understanding its societal impact. A particularly successful branch of <b>machine</b> <b>learning</b> is supervised <b>learning</b>. With enough past data and computational resources, <b>learning</b> algorithms often produce surprisingly effective predictors of future events. To take one hypothetical example: an <b>algorithm</b> could, for ...", "dateLastCrawled": "2021-12-17T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Algorithmic Discrimination and Equality of Opportunity</b> \u2013 Data Science ...", "url": "https://blogs.ischool.berkeley.edu/w231/2018/04/07/algorithmic-discrimination-and-equality-of-opportunity/", "isFamilyFriendly": true, "displayUrl": "https://blogs.ischool.berkeley.edu/w231/2018/04/07/<b>algorithm</b>ic-discrimination-and...", "snippet": "Historically, judges have made these subjective determinations based on personal experience and professional expertise; the introduction of an objective, data-driven <b>algorithm</b> into these settings seems <b>like</b> a sensible thing to do. Indeed, it sounds <b>like</b> a marquee application for the field of <b>machine</b> <b>learning</b>.", "dateLastCrawled": "2022-01-29T17:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Equality</b> <b>of Opportunity</b> in Supervised <b>Learning</b>", "url": "https://home.ttic.edu/~nati/Publications/HardtPriceSrebro2016.pdf", "isFamilyFriendly": true, "displayUrl": "https://home.ttic.edu/~nati/Publications/HardtPriceSrebro2016.pdf", "snippet": "<b>Equality</b> <b>of Opportunity</b> in Supervised <b>Learning</b> Moritz Hardt Eric Price Nathan Srebro October 7, 2016 Abstract We propose a criterion for discrimination against a speci\ufb01ed sensitive attribute in su- pervised <b>learning</b>, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are avail-able, we show how to optimally adjust any learned predictor so as to remove discrimination according to our ...", "dateLastCrawled": "2022-01-31T14:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Equality of Opportunity in Supervised Learning</b>", "url": "https://www.researchgate.net/publication/308980568_Equality_of_Opportunity_in_Supervised_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../308980568_<b>Equality_of_Opportunity_in_Supervised_Learning</b>", "snippet": "This notion is similar to the well studied notion of equal <b>opportunity</b> in the <b>machine</b> <b>learning</b> literature (see [10]). With this in mind, the proposed <b>algorithm</b> iteratively constructs allocations ...", "dateLastCrawled": "2022-01-15T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Evolution of Inequality <b>of Opportunity</b> in Germany: <b>A Machine</b> ...", "url": "https://onlinelibrary.wiley.com/doi/10.1111/roiw.12502", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1111/roiw.12502", "snippet": "We show that measures of inequality <b>of opportunity</b> (IOP) fully consistent with the IOP theory of Roemer (1998) can be straightforwardly estimated by adopting <b>a machine</b> <b>learning</b> approach, and apply our method to analyze the development of IOP in Germany during the past three decades. Hereby, we take advantage of information contained in 25 waves of the Socio\u2010Economic Panel. Our analysis shows that in Germany IOP declined immediately after reunification, increased in the first decade of the ...", "dateLastCrawled": "2021-03-19T12:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Identifying the roots of inequality <b>of opportunity</b> in South Korea by ...", "url": "https://www.nature.com/articles/s41599-021-01026-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41599-021-01026-y", "snippet": "In addition, the <b>machine</b> <b>learning</b> <b>algorithm</b> is limited, thereby making it difficult to interpret the estimated results without knowledge of the process between the input and output of data, <b>like</b> a ...", "dateLastCrawled": "2022-02-03T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[PDF] <b>Equality of Opportunity in Supervised Learning</b> | Semantic Scholar", "url": "https://www.semanticscholar.org/paper/Equality-of-Opportunity-in-Supervised-Learning-Hardt-Price/d42b11ce90c9c69a20ed015b73dc33e0e4100a7b", "isFamilyFriendly": true, "displayUrl": "https://www.semanticscholar.org/paper/<b>Equality-of-Opportunity-in-Supervised-Learning</b>...", "snippet": "<b>Equality of Opportunity in Supervised Learning</b> @inproceedings{Hardt2016EqualityOO, title={<b>Equality of Opportunity in Supervised Learning</b>}, author={Moritz Hardt and Eric Price and Nathan Srebro}, booktitle={NIPS}, year={2016} } Moritz Hardt, Eric Price, Nathan Srebro; Published in NIPS 7 October 2016; Computer Science, Mathematics; We propose a criterion for discrimination against a specified sensitive attribute in supervised <b>learning</b>, where the goal is to predict some target based on ...", "dateLastCrawled": "2021-12-16T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Discrimination by <b>algorithm</b>: scientists devise test to detect AI bias ...", "url": "https://www.theguardian.com/technology/2016/dec/19/discrimination-by-algorithm-scientists-devise-test-to-detect-ai-bias", "isFamilyFriendly": true, "displayUrl": "https://<b>www.theguardian.com</b>/technology/2016/dec/19/discrimination-by-<b>algorithm</b>...", "snippet": "Their approach, called <b>Equality</b> <b>of Opportunity</b> in Supervised <b>Learning</b>, works on the basic principle that when an <b>algorithm</b> makes a decision about an individual - be it to show them an online ad or ...", "dateLastCrawled": "2021-12-09T07:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>The Problem of Biased Algorithms and How to Prevent</b> Them | DataScience.US", "url": "https://www.datascience.us/problem-biased-algorithms-prevent/", "isFamilyFriendly": true, "displayUrl": "https://www.datascience.us/problem-biased-<b>algorithms</b>-prevent", "snippet": "<b>A machine</b> <b>learning</b> <b>algorithm</b> is not usually trained on variables <b>like</b> race, sex, or similar variables that could be used to treat someone in a biased way. Instead it could be trained on things <b>like</b> the words used in loan applications. A recent study done by three economists found that if a person used one of five words or phrases (God, promise, will pay, thank you, hospital), they were much less likely to pay back their loans. A bank might use this data to try and minimize the amount of ...", "dateLastCrawled": "2022-02-02T00:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "<b>Equality</b> <b>of opportunity</b> suggests that people <b>similar</b> in real life (\\(Y\\)) get classified similarly (\\(\\hat{Y}\\)). ... From a <b>machine</b> <b>learning</b> perspective, the interesting point is the classification of metrics into bias-preserving and bias-transforming. The terms speak for themselves: Metrics in the first group reflect biases in the dataset used for training; ones in the second do not. In that way, the distinction parallels Friedler, Scheidegger, and Venkatasubramanian \u2019s confrontation of ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Tutorial #1: <b>bias and fairness in AI</b> - Borealis AI", "url": "https://www.borealisai.com/en/blog/tutorial1-bias-and-fairness-ai/", "isFamilyFriendly": true, "displayUrl": "https://www.borealisai.com/en/blog/tutorial1-bias-and-fairness-ai", "snippet": "Complementary to this is individual fairness which mandates that <b>similar</b> individuals should be treated similarly regardless of group membership. In this blog, we&#39;ll mainly focus on group fairness, three definitions of which include: (i) demographic parity, (ii) <b>equality</b> of odds, and (iii) <b>equality</b> <b>of opportunity</b>. We now discuss each in turn. Demographic Parity. Demographic parity or statistical parity suggests that a predictor is unbiased if the prediction $\\hat{y}$ is independent of the ...", "dateLastCrawled": "2022-02-02T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Identifying the roots of inequality <b>of opportunity</b> in South Korea by ...", "url": "https://www.nature.com/articles/s41599-021-01026-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41599-021-01026-y", "snippet": "In addition, the <b>machine</b> <b>learning</b> <b>algorithm</b> is limited, thereby making it difficult to interpret the estimated results without knowledge of the process between the input and output of data, like a ...", "dateLastCrawled": "2022-02-03T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Equality</b> <b>of opportunity</b> in travel behavior prediction with deep neural ...", "url": "https://www.sciencedirect.com/science/article/pii/S0968090X21004058", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0968090X21004058", "snippet": "Although researchers increasingly adopt <b>machine</b> <b>learning</b> to model travel behavior, they predominantly focus on prediction accuracy, ignoring the ethical challenges embedded in <b>machine</b> <b>learning</b> algorithms. This study introduces an important missing dimension - computational fairness - to travel behavior analysis. It highlights the accuracy-fairness tradeoff instead of the single dimensional focus on prediction accuracy in the contexts of deep neural network (DNN) and discrete choice models ...", "dateLastCrawled": "2022-01-20T13:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "[PDF] <b>Equality of Opportunity in Supervised Learning</b> | Semantic Scholar", "url": "https://www.semanticscholar.org/paper/Equality-of-Opportunity-in-Supervised-Learning-Hardt-Price/d42b11ce90c9c69a20ed015b73dc33e0e4100a7b", "isFamilyFriendly": true, "displayUrl": "https://www.semanticscholar.org/paper/<b>Equality-of-Opportunity-in-Supervised-Learning</b>...", "snippet": "<b>Equality of Opportunity in Supervised Learning</b> @inproceedings{Hardt2016EqualityOO, title={<b>Equality of Opportunity in Supervised Learning</b>}, author={Moritz Hardt and Eric Price and Nathan Srebro}, booktitle={NIPS}, year={2016} } Moritz Hardt, Eric Price, Nathan Srebro; Published in NIPS 7 October 2016; Computer Science, Mathematics; We propose a criterion for discrimination against a specified sensitive attribute in supervised <b>learning</b>, where the goal is to predict some target based on ...", "dateLastCrawled": "2021-12-16T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Equality</b> of <b>Learning Opportunity in Personalized Recommendations</b>", "url": "https://www.researchgate.net/publication/342027329_Equality_of_Learning_Opportunity_in_Personalized_Recommendations", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342027329_<b>Equality</b>_of_<b>Learning</b>_<b>Opportunity</b>_in...", "snippet": "<b>Equality</b> of <b>Learning Opportunity in Personalized Recommendations</b> 19 in general, it is hard to plug-in the balancing phase into the internal logic of a recommender system, we propose to re-arrange ...", "dateLastCrawled": "2021-11-18T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Fairness Criteria</b> | Module 3: Pedagogical Framework for Addressing ...", "url": "https://ocw.mit.edu/resources/res-ec-001-exploring-fairness-in-machine-learning-for-international-development-spring-2020/module-three-framework/fairness-criteria/", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/resources/res-ec-001-exploring-fairness-in-<b>machine</b>-<b>learning</b>-for...", "snippet": "This means that we are only enforcing <b>equality</b> among individuals who reach <b>similar</b> outcomes. This <b>algorithm</b> is more challenging to implement, but achieves one of the highest levels of algorithmic fairness. For example, the probability for a qualified applicant being hired and the probability of an unqualified applicant not being hired should be the same across all protected attributes. As compared to demographic parity, if a large number of unqualified male applicants apply for the job, the ...", "dateLastCrawled": "2022-01-04T22:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Programming Fairness in Algorithms</b> | by Matthew Stewart, PhD Researcher ...", "url": "https://towardsdatascience.com/programming-fairness-in-algorithms-4943a13dd9f8", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>programming-fairness-in-algorithms</b>-4943a13dd9f8", "snippet": "<b>Machine</b> <b>learning</b> fairness is a young subfield of <b>machine</b> <b>learning</b> that has been growing in popularity over the last few years in response to the rapid integration of <b>machine</b> <b>learning</b> into social realms. Computer scientists, unlike doctors, are not necessarily trained to consider the ethical implications of their actions. It is only relatively recently (one could argue since the advent of social media) that the designs or inventions of computer scientists were able to take on an ethical ...", "dateLastCrawled": "2022-01-23T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "We Want Fair AI Algorithms \u2013 But How To Define Fairness? (Fairness ...", "url": "https://mostly.ai/blog/we-want-fair-ai-algorithms-but-how-to-define-fairness/", "isFamilyFriendly": true, "displayUrl": "https://<b>mostly.ai</b>/blog/we-want-fair-ai-<b>algorithms</b>-but-how-to-define-fairness", "snippet": "An integral part of the factory is a <b>machine</b> <b>learning</b> <b>algorithm</b> that automatically analyzes tomatoes on the conveyor belt and classifies them into fresh and bad (or rotten) tomatoes. Fresh tomatoes are transferred into the \u201cAcceptable\u201d bin and ultimately end up in the spaghetti sauce, rotten tomatoes end up in the \u201cDiscard\u201d bin and are thrown away. Consider there exist only two kinds of tomatoes worldwide: 80% of all tomatoes are red tomatoes and 20% of them are yellow. Apart from ...", "dateLastCrawled": "2022-01-29T01:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Algorithm</b> <b>Equality</b> and International Law: An Incongruous Reality", "url": "https://www.jindalsocietyofinternationallaw.com/post/algorithm-equality-and-international-law-an-incongruous-reality", "isFamilyFriendly": true, "displayUrl": "https://www.jindalsocietyofinternationallaw.com/post/<b>algorithm</b>-<b>equality</b>-and...", "snippet": "An <b>algorithm</b> bias is a default in the <b>machine</b> <b>learning</b> system due to failed training data sets or the sided assumptions during the development of the <b>algorithm</b>. Gender bias has persisted in society for ages. Though there are international and regional instruments thriving to bring <b>equality</b> between the genders, they seem to have become incompetent given the new \u2018algorithmic bias\u2019.", "dateLastCrawled": "2022-01-10T19:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>A Moral Framework for Understanding Fair ML through Economic</b> Models of ...", "url": "https://www.cs.cmu.edu/~hheidari/heidari2019moral.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.cmu.edu/~hheidari/heidari2019moral.pdf", "snippet": "<b>Equality</b> <b>of Opportunity</b> (EOP), Fairness for <b>Machine</b> <b>Learning</b>, Rawlsian and Luck Egalitarian EOP, Statistical Parity, <b>Equality</b> of Odds, Predictive Value Parity ACM Reference Format: Hoda Heidari, Michele Loi, Krishna P. Gummadi, and Andreas Krause. 2019. <b>A Moral Framework for Understanding Fair ML, through Economic</b> Models of <b>Equality</b> <b>of Opportunity</b>. In FAT* \u201919: Conference on Fairness, Account-ability, and Transparency (FAT* \u201919), January 29\u201331, 2019, Atlanta, GA, USA. ACM,NewYork,NY ...", "dateLastCrawled": "2021-09-09T14:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Rawlsian Fairness for Machine Learning</b> - Semantic Scholar", "url": "https://www.semanticscholar.org/paper/Rawlsian-Fairness-for-Machine-Learning-Joseph-Kearns/2d55ff4542eaae18dcd10c2cd74199396e260402", "isFamilyFriendly": true, "displayUrl": "https://www.semanticscholar.org/paper/<b>Rawlsian-Fairness-for-Machine-Learning</b>-Joseph...", "snippet": "Motivated by concerns that automated decision-making procedures <b>can</b> unintentionally lead to discriminatory behavior, we study a technical definition of fairness modeled after John Rawls&#39; notion of &quot;fair <b>equality</b> <b>of opportunity</b>&quot;. In the context of a simple model of online decision making, we give an <b>algorithm</b> that satisfies this fairness constraint, while still being able to learn at a rate that is comparable to (but necessarily worse than) that of the best algorithms absent a fairness ...", "dateLastCrawled": "2021-12-21T06:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "2. What is Fairness? \u2014 Fairness &amp; Algorithmic Decision Making", "url": "https://afraenkel.github.io/fairness-book/content/02-frameworks.html", "isFamilyFriendly": true, "displayUrl": "https://afraenkel.github.io/fairness-book/content/02-frameworks.html", "snippet": "One limitation of Formal <b>Equality</b> <b>of Opportunity</b> (FEO) is that while the distribution of goods is open to all, the ability to take advantage of such an <b>opportunity</b> may effectively be non-existent. For example, a job may be available through passing an arbitrary examination that only very wealthy pass (because only they <b>can</b> afford the training). While this job is theoretically available to everyone (satisfying formal EO), it in practice is only available to the very wealthy.", "dateLastCrawled": "2022-01-31T18:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Handling Discriminatory Biases in Data for <b>Machine Learning</b> | by ...", "url": "https://towardsdatascience.com/machine-learning-and-discrimination-2ed1a8b01038", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine-learning</b>-and-<b>discrimination</b>-2ed1a8b01038", "snippet": "Food for <b>Thought</b>. To end such a long and serious article, I leave you with a quote from Google about <b>discrimination</b> in <b>machine learning</b> to mull over. \u201cOptimizing for equal <b>opportunity</b> is just one of many tools that <b>can</b> be used to improve <b>machine learning</b> systems \u2014 and mathematics alone is unlikely to lead to the best solutions. Attacking ...", "dateLastCrawled": "2022-01-29T20:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Differentiating Bias and Fairness in <b>Machine</b> <b>Learning</b>", "url": "https://www.closedloop.ai/post/bias-v-fairness-in-ml", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/bias-v-fairness-in-ml", "snippet": "Differentiating Bias and Fairness in <b>Machine</b> <b>Learning</b>. Joseph Gartner. May 26, 2021. ClosedLoop was recently recognized as winner of the AI for Health Outcomes Challenge by the Center for Medicare and Medicaid Services (CMS). The criteria for judgement were the overall accuracy of the model, the transparency of the decision criteria, and a ...", "dateLastCrawled": "2021-12-28T14:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Big data and <b>machine learning</b> algorithms for health-care delivery - The ...", "url": "https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(19)30149-4/fulltext", "isFamilyFriendly": true, "displayUrl": "https://<b>www.thelancet.com</b>/journals/lanonc/article/PIIS1470-2045(19)30149-4/fulltext", "snippet": "Analysis of big data by <b>machine learning</b> offers considerable advantages for assimilation and evaluation of large amounts of complex health-care data. However, to effectively use <b>machine learning</b> tools in health care, several limitations must be addressed and key issues considered, such as its clinical implementation and ethics in health-care delivery. Advantages of <b>machine learning</b> include flexibility and scalability compared with traditional biostatistical methods, which makes it deployable ...", "dateLastCrawled": "2022-01-25T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "MLW 2019: Aligning on the role of AI in preparing ... - <b>Learning</b> <b>Equality</b>", "url": "https://blog.learningequality.org/mlw-2019-aligning-on-the-role-of-ai-in-preparing-curriculum-for-emergency-contexts-a974fa5c2260", "isFamilyFriendly": true, "displayUrl": "https://blog.<b>learningequality</b>.org/mlw-2019-aligning-on-the-role-of-ai-in-preparing...", "snippet": "The week was full of <b>learning</b>, connecting, and sharing with our peers in the field. We attended <b>thought</b>-provoking sessions that illustrated the risks, especially for marginalized and vulnerable communities, of excluding humane principles in the development of AI as it becomes more ubiquitous in education and the world at large. However, these sessions also revealed the deep potential that AI holds to empower a wide range of initiatives \u2014 from creating more effective personalized digital ...", "dateLastCrawled": "2022-01-27T19:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Tuning EU <b>equality</b> law <b>to algorithmic discrimination: Three pathways to</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/1023263X20982173", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/1023263X20982173", "snippet": "A well-known example of the way an <b>algorithm</b> is able to infer membership of a particular ethnic group is the case of discrimination arising from algorithmic prediction models that process residency data. 53 An <b>algorithm</b> that used the distance between workers\u2019 home and workplace as a predictor for job tenure was for example found discriminatory because it disproportionately disadvantaged ethnic minority workers. 54 Discrimination <b>can</b> also arise in cases of misprofiling, which takes place ...", "dateLastCrawled": "2022-01-29T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Discrimination and Oppression</b> | SpringerLink", "url": "https://link.springer.com/chapter/10.1007/978-0-230-21647-1_4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-0-230-21647-1_4", "snippet": "Promoting <b>equality</b>, as we have seen, involves countering <b>discrimination and oppression</b>. This chapter therefore examines: the relationship between <b>discrimination and oppression</b>; the various processes by which <b>discrimination</b> occurs; the ways in which <b>discrimination</b> <b>can</b> be categorized; and. the forms of oppression that arise as a result of the ...", "dateLastCrawled": "2022-02-02T21:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Can</b> Algorithms be Racist?. A brief exploration of juristic and\u2026 | by ...", "url": "https://towardsdatascience.com/can-algorithms-be-racist-6dddf8d69065", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>can</b>-<b>algorithms</b>-be-racist-6dddf8d69065", "snippet": "For example, the <b>algorithm</b> used in Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) in the U.S., has an inherent bias toward African-Americans, as it gives this group a higher risk rating than Caucasians, even when both have the exact offender profile (Mehrabi et al., 2019). Obermeyer et al. (2019) references a popular <b>algorithm</b> widely used within US hospitals that lessens the likelihood of Black people accessing medical programs for the same complex health ...", "dateLastCrawled": "2022-01-30T02:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Equality</b> <b>of opportunity</b> in travel behavior prediction with deep neural ...", "url": "https://www.sciencedirect.com/science/article/pii/S0968090X21004058", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0968090X21004058", "snippet": "Although researchers increasingly adopt <b>machine</b> <b>learning</b> to model travel behavior, they predominantly focus on prediction accuracy, ignoring the ethical challenges embedded in <b>machine</b> <b>learning</b> algorithms. This study introduces an important missing dimension - computational fairness - to travel behavior analysis. It highlights the accuracy-fairness tradeoff instead of the single dimensional focus on prediction accuracy in the contexts of deep neural network (DNN) and discrete choice models ...", "dateLastCrawled": "2022-01-20T13:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Identifying the roots of inequality <b>of opportunity</b> in South Korea by ...", "url": "https://www.nature.com/articles/s41599-021-01026-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41599-021-01026-y", "snippet": "In addition, the <b>machine</b> <b>learning</b> <b>algorithm</b> is limited, thereby making it difficult to interpret the estimated results without knowledge of the process between the input and output of data, like a ...", "dateLastCrawled": "2022-02-03T04:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The Evolution of Inequality <b>of Opportunity</b> in Germany: A <b>Machine</b> ...", "url": "https://www.researchgate.net/publication/339189246_The_Evolution_of_Inequality_of_Opportunity_in_Germany_A_Machine_Learning_Approach", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339189246_The_Evolution_of_In<b>equality</b>_of...", "snippet": "We show that measures of inequality <b>of opportunity</b> (IOP) fully consistent with the IOP theory of Roemer (1998) <b>can</b> be straightforwardly estimated by adopting a <b>machine</b> <b>learning</b> approach, and apply ...", "dateLastCrawled": "2022-01-20T22:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Equality</b> of <b>Learning Opportunity in Personalized Recommendations</b>", "url": "https://www.researchgate.net/publication/342027329_Equality_of_Learning_Opportunity_in_Personalized_Recommendations", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342027329_<b>Equality</b>_of_<b>Learning</b>_<b>Opportunity</b>_in...", "snippet": "In this paper, we introduced a new metric of <b>learning</b> <b>opportunity</b> <b>equality</b>. among learners in the context of personalized recommendations. Then, we. proposed a re-ranking procedure able to ...", "dateLastCrawled": "2021-11-18T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bias and Fairness in Machine Learning</b> - Abhishek Tiwari", "url": "https://www.abhishek-tiwari.com/bias-and-fairness-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.abhishek-tiwari.com/<b>bias-and-fairness-in-machine-learning</b>", "snippet": "Wall Street Journal investigators showed that Staples\u2019 online pricing <b>algorithm</b> discriminated against lower-income people; Black people were more likely to be assessed as having a higher risk of recidivism when using commercial prediction tools such as COMPAS ; An insurance company that used <b>machine</b> <b>learning</b> to workout insurance premiums involuntarily discriminated against elderly patients; A credit card company used tracking information to personalize offers steering minorities into ...", "dateLastCrawled": "2022-01-29T16:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Big data and <b>machine learning</b> algorithms for health-care delivery - The ...", "url": "https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(19)30149-4/fulltext", "isFamilyFriendly": true, "displayUrl": "https://<b>www.thelancet.com</b>/journals/lanonc/article/PIIS1470-2045(19)30149-4/fulltext", "snippet": "Analysis of big data by <b>machine learning</b> offers considerable advantages for assimilation and evaluation of large amounts of complex health-care data. However, to effectively use <b>machine learning</b> tools in health care, several limitations must be addressed and key issues considered, such as its clinical implementation and ethics in health-care delivery. Advantages of <b>machine learning</b> include flexibility and scalability <b>compared</b> with traditional biostatistical methods, which makes it deployable ...", "dateLastCrawled": "2022-01-25T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "When Good Algorithms Go Sexist: Why and How to Advance AI <b>Gender</b> Equity", "url": "https://ssir.org/articles/entry/when_good_algorithms_go_sexist_why_and_how_to_advance_ai_gender_equity", "isFamilyFriendly": true, "displayUrl": "https://ssir.org/articles/entry/when_good_<b>algorithms</b>_go_sexist_why_and_how_to_advance...", "snippet": "Seven actions social change leaders and <b>machine</b> <b>learning</b> developers <b>can</b> take to build <b>gender</b>-smart artificial intelligence for a more just world. Cite; share; comment; print; order reprints; related stories ; By Genevieve Smith &amp; Ishita Rustagi Mar. 31, 2021 (Photo by iStock/Pitiphothivichit) In 2019, Genevieve (co-author of this article) and her husband applied for the same credit card. Despite having a slightly better credit score and the same income, expenses, and debt as her husband, the ...", "dateLastCrawled": "2022-01-28T04:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A seat at <b>the table: equality, diversity &amp; inclusion</b>", "url": "https://www.aiimi.com/insights/a-seat-at-the-table-equality-diversity-inclusion", "isFamilyFriendly": true, "displayUrl": "https://www.aiimi.com/insights/a-seat-at-<b>the-table-equality-diversity-inclusion</b>", "snippet": "It provides an <b>opportunity</b> to be comfortable being uncomfortable, building with others in mind and creating a business or product that is relatable. It is the blueprint for a business to transcend the times and drive the working culture forward. In my career, as a black man who is a data scientist, I\u2019ve found I have had to work extra hard. At the heart of this has been a covert battle against pre-conceived assumptions. In the past, I compensated subconsciously by speaking in a higher tone ...", "dateLastCrawled": "2022-01-16T05:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Tuning EU <b>equality</b> law <b>to algorithmic discrimination: Three pathways to</b> ...", "url": "https://journals.sagepub.com/doi/full/10.1177/1023263X20982173", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/1023263X20982173", "snippet": "A well-known example of the way an <b>algorithm</b> is able to infer membership of a particular ethnic group is the case of discrimination arising from algorithmic prediction models that process residency data. 53 An <b>algorithm</b> that used the distance between workers\u2019 home and workplace as a predictor for job tenure was for example found discriminatory because it disproportionately disadvantaged ethnic minority workers. 54 Discrimination <b>can</b> also arise in cases of misprofiling, which takes place ...", "dateLastCrawled": "2022-01-29T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>can</b> I change the training threshold for any <b>learning</b> <b>algorithm</b> in ...", "url": "https://stackoverflow.com/questions/63672643/how-can-i-change-the-training-threshold-for-any-learning-algorithm-in-sklearn", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/63672643/how-<b>can</b>-i-change-the-training-threshold...", "snippet": "There is no threshold involved in a probabilistic classifier training (by scikit-learn or any other framework).. A threshold is necessary at inference time in order to convert the probabilistic predictions to hard labels, which in turn is necessary in order to calculate what are essentially business metrics like accuracy, precision, recall etc. But these metrics play no role at model training, where the only quantity that matters (and is minimized during model fitting) is the loss.And no ...", "dateLastCrawled": "2022-01-21T12:22:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "A <b>machine learning</b> technique that iteratively combines a set of simple and not very accurate classifiers ... Contrast with equalized odds and <b>equality</b> <b>of opportunity</b>, which permit classification results in aggregate to depend on sensitive attributes, but do not permit classification results for certain specified ground-truth labels to depend on sensitive attributes. See &quot;Attacking discrimination with smarter <b>machine learning</b>&quot; for a visualization exploring the tradeoffs when optimizing for ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> | Gendered Innovations", "url": "http://genderedinnovations.stanford.edu/case-studies/machinelearning.html", "isFamilyFriendly": true, "displayUrl": "genderedinnovations.stanford.edu/case-studies/<b>machinelearning</b>.html", "snippet": "As <b>machine learning</b> becomes increasingly ubiquitous in everyday lives, such bias, if uncorrected, can lead to social inequities. Researchers need to understand how gender and ethnicity operate within the context of their algorithm in order to enhance or, at least, not reinforce social equalities. Here we suggest avenues for reducing bias in training data and algorithms in efforts to produce AI that enhances social equalities.", "dateLastCrawled": "2022-01-25T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A New Metric for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare", "url": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "<b>Equality</b> <b>of Opportunity</b> occurs when the sensitivity for the two groups are the same (tp/(tp+fn) ). Our metric differs by this mathematically by the presence of the false positive term in the numerator. If such a similar term exists, why would one elect to report fairness using a different metric? The strength of group benefit <b>equality</b> is its transparency and ease of explanation. One huge strength of group benefit <b>equality</b> is having a default objective for tuning the decision threshold. Even ...", "dateLastCrawled": "2022-02-01T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "RStudio AI Blog: Starting to think about AI Fairness", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness", "snippet": "<b>Equality</b> <b>of opportunity</b> suggests that people similar in real life (\\(Y\\)) get classified similarly ... From a <b>machine</b> <b>learning</b> perspective, the interesting point is the classification of metrics into bias-preserving and bias-transforming. The terms speak for themselves: Metrics in the first group reflect biases in the dataset used for training; ones in the second do not. In that way, the distinction parallels Friedler, Scheidegger, and Venkatasubramanian \u2019s confrontation of two ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A New Metric for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare ...", "url": "https://towardsdatascience.com/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare-closedloop-ai-fc07b9c83487", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-new-metric-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "<b>Equality</b> <b>of Opportunity</b> occurs when the sensitivity for the two groups are the same (tp/(tp+fn)). Our metric differs by this mathematically by the presence of the false positive term in the numerator. If such a similar term exists, why would one elect to report fairness using a different metric? The strength of group benefit <b>equality</b> is its transparency and ease of explanation. One huge strength of group benefit <b>equality</b> is having a default objective for tuning the decision threshold. Even ...", "dateLastCrawled": "2022-01-17T14:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning \u2013 An automotive analogy</b> - BCS Consulting", "url": "https://www.bcsconsulting.com/blog/machine-learning-automotive-analogy/", "isFamilyFriendly": true, "displayUrl": "https://www.bcsconsulting.com/blog/<b>machine</b>-<b>learning</b>-automotive-<b>analogy</b>", "snippet": "<b>Machine Learning \u2013 An automotive analogy</b>. Gonzalo Gonzalez. 12th April, 2018. Progress in emerging technologies, such as <b>machine</b> <b>learning</b>, is creating alternatives to labour intensive risk modelling activities. Banks will require vision, investment and enduring strategic actions to truly leverage the full range of potential benefits . The roadmap defined for autonomous electric cars by tech giants and cars manufacturers include: changes to usage and storage of fuel; investment in talent ...", "dateLastCrawled": "2021-12-13T13:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Analogical proportions</b>: From <b>equality</b> to inequality - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0888613X17306096", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0888613X17306096", "snippet": "Later on, a <b>machine</b> <b>learning</b>-oriented view where <b>analogical proportions</b> are represented in terms of Kolmogorov algorithmic complexity has been presented in . A similar, but simplified modeling, still expressing that a and b differ as c and d differ, can be found in [1] , where the complexities of the target and source universes have not to be taken into account, since they are identical in this latter case.", "dateLastCrawled": "2021-11-13T00:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Adversarial Approaches to Debiasing Word Embeddings", "url": "https://web.stanford.edu/class/cs224n/reports/final_reports/report101.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/cs224n/reports/final_reports/report101.pdf", "snippet": "analogies and identify the gender bias of the <b>analogy</b>, paired with a generator that only minimizes the discriminator\u2019s ability to identify the gender bias. Preliminary results on the WEAT scoring system show that both methods were successful in eliminating bias on commonly-used job words; qualitative analysis on similar words also show that racially or gender charged synonyms were considered less relevant to the debiased vector. 1 Introduction <b>Machine</b> <b>learning</b> for natural language ...", "dateLastCrawled": "2022-01-25T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fairness Through Awareness", "url": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "snippet": "\u201c<b>Equality</b> <b>of opportunity</b> de\ufb01nes an important welfare criterion in political philosophy and policy analysis. Philosophers de\ufb01ne <b>equality</b> <b>of opportunity</b> as the requirement that an individual\u2019s well being be independent of his or her irrelevant characteristics. The di erence among philosophers is mainly about which characteristics should be", "dateLastCrawled": "2022-01-29T03:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Socialist equality of opportunity</b> \u2013 TOWARDS LIFE-KNOWLEDGE", "url": "https://bsahely.com/life-value-onto-axiology/socialist-equality-of-opportunity/", "isFamilyFriendly": true, "displayUrl": "https://bsahely.com/life-value-onto-axiology/<b>socialist-equality-of-opportunity</b>", "snippet": "<b>Socialist equality of opportunity</b>: The principle that seeks to correct for all disadvantages for which the agent cannot herself reasonably be held responsible, whether they be disadvantages that reflect social misfortune or disadvantages that reflect natural misfortune. See Left-liberal <b>equality</b> <b>of opportunity</b>.. Source: \u2018What is Good? What is Bad? The Value of All Values across Time, Place and Theories\u2019 by John McMurtry, Philosophy and World Problems, Volume I-III, UNESCO in partnership ...", "dateLastCrawled": "2022-01-29T07:21:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Philosophical Issues in Economics", "url": "https://www.ibiblio.org/philecon/Publications/publications.doc", "isFamilyFriendly": true, "displayUrl": "https://www.ibiblio.org/philecon/Publications/publications.doc", "snippet": ": Tawney\u2019s definition of <b>equality of opportunity is similar</b> to that of the Friedmans but does consider class, economic, and social position to be actual obstacles that can limit or enhance an individual\u2019s ability to act. He believes that in so far social arrangements can achieve it, everyone should have equal opportunity to enjoy a worthwhile life (Tawney 1964:122). To achieve this Tawney promotes a society that communally provides welfare services by pooling surplus resources by means ...", "dateLastCrawled": "2022-01-20T11:28:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Equality of <b>Educational Opportunity</b> (<b>Stanford Encyclopedia of Philosophy</b>)", "url": "https://plato.stanford.edu/entries/equal-ed-opportunity/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/equal-ed-opportunity", "snippet": "It might be argued that <b>just as equality of opportunity</b> to become a flourishing individual is a matter of justice, so too is equality of opportunity to develop civic skills, and to participate effectively in political deliberations. The structure and appropriate content of civic education is debated extensively. While some argue that citizenship education can be narrowly construed so as to not encroach upon individuals\u2019 private commitments, others claim it is a far more demanding ...", "dateLastCrawled": "2022-02-03T04:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "American Education (sociocultural, Political, And Historical Studies In ...", "url": "https://idoc.pub/documents/american-education-sociocultural-political-and-historical-studies-in-education-18th-edition-d47emk33myn2", "isFamilyFriendly": true, "displayUrl": "https://idoc.pub/documents/american-education-sociocultural-political-and-historical...", "snippet": "Service-<b>learning</b> combines service to the community with student <b>learning</b> in a way that improves both the student and the community. As they participate in their community service projects, actively meeting the needs of communities, youth develop practical skills, selfesteem, and a sense of civic responsibility. Service <b>learning</b> is a form of civic education rather than an education for direct involvement in politics. It is based on a belief that voluntary engagement in civic organizations and ...", "dateLastCrawled": "2022-01-16T11:12:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(equality of opportunity)  is like +(a machine learning algorithm)", "+(equality of opportunity) is similar to +(a machine learning algorithm)", "+(equality of opportunity) can be thought of as +(a machine learning algorithm)", "+(equality of opportunity) can be compared to +(a machine learning algorithm)", "machine learning +(equality of opportunity AND analogy)", "machine learning +(\"equality of opportunity is like\")", "machine learning +(\"equality of opportunity is similar\")", "machine learning +(\"just as equality of opportunity\")", "machine learning +(\"equality of opportunity can be thought of as\")", "machine learning +(\"equality of opportunity can be compared to\")"]}