{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>AUC</b>-<b>ROC</b> <b>Curve</b> in Machine Learning Clearly Explained - Analytics Vidhya", "url": "https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2020/06/<b>auc</b>-<b>roc</b>-<b>curve</b>-machine-learning", "snippet": "The <b>Area</b> <b>Under</b> the <b>Curve</b> (<b>AUC</b>) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of <b>the ROC</b> <b>curve</b>. The higher the <b>AUC</b>, the better the performance of <b>the model</b> at distinguishing between the positive and negative classes.", "dateLastCrawled": "2022-02-02T11:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is a <b>ROC Curve</b>? A visualization with credit scores.", "url": "https://kiwidamien.github.io/what-is-a-roc-curve-a-visualization-with-credit-scores.html", "isFamilyFriendly": true, "displayUrl": "https://kiwidamien.github.io/what-is-a-<b>roc-curve</b>-a-visualization-with-credit-scores.html", "snippet": "<b>The ROC curve</b> (and the <b>area</b> <b>under</b> the <b>curve</b>) tells us how <b>well</b> <b>the model</b>&#39;s score does at separating the two classes. We eventually need to make a threshold, so we can decide whether to act or not, but <b>the ROC curve</b> allows us to select a <b>model</b> that does a good job distinguishing between the two cases, and once we have settled on a <b>model</b> we can separately determine the appropriate threshold for our problem. <b>The ROC</b> and <b>Area</b> <b>Under</b> The <b>Curve</b> Credit score example. Let&#39;s consider the example of ...", "dateLastCrawled": "2022-01-30T07:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "F1 <b>Score</b> vs <b>ROC</b> <b>AUC</b> vs Accuracy vs PR <b>AUC</b>: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-accuracy-<b>roc</b>-<b>auc</b>-pr-<b>auc</b>", "snippet": "Talk about some of the most common binary classification metrics <b>like</b> F1 <b>score</b>, <b>ROC</b> <b>AUC</b>, PR <b>AUC</b>, ... In order to get one number that tells us how good our <b>curve</b> is, we can calculate the <b>Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>, or <b>ROC</b> <b>AUC</b> <b>score</b>. The more top-left your <b>curve</b> is the higher the <b>area</b> and hence higher <b>ROC</b> <b>AUC</b> <b>score</b>. Alternatively, it can be shown that <b>ROC</b> <b>AUC</b> <b>score</b> is equivalent to calculating the rank correlation between predictions and targets. From an interpretation standpoint, it is more ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Is the <b>area</b> <b>under</b> <b>curve</b> of <b>ROC</b> <b>represent the accuracy of classifier</b>?", "url": "https://www.researchgate.net/post/Is-the-area-under-curve-of-ROC-represent-the-accuracy-of-classifier", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/Is-the-<b>area</b>-<b>under</b>-<b>curve</b>-of-<b>ROC</b>-represent-the...", "snippet": "I am using <b>ROC</b> method to evaluate the classification stage my question is the <b>area</b> <b>under</b> <b>curve</b> represent the accuracy as <b>well</b> as how can I use <b>ROC</b> method to evaluate the segmentation if I have ...", "dateLastCrawled": "2022-01-16T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Assessing and <b>Comparing Classifier Performance</b> with <b>ROC</b> Curves", "url": "https://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/assessing-<b>comparing-classifier-performance</b>-<b>roc</b>-<b>curves</b>-2", "snippet": "The most widely-used measure is the <b>area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>). As you can see from Figure 2, the <b>AUC</b> for a classifier with no power, essentially random guessing, is 0.5, because the <b>curve</b> follows the diagonal. The <b>AUC</b> for that mythical being, the perfect classifier, is 1.0. Most classifiers have AUCs that fall somewhere between these two values.", "dateLastCrawled": "2022-01-29T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "In machine learning, how <b>model</b> accuracy and <b>ROC</b> <b>AUC</b> (<b>area</b> <b>under</b> the TP ...", "url": "https://www.quora.com/In-machine-learning-how-model-accuracy-and-ROC-AUC-area-under-the-TP-vs-FP-rates-curve-are-related", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-machine-learning-how-<b>model</b>-accuracy-and-<b>ROC</b>-<b>AUC</b>-<b>area</b>-<b>under</b>...", "snippet": "Answer (1 of 2): High accuracy and higher <b>AUC</b> are both good things generally. Before understanding AUROC, first the concept of confusion matrix must be understood ...", "dateLastCrawled": "2022-01-07T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Using the <b>Gini coefficient</b> to evaluate the performance of credit score ...", "url": "https://towardsdatascience.com/using-the-gini-coefficient-to-evaluate-the-performance-of-credit-score-models-59fe13ef420", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-the-<b>gini-coefficient</b>-to-evaluate-the-performance...", "snippet": "The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, which is usually called the <b>AUC</b>, is also a popular metric for evaluating and comparing the performance of credit score models. <b>The ROC</b> <b>curve</b> summarizes two ratios from the confusion matrix: the True Positive Ratio (TPR or Recall) and the False Positive Ratio (FPR). The confusion matrix summarizes, for a given threshold, the number of cases in which: <b>The model</b> predicted a default and the borrower defaulted \u2014 True Positive. <b>The model</b> predicted a default and the ...", "dateLastCrawled": "2022-02-02T22:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "An experimental comparison of performance measures for <b>classification</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0167865508002687", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167865508002687", "snippet": "Metrics based on how <b>well</b> <b>the model</b> ranks the examples: <b>AUC</b> (Flach et al., 2003), ... The <b>AUC</b> (<b>Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>) (Fawcett, 2006) of a binary classifier is equivalent to the probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance (Mann\u2013Whitney\u2013Wilcoxon statistic interpretation). <b>AUC</b> (j, k) = \u2211 i = 1 m f (i, j) \u2211 t = 1 m f (t, k) I (p (i, j), p (t, j)) m j \u00b7 m k. I (\u00b7) is a comparison function satisfying I ...", "dateLastCrawled": "2022-01-26T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Evaluation</b> Metrics for Machine Learning Models | by Bhajandeep Singh ...", "url": "https://heartbeat.comet.ml/evaluation-metrics-for-machine-learning-models-d42138496366", "isFamilyFriendly": true, "displayUrl": "https://heartbeat.comet.ml/<b>evaluation</b>-metrics-for-machine-learning-<b>models</b>-d42138496366", "snippet": "A common method is to calculate the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, abbreviated <b>AUC</b>. Since the <b>AUC</b> is a portion of the <b>area</b> of the unit square, its value will always be between 0 and 1.0. However, because random guessing produces the diagonal line between (0, 0) and (1, 1), which has an <b>area</b> of 0.5, no realistic classifier should have an <b>AUC</b> less than 0.5", "dateLastCrawled": "2022-01-28T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why is <b>AUC</b> a better measure of an algorithm&#39;s performance than ... - Quora", "url": "https://www.quora.com/Why-is-AUC-a-better-measure-of-an-algorithms-performance-than-accuracy", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-is-<b>AUC</b>-a-better-measure-of-an-algorithms-performance-than...", "snippet": "Answer (1 of 3): They both measure different things, so they are complementary. Accuracy: Measures, for a given threshold, the percentage of points correctly classified, regardless of which class they belong to. <b>AUC</b>: Measures the likelihood that given two random points \u2014 one from the positive a...", "dateLastCrawled": "2022-01-24T20:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "F1 <b>Score</b> vs <b>ROC</b> <b>AUC</b> vs Accuracy vs PR <b>AUC</b>: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-accuracy-<b>roc</b>-<b>auc</b>-pr-<b>auc</b>", "snippet": "<b>ROC</b> <b>AUC</b>. <b>AUC</b> means <b>area</b> <b>under</b> the <b>curve</b> so to speak about <b>ROC</b> <b>AUC</b> <b>score</b> we need to define <b>ROC</b> <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart. Of course, the higher TPR and the lower FPR is for each threshold the better and so classifiers that have curves that are more top-left-side are better. An extensive discussion of <b>ROC</b> <b>Curve</b> and <b>ROC</b> ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) The AUK: A simple alternative to the <b>AUC</b> | Rob Potharst ...", "url": "https://www.academia.edu/68168293/The_AUK_A_simple_alternative_to_the_AUC", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/68168293/The_AUK_A_simple_alternative_to_the_<b>AUC</b>", "snippet": "Keywords <b>ROC</b> <b>curve</b>, <b>area</b> <b>under</b> <b>ROC</b> <b>curve</b>, <b>AUC</b>, H-measure, Kappa index, AUK, <b>model</b> rank- ing, <b>model</b> selection. 1 1 Introduction <b>Receiver Operating Characteristic</b> (<b>ROC</b>) curves are among the most popular tools which have been proposed over the years for ranking <b>model</b> performance. <b>ROC</b> curves are two dimensional graphs in which true positives are plotted against false positives. Historically, they have been used for finding an optimum operating point for radio and radar transmissions, but the ...", "dateLastCrawled": "2022-02-01T02:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Top 10 <b>model</b> <b>performance</b> <b>metrics</b> for classification ML models | by Juhi ...", "url": "https://towardsdatascience.com/top-10-model-evaluation-metrics-for-classification-ml-models-a0a0f1d51b9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/top-10-<b>model</b>-evaluation-<b>metrics</b>-for-classification-ml...", "snippet": "The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is known as <b>AUC</b>. The more the <b>AUC</b> the better your <b>model</b> is. The farther away your <b>ROC</b> <b>curve</b> is from the middle linear line, the better your <b>model</b> is. This is how <b>ROC</b>-<b>AUC</b> can help us judge the <b>performance</b> of our classification models as <b>well</b> as provide us a means to select one <b>model</b> from many classification models ...", "dateLastCrawled": "2022-02-02T17:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The Smartphone Addiction Scale: Development and Validation of a Short ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3877074/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3877074", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>) of <b>the ROC</b> is a <b>measurement</b> of the diagnostic ability of the SAS-SV score in order to correctly classify a specified outcome of smartphone addiction diagnosis through consultation with clinical psychologists. The clinical psychologists selected 90 boys and 60 girls among all the participants using simple random sampling from a computer program. The addiction group was determined after their consultation based on tolerance, withdrawal and daily-life disturbance ...", "dateLastCrawled": "2022-02-02T09:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The tyranny of the averages and the indiscriminate use of risk factors ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5769103/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC5769103", "snippet": "<b>The receiver operating characteristic</b> (<b>ROC</b>) <b>curve</b> and the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (<b>AUC</b>) In the context of DA, <b>the ROC</b> <b>curve</b> is constructed by plotting the TPF against the FPF. <b>The ROC</b> <b>curve</b> informs in regard to the tradeoff between TPF and FPF when the threshold value of the predicted absolute risk for what we consider as a relevant definition of the existence or absence of a \u201crisk factor\u201d is moved.", "dateLastCrawled": "2021-09-29T05:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Is the <b>area</b> <b>under</b> <b>curve</b> of <b>ROC</b> <b>represent the accuracy of classifier</b>?", "url": "https://www.researchgate.net/post/Is-the-area-under-curve-of-ROC-represent-the-accuracy-of-classifier", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/Is-the-<b>area</b>-<b>under</b>-<b>curve</b>-of-<b>ROC</b>-represent-the...", "snippet": "The <b>AUC</b> value lies between 0.5 to 1 where 0.5 denotes a bad classifer and 1 denotes an excellent classifier. Is there any quantitative value for the <b>AUC</b> in order to segregate the quality of a ...", "dateLastCrawled": "2022-01-16T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Assessing and <b>Comparing Classifier Performance</b> with <b>ROC</b> Curves", "url": "https://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/assessing-<b>comparing-classifier-performance</b>-<b>roc</b>-<b>curves</b>-2", "snippet": "The most widely-used measure is the <b>area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>). As you can see from Figure 2, the <b>AUC</b> for a classifier with no power, essentially random guessing, is 0.5, because the <b>curve</b> follows the diagonal. The <b>AUC</b> for that mythical being, the perfect classifier, is 1.0. Most classifiers have AUCs that fall somewhere between these two values.", "dateLastCrawled": "2022-01-29T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "machine learning - How to choose between <b>ROC</b> <b>AUC</b> and <b>F1 score</b>? - Cross ...", "url": "https://stats.stackexchange.com/questions/210700/how-to-choose-between-roc-auc-and-f1-score", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/210700", "snippet": "<b>The ROC</b>/<b>AUC</b> <b>curve</b> does not reflect the performance of the classifier, but the PR <b>curve</b> can. If you just do the experiment in research papers, you can use <b>the ROC</b>, the experimental results will be more beautiful. On another hand, PR <b>curve</b> use in the real problem, and it has better interpretability. Share. Cite. Improve this answer. Follow edited Feb 24 &#39;19 at 21:07. JoeyC. 109 5 5 bronze badges. answered May 3 &#39;16 at 20:00. WeiYuan WeiYuan. 488 4 4 silver badges 9 9 bronze badges $\\endgroup ...", "dateLastCrawled": "2022-01-23T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Optimization metrics: DataRobot docs", "url": "https://docs.datarobot.com/en/docs/modeling/reference/model-detail/opt-metric.html", "isFamilyFriendly": true, "displayUrl": "https://docs.datarobot.com/en/docs/<b>model</b>ing/reference/<b>model</b>-detail/opt-metric.html", "snippet": "<b>AUC</b> for <b>the ROC</b> <b>curve</b> is a performance <b>measurement</b> for classification problems. <b>ROC</b> is a probability <b>curve</b> and <b>AUC</b> represents the degree or measure of separability. The metric ranges from 0 to 1 and indicates how much <b>the model</b> is capable of distinguishing between classes. The higher the <b>AUC</b>, the better <b>the model</b> is at predicting negatives (0s as 0s) and positives (1s as 1s). <b>The ROC</b> <b>curve</b> shows how the true positive rate (sensitivity) on the Y-axis and false positive rate (specificity) on ...", "dateLastCrawled": "2022-01-31T16:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Metrics to Evaluate your Machine Learning Algorithm | by Aditya Mishra ...", "url": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10...", "snippet": "<b>AUC</b> is the <b>area</b> <b>under</b> the <b>curve</b> of plot False Positive Rate vs True Positive Rate at different points in [0, 1]. As evident, <b>AUC</b> has a range of [0, 1]. The greater the value, the better is the performance of our <b>model</b>.", "dateLastCrawled": "2022-02-02T07:06:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "F1 <b>Score</b> vs <b>ROC</b> <b>AUC</b> vs Accuracy vs PR <b>AUC</b>: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-accuracy-<b>roc</b>-<b>auc</b>-pr-<b>auc</b>", "snippet": "<b>ROC</b> <b>AUC</b>. <b>AUC</b> means <b>area</b> <b>under</b> the <b>curve</b> so to speak about <b>ROC</b> <b>AUC</b> <b>score</b> we need to define <b>ROC</b> <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart. Of course, the higher TPR and the lower FPR is for each threshold the better and so classifiers that have curves that are more top-left-side are better. An extensive discussion of <b>ROC</b> <b>Curve</b> and <b>ROC</b> ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Performance Evaluation Measures of Classification model</b>", "url": "https://www.analyticsvidhya.com/blog/2020/12/decluttering-the-performance-measures-of-classification-models/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2020/12/decluttering-the-performance-measures-of...", "snippet": "<b>Area</b> <b>Under</b> <b>Curve</b> (<b>AUC</b>) and <b>ROC</b> <b>Curve</b>: <b>AUC</b> or <b>Area</b> <b>Under</b> <b>Curve</b> is used in conjecture with <b>ROC</b> <b>Curve</b> which is Receiver Operating Characteristics <b>Curve</b>. <b>AUC</b> is the <b>area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>. So let\u2019s first understand <b>the ROC</b> <b>Curve</b>. A <b>ROC</b> <b>Curve</b> is drawn by plotting TPR or True Positive Rate or Recall or Sensitivity (which we saw above) in the y-axis against FPR or False Positive Rate in the x-axis. FPR = 1- Specificity (which we saw above). TPR = TP/ (TP + FN) FPR = 1 \u2013 TN/ (TN+FP) = FP/ (TN ...", "dateLastCrawled": "2022-01-28T19:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Tour of <b>Evaluation Metrics for Imbalanced Classification</b>", "url": "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced...", "snippet": "<b>The ROC</b> <b>Curve</b> is a helpful diagnostic for one <b>model</b>. The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> <b>can</b> be calculated and provides a single score to summarize the plot that <b>can</b> be used to compare models. A no skill classifier will have a score of 0.5, whereas a perfect classifier will have a score of 1.0. <b>ROC</b> <b>AUC</b> = <b>ROC</b> <b>Area</b> <b>Under</b> <b>Curve</b>; Although generally effective, <b>the ROC</b> <b>Curve</b> and <b>ROC</b> <b>AUC</b> <b>can</b> be optimistic <b>under</b> a severe class imbalance, especially when the number of examples in the minority class is small ...", "dateLastCrawled": "2022-02-02T08:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>AUC</b>: A misleading measure of the performance of predictive ...", "url": "https://www.researchgate.net/publication/285698707_AUC_A_misleading_measure_of_the_performance_of_predictive_distribution_models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/285698707_<b>AUC</b>_A_misleading_measure_of_the...", "snippet": "Through observing <b>the ROC</b> curves [17] and circulating the <b>AUC</b> [18]value of the three models, we <b>can</b> see that <b>the model</b> of the random forest has a larger <b>area</b> of <b>ROC</b> <b>curve</b> and a bigger <b>AUC</b> value ...", "dateLastCrawled": "2022-01-31T07:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Factors predicting timely implementation of radiotherapy innovations ...", "url": "https://europepmc.org/article/PMC/PMC7774677", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC7774677", "snippet": "<b>AUC</b>, <b>Area</b> <b>under</b> the <b>curve</b>, <b>ROC</b>, <b>Receiver operating characteristic</b>. Go to: Discussion. We were able to build a prediction <b>model</b> that <b>can</b> help radiotherapy centres to calculate the expected successfulness of an innovation implementation before the project starts. On this basis, it is possible to manage those factors that cause a low score in the prediction <b>model</b> in such a way that the chance of successful implementation increases. The relevance of success factors with a significant impact on ...", "dateLastCrawled": "2022-01-06T06:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Gentle Introduction to Threshold-Moving for Imbalanced Classification", "url": "https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification", "snippet": "The <b>area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>, so-called <b>ROC</b> <b>AUC</b>, provides a single number to summarize the performance of a <b>model</b> in terms of its <b>ROC</b> <b>Curve</b> with a value between 0.5 (no-skill) and 1.0 (perfect skill). <b>The ROC</b> <b>Curve</b> is a useful diagnostic tool for understanding the trade-off for different thresholds and <b>the ROC</b> <b>AUC</b> provides a useful number for comparing models based on their general capabilities. If crisp class labels are required from a <b>model</b> <b>under</b> such an analysis, then an optimal threshold ...", "dateLastCrawled": "2022-01-30T10:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Theoretical <b>interview questions</b>", "url": "https://ds-interviews.org/theory.html", "isFamilyFriendly": true, "displayUrl": "https://ds-interviews.org/theory.html", "snippet": "<b>AUC</b> score is the value of <b>Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>. If we assume <b>ROC</b> <b>curve</b> consists of dots, , then. An excellent <b>model</b> has <b>AUC</b> near to the 1 which means it has good measure of separability. A poor <b>model</b> has <b>AUC</b> near to the 0 which means it has worst measure of separability. When <b>AUC</b> score is 0.5, it means <b>model</b> has no class separation capacity ...", "dateLastCrawled": "2022-02-02T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Why measuring <b>accuracy</b> is hard (and very important)! | by Bradley ...", "url": "https://towardsdatascience.com/why-measuring-accuracy-is-hard-and-very-important-part-1-why-measuring-right-is-important-a279e8a6fcd", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/why-measuring-<b>accuracy</b>-is-hard-and-very-important-part...", "snippet": "Now I should mention that <b>the ROC</b> curves come with an associated single number metric, <b>AUC</b> or <b>Area</b>-<b>Under</b>-<b>Curve</b>, which is literally the <b>area</b> underneath <b>the ROC</b> <b>curve</b>. <b>AUC</b> is a robust and very useful metric. But <b>AUC</b> is not an easy metric to explain to a stakeholder and doesn\u2019t have any easy interpretation for us to understand. Maybe then we resort to using precision and recall? We find some acceptable point on <b>the ROC</b> <b>curve</b>, set the threshold to that point, and use these two new numbers to ...", "dateLastCrawled": "2022-01-13T16:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How <b>can</b> we find <b>the ROC</b> <b>curve</b> and <b>area</b> <b>under</b> <b>ROC</b> <b>curve</b> for a multi ...", "url": "https://www.quora.com/How-can-we-find-the-ROC-curve-and-area-under-ROC-curve-for-a-multi-instance-multi-label-classification-One-feature-vector-may-correspond-to-one-or-more-labels", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>can</b>-we-find-<b>the-ROC</b>-<b>curve</b>-and-<b>area</b>-<b>under</b>-<b>ROC</b>-<b>curve</b>-for-a...", "snippet": "Answer: Lets say you have 3 labels 1,2,3 and you have data belonging to these 3 labels. Let&#39;s say they were labelled as a(1), b(2), c(3) by your <b>model</b> 1 2 3 A 25 5 5 B 5 15 10 C 5 10 20 This table means that 25 instances which were label 1 were labeled a and so on. The true positives would be ...", "dateLastCrawled": "2022-01-19T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>can</b> the <b>F1-score</b> help with dealing with class imbalance?", "url": "https://sebastianraschka.com/faq/docs/computing-the-f1-score.html", "isFamilyFriendly": true, "displayUrl": "https://sebastianraschka.com/faq/docs/computing-the-<b>f1-score</b>.html", "snippet": "JM. Lobo, A. Jim\u00e9nez-Valverde, and R. Real 2008: <b>AUC</b>: a misleading measure of the performance of predictive distribution models; Jin Huang &amp; C. X. Ling 2005: Using <b>AUC</b> and accuracy in evaluating learning algorithms; AP. Bradley 1997 The use of the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> in the evaluation of machine learning algorithms", "dateLastCrawled": "2022-01-30T05:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>AUC</b>-<b>ROC</b> <b>Curve</b> in Machine Learning Clearly Explained - Analytics Vidhya", "url": "https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2020/06/<b>auc</b>-<b>roc</b>-<b>curve</b>-machine-learning", "snippet": "The <b>Area</b> <b>Under</b> the <b>Curve</b> (<b>AUC</b>) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of <b>the ROC</b> <b>curve</b>. The higher the <b>AUC</b>, the better the performance of <b>the model</b> at distinguishing between the positive and negative classes.", "dateLastCrawled": "2022-02-02T11:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification: <b>ROC</b> <b>Curve</b> and <b>AUC</b> | Machine Learning Crash Course ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/crash-course/classification/<b>roc</b>-and-<b>auc</b>", "snippet": "<b>AUC</b>: <b>Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>. <b>AUC</b> stands for &quot;<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>.&quot; That is, <b>AUC</b> measures the entire two-dimensional <b>area</b> underneath the entire <b>ROC</b> <b>curve</b> (think integral calculus) from (0,0) to (1,1). Figure 5. <b>AUC</b> (<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>). <b>AUC</b> provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting <b>AUC</b> is as the probability that <b>the model</b> ranks a random positive example more highly than a random negative example. For ...", "dateLastCrawled": "2022-02-02T09:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "F1 <b>Score</b> vs <b>ROC</b> <b>AUC</b> vs Accuracy vs PR <b>AUC</b>: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-accuracy-<b>roc</b>-<b>auc</b>-pr-<b>auc</b>", "snippet": "<b>ROC</b> <b>AUC</b>. <b>AUC</b> means <b>area</b> <b>under</b> the <b>curve</b> so to speak about <b>ROC</b> <b>AUC</b> <b>score</b> we need to define <b>ROC</b> <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart. Of course, the higher TPR and the lower FPR is for each threshold the better and so classifiers that have curves that are more top-left-side are better. An extensive discussion of <b>ROC</b> <b>Curve</b> and <b>ROC</b> ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Sensitivity, Specificity, <b>Receiver-Operating Characteristic</b> (<b>ROC</b> ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2556590/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2556590", "snippet": "<b>The ROC</b> <b>curve</b> graphically displays the trade-off between sensitivity and specificity and is useful in assigning the best cut-offs for clinical use. 3 Overall accuracy is sometimes expressed as <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (<b>AUC</b>) and provides a useful parameter for comparing test performance between, for example, different commercial BNP assays and also the related N-terminal pro-BNP assay. 6", "dateLastCrawled": "2022-02-03T06:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The Smartphone Addiction Scale: Development and Validation of a Short ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3877074/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3877074", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>) of <b>the ROC</b> is a <b>measurement</b> of the diagnostic ability of the SAS-SV score in order to correctly classify a specified outcome of smartphone addiction diagnosis through consultation with clinical psychologists. The clinical psychologists selected 90 boys and 60 girls among all the participants using simple random sampling from a computer program. The addiction group was determined after their consultation based on tolerance, withdrawal and daily-life disturbance ...", "dateLastCrawled": "2022-02-02T09:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) The AUK: A simple alternative to the <b>AUC</b> | Rob Potharst ...", "url": "https://www.academia.edu/68168293/The_AUK_A_simple_alternative_to_the_AUC", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/68168293/The_AUK_A_simple_alternative_to_the_<b>AUC</b>", "snippet": "Since Kappa is a transformation of the difference between <b>the ROC</b> <b>curve</b> of a classifier and <b>the ROC</b> <b>curve</b> of a random <b>model</b>, AUK <b>can</b> be seen as a transformation of the <b>area</b> between <b>the ROC</b> <b>curve</b> and <b>the ROC</b> of a random <b>model</b>, one which compensates for skewness and for random successes. 6 The relation between <b>AUC</b> and AUK Since <b>AUC</b> is the <b>area</b> <b>under</b> an <b>ROC</b> <b>curve</b> and <b>ROC</b> is related to \u03ba, AUK is related to the <b>AUC</b>. AUK is a transformation of the <b>area</b> <b>under</b> <b>ROC</b> that is above the main diagonal ...", "dateLastCrawled": "2022-02-01T02:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Top 10 <b>model</b> <b>performance</b> <b>metrics</b> for classification ML models | by Juhi ...", "url": "https://towardsdatascience.com/top-10-model-evaluation-metrics-for-classification-ml-models-a0a0f1d51b9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/top-10-<b>model</b>-evaluation-<b>metrics</b>-for-classification-ml...", "snippet": "The <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is known as <b>AUC</b>. The more the <b>AUC</b> the better your <b>model</b> is. The farther away your <b>ROC</b> <b>curve</b> is from the middle linear line, the better your <b>model</b> is. This is how <b>ROC</b>-<b>AUC</b> <b>can</b> help us judge the <b>performance</b> of our classification models as <b>well</b> as provide us a means to select one <b>model</b> from many classification models ...", "dateLastCrawled": "2022-02-02T17:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Assessing and <b>Comparing Classifier Performance</b> with <b>ROC</b> Curves", "url": "https://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/assessing-<b>comparing-classifier-performance</b>-<b>roc</b>-<b>curves</b>-2", "snippet": "The most widely-used measure is the <b>area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>). As you <b>can</b> see from Figure 2, the <b>AUC</b> for a classifier with no power, essentially random guessing, is 0.5, because the <b>curve</b> follows the diagonal. The <b>AUC</b> for that mythical being, the perfect classifier, is 1.0. Most classifiers have AUCs that fall somewhere between these two values.", "dateLastCrawled": "2022-01-29T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>ROC</b> <b>curve</b> analysis - MedCalc", "url": "https://www.medcalc.org/manual/roc-curves.php", "isFamilyFriendly": true, "displayUrl": "https://www.medcalc.org/manual/<b>roc</b>-<b>curves</b>.php", "snippet": "The Significance level or P-value is the probability that the observed sample <b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is found when in fact, the true (population) <b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is 0.5 (null hypothesis: <b>Area</b> = 0.5). If P is small (P&lt;0.05) then it <b>can</b> be concluded that the <b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b> is significantly different from 0.5 and that therefore there is evidence that the laboratory test does have an ability to distinguish between the two groups (Hanley &amp; McNeil, 1982; Zweig &amp; Campbell, 1993).", "dateLastCrawled": "2022-02-03T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "An experimental comparison of performance measures for <b>classification</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0167865508002687", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167865508002687", "snippet": "Metrics based on how <b>well</b> <b>the model</b> ranks the examples: <b>AUC</b> (Flach et al., 2003), ... The <b>AUC</b> (<b>Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>) (Fawcett, 2006) of a binary classifier is equivalent to the probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance (Mann\u2013Whitney\u2013Wilcoxon statistic interpretation). <b>AUC</b> (j, k) = \u2211 i = 1 m f (i, j) \u2211 t = 1 m f (t, k) I (p (i, j), p (t, j)) m j \u00b7 m k. I (\u00b7) is a comparison function satisfying I ...", "dateLastCrawled": "2022-01-26T13:23:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding <b>AUC</b> - <b>ROC</b> <b>Curve</b> | by Sarang Narkhede | Towards Data Science", "url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>auc</b>-<b>roc</b>-<b>curve</b>-68b2303cc9c5", "snippet": "<b>AUC</b> - <b>ROC</b> <b>curve</b> is a performance measurement for the classification problems at various threshold settings. <b>ROC</b> is a probability <b>curve</b> and <b>AUC</b> represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. Higher the <b>AUC</b>, the better the model is at predicting 0 classes as 0 and 1 classes as 1. By <b>analogy</b>, the Higher the <b>AUC</b>, the better the model is at distinguishing between patients with the disease and no disease.", "dateLastCrawled": "2022-01-30T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "<b>AUC</b> calculates the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, and therefore it is between 0 and 1. One way of interpreting <b>AUC</b> is the probability that the model ranks a random positive example more highly than a random negative example. Youden\u2019s index Youden\u2019s J statistic (also called Youden\u2019s index) is a single statistic that captures the performance of a dichotomous (A partition of a whole into two) diagnostic tests. Youden\u2019s J statistic is J = sensitivity + specificity - 1 The right-hand two ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Comparison of <b>machine</b>-<b>learning</b> methodologies for accurate diagnosis of ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8128240/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8128240", "snippet": "After completion of training and prediction steps during each iteration, predictive metrics (<b>area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>) and probability of correct classification (PCC)) are calculated based on the respective <b>machine</b>-<b>learning</b> classifier results, and <b>receiver operating characteristic</b> (<b>ROC</b>) plots are generated using R package \u201cPresenceAbsence\u201d . The difference between <b>AUC</b> and PCC means was compared by unpaired Student\u2019s t-tests using R base functions for all <b>machine</b>-<b>learning</b>-based ...", "dateLastCrawled": "2022-01-26T11:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Understanding <b>AUC</b> - <b>RO C</b> <b>Cur ve</b>", "url": "https://48hours.ai/files/AUC.pdf", "isFamilyFriendly": true, "displayUrl": "https://48hours.ai/files/<b>AUC</b>.pdf", "snippet": "In <b>Machine</b> <b>Learning</b>, performance measurement is an essential task. So when it comes to a classification problem, we can count on an <b>AUC</b> - <b>ROC</b> <b>Curve</b>. When we need to check or visualize the performance of the multi - class classification problem, we use <b>AUC</b> (<b>Area</b> <b>Under</b> The <b>Cur ve</b>) <b>ROC</b> (Receiver Operating Character istics) <b>curve</b>. It is one of the most important evaluation metrics for checking any classification model\u2019s performance. It is also written as AUROC (<b>Area</b> <b>Under</b> t he Receiver ...", "dateLastCrawled": "2022-02-01T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is the <b>AUC</b> \u2014 <b>ROC</b> <b>Curve</b>?. <b>AUC</b>-<b>ROC</b> <b>CURVE</b> | CONFUSION MATRIX |\u2026 | by ...", "url": "https://medium.com/computer-architecture-club/what-is-the-auc-roc-curve-47fbdcbf7a4a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/computer-architecture-club/what-is-the-<b>auc</b>-<b>roc</b>-<b>curve</b>-47fbdcbf7a4a", "snippet": "The <b>Area</b> <b>Under</b> the <b>Curve</b> (<b>AUC</b>) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of <b>the ROC</b> <b>curve</b>. <b>AUC</b>-<b>ROC</b> <b>curve</b> is a performance measurement ...", "dateLastCrawled": "2022-01-26T00:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "In <b>machine</b> <b>learning</b>, how model accuracy and <b>ROC</b> <b>AUC</b> (<b>area</b> <b>under</b> the TP ...", "url": "https://www.quora.com/In-machine-learning-how-model-accuracy-and-ROC-AUC-area-under-the-TP-vs-FP-rates-curve-are-related", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-<b>machine</b>-<b>learning</b>-how-model-accuracy-and-<b>ROC</b>-<b>AUC</b>-<b>area</b>-<b>under</b>...", "snippet": "Answer (1 of 2): High accuracy and higher <b>AUC</b> are both good things generally. Before understanding AUROC, first the concept of confusion matrix must be understood ...", "dateLastCrawled": "2022-01-07T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine learning predicts mortality based on analysis</b> of ventilation ...", "url": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01506-w", "isFamilyFriendly": true, "displayUrl": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01506-w", "snippet": "Predictive performance of RNN-based model was higher with <b>Area</b> <b>Under</b> <b>the Receiver Operating Characteristic</b> (<b>ROC</b>) <b>Curve</b> (<b>AUC</b>) of 0.72 (\u00b1 0.01) and Average Precision (AP) of 0.57 (\u00b1 0.01) in comparison to RF and LR for the overall patient dataset. Higher predictive performance was recorded in the subgroup of patients admitted with respiratory disorders with <b>AUC</b> of 0.75 (\u00b1 0.02) and AP of 0.65 (\u00b1 0.03). Inclusion of function of other organs further improved the performance to <b>AUC</b> of 0.79 ...", "dateLastCrawled": "2022-01-31T04:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Receiver Operating <b>Curve</b> (<b>ROC</b>) and The Scale \u2014 Understanding <b>ROC</b> ...", "url": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the-scale-understanding-roc-through-an-analogy-8b8f9d954f84", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-everyday/the-receiver-operating-<b>curve</b>-<b>roc</b>-and-the...", "snippet": "The Receiver Operating <b>Curve</b> (<b>ROC</b>) is used to evaluate and improve classification <b>Machine</b> <b>Learning</b> models. Who does not want an accurate classifier, that place observations where they actually\u2026", "dateLastCrawled": "2021-02-13T00:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "C. <b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b> D. All of the above Answer : D. 24. Which of the following is a good test dataset characteristic? A. Large enough to yield meaningful results B. Is representative of the dataset as a whole C. Both A and B D. None of the above Answer : C. 25. Which of the following is a disadvantage of decision trees? A. Factor analysis", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>AUC</b> <b>ROC</b> <b>curve</b> - <b>auc</b>: <b>area</b> <b>under</b> <b>the roc</b> <b>curve</b>", "url": "https://haar-t.com/questions/25009284/how-to-plot-roc-curve-in-python5q3cww3348a8y8", "isFamilyFriendly": true, "displayUrl": "https://haar-t.com/questions/25009284/how-to-plot-<b>roc</b>-<b>curve</b>-in-python5q3cww3348a8y8", "snippet": "The function returns the false positive rates for each threshold, true positive rates for each threshold and. <b>ROC</b> <b>curve</b> (<b>Receiver Operating Characteristic</b>) is a commonly used way to visualize the performance of a binary classifier and <b>AUC</b> (<b>Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>) is used to summarize its performance in a single number. Most <b>machine</b> <b>learning</b> algorithms have the ability to produce probability scores that tells us the strength in which it thinks a given observation is positive L&#39;aire sous la ...", "dateLastCrawled": "2022-01-25T23:14:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(auc (area under the roc curve))  is like +(measurement of how well the model is doing)", "+(auc (area under the roc curve)) is similar to +(measurement of how well the model is doing)", "+(auc (area under the roc curve)) can be thought of as +(measurement of how well the model is doing)", "+(auc (area under the roc curve)) can be compared to +(measurement of how well the model is doing)", "machine learning +(auc (area under the roc curve) AND analogy)", "machine learning +(\"auc (area under the roc curve) is like\")", "machine learning +(\"auc (area under the roc curve) is similar\")", "machine learning +(\"just as auc (area under the roc curve)\")", "machine learning +(\"auc (area under the roc curve) can be thought of as\")", "machine learning +(\"auc (area under the roc curve) can be compared to\")"]}