{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Ultimate Data Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-data-science-flash-cards", "snippet": "<b>Depthwise</b> <b>Separable</b> <b>Convolutional</b> <b>Neural</b> <b>Network</b> (<b>sepCNN</b>) A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced with <b>depthwise</b> <b>separable</b> convolutions. Also known as Xception. A <b>depthwise</b> <b>separable</b> convolution (also abbreviated as <b>separable</b> convolution) factors a standard 3-D convolution into two separate convolution operations that are more computationally efficient: first, a <b>depthwise</b> convolution, with a depth of 1 (n n 1), and then second ...", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "TensorFlow \u2013 \u30da\u30fc\u30b8 <b>7 \u2013 TensorFlow</b> &amp; Keras", "url": "https://tensorflow.classcat.com/category/tensorflow/page/7/", "isFamilyFriendly": true, "displayUrl": "https://tensorflow.classcat.com/category/tensorflow/page/7", "snippet": "\u79c1\u9054\u306f\u30e2\u30c7\u30eb\u30fb\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u591a\u69d8\u306b\u3057\u3066\u3001CNN, <b>sepCNN</b> (<b>Depthwise</b> <b>Separable</b> <b>Convolutional</b> <b>Network</b>), RNN (LSTM &amp; GRU), CNN-RNN, \u305d\u3057\u3066 stacked RNN \u306e\u3088\u3046\u306a\u7570\u306a\u308b\u30b7\u30fc\u30af\u30a8\u30f3\u30b9\u30fb\u30e2\u30c7\u30eb\u3092\u6bd4\u8f03\u3057\u307e\u3057\u305f\u3002 \u3057\u3070\u3057\u3070\u3088\u308a\u30c7\u30fc\u30bf\u52b9\u7387\u7684\u3067\u8a08\u7b97\u52b9\u7387\u7684\u306a\u7573\u307f\u8fbc\u307f\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5909\u7a2e \u2013 <b>sepCNN</b> \u304c\u4ed6\u306e\u30e2\u30c7\u30eb\u3088\u308a\u3082\u3088\u308a\u826f\u304f\u9042\u884c\u3059\u308b\u3053\u3068\u3092\u898b\u51fa\u3057\u307e\u3057\u305f\u3002 Note: RNN \u306f\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u5c0f\u3055\u3044\u30b5\u30d6\u30bb\u30c3\u30c8 ...", "dateLastCrawled": "2022-01-14T08:41:00.0000000Z", "language": "ja", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary: Image Models | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/image", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary/image", "snippet": "<b>depthwise</b> <b>separable</b> <b>convolutional</b> <b>neural</b> <b>network</b> (<b>sepCNN</b>) #image. A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced with <b>depthwise</b> <b>separable</b> convolutions. Also known as Xception. A <b>depthwise</b> <b>separable</b> convolution (also abbreviated as <b>separable</b> convolution) factors a standard 3-D convolution into two separate convolution operations that are more computationally efficient: first, a <b>depthwise</b> convolution, with a depth of 1 (n n 1), and then ...", "dateLastCrawled": "2022-01-25T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "<b>depthwise</b> <b>separable</b> <b>convolutional</b> <b>neural</b> <b>network</b> (<b>sepCNN</b>) #image. A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced with <b>depthwise</b> <b>separable</b> convolutions. Also known as Xception. A <b>depthwise</b> <b>separable</b> convolution (also abbreviated as <b>separable</b> convolution) factors a standard 3-D convolution into two separate convolution operations that are more computationally efficient: first, a <b>depthwise</b> convolution, with a depth of 1 (n n 1), and then ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Fully Connected Layer Deutsch</b> \u2014 \u00fcber 7 millionen englischsprachige b\u00fccher", "url": "https://john-haltet-versucht.com/tutorial/supervised/ConvolutionalNeuralNetwork/6e-j553tot", "isFamilyFriendly": true, "displayUrl": "https://john-haltet-versucht.com/tutorial/supervised/<b>ConvolutionalNeuralNetwork</b>/6e-j553tot", "snippet": "For example, a <b>neural</b> <b>network</b> with 5 hidden layers and 1 output layer has a depth of 6. <b>depthwise</b> <b>separable</b> <b>convolutional</b> <b>neural</b> <b>network</b> (<b>sepCNN</b>) #image . A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced. Now during each batch when the final layer output is obtained (as a symbol) I want to multiply the ndArray obtained from my custom iterator and the output of the last layer so that I can create a custom loss function further. But How ...", "dateLastCrawled": "2022-01-27T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Dense layer output | unbegrenzt und \u00fcberall", "url": "https://house-ulici.com/2019-06-12/embeddings-with-numeric-variables-Keras3-v1ce40208hh", "isFamilyFriendly": true, "displayUrl": "https://house-ulici.com/2019-06-12/embeddings-with-numeric-variables-Keras3-v1ce40208hh", "snippet": "For example, a <b>neural</b> <b>network</b> with 5 hidden layers and 1 output layer has a depth of 6. <b>depthwise</b> <b>separable</b> <b>convolutional</b> <b>neural</b> <b>network</b> (<b>sepCNN</b>) #image. A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules. Python Model.fit - 30 examples found. These are the top rated real world Python examples of kerasmodels.Model.fit extracted from open source projects. You can rate examples to help us improve the quality of examples Another LSTM layer with 128 cells ...", "dateLastCrawled": "2022-01-26T02:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Number of weights in fully connected <b>network</b>, when it comes to ...", "url": "https://magadnakbaja.com/ccna-3-practice-final-exam-answers-v5-0-3-v6-0-full-100c2gvq3439-4hg9.html", "isFamilyFriendly": true, "displayUrl": "https://magadnakbaja.com/ccna-3-practice-final-exam-answers-v5-0-3-v6-0-full-100c2gvq...", "snippet": "Here&#39;s a brief overview of how a simple feedforward <b>neural</b> <b>network</b> works: Take inputs as a matrix (<b>2D</b> <b>array</b> of numbers) Multiply the inputs by a set of. <b>Network</b> Topology - Fully Connected - ConceptDra . The two metrics that people commonly use to measure the size of <b>neural</b> networks are the number of neurons, or more commonly the number of parameters. Working with the two example networks in the above picture: The first <b>network</b> (left) has 4 + 2 = 6 neurons (not counting the inputs), [3 x 4 ...", "dateLastCrawled": "2022-01-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "TensorFlow embedding layer example | tf", "url": "https://fretta-teba.com/article/text-classification-using-tensorflow-2-and-keras-in-python-d581282oxbp", "isFamilyFriendly": true, "displayUrl": "https://fretta-teba.com/article/text-classification-using-tensorflow-2-and-keras-in...", "snippet": "- Shamane Siriwardhana Jun 5 &#39;18 at 7:4 2 \u2014 An Embedding layer to convert 1D Tensors of Integers into dense vectors of fixed size. 3 \u2014 A fully connected <b>neural</b> <b>network</b> for backpropagation and cost function and other deep learning tasks. Text Vectorization Layer. Text vectorization is an experimental layer that offers a lot of value for the text preprocessing automation The following are 30 code examples for showing how to use tensorflow.keras.layers.ReLU(). These examples are extracted ...", "dateLastCrawled": "2022-01-04T18:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fully connected <b>neural</b> <b>network</b> gradient - running the gradient descent ...", "url": "https://cielos-vada.biz/transformers-are-graph-neural-networks/s9-f-2616xdi4", "isFamilyFriendly": true, "displayUrl": "https://cielos-vada.biz/transformers-are-graph-<b>neural</b>-<b>networks</b>/s9-f-2616xdi4", "snippet": "A feed-forward <b>neural</b> <b>network</b> allows information to flow only in. Synonym for fully connected layer. depth. The number of layers (including any embedding layers) in a <b>neural</b> <b>network</b> that learn weights. For example, a <b>neural</b> <b>network</b> with 5 hidden layers and 1 output layer has a depth of 6. <b>depthwise</b> <b>separable</b> <b>convolutional</b> <b>neural</b> <b>network</b> (<b>sepCNN</b>", "dateLastCrawled": "2021-11-19T17:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Ultimate Data Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-data-science-flash-cards", "snippet": "<b>Depthwise</b> <b>Separable</b> <b>Convolutional</b> <b>Neural</b> <b>Network</b> (<b>sepCNN</b>) A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced with <b>depthwise</b> <b>separable</b> convolutions. Also known as Xception. A <b>depthwise</b> <b>separable</b> convolution (also abbreviated as <b>separable</b> convolution) factors a standard 3-D convolution into two separate convolution operations that are more computationally efficient: first, a <b>depthwise</b> convolution, with a depth of 1 (n n 1), and then second ...", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "<b>depthwise</b> <b>separable</b> <b>convolutional</b> <b>neural</b> <b>network</b> (<b>sepCNN</b>) #image. A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced with <b>depthwise</b> <b>separable</b> convolutions. Also known as Xception. A <b>depthwise</b> <b>separable</b> convolution (also abbreviated as <b>separable</b> convolution) factors a standard 3-D convolution into two separate convolution operations that are more computationally efficient: first, a <b>depthwise</b> convolution, with a depth of 1 (n n 1), and then ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Fully Connected Layer Deutsch</b> \u2014 \u00fcber 7 millionen englischsprachige b\u00fccher", "url": "https://john-haltet-versucht.com/tutorial/supervised/ConvolutionalNeuralNetwork/6e-j553tot", "isFamilyFriendly": true, "displayUrl": "https://john-haltet-versucht.com/tutorial/supervised/<b>ConvolutionalNeuralNetwork</b>/6e-j553tot", "snippet": "For example, a <b>neural</b> <b>network</b> with 5 hidden layers and 1 output layer has a depth of 6. <b>depthwise</b> <b>separable</b> <b>convolutional</b> <b>neural</b> <b>network</b> (<b>sepCNN</b>) #image . A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced. Now during each batch when the final layer output is obtained (as a symbol) I want to multiply the ndArray obtained from my custom iterator and the output of the last layer so that I can create a custom loss function further. But How ...", "dateLastCrawled": "2022-01-27T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Number of weights in fully connected <b>network</b>, when it comes to ...", "url": "https://magadnakbaja.com/ccna-3-practice-final-exam-answers-v5-0-3-v6-0-full-100c2gvq3439-4hg9.html", "isFamilyFriendly": true, "displayUrl": "https://magadnakbaja.com/ccna-3-practice-final-exam-answers-v5-0-3-v6-0-full-100c2gvq...", "snippet": "Here&#39;s a brief overview of how a simple feedforward <b>neural</b> <b>network</b> works: Take inputs as a matrix (<b>2D</b> <b>array</b> of numbers) Multiply the inputs by a set of. <b>Network</b> Topology - Fully Connected - ConceptDra . The two metrics that people commonly use to measure the size of <b>neural</b> networks are the number of neurons, or more commonly the number of parameters. Working with the two example networks in the above picture: The first <b>network</b> (left) has 4 + 2 = 6 neurons (not counting the inputs), [3 x 4 ...", "dateLastCrawled": "2022-01-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Fully connected <b>neural</b> <b>network</b> gradient - running the gradient descent ...", "url": "https://cielos-vada.biz/transformers-are-graph-neural-networks/s9-f-2616xdi4", "isFamilyFriendly": true, "displayUrl": "https://cielos-vada.biz/transformers-are-graph-<b>neural</b>-<b>networks</b>/s9-f-2616xdi4", "snippet": "A feed-forward <b>neural</b> <b>network</b> allows information to flow only in. Synonym for fully connected layer. depth. The number of layers (including any embedding layers) in a <b>neural</b> <b>network</b> that learn weights. For example, a <b>neural</b> <b>network</b> with 5 hidden layers and 1 output layer has a depth of 6. <b>depthwise</b> <b>separable</b> <b>convolutional</b> <b>neural</b> <b>network</b> (<b>sepCNN</b>", "dateLastCrawled": "2021-11-19T17:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "TensorFlow embedding layer example | tf", "url": "https://fretta-teba.com/article/text-classification-using-tensorflow-2-and-keras-in-python-d581282oxbp", "isFamilyFriendly": true, "displayUrl": "https://fretta-teba.com/article/text-classification-using-tensorflow-2-and-keras-in...", "snippet": "- Shamane Siriwardhana Jun 5 &#39;18 at 7:4 2 \u2014 An Embedding layer to convert 1D Tensors of Integers into dense vectors of fixed size. 3 \u2014 A fully connected <b>neural</b> <b>network</b> for backpropagation and cost function and other deep learning tasks. Text Vectorization Layer. Text vectorization is an experimental layer that offers a lot of value for the text preprocessing automation The following are 30 code examples for showing how to use tensorflow.keras.layers.ReLU(). These examples are extracted ...", "dateLastCrawled": "2022-01-04T18:41:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Ultimate Data Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-data-science-flash-cards", "snippet": "<b>Depthwise</b> <b>Separable</b> <b>Convolutional</b> <b>Neural</b> <b>Network</b> (<b>sepCNN</b>) A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced with <b>depthwise</b> <b>separable</b> convolutions. Also known as Xception. A <b>depthwise</b> <b>separable</b> convolution (also abbreviated as <b>separable</b> convolution) factors a standard 3-D convolution into two separate convolution operations that are more computationally efficient: first, a <b>depthwise</b> convolution, with a depth of 1 (n n 1), and then second ...", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "<b>depthwise</b> <b>separable</b> <b>convolutional</b> <b>neural</b> <b>network</b> (<b>sepCNN</b>) #image. A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced with <b>depthwise</b> <b>separable</b> convolutions. Also known as Xception. A <b>depthwise</b> <b>separable</b> convolution (also abbreviated as <b>separable</b> convolution) factors a standard 3-D convolution into two separate convolution operations that are more computationally efficient: first, a <b>depthwise</b> convolution, with a depth of 1 (n n 1), and then ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Number of weights in fully connected <b>network</b>, when it comes to ...", "url": "https://magadnakbaja.com/ccna-3-practice-final-exam-answers-v5-0-3-v6-0-full-100c2gvq3439-4hg9.html", "isFamilyFriendly": true, "displayUrl": "https://magadnakbaja.com/ccna-3-practice-final-exam-answers-v5-0-3-v6-0-full-100c2gvq...", "snippet": "Here&#39;s a brief overview of how a simple feedforward <b>neural</b> <b>network</b> works: Take inputs as a matrix (<b>2D</b> <b>array</b> of numbers) Multiply the inputs by a set of. <b>Network</b> Topology - Fully Connected - ConceptDra . The two metrics that people commonly use to measure the size of <b>neural</b> networks are the number of neurons, or more commonly the number of parameters. Working with the two example networks in the above picture: The first <b>network</b> (left) has 4 + 2 = 6 neurons (not counting the inputs), [3 x 4 ...", "dateLastCrawled": "2022-01-28T15:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "TensorFlow embedding layer example | tf", "url": "https://fretta-teba.com/article/text-classification-using-tensorflow-2-and-keras-in-python-d581282oxbp", "isFamilyFriendly": true, "displayUrl": "https://fretta-teba.com/article/text-classification-using-tensorflow-2-and-keras-in...", "snippet": "This <b>can</b> be same for trying to get an embedding for each feature. - Shamane Siriwardhana Jun 5 &#39;18 at 7:4 2 \u2014 An Embedding layer to convert 1D Tensors of Integers into dense vectors of fixed size. 3 \u2014 A fully connected <b>neural</b> <b>network</b> for backpropagation and cost function and other deep learning tasks. Text Vectorization Layer. Text ...", "dateLastCrawled": "2022-01-04T18:41:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Ultimate Data Science Flashcards | Quizlet", "url": "https://quizlet.com/474731310/ultimate-data-science-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/474731310/ultimate-data-science-flash-cards", "snippet": "<b>Depthwise</b> <b>Separable</b> <b>Convolutional</b> <b>Neural</b> <b>Network</b> (<b>sepCNN</b>) A <b>convolutional</b> <b>neural</b> <b>network</b> architecture based on Inception, but where Inception modules are replaced with <b>depthwise</b> <b>separable</b> convolutions. Also known as Xception. A <b>depthwise</b> <b>separable</b> convolution (also abbreviated as <b>separable</b> convolution) factors a standard 3-D convolution into two separate convolution operations that are more computationally efficient: first, a <b>depthwise</b> convolution, with a depth of 1 (n n 1), and then second ...", "dateLastCrawled": "2021-06-24T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>ML Interview Questions</b> | PDF | Principal Component Analysis | Logistic ...", "url": "https://www.scribd.com/document/444350635/ML-interview-questions-docx", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/444350635/<b>ML-interview-questions</b>-docx", "snippet": "In <b>machine</b> <b>learning</b>, <b>convolutional</b> filters are typically seeded with random numbers and then the <b>network</b> trains the ideal values. <b>Convolutional</b> layer is a layer of a deep <b>neural</b> <b>network</b> in which a <b>convolutional</b> filter passes along an input matrix. For example, consider the following 3x3 <b>convolutional</b> filter: The following animation shows a <b>convolutional</b> layer consisting of 9 <b>convolutional</b> operations involving the 5x5 input matrix. Notice that each <b>convolutional</b> operation works on a different ...", "dateLastCrawled": "2022-01-21T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Simple Bidirectional LSTM Solution for Text Classification | Request PDF", "url": "https://www.researchgate.net/publication/337486737_Simple_Bidirectional_LSTM_Solution_for_Text_Classification", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/337486737_Simple_Bidirectional_LSTM_Solution...", "snippet": "Deep <b>neural</b> nets with a large number of parameters are very powerful <b>machine</b> <b>learning</b> systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use ...", "dateLastCrawled": "2022-01-27T12:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "In <b>machine learning</b>, <b>convolutional</b> filters are typically seeded with random numbers and then the <b>network</b> trains the ideal values. <b>convolutional</b> layer. #image. A layer of a deep <b>neural</b> <b>network</b> in which a <b>convolutional</b> filter passes along an input matrix. For example, consider the following 3x3 <b>convolutional</b> filter: The following animation shows a <b>convolutional</b> layer consisting of 9 <b>convolutional</b> operations involving the 5x5 input matrix. Notice that each <b>convolutional</b> operation works on a ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(depthwise separable convolutional neural network (sepcnn))  is like +(2D array)", "+(depthwise separable convolutional neural network (sepcnn)) is similar to +(2D array)", "+(depthwise separable convolutional neural network (sepcnn)) can be thought of as +(2D array)", "+(depthwise separable convolutional neural network (sepcnn)) can be compared to +(2D array)", "machine learning +(depthwise separable convolutional neural network (sepcnn) AND analogy)", "machine learning +(\"depthwise separable convolutional neural network (sepcnn) is like\")", "machine learning +(\"depthwise separable convolutional neural network (sepcnn) is similar\")", "machine learning +(\"just as depthwise separable convolutional neural network (sepcnn)\")", "machine learning +(\"depthwise separable convolutional neural network (sepcnn) can be thought of as\")", "machine learning +(\"depthwise separable convolutional neural network (sepcnn) can be compared to\")"]}