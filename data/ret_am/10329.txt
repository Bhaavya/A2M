{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Multi-head</b> <b>Self Attention</b> vs 2D Convolutions", "url": "https://groups.google.com/g/lczero/c/mxXNV41-DfQ", "isFamilyFriendly": true, "displayUrl": "https://<b>groups</b>.google.com/g/lczero/c/mxXNV41-DfQ", "snippet": "In developing and testing a pure <b>self-attention</b> vision model, we verify that <b>self-attention</b> can indeed be an effective stand-alone layer. A simple procedure of replacing all instances of spatial convolutions with a form of <b>self-attention</b> applied to ResNet model produces a fully self-attentional model that outperforms the baseline on ImageNet classification with 12% fewer FLOPS and 29% fewer parameters.", "dateLastCrawled": "2022-01-25T14:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Transformer-Based Hierarchical Variational AutoEncoder Combined ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8534582/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8534582", "snippet": "The <b>multi-head</b> <b>self-attention</b> mechanism is the core of the Transformer. It mainly consists of two parts: Scaled Dot-Product Attention and <b>Multi-Head</b> Attention. Generally speaking, the point of Scaled Dot-Product Attention is to map a query and a key-value into an output, as shown in (1) of Figure 2. This output is the weighted sum of key values, and its weight is calculated from the similarity between query and key. In the <b>self-attention</b> mechanism, the similarity between query and key is ...", "dateLastCrawled": "2022-01-08T14:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Intuitive Introduction to BERT \u2013 MachineCurve</b>", "url": "https://www.machinecurve.com/index.php/2021/01/04/intuitive-introduction-to-bert/", "isFamilyFriendly": true, "displayUrl": "https://www.machinecurve.com/index.php/2021/01/04/<b>intuitive-introduction-to-bert</b>", "snippet": "The <b>multi-head</b> attention segment differentiates itself from the masked <b>multi-head</b> attention segment used by the GPT model and is why Devlin et al. (2018) propose BERT. It\u2019s exactly the <b>same</b>, except for the mask. In other words, this is how bidirectionality is added to the <b>self-attention</b> mechanism.", "dateLastCrawled": "2022-01-30T22:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Why does a transformer not use an activation function following the ...", "url": "https://ai.stackexchange.com/questions/30341/why-does-a-transformer-not-use-an-activation-function-following-the-multi-head-a", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/30341/why-does-a-transformer-not-use-an...", "snippet": "Bloem, in the blog post above, does discuss the mathematical properties of <b>self-attention</b> without bringing up the fact that the original architecture does have learned embeddings. All this shows is that having learned embeddings does not matter that much; The layers following the multi-headed attention will learn the relationships between the vectors.", "dateLastCrawled": "2022-01-25T19:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How DeepMind AlphaFold2 works? | Personal blog of Boris Burkov", "url": "http://borisburkov.net/2021-12-25-1/", "isFamilyFriendly": true, "displayUrl": "borisburkov.net/2021-12-25-1", "snippet": "The resulting mechanism is called a single <b>multi-head</b> attention block. Blocks <b>like</b> this are units of a transformer network. <b>Multi-head</b> attention . This was a single <b>multi-head</b> attention layer. As a result of its application, each column of matrix X i X_i X i will be enriched with weighted sums of several (h h h to be precise) relations with other columns X j X_j X j in some aspect. The more layers of <b>multi-head</b> attention we stack, the more complex and high-level relations we shall be able to ...", "dateLastCrawled": "2022-02-02T02:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The <b>Illustrated Transformer</b> \u2013 Jay Alammar \u2013 Visualizing machine ...", "url": "http://jalammar.github.io/illustrated-transformer/", "isFamilyFriendly": true, "displayUrl": "jalammar.github.io/<b>illustrated-transformer</b>", "snippet": "The encoder\u2019s inputs first flow through a <b>self-attention</b> layer \u2013 a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. We\u2019ll look closer at <b>self-attention</b> later in the post. The outputs of the <b>self-attention</b> layer are fed to a feed-forward neural network. The exact <b>same</b> feed-forward ...", "dateLastCrawled": "2022-02-03T07:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "neural networks - What exactly are keys, queries, and values in ...", "url": "https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/421935", "snippet": "The <b>Multi-head</b> Attention mechanism in my understanding is this <b>same</b> process happening independently in parallel a given number of times (i.e number of heads), and then the result of each parallel process is combined and processed later on using math. I didn&#39;t fully understand the rationale of having the <b>same</b> <b>thing</b> done multiple times in parallel before combining, but i wonder if its something to do with, as the authors might mention, the fact that each parallel process takes place in a ...", "dateLastCrawled": "2022-02-02T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>How Transformer is Bidirectional - Machine Learning</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/55158554/how-transformer-is-bidirectional-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/55158554", "snippet": "Edit of Edit: forget about the scale product, it&#39;s the inside the Attention which is inside A <b>multi head</b> attention itself inside the Transformer: you are <b>looking</b> to deep. The transformer is using the entire sequence every time to find the other sequence (In case of BERT it&#39;s the missing 0.15 percentage of the sentence) and that&#39;s it. The use of BERT as a language model is realy a transfer learning As stated in your post, unidirectional can be done with a certain type of mask, bidirec is ...", "dateLastCrawled": "2022-01-13T22:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Introduction to Transformers in Machine Learning</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in...", "snippet": "In human language, you can visualize this as if you are <b>looking</b> <b>at the same</b> problem from different angles, rather than just one angle (i.e. the <b>self-attention</b> we just covered). By learning multiple representations, the Transformer becomes more and more context-aware. As you can see, the outputs of the linear layers are sent to separate scaled dot-product attention blocks, which output the importance of the values; these are concatenated and passed through a Linear layer again.", "dateLastCrawled": "2022-02-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Replac your RNN and LSTM with Attention base Transformer model for NLP ...", "url": "https://androidkt.com/attention-base-transformer-for-nlp/", "isFamilyFriendly": true, "displayUrl": "https://androidkt.com/attention-base-transformer-for-nlp", "snippet": "So <b>people</b> have been doing a lot of stuff in natural language processing <b>like</b> parsing, translation, finding entities anything towards making machines understand text a little bit. You\u2019ve seen in the previous post the main <b>thing</b> is they generate the next word. They look at the past using RNN to generate the next word of the output or you have LSTM cell to generates the next word. They have some problems with architecture and we were thinking for a long time <b>like</b> what\u2019s the gist of this ...", "dateLastCrawled": "2022-02-03T01:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Multi-head</b> <b>Self Attention</b> vs 2D Convolutions", "url": "https://groups.google.com/g/lczero/c/mxXNV41-DfQ", "isFamilyFriendly": true, "displayUrl": "https://<b>groups</b>.google.com/g/lczero/c/mxXNV41-DfQ", "snippet": "In developing and testing a pure <b>self-attention</b> vision model, we verify that <b>self-attention</b> can indeed be an effective stand-alone layer. A simple procedure of replacing all instances of spatial convolutions with a form of <b>self-attention</b> applied to ResNet model produces a fully self-attentional model that outperforms the baseline on ImageNet classification with 12% fewer FLOPS and 29% fewer parameters.", "dateLastCrawled": "2022-01-25T14:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Transformer-Based Hierarchical Variational AutoEncoder Combined ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8534582/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8534582", "snippet": "The <b>multi-head</b> <b>self-attention</b> mechanism is the core of the Transformer. It mainly consists of two parts: Scaled Dot-Product Attention and <b>Multi-Head</b> Attention. Generally speaking, the point of Scaled Dot-Product Attention is to map a query and a key-value into an output, as shown in (1) of Figure 2. This output is the weighted sum of key values, and its weight is calculated from the similarity between query and key. In the <b>self-attention</b> mechanism, the similarity between query and key is ...", "dateLastCrawled": "2022-01-08T14:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Why does a transformer not use an activation function following the ...", "url": "https://ai.stackexchange.com/questions/30341/why-does-a-transformer-not-use-an-activation-function-following-the-multi-head-a", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/30341/why-does-a-transformer-not-use-an...", "snippet": "The important <b>thing</b> to take into consideration is that within the <b>self-attention</b> mechanism, there are no parameters; Those linear operations are just there to capture the relationship between the different vectors by using the properties of the vectors used to represent them.", "dateLastCrawled": "2022-01-25T19:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Intuitive Introduction to BERT \u2013 MachineCurve</b>", "url": "https://www.machinecurve.com/index.php/2021/01/04/intuitive-introduction-to-bert/", "isFamilyFriendly": true, "displayUrl": "https://www.machinecurve.com/index.php/2021/01/04/<b>intuitive-introduction-to-bert</b>", "snippet": "The <b>multi-head</b> attention segment differentiates itself from the masked <b>multi-head</b> attention segment used by the GPT model and is why Devlin et al. (2018) propose BERT. It\u2019s exactly the <b>same</b>, except for the mask. In other words, this is how bidirectionality is added to the <b>self-attention</b> mechanism.", "dateLastCrawled": "2022-01-30T22:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Replac your RNN and LSTM with Attention base Transformer model for NLP ...", "url": "https://androidkt.com/attention-base-transformer-for-nlp/", "isFamilyFriendly": true, "displayUrl": "https://androidkt.com/attention-base-transformer-for-nlp", "snippet": "<b>Self-Attention</b>. Imagine you\u2019re producing the name of the <b>group</b> member now you can attend however many steps behind. You can see earlier I said it was Jackson let me say this again. With CNN you could do this but you need to know the exact position. You need to compress the data very much. With attention since it\u2019s content-based queering you can do this quickly. 3 Ways of Attention. What I showed you is a language model meaning it just decodes it has no inputs but for translation, you ...", "dateLastCrawled": "2022-02-03T01:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "neural networks - What exactly are keys, queries, and values in ...", "url": "https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/421935", "snippet": "The <b>Multi-head</b> Attention mechanism in my understanding is this <b>same</b> process happening independently in parallel a given number of times (i.e number of heads), and then the result of each parallel process is combined and processed later on using math. I didn&#39;t fully understand the rationale of having the <b>same</b> <b>thing</b> done multiple times in parallel before combining, but i wonder if its something to do with, as the authors might mention, the fact that each parallel process takes place in a ...", "dateLastCrawled": "2022-02-02T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "comparison - In Computer Vision, what is the difference between a ...", "url": "https://ai.stackexchange.com/questions/28818/in-computer-vision-what-is-the-difference-between-a-transformer-and-attention", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/28818/in-computer-vision-what-is-the-difference...", "snippet": "Here&#39;s the picture of the attention mechanism (as you can see from the diagram above, the transformer used the <b>multi-head</b> attention on the right). One <b>thing</b> to keep in mind is that the idea of attention is not novel to the transformer, given that <b>similar</b> ideas had already been used in previous works and models, for example, here , although the specific attention mechanisms are different.", "dateLastCrawled": "2022-01-23T20:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Introduction to Transformers in Machine Learning</b> \u2013 MachineCurve", "url": "https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in...", "snippet": "In human language, you can visualize this as if you are <b>looking</b> <b>at the same</b> problem from different angles, rather than just one angle (i.e. the <b>self-attention</b> we just covered). By learning multiple representations, the Transformer becomes more and more context-aware. As you can see, the outputs of the linear layers are sent to separate scaled dot-product attention blocks, which output the importance of the values; these are concatenated and passed through a Linear layer again.", "dateLastCrawled": "2022-02-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The <b>Illustrated Transformer</b> \u2013 Jay Alammar \u2013 Visualizing machine ...", "url": "http://jalammar.github.io/illustrated-transformer/", "isFamilyFriendly": true, "displayUrl": "jalammar.github.io/<b>illustrated-transformer</b>", "snippet": "Harvard\u2019s NLP <b>group</b> created a guide annotating the paper with PyTorch implementation. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to <b>people</b> without in-depth knowledge of the subject matter. 2020 Update: I\u2019ve created a \u201cNarrated Transformer\u201d video which is a gentler approach to the topic: A High-Level Look Let\u2019s begin by <b>looking</b> at the model as a single black box. In a machine translation ...", "dateLastCrawled": "2022-02-03T07:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[D] Confused mathematician <b>looking</b> for clarity on transformers, and ...", "url": "https://www.reddit.com/r/MachineLearning/comments/j5jg1l/d_confused_mathematician_looking_for_clarity_on/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/j5jg1l/d_confused_mathematician_<b>looking</b>_for_clarity_on", "snippet": "I also find, that fancy names (<b>multi-head</b> <b>self-attention</b>) and complicated diagrams and notation can distract from the core principles which are very simple. You have bunch (n) of vectors x_1 ... x_n of, say, dimension 1024. By the power of transformers you want to make a new bunch of n vectors, that are better, as in they encode the information in a more suitable way or whatever. The basic idea of attention is to make a weighted sum of the vectors. We find the weights by comparing pairs of ...", "dateLastCrawled": "2021-02-01T11:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Transformer-Based Hierarchical Variational AutoEncoder Combined ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8534582/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8534582", "snippet": "The <b>multi-head</b> <b>self-attention</b> mechanism is the core of the Transformer. It mainly consists of two parts: Scaled Dot-Product Attention and <b>Multi-Head</b> Attention. Generally speaking, the point of Scaled Dot-Product Attention is to map a query and a key-value into an output, as shown in (1) of Figure 2. This output is the weighted sum of key values, and its weight is calculated from the similarity between query and key. In the <b>self-attention</b> mechanism, the similarity between query and key is ...", "dateLastCrawled": "2022-01-08T14:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "neural networks - What exactly are keys, queries, and values in ...", "url": "https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/421935", "snippet": "The attention operation <b>can</b> <b>be thought</b> of as a retrieval process as well. ... The real power of the attention layer / transformer comes from the fact that each token is <b>looking</b> at all the other tokens <b>at the same</b> time (unlike an RNN / LSTM which is restricted to <b>looking</b> at the tokens to the left) The <b>Multi-head</b> Attention mechanism in my understanding is this <b>same</b> process happening independently in parallel a given number of times (i.e number of heads), and then the result of each parallel ...", "dateLastCrawled": "2022-02-02T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Multi-head</b> <b>Self Attention</b> vs 2D Convolutions", "url": "https://groups.google.com/g/lczero/c/mxXNV41-DfQ", "isFamilyFriendly": true, "displayUrl": "https://<b>groups</b>.google.com/g/lczero/c/mxXNV41-DfQ", "snippet": "I still don&#39;t know exactly what <b>multi-head</b> <b>self-attention</b> means precisely in terms of architecture/training algorithm. But to answer my question about whether time series was the only place where this would apply. I am now wanting to read first the following paper. here link and paste abstract. On the Relationship between <b>Self-Attention</b> and Convolutional Layers. Recent trends of incorporating attention mechanisms in vision have led researchers to reconsider the supremacy of convolutional ...", "dateLastCrawled": "2022-01-25T14:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Convolutional networks, recurrent neural networks and transfomers | by ...", "url": "https://medium.com/mlearning-ai/convolutional-networks-recurrent-neural-networks-and-transfomers-ee6a63ddb57f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/mlearning-ai/convolutional-networks-recurrent-neural-networks-and...", "snippet": "The basic concept of <b>self-attention</b> <b>can</b> be used to develop a powerful type of sequence model called a transformer, but to make this actually work we need to develop a few additional components and ...", "dateLastCrawled": "2022-01-11T22:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "10 Don\u2019ts on Your Digital Devices | Request PDF", "url": "https://www.researchgate.net/publication/321499573_10_Don'ts_on_Your_Digital_Devices", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321499573_10_Don&#39;ts_on_Your_Digital_Devices", "snippet": "The first is a <b>multi-head</b> <b>self-attention</b> mechanism, and the second is a simple, positionconnected feed-forward network. We employ a residual connection [11] around each of ub-layers, followed by ...", "dateLastCrawled": "2021-11-07T13:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "prettyandnerdy \u2013 This WordPress.com site is the bee&#39;s knees", "url": "https://pretteyandnerdy.wordpress.com/", "isFamilyFriendly": true, "displayUrl": "https://pretteyandnerdy.wordpress.com", "snippet": "The first is a <b>multi-head</b> <b>self-attention</b> mechanism in the encoder, and the second is the original encoder-decoder attention in the decoder, which performs <b>multi-head</b> attention over the output of the encoder stack The decoder stack also has a <b>self-attention</b> layer but it is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions by setting them to negative infinity before the Softmax step. Residual Connection. Six layers is pretty deep. When ...", "dateLastCrawled": "2021-12-25T08:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "neural networks - What&#39;s the difference between content-based attention ...", "url": "https://ai.stackexchange.com/questions/25459/whats-the-difference-between-content-based-attention-and-dot-product-attention", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/25459/whats-the-difference-between-content...", "snippet": "Finally, since apparently we don&#39;t really know why the BatchNorm works <b>same</b> <b>thing</b> holds for the LayerNorm. Interestingly, it seems like (1) BatchNorm (2) LayerNorm and (3) your question about normalization in the attention mechanism - all of it look like different ways at <b>looking</b> <b>at the same</b>, yet undiscovered and clearly stated <b>thing</b>.", "dateLastCrawled": "2022-01-28T18:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "CoCon: A Self-Supervised Approach for Controlled ... - arxiv-vanity.com", "url": "https://www.arxiv-vanity.com/papers/2006.03535/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2006.03535", "snippet": "Pretrained Transformer-based language models (LMs) display remarkable natural language generation capabilities. With their immense potential, controlling text generation of such LMs is getting attention. While there are studies that seek to control high-level attributes (such as sentiment and topic) of generated text, there is still a lack of more precise control over its content at the word- and phrase-level. Here, we propose Content-Conditioner (CoCon) to control an LM\u2019s output text with ...", "dateLastCrawled": "2021-11-25T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>ONNX import/export</b> \u00b7 Issue #10 \u00b7 FluxML/ML-Coordination-Tracker \u00b7 <b>GitHub</b>", "url": "https://github.com/FluxML/ML-Coordination-Tracker/issues/10", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/FluxML/ML-Coordination-Tracker/issues/10", "snippet": "There are two reasons for this: - Flux layers are pretty well designed for manipulation with standard Julia syntax - Most <b>people</b> (myself included for my work) don&#39;t want to learn another library to interpret a model Isn&#39;t the nice <b>thing</b> about the Chain that if your model is super simple so that it only consists of unary operations stringed (well chained actually) you <b>can</b> get rid of alot of complexity as you only need to store the layers as a tuple/array since the structure is implicit from ...", "dateLastCrawled": "2022-01-04T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "notes/Deep Learning.md at master \u00b7 brylevkirill/notes \u00b7 <b>GitHub</b>", "url": "https://github.com/brylevkirill/notes/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/brylevkirill/notes/blob/master/Deep Learning.md", "snippet": "Masked <b>Self-Attention</b> Nets: unbounded receptive field; parallel compute: O(1) matrix-vector ops, but O(N^2) factor ; O(1) dependency steps; the state is the captured context: O(N) generative models - flow models. papers and resources &quot;Normalizing Flows for Probabilistic Modeling and Inference&quot; by Papamakarios et al. paper. overview by Aravind Srinivas video 2020 overview by Aravind Srinivas video 2019 overview by Pieter Abbeel video 2020 overview (1, 2) by Jonathan Ho video 2019 overview by ...", "dateLastCrawled": "2021-12-14T09:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Transformer-Based Hierarchical Variational AutoEncoder Combined ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8534582/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8534582", "snippet": "<b>At the same</b> time, deep recurrent belief and capsule networks [15,16,17] also ... The <b>multi-head</b> <b>self-attention</b> mechanism is the core of the Transformer. It mainly consists of two parts: Scaled Dot-Product Attention and <b>Multi-Head</b> Attention. Generally speaking, the point of Scaled Dot-Product Attention is to map a query and a key-value into an output, as shown in (1) of Figure 2. This output is the weighted sum of key values, and its weight is calculated from the similarity between query and ...", "dateLastCrawled": "2022-01-08T14:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Intuitive Introduction to BERT \u2013 MachineCurve</b>", "url": "https://www.machinecurve.com/index.php/2021/01/04/intuitive-introduction-to-bert/", "isFamilyFriendly": true, "displayUrl": "https://www.machinecurve.com/index.php/2021/01/04/<b>intuitive-introduction-to-bert</b>", "snippet": "The attention head <b>can</b> be split into multiple segments, hence the name <b>multi-head</b>. The <b>multi-head</b> attention segment differentiates itself from the masked <b>multi-head</b> attention segment used by the GPT model and is why Devlin et al. (2018) propose BERT. It\u2019s exactly the <b>same</b>, except for the mask. In other words, this is how bidirectionality is ...", "dateLastCrawled": "2022-01-30T22:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Convolutional networks, recurrent neural networks and transfomers | by ...", "url": "https://medium.com/mlearning-ai/convolutional-networks-recurrent-neural-networks-and-transfomers-ee6a63ddb57f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/mlearning-ai/convolutional-networks-recurrent-neural-networks-and...", "snippet": "The basic concept of <b>self-attention</b> <b>can</b> be used to develop a powerful type of sequence model called a transformer, but to make this actually work we need to develop a few additional components and ...", "dateLastCrawled": "2022-01-11T22:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "machine learning - Why does the <b>transformer</b> do better than RNN and LSTM ...", "url": "https://ai.stackexchange.com/questions/20075/why-does-the-transformer-do-better-than-rnn-and-lstm-in-long-range-context-depen", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/20075/why-does-the-<b>transformer</b>-do-better-than...", "snippet": "<b>Self Attention</b>: this is the newly introduced &#39;unit&#39; used to compute similarity scores between words ... (or &quot;forget&quot;) past information. Moreover, <b>multi-head</b> attention and positional embeddings both provide information about the relationship between different words. RNN / LSTM. Recurrent neural networks and Long-short term memory models, for what concerns this question, are almost identical in their core properties: Sequential processing: sentences must be processed word by word. Past ...", "dateLastCrawled": "2022-01-29T00:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "neural networks - What exactly are keys, queries, and values in ...", "url": "https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/421935", "snippet": "The <b>Multi-head</b> Attention mechanism in my understanding is this <b>same</b> process happening independently in parallel a given number of times (i.e number of heads), and then the result of each parallel process is combined and processed later on using math. I didn&#39;t fully understand the rationale of having the <b>same</b> <b>thing</b> done multiple times in parallel before combining, but i wonder if its something to do with, as the authors might mention, the fact that each parallel process takes place in a ...", "dateLastCrawled": "2022-02-02T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "<b>multi-head</b> <b>self-attention</b>. #language. An extension of <b>self-attention</b> that applies the <b>self-attention</b> mechanism multiple times for each position in the input sequence. Transformers introduced <b>multi-head</b> <b>self-attention</b>. multimodal model. #language. A model whose inputs and/or outputs include more than one modality. For example, consider a model that takes both an image and a text caption (two modalities) as features, and outputs a score indicating how appropriate the text caption is for the ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Exploring Self-Attention for Image Recognition</b> | Request PDF", "url": "https://www.researchgate.net/publication/343466025_Exploring_Self-Attention_for_Image_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343466025_<b>Exploring_Self-Attention_for_Image</b>...", "snippet": "Next, a module such as <b>multi-head</b> <b>self-attention</b> captures the pairwise relations among the tokens and mixes them. In this paper, we argue that models <b>can</b> have significant gains when spatial ...", "dateLastCrawled": "2022-01-28T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>ONNX import/export</b> \u00b7 Issue #10 \u00b7 FluxML/ML-Coordination-Tracker \u00b7 <b>GitHub</b>", "url": "https://github.com/FluxML/ML-Coordination-Tracker/issues/10", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/FluxML/ML-Coordination-Tracker/issues/10", "snippet": "There are two reasons for this: - Flux layers are pretty well designed for manipulation with standard Julia syntax - Most <b>people</b> (myself included for my work) don&#39;t want to learn another library to interpret a model Isn&#39;t the nice <b>thing</b> about the Chain that if your model is super simple so that it only consists of unary operations stringed (well chained actually) you <b>can</b> get rid of alot of complexity as you only need to store the layers as a tuple/array since the structure is implicit from ...", "dateLastCrawled": "2022-01-04T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What if our dreams <b>are a deep learning mechanism? - Quora</b>", "url": "https://www.quora.com/What-if-our-dreams-are-a-deep-learning-mechanism", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-if-our-dreams-<b>are-a-deep-learning-mechanism</b>", "snippet": "Answer (1 of 4): It\u2019s super interesting and still open question what our dreams are, but they definitely not a deep learning mechanism. :D First of all, \u201cDeep Learning\u201d is just a name for multi-layered Artificial Neural Networks, lately Convolutional ANNs in particular. All learning and thinkin...", "dateLastCrawled": "2022-01-16T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "notes/Deep Learning.md at master \u00b7 brylevkirill/notes \u00b7 <b>GitHub</b>", "url": "https://github.com/brylevkirill/notes/blob/master/Deep%20Learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/brylevkirill/notes/blob/master/Deep Learning.md", "snippet": "This representation <b>can</b> <b>be compared</b> with the theoretically optimal relevant compression of the variable X with respect to Y, provided by the information bottleneck (or information distortion) tradeoff. This is done by introducing a new information theoretic view of DNN training as an successive (Markovian) relevant compression of the input variable X, given the empirical training data. The DNN\u2019s prediction is activating the trained compression layered hierarchy to generate a predicted ...", "dateLastCrawled": "2021-12-14T09:36:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "10.5. <b>Multi-Head Attention</b> \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "http://d2l.ai/chapter_attention-mechanisms/multihead-attention.html", "isFamilyFriendly": true, "displayUrl": "d2l.ai/chapter_attention-mechanisms/<b>multihead-attention</b>.html", "snippet": "This design is called <b>multi-head attention</b>, where each of the \\(h\\) attention pooling outputs is a head [Vaswani et al., 2017]. Using fully-connected layers to perform learnable linear transformations, Fig. 10.5.1 describes <b>multi-head attention</b>.", "dateLastCrawled": "2022-02-02T01:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Introduction to Transformers in Machine Learning</b>", "url": "https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/.../12/28/<b>introduction-to-transformers-in-machine-learning</b>", "snippet": "The masked <b>multi-head</b> attention segment, which performs <b>multi-head</b> <b>self-attention</b> on the outputs, but does so in a masked way, so that positions depend on the past only. The <b>multi-head</b> attention segment , which performs <b>multi-head</b> <b>self-attention</b> on a combination of the ( encoded ) inputs and the outputs, so that the model learns to correlate encoded inputs with desired outputs.", "dateLastCrawled": "2022-02-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> Glossary: Language Evaluation | Google Developers", "url": "https://developers.google.com/machine-learning/glossary/language", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine</b>-<b>learning</b>/glossary/language", "snippet": "Refer also to <b>self-attention</b> and <b>multi-head</b> <b>self-attention</b>, which are the building blocks of Transformers. B. bag of words. #language. A representation of the words in a phrase or passage, irrespective of order. For example, bag of words represents the following three phrases identically: the dog jumps; jumps the dog; dog jumps the; Each word is mapped to an index in a sparse vector, where the vector has an index for every word in the vocabulary. For example, the phrase the dog jumps is ...", "dateLastCrawled": "2022-01-29T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Attending to Attention. A summary of a revolutionary paper\u2026 | by Akash ...", "url": "https://towardsdatascience.com/attending-to-attention-eba798f0e940", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/attending-to-attention-eba798f0e940", "snippet": "The first is a <b>multi-head</b> <b>self-attention</b> mechanism, and the second is a simple, position-wise fully connected feed-forward network. We employ a residual connection around each of the two sub-layers, followed by layer normalization. That is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of ...", "dateLastCrawled": "2022-01-25T10:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Lecture 7: Transformers</b> - Deep <b>Learning</b>", "url": "https://chinmayhegde.github.io/dl-notes/notes/lecture07/", "isFamilyFriendly": true, "displayUrl": "https://chinmayhegde.github.io/dl-notes/notes/lecture07", "snippet": "<b>Self-Attention</b>. This is the point where papers-blogs-tweets-slides etc start talking about keys/values and attention mechanisms and everything goes a bit haywire. Let\u2019s just ignore all that for now, and instead talk about something called <b>self-attention</b>. The use of the \u201cself-\u201c prefix will become clear later on. Here is how it is defined.", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Intuitive Introduction to BERT \u2013 MachineCurve</b>", "url": "https://www.machinecurve.com/index.php/2021/01/04/intuitive-introduction-to-bert/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/index.php/2021/01/04/<b>intuitive-introduction-to-bert</b>", "snippet": "From our article about GPT: \u201cThe input is then served to a masked <b>multi-head</b> attention segment, which computes <b>self-attention</b> in a unidirectional way.Here, the residual is added and the result is layer normalized.\u201d Indeed, GPT (which uses the Transformer decoder segment autoregressively during pretraining) and the original Transformer (which performs Seq2Seq), apply a mask in one of the attention modules \u2013 the masked <b>multi-head</b> <b>self-attention</b> subsegment in the decoder segment.. For any ...", "dateLastCrawled": "2022-01-30T22:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Capturing Multi-Resolution Context by Dilated <b>Self-Attention</b>", "url": "https://www.merl.com/publications/docs/TR2021-036.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.merl.com/publications/docs/TR2021-036.pdf", "snippet": "to <b>machine</b> translation or language modeling, where close-by words are more likely to have a dependent relationship, while only a few distant words or word groups are relevant to trace the semantic con-text and syntax of a sentence [15]. This hypothesis is investigated in this work by combining re-stricted (or time-restricted) <b>self-attention</b> with a dilation mechanism, whereby a high <b>self-attention</b> resolution for neighboring frames and a lower <b>self-attention</b> resolution for distant information ...", "dateLastCrawled": "2021-12-02T00:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "CoAtNet: how to perfectly combine CNNs and Transformers | by Leonardo ...", "url": "https://medium.com/codex/coatnet-how-to-perfectly-combine-cnns-and-transformer-9632e187ecbf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/codex/coatnet-how-to-perfectly-combine-cnns-and-transformer-9632e...", "snippet": "The <b>multi-head</b> attention block computes <b>self-attention</b> several times with different weight matrices and then concatenates the results together, which are resized to the embedding dimension using ...", "dateLastCrawled": "2022-01-26T06:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Dilated Residual Network with Multi-head</b> <b>Self-attention</b> for Speech ...", "url": "https://www.researchgate.net/publication/332791636_Dilated_Residual_Network_with_Multi-head_Self-attention_for_Speech_Emotion_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/332791636_<b>Dilated_Residual_Network_with_Multi</b>...", "snippet": "While Li et al. [23] proposed the combining use of Dilated Residual Network and <b>Multi-head</b> <b>Self-attention</b> for feature <b>learning</b> in speech emotion recognition. <b>Multi-head</b> <b>Self-attention</b> models ...", "dateLastCrawled": "2021-12-21T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Transformers in NLP: A beginner friendly explanation | Towards Data Science", "url": "https://towardsdatascience.com/transformers-89034557de14", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>transformer</b>s-89034557de14", "snippet": "If you are looking for an <b>analogy</b> between <b>self attention</b> and attention, think of z serving the purpose of context vectors and not global alignment weights. The <b>Transformer</b> . \u26a0\ufe0f A word of caution: the contents of this image may appear exponentially more complicated than they are. We will break this scary beast down into small baby beasts and it will all make sense. (I promise #2) (left) The <b>Transformer</b> architecture. Source: paper. (right) An abstracted version of the same for better ...", "dateLastCrawled": "2022-02-02T13:19:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(multi-head self-attention)  is like +(a group of people looking at the same thing)", "+(multi-head self-attention) is similar to +(a group of people looking at the same thing)", "+(multi-head self-attention) can be thought of as +(a group of people looking at the same thing)", "+(multi-head self-attention) can be compared to +(a group of people looking at the same thing)", "machine learning +(multi-head self-attention AND analogy)", "machine learning +(\"multi-head self-attention is like\")", "machine learning +(\"multi-head self-attention is similar\")", "machine learning +(\"just as multi-head self-attention\")", "machine learning +(\"multi-head self-attention can be thought of as\")", "machine learning +(\"multi-head self-attention can be compared to\")"]}