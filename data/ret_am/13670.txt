{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "DISCREPANCY RISK MODEL SELECTION TEST THEORY FOR COMPARING POSSIBLY ...", "url": "https://labs.utdallas.edu/app/uploads/sites/71/2020/08/Golden2003_Article_DiscrepancyRiskModelSelectionT.pdf", "isFamilyFriendly": true, "displayUrl": "https://labs.utdallas.edu/app/uploads/sites/71/2020/08/Golden2003_Article_Discrepancy...", "snippet": "an independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) assumption. Historically, both Linhart (1988; also see Efron, 1984) and Vuong (1989) showed how the null hypothesis that two strictly nonnested models (i.e., two models which have no probability distribution in common) provide equally effective descriptions of the DGP could be tested. Prob- lems in applying this methodology arose however when the models were not strictly nonnested (see Shimodaira, 1997). Vuong addressed this problem using a ...", "dateLastCrawled": "2021-09-08T13:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Theory of Evolution Strategies: a New Perspective Theory of Randomized ...", "url": "http://www.cmap.polytechnique.fr/~nikolaus.hansen/TRSH-ChapterAugerHansen.pdf", "isFamilyFriendly": true, "displayUrl": "www.cmap.polytechnique.fr/~nikolaus.hansen/TRSH-ChapterAugerHansen.pdf", "snippet": "independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) over D, X 0 = Y 0 and Xn+1 =! Yn if f(Yn) \u2264 f(Xn) , Xn otherwise. (10.1) The probably most important concept in an adaptive algorithm is to probe preferably in the neighborhood of the current solution since for non patho-logical functions good solutions are usually close to even better ones. If W", "dateLastCrawled": "2022-01-31T14:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is an <b>intuitive explanation of an independent</b> and identical ...", "url": "https://www.quora.com/What-is-an-intuitive-explanation-of-an-independent-and-identical-distribution-IID", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-an-<b>intuitive-explanation-of-an-independent</b>-and-identical...", "snippet": "Answer: A process with no memory. If you flip a fair coin 100 times, the first 100 results have no bearing on the outcome of the 101st flip. You don&#39;t need to keep information regarding past behavior as a context that would inform future expectations, because every sample comes from the same di...", "dateLastCrawled": "2021-12-16T23:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Using Conditional Extreme Value Theory to</b> Estimate Value-at-Risk for ...", "url": "https://www.scirp.org/journal/PaperInformation.aspx?PaperID=80121", "isFamilyFriendly": true, "displayUrl": "https://www.scirp.org/journal/PaperInformation.aspx?PaperID=80121", "snippet": "EVT provides a robust framework for modeling the tail distributions and it does for the maxima of <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) random variables what the central limit theorem (CLT) does for modeling the summation of random variables and both theories give the asymptotically limiting distributions as the sample increases. In extreme value theory, there are two statistical approaches for analyzing extreme values: the block maxima (BM) method and peaks-over-threshold (POT ...", "dateLastCrawled": "2022-01-29T23:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "WHY IS ATTENTIONNOT SO INTERPRETABLE", "url": "https://openreview.net/pdf?id=pQhnag-dIt", "isFamilyFriendly": true, "displayUrl": "https://openreview.net/pdf?id=pQhnag-dIt", "snippet": "<b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) from a distribution with domain X\u21e5Y, where X is the feature domain, and Y is the label domain3. Additionally, we assume that the mask is drawn from a distribution with domain M. Usually, M is under some constraints, for example, only being", "dateLastCrawled": "2022-01-10T20:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "probability theory - What does &quot;<b>identically distributed</b>&quot; mean ...", "url": "https://math.stackexchange.com/questions/1788606/what-does-identically-distributed-mean", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/1788606", "snippet": "This answer is not useful. Show activity on this post. In probability theory and statistics, a sequence or other collection of random variables are independent <b>and identically distributed</b> (<b>i.i.d</b>.) if each random variable has the same probability distribution as the others and all are mutually independent. Share.", "dateLastCrawled": "2022-02-03T07:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Rate-adaptive model selection over</b> a <b>collection of black-box contextual</b> ...", "url": "https://deepai.org/publication/rate-adaptive-model-selection-over-a-collection-of-black-box-contextual-bandit-algorithms", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>rate-adaptive-model-selection-over</b>-a-collection-of...", "snippet": "We suppose that contexts are independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) and that the conditional distribution of rewards given actions and contexts is fixed across time points. After each round t , the master passes the triple ( X ( t ) , A ( t ) , Y ( t ) ) to base algorithm \u02c6 J ( t ) , which increments the internal time n ( \u02c6 J ( t ) , t ) of algorithm \u02c6 J ( t ) by 1, and leaves unchanged the internal time of the other algorithms.", "dateLastCrawled": "2021-12-25T16:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Is linear regression valid when the outcome (dependant variable) not ...", "url": "https://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome_dependant_variable_not_normally_distributed", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome...", "snippet": "The usual statement is that the errors are <b>i.i.d</b>. (i.e., <b>independently</b> <b>and identically</b> <b>distributed</b>) as Normal with a mean of 0 and some variance. Independence and homoscedasticity are more ...", "dateLastCrawled": "2022-02-03T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Lesson 46 Central Limit Theorem</b> | Introduction to Probability", "url": "https://dlsun.github.io/probability/clt.html", "isFamilyFriendly": true, "displayUrl": "https://dlsun.github.io/probability/clt.html", "snippet": "Motivation. In Lesson 45, we saw that calculating the exact distribution of a sum of <b>i.i.d</b>. random variables, \\(S_n = X_1 + X_2 + \\ldots + X_n\\) is a lot of work. Each time we add another random variable, we have to calculate a convolution, which requires calculating an integral. For arbitrary p.m.f.s and p.d.f.s, calculating many convolutions is impractical.", "dateLastCrawled": "2022-01-06T18:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>Random Matrix Theory Approach to Denoise Single</b>-Cell Data", "url": "https://www.cell.com/patterns/pdfExtended/S2666-3899(20)30040-4", "isFamilyFriendly": true, "displayUrl": "https://www.cell.com/patterns/pdfExtended/S2666-3899(20)30040-4", "snippet": "bution (i.e., they assume independent <b>and identically</b> <b>distributed</b> random variables, or <b>i.i.d</b>.). Although there have been efforts to understand the intrinsic stochastic nature of gene expres-sion,14,15 we currently do not have predictive quantitative models of gene expression. Therefore, it is not clear what the", "dateLastCrawled": "2021-09-08T19:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Statistical tests for whether a given set of independent, <b>identically</b> ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2944726/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC2944726", "snippet": "A basic task in statistics is to ascertain whether a given set of independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) draws X 1,X 2,\u2026,X n-1,X n does not come from a distribution with a specified probability density function p (the null hypothesis is that X 1,X 2,\u2026,X n-1,X n do in fact come from the specified p).In the present paper, we consider the case when X 1,X 2,\u2026,X n-1,X n are real valued. In this case, the most commonly used approach is due to Kolmogorov and Smirnov (with a popular ...", "dateLastCrawled": "2022-01-14T02:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What is an <b>intuitive explanation of an independent</b> and identical ...", "url": "https://www.quora.com/What-is-an-intuitive-explanation-of-an-independent-and-identical-distribution-IID", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-an-<b>intuitive-explanation-of-an-independent</b>-and-identical...", "snippet": "Answer: A process with no memory. If you flip a fair coin 100 times, the first 100 results have no bearing on the outcome of the 101st flip. You don&#39;t need to keep information regarding past behavior as a context that would inform future expectations, because every sample comes from the same di...", "dateLastCrawled": "2021-12-16T23:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Deterministic Sampling-Based Motion Planning: Optimality, Complexity ...", "url": "http://lucasjanson.fas.harvard.edu/papers/Deterministic_Sampling_Based_Motion_Planning-Janson_Ichter_Pavone-2015.pdf", "isFamilyFriendly": true, "displayUrl": "lucasjanson.fas.harvard.edu/papers/Deterministic_Sampling_Based_Motion_Planning-Janson...", "snippet": "search that probabilistically probes the con\ufb01guration space with <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) random samples. This probing is enabled by a collision detection module, which the motion planning algorithm considers as a \u201c<b>black</b> <b>box</b>&quot; [Lavalle, 2006]. Examples, roughly in chronological order, include the probabilistic roadmap algorithm (PRM) [Kavraki et al., 1996], expansive space trees (EST) [Hsu et al., 1999, Phillips et al., 2004], Lazy-PRM [Bohlin and Kavraki,2000 ...", "dateLastCrawled": "2022-02-02T20:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Deterministic Sampling-Based Motion Planning: Optimality, Complexity</b> ...", "url": "https://web.stanford.edu/~pavone/papers/Janson.Ichter.ea.ISRR15.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/~pavone/papers/Janson.Ichter.ea.ISRR15.pdf", "snippet": "in that they compute a path by connecting <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) random points in the con\ufb01guration space. Their randomization aspect, how- ever, makes several tasks challenging, including certi\ufb01cation for safety-critical ap-plications and use of of\ufb02ine computation to improve real-time execution. Hence, an important open question is whether <b>similar</b> (or better) theoretical guarantees and practical performance could be obtained by considering deterministic, as ...", "dateLastCrawled": "2022-01-26T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "An Alternative to the Feltham Ohlson Valuation Framework", "url": "http://www.cdam.lse.ac.uk/Reports/Files/cdam-2001-12.pdf", "isFamilyFriendly": true, "displayUrl": "www.cdam.lse.ac.uk/Reports/Files/cdam-2001-12.pdf", "snippet": "t are modelled as <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.; assuming such a belief on the part of investors), then the physical probability for the distribution of equity price may be used as an equivalent procedure, in which case the discount rate becomes the constant expected rate of return and that of necessity is set equal to the \u2018required rate of return\u2019 for the given class of risk. Our model is based on the latter premise; that is to say the model assumes that management ...", "dateLastCrawled": "2021-11-22T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Frontiers | <b>Statistical Analysis of fMRI Time-Series: A Critical Review</b> ...", "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2011.00028/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fnhum.2011.00028", "snippet": "(A1) Errors are <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) ... it does so in a <b>black</b>-<b>box</b> fashion without being informative on what are the processes generating the non-linearities. In response to these criticisms Friston et al. (2000b) present evidence for the non-linearities expressed in the Balloon model of hemodynamic signal transduction (see Buxton et al., 1998) being compatible with a second order Volterra characterization, thus adding biological plausibility to the model. A ...", "dateLastCrawled": "2022-01-28T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Opening the <b>black</b> <b>box</b>: an open\u2010source release of <b>Maxent</b> - Phillips ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.03049", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.03049", "snippet": "An IPP with intensity l is defined as an independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) sample from p l, whose size (number of points) is a Poisson random variable with mean Warton and Shepherd suggested modeling the occurrence records for a species as arising from an IPP whose intensity l(z) is a log-linear function of a vector of real-valued features x(z):", "dateLastCrawled": "2021-12-19T18:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Deterministic sampling-based motion - SAGE Journals", "url": "https://journals.sagepub.com/doi/pdf/10.1177/0278364917714338", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/pdf/10.1177/0278364917714338", "snippet": "Such algorithms are probabilistic in that they compute a path by connecting <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) random points in the con\ufb01guration space. Their randomization aspect, however, makes several tasks challenging, including certi\ufb01cation for safety-critical applications and use of of\ufb02ine computation to improve real-time execution. Hence, an important open question is whether <b>similar</b> (or better) theoretical guarantees and practical perfor-mance could be obtained ...", "dateLastCrawled": "2022-01-29T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is linear regression valid when the outcome (dependant variable) not ...", "url": "https://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome_dependant_variable_not_normally_distributed", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome...", "snippet": "The usual statement is that the errors are <b>i.i.d</b>. (i.e., <b>independently</b> <b>and identically</b> <b>distributed</b>) as Normal with a mean of 0 and some variance. Independence and homoscedasticity are more ...", "dateLastCrawled": "2022-02-03T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>Random Matrix Theory Approach to Denoise Single</b>-Cell Data", "url": "https://www.cell.com/patterns/pdfExtended/S2666-3899(20)30040-4", "isFamilyFriendly": true, "displayUrl": "https://www.cell.com/patterns/pdfExtended/S2666-3899(20)30040-4", "snippet": "bution (i.e., they assume independent <b>and identically</b> <b>distributed</b> random variables, or <b>i.i.d</b>.). Although there have been efforts to understand the intrinsic stochastic nature of gene expres-sion,14,15 we currently do not have predictive quantitative models of gene expression. Therefore, it is not clear what the", "dateLastCrawled": "2021-09-08T19:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Practical device-independent quantum cryptography via entropy ...", "url": "https://www.nature.com/articles/s41467-017-02307-4", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41467-017-02307-4", "snippet": "An independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) device (left) is initialised in some (unknown) <b>i.i.d</b>. state \u03c3 \u2297 n; each \u201csmall device\u201d is described by one copy of the same bipartite ...", "dateLastCrawled": "2022-01-29T12:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Introduction to <b>linear regression</b> analysis", "url": "https://people.duke.edu/~rnau/regintro.htm", "isFamilyFriendly": true, "displayUrl": "https://people.duke.edu/~rnau/regintro.htm", "snippet": "A sum of 10 or 20 <b>independently</b> <b>and identically</b> lognormally <b>distributed</b> variables has a distribution that is still quite close to lognormal. If you don\u2019t believe this, try testing it by Monte Carlo simulation: you\u2019ll be surprised. (I was.) Because the assumptions of <b>linear regression</b> (linear, additive relationships with <b>i.i.d</b>. normally <b>distributed</b> errors) are so strong, it is very important to test their validity when fitting models, a topic discussed in more detail on the testing-model ...", "dateLastCrawled": "2022-02-03T03:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The Basic Method", "url": "http://www.math.lsa.umich.edu/~conlon/math623/notes12part2.pdf", "isFamilyFriendly": true, "displayUrl": "www.math.lsa.umich.edu/~conlon/math623/notes12part2.pdf", "snippet": "based on the law of averages for independent <b>identically</b> <b>distributed</b> (<b>i.i.d</b>.) random variables. To take the simplest example, consider the situation where a fair coin is tossed many times. Then we expect that in a large number of tosses approximately 50% of the tosses will come up heads. This is a particular case of the strong law of large numbers. Let Xbe a random variable with nite mean and variance. We have that (1.1) Var[X] = E[ (X E[X])2] = E[X2] (E[X])2: Since variance is non-negative ...", "dateLastCrawled": "2021-09-14T08:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Deep Learning for Protein\u2013Protein Interaction Site Prediction ...", "url": "https://link.springer.com/protocol/10.1007%2F978-1-0716-1641-3_16", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/protocol/10.1007/978-1-0716-1641-3_16", "snippet": "Both of these scenarios violate the independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) assumption, where one assumes that the training and test data are drawn from the same underlying joint distribution. In developing a model, one is interested in performing predictions on novel protein structures that may lie outside of this distribution (ideally a dataset with a representative distribution is constructed), and so a practitioner wishes to examine the generalization of the model, i.e., the ...", "dateLastCrawled": "2022-01-26T01:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Opening the <b>black</b> <b>box</b>: an open\u2010source release of <b>Maxent</b> - Phillips ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.03049", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.03049", "snippet": "It <b>can</b> <b>be thought</b> of as indexing the likelihood that a point (here, ... where the denominator simply makes p l (z) sum to 1. An IPP with intensity l is defined as an independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) sample from p l, whose size (number of points) is a Poisson random variable with mean Warton and Shepherd suggested modeling the occurrence records for a species as arising from an IPP whose intensity l(z) is a log-linear function of a vector of real-valued features x(z): (2) The ...", "dateLastCrawled": "2021-12-19T18:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Reverse Test and Characterization of Quantum Relative Entropy | Request PDF", "url": "https://www.researchgate.net/publication/47338148_Reverse_Test_and_Characterization_of_Quantum_Relative_Entropy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/47338148_Reverse_Test_and_Characterization_of...", "snippet": "Second, one recovers the usual laws of thermodynamics in regimes of many <b>identically</b> and <b>independently</b> <b>distributed</b> (<b>i.i.d</b>.) copies of a state, such as for an ideal gas, or if the states considered ...", "dateLastCrawled": "2022-01-06T08:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A <b>Random Matrix Theory Approach to Denoise Single</b>-Cell Data", "url": "https://www.cell.com/patterns/pdfExtended/S2666-3899(20)30040-4", "isFamilyFriendly": true, "displayUrl": "https://www.cell.com/patterns/pdfExtended/S2666-3899(20)30040-4", "snippet": "bution (i.e., they assume independent <b>and identically</b> <b>distributed</b> random variables, or <b>i.i.d</b>.). Although there have been efforts to understand the intrinsic stochastic nature of gene expres-sion,14,15 we currently do not have predictive quantitative models of gene expression. Therefore, it is not clear what the", "dateLastCrawled": "2021-09-08T19:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to <b>determine if a stochastic process is IID from</b> a set of ... - Quora", "url": "https://www.quora.com/How-do-you-determine-if-a-stochastic-process-is-IID-from-a-set-of-samples", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-do-you-<b>determine-if-a-stochastic-process-is-IID-from</b>-a-set...", "snippet": "Answer (1 of 2): At a descriptive-stats level, the sample statistic you wanna focus on is the autocovariance. The autocovariance of an <b>IID</b> process - a white noise process - is an impulse function, i.e. a function whose value is 1 at 0 and 0 everywhere else. Intuitively, if the autocovariance of y...", "dateLastCrawled": "2022-01-25T01:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Tychomancy: Inferring Probability from Causal Structure | Reviews ...", "url": "https://ndpr.nd.edu/reviews/tychomancy-inferring-probability-from-causal-structure/", "isFamilyFriendly": true, "displayUrl": "https://ndpr.nd.edu/reviews/tychomancy-inferring-probability-from-causal-structure", "snippet": "And Strevens hardly advances his case by claiming that, faced with drawings from a <b>box</b> containing red and <b>black</b> balls, we believe that BBBB is as probable as BBBR (p. 54). Add a few more Bs before the R and we <b>can</b> see that this is nonsense: we would think, for reasons that a simple Bayesian analysis makes clear, that a B is more likely than an R to follow a string of Bs, however physically symmetric the set up might appear (as I noted above, symmetry <b>can</b> be an equivocal guide).", "dateLastCrawled": "2021-12-11T23:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Learning to Optimize with Reinforcement Learning \u2013 The Berkeley ...", "url": "https://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl/", "isFamilyFriendly": true, "displayUrl": "https://bair.berkeley.edu/blog/2017/09/12/learning-to-optimize-with-rl", "snippet": "(Hochreiter et al., 2001) views an algorithm that trains a base-model as a <b>black</b> <b>box</b> function that maps a sequence of training examples to a sequence of predictions and models it as a recurrent neural net. Meta-training then simply reduces to training the recurrent net. Because the base-model is encoded in the recurrent net\u2019s memory state, its capacity is constrained by the memory size. A related area is hyperparameter optimization, which aims for a weaker goal and searches over base ...", "dateLastCrawled": "2022-02-03T06:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "DISCREPANCY RISK MODEL SELECTION TEST THEORY FOR COMPARING POSSIBLY ...", "url": "https://labs.utdallas.edu/app/uploads/sites/71/2020/08/Golden2003_Article_DiscrepancyRiskModelSelectionT.pdf", "isFamilyFriendly": true, "displayUrl": "https://labs.utdallas.edu/app/uploads/sites/71/2020/08/Golden2003_Article_Discrepancy...", "snippet": "an independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) assumption. Historically, both Linhart (1988; also see Efron, 1984) and Vuong (1989) showed how the null hypothesis that two strictly nonnested models (i.e., two models which have no probability distribution in common) provide equally effective descriptions of the DGP could be tested. Prob- lems in applying this methodology arose however when the models were not strictly nonnested (see Shimodaira, 1997). Vuong addressed this problem using a ...", "dateLastCrawled": "2021-09-08T13:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Using Conditional Extreme Value Theory to</b> Estimate Value-at-Risk for ...", "url": "https://www.scirp.org/journal/PaperInformation.aspx?PaperID=80121", "isFamilyFriendly": true, "displayUrl": "https://www.scirp.org/journal/PaperInformation.aspx?PaperID=80121", "snippet": "EVT provides a robust framework for modeling the tail distributions and it does for the maxima of <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) random variables what the central limit theorem (CLT) does for modeling the summation of random variables and both theories give the asymptotically limiting distributions as the sample increases. In extreme value theory, there are two statistical approaches for analyzing extreme values: the block maxima (BM) method and peaks-over-threshold (POT ...", "dateLastCrawled": "2022-01-29T23:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>24 Information Theoretic Ranking Criteria Several</b> approaches to the ...", "url": "https://www.coursehero.com/file/p4dp3p7/24-Information-Theoretic-Ranking-Criteria-Several-approaches-to-the-variable/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/p4dp3p7/<b>24-Information-Theoretic-Ranking-Criteria</b>...", "snippet": "(a) A two class problem with <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) variables. Each class has a Gaussian distribution with no covariance. (b) The same example after a 45 degree rotation showing that a combination of the two variables yields a separation improvement by a factor \u221a 2. <b>I.i.d</b>. variables are not truly redundant.", "dateLastCrawled": "2022-01-19T17:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Opening the <b>black</b> <b>box</b>: an open\u2010source release of <b>Maxent</b> - Phillips ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.03049", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.03049", "snippet": "An IPP with intensity l is defined as an independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) sample from p l, whose size (number of points) is a Poisson random variable with mean Warton and Shepherd suggested modeling the occurrence records for a species as arising from an IPP whose intensity l(z) is a log-linear function of a vector of real-valued features x(z): (2) The coefficient \u03b1 is essentially a normalizing constant, giving no information about the species\u2019 distribution \u2013 its maximum ...", "dateLastCrawled": "2021-12-19T18:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Structural Time Series", "url": "https://structural-time-series.fastforwardlabs.com/", "isFamilyFriendly": true, "displayUrl": "https://structural-time-series.fastforwardlabs.com", "snippet": "Time series data violates the assumption of independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) data that we often use implicitly in supervised learning. For example, if we include both June and August in a fictitious training set, but withhold July for testing, a good estimate of the model\u2019s true performance is improbable, since the time series in July is likely to interpolate between June and August. Essentially, by cutting out chunks mid-way through the time series, we\u2019re testing a ...", "dateLastCrawled": "2022-01-31T21:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "An <b>Empirical Evaluation in GARCH Volatility Modeling: Evidence from</b> the ...", "url": "https://www.scirp.org/journal/PaperInformation.aspx?PaperID=76274", "isFamilyFriendly": true, "displayUrl": "https://www.scirp.org/journal/PaperInformation.aspx?PaperID=76274", "snippet": "where z t is an independent <b>identically</b> <b>distributed</b> (<b>i.i.d</b>.) process with mean zero and variance 1. \u03c3 t ... The EGARCH model has many advantages when <b>compared</b> to the GARCH (p, q) model. \u30fb The first is the logarithmic form which does not allow the positive constraint among parameters. \u30fb Another advantage of EGARCH model is that it incorporates asymmetries in the change of volatility of returns. \u30fb Parameters \u03b1 and \u03b3 define two important asymmetries in the conditional variance. If \u03b3 1 ...", "dateLastCrawled": "2022-02-01T20:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Is linear regression valid when the outcome (dependant variable) not ...", "url": "https://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome_dependant_variable_not_normally_distributed", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome...", "snippet": "The usual statement is that the errors are <b>i.i.d</b>. (i.e., <b>independently</b> <b>and identically</b> <b>distributed</b>) as Normal with a mean of 0 and some variance. Independence and homoscedasticity are more ...", "dateLastCrawled": "2022-02-03T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 7, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Central limit theorem</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Central_limit_theorem", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Central_limit_theorem</b>", "snippet": "Classical CLT. Let {, \u2026,} be a random sample of size \u2014 that is, a sequence of independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) random variables drawn from a distribution of expected value given by and finite variance given by . Suppose we are interested in the sample average \u00af + + of these random variables. By the law of large numbers, the sample averages converge almost surely (and therefore also converge in probability) to the expected value as \u2192. The classical <b>central limit theorem</b> ...", "dateLastCrawled": "2022-02-03T06:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "DeepSigns: An End-to-End Watermarking Framework for Protecting the ...", "url": "https://www.microsoft.com/en-us/research/uploads/prod/2018/11/2019ASPLOS_Final_DeepSigns.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.microsoft.com</b>/en-us/research/uploads/prod/2018/11/2019ASPLOS_Final_Deep...", "snippet": "both white-<b>box</b> and <b>black</b>-<b>box</b> security models. Watermark Embedding. DeepSigns takes the DNN ar-chitecture and the owner-speci\ufb01c watermark signature as its input. The WM signature is a set of arbitrary binary strings that should be generated such that each bit is <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.). DeepSigns, then, outputs a", "dateLastCrawled": "2022-01-30T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Pt Each of 3 balls is <b>independently</b> painted red, <b>black</b> or gold, and ...", "url": "https://www.coursehero.com/file/38637631/Final-2pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/38637631/Final-2pdf", "snippet": ", X n be n <b>independently</b> <b>and identically</b> <b>distributed</b> random variables with mean \u03bc and variance \u03c3 2. While we have learned in class that by the Central Limit Theorem (CLT), the average of X 1 to X n approximately follows a normal distribution when n is large. It is known by the CLT that the sum, T = n X i =1 X i also approximately follows a normal distribution with mean n\u03bc, and variance n\u03c3 2. Now let X denote the number of tickets a person buys at the premiere (i.e., the first showing) of ...", "dateLastCrawled": "2021-12-13T13:24:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What is <b>Learning</b>? <b>Machine Learning: Introduction and Unsupervised Learning</b>", "url": "http://pages.cs.wisc.edu/~bgibson/cs540/handouts/learning_intro.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~bgibson/cs540/handouts/<b>learning</b>_intro.pdf", "snippet": "<b>learning</b> process \u2022x i = (x i1, . . . , x iD) \u2022Assume these instances are sampled <b>independently</b> from an unknown (population) distribution, P(x) \u2022We denote this by x i \u223c P(x), where <b>i.i.d</b>. stands for independent <b>and identically</b> <b>distributed</b> <b>i.i.d</b>. Training Sample \u2022A training sample is the \u201cexperience\u201d given to a <b>learning</b> algorithm", "dateLastCrawled": "2021-08-25T13:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "2 - The Process of <b>Learning</b>.pdf - CMPSC 448 <b>Machine</b> <b>Learning</b> Lecture 2 ...", "url": "https://www.coursehero.com/file/113918059/2-The-Process-of-Learningpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/113918059/2-The-Process-of-<b>Learning</b>pdf", "snippet": "<b>I.I.D</b> assumption Training/test data is independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>) if: All objects come from the same distribution (<b>identically</b> <b>distributed</b>). The object are sampled <b>independently</b> (order doesn\u2019t matter). We do NOT need to know the underlying distribution as long as the samples are sampled <b>i.i.d</b>. Examples in terms of cards: Pick a card, put it back in the deck, re-shuffle, repeat. Pick a card, put it back in the deck, repeat.", "dateLastCrawled": "2021-12-30T01:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "What is <b>Learning</b>? <b>Machine</b> <b>Learning</b>: Introduction and Unsupervised <b>Learning</b>", "url": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_learning-intro.pdf", "isFamilyFriendly": true, "displayUrl": "https://pages.cs.wisc.edu/~dyer/cs540/notes/08_<b>learning</b>-intro.pdf", "snippet": "the inputto the <b>learning</b> process \u2022x i=(x i1, . . . , x iD) \u2022Assume these instances are all sampled independentlyfrom the same, unknown (population) distribution, P(x) \u2022We denote this by x i\u223cP(x), where <b>i.i.d</b>. stands for independent <b>and identically</b> <b>distributed</b> \u2022Example: Repeated throws of dice <b>i.i.d</b>. 13", "dateLastCrawled": "2022-02-03T16:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "11._Intro_to_<b>Machine</b>_<b>Learning</b>.pdf - CMPSC 442 Artificial Intelligence ...", "url": "https://www.coursehero.com/file/121916721/11-Intro-to-Machine-Learningpdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/121916721/11-Intro-to-<b>Machine</b>-<b>Learning</b>pdf", "snippet": "<b>I.I.D</b> assumption Training/test data is independent <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>) if: All objects come from the same distribution (<b>identically</b> <b>distributed</b>). The object are sampled <b>independently</b> (order doesn\u2019t matter). We do NOT need to know the underlying distribution as long as the samples are sampled <b>i.i.d</b>. Examples in terms of cards: Pick a card, put it back in the deck, re-shuffle, repeat. Pick a card, put it back in the deck, repeat. Pick a card, don\u2019t put it back, re-shuffle ...", "dateLastCrawled": "2022-01-15T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Background on <b>machine</b> <b>learning</b> and <b>learning</b> theory", "url": "https://matthewhirn.files.wordpress.com/2020/02/cmse890_spring2020_chapter1.pdf", "isFamilyFriendly": true, "displayUrl": "https://matthewhirn.files.wordpress.com/2020/02/cmse890_spring2020_chapter1.pdf", "snippet": "Often we will assume that the #i are <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) according to the normal distribution with mean zero and variance s2, i.e. #i \u21e0N(0,s2). In this case, if X is the random variable that takes values in Rd according to the probability distribution PX, and Y is the random variable that takes values in R ...", "dateLastCrawled": "2021-08-12T13:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning</b> from Examples as an <b>Inverse Problem</b> - Journal of <b>Machine</b> ...", "url": "https://jmlr.csail.mit.edu/papers/volume6/devito05a/devito05a.pdf", "isFamilyFriendly": true, "displayUrl": "https://jmlr.csail.mit.edu/papers/volume6/devito05a/devito05a.pdf", "snippet": "<b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.) according to \u03c1. Given the sample z, the aim of <b>learning</b> theory is to \ufb01nd a function fz: X \u2192R such that fz(x) is a good estimate of the output y when a new input x is given. The function fz is called estimator and the map providing fz, for any training set z, is called <b>learning</b> algorithm.", "dateLastCrawled": "2021-09-19T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "8. Recurrent Neural Networks \u2014 Dive into <b>Deep Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_recurrent-neural-networks/index.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_recurrent-neural-networks/index.html", "snippet": "Most importantly, so far we tacitly assumed that our data are all drawn from some distribution, and all the examples are <b>independently</b> <b>and identically</b> <b>distributed</b> (<b>i.i.d</b>.). Unfortunately, this is not true for most data. For instance, the words in this paragraph are written in sequence, and it would be quite difficult to decipher its meaning if they were permuted randomly. Likewise, image frames in a video, the audio signal in a conversation, and the browsing behavior on a website, all follow ...", "dateLastCrawled": "2022-02-03T01:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Assignment 1</b> - Department of Computer Science and Electrical Engineering", "url": "https://www.csee.umbc.edu/courses/undergraduate/473/f19/content/materials/a1.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.csee.umbc.edu/courses/undergraduate/473/f19/content/materials/a1.pdf", "snippet": "i is an <b>i.i.d</b>. sample, where <b>i.i.d</b>. means \u201c<b>independently</b> <b>and identically</b> <b>distributed</b>. ... Using a programming <b>analogy</b>, we can say that word types are like classes while word tokens are like instances of that class. For example, in the following sentence there are six types and eight tokens: the gray cat chased the tabby cat . Notice that this computation includes punctuation. (b)In the training \ufb01le, how many different word types and tokens are there? Do not perform any processing that ...", "dateLastCrawled": "2022-02-02T03:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>The Essence of RNNs</b>. The intuition behind the building\u2026 | by Taha ...", "url": "https://towardsdatascience.com/the-essence-of-rnns-44dfb4107a47", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>the-essence-of-rnns</b>-44dfb4107a47", "snippet": "When considering CNNs and MLPs, we always assumed that the data was sampled from and <b>independently</b> <b>and identically</b> <b>distributed</b> data(<b>i.i.d</b>), but with sequential data, that is not the case. Contrary to (<b>i.i.d</b>) data, the previous input points affect the outcome of the next output. Since RNNs are most widely used in natural language processing(NLP), an <b>analogy</b> from that field would suffice to make the point clear. Imagine textual data, all the words in a sequence affect the outcome of the ...", "dateLastCrawled": "2022-01-23T05:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Learning from positive</b> and unlabeled data: a survey - <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "<b>Learning from positive</b> and unlabeled data or PU <b>learning</b> is the setting where a learner only has access to positive examples and unlabeled data. The assumption is that the unlabeled data can contain both positive and negative examples. This setting has attracted increasing interest within the <b>machine</b> <b>learning</b> literature as this type of data naturally arises in applications such as medical diagnosis and knowledge base completion. This article provides a survey of the current state of the art ...", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(independently and identically distributed (i.i.d))  is like +(black box)", "+(independently and identically distributed (i.i.d)) is similar to +(black box)", "+(independently and identically distributed (i.i.d)) can be thought of as +(black box)", "+(independently and identically distributed (i.i.d)) can be compared to +(black box)", "machine learning +(independently and identically distributed (i.i.d) AND analogy)", "machine learning +(\"independently and identically distributed (i.i.d) is like\")", "machine learning +(\"independently and identically distributed (i.i.d) is similar\")", "machine learning +(\"just as independently and identically distributed (i.i.d)\")", "machine learning +(\"independently and identically distributed (i.i.d) can be thought of as\")", "machine learning +(\"independently and identically distributed (i.i.d) can be compared to\")"]}