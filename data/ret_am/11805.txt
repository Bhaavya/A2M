{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What Is <b>Bias</b> In <b>Computer</b> - SeniorCare2Share", "url": "https://www.seniorcare2share.com/what-is-bias-in-computer/", "isFamilyFriendly": true, "displayUrl": "https://www.seniorcare2share.com/what-is-<b>bias</b>-in-<b>computer</b>", "snippet": "<b>Bias</b> is just <b>like</b> an intercept added in a linear equation. It is an additional parameter in the Neural Network which is used to adjust the output along with the weighted sum of the inputs to the neuron. Moreover, <b>bias</b> value allows you to shift the activation <b>function</b> to either right or left.", "dateLastCrawled": "2022-01-21T09:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Ethics and <b>Bias</b> in <b>Machine</b> <b>Learning</b>: A Technical Study of What Makes Us ...", "url": "https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=1042&context=jj_etds", "isFamilyFriendly": true, "displayUrl": "https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=1042&amp;context=jj_etds", "snippet": "\u201c<b>bias</b>\u201d has many meanings in a <b>machine</b> <b>learning</b> context, so it is necessary to define this term explicitly. In fact, <b>bias</b> is a required <b>function</b> in predictive algorithms. As Dietterich and Kong pointed out over 20 years ago, <b>bias</b> is <b>implicit</b> in <b>machine</b> algorithms, a required specification to determining desired behavior in prediction making ...", "dateLastCrawled": "2022-01-27T14:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Addressing Fairness, <b>Bias</b>, and Appropriate Use of Artificial ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8107824/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8107824", "snippet": "While the <b>bias</b> found in other application domains of <b>machine</b> <b>learning</b> (finance, employment, law enforcement, etc.) may often be due to sampling <b>bias</b> or <b>implicit</b> cultural <b>bias</b>, the domain of health also contains true systematic <b>bias</b> inherent in biological processes which may not be possible to mitigate or \u201crepair.\u201d In the domain of health, there are true genetic differences across different races and ethnic groups which affect disease prevalence, and these differences cannot (and should ...", "dateLastCrawled": "2021-12-05T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "[2112.12713] Modeling <b>Implicit</b> <b>Bias</b> with Fuzzy Cognitive Maps", "url": "https://arxiv.org/abs/2112.12713", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2112.12713", "snippet": "<b>Computer</b> Science &gt; <b>Machine</b> <b>Learning</b>. arXiv:2112.12713 (cs) [Submitted on 23 Dec 2021] Title: Modeling <b>Implicit</b> <b>Bias</b> with Fuzzy Cognitive Maps. Authors: Gonzalo N\u00e1poles, Isel Grau, Leonardo Concepci\u00f3n, Lisa Koutsoviti Koumeri, Jo\u00e3o Paulo Papa. Download PDF Abstract: This paper presents a Fuzzy Cognitive Map model to quantify <b>implicit</b> <b>bias</b> in structured datasets where features can be numeric or discrete. In our proposal, problem features are mapped to neural concepts that are initially ...", "dateLastCrawled": "2021-12-24T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Modeling <b>Implicit</b> <b>Bias</b> with Fuzzy Cognitive Maps - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S092523122200090X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S092523122200090X", "snippet": "Fig. 2a provides an overview of the correlation patterns in an attempt to visualize all possible pathways through which <b>implicit</b> <b>bias</b> related to the sensitive features can be propagated within the system.In this chord chart, we highlighted the correlation between each unprotected feature and the protected ones. However, our FCM model takes into account all interactions when quantifying <b>implicit</b> <b>bias</b>.", "dateLastCrawled": "2022-01-25T05:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Assessing Implicit Knowledge in BIM Models with Machine Learning</b>", "url": "https://www.researchgate.net/publication/302488577_Assessing_Implicit_Knowledge_in_BIM_Models_with_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/302488577_<b>Assessing_Implicit_Knowledge_in_BIM</b>...", "snippet": "AI&#39;s many techniques, but <b>machine</b> <b>learning</b> is a subset of this more extensive list letting the algorithms learn from the data.At the same time, deep <b>learning</b> is a <b>computer</b> <b>learning</b> subset that ...", "dateLastCrawled": "2022-01-18T17:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Comparison of <b>Implicit</b> vs. Explicit Regime Identification in <b>Machine</b> ...", "url": "https://www.academia.edu/59128750/Comparison_of_Implicit_vs_Explicit_Regime_Identification_in_Machine_Learning_Methods_for_Solar_Irradiance_Prediction", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/59128750/Comparison_of_<b>Implicit</b>_vs_Explicit_Regime...", "snippet": "energies Article Comparison of <b>Implicit</b> vs. Explicit Regime Identification in <b>Machine</b> <b>Learning</b> Methods for Solar Irradiance Prediction Tyler McCandless * , Susan Dettling and Sue Ellen Haupt National Center for Atmospheric Research (NCAR), Boulder, CO 80305, USA; dettling@ucar.edu (S.D.); haupt@ucar.edu (S.E.H.) * Correspondence: mccandle@ucar.edu; Tel.: +1-303-497-8448 Received: 15 November 2019; Accepted: 1 February 2020; Published: 5 February 2020 Abstract: This work compares the solar ...", "dateLastCrawled": "2021-11-22T03:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning 99+ Most Important MCQ</b> - JOB SAARNEE", "url": "https://www.jobsaarnee.com/2020/09/machine-learning-100-most-important-mcq.html", "isFamilyFriendly": true, "displayUrl": "https://www.jobsaarnee.com/2020/09/<b>machine</b>-<b>learning</b>-100-most-important-mcq.html", "snippet": "<b>Machine</b> <b>learning</b> is the autonomous acquisition of knowledge through the use of <b>computer</b> programs. <b>Machine</b> <b>learning</b> is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. <b>Machine</b> <b>learning</b> focuses on the development of <b>computer</b> programs that can access data and use it learn for themselves. The process of <b>learning</b> begins with observations or data, such as examples, direct ...", "dateLastCrawled": "2022-02-02T11:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>machine</b> <b>learning</b> approach to the potential-field method for <b>implicit</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0098300416304848", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0098300416304848", "snippet": "This work presented a new <b>machine</b> <b>learning</b> method for <b>implicit</b> modeling of geological bodies. Training the model by maximizing the log-likelihood avoids the laborious and subjective variogram modeling, but does not guarantee a unique solution in practical terms. This method is capable of working even without any orientation measurements, and it can model the whole region of interest at once, eliminating the need for a separate model for each surface. We believe that the current practices in ...", "dateLastCrawled": "2021-12-24T14:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Comparison of <b>Implicit</b> vs. Explicit Regime Identification in <b>Machine</b> ...", "url": "https://www.academia.edu/59128750/Comparison_of_Implicit_vs_Explicit_Regime_Identification_in_Machine_Learning_Methods_for_Solar_Irradiance_Prediction", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/59128750/Comparison_of_<b>Implicit</b>_vs_Explicit_Regime...", "snippet": "<b>Machine</b> <b>learning</b> can bridge the gap between persistence and physical-based NWP models by <b>learning</b> the relationships among predictor variables and solar irradiance; however, there are many different <b>machine</b> <b>learning</b> algorithms that can be used and each has its strengths and weaknesses depending on the quality of the training data. The most common <b>machine</b> <b>learning</b> algorithms for solar irradiance or power prediction are support vector machines (SVM)/support vector regression (SVR) and ...", "dateLastCrawled": "2021-11-22T03:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Addressing Fairness, <b>Bias</b>, and Appropriate Use of Artificial ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8107824/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8107824", "snippet": "While the <b>bias</b> found in other application domains of <b>machine</b> <b>learning</b> (finance, employment, law enforcement, etc.) may often be due to sampling <b>bias</b> or <b>implicit</b> cultural <b>bias</b>, the domain of health also contains true systematic <b>bias</b> inherent in biological processes which may not be possible to mitigate or \u201crepair.\u201d In the domain of health, there are true genetic differences across different races and ethnic groups which affect disease prevalence, and these differences cannot (and should ...", "dateLastCrawled": "2021-12-05T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Explicitizing an <b>Implicit</b> <b>Bias</b> of the Frequency Principle in Two-layer ...", "url": "https://ui.adsabs.harvard.edu/abs/2019arXiv190510264Z/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2019arXiv190510264Z/abstract", "snippet": "It remains a puzzle that why deep neural networks (DNNs), with more parameters than samples, often generalize well. An attempt of understanding this puzzle is to discover <b>implicit</b> biases underlying the training process of DNNs, such as the Frequency Principle (F-Principle), i.e., DNNs often fit target functions from low to high frequencies. Inspired by the F-Principle, we propose an effective model of linear F-Principle (LFP) dynamics which accurately predicts the <b>learning</b> results of two ...", "dateLastCrawled": "2021-08-22T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bias</b> Amplification &amp; Algorithmic Determinism | HyperLearning AI", "url": "https://knowledgebase.hyperlearning.ai/en/articles/bias-amplification-and-algorithmic-determinism", "isFamilyFriendly": true, "displayUrl": "https://knowledgebase.hyper<b>learning</b>.ai/en/articles/<b>bias</b>-amplification-and-algorithmic...", "snippet": "Recall that both supervised and unsupervised <b>machine</b> <b>learning</b> make an <b>implicit</b> assumption that trends and patterns identified in historic data in order to learn a mathematical <b>function</b> can be used to make inferences and predictions about the future using that same mathematical <b>function</b>. Personalised recommendations from services like Netflix and Amazon, and personal assistants and virtual agents like Alexa and Siri, all work by providing services using this same fundamental principle of ...", "dateLastCrawled": "2021-12-07T05:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Eliminating Bias in Facial Recognition</b> | by Rucha Apte | The Startup ...", "url": "https://medium.com/swlh/eliminating-bias-in-facial-recognition-8ad3bb9786a5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>eliminating-bias-in-facial-recognition</b>-8ad3bb9786a5", "snippet": "<b>Implicit</b> <b>bias</b> seeps in several <b>machine</b> <b>learning</b> algorithms and is amplified while predicting outputs within predetermined patterns which lead to discriminatory outcomes. Large scale face ...", "dateLastCrawled": "2021-12-18T21:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Modeling <b>Implicit</b> <b>Bias</b> with Fuzzy Cognitive Maps - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S092523122200090X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S092523122200090X", "snippet": "Fig. 2a provides an overview of the correlation patterns in an attempt to visualize all possible pathways through which <b>implicit</b> <b>bias</b> related to the sensitive features can be propagated within the system.In this chord chart, we highlighted the correlation between each unprotected feature and the protected ones. However, our FCM model takes into account all interactions when quantifying <b>implicit</b> <b>bias</b>.", "dateLastCrawled": "2022-01-25T05:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Underfitting and Overfitting in <b>Machine</b> <b>Learning</b> | Baeldung on <b>Computer</b> ...", "url": "https://www.baeldung.com/cs/ml-underfitting-overfitting", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/cs/ml-underfitting-overfitting", "snippet": "Even without using a test set, we can decide if the model is performing poorly on the training set or not. If the model accuracy is insufficient on the training data, it has high <b>bias</b> and hence, underfitting. A challenge in <b>machine</b> <b>learning</b> is to decide the model complexity as we don\u2019t know the underlying optimal complexity of the dataset ...", "dateLastCrawled": "2022-01-28T05:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Assessing Implicit Knowledge in BIM Models with Machine Learning</b>", "url": "https://www.researchgate.net/publication/302488577_Assessing_Implicit_Knowledge_in_BIM_Models_with_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/302488577_<b>Assessing_Implicit_Knowledge_in_BIM</b>...", "snippet": "AI&#39;s many techniques, but <b>machine</b> <b>learning</b> is a subset of this more extensive list letting the algorithms learn from the data.At the same time, deep <b>learning</b> is a <b>computer</b> <b>learning</b> subset that ...", "dateLastCrawled": "2022-01-18T17:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the meaning of inductive <b>bias</b> in <b>machine</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-the-meaning-of-inductive-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-meaning-of-inductive-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "Answer (1 of 2): Inductive <b>bias</b> is nothing but a set of assumptions in which a model learns by itself through the observation of the relationship between data points in order to make itself a generalized model so that the accuracy of prediction will be increased when exposed to a new test data in...", "dateLastCrawled": "2022-01-22T08:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Addressing Fairness, <b>Bias</b>, and Appropriate Use of Artificial ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8107824/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8107824", "snippet": "While the <b>bias</b> found in other application domains of <b>machine</b> <b>learning</b> (finance, employment, law enforcement, etc.) may often be due to sampling <b>bias</b> or <b>implicit</b> cultural <b>bias</b>, the domain of health also contains true systematic <b>bias</b> inherent in biological processes which may not be possible to mitigate or \u201crepair.\u201d In the domain of health, there are true genetic differences across different races and ethnic groups which affect disease prevalence, and these differences cannot (and should ...", "dateLastCrawled": "2021-12-05T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Can</b> Machines <b>Think</b>?. Disclaimer: This post is part of a\u2026 | by Rounak ...", "url": "https://medium.com/swlh/can-machines-think-9fc81e61ac6", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>can</b>-<b>machines</b>-<b>think</b>-9fc81e61ac6", "snippet": "I <b>think</b> Turing\u2019s refute to the mathematical objection is sufficient. Machines not being able to answer Q <b>can</b> simply be viewed as a <b>machine</b>\u2019s <b>implicit</b> <b>bias</b>; a tendency that humans also suffer from.", "dateLastCrawled": "2022-01-26T23:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Engineering Equity: How AI Can</b> Help <b>Reduce the Harm of Implicit Bias</b> ...", "url": "https://link.springer.com/article/10.1007/s13347-020-00406-7", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-020-00406-7", "snippet": "The extensions of AI include <b>machine</b> <b>learning</b>, smart robotics, <b>computer</b> vision, virtual agents, etc. Chamorro-Premuzic , for instance, argues that AI systems <b>can</b> be programmed to ignore information that is irrelevant to certain decisions (e.g., a job applicant\u2019s gender in hiring a <b>computer</b> programmer). This allows AI to analyze only information that is relevant to the job requirements (e.g., programming skills) in order to reach an unbiased decision. However, AI systems have been found to ...", "dateLastCrawled": "2022-01-17T00:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Algorithmic <b>Bias</b> in <b>Machine</b> <b>Learning</b> - Duke Forge", "url": "https://forge.duke.edu/sites/default/files/atoms/files/Algorithmic%20Bias%20in%20Machine%20Learning_0.pdf", "isFamilyFriendly": true, "displayUrl": "https://forge.duke.edu/sites/default/files/atoms/files/Algorithmic <b>Bias</b> in <b>Machine</b>...", "snippet": "seem a <b>computer</b> program would not exhibit <b>bias</b>, it is increasingly clear that algorithms often incorporate the conscious and unconscious biases of their creators or the data on which they are trained. This introduces the possibility that by using them, algorithms will cause clinicians to care for subpopulations of patients inequitably. With funding from the Moore Foundation, Duke Forge hosted a conference of experts to discuss algorithmic <b>bias</b> and its implications in healthcare and ...", "dateLastCrawled": "2022-01-19T02:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The Social Impact of Brain <b>Machine</b> Interfaces: <b>Bias</b> and (Big) Neural Data", "url": "http://www.theneuroethicsblog.com/2020/08/the-social-impact-of-brain-machine.html", "isFamilyFriendly": true, "displayUrl": "www.theneuroethicsblog.com/2020/08/the-social-impact-of-brain-<b>machine</b>.html", "snippet": "Laura Specker Sullivan (LSS): The term <b>bias</b> <b>can</b> pick out so many different things. I find it helpful to start thinking about a concept by identifying all the different boxes it <b>can</b> fit into. In my mind, <b>bias</b> <b>can</b> be explicit or <b>implicit</b>, individual or structural, natural or unnatural, related to content or processes, cognitive or affective, blameworthy or not, and immutable or changeable. These categories interrelate \u2013 for example, biases that are natural are often <b>thought</b> to be immutable ...", "dateLastCrawled": "2022-01-26T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Spectral <b>Bias</b> in Practice: The Role of <b>Function</b> Frequency in ...", "url": "https://deepai.org/publication/spectral-bias-in-practice-the-role-of-function-frequency-in-generalization", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/spectral-<b>bias</b>-in-practice-the-role-of-<b>function</b>...", "snippet": "Several forms of explicit and <b>implicit</b> regularization, including weight decay, increasing the dataset size, and applying Mixup (Zhang et al., 2018) data augmentation, increase spectral <b>bias</b> and produce a smoother learned <b>function</b>. Our experiments suggest that an ideal <b>function</b> should include high enough frequencies to fit the data but avoid unnecessary high frequencies that <b>can</b> harm generalization.", "dateLastCrawled": "2022-01-14T08:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Reconciling modern <b>machine</b>-<b>learning</b> practice and the classical <b>bias</b> ...", "url": "https://www.cs.columbia.edu/~djhsu/papers/biasvariance-pnas.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.columbia.edu/~djhsu/papers/<b>bias</b>variance-pnas.pdf", "snippet": "observed behavior of methods used in modern <b>machine</b>-<b>learning</b> practice. The <b>bias</b>\u2013variance trade-off implies that a model should balance under\ufb01tting and over\ufb01tting: Rich enough to express underlying structure in data and simple enough to avoid \ufb01t-ting spurious patterns. However, in modern practice, very rich models such as neural networks are trained to exactly \ufb01t (i.e., interpolate) the data. Classically, such models would be consid-ered over\ufb01tted, and yet they often obtain high ...", "dateLastCrawled": "2022-01-18T04:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "inductive <b>bias</b> in <b>machine</b> <b>learning</b> geeksforgeeks", "url": "http://pahurling.com/site/9zrmu5t/inductive-bias-in-machine-learning-geeksforgeeks", "isFamilyFriendly": true, "displayUrl": "pahurling.com/site/9zrmu5t/inductive-<b>bias</b>-in-<b>machine</b>-<b>learning</b>-geeksforgeeks", "snippet": "Often called the target <b>function</b> in <b>machine</b> <b>learning</b>, and abductive inductive <b>bias</b> in <b>machine</b> <b>learning</b> geeksforgeeks is. Mental process of thinking rationally, to find valid conclusions <b>function</b> is often called target! Models have a huge influence on the GeeksforGeeks main page and help Geeks! And AI have very di erent goals is defined as a <b>machine</b> <b>learning</b> method that helps you to some. Overfitting is a software that <b>can</b> emulate the human mind field has undergone significant developments in ...", "dateLastCrawled": "2022-01-29T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Assessing Implicit Knowledge in BIM Models with Machine Learning</b>", "url": "https://www.researchgate.net/publication/302488577_Assessing_Implicit_Knowledge_in_BIM_Models_with_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/302488577_<b>Assessing_Implicit_Knowledge_in_BIM</b>...", "snippet": "AI&#39;s many techniques, but <b>machine</b> <b>learning</b> is a subset of this more extensive list letting the algorithms learn from the data.At the same time, deep <b>learning</b> is a <b>computer</b> <b>learning</b> subset that ...", "dateLastCrawled": "2022-01-18T17:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the meaning of inductive <b>bias</b> in <b>machine</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-the-meaning-of-inductive-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-meaning-of-inductive-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "Answer (1 of 2): Inductive <b>bias</b> is nothing but a set of assumptions in which a model learns by itself through the observation of the relationship between data points in order to make itself a generalized model so that the accuracy of prediction will be increased when exposed to a new test data in...", "dateLastCrawled": "2022-01-22T08:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans <b>can</b> be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans <b>can</b> introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we <b>can</b> detect <b>bias</b> in <b>machine learning</b> models and how it <b>can</b> be eliminated. Types of <b>bias</b> . <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools from many of the leaders in <b>machine learning</b> development. Detecting <b>bias</b> starts with the data set. A data set might not represent the problem space ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Implicit Bias</b> | SWD at NIH", "url": "https://diversity.nih.gov/sociocultural-factors/implicit-bias", "isFamilyFriendly": true, "displayUrl": "https://diversity.nih.gov/sociocultural-factors/<b>implicit-bias</b>", "snippet": "<b>Bias</b> consists of attitudes, behaviors, and actions that are prejudiced in favor of or against one person or group <b>compared</b> to another. <b>Implicit Bias</b>: Training Module Now Open!! Check Out The Training Module. <b>Implicit Bias</b> Presentation. What is <b>implicit bias</b>? <b>Implicit bias</b> is a form of <b>bias</b> that occurs automatically and unintentionally, that nevertheless affects judgments, decisions, and behaviors. Research has shown <b>implicit bias</b> <b>can</b> pose a barrier to recruiting and retaining a diverse ...", "dateLastCrawled": "2022-02-03T05:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Comparison of <b>Implicit</b> vs. Explicit Regime Identification in <b>Machine</b> ...", "url": "https://www.academia.edu/59128750/Comparison_of_Implicit_vs_Explicit_Regime_Identification_in_Machine_Learning_Methods_for_Solar_Irradiance_Prediction", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/59128750/Comparison_of_<b>Implicit</b>_vs_Explicit_Regime...", "snippet": "<b>Machine</b> <b>learning</b> <b>can</b> bridge the gap between persistence and physical-based NWP models by <b>learning</b> the relationships among predictor variables and solar irradiance; however, there are many different <b>machine</b> <b>learning</b> algorithms that <b>can</b> be used and each has its strengths and weaknesses depending on the quality of the training data. The most common <b>machine</b> <b>learning</b> algorithms for solar irradiance or power prediction are support vector machines (SVM)/support vector regression (SVR) and ...", "dateLastCrawled": "2021-11-22T03:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Addressing Fairness, <b>Bias</b>, and Appropriate Use of Artificial ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8107824/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8107824", "snippet": "While the <b>bias</b> found in other application domains of <b>machine</b> <b>learning</b> (finance, employment, law enforcement, etc.) may often be due to sampling <b>bias</b> or <b>implicit</b> cultural <b>bias</b>, the domain of health also contains true systematic <b>bias</b> inherent in biological processes which may not be possible to mitigate or \u201crepair.\u201d In the domain of health, there are true genetic differences across different races and ethnic groups which affect disease prevalence, and these differences cannot (and should ...", "dateLastCrawled": "2021-12-05T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>What is unconscious bias</b>? How does it affect you?", "url": "https://caseguard.com/articles/what-is-unconscious-bias/", "isFamilyFriendly": true, "displayUrl": "https://caseguard.com/articles/<b>what-is-unconscious-bias</b>", "snippet": "The first step to combating unconscious <b>bias</b> in <b>machine</b> <b>learning</b> is identify what <b>bias</b> in the data is being fed to <b>machine</b> <b>learning</b>. The algorithms that <b>machine</b> <b>learning</b> is predicated upon <b>can</b> only <b>function</b> based on the data being given. If a data set has inherently marginalized a certain demographic of people, that will obviously be made apparent through <b>machine</b> <b>learning</b> as well. Another angle is to analyze the processes designed to catch unconscious <b>bias</b> present in <b>machine</b> <b>learning</b> and ...", "dateLastCrawled": "2022-01-30T06:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Modeling <b>Implicit</b> <b>Bias</b> with Fuzzy Cognitive Maps - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S092523122200090X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S092523122200090X", "snippet": "Fig. 2a provides an overview of the correlation patterns in an attempt to visualize all possible pathways through which <b>implicit</b> <b>bias</b> related to the sensitive features <b>can</b> be propagated within the system.In this chord chart, we highlighted the correlation between each unprotected feature and the protected ones. However, our FCM model takes into account all interactions when quantifying <b>implicit</b> <b>bias</b>.", "dateLastCrawled": "2022-01-25T05:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Spectral <b>Bias</b> in Practice: The Role of <b>Function</b> Frequency in ...", "url": "https://deepai.org/publication/spectral-bias-in-practice-the-role-of-function-frequency-in-generalization", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/spectral-<b>bias</b>-in-practice-the-role-of-<b>function</b>...", "snippet": "Several forms of explicit and <b>implicit</b> regularization, including weight decay, increasing the dataset size, and applying Mixup (Zhang et al., 2018) data augmentation, increase spectral <b>bias</b> and produce a smoother learned <b>function</b>. Our experiments suggest that an ideal <b>function</b> should include high enough frequencies to fit the data but avoid unnecessary high frequencies that <b>can</b> harm generalization.", "dateLastCrawled": "2022-01-14T08:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine Learning 99+ Most Important MCQ</b> - JOB SAARNEE", "url": "https://www.jobsaarnee.com/2020/09/machine-learning-100-most-important-mcq.html", "isFamilyFriendly": true, "displayUrl": "https://www.jobsaarnee.com/2020/09/<b>machine</b>-<b>learning</b>-100-most-important-mcq.html", "snippet": "<b>Machine</b> <b>learning</b> is the autonomous acquisition of knowledge through the use of <b>computer</b> programs. <b>Machine</b> <b>learning</b> is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. <b>Machine</b> <b>learning</b> focuses on the development of <b>computer</b> programs that <b>can</b> access data and use it learn for themselves. The process of <b>learning</b> begins with observations or data, such as examples, direct ...", "dateLastCrawled": "2022-02-02T11:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[D] A Theoretical Comparison of Gradient and Newton Optimization ...", "url": "https://www.reddit.com/r/MachineLearning/comments/sb6p3v/d_a_theoretical_comparison_of_gradient_and_newton/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/sb6p3v/d_a_theoretical_comparison_of...", "snippet": "Thus, in any practical application of <b>function</b> minimization in the real world (e.g. engineering, <b>machine</b> <b>learning</b>), if finding the minimum of the <b>function</b> in a shorter amount of time is considered to be important - it is natural to believe that Gradient Based Methods might display advantages <b>compared</b> to Newton Based Methods in this regard. Although proofs are generally required for every statement in mathematics, it seems very intuitive to accept that the same <b>computer</b> would fundamentally ...", "dateLastCrawled": "2022-01-26T15:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/417004728/machine-learning-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/417004728/<b>machine-learning</b>-flash-cards", "snippet": "The direct relationship between weather and commute time. -&gt; <b>Machine</b> begins to understand concepts such as how rain <b>can</b> affect how people drive or how leaving the office at 5pm and 4pm <b>can</b> impact commute due to the difference in number of ppl on the road. You <b>can</b> ask the <b>machine</b> how long it&#39;ll take to drive home each day, and give it feedback on how accurate it is. Overtime, the <b>machine</b> will learn and adapt its model to improve the output.", "dateLastCrawled": "2022-01-05T00:27:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning</b> and <b>bias</b> \u2013 IBM Developer", "url": "https://developer.ibm.com/articles/machine-learning-and-bias/", "isFamilyFriendly": true, "displayUrl": "https://developer.ibm.com/articles/<b>machine-learning</b>-and-<b>bias</b>", "snippet": "<b>Bias</b> in humans can be unconscious (also called <b>implicit</b> <b>bias</b>), which indicates humans can introduce <b>bias</b> without even knowing they are doing so. Let\u2019s explore how we can detect <b>bias</b> in <b>machine learning</b> models and how it can be eliminated. Types of <b>bias</b>. <b>Bias</b> in <b>machine learning</b> data sets and models is such a problem that you\u2019ll find tools ...", "dateLastCrawled": "2022-02-02T20:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Implicit/Machine learning gender bias</b> | ReberLab", "url": "https://www.reberlab.psych.northwestern.edu/2018/10/11/implicitmachine-learning-gender-bias/", "isFamilyFriendly": true, "displayUrl": "https://www.reberlab.psych.northwestern.edu/.../10/11/<b>implicitmachine-learning-gender-bias</b>", "snippet": "First, I have found myself describing on a few recent occasions that it is reasonable to think of <b>implicit</b> <b>learning</b> (IL) as the brain\u2019s <b>machine</b> <b>learning</b> (ML) algorithm. ML is a super-hot topic in AI and data science research, so this might be a useful <b>analogy</b> to help people understand what we mean by studying IL. We characterize IL as the statistical extraction of patterns in the environment and the shaping of cognitive processing to maximize efficiency and effectiveness to these patterns ...", "dateLastCrawled": "2020-11-16T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "Often <b>machine</b> <b>learning</b> programs inherit social patterns reflected in their training data without any directed effort by programmers to include such biases. Computer scientists call this algorithmic <b>bias</b>. This paper explores the relationship between <b>machine</b> <b>bias</b> and human cognitive <b>bias</b>. In it, I argue similarities between algorithmic and cognitive biases indicate a disconcerting sense in which sources of <b>bias</b> emerge out of seemingly innocuous patterns of information processing. The emergent ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Harnessing data for unbiased <b>Learning</b> of Machines | by Vivek Gupta | Medium", "url": "https://gvivek.medium.com/harnessing-data-for-unbiased-learning-of-machines-dc614497a29c", "isFamilyFriendly": true, "displayUrl": "https://gvivek.medium.com/harnessing-data-for-un<b>bias</b>ed-<b>learning</b>-of-<b>machines</b>-dc614497a29c", "snippet": "In <b>Machine</b> <b>Learning</b>, the input data reflects stereotypes and biases of the broader society, then the output of the <b>learning</b> algorithm also captures these stereotypes. Here, we will discuss the gender stereotypes in word embedding. word-embedding encode semantic information, they also exhibit hidden biases inherent in the dataset they are trained on associations such as: father:doctor :: mother:nurse. man:computer programmer :: woman:homemaker. The prejudices and stereotypes in these ...", "dateLastCrawled": "2022-01-12T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning</b> | Gendered Innovations", "url": "http://genderedinnovations.stanford.edu/case-studies/machinelearning.html", "isFamilyFriendly": true, "displayUrl": "genderedinnovations.stanford.edu/case-studies/<b>machinelearning</b>.html", "snippet": "As <b>machine learning</b> becomes increasingly ubiquitous in everyday lives, such <b>bias</b>, if uncorrected, can lead to social inequities. Researchers need to understand how gender and ethnicity operate within the context of their algorithm in order to enhance or, at least, not reinforce social equalities. Here we suggest avenues for reducing <b>bias</b> in training data and algorithms in efforts to produce AI that enhances social equalities.", "dateLastCrawled": "2022-01-25T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Introduction to Natural Language Processing</b> (NLP) and <b>Bias</b> in AI | by ...", "url": "https://towardsdatascience.com/introduction-to-natural-language-processing-nlp-and-bias-in-ai-877d3f3ee680", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>introduction-to-natural-language-processing</b>-nlp-and...", "snippet": "In this post, I will introduce key concepts of NLP such as word embeddings, and we will see how an algorithm can become biased, and how we can remove that <b>bias</b>. Le t \u2019s get started! For hands-on video tutorials on <b>machine</b> <b>learning</b>, deep <b>learning</b>, and artificial intelligence, checkout my YouTube channel.", "dateLastCrawled": "2022-01-20T19:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word ...", "url": "https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf", "snippet": "signi\ufb01cant risk and challenge for <b>machine</b> <b>learning</b> and its applications. The analogies generated from these embeddings spell out the <b>bias</b> <b>implicit</b> in the data on which they were trained. Hence, word embeddings may serve as a means to extract <b>implicit</b> gender associations from a large text corpus", "dateLastCrawled": "2022-02-02T05:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fairness Metrics - Data Analytics - Data Science, <b>Machine</b> <b>Learning</b>, AI", "url": "https://vitalflux.com/fairness-metrics-ml-model-sensitivity-bias-detection/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>fairness-metrics-ml-model-sensitivity</b>-<b>bias</b>-detection", "snippet": "There are many different ways in which <b>machine</b> <b>learning</b> ... Instinctively (based on <b>implicit</b> human <b>bias</b>), it is one of the specific \u201cgender\u201d (male or female) against which the model could get biased as like in the real world in predicting whether those with a specific gender could re-offend or not. Thus, one of the protected attributes becomes gender. For the current example, in the real world, one could get biased in favor of female and not (or fail to) classify them as the ones who ...", "dateLastCrawled": "2022-01-20T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning is Requirements Engineering</b> \u2014 On the Role of Bugs ...", "url": "https://medium.com/analytics-vidhya/machine-learning-is-requirements-engineering-8957aee55ef4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>machine-learning-is-requirements-engineering</b>-8957...", "snippet": "A <b>machine</b>-learned model is not an attempt at implementing an <b>implicit</b> specification; a <b>machine</b>-learned model is a specification! It is a learned description of how the system shall behave. The ...", "dateLastCrawled": "2022-01-19T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Man is to Computer Programmer as Woman is</b> to Homemaker? | by Sheldon ...", "url": "https://towardsdatascience.com/man-is-to-computer-programmer-as-woman-is-to-homemaker-e57b07cbde96", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>man-is-to-computer-programmer-as-woman-is</b>-to-homemaker...", "snippet": "The paper discusses gender <b>bias</b> in <b>machine</b> <b>learning</b> as a result of using biased training data and proposes a solution to debias the model. This article contains an overview of the paper and discusses key findings in the python implementation of the paper. Overview. The authors of the paper used Word Embe d ding Model to demonstrate gender <b>bias</b> in the training data. The Word Embedding Model was trained on Google News articles and the vector representation of all words were stored in the ...", "dateLastCrawled": "2022-01-30T22:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "CSWA: <b>Unconscious Bias</b> | American Astronomical Society", "url": "https://aas.org/comms/cswa/resources/unconsciousbias", "isFamilyFriendly": true, "displayUrl": "https://aas.org/comms/cswa/resources/<b>unconsciousbias</b>", "snippet": "The intervention is based on the premise that <b>implicit bias is like</b> a habit that can be broken through a combination of awareness of implicit bias, concern about the effects of that bias, and the application of strategies to reduce bias. In a 12-week longitudinal study, people who received the intervention showed dramatic reductions in implicit race bias. People who were concerned about discrimination or who reported using the strategies showed the greatest reductions. The intervention also ...", "dateLastCrawled": "2022-02-03T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Patrick Forscher</b> \u2013 Research Lead \u2013 Busara Center for Behavioral ...", "url": "https://ch.linkedin.com/in/patrick-forscher-91163854", "isFamilyFriendly": true, "displayUrl": "https://ch.linkedin.com/in/<b>patrick-forscher</b>-91163854", "snippet": "The intervention is based on the premise that <b>implicit bias is like</b> a habit that can be broken through a combination of awareness of implicit bias, concern about the effects of that bias, and the application of strategies to reduce bias. In a 12-week longitudinal study, people who received the intervention showed dramatic reductions in implicit race bias. People who were\u2026 We developed a multi-faceted prejudice habit-breaking intervention to produce long-term reductions in implicit race ...", "dateLastCrawled": "2022-02-03T15:10:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Those designing healthcare algorithms must become actively</b> anti-racist ...", "url": "https://www.nature.com/articles/s41591-020-1020-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41591-020-1020-3", "snippet": "<b>Just as \u2018implicit bias</b>\u2019 training for police does little to change racist behavior 10 \u2014in large part because departmental cultures do not fully support the lessons of anti-racism\u2014healthcare ...", "dateLastCrawled": "2021-11-15T00:12:00.0000000Z", "language": "en", "isNavigational": false}], [], []], "all_bing_queries": ["+(implicit bias)  is like +(computer or machine learning function)", "+(implicit bias) is similar to +(computer or machine learning function)", "+(implicit bias) can be thought of as +(computer or machine learning function)", "+(implicit bias) can be compared to +(computer or machine learning function)", "machine learning +(implicit bias AND analogy)", "machine learning +(\"implicit bias is like\")", "machine learning +(\"implicit bias is similar\")", "machine learning +(\"just as implicit bias\")", "machine learning +(\"implicit bias can be thought of as\")", "machine learning +(\"implicit bias can be compared to\")"]}