{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>ROC</b> <b>Curve</b> and <b>AUC</b> for Model Selection - Machine Learning Concepts", "url": "https://www.ml-concepts.com/roc-curve-and-auc-for-model-selection/", "isFamilyFriendly": true, "displayUrl": "https://www.ml-concepts.com/<b>roc</b>-<b>curve</b>-and-<b>auc</b>-for-model-selection", "snippet": "B. <b>Area</b> <b>Under</b> <b>ROC</b> <b>Curve</b>. <b>AUC</b> is the acronym for the <b>A rea</b> <b>U nder</b> <b>C urve</b>. It is the summary of <b>the ROC</b> <b>curve</b> that tells about how good a model is when we talk about its ability to generalize. Greater the <b>area</b> <b>under</b> this <b>curve</b> (<b>AUC</b>), the greater the model\u2019s ability to separate the responses (e.g., <b>Spam</b> and Not <b>Spam</b>). <b>AUC</b> <b>ROC</b>.", "dateLastCrawled": "2022-02-03T06:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Understanding <b>the ROC Curve</b> and <b>AUC</b> | by Doug Steen | Towards Data Science", "url": "https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>the-roc-curve</b>-and-<b>auc</b>-dd4f9a192ecb", "snippet": "<b>AUC</b> stands for <b>area</b> <b>under</b> <b>the (ROC) curve</b>. Generally, the higher the <b>AUC</b> score, the better a classifier performs for the given task. Figure 2 shows that for a classifier with no predictive power (i.e., random guessing), <b>AUC</b> = 0.5, and for a perfect classifier, <b>AUC</b> = 1.0. Most classifiers will fall between 0.5 and 1.0, with the rare exception being a classifier performs worse than random guessing (<b>AUC</b> &lt; 0.5). Fig. 2 \u2014 Theoretical <b>ROC</b> curves with <b>AUC</b> scores Why use <b>ROC</b> Curves? One advantage ...", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Demystifying the <b>Confusion Matrix</b> Using a Business Example | by Mohd ...", "url": "https://towardsdatascience.com/demystifying-confusion-matrix-29f3037b0cfa", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/demystifying-<b>confusion-matrix</b>-29f3037b0cfa", "snippet": "<b>The ROC</b> <b>curve</b> is different for different classification machine learning models. Just <b>like</b> sensitivity or <b>accuracy</b>, the <b>area</b> <b>under</b> <b>curve</b>(<b>AUC</b>) of <b>ROC</b> <b>curve</b> is treated as a very valuable metric to evaluate the model. <b>The ROC</b> in the figure has a high <b>AUC</b>. We can also see there\u2019s a", "dateLastCrawled": "2022-02-02T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Classification</b> Model Evaluation | by Lahiru Liyanapathirana | Heartbeat", "url": "https://heartbeat.comet.ml/classification-model-evaluation-90d743883106", "isFamilyFriendly": true, "displayUrl": "https://heartbeat.comet.ml/<b>classification</b>-model-evaluation-90d743883106", "snippet": "<b>AUC</b> (<b>Area</b> <b>Under</b> the <b>Curve</b>) <b>AUC</b> or <b>Area</b> <b>Under</b> the <b>Curve</b> is the percentage of <b>the ROC</b> plot that is underneath the <b>curve</b>. <b>AUC</b> is useful as a single number summary of classifier performance. In Scikit-learn, we can find the <b>AUC</b> score using the method <b>roc</b>_<b>auc</b>_score. print(<b>roc</b>_<b>auc</b>_score(y_test, y_pred_prob)) OUTPUT : 0.858769314177", "dateLastCrawled": "2022-01-27T00:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Maria Khalusova | <b>Machine Learning Model Evaluation Metrics part</b> 1 ...", "url": "https://www.mariakhalusova.com/posts/2019-04-11-ml-model-evaluation-metrics-p1/", "isFamilyFriendly": true, "displayUrl": "https://www.mariakhalusova.com/posts/2019-04-11-ml-model-evaluation-metrics-p1", "snippet": "The evaluation metric that helps in this case is <b>AUC</b> score. <b>AUC</b> stands for <b>Area</b> <b>Under</b> <b>Curve</b> and it is simply the percentage of the plot box that lies <b>under</b> <b>the ROC</b> <b>curve</b>. The closer it is to 1 (100%), the better. Precision/Recall <b>Curve</b>. Another <b>curve</b> that you may see being used is called Precision/Recall <b>curve</b>. The idea is exactly the same - we ...", "dateLastCrawled": "2022-02-02T16:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Modeling - Interpretable <b>Spam</b> Filters", "url": "https://utkucanozturk.github.io/interpretable-spam-filters/model/", "isFamilyFriendly": true, "displayUrl": "https://utkucanozturk.github.io/interpretable-<b>spam</b>-<b>filters</b>/model", "snippet": "However, the <b>AUC</b> (<b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>) measures how true positive rate (recall) and false positive rate trade off and therefore evaluates the classifier for all possible threshold values. Compared to <b>accuracy</b>, <b>AUC</b> is a broader measure that tests the quality of the internal value, which the classifier generates and then compares it to a threshold. Since <b>AUC</b> does not test the quality of a particular choice of threshold, it will be used for the rest of the analysis. In our case, the <b>AUC</b> is ...", "dateLastCrawled": "2022-01-11T22:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Confusion matrix</b> and other metrics in machine learning | by Hugo ...", "url": "https://medium.com/hugo-ferreiras-blog/confusion-matrix-and-other-metrics-in-machine-learning-894688cb1c0a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/hugo-ferreiras-blog/<b>confusion-matrix</b>-and-other-metrics-in-machine...", "snippet": "The above points suggest that the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (usually denoted by <b>AUC</b>) is a good measure of the performance of the classification algorithm. If it is near 0.5, the classifier is not ...", "dateLastCrawled": "2022-01-14T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Supervised Learning with scikit-learn</b> - Yulei&#39;s Sandbox", "url": "https://yuleii.github.io/2020/09/26/supervised-learning-with-scikit-learn.html", "isFamilyFriendly": true, "displayUrl": "https://yuleii.github.io/2020/09/26/<b>supervised-learning-with-scikit-learn</b>.html", "snippet": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b>. Larger <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>(<b>AUC</b>) = better model; Exercise <b>AUC</b> computation. Say you have a binary classifier that in fact is just randomly making guesses. It would be correct approximately 50% of the time, and the resulting <b>ROC</b> <b>curve</b> would be a diagonal line in which the True Positive Rate and False Positive Rate ...", "dateLastCrawled": "2022-02-03T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>GitHub</b> - krishnadulal/<b>Feature-Selection-in-Machine-Learning-using</b> ...", "url": "https://github.com/krishnadulal/Feature-Selection-in-Machine-Learning-using-Python-All-Code", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/krishnadulal/<b>Feature-Selection-in-Machine-Learning-using-Python</b>-All...", "snippet": "<b>The ROC</b> <b>curve</b> and <b>AUC</b> (<b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>) have been widely used to determine the classification <b>accuracy</b> in supervised learning. Through analyzing a two-dimensional graph, it is hard to compare two <b>ROC</b> curves directly. <b>AUC</b>, which is denoted as a quantitative measurement, provides a good summary for examining <b>the ROC</b> curves. Link: 37:53: 6", "dateLastCrawled": "2022-01-26T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "you-have-come-up-<b>with-a-spam-classifier-how-do-you-measure-accuracy</b>/", "url": "https://machinelearninginterview.com/topics/machine-learning/you-have-come-up-with-a-spam-classifier-how-do-you-measure-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://machinelearninginterview.com/topics/machine-learning/you-have-come-up-with-a...", "snippet": "<b>AUC</b> / <b>ROC</b> : If we chose a model that gives us probability of a document being <b>spam</b> instead of binary <b>spam</b> / non <b>spam</b> result, we can compute <b>AUC</b>. Typically thresholding is used such that all documents with score above threshold are <b>spam</b> and the rest are non <b>spam</b>. The <b>AUC</b> <b>curve</b> is obtained by plotting TPR on X axis and FPR on Y axis for different threshold values (each threshold value leads to a different point and you get a <b>curve</b> represented by these points). The <b>Area</b> <b>under</b> this <b>curve</b> is the ...", "dateLastCrawled": "2022-01-26T06:11:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Is <b>roc</b> <b>auc</b> graph better than <b>roc</b> <b>auc</b> score? If yes why? - Data Science ...", "url": "https://datascience.stackexchange.com/questions/104882/is-roc-auc-graph-better-than-roc-auc-score-if-yes-why", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/104882/is-<b>roc</b>-<b>auc</b>-graph-better-than...", "snippet": "This brings up a point that many candidate models for a problem have <b>similar</b> <b>ROC</b> curves and selecting a model based on the AUROC or <b>ROC</b> may not be discriminating enough. Share. Improve this answer. Follow edited Dec 8 &#39;21 at 19:34. answered Dec 8 &#39;21 at 16:19. Craig Craig. 594 2 2 silver badges 8 8 bronze badges $\\endgroup$ Add a comment | 0 $\\begingroup$ These is what I interpreted from your question: Here is my answer: <b>ROC</b>-<b>AUC</b> Score is basically <b>AUC</b> (<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>).. IF you need ...", "dateLastCrawled": "2022-01-17T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "| notebook.community", "url": "https://notebook.community/AbnerZheng/Titanic_Kaggle/scikit-learn/09_classification_metrics", "isFamilyFriendly": true, "displayUrl": "https://notebook.community/AbnerZheng/Titanic_Kaggle/scikit-learn/09_classification...", "snippet": "What is the purpose of an <b>ROC</b> <b>curve</b>? How does <b>Area</b> <b>Under</b> the <b>Curve</b> (<b>AUC</b>) differ from classification <b>accuracy</b>? Review of model evaluation. Need a way to choose between models: different model types, tuning parameters, and features; Use a model evaluation procedure to estimate how well a model will generalize to out-of-sample data; Requires a model evaluation metric to quantify the model performance; Model evaluation procedures. Training and testing on the same data. Rewards overly complex ...", "dateLastCrawled": "2022-01-27T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Maria Khalusova | <b>Machine Learning Model Evaluation Metrics part</b> 1 ...", "url": "https://www.mariakhalusova.com/posts/2019-04-11-ml-model-evaluation-metrics-p1/", "isFamilyFriendly": true, "displayUrl": "https://www.mariakhalusova.com/posts/2019-04-11-ml-model-evaluation-metrics-p1", "snippet": "The evaluation metric that helps in this case is <b>AUC</b> score. <b>AUC</b> stands for <b>Area</b> <b>Under</b> <b>Curve</b> and it is simply the percentage of the plot box that lies <b>under</b> <b>the ROC</b> <b>curve</b>. The closer it is to 1 (100%), the better. Precision/Recall <b>Curve</b>. Another <b>curve</b> that you may see being used is called Precision/Recall <b>curve</b>. The idea is exactly the same - we ...", "dateLastCrawled": "2022-02-02T16:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Data Science: <b>Confusion Matrix, Accuracy, Precision</b>, Recall, F score ...", "url": "https://www.datasciencesmachinelearning.com/2018/11/confusion-matrix-accuracy-precision.html", "isFamilyFriendly": true, "displayUrl": "https://www.datasciencesmachinelearning.com/2018/11/confusion-matrix-<b>accuracy</b>...", "snippet": "<b>Receiver Operating Characteristic</b> (<b>ROC</b>) <b>curve</b>: In <b>ROC</b> <b>curve</b>, we plot sensitivity against (1-specificity) for different threshold values. <b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b> (<b>AUC</b>) <b>curve</b> is called <b>AUC</b>. Each point on <b>the ROC</b> <b>curve</b> represents a separate confusion matrix. There are many ways to interpret the <b>AUC</b>, but the definition I found easier is this one:", "dateLastCrawled": "2022-01-28T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Classification</b> In Machine Learning | by Amit Upadhyay | Analytics ...", "url": "https://medium.com/analytics-vidhya/classification-in-machine-learning-ed30753d9461", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>classification</b>-in-machine-learning-ed30753d9461", "snippet": "<b>ROC</b>-<b>AUC</b> <b>Curve</b>. One way to compare classifiers is to measure the <b>area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>). A perfect classifier will have a <b>ROC</b> <b>AUC</b> equal to 1, whereas a purely random classifier will have a <b>ROC</b> ...", "dateLastCrawled": "2022-02-01T00:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Confusion matrix</b> and other metrics in machine learning | by Hugo ...", "url": "https://medium.com/hugo-ferreiras-blog/confusion-matrix-and-other-metrics-in-machine-learning-894688cb1c0a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/hugo-ferreiras-blog/<b>confusion-matrix</b>-and-other-metrics-in-machine...", "snippet": "The above points suggest that the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b> (usually denoted by <b>AUC</b>) is a good measure of the performance of the classification algorithm. If it is near 0.5, the classifier is not ...", "dateLastCrawled": "2022-01-14T03:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to split and merge channels in cv2 - 2022 - Machine Learning Projects", "url": "https://machinelearningprojects.net/split-and-merge-channels-in-cv2/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningprojects.net/split-and-merge-channels-in-cv2", "snippet": "<b>AUC</b>-<b>ROC</b> <b>Curve</b> \u201c<b>Area</b> <b>Under</b> the <b>Curve</b>\u201d (<b>AUC</b>) of \u201cReceiver Characteristic Operator\u201d (<b>ROC</b>)<b>curve</b> is a special type of <b>curve</b> that is used to check the performance of a classification model. It basically tells how well our model is differentiating between True Positives and False Positives. <b>AUC</b>-<b>ROC</b> <b>curve</b> is plotted between True Positive rate and False Positive rate. Autoencoders. Autoencoders <b>are a</b> special type of neural network which just tries to produce the output, the same as the input ...", "dateLastCrawled": "2022-01-29T16:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Supervised Learning with scikit-learn</b> - Yulei&#39;s Sandbox", "url": "https://yuleii.github.io/2020/09/26/supervised-learning-with-scikit-learn.html", "isFamilyFriendly": true, "displayUrl": "https://yuleii.github.io/2020/09/26/<b>supervised-learning-with-scikit-learn</b>.html", "snippet": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b>. Larger <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>(<b>AUC</b>) = better model; Exercise <b>AUC</b> computation. Say you have a binary classifier that in fact is just randomly making guesses. It would be correct approximately 50% of the time, and the resulting <b>ROC</b> <b>curve</b> would be a diagonal line in which the True Positive Rate and False Positive Rate ...", "dateLastCrawled": "2022-02-03T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What Yelp Fake Review <b>Filter</b> Might Be Doing?", "url": "https://www.cs.uic.edu/~liub/publications/ICWSM-2013-Arjun-Spam.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.uic.edu/~liub/publications/ICWSM-2013-Arjun-<b>Spam</b>.pdf", "snippet": "An <b>AUC</b> (<b>Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>) of 0.78 was reported using logistic regression. The assumption, however, is too restricted for detecting generic fake reviews. Li et al. (2011) applied a co-training method on a manually labeled dataset of fake and non-fake reviews attaining an F1-score of 0.63. This result too may not be reliable as human labeling of fake reviews has been shown to be quite poor (Ott et al., 2011). In this work, we aim to study how well do the existing research methods work ...", "dateLastCrawled": "2022-01-11T23:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>GitHub</b> - krishnadulal/<b>Feature-Selection-in-Machine-Learning-using</b> ...", "url": "https://github.com/krishnadulal/Feature-Selection-in-Machine-Learning-using-Python-All-Code", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/krishnadulal/<b>Feature-Selection-in-Machine-Learning-using-Python</b>-All...", "snippet": "<b>The ROC</b> <b>curve</b> and <b>AUC</b> (<b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>) have been widely used to determine the classification <b>accuracy</b> in supervised learning. Through analyzing a two-dimensional graph, it is hard to compare two <b>ROC</b> curves directly. <b>AUC</b>, which is denoted as a quantitative measurement, provides a good summary for examining <b>the ROC</b> curves. Link: 37:53: 6", "dateLastCrawled": "2022-01-26T08:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Accelerating Prescriptive Analytics Using Einstein Discovery Templates</b> ...", "url": "https://www.salesforceblogger.com/2020/12/17/accelerating-prescriptive-analytics-using-einstein-discovery-templates/", "isFamilyFriendly": true, "displayUrl": "https://www.salesforceblogger.com/2020/12/17/accelerating-prescriptive-analytics-using...", "snippet": "<b>AUC</b> (<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>) This is the probability that the model ranks a random positive example higher than a random negative example. A high <b>AUC</b> (1) means that there is a high probability that a positive prediction will have a higher score assigned to it than a negative prediction. A low <b>AUC</b> (.5) means that this probability is random. Interpreting <b>AUC</b>. We <b>can</b> see that the <b>AUC</b> is relatively high at .89. This tells us that when two examples of different outcomes are selected at random ...", "dateLastCrawled": "2022-01-20T01:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Chapter 7 Logistic regression | Analytics with KNIME and R", "url": "https://bookdown.org/acitofrank/TextbookDraft/logistic-regression.html", "isFamilyFriendly": true, "displayUrl": "https://bookdown.org/acitofrank/TextbookDraft/logistic-regression.html", "snippet": "The areas <b>under</b> <b>the ROC</b> curves (<b>AUC</b>) for both are about 0.83, which is fairly high, as the <b>AUC</b> varies from 0.0 to 1.0. The overall assessment of the logistic model with this data is that it would be useful in identifying employees likely to turnover when the predictor variables are input to the model. As noted earlier, however, when an employee is predicted to turnover, additional human review is needed since the precision of the model was not high.", "dateLastCrawled": "2022-02-03T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>AUC</b>: A Better Measure <b>than Accuracy in Comparing Learning Algorithms</b> ...", "url": "https://www.researchgate.net/publication/221442229_AUC_A_Better_Measure_than_Accuracy_in_Comparing_Learning_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221442229_<b>AUC</b>_A_Better_Measure_than_<b>Accuracy</b>...", "snippet": "A scoring method was proposed based on the <b>area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>) and the <b>accuracy</b> to evaluate the effect of electrode configurations on recognizing UCs. The EHG signals from the 4 electrodes ...", "dateLastCrawled": "2022-02-03T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Feature Selection for Maximizing the Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>", "url": "https://www.researchgate.net/publication/220764833_Feature_Selection_for_Maximizing_the_Area_Under_the_ROC_Curve", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220764833_<b>Feature_Selection_for_Maximizing</b>...", "snippet": "Several evaluation criteria such as <b>accuracy</b> [27,28] , a false-positive (FP) elimination rate [29,30] , and <b>area</b> <b>under</b> <b>the receiver-operating-characteristic</b> (<b>ROC</b>) <b>curve</b> (<b>AUC</b>) [31] [32][33][34][35 ...", "dateLastCrawled": "2022-02-02T01:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Exhaled volatile organic compounds as markers for medication</b> use in ...", "url": "https://erj.ersjournals.com/content/55/2/1900544", "isFamilyFriendly": true, "displayUrl": "https://erj.ersjournals.com/content/55/2/1900544", "snippet": "<b>AUC</b>: <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>. Association with urinary levels of salbutamol and OCS SPLS modelling followed by regression analysis among classifying GC-MS features and urinary concentrations of salbutamol, prednisone and prednisolone resulted in three linear models with R 2 of 0.10 (95% CI 0.00\u20130.23), 0.63 (95% CI 0.33\u20130.94) and 0.29 (95% CI 0.05\u20130.48), respectively (all p&lt;0.01).", "dateLastCrawled": "2022-02-03T04:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Beyond <b>Accuracy</b>: <b>Precision</b> and <b>Recall</b> | by Will Koehrsen | Towards Data ...", "url": "https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/beyond-<b>accuracy</b>-<b>precision</b>-and-<b>recall</b>-3da06bea9f6c", "snippet": "<b>Receiver operating characteristic</b> (<b>ROC</b>) <b>curve</b>: plots the true positive rate (TPR) versus the false positive rate (FPR) as a function of the model\u2019s threshold for classifying a positive; <b>Area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>): metric to calculate the overall performance of a classification model based on <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>; Example Application. Our task will be to diagnose 100 patients with a disease present in 50% of the general population. We will assume a black box model, where we put in ...", "dateLastCrawled": "2022-02-02T23:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Detecting bad customer <b>reviews</b> with NLP | by Jonathan Oheix | Towards ...", "url": "https://towardsdatascience.com/detecting-bad-customer-reviews-with-nlp-d8b36134dc7e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/detecting-bad-customer-<b>reviews</b>-with-nlp-d8b36134dc7e", "snippet": "<b>The ROC</b> (<b>Receiver Operating Characteristic</b>) <b>curve</b> is usually a good graph to summarize the quality of our classifier. The higher the <b>curve</b> is above the diagonal baseline, the better the predictions. Although the <b>AUC</b> <b>ROC</b> (<b>Area</b> <b>Under</b> the <b>Curve</b> <b>ROC</b>) is very good, we should not use here <b>the ROC</b> <b>curve</b> to assess the quality of our model.", "dateLastCrawled": "2022-01-31T09:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>GitHub</b> - krishnadulal/<b>Feature-Selection-in-Machine-Learning-using</b> ...", "url": "https://github.com/krishnadulal/Feature-Selection-in-Machine-Learning-using-Python-All-Code", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/krishnadulal/<b>Feature-Selection-in-Machine-Learning-using-Python</b>-All...", "snippet": "<b>The ROC</b> <b>curve</b> and <b>AUC</b> (<b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>) have been widely used to determine the classification <b>accuracy</b> in supervised learning. Through analyzing a two-dimensional graph, it is hard to compare two <b>ROC</b> curves directly. <b>AUC</b>, which is denoted as a quantitative measurement, provides a good summary for examining <b>the ROC</b> curves. Link: 37:53: 6", "dateLastCrawled": "2022-01-26T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to plot <b>ROC</b> curves in <b>multiclass</b> classification? - Cross Validated", "url": "https://stats.stackexchange.com/questions/2151/how-to-plot-roc-curves-in-multiclass-classification", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/2151", "snippet": "It seems you are looking for <b>multi-class</b> <b>ROC</b> analysis, which is a kind of multi-objective optimization covered in a tutorial at ICML&#39;04. As in several <b>multi-class</b> problem, the idea is generally to carry out pairwise comparison (one class vs. all other classes, one class vs. another class, see (1) or the Elements of Statistical Learning), and there is a recent paper by Landgrebe and Duin on that topic, Approximating the <b>multiclass</b> <b>ROC</b> by pairwise analysis, Pattern Recognition Letters 2007 28 ...", "dateLastCrawled": "2022-01-24T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "For <b>spam</b> filtering, a false positive occurs when <b>spam</b> filtering or <b>spam</b> blocking techniques wrongly classify a legitimate email message as <b>spam</b> and, as a result, interferes with its delivery. While most anti-<b>spam</b> tactics <b>can</b> block or <b>filter</b> a high percentage of unwanted emails, doing so without creating significant false-positive results is a much more demanding task. So, we prefer too many false negatives over many false positives.", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding <b>the ROC Curve</b> and <b>AUC</b> | by Doug Steen | Towards Data Science", "url": "https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>the-roc-curve</b>-and-<b>auc</b>-dd4f9a192ecb", "snippet": "Fig. 1 \u2014 Some theoretical <b>ROC</b> curves <b>AUC</b>. While it is useful to visualize a classifier\u2019s <b>ROC curve</b>, in many cases we <b>can</b> boil this information down to a single metric \u2014 the <b>AUC</b>. <b>AUC</b> stands for <b>area</b> <b>under</b> <b>the (ROC) curve</b>. Generally, the higher the <b>AUC</b> score, the better a classifier performs for the given task.", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Is <b>roc</b> <b>auc</b> graph better than <b>roc</b> <b>auc</b> score? If yes why? - Data Science ...", "url": "https://datascience.stackexchange.com/questions/104882/is-roc-auc-graph-better-than-roc-auc-score-if-yes-why", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/104882/is-<b>roc</b>-<b>auc</b>-graph-better-than...", "snippet": "Here is my answer: <b>ROC</b>-<b>AUC</b> Score is basically <b>AUC</b> (<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>).. IF you need more clarification: <b>ROC</b>: will tell how well the classification model predicts given its threshold changes. <b>AUC</b>: will tell you how the aggregrate measures across all the threshold. <b>AUC</b> will be 0 if all the predictions are wrong and 1 if all the predictions ...", "dateLastCrawled": "2022-01-17T19:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>AUC</b>: A Better Measure <b>than Accuracy in Comparing Learning Algorithms</b> ...", "url": "https://www.researchgate.net/publication/221442229_AUC_A_Better_Measure_than_Accuracy_in_Comparing_Learning_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/221442229_<b>AUC</b>_A_Better_Measure_than_<b>Accuracy</b>...", "snippet": "A scoring method was proposed based on the <b>area</b> <b>under</b> the <b>curve</b> (<b>AUC</b>) and the <b>accuracy</b> to evaluate the effect of electrode configurations on recognizing UCs. The EHG signals from the 4 electrodes ...", "dateLastCrawled": "2022-02-03T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Accelerating Prescriptive Analytics Using Einstein Discovery Templates</b> ...", "url": "https://www.salesforceblogger.com/2020/12/17/accelerating-prescriptive-analytics-using-einstein-discovery-templates/", "isFamilyFriendly": true, "displayUrl": "https://www.salesforceblogger.com/2020/12/17/accelerating-prescriptive-analytics-using...", "snippet": "<b>AUC</b> (<b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b>) This is the probability that the model ranks a random positive example higher than a random negative example. A high <b>AUC</b> (1) means that there is a high probability that a positive prediction will have a higher score assigned to it than a negative prediction. A low <b>AUC</b> (.5) means that this probability is random. Interpreting <b>AUC</b>. We <b>can</b> see that the <b>AUC</b> is relatively high at .89. This tells us that when two examples of different outcomes are selected at random ...", "dateLastCrawled": "2022-01-20T01:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Maria Khalusova | <b>Machine Learning Model Evaluation Metrics part</b> 1 ...", "url": "https://www.mariakhalusova.com/posts/2019-04-11-ml-model-evaluation-metrics-p1/", "isFamilyFriendly": true, "displayUrl": "https://www.mariakhalusova.com/posts/2019-04-11-ml-model-evaluation-metrics-p1", "snippet": "Now, we could compare different models by plotting their <b>ROC</b> curves, but it still would be more convenient in many cases to have a single number metric for comparison. The evaluation metric that helps in this case is <b>AUC</b> score. <b>AUC</b> stands for <b>Area</b> <b>Under</b> <b>Curve</b> and it is simply the percentage of the plot box that lies <b>under</b> <b>the ROC</b> <b>curve</b>. The ...", "dateLastCrawled": "2022-02-02T16:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Feature Selection for Maximizing the Area</b> <b>Under</b> <b>the ROC</b> <b>Curve</b>", "url": "https://www.researchgate.net/publication/220764833_Feature_Selection_for_Maximizing_the_Area_Under_the_ROC_Curve", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220764833_<b>Feature_Selection_for_Maximizing</b>...", "snippet": "A <b>filter</b> method was applied using the <b>Area</b>-<b>Under</b>-the-<b>Curve</b> (<b>AUC</b>) of <b>the Receiver Operating Characteristic</b> (<b>ROC</b>) curves as a ranking criterion [39]. Radial Basis Function (RBF) kernel was used for ...", "dateLastCrawled": "2022-02-02T01:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Data Science: <b>Confusion Matrix, Accuracy, Precision</b>, Recall, F score ...", "url": "https://www.datasciencesmachinelearning.com/2018/11/confusion-matrix-accuracy-precision.html", "isFamilyFriendly": true, "displayUrl": "https://www.datasciencesmachinelearning.com/2018/11/confusion-matrix-<b>accuracy</b>...", "snippet": "<b>Receiver Operating Characteristic</b> (<b>ROC</b>) <b>curve</b>: In <b>ROC</b> <b>curve</b>, we plot sensitivity against (1-specificity) for different threshold values. <b>Area</b> <b>under</b> <b>the ROC</b> <b>Curve</b> (<b>AUC</b>) <b>curve</b> is called <b>AUC</b>. Each point on <b>the ROC</b> <b>curve</b> represents a separate confusion matrix. There are many ways to interpret the <b>AUC</b>, but the definition I found easier is this one:", "dateLastCrawled": "2022-01-28T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Evaluating a <b>Classification Model</b> | Machine Learning, Deep Learning ...", "url": "https://www.ritchieng.com/machine-learning-evaluate-classification-model/", "isFamilyFriendly": true, "displayUrl": "https://www.ritchieng.com/machine-learning-evaluate-<b>classification-model</b>", "snippet": "<b>Receiver Operating Characteristic</b> (<b>ROC</b>) Curves; <b>Area</b> <b>Under</b> the <b>Curve</b> (<b>AUC</b>) Confusion Matrix Resources; <b>ROC</b> and <b>AUC</b> Resources ; Other Resources; This tutorial is derived from Data School&#39;s Machine Learning with scikit-learn tutorial. I added my own notes so anyone, including myself, <b>can</b> refer to this tutorial without watching the videos. 1. Review of model evaluation\u00b6 Need a way to choose between models: different model types, tuning parameters, and features; Use a model evaluation procedure ...", "dateLastCrawled": "2022-02-03T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Supervised Learning with scikit-learn</b> - Yulei&#39;s Sandbox", "url": "https://yuleii.github.io/2020/09/26/supervised-learning-with-scikit-learn.html", "isFamilyFriendly": true, "displayUrl": "https://yuleii.github.io/2020/09/26/<b>supervised-learning-with-scikit-learn</b>.html", "snippet": "<b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b>. Larger <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>(<b>AUC</b>) = better model; Exercise <b>AUC</b> computation . Say you have a binary classifier that in fact is just randomly making guesses. It would be correct approximately 50% of the time, and the resulting <b>ROC</b> <b>curve</b> would be a diagonal line in which the True Positive Rate and False Positive Rate are always equal. The <b>Area</b> <b>under</b> this <b>ROC</b> <b>curve</b> would be 0.5. This is one way in which the <b>AUC</b>, is an informative metric to evaluate a model. If the ...", "dateLastCrawled": "2022-02-03T04:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>GitHub</b> - krishnadulal/<b>Feature-Selection-in-Machine-Learning-using</b> ...", "url": "https://github.com/krishnadulal/Feature-Selection-in-Machine-Learning-using-Python-All-Code", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/krishnadulal/<b>Feature-Selection-in-Machine-Learning-using-Python</b>-All...", "snippet": "<b>The ROC</b> <b>curve</b> and <b>AUC</b> (<b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>) have been widely used to determine the classification <b>accuracy</b> in supervised learning. Through analyzing a two-dimensional graph, it is hard to compare two <b>ROC</b> curves directly. <b>AUC</b>, which is denoted as a quantitative measurement, provides a good summary for examining <b>the ROC</b> curves. Link: 37:53: 6", "dateLastCrawled": "2022-01-26T08:14:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding <b>AUC</b> - <b>ROC</b> <b>Curve</b> | by Sarang Narkhede | Towards Data Science", "url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>auc</b>-<b>roc</b>-<b>curve</b>-68b2303cc9c5", "snippet": "<b>AUC</b> - <b>ROC</b> <b>curve</b> is a performance measurement for the classification problems at various threshold settings. <b>ROC</b> is a probability <b>curve</b> and <b>AUC</b> represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. Higher the <b>AUC</b>, the better the model is at predicting 0 classes as 0 and 1 classes as 1. By <b>analogy</b>, the Higher the <b>AUC</b>, the better the model is at distinguishing between patients with the disease and no disease.", "dateLastCrawled": "2022-01-30T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "<b>AUC</b> calculates the <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, and therefore it is between 0 and 1. One way of interpreting <b>AUC</b> is the probability that the model ranks a random positive example more highly than a random negative example. Youden\u2019s index Youden\u2019s J statistic (also called Youden\u2019s index) is a single statistic that captures the performance of a dichotomous (A partition of a whole into two) diagnostic tests. Youden\u2019s J statistic is J = sensitivity + specificity - 1 The right-hand two ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding <b>AUC</b> - <b>RO C</b> <b>Cur ve</b>", "url": "https://48hours.ai/files/AUC.pdf", "isFamilyFriendly": true, "displayUrl": "https://48hours.ai/files/<b>AUC</b>.pdf", "snippet": "In <b>Machine</b> <b>Learning</b>, performance measurement is an essential task. So when it comes to a classification problem, we can count on an <b>AUC</b> - <b>ROC</b> <b>Curve</b>. When we need to check or visualize the performance of the multi - class classification problem, we use <b>AUC</b> (<b>Area</b> <b>Under</b> The <b>Cur ve</b>) <b>ROC</b> (Receiver Operating Character istics) <b>curve</b>. It is one of the most important evaluation metrics for checking any classification model\u2019s performance. It is also written as AUROC (<b>Area</b> <b>Under</b> t he Receiver ...", "dateLastCrawled": "2022-02-01T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>What is</b> <b>AUC</b> - <b>ROC</b> in <b>Machine</b> <b>Learning</b> | Overview of <b>ROC</b>", "url": "https://www.mygreatlearning.com/blog/roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>roc</b>-<b>curve</b>", "snippet": "<b>ROC</b> is a probability <b>curve</b>, and <b>AUC</b> represents the degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the <b>AUC</b>, better the model is at predicting 0s as 0s and 1s as 1s. By <b>analogy</b>, Higher the <b>AUC</b>, better the model is at distinguishing between patients with the disease and no disease.", "dateLastCrawled": "2022-01-30T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "In <b>machine</b> <b>learning</b>, how model accuracy and <b>ROC</b> <b>AUC</b> (<b>area</b> <b>under</b> the TP ...", "url": "https://www.quora.com/In-machine-learning-how-model-accuracy-and-ROC-AUC-area-under-the-TP-vs-FP-rates-curve-are-related", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-<b>machine</b>-<b>learning</b>-how-model-accuracy-and-<b>ROC</b>-<b>AUC</b>-<b>area</b>-<b>under</b>...", "snippet": "Answer (1 of 2): High accuracy and higher <b>AUC</b> are both good things generally. Before understanding AUROC, first the concept of confusion matrix must be understood ...", "dateLastCrawled": "2022-01-07T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Receiver Operating <b>Curve</b> (<b>ROC</b>) and The Scale \u2014 Understanding <b>ROC</b> ...", "url": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the-scale-understanding-roc-through-an-analogy-8b8f9d954f84", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-everyday/the-receiver-operating-<b>curve</b>-<b>roc</b>-and-the...", "snippet": "The Receiver Operating <b>Curve</b> (<b>ROC</b>) is used to evaluate and improve classification <b>Machine</b> <b>Learning</b> models. Who does not want an accurate classifier, that place observations where they actually\u2026", "dateLastCrawled": "2021-02-13T00:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is the <b>AUC</b> \u2014 <b>ROC</b> <b>Curve</b>?. <b>AUC</b>-<b>ROC</b> <b>CURVE</b> | CONFUSION MATRIX |\u2026 | by ...", "url": "https://medium.com/computer-architecture-club/what-is-the-auc-roc-curve-47fbdcbf7a4a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/computer-architecture-club/what-is-the-<b>auc</b>-<b>roc</b>-<b>curve</b>-47fbdcbf7a4a", "snippet": "The <b>Area</b> <b>Under</b> the <b>Curve</b> (<b>AUC</b>) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of <b>the ROC</b> <b>curve</b>. <b>AUC</b>-<b>ROC</b> <b>curve</b> is a performance measurement ...", "dateLastCrawled": "2022-01-26T00:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "21 <b>Machine</b> <b>Learning</b> <b>Interview Questions</b> and Answers", "url": "https://elitedatascience.com/machine-learning-interview-questions-answers", "isFamilyFriendly": true, "displayUrl": "https://elitedatascience.com/<b>machine</b>-<b>learning</b>-<b>interview-questions</b>-answers", "snippet": "<b>AUC</b> is <b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>, and it&#39;s a common performance metric for evaluating binary classification models. It&#39;s equivalent to the expected probability that a uniformly drawn random positive is ranked before a uniformly drawn random negative. Learn more about <b>the ROC</b> <b>Curve</b>; 7.2 - Why is <b>Area</b> <b>Under</b> <b>ROC</b> <b>Curve</b> (AUROC) better than raw ...", "dateLastCrawled": "2022-02-02T19:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Applying <b>machine</b> <b>learning</b> algorithms to predict default probability in ...", "url": "https://www.sciencedirect.com/science/article/pii/S1057521921002878", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1057521921002878", "snippet": "The results show that, first, based on the <b>AUC</b> (<b>area</b> <b>under</b> <b>the ROC</b> <b>curve</b>) value, accuracy rate and Brier score, the <b>machine</b> <b>learning</b> models can accurately predict the default risk of online borrowers. Second, the integrated discrimination improvement (IDI) test results show that the prediction performance of the <b>machine</b> <b>learning</b> algorithms is significantly better than that of the logistic model. Third, after constructing the investor profit function with misclassification cost, we find that ...", "dateLastCrawled": "2022-01-27T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "C. <b>Area</b> <b>under</b> <b>the ROC</b> <b>curve</b> D. All of the above Answer : D. 24. Which of the following is a good test dataset characteristic? A. Large enough to yield meaningful results B. Is representative of the dataset as a whole C. Both A and B D. None of the above Answer : C. 25. Which of the following is a disadvantage of decision trees? A. Factor analysis", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(auc (area under the roc curve))  is like +(accuracy of a spam filter)", "+(auc (area under the roc curve)) is similar to +(accuracy of a spam filter)", "+(auc (area under the roc curve)) can be thought of as +(accuracy of a spam filter)", "+(auc (area under the roc curve)) can be compared to +(accuracy of a spam filter)", "machine learning +(auc (area under the roc curve) AND analogy)", "machine learning +(\"auc (area under the roc curve) is like\")", "machine learning +(\"auc (area under the roc curve) is similar\")", "machine learning +(\"just as auc (area under the roc curve)\")", "machine learning +(\"auc (area under the roc curve) can be thought of as\")", "machine learning +(\"auc (area under the roc curve) can be compared to\")"]}