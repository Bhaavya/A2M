{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>The Java Graphics2D Class</b> | Java Programming Tutorial", "url": "https://www.developer.com/guides/java-graphics2d-class-tutorial/", "isFamilyFriendly": true, "displayUrl": "https://www.developer.com/guides/<b>java-graphics2d-class</b>-tutorial", "snippet": "Each <b>Shape</b> object provides callbacks to get the <b>bounding</b> <b>box</b> of the geometry, ... Stroking a <b>Shape</b> <b>is like</b> tracing its <b>outline</b> with a marking pen of the appropriate size and <b>shape</b>. The area where the pen would place ink is the area enclosed by the <b>outline</b> <b>Shape</b>. The methods of the Graphics2D interface that use the <b>outline</b> <b>Shape</b> returned by a Stroke object include draw and any other methods that are implemented in terms of that method, such as drawLine, drawRect, drawRoundRect, drawOval ...", "dateLastCrawled": "2022-02-02T03:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Clipping in CSS and SVG \u2014 The clip-path Property and &lt;clipPath&gt; Element", "url": "https://www.sarasoueidan.com/blog/css-svg-clipping/", "isFamilyFriendly": true, "displayUrl": "https://www.sarasoueidan.com/blog/css-svg-clipping", "snippet": "A <b>bounding</b> <b>box</b> is the object <b>bounding</b> <b>box</b> for all SVG elements (it contains only an element&#39;s geometric <b>shape</b>) and the border <b>box</b> for HTML elements with an associated <b>box</b> model. This value is particularly useful for SVG elements because it allows you to apply the clip path to the boundaries of the element itself, not the coordinate system on use.", "dateLastCrawled": "2022-02-01T20:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "OpenCV for <b>detecting Edges, lines and shapes</b> - Packt Hub", "url": "https://hub.packtpub.com/opencv-detecting-edges-lines-shapes/", "isFamilyFriendly": true, "displayUrl": "https://hub.packtpub.com/opencv-detecting-edges-lines-<b>shapes</b>", "snippet": "A convex <b>shape</b> is defined as such when there exists two points within that <b>shape</b> whose connecting line goes outside the perimeter of the <b>shape</b> itself. The first facility OpenCV offers to calculate the approximate <b>bounding</b> polygon <b>of a shape</b> is cv2.approxPolyDP. This function takes three parameters: A contour.", "dateLastCrawled": "2022-02-02T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Object Detection Using OpenCV</b> YOLO | Great Learning", "url": "https://www.mygreatlearning.com/blog/yolo-object-detection-using-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreatlearning.com/blog/yolo-<b>object-detection-using-opencv</b>", "snippet": "The predicted <b>bounding</b> boxes may look something <b>like</b> the following (the higher the confidence score, the fatter the <b>box</b> is drawn): Source: Original YOLO research <b>paper</b> Finally, the confidence score for the <b>bounding</b> <b>box</b> and the class prediction are combined into one final score that tells us the probability that this <b>bounding</b> <b>box</b> contains a specific type of object.", "dateLastCrawled": "2022-02-03T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Measuring size of objects in an image with OpenCV - <b>PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv", "snippet": "Measuring the size of an object (or objects) in an image has been a heavily requested tutorial on the <b>PyImageSearch</b> blog for some time now \u2014 and it feels great to get this post online and share it with you. Today\u2019s post is the second in a three part series on measuring the size of objects in an image and computing the distances between them.. Last week, we learned an important technique: how reliably order a set of rotated <b>bounding</b> <b>box</b> coordinates in a top-left, top-right, bottom-right ...", "dateLastCrawled": "2022-02-02T15:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>OpenCV shape detection - PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2016/02/08/opencv-shape-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2016/02/08/<b>opencv-shape-detection</b>", "snippet": "We then have our detect method on Line 8 which requires only a single argument, c, the contour (i.e., <b>outline</b>) of the <b>shape</b> we are trying to identify. In order to perform <b>shape</b> detection, we\u2019ll be using contour approximation. As the name suggests, contour approximation is an algorithm for reducing the number of points in a curve with a reduced set of points \u2014 thus the term approximation. This algorithm is commonly known as the Ramer-Douglas-Peucker algorithm, or simply the split-and ...", "dateLastCrawled": "2022-02-03T01:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Basic sketching</b> - SlideShare", "url": "https://www.slideshare.net/deluxinsite/basic-sketching", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/deluxinsite/<b>basic-sketching</b>", "snippet": "Divide this <b>bounding</b> <b>box</b> in cubes and search for the right viewpoint. Once found. Print out the grid and start drawing. It&#39;s fairly easy to create a axi-symmetrical <b>shape</b>. Define a profile curve In one of the Mid-section planes of the <b>bounding</b> <b>box</b>. You can also define this profile curve first <b>on a piece</b> <b>of paper</b> in a side-or top view of the grid. Create the corresponding squares and ellipses where the profile curve intersects with the grid corresponding to the chosen plane. Once all the ...", "dateLastCrawled": "2022-01-28T16:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Draw a <b>rectangular shape and extract objects</b> using Python&#39;s OpenCV ...", "url": "https://www.geeksforgeeks.org/python-draw-rectangular-shape-and-extract-objects-using-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/python-draw-<b>rectangular-shape-and-extract-objects</b>-using...", "snippet": "Above <b>piece</b> of code will work with only black background image. But rectangles can be drawn to any images. We can write a program which allows us to select desired portion in an image and extract that selected portion as well. The task includes following things \u2013 draw <b>shape</b> on any image; re-select the extract portion for in case bad selection; extract particular object from the image # Write Python code here # import the necessary packages. import cv2. import argparse # now let&#39;s ...", "dateLastCrawled": "2022-02-01T09:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Model Repair</b> | Materialise Cloud", "url": "https://cloud.materialise.com/tools/model-repair", "isFamilyFriendly": true, "displayUrl": "https://cloud.materialise.com/tools/<b>model-repair</b>", "snippet": "To make this all a little more clear visually, imagine drawing the <b>outline</b> <b>of a shape</b> <b>on a piece</b> <b>of paper</b>. If you trace the same <b>outline</b> a second time, it will become thicker, much <b>like</b> the way a 3D printed object gets thicker and stronger the more shells it is printed with. When printing a hollow design (a fairly standard practice as the model will be lighter and more cost-effective), the most common tactic is to print an outer shell (called an \u201c<b>outline</b>\u201d) and an inner shell (called an ...", "dateLastCrawled": "2022-01-29T14:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Coordinate System and Shapes \\ Tutorials - Processing", "url": "https://py.processing.org/tutorials/drawing/", "isFamilyFriendly": true, "displayUrl": "https://py.processing.org/tutorials/drawing", "snippet": "Coordinate Space. Before we begin programming with Processing, we must first channel our eighth grade selves, pull out a <b>piece</b> of graph <b>paper</b>, and draw a line. The shortest distance between two points is a good old fashioned line, and this is where we begin, with two points on that graph <b>paper</b>. The above figure shows a line between point A (1,0 ...", "dateLastCrawled": "2022-01-29T04:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>The Java Graphics2D Class</b> | Java Programming Tutorial", "url": "https://www.developer.com/guides/java-graphics2d-class-tutorial/", "isFamilyFriendly": true, "displayUrl": "https://www.developer.com/guides/<b>java-graphics2d-class</b>-tutorial", "snippet": "Each <b>Shape</b> object provides callbacks to get the <b>bounding</b> <b>box</b> of the ... The methods of the Graphics2D interface that use the <b>outline</b> <b>Shape</b> returned by a Stroke object include draw and any other methods that are implemented in terms of that method, such as drawLine, drawRect, drawRoundRect, drawOval, drawArc, drawPolyline, and drawPolygon. You need to read this very carefully to make sure that you understand it. What this says to me is that the Stroke interface is used to produce a <b>Shape</b> that ...", "dateLastCrawled": "2022-02-02T03:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "OpenCV for <b>detecting Edges, lines and shapes</b> - Packt Hub", "url": "https://hub.packtpub.com/opencv-detecting-edges-lines-shapes/", "isFamilyFriendly": true, "displayUrl": "https://hub.packtpub.com/opencv-detecting-edges-lines-<b>shapes</b>", "snippet": "Contours \u2013 <b>bounding</b> <b>box</b>, minimum area rectangle and minimum enclosing circle. Finding the contours of a square is a simple task; irregular, skewed, and rotated shapes bring the best out of the cv2.findContours utility function of OpenCV. Let\u2019s take a look at the following image:", "dateLastCrawled": "2022-02-02T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>OpenCV shape detection - PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2016/02/08/opencv-shape-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2016/02/08/<b>opencv-shape-detection</b>", "snippet": "We then have our detect method on Line 8 which requires only a single argument, c, the contour (i.e., <b>outline</b>) of the <b>shape</b> we are trying to identify. In order to perform <b>shape</b> detection, we\u2019ll be using contour approximation. As the name suggests, contour approximation is an algorithm for reducing the number of points in a curve with a reduced set of points \u2014 thus the term approximation. This algorithm is commonly known as the Ramer-Douglas-Peucker algorithm, or simply the split-and ...", "dateLastCrawled": "2022-02-03T01:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Model Repair</b> | Materialise Cloud", "url": "https://cloud.materialise.com/tools/model-repair", "isFamilyFriendly": true, "displayUrl": "https://cloud.materialise.com/tools/<b>model-repair</b>", "snippet": "To make this all a little more clear visually, imagine drawing the <b>outline</b> <b>of a shape</b> <b>on a piece</b> <b>of paper</b>. If you trace the same <b>outline</b> a second time, it will become thicker, much like the way a 3D printed object gets thicker and stronger the more shells it is printed with. When printing a hollow design (a fairly standard practice as the model will be lighter and more cost-effective), the most common tactic is to print an outer shell (called an \u201c<b>outline</b>\u201d) and an inner shell (called an ...", "dateLastCrawled": "2022-01-29T14:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Basic sketching</b> - SlideShare", "url": "https://www.slideshare.net/deluxinsite/basic-sketching", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/deluxinsite/<b>basic-sketching</b>", "snippet": "Divide this <b>bounding</b> <b>box</b> in cubes and search for the right viewpoint. Once found. Print out the grid and start drawing. It&#39;s fairly easy to create a axi-symmetrical <b>shape</b>. Define a profile curve In one of the Mid-section planes of the <b>bounding</b> <b>box</b>. You can also define this profile curve first <b>on a piece</b> <b>of paper</b> in a side-or top view of the grid. Create the corresponding squares and ellipses where the profile curve intersects with the grid corresponding to the chosen plane. Once all the ...", "dateLastCrawled": "2022-01-28T16:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Gentle Introduction to Object Recognition With Deep Learning", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/object-recognition-with-deep-learnin", "snippet": "A computer vision technique is used to propose candidate regions or <b>bounding</b> boxes of potential objects in the image called \u201cselective search,\u201d although the flexibility of the design allows other region proposal algorithms to be used. The feature extractor used by the model was the AlexNet deep CNN that won the ILSVRC-2012 image classification competition. The output of the CNN was a 4,096 element vector that describes the contents of the image that is fed to a linear SVM for ...", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Draw a <b>rectangular shape and extract objects</b> using Python&#39;s OpenCV ...", "url": "https://www.geeksforgeeks.org/python-draw-rectangular-shape-and-extract-objects-using-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/python-draw-<b>rectangular-shape-and-extract-objects</b>-using...", "snippet": "Above <b>piece</b> of code will work with only black background image. But rectangles can be drawn to any images. We can write a program which allows us to select desired portion in an image and extract that selected portion as well. The task includes following things \u2013 draw <b>shape</b> on any image; re-select the extract portion for in case bad selection", "dateLastCrawled": "2022-02-01T09:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>YOLOv3</b> \u2014 Real-time object detection | by Karlijn Alderliesten ...", "url": "https://medium.com/analytics-vidhya/yolov3-real-time-object-detection-54e69037b6d0", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>yolov3</b>-real-time-object-detection-54e69037b6d0", "snippet": "A general <b>outline</b> of the <b>YOLOv3</b>-approach on real-time object detection, explained by taking a quick dive into convolutional neural networks. To make this comprehensible I left out the details and\u2026", "dateLastCrawled": "2022-02-03T14:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Finding Shapes in Images using Python and OpenCV</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2014/10/20/finding-shapes-images-using-python-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2014/10/20/finding-<b>shapes</b>-images-using-python-opencv", "snippet": "<b>Finding Shapes in Images using Python and OpenCV</b>. Let\u2019s go ahead and get started. Open up a new file, name it find_shapes.py, and we\u2019ll get to work. # import the necessary packages import numpy as np import argparse import imutils import cv2 # construct the argument parse and parse the arguments ap = argparse.ArgumentParser() ap.add_argument(&quot;-i&quot;, &quot;--image&quot;, help = &quot;path to the image file&quot;) args = vars(ap.parse_args()) # load the image image = cv2.imread(args[&quot;image&quot;])", "dateLastCrawled": "2022-02-02T18:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Make an Easy <b>Paper</b> Cut Out Effect In PowerPoint - PrettyWebz ...", "url": "https://prettywebz.com/paper-cut-out-effect/", "isFamilyFriendly": true, "displayUrl": "https://prettywebz.com/<b>paper</b>-cut-out-effect", "snippet": "Once we have this basic shapes here, noticed that on the outside, it looks like we laid a <b>piece</b> <b>of paper</b> on top of this pink, this is what we want. Now what we\u2019re going to do is right-click, copy, and paste the second heart. Use the <b>bounding</b> <b>box</b> handles to resize to adjust the size and nested inside the large heart <b>shape</b>.", "dateLastCrawled": "2022-01-27T11:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Tree-maps: A space-filling approach to the visualization of ...", "url": "https://www.academia.edu/2900413/Tree_maps_A_space_filling_approach_to_the_visualization_of_hierarchical_information_structures", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/2900413/Tree_maps_A_space_filling_approach_to_the...", "snippet": "A node&#39;s weight (<b>bounding</b> <b>box</b>) determines its display size and <b>can</b> <b>be thought</b> of as a measure of importance or degree of interest (Furnas, 1986). The following relationships between the structure of the hierarchy and the structure of its treemap drawing always hold: Properties 1) If Node 1 is an ancestor of Node 2, then the <b>bounding</b> <b>box</b> of Node 1 completely encloses, or is equal to, the <b>bounding</b> <b>box</b> of Node 2. 2) The <b>bounding</b> boxes of two nodes intersect if one node is an ancestor of the ...", "dateLastCrawled": "2021-12-19T21:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "YOLO <b>object detection with OpenCV</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2018/11/12/yolo-<b>object-detection-with-opencv</b>", "snippet": "Scale <b>bounding</b> <b>box</b> coordinates so we <b>can</b> display them properly on our original image (Line 81). Extract coordinates and dimensions of the <b>bounding</b> <b>box</b> (Line 82). YOLO returns <b>bounding</b> <b>box</b> coordinates in the form: (centerX, centerY, width, and height). Use this information to derive the top-left (x, y)-coordinates of the <b>bounding</b> <b>box</b> (Lines 86 ...", "dateLastCrawled": "2022-02-02T04:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>OpenCV shape detection - PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2016/02/08/opencv-shape-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2016/02/08/<b>opencv-shape-detection</b>", "snippet": "We then have our detect method on Line 8 which requires only a single argument, c, the contour (i.e., <b>outline</b>) of the <b>shape</b> we are trying to identify. In order to perform <b>shape</b> detection, we\u2019ll be using contour approximation. As the name suggests, contour approximation is an algorithm for reducing the number of points in a curve with a reduced set of points \u2014 thus the term approximation. This algorithm is commonly known as the Ramer-Douglas-Peucker algorithm, or simply the split-and ...", "dateLastCrawled": "2022-02-03T01:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Basic sketching</b> - SlideShare", "url": "https://www.slideshare.net/deluxinsite/basic-sketching", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/deluxinsite/<b>basic-sketching</b>", "snippet": "With a simple CAD-program we <b>can</b> construct a simple <b>bounding</b> <b>box</b>. Divide this <b>bounding</b> <b>box</b> in cubes and search for the right viewpoint. Once found. Print out the grid and start drawing. It&#39;s fairly easy to create a axi-symmetrical <b>shape</b>. Define a profile curve In one of the Mid-section planes of the <b>bounding</b> <b>box</b>. You <b>can</b> also define this profile curve first <b>on a piece</b> <b>of paper</b> in a side-or top view of the grid. Create the corresponding squares and ellipses where the profile curve intersects ...", "dateLastCrawled": "2022-01-28T16:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Gentle Introduction to Object Recognition With Deep Learning", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/object-recognition-with-deep-learnin", "snippet": "For example, an image may be divided into a 7\u00d77 grid and each cell in the grid may predict 2 <b>bounding</b> boxes, resulting in 94 proposed <b>bounding</b> <b>box</b> predictions. The class probabilities map and the <b>bounding</b> boxes with confidences are then combined into a final set of <b>bounding</b> boxes and class labels. The image taken from the <b>paper</b> below summarizes the two outputs of the model.", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to Scale, Transform, and <b>Resize an Object in Photoshop</b> | Elegant ...", "url": "https://www.elegantthemes.com/blog/design/how-to-scale-transform-and-resize-an-object-in-photoshop", "isFamilyFriendly": true, "displayUrl": "https://www.elegantthemes.com/blog/design/how-to-scale-transform-and-resize-an-object...", "snippet": "The sun now has a <b>bounding</b> <b>box</b> with handles that I <b>can</b> use to resize just as I did for the white square. Transform image 9 . I want to keep this one in proportion to start so I will click the Maintain Aspect Ratio button (link icon) in the Options Bar again, then use the handles to resize the sun so that it fills the white square. Transform image 10. There\u2019s one other option for sizing here. Whether you choose Scale or Free Transform, you <b>can</b> use the handles on the <b>bounding</b> <b>box</b> as ...", "dateLastCrawled": "2022-02-02T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Chapter 2</b>. Using the acm.graphics Package", "url": "https://cs.stanford.edu/people/eroberts/jtf/tutorial/UsingTheGraphicsPackage.html", "isFamilyFriendly": true, "displayUrl": "https://cs.stanford.edu/people/eroberts/jtf/tutorial/UsingTheGraphicsPackage.html", "snippet": "<b>Chapter 2</b> Using the acm.graphics Package The HelloGraphics example in Chapter 1 offers a simple example of how to write graphical programs, but does not explain the details behind the methods it contains. The purpose of this chapter is to give you a working knowledge of the facilities available in the acm.graphics package and how to use them effectively.. The class structure of acm.graphics package appears in Figure 2-1.Most of the classes in the package are subclasses of the abstract class ...", "dateLastCrawled": "2022-01-29T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "elements o 3.5 The element o 3.6 The element o 3.7 The element * 4 SVG ...", "url": "https://www.w3.org/WAI/PF/svg-12aug1999.txt", "isFamilyFriendly": true, "displayUrl": "https://www.w3.org/WAI/PF/svg-12aug1999.txt", "snippet": "(Note: the <b>bounding</b> <b>box</b> represents the maximum extent of the <b>shape</b> of the object in X and Y with respect to the user coordinate system of the object exclusive of stroke-width.) x = &quot;x-coordinate&quot; The x-coordinate of one corner of the rectangle for the largest possible offscreen buffer, where the values are either relative to the current user coordinate system (if maskUnits=&quot;userSpace&quot;) or relative to the current object (if maskUnits=&quot;objectBoundingBox&quot;). Note that the clipping path used to ...", "dateLastCrawled": "2021-12-15T15:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Custom image cropping in PowerPoint</b> | BrightCarbon", "url": "https://www.brightcarbon.com/blog/custom-image-cropping-in-powerpoint/", "isFamilyFriendly": true, "displayUrl": "https://www.brightcarbon.com/blog/<b>custom-image-cropping-in-powerpoint</b>", "snippet": "You should also remove any <b>outline</b> that your freeform <b>shape</b> may have had. Top tips. If your <b>shape</b>\u2019s edges look a little jagged, you might want to add a drop shadow or apply the \u2018soft edges\u2019 effect. This will blur the edges a little, giving it a slicker look. You <b>can</b> now sit your cropped image on top of another, or leave it just as it is \u2013 either way, it\u2019s a cool technique that you\u2019ll use time and time again. Good luck! And the best news is that this process is even easier if you ...", "dateLastCrawled": "2022-02-02T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Make an Easy <b>Paper</b> Cut Out Effect In PowerPoint - PrettyWebz ...", "url": "https://prettywebz.com/paper-cut-out-effect/", "isFamilyFriendly": true, "displayUrl": "https://prettywebz.com/<b>paper</b>-cut-out-effect", "snippet": "The <b>paper</b> cut out effect is meant to look like layered pieces <b>of paper</b> with shapes cut out. Anything with the gradient is not going to work. Try to choose images that are silhouette or vector-based so that you <b>can</b> separate each <b>piece</b> and layer them to look like <b>paper</b> cut-outs layered on top of each other for a nice back to school or crafting look.", "dateLastCrawled": "2022-01-27T11:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "YOLO <b>object detection with OpenCV</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2018/11/12/yolo-<b>object-detection-with-opencv</b>", "snippet": "Scale <b>bounding</b> <b>box</b> coordinates so we <b>can</b> display them properly on our original image (Line 81). Extract coordinates and dimensions of the <b>bounding</b> <b>box</b> (Line 82). YOLO returns <b>bounding</b> <b>box</b> coordinates in the form: (centerX, centerY, width, and height). Use this information to derive the top-left (x, y)-coordinates of the <b>bounding</b> <b>box</b> (Lines 86 ...", "dateLastCrawled": "2022-02-02T04:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Object Detection Using OpenCV</b> YOLO | Great Learning", "url": "https://www.mygreatlearning.com/blog/yolo-object-detection-using-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreatlearning.com/blog/yolo-<b>object-detection-using-opencv</b>", "snippet": "Coordinates of B <b>bounding</b> boxes -YOLO predicts 4 coordinates for each <b>bounding</b> <b>box</b> (bx,by,bw,bh) with respect to the corresponding grid cell. Here bx, by are the x and y coordinates of the midpoint of the object with respect to this grid. The value of bh is the ratio of the height of the <b>bounding</b> <b>box</b> to the height of the corresponding grid cell and bw is the ratio of the width of the <b>bounding</b> <b>box</b> to the width of the grid cell.", "dateLastCrawled": "2022-02-03T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Measuring size of objects in an image with OpenCV - You <b>can</b> master ...", "url": "https://www.pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv", "snippet": "Measuring the size of an object (or objects) in an image has been a heavily requested tutorial on the <b>PyImageSearch</b> blog for some time now \u2014 and it feels great to get this post online and share it with you. Today\u2019s post is the second in a three part series on measuring the size of objects in an image and computing the distances between them.. Last week, we learned an important technique: how reliably order a set of rotated <b>bounding</b> <b>box</b> coordinates in a top-left, top-right, bottom-right ...", "dateLastCrawled": "2022-02-02T15:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Gentle Introduction to Object Recognition With Deep Learning", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/object-recognition-with-deep-learnin", "snippet": "For example, an image may be divided into a 7\u00d77 grid and each cell in the grid may predict 2 <b>bounding</b> boxes, resulting in 94 proposed <b>bounding</b> <b>box</b> predictions. The class probabilities map and the <b>bounding</b> boxes with confidences are then combined into a final set of <b>bounding</b> boxes and class labels. The image taken from the <b>paper</b> below summarizes the two outputs of the model.", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 4, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Nether Fortress</b> \u2013 Minecraft Wiki", "url": "https://minecraft.fandom.com/wiki/Nether_Fortress", "isFamilyFriendly": true, "displayUrl": "https://minecraft.fandom.com/wiki/<b>Nether_Fortress</b>", "snippet": "An <b>outline</b> of the &quot;<b>bounding</b> boxes&quot;. The actual area, which works as the fortress itself is the <b>bounding</b> <b>box</b> of the actual generated structure. The &quot;<b>bounding</b> boxes&quot; are based on the uppermost level of nether brick generated in the actual section (bridges, corridors, blaze spawner platforms etc.) except walls and railings on the side. Basically the level where you <b>can</b> walk, the level of the floor. The roof of sections with fully closed top behave like this as well. These are the base levels of ...", "dateLastCrawled": "2022-02-03T07:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>OCR with Deep Learning</b>: How Do You Do It?", "url": "https://labelyourdata.com/articles/ocr-with-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://labelyourdata.com/articles/<b>ocr-with-deep-learning</b>", "snippet": "This step of an OCR project requires drawing a <b>bounding</b> <b>box</b> around the pieces of text found on the image. A few of the legacy techniques used for this step include SSD, real-time (YOLO) and region-based detectors, sliding window technique, Mask R-CNN, EAST detector, etc. You <b>can</b> read more on some of them in this article. (On a side note ...", "dateLastCrawled": "2022-02-03T07:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to <b>crop</b> an image in OpenCV using <b>Python</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/15589517/how-to-crop-an-image-in-opencv-using-python", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/15589517", "snippet": "Now img is a (imageheight, imagewidth, 3) <b>shape</b> array. <b>Crop</b> the array with tensorflow: import tensorflow as tf offset_height=0 offset_width=0 target_height=500 target_width=500 x = tf.image.<b>crop</b>_to_<b>bounding</b>_<b>box</b>( img, offset_height, offset_width, target_height, target_width ) Reassemble the image with tf.keras, so we <b>can</b> look at it if it worked:", "dateLastCrawled": "2022-02-03T06:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "algorithm - Combined area of <b>overlapping circles</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/1667310/combined-area-of-overlapping-circles", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/1667310", "snippet": "put a <b>bounding</b> <b>box</b> around the circles; ... So if you <b>can</b> work out how to calculate such a <b>shape</b>, you just do it for all the individual shapes and add them together. The complexity of this naive approach is O(N^3), where N is the number of circles in the figure. With some clever data structure use, you could improve this line-sweep method to O(N^2 * log(N)), but unless you really need to, it&#39;s probably not worth the trouble. Share. Follow answered Jan 21 &#39;10 at 15:57. Steve Thomas Steve ...", "dateLastCrawled": "2022-01-21T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Face Recognition</b>: Real-Time <b>Face Recognition</b> System using Deep Learning ...", "url": "https://bhashkarkunal.medium.com/face-recognition-real-time-webcam-face-recognition-system-using-deep-learning-algorithm-and-98cf8254def7", "isFamilyFriendly": true, "displayUrl": "https://bhashkarkunal.medium.com/<b>face-recognition</b>-real-time-webcam-<b>face-recognition</b>...", "snippet": "The dataset you <b>can</b> download from Casia-WebFace and VggFace2. A face detector is run on each image and a tight <b>bounding</b> <b>box</b> around each face is generated. These face thumbnails are resized to the input size of the respective network. Input sizes range from 96x96 pixels to 224x224 pixels in our experiments.", "dateLastCrawled": "2022-01-31T16:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "elements o 3.5 The element o 3.6 The element o 3.7 The element * 4 SVG ...", "url": "https://www.w3.org/WAI/PF/svg-12aug1999.txt", "isFamilyFriendly": true, "displayUrl": "https://www.w3.org/WAI/PF/svg-12aug1999.txt", "snippet": "(Note: the <b>bounding</b> <b>box</b> represents the maximum extent of the <b>shape</b> of the object in X and Y with respect to the user coordinate system of the object exclusive of stroke-width.) x = &quot;x-coordinate&quot; The x-coordinate of one corner of the rectangle for the largest possible offscreen buffer, where the values are either relative to the current user coordinate system (if maskUnits=&quot;userSpace&quot;) or relative to the current object (if maskUnits=&quot;objectBoundingBox&quot;). Note that the clipping path used to ...", "dateLastCrawled": "2021-12-15T15:15:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "13.3. Object Detection and <b>Bounding</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0 ...", "url": "http://d2l.ai/chapter_computer-vision/bounding-box.html", "isFamilyFriendly": true, "displayUrl": "d2l.ai/chapter_computer-vision/<b>bounding</b>-<b>box</b>.html", "snippet": "13.3.1. <b>Bounding</b> Boxes\u00b6. In object detection, we usually use a <b>bounding</b> <b>box</b> to describe the spatial location of an object. The <b>bounding</b> <b>box</b> is rectangular, which is determined by the \\(x\\) and \\(y\\) coordinates of the upper-left corner of the rectangle and the such coordinates of the lower-right corner. Another commonly used <b>bounding</b> <b>box</b> representation is the \\((x, y)\\)-axis coordinates of the <b>bounding</b> <b>box</b> center, and the width and height of the <b>box</b>. Here we define functions to convert ...", "dateLastCrawled": "2022-02-02T00:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "5 Main Types of <b>Machine</b> <b>Learning</b> Systems | by Jean de Dieu Nyandwi | Medium", "url": "https://jeande.medium.com/5-main-types-of-machine-learning-systems-fb07b0cc3d35", "isFamilyFriendly": true, "displayUrl": "https://jeande.medium.com/5-main-types-of-<b>machine</b>-<b>learning</b>-systems-fb07b0cc3d35", "snippet": "Semi-supervised <b>learning</b> is most notable in problems that involve working with massive datasets like internet image searches, image and audio recognition, and webpages classification. 4. Self-supervised <b>learning</b>. Self-supervised <b>learning</b> is one of the most exciting types of <b>machine</b> <b>learning</b> that is most applicable in computer vision and robotics.", "dateLastCrawled": "2022-01-25T04:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "In <b>machine-learning</b> image-detection tasks, IoU is used to measure the accuracy of the model\u2019s predicted <b>bounding</b> <b>box</b> with respect to the ground-truth <b>bounding</b> <b>box</b>. In this case, the IoU for the two boxes is the ratio between the overlapping area and the total area, and its value ranges from 0 (no overlap of predicted <b>bounding</b> <b>box</b> and ground-truth <b>bounding</b> <b>box</b>) to 1 (predicted <b>bounding</b> <b>box</b> and ground-truth <b>bounding</b> <b>box</b> have the exact same coordinates).", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> in <b>Computer Vision</b> - Princeton University", "url": "https://www.cs.princeton.edu/courses/archive/spring07/cos424/lectures/li-guest-lecture.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.princeton.edu/courses/archive/spring07/cos424/lectures/li-guest-lecture.pdf", "snippet": "<b>Machine</b> <b>learning</b> Speech Information retrieval Maths Computer Science Information Engineering Physics Biology Robotics Cognitive sciences Psychology. Quiz? What about this? A picture is worth a thousand words.--- Confucius or Printers\u2019 Ink Ad (1921) horizontal lines vertical blue on the top porous oblique white shadow to the left textured large green patches A picture is worth a thousand words.--- Confucius or Printers\u2019 Ink Ad (1921) A picture is worth a thousand words.--- Confucius or ...", "dateLastCrawled": "2022-01-29T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "13.4. <b>Anchor</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/anchor.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>anchor</b>.html", "snippet": "In order to train an object detection model, we need class and offset labels for each <b>anchor</b> <b>box</b>, where the former is the class of the object relevant to the <b>anchor</b> <b>box</b> and the latter is the offset of the ground-truth <b>bounding</b> <b>box</b> relative to the <b>anchor</b> <b>box</b>. During the prediction, for each image we generate multiple <b>anchor</b> boxes, predict classes and offsets for all the <b>anchor</b> boxes, adjust their positions according to the predicted offsets to obtain the predicted <b>bounding</b> boxes, and finally ...", "dateLastCrawled": "2022-01-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Why <b>Deep Learning</b> over Traditional <b>Machine</b> <b>Learning</b>? | by Sambit ...", "url": "https://towardsdatascience.com/why-deep-learning-is-needed-over-traditional-machine-learning-1b6a99177063", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/why-<b>deep-learning</b>-is-needed-over-traditional-<b>machine</b>...", "snippet": "In a simpler way, <b>Machine</b> <b>Learning</b> is set of algorithms that parse data, learn from them, and then apply what they\u2019ve learned to make ... \u201cThe <b>analogy</b> to <b>deep learning</b> is that the rocket engine is the <b>deep learning</b> models and the fuel is the huge amounts of data we can feed to these algorithms.\u201d <b>Deep Learning</b> requires high-end machines contrary to traditional <b>Machine</b> <b>Learning</b> algorithms. GPU has become a integral part now to execute any <b>Deep Learning</b> algorithm. In traditional <b>Machine</b> ...", "dateLastCrawled": "2022-01-30T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning and its Applications</b> - SlideShare", "url": "https://www.slideshare.net/ganeshn9/machine-learning-and-its-applications-138639251", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ganeshn9/<b>machine-learning-and-its-applications</b>-138639251", "snippet": "Problem Solving Approach - Example \u2022 In a <b>machine</b> <b>learning</b> approach, we will divide problem in to two parts \u2013 object detection and object recognition \u2022 We will use an algorithm like <b>bounding</b> <b>box</b> detection as an example to scan through image and detect all objects then use object recognition algorithm to recognize relevant objects \u2022 When ...", "dateLastCrawled": "2022-01-30T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ODAM: Object Detection, Association, and Mapping Using Posed RGB Video", "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Li_ODAM_Object_Detection_Association_and_Mapping_Using_Posed_RGB_Video_ICCV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021/papers/Li_ODAM_Object_Detection...", "snippet": "<b>analogy</b> to the use of 2D <b>bounding</b> boxes (BBs) in images, a 3D <b>bounding</b> volume presents a valuable abstraction of location and space, enabling for example, object-level plan- ningforrobots[13,15],learningscene-levelpriorsoverob-jects [55], or anchoring information on object instances. A robust way of inferring <b>bounding</b> volumes and associated views of individual objects in a scene is a stepping stone to-ward reconstructing, embedding and describing the objects with advanced state-of-the-art ...", "dateLastCrawled": "2022-02-01T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Deep-<b>Learning</b> Model with <b>Task-Specific Bounding Box Regressors</b> and ...", "url": "https://www.mdpi.com/1424-8220/20/18/5269/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/20/18/5269/htm", "snippet": "This paper proposes a deep-<b>learning</b> model with <b>task-specific bounding box regressors</b> (TSBBRs) and conditional back-propagation mechanisms for detection of objects in motion for advanced driver assistance system (ADAS) applications. The proposed model separates the object detection networks for objects of different sizes and applies the proposed algorithm to achieve better detection results for both larger and tinier objects. For larger objects, a neural network with a larger visual receptive ...", "dateLastCrawled": "2022-01-01T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A comprehensive guide to OCR with <b>Tesseract</b>, OpenCV and Python | by ...", "url": "https://medium.com/nanonets/a-comprehensive-guide-to-ocr-with-tesseract-opencv-and-python-fd42f69e8ca8", "isFamilyFriendly": true, "displayUrl": "https://medium.com/nanonets/a-comprehensive-guide-to-ocr-with-<b>tesseract</b>-opencv-and...", "snippet": "Deep <b>learning</b> based models (such as named entity recognition) have managed to obtain unprecedented text recognition accuracy, far beyond traditional feature extraction and <b>machine</b> <b>learning</b> approaches.", "dateLastCrawled": "2022-02-02T15:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Solved: <b>Checking in features</b> - <b>Autodesk</b> Community", "url": "https://forums.autodesk.com/t5/autocad-map-3d-forum/checking-in-features/td-p/6270481", "isFamilyFriendly": true, "displayUrl": "https://<b>forums.autodesk.com</b>/t5/autocad-map-3d-forum/<b>checking-in-features</b>/td-p/6270481", "snippet": "The &quot;<b>bounding box&quot; is like</b> a spatial filter defining the lef bottom and the right upper corner for legal objects. Are you working with UTM coordinates without zone information e.g. 32(N) and inside the shape it is define with 32(N)? 32(N) means a addition of 32000000 to the x-value. When that is true you are out of the bounding box and your ...", "dateLastCrawled": "2022-01-25T23:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "arXiv:2007.04499v1 [cs.RO] 9 Jul 2020", "url": "https://arxiv.org/pdf/2007.04499.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/2007.04499.pdf", "snippet": "contains the observed object, and the <b>bounding box is similar</b> for each valid object detected. However, for robotic grasping, there may be several methods to grasp an object. But it is essential to pick the one with the highest grasp success or with the most stable grasp, thus relying on <b>machine</b> <b>learning</b> techniques to \ufb01nd the best possible grasp. The use of convolutional neural networks is a popular technique used for <b>learning</b> features and visual models that uses a sliding window detection ...", "dateLastCrawled": "2020-07-12T09:31:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "YOLOv3 Tutorial: Understanding What is YOLOv3 and How it works?", "url": "https://bestinau.com.au/yolov3-architecture-best-model-in-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://bestinau.com.au/<b>yolov3-architecture-best-model-in-object-detection</b>", "snippet": "In many <b>machine</b> <b>learning</b> models (Logistic Regression, SVMs), in loss functions we have loss as well as a regularizer multiplied by. The job of this is to make a choice between minimizing loss and regularizing the model. Because of the scale of these two numbers being different, it is sensible to actually weigh them differently. Initially, they didn\u2019t do it and weren\u2019t getting good performance, but later thought that if they could create a weighted model, that might do the trick. These ...", "dateLastCrawled": "2022-02-02T01:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Using AI to Detect Social Distancing Violations - <b>Deep Learning Analytics</b>", "url": "https://deeplearninganalytics.org/using-ai-to-detect-social-distancing-violations/", "isFamilyFriendly": true, "displayUrl": "https://<b>deeplearninganalytics</b>.org/using-ai-to-detect-social-distancing-violations", "snippet": "Each track is basically a bounding box with an ID. So a <b>bounding box can be compared to</b> another bounding using the euclidean distance between them. Now we start our modeling. The code for that is shared below. This is the same code as in my Github. Modeling Social Distancing. The main steps that are run for every frame are: Compare the pixel distance between each track and every other track; If distance &lt; proximity threshold then, two people are too close to each other. So put safe =1 in the ...", "dateLastCrawled": "2022-01-31T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Using AI to Detect <b>Social Distancing</b> Violations | by Priya Dwivedi ...", "url": "https://medium.com/swlh/using-ai-to-detect-social-distancing-violations-4707301844be", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/using-ai-to-detect-<b>social-distancing</b>-violations-4707301844be", "snippet": "<b>Social Distancing</b> Violations Detection and Counting. At Deep <b>Learning</b> Analytics, we are very passionate about using data science and <b>machine</b> <b>learning</b> to solve problems.Please reach out to us if ...", "dateLastCrawled": "2022-01-28T16:11:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(bounding box)  is like +(outline of a shape on a piece of paper)", "+(bounding box) is similar to +(outline of a shape on a piece of paper)", "+(bounding box) can be thought of as +(outline of a shape on a piece of paper)", "+(bounding box) can be compared to +(outline of a shape on a piece of paper)", "machine learning +(bounding box AND analogy)", "machine learning +(\"bounding box is like\")", "machine learning +(\"bounding box is similar\")", "machine learning +(\"just as bounding box\")", "machine learning +(\"bounding box can be thought of as\")", "machine learning +(\"bounding box can be compared to\")"]}