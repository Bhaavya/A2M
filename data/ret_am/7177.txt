{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Watch and Learn: The Cognitive Neuroscience of <b>Learning</b> from Others ...", "url": "https://www.cell.com/trends/neurosciences/pdf/S0166-2236(21)00020-5.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cell.com/trends/neurosciences/pdf/S0166-2236(21)00020-5.pdf", "snippet": "of <b>Learning</b> from Others\u2019 Actions ... Whether <b>learning</b> to dance Gangnam Style, open a bottle of champagne, or <b>tie</b> <b>shoelaces</b>, humans learn a great deal by simply watching others [1,2]. <b>Learning</b> by observation can have many bene\ufb01ts over physical practice without observation. This is especially true in dangerous or novel environments where poor initial performance can be costly, such as <b>learning</b> to drop in on a skateboard ramp without \ufb01rst watching someone else do it successfully. Equally ...", "dateLastCrawled": "2022-02-02T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Human Brain - Exercise", "url": "http://faculty.gordonstate.edu/tmcclanahan/Health/Lecture%20Slides/Chapter%201&2/doc10.pdf", "isFamilyFriendly": true, "displayUrl": "faculty.gordonstate.edu/tmcclanahan/Health/Lecture Slides/Chapter 1&amp;2/doc10.pdf", "snippet": "<b>learning</b> <b>to tie</b> your <b>shoelaces</b>? If you are feeling uncomfortable and awkward don\u2019t worry, your brain is <b>learning</b> a new skill. Try other <b>neural</b> building and strengthening exercises with everyday movements. Use your Mental Exercise for a Better Brain When we are young the world seems filled with curious wonders, delightful discoveries, and daunting challenges. Our brains are taking in countless bits of information and we are developing lifetime skills. This burst of <b>learning</b> <b>is like</b> the ...", "dateLastCrawled": "2021-10-26T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Watch <b>and Learn: The Cognitive Neuroscience of Learning from</b> Others ...", "url": "https://www.sciencedirect.com/science/article/pii/S0166223621000205", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0166223621000205", "snippet": "Whether <b>learning</b> to dance Gangnam Style, open a bottle of champagne, or <b>tie</b> <b>shoelaces</b>, humans learn a great deal by simply watching others [1,2]. <b>Learning</b> by observation can have many benefits over physical practice without observation. This is especially true in dangerous or novel environments where poor initial performance can be costly, such as <b>learning</b> to drop in on a skateboard ramp without first watching someone else do it successfully. Equally, <b>learning</b> by watching others is ...", "dateLastCrawled": "2021-11-17T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Dendritic Computing: Branching Deeper into Machine <b>Learning</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0306452221005017", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306452221005017", "snippet": "The last decade has seen a resurgence of interest in <b>neural</b> <b>networks</b> fueled by the huge success of deep <b>learning</b> across ... far superior to the state-of-the-art deep <b>neural</b> network models especially in sensorimotor tasks\u2014a child can easily <b>tie</b> <b>shoelaces</b> while a robot would struggle with such fine manipulation. Quite naturally one therefore investigates biological <b>neural</b> <b>networks</b> in order to determine the missing parts. The basic model of a neuron used in deep <b>learning</b> is still largely the ...", "dateLastCrawled": "2022-01-29T08:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Human- versus Artificial Intelligence", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8108480/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8108480", "snippet": "<b>Like</b> our own brains, artificial <b>neural</b> <b>networks</b> are fundamentally intransparant (Nosek et al., 2011; Feldman-Barret, 2017). Therefore, trust in AI should be primarily based on its objective performance. This forms a more important base than providing trust on the basis of subjective (trickable) impressions, stories, or images aimed at belief and appeal to the user. Based on empirical validation research, developers and users can explicitly verify how well the system is doing with respect to ...", "dateLastCrawled": "2022-02-02T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Brain-shaped Mind : What the Brain Can Tell Us About the Mind", "url": "https://xn--webducation-dbb.com/wp-content/uploads/2020/01/Naomi-Goldblum-Shifra-Glick-The-brain-shaped-mind_-what-the-brain-can-tell-us-about-the-mind-Cambridge-University-Press-2001.pdf", "isFamilyFriendly": true, "displayUrl": "https://web\u00e9ducation.com/wp-content/uploads/2020/01/Naomi-Goldblum-Shifra-Glick-The...", "snippet": "Neuroscientists are now <b>learning</b> about our minds by examining how the neurons in the brain are con- nected with one another and the surrounding environment. This book explores how <b>neural</b> <b>networks</b> enable us to recognize objects and learn new things, and what happens when things go wrong. The reader is taken on a fascinating journey into what is arguably one of the most complicated and remarkable aspects of our lives. Born in New York, Naomi Goldblumoriginally studied mathematics at Yeshiva ...", "dateLastCrawled": "2022-01-31T20:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Neural Networking: Robots Learning From Video</b> | Hackaday", "url": "https://hackaday.com/2018/01/18/neural-networking-robots-learning-from-video/", "isFamilyFriendly": true, "displayUrl": "https://<b>hackaday.com</b>/2018/01/18/<b>neural-networking-robots-learning-from-video</b>", "snippet": "The latter video of robots in a pouring setting is needed in order for the TCN to create the abstraction of a hand that\u2019s independent of either a human or a robot hand. Frames from the videos ...", "dateLastCrawled": "2022-01-24T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Chapter 7 PSYC 2013</b> - <b>Learning</b> tools &amp; flashcards, for free | <b>Quizlet</b>", "url": "https://quizlet.com/372680519/chapter-7-psyc-2013-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/372680519/<b>chapter-7-psyc-2013</b>-flash-cards", "snippet": "Federico&#39;s son is 2 years old and is trying to learn how <b>to tie</b> his <b>shoelaces</b>. Federico knows how <b>to tie</b> <b>shoelaces</b> but is having a hard time explaining the steps to his son. Federico is struggling with describing his _____ memory of how <b>to tie</b> <b>shoelaces</b>. a) episodic b) procedural c) semantic d) prospective", "dateLastCrawled": "2021-11-17T06:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Does a Quora &#39;space&#39; exist focused on <b>learning</b> how to &#39;think&#39; AI? I am ...", "url": "https://www.quora.com/Does-a-Quora-space-exist-focused-on-learning-how-to-think-AI-I-am-a-neurologist-retired-Im-too-old-to-become-an-AI-programmer-However-I-wish-to-know-how-to-think-AI-particularly-as-relates-to-neuroscience", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Does-a-Quora-space-exist-focused-on-<b>learning</b>-how-to-think-AI-I...", "snippet": "Answer (1 of 2): I could not find any, but you can definitely create one. From the short question, I guess you are aiming at a new category wrt the typical ways AI and neuroscience have interacted in the past, to mention some: * inspiration in both directions: AI inspiring neuroscience studies...", "dateLastCrawled": "2022-01-16T07:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Neural</b> Representations of Procedural Knowledge", "url": "http://ccbi.cmu.edu/reprints/Mason_Just_PsychSci-2020_Journal-preprint-knots.pdf", "isFamilyFriendly": true, "displayUrl": "ccbi.cmu.edu/reprints/Mason_Just_PsychSci-2020_Journal-preprint-knots.pdf", "snippet": "In this study, 7 participants were trained <b>to tie</b> seven knots. Their <b>neural</b> representations of these seven procedures were assessed with fMRI as they imagined tying each knot. A subset of the trained participants physically tied each knot in a later fMRI session. Findings demonstrated that procedural knowledge of tying a particular knot can be reliably identified from its fMRI signature, and such procedural signatures were found here in frontal, parietal, motor, and cerebellar regions. In ...", "dateLastCrawled": "2021-12-10T16:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Watch <b>and Learn: The Cognitive Neuroscience of Learning from</b> Others ...", "url": "https://www.sciencedirect.com/science/article/pii/S0166223621000205", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0166223621000205", "snippet": "Whether <b>learning</b> to dance Gangnam Style, open a bottle of champagne, or <b>tie</b> <b>shoelaces</b>, humans learn a great deal by simply watching others [1,2]. <b>Learning</b> by observation can have many benefits over physical practice without observation. This is especially true in dangerous or novel environments where poor initial performance can be costly, such as <b>learning</b> to drop in on a skateboard ramp without first watching someone else do it successfully. Equally, <b>learning</b> by watching others is ...", "dateLastCrawled": "2021-11-17T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Watch and Learn: The Cognitive Neuroscience of <b>Learning</b> from Others ...", "url": "https://www.cell.com/trends/neurosciences/pdf/S0166-2236(21)00020-5.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cell.com/trends/neurosciences/pdf/S0166-2236(21)00020-5.pdf", "snippet": "of <b>Learning</b> from Others\u2019 Actions ... Whether <b>learning</b> to dance Gangnam Style, open a bottle of champagne, or <b>tie</b> <b>shoelaces</b>, humans learn a great deal by simply watching others [1,2]. <b>Learning</b> by observation can have many bene\ufb01ts over physical practice without observation. This is especially true in dangerous or novel environments where poor initial performance can be costly, such as <b>learning</b> to drop in on a skateboard ramp without \ufb01rst watching someone else do it successfully. Equally ...", "dateLastCrawled": "2022-02-02T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Neural</b> Representations of Procedural Knowledge", "url": "http://ccbi.cmu.edu/reprints/Mason_Just_PsychSci-2020_Journal-preprint-knots.pdf", "isFamilyFriendly": true, "displayUrl": "ccbi.cmu.edu/reprints/Mason_Just_PsychSci-2020_Journal-preprint-knots.pdf", "snippet": "(besides <b>shoelaces</b> and square knots) computer-based video training in tying knots. This training technique has proven to be effective for <b>learning</b> how <b>to tie</b> knots (Brandt &amp; Davies, 2006; Rogers, Regehr, Yeh, &amp; Howdieshell, 1998; Schwan &amp; Riempp, 2004), and imagined knot tying is one of the training techniques surgeons use for teaching suturing (Torkington, Smith, Rees, &amp; Darzi, 2000). <b>Neural</b> representations were assessed using a machine-<b>learning</b> technique applied to the fMRI data, which ...", "dateLastCrawled": "2021-12-10T16:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Human- versus Artificial Intelligence", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8108480/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8108480", "snippet": "Deep <b>learning</b> simulates a network resembling the layered <b>neural</b> <b>networks</b> of our brain. Based on large quantities of data, the network learns to recognize patterns and links to a high level of accuracy and then connect them to courses of action without knowing the underlying causal links. This implies that it is difficult to provide deep <b>learning</b> AI with some kind of transparency in how or why it has made a particular choice by, for example, by expressing an intelligible reasoning (for humans ...", "dateLastCrawled": "2022-02-02T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Learning</b> <b>to tie</b> the knot: The acquisition of functional object ...", "url": "https://www.researchgate.net/publication/320362347_Learning_to_tie_the_knot_The_acquisition_of_functional_object_representations_by_physical_and_observational_experience", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320362347_<b>Learning</b>_<b>to_tie</b>_the_knot_The...", "snippet": "PDF | Here we examined <b>neural</b> substrates for physically and observationally <b>learning</b> to construct novel objects, and characterized brain regions... | Find, read and cite all the research you need ...", "dateLastCrawled": "2021-08-26T20:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning</b> <b>to tie</b> the knot: The acquisition of functional object ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185044", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185044", "snippet": "Here we examined <b>neural</b> substrates for physically and observationally <b>learning</b> to construct novel objects, and characterized brain regions associated with each kind of <b>learning</b> using fMRI. Each participant was assigned a training partner, and for five consecutive days practiced tying one group of knots (\u201ctied\u201d condition) or watched their partner <b>tie</b> different knots (\u201cwatched\u201d condition) while a third set of knots remained untrained. Functional MRI was obtained prior to and ...", "dateLastCrawled": "2021-08-28T11:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Dendritic Computing: Branching Deeper into Machine <b>Learning</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0306452221005017", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306452221005017", "snippet": "It is clear that biological neuronal <b>networks</b> are far superior to the state-of-the-art deep <b>neural</b> network models especially in sensorimotor tasks\u2014a child can easily <b>tie</b> <b>shoelaces</b> while a robot would struggle with such fine manipulation. Quite naturally one therefore investigates biological <b>neural</b> <b>networks</b> in order to determine the missing parts.", "dateLastCrawled": "2022-01-29T08:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Neural Networking: Robots Learning From Video</b> | Hackaday", "url": "https://hackaday.com/2018/01/18/neural-networking-robots-learning-from-video/", "isFamilyFriendly": true, "displayUrl": "https://<b>hackaday.com</b>/2018/01/18/<b>neural-networking-robots-learning-from-video</b>", "snippet": "The researchers give their robot a <b>similar</b> head start by first training a deep <b>neural</b> network called a Time-Contrastive Network (TCN). Once trained, the TCN can be given an image from a video ...", "dateLastCrawled": "2022-01-24T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Does a Quora &#39;space&#39; exist focused on <b>learning</b> how to &#39;think&#39; AI? I am ...", "url": "https://www.quora.com/Does-a-Quora-space-exist-focused-on-learning-how-to-think-AI-I-am-a-neurologist-retired-Im-too-old-to-become-an-AI-programmer-However-I-wish-to-know-how-to-think-AI-particularly-as-relates-to-neuroscience", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Does-a-Quora-space-exist-focused-on-<b>learning</b>-how-to-think-AI-I...", "snippet": "Answer (1 of 2): I could not find any, but you can definitely create one. From the short question, I guess you are aiming at a new category wrt the typical ways AI and neuroscience have interacted in the past, to mention some: * inspiration in both directions: AI inspiring neuroscience studies...", "dateLastCrawled": "2022-01-16T07:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Chapter 6 - Vocabulary and Quiz Questions Flashcards | Quizlet", "url": "https://quizlet.com/448556023/chapter-6-vocabulary-and-quiz-questions-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/448556023/chapter-6-vocabulary-and-quiz-questions-flash-cards", "snippet": "<b>Learning</b> c. Memory d. Priming. c _____ refers to the process by which information gets into memory storage. a. Transmission b. Decay c. Encoding d. Retrieval . b. Attention, deep processing, elaboration, and the use of mental imagery are all part of _____ processes. a. chunking b. encoding c. storage d. retrieval. d _____ is the ability to maintain attention to a selected stimulus for a prolonged period of time. a. elaboration b. divided attention c. multitasking d. sustained attention. a ...", "dateLastCrawled": "2022-01-22T10:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Watch <b>and Learn: The Cognitive Neuroscience of Learning from</b> Others ...", "url": "https://www.sciencedirect.com/science/article/pii/S0166223621000205", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0166223621000205", "snippet": "Whether <b>learning</b> to dance Gangnam Style, open a bottle of champagne, or <b>tie</b> <b>shoelaces</b>, humans learn a great deal by simply watching others [1,2]. <b>Learning</b> by observation <b>can</b> have many benefits over physical practice without observation. This is especially true in dangerous or novel environments where poor initial performance <b>can</b> be costly, such as <b>learning</b> to drop in on a skateboard ramp without first watching someone else do it successfully. Equally, <b>learning</b> by watching others is ...", "dateLastCrawled": "2021-11-17T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning</b> <b>to tie</b> the knot: The acquisition of functional object ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185044", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185044", "snippet": "Here we examined <b>neural</b> substrates for physically and observationally <b>learning</b> to construct novel objects, and characterized brain regions associated with each kind of <b>learning</b> using fMRI. Each participant was assigned a training partner, and for five consecutive days practiced tying one group of knots (\u201ctied\u201d condition) or watched their partner <b>tie</b> different knots (\u201cwatched\u201d condition) while a third set of knots remained untrained. Functional MRI was obtained prior to and ...", "dateLastCrawled": "2021-08-28T11:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Neural Networking: Robots Learning From Video</b> | Hackaday", "url": "https://hackaday.com/2018/01/18/neural-networking-robots-learning-from-video/", "isFamilyFriendly": true, "displayUrl": "https://<b>hackaday.com</b>/2018/01/18/<b>neural-networking-robots-learning-from-video</b>", "snippet": "The researchers give their robot a similar head start by first training a deep <b>neural</b> network called a Time-Contrastive Network (TCN). Once trained, the TCN <b>can</b> be given an image from a video ...", "dateLastCrawled": "2022-01-24T18:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Learning</b> <b>to tie</b> the knot: The acquisition of functional object ...", "url": "https://www.researchgate.net/publication/320362347_Learning_to_tie_the_knot_The_acquisition_of_functional_object_representations_by_physical_and_observational_experience", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320362347_<b>Learning</b>_<b>to_tie</b>_the_knot_The...", "snippet": "PDF | Here we examined <b>neural</b> substrates for physically and observationally <b>learning</b> to construct novel objects, and characterized brain regions... | Find, read and cite all the research you need ...", "dateLastCrawled": "2021-08-26T20:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The Brain-shaped Mind : What the Brain <b>Can</b> Tell Us About the Mind", "url": "https://xn--webducation-dbb.com/wp-content/uploads/2020/01/Naomi-Goldblum-Shifra-Glick-The-brain-shaped-mind_-what-the-brain-can-tell-us-about-the-mind-Cambridge-University-Press-2001.pdf", "isFamilyFriendly": true, "displayUrl": "https://web\u00e9ducation.com/wp-content/uploads/2020/01/Naomi-Goldblum-Shifra-Glick-The...", "snippet": "Neuroscientists are now <b>learning</b> about our minds by examining how the neurons in the brain are con- nected with one another and the surrounding environment. This book explores how <b>neural</b> <b>networks</b> enable us to recognize objects and learn new things, and what happens when things go wrong. The reader is taken on a fascinating journey into what is arguably one of the most complicated and remarkable aspects of our lives. Born in New York, Naomi Goldblumoriginally studied mathematics at Yeshiva ...", "dateLastCrawled": "2022-01-31T20:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Computational Theory of Mind (Stanford Encyclopedia of Philosophy)", "url": "https://plato.stanford.edu/entries/computational-mind/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/computational-mind", "snippet": "For instance, there are <b>neural</b> <b>networks</b> that replace backpropagation with more realistic <b>learning</b> algorithms, such as a reinforcement <b>learning</b> algorithm (Pozzi, Boht\u00e9, and Roelfsema 2019, Other Internet Resources) or an unsupervised <b>learning</b> algorithm (Krotov and Hopfield 2019). There are also <b>neural</b> <b>networks</b> whose nodes output discrete spikes roughly akin to those emitted by real neurons in the brain (Maass 1996; Buesing, Bill, Nessler, and Maass 2011).", "dateLastCrawled": "2022-01-30T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Human- versus Artificial Intelligence", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8108480/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8108480", "snippet": "Deep <b>learning</b> simulates a network resembling the layered <b>neural</b> <b>networks</b> of our brain. Based on large quantities of data, the network learns to recognize patterns and links to a high level of accuracy and then connect them to courses of action without knowing the underlying causal links. This implies that it is difficult to provide deep <b>learning</b> AI with some kind of transparency in how or why it has made a particular choice by, for example, by expressing an intelligible reasoning (for humans ...", "dateLastCrawled": "2022-02-02T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Does a Quora &#39;space&#39; exist focused on <b>learning</b> how to &#39;think&#39; AI? I am ...", "url": "https://www.quora.com/Does-a-Quora-space-exist-focused-on-learning-how-to-think-AI-I-am-a-neurologist-retired-Im-too-old-to-become-an-AI-programmer-However-I-wish-to-know-how-to-think-AI-particularly-as-relates-to-neuroscience", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Does-a-Quora-space-exist-focused-on-<b>learning</b>-how-to-think-AI-I...", "snippet": "Answer (1 of 2): I could not find any, but you <b>can</b> definitely create one. From the short question, I guess you are aiming at a new category wrt the typical ways AI and neuroscience have interacted in the past, to mention some: * inspiration in both directions: AI inspiring neuroscience studies...", "dateLastCrawled": "2022-01-16T07:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Nervous System CHAPTER 11 - Stunner - HOME", "url": "http://devduttpatel.weebly.com/uploads/9/5/9/0/959041/the_nervous_system_chapter_11.pdf", "isFamilyFriendly": true, "displayUrl": "devduttpatel.weebly.com/uploads/9/5/9/0/959041/the_nervous_system_chapter_11.pdf", "snippet": "\u2022 <b>Neural</b> transmission occurs along axons, due to an action potential that causes depolarization of the neuron. \u2022 Electrochemical communication occurs between cells at the synapse. 11.2 The Central Nervous System \u2022 The central nervous system is the body\u2019s control centre. It consists of the brain and spinal cord. \u2022 The brain includes centres that control involuntary responses and voluntary responses. \u2022 The cerebrum is the largest part of the brain. It contains four pairs of lobes ...", "dateLastCrawled": "2021-11-09T10:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "9 <b>Exercises That Challenge Your Body</b> and Brain For A Satisfying Body ...", "url": "https://www.gymguider.com/9-exercises-that-challenge-your-body-and-brain-for-a-satisfying-body-changing-workout/", "isFamilyFriendly": true, "displayUrl": "https://www.gymguider.com/9-<b>exercises-that-challenge-your-body</b>-and-brain-for-a...", "snippet": "Think of all the amazing things your hands do: grip, write, <b>tie</b> your <b>shoelaces</b>, perhaps play the piano or climb up the side of a mountain. Improving hand dexterity improves the <b>neural</b> <b>networks</b> in the brain that control these fine motor skills. And grip strength is important too. How to: Start in a kneeling position with your hands flat on the floor, fingers spread wide. Lift your palm and thumb off the floor, but keep the base of your first knuckle of the other fingers on the floor as you ...", "dateLastCrawled": "2022-01-20T05:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Learning</b> <b>to tie</b> the knot: The acquisition of functional object ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185044", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185044", "snippet": "Here we examined <b>neural</b> substrates for physically and observationally <b>learning</b> to construct novel objects, and characterized brain regions associated with each kind of <b>learning</b> using fMRI. Each participant was assigned a training partner, and for five consecutive days practiced tying one group of knots (\u201ctied\u201d condition) or watched their partner <b>tie</b> different knots (\u201cwatched\u201d condition) while a third set of knots remained untrained. Functional MRI was obtained prior to and ...", "dateLastCrawled": "2021-08-28T11:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Learning</b> <b>to tie</b> the knot: The acquisition of functional object ...", "url": "https://www.researchgate.net/publication/320362347_Learning_to_tie_the_knot_The_acquisition_of_functional_object_representations_by_physical_and_observational_experience", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320362347_<b>Learning</b>_<b>to_tie</b>_the_knot_The...", "snippet": "PDF | Here we examined <b>neural</b> substrates for physically and observationally <b>learning</b> to construct novel objects, and characterized brain regions... | Find, read and cite all the research you need ...", "dateLastCrawled": "2021-08-26T20:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Human- versus Artificial Intelligence", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8108480/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8108480", "snippet": "Deep <b>learning</b> simulates a network resembling the layered <b>neural</b> <b>networks</b> of our brain. Based on large quantities of data, the network learns to recognize patterns and links to a high level of accuracy and then connect them to courses of action without knowing the underlying causal links. This implies that it is difficult to provide deep <b>learning</b> AI with some kind of transparency in how or why it has made a particular choice by, for example, by expressing an intelligible reasoning (for humans ...", "dateLastCrawled": "2022-02-02T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Watch <b>and Learn: The Cognitive Neuroscience of Learning from</b> Others ...", "url": "https://www.sciencedirect.com/science/article/pii/S0166223621000205", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0166223621000205", "snippet": "Whether <b>learning</b> to dance Gangnam Style, open a bottle of champagne, or <b>tie</b> <b>shoelaces</b>, humans learn a great deal by simply watching others [1,2]. <b>Learning</b> by observation <b>can</b> have many benefits over physical practice without observation. This is especially true in dangerous or novel environments where poor initial performance <b>can</b> be costly, such as <b>learning</b> to drop in on a skateboard ramp without first watching someone else do it successfully. Equally, <b>learning</b> by watching others is ...", "dateLastCrawled": "2021-11-17T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Dendritic Computing: Branching Deeper into Machine <b>Learning</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0306452221005017", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306452221005017", "snippet": "It is clear that biological neuronal <b>networks</b> are far superior to the state-of-the-art deep <b>neural</b> network models especially in sensorimotor tasks\u2014a child <b>can</b> easily <b>tie</b> <b>shoelaces</b> while a robot would struggle with such fine manipulation. Quite naturally one therefore investigates biological <b>neural</b> <b>networks</b> in order to determine the missing parts.", "dateLastCrawled": "2022-01-29T08:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Computational Theory of Mind (Stanford Encyclopedia of Philosophy)", "url": "https://plato.stanford.edu/entries/computational-mind/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/computational-mind", "snippet": "<b>Neural</b> <b>networks</b> <b>can</b> also manipulate symbols satisfying these two conditions: as just noted, one <b>can</b> implement a Turing-style model in a <b>neural</b> network. Many discussions of the symbolic/non-symbolic dichotomy employ a more robust notion of \u201csymbol\u201d. On the more robust approach, a symbol is the sort of thing that represents a subject matter. Thus, something is a symbol only if it has semantic or representational properties. If we employ this more robust notion of symbol, then the symbolic ...", "dateLastCrawled": "2022-01-30T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is the difference between deep <b>learning</b> and usual machine <b>learning</b> ...", "url": "https://news.ycombinator.com/item?id=11840175", "isFamilyFriendly": true, "displayUrl": "https://news.ycombinator.com/item?id=11840175", "snippet": "Feature <b>Learning</b>. Deep <b>Neural</b> <b>Networks</b> <b>can</b> learn features from essentially raw data. Usual machine <b>learning</b> starts with features engineered manually. DNNs also learn to predict from the features they learn, so you cold say (very roughly) &quot;DNN = usual machine <b>learning</b> + feature <b>learning</b>&quot;. In practice manually engineering features is a time-consuming &quot;guess-and-check&quot; process which benefits from domain expertise. Feature <b>Learning</b>, otoh, is more automatic and benefits from data, computing ...", "dateLastCrawled": "2021-06-21T09:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Neural Representations of Procedural Knowledge</b> - Robert A. Mason ...", "url": "https://journals.sagepub.com/doi/full/10.1177/0956797620916806", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/0956797620916806", "snippet": "In this study, 7 participants were trained <b>to tie</b> seven knots. Their <b>neural</b> representations of these seven procedures were assessed with fMRI as they imagined tying each knot. A subset of the trained participants physically tied each knot in a later fMRI session. Findings demonstrated that procedural knowledge of tying a particular knot <b>can</b> be reliably identified from its fMRI signature, and such procedural signatures were found here in frontal, parietal, motor, and cerebellar regions. In ...", "dateLastCrawled": "2022-01-17T17:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A review of motor <b>neural</b> system robotic modeling approaches and ...", "url": "https://link.springer.com/article/10.1007%2Fs00422-021-00918-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00422-021-00918-1", "snippet": "Such similarity in the organization <b>can</b> be seen in <b>neural</b> <b>networks</b> models of the robot and human.This requirement is due to spinal cord, central pattern generators (CPG). Examples of the organization of the vertebrates spinal cord neurons V0v and arthropods thoracic ganglia EL neurons was investigated in Jay and McLean . They participate in regulation and switching between exploratory and danger avoidance behavior. Comparing the CPG in the vertebrate spinal cord and in the arthropod thoracic ...", "dateLastCrawled": "2022-01-31T15:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why <b>is forgetting different for driving and calculus</b>? I learned to ...", "url": "https://www.quora.com/Why-is-forgetting-different-for-driving-and-calculus-I-learned-to-drive-I-also-learned-calculus-I-still-remember-how-to-drive-but-I-have-forgotten-calculus-Why", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-<b>is-forgetting-different-for-driving-and-calculus</b>", "snippet": "Answer (1 of 7): There are many different types of memory. Each type of memory works according to different <b>neural</b> mechanisms, has different properties, and in most cases is managed by different parts of the brain. Two of the more commonly known types of memory are procedural memory (memory for ...", "dateLastCrawled": "2022-01-30T16:12:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> (ML) and <b>Neural</b> <b>Networks</b> (NN)\u2026 An Intuitive ...", "url": "https://medium.com/visionary-hub/machine-learning-ml-and-neural-networks-nn-an-intuitive-walkthrough-76bdaba8b0e3", "isFamilyFriendly": true, "displayUrl": "https://medium.com/visionary-hub/<b>machine</b>-<b>learning</b>-ml-and-<b>neural</b>-<b>networks</b>-nn-an...", "snippet": "The process of <b>learning</b> artificial intelligence, <b>machine</b> <b>learning</b>, and how to code <b>neural</b> <b>networks</b> is no doubt intimidating. That being said, I genuinely believe that every single one of you who ...", "dateLastCrawled": "2022-01-30T17:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Neural</b> <b>Networks</b>: Analogies. When our brains form analogies, they\u2026 | by ...", "url": "https://towardsdatascience.com/neural-networks-analogies-7ebeb3ac5d5e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>neural</b>-<b>networks</b>-analogies-7ebeb3ac5d5e", "snippet": "This is called \u2018transfer <b>learning</b>\u2019, when we form a generalization, an <b>analogy</b> between two tasks. I\u2019ll outline a potential route to artificial <b>neural</b> <b>networks</b> which exhibit transfer <b>learning</b>: First, Sparse Distributed Representations. Numenta\u2019s Hierarchical Te m poral Memory, along with other techniques, relies upon a sparse distributed representation. An example of this is a very long string of ones and zeroes, where almost all the values are zero \u2014 there is a sparse distribution ...", "dateLastCrawled": "2022-01-28T03:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Neural Networks: Forming Analogies</b> | by Anthony Repetto | Towards Data ...", "url": "https://towardsdatascience.com/neural-networks-forming-analogies-587557c3b26e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>neural-networks-forming-analogies</b>-587557c3b26e", "snippet": "Where two systems behave similarly, a single <b>analogy</b> describes them both. <b>Learning</b> Something New. Artificial <b>neural</b> <b>networks</b> can now avoid catastrophic forgetting, which was a major stumbling block. Previously, when a <b>neural</b> network was trained on a new task, it was either too malleable, <b>learning</b> the new task while forgetting the old one, or it was too rigid, remembering the first task while never <b>learning</b> the second. This advancement is an important step toward transfer <b>learning</b>, yet it ...", "dateLastCrawled": "2021-11-26T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Complete Guide To <b>Artificial Neural Network</b> In <b>Machine</b> <b>Learning</b>", "url": "https://www.softwaretestinghelp.com/artificial-neural-network/", "isFamilyFriendly": true, "displayUrl": "https://www.softwaretestinghelp.com/<b>artificial-neural-network</b>", "snippet": "Let\u2019s explore more about <b>Machine</b> <b>Learning</b> And <b>Artificial Neural Network</b>!! =&gt; ... Biological Neuron <b>Analogy</b>: The ANN has a human brain-inspired structure and functionality. Fault Tolerance: These <b>networks</b> are highly tolerant as the information is distributed in layers and computation occurs in real-time. Structure Of ANN. Artificial <b>Neural</b> <b>Networks</b> are processing elements either in the form of algorithms or hardware devices modeled after the neuronal structure of a human brain cerebral ...", "dateLastCrawled": "2022-01-31T05:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "<b>Machine</b> <b>learning</b> models, or, more specifically, the predictors induced by a <b>machine</b> <b>learning</b> algorithm on the basis of suitable training data, are not immediately understandable most of the time. This is especially true for the most \u201cfashionable\u201d class of ML algorithms these days, namely deep <b>neural</b> <b>networks</b>. On the contrary, a <b>neural</b> ...", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> Mar. 04, 2016 ... forecasted pieces into a complete forecast by superposing these individual forecasts Several extensions to <b>neural</b> <b>networks</b>, time- lagged <b>machine</b> <b>learning</b> models\u2026 44. A time-series method incorporating predictors Constant predictors at initial time point Varying predictors at multiple time points Creates a sort of correlation web between predictors and time points Can handle multiple time lags and multivariate outcomes Can handle any GLM outcome ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep <b>neural</b> network models, and it has been used for conducting ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Understanding Machine Learning by Analogy</b> with a Simple Contour Map ...", "url": "https://contemplations.blog/machine-learning-analogy-countour-map/", "isFamilyFriendly": true, "displayUrl": "https://<b>contemplations</b>.blog/<b>machine</b>-<b>learning</b>-<b>analogy</b>-countour-map", "snippet": "The Basis for <b>Machine</b> <b>Learning</b> by <b>Analogy</b>, Using a Contour Map. In this post, we will take a closer look at <b>Machine</b> <b>Learning</b> and its nephew, Deep <b>Learning</b>. There is no \u201c<b>Learning</b>\u201d (in the human sense) in either <b>Machine</b> <b>learning</b> or Deep <b>Learning</b>, there are only quite simple and readily available mathematical procedures which allow us to adapt parameters of many kinds of parameterized systems (or <b>networks</b>), such as a <b>neural</b> network, in such a way that the system (or network), together with ...", "dateLastCrawled": "2022-02-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Neural Networks and Learning Machines</b> - uniba.sk", "url": "http://dai.fmph.uniba.sk/courses/NN/haykin.neural-networks.3ed.2009.pdf", "isFamilyFriendly": true, "displayUrl": "dai.fmph.uniba.sk/courses/NN/haykin.<b>neural</b>-<b>networks</b>.3ed.2009.pdf", "snippet": "<b>Neural Networks and Learning Machines</b> Third Edition Simon Haykin McMaster University Hamilton, Ontario, Canada New York Boston San Francisco London Toronto Sydney Tokyo Singapore Madrid Mexico City Munich Paris Cape Town Hong Kong Montreal. Library of Congress Cataloging-in-Publication Data Haykin, Simon <b>Neural networks and learning machines</b> / Simon Haykin.\u20143rd ed. p. cm. Rev. ed of: <b>Neural</b> <b>networks</b>. 2nd ed., 1999. Includes bibliographical references and index. ISBN-13: 978-0-13-147139-9 ...", "dateLastCrawled": "2022-02-02T18:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "deep-<b>learning</b>-coursera/Week 1 Quiz - Introduction to deep <b>learning</b>.md ...", "url": "https://github.com/Kulbear/deep-learning-coursera/blob/master/Neural%20Networks%20and%20Deep%20Learning/Week%201%20Quiz%20-%20Introduction%20to%20deep%20learning.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/Kulbear/deep-<b>learning</b>-coursera/blob/master/<b>Neural</b> <b>Networks</b> and Deep...", "snippet": "Week 1 Quiz - Introduction to deep <b>learning</b>. What does the <b>analogy</b> \u201cAI is the new electricity\u201d refer to? AI is powering personal devices in our homes and offices, similar to electricity. Through the \u201csmart grid\u201d, AI is delivering a new wave of electricity. AI runs on computers and is thus powered by electricity, but it is letting computers do things not possible before. Similar to electricity starting about 100 years ago, AI is transforming multiple industries. Note: Andrew ...", "dateLastCrawled": "2022-02-03T05:16:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Artificial Neural Networks for <b>Machine</b> <b>Learning</b> - Every aspect you need ...", "url": "https://data-flair.training/blogs/artificial-neural-networks-for-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>data-flair</b>.training/blogs/artificial-neural-networks-", "snippet": "The functioning of the Artificial <b>Neural Networks is similar</b> to the way neurons work in our nervous system. The Neural Networks go back to the early 1970s when Warren S McCulloch and Walter Pitts coined this term. In order to understand the workings of ANNs, let us first understand how it is structured. In a neural network, there are three essential layers \u2013 Input Layers. The input layer is the first layer of an ANN that receives the input information in the form of various texts, numbers ...", "dateLastCrawled": "2022-02-03T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b> @ Stanford - A Cheat Sheet", "url": "http://christiansch.github.io/machine-learning-cheat-sheet/", "isFamilyFriendly": true, "displayUrl": "christiansch.github.io/<b>machine</b>-<b>learning</b>-cheat-sheet", "snippet": "<b>Machine Learning @ Coursera</b> A cheat sheet. This cheatsheet wants to provide an overview of the concepts and the used formulas and definitions of the \u00bb<b>Machine</b> <b>Learning</b>\u00ab online course at coursera. Last changed: February 17th, 2015. Please note: I changed the notation very slighty. I&#39;ll denote vectors with a little arrow on the top. Example: $\\vec\\theta$ The octave tutorial that was part of the seond week is available as a script here. Week 1 Introduction <b>Machine</b> <b>Learning</b> \u00bbWell-posed ...", "dateLastCrawled": "2021-11-01T03:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> | a blog devoted to topics in a rapidly growing field", "url": "https://wp.wwu.edu/machinelearning/", "isFamilyFriendly": true, "displayUrl": "https://wp.wwu.edu/<b>machinelearning</b>", "snippet": "Supervised <b>learning</b> in <b>machine</b> <b>learning</b> is one method for the model to learn and understand data. There are other types of <b>learning</b>, such as unsupervised and reinforcement <b>learning</b>, but those are topics for another time and another blog post. With supervised <b>learning</b>, a model is given a set of labeled training data. The model learns to make predictions based on this training data, so the more training data the model has access to, the better it gets at making predictions. With training data ...", "dateLastCrawled": "2022-02-03T09:12:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How <b>Machine Learning is Transforming Healthcare at Google and</b> Beyond ...", "url": "https://towardsdatascience.com/how-machine-learning-is-transforming-healthcare-at-google-and-beyond-d4f664b7e27c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-<b>machine-learning-is-transforming-healthcare-at</b>...", "snippet": "Over the past ~5 years, <b>machine</b> <b>learning</b> has become incredibly good at analyzing images, largely thanks to a type of model called a ... <b>Just as neural networks</b> can be trained to spot diseases in images, so too can they be trained to parse documents and forms. For example, we might use models to analyze medical intake forms, converting handwriting to text and organizing that text semantically so that it can be stored in a database.\u00b9 . Using a ML Vision model, you could extract handwriting to ...", "dateLastCrawled": "2022-01-18T16:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Amp: A <b>modular approach to machine learning in atomistic simulations</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0010465516301266", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0010465516301266", "snippet": "A common <b>machine</b>-<b>learning</b> model suitable for large data sets is the artificial neural network (referred to here <b>just as neural networks</b>). Historically, the neural network was considered a very simple model of how the nervous system processes information. The first mathematical model was developed in 1943 by McCulloch and Pitts", "dateLastCrawled": "2021-12-17T22:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Visualizing Representations: Deep Learning and Human</b> Beings - colah&#39;s blog", "url": "https://colah.github.io/posts/2015-01-Visualizing-Representations/", "isFamilyFriendly": true, "displayUrl": "https://colah.github.io/posts/2015-01-Visualizing-Representations", "snippet": "I think these techniques form a set of basic building blocks to try and understand <b>machine</b> <b>learning</b>, and specifically to understand the internal operations of deep neural networks. Deep neural networks are an approach to <b>machine</b> <b>learning</b> that has revolutionized computer vision and speech recognition in the last few years, blowing the previous state of the art results out of the water. They\u2019ve also brought promising results to many other areas, including language understanding and <b>machine</b> ...", "dateLastCrawled": "2022-02-02T13:29:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>learning</b>: neural networks", "url": "https://stanford-cs221.github.io/autumn2021-extra/modules/machine-learning/neural-networks.pdf", "isFamilyFriendly": true, "displayUrl": "https://stanford-cs221.github.io/autumn2021-extra/modules/<b>machine</b>-<b>learning</b>/neural...", "snippet": "Beyond <b>learning</b> hierarchical feature representations, deep neural networks can be interpreted in a few other ways. One perspective is that each layer can be thought of as performing some computation, and therefore deep <b>neural networks can be thought of as</b> performing multiple steps of computation.", "dateLastCrawled": "2022-01-31T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The role <b>of bias in Neural Networks</b> | Pico", "url": "https://www.pico.net/kb/the-role-of-bias-in-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.pico.net/kb/the-role-<b>of-bias-in-neural-networks</b>", "snippet": "<b>Bias in Neural Networks can be thought of as</b> analogous to the role of a constant in a linear function, whereby the line is effectively transposed by the constant value. In a scenario with no bias, the input to the activation function is &#39;x&#39; multiplied by the connection weight &#39;w 0 &#39;. In a scenario with bias, the input to the activation function is &#39;x&#39; times the connection weight &#39;w 0 &#39; plus the bias times the connection weight for the bias &#39;w 1 &#39;. This has the effect of shifting the ...", "dateLastCrawled": "2022-02-02T13:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Recurrent Neural Network</b> Definition | DeepAI", "url": "https://deepai.org/machine-learning-glossary-and-terms/recurrent-neural-network", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/<b>machine</b>-<b>learning</b>-glossary-and-terms/<b>recurrent-neural-network</b>", "snippet": "<b>Recurrent Neural Networks can be thought of as</b> a series of networks linked together. They often have a chain-like architecture, making them applicable for tasks such as speech recognition, language translation, etc. An RNN can be designed to operate across sequences of vectors in the input, output, or both. For example, a sequenced input may take a sentence as an input and output a positive or negative sentiment value. Alternatively, a sequenced output may take an image as an input, and ...", "dateLastCrawled": "2022-01-29T05:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Meta-Learning</b>: <b>Learning</b> to Learn. Extensive innovation for <b>machine</b> ...", "url": "https://towardsdatascience.com/meta-learning-learning-to-learn-a0365a6a44f0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>meta-learning</b>-<b>learning</b>-to-learn-a0365a6a44f0", "snippet": "Furthermore, evolutionary algorithms can be reflected as inter-life <b>learning</b>, whereas <b>neural networks can be thought of as</b> intra-life <b>learning</b>. Evolutionary algorithms and neural networks are likely the main factor to accomplish an optimized algorithm in deep reinforcement <b>learning</b> techniques. Evolutionary Algorithms. Bingham, Macke, and Miikkulainen (2020)\u00b9\u2070 emphasize there are four main features associated with evolutionary algorithms, which are, numbers of network layers, numbers of ...", "dateLastCrawled": "2022-02-03T13:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Artificial intelligence and machine learning: What</b> managers need ...", "url": "https://www.researchgate.net/publication/338130773_Artificial_intelligence_and_machine_learning_What_managers_need_to_know", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338130773_Artificial_intelligence_and_<b>machine</b>...", "snippet": "The field of <b>neural networks can be thought of as</b> being related to artificial intelligence, <b>machine</b> <b>learning</b>, parallel processing, statistics, and other fields. The attraction of neural networks ...", "dateLastCrawled": "2022-01-31T04:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Why are <b>deep learning models so popular</b>? - <b>Solita Data</b>", "url": "https://data.solita.fi/why-are-deep-learning-models-so-popular/", "isFamilyFriendly": true, "displayUrl": "https://data.solita.fi/why-are-<b>deep-learning-models-so-popular</b>", "snippet": "The idea of training a <b>machine</b> to transform numerical representations of inputs to outputs applies to most <b>machine</b> <b>learning</b> models, so what makes neural networks work special? Three reasons come to mind. First, the structure of a neural network is specified only very broadly before the model is trained, which gives a lot of room for the model to adjust during training. In statistical terms, large <b>neural networks can be thought of as</b> being somewhere in between parametric and nonparametric ...", "dateLastCrawled": "2021-12-26T14:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Proposal on <b>Machine Learning</b> via Dynamical Systems | SpringerLink", "url": "https://link.springer.com/article/10.1007/s40304-017-0103-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s40304-017-0103-z", "snippet": "In the framework of supervised <b>learning</b>, this gives rise to a new class of control problems. In this view, the deep <b>neural networks can be thought of as</b> being discrete dynamical systems. Compared with deep neural networks, there are several potential advantages with a continuous approach. 1.", "dateLastCrawled": "2022-01-30T23:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Why is it popular <b>to use machine/deep learning to solve</b> PDEs?", "url": "https://www.researchgate.net/post/Why_is_it_popular_to_use_machine_deep_learning_to_solve_PDEs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/Why_is_it_popular_<b>to_use_machine_deep_learning_to</b>...", "snippet": "<b>Machine</b> / deep <b>learning</b> is becoming popular because it has recently become feasible on regular computers. In neuroscience it has been proposed to model how the brain works, but the proposal has ...", "dateLastCrawled": "2022-01-27T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Puzzles of modern machine learning</b> \u2013 Windows On Theory", "url": "https://windowsontheory.org/2019/11/15/puzzles-of-modern-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://windowsontheory.org/2019/11/15/<b>puzzles-of-modern-machine-learning</b>", "snippet": "<b>Machine</b> <b>learning</b> offers many opportunities for theorists; there are many more questions than answers, and it is clear that a better theoretical understanding of what makes certain training procedures work or fail is desperately needed. Moreover, recent advances in software frameworks made it much easier to test out intuitions and conjectures. While in the past running training procedures might have required a Ph.D in <b>machine</b> <b>learning</b>, recently the &quot;barrier to entry&quot; was reduced to first to ...", "dateLastCrawled": "2022-01-18T19:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Parameterized quantum circuits as <b>machine</b> <b>learning</b> models - IOPscience", "url": "https://iopscience.iop.org/article/10.1088/2058-9565/ab4eb5", "isFamilyFriendly": true, "displayUrl": "https://iopscience.iop.org/article/10.1088/2058-9565/ab4eb5", "snippet": "Parameterized quantum <b>circuit</b> models can be trained for a variety of <b>machine</b> <b>learning</b> tasks, such as supervised and unsupervised <b>learning</b>, on both classical and quantum data. This figure shows examples from each category. In the top-left panel, the model learns to recognize patterns to classify the classical data. In the top-right panel, the model learns the probability distribution of the training data and can generate new synthetic data accordingly. For supervised <b>learning</b> of quantum data ...", "dateLastCrawled": "2021-12-01T23:52:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(neural networks)  is like +(learning to tie shoelaces)", "+(neural networks) is similar to +(learning to tie shoelaces)", "+(neural networks) can be thought of as +(learning to tie shoelaces)", "+(neural networks) can be compared to +(learning to tie shoelaces)", "machine learning +(neural networks AND analogy)", "machine learning +(\"neural networks is like\")", "machine learning +(\"neural networks is similar\")", "machine learning +(\"just as neural networks\")", "machine learning +(\"neural networks can be thought of as\")", "machine learning +(\"neural networks can be compared to\")"]}