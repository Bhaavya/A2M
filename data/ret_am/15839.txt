{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>gentle guide to deep learning object detection</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2018/05/14/a-<b>gentle-guide-to-deep-learning-object-detection</b>", "snippet": "Figure 5: In this visual example of Intersection over Union (<b>IoU</b>), the ground-truth bounding box (green) can be compared to the predicted bounding box (red).<b>IoU</b> is used with mean Average Precision (mAP) to evaluate the accuracy of a deep <b>learning</b> object detector. The simple equation to calculate <b>IoU</b> is shown on the right.. You\u2019ll typically find <b>IoU</b> and mAP used to evaluate the performance of HOG + Linear SVM detectors, Haar cascades, and deep <b>learning</b>-based methods; however, keep in mind ...", "dateLastCrawled": "2022-01-26T13:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Object detection with deep <b>learning</b> and OpenCV - <b>PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2017/09/11/object-detection-with-deep-<b>learning</b>-and-opencv", "snippet": "When it comes to deep <b>learning</b>-based object detection there are three primary object detection methods that you\u2019ll likely encounter: Faster R-CNNs (Ren et al., 2015); You Only Look Once (YOLO) (Redmon et al., 2015) Single Shot Detectors (SSDs) (Liu et al., 2015) Faster R-CNNs are likely the most \u201cheard of\u201d method for object detection using deep <b>learning</b>; however, the technique can be difficult to understand (especially for beginners in deep <b>learning</b>), hard to implement, and challenging ...", "dateLastCrawled": "2022-01-30T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Object Detection Guide</b> | Fritz AI", "url": "https://www.fritz.ai/object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.fritz.ai/<b>object-detection</b>", "snippet": "<b>Object detection</b> is a <b>computer</b> vision technique that allows us to <b>identify</b> and locate <b>objects</b> in an image or video. With this kind of identification and localization, <b>object detection</b> can be used to count <b>objects</b> in a scene and determine and track their precise locations, all while accurately labeling them. Imagine, for example, an image that contains two cats and a person. <b>Object detection</b> allows us to at once classify the types of things found while also locating instances of them within ...", "dateLastCrawled": "2022-01-29T01:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Gentle Introduction to Object Recognition With Deep <b>Learning</b>", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/object-recognition-with-deep-learnin", "snippet": "A <b>computer</b> vision technique is used to propose candidate regions or bounding boxes of potential <b>objects</b> in the image called \u201cselective search,\u201d although the flexibility of the design allows other region proposal algorithms to be used. The feature extractor used by the model was the AlexNet deep CNN that won the ILSVRC-2012 image classification competition. The output of the CNN was a 4,096 element vector that describes the contents of the image that is fed to a linear SVM for ...", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "An <b>improved object detection algorithm based</b> on multi-scaled and ...", "url": "https://hcis-journal.springeropen.com/articles/10.1186/s13673-020-00219-9", "isFamilyFriendly": true, "displayUrl": "https://hcis-journal.springeropen.com/articles/10.1186/s13673-020-00219-9", "snippet": "Object detection methods aim to <b>identify</b> all target <b>objects</b> in the target image and determine the categories and position information in order to achieve machine vision understanding. Numerous approaches have been proposed to solve this problem, mainly inspired by methods of <b>computer</b> vision and deep <b>learning</b>. However, existing approaches always perform poorly for the detection of small, dense <b>objects</b>, and even fail to detect <b>objects</b> with random geometric transformations. In this study, we ...", "dateLastCrawled": "2022-02-01T11:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Anchor</b> Boxes \u2014 The key to quality object detection | Towards Data Science", "url": "https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>anchor</b>-boxes-the-key-to-quality-object-detection-ddf9d...", "snippet": "Predictors can specialize in certain size <b>objects</b>, <b>objects</b> with a certain aspect ratio (tall vs. wide), or <b>objects</b> in different parts of the image. Most networks use all three criteria. In our example of the pear/apple image, we could have Prediction 1 be for <b>objects</b> on the left and Prediction 2 for <b>objects</b> on the right side of the image. Then we would have our answer for what the network should be predicting:", "dateLastCrawled": "2022-02-03T03:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Train <b>Object Detection</b> AI with 6 lines of code | by Moses ... - Medium", "url": "https://medium.com/deepquestai/train-object-detection-ai-with-6-lines-of-code-6d087063f6ff", "isFamilyFriendly": true, "displayUrl": "https://medium.com/deepquestai/train-<b>object-detection</b>-ai-with-6-lines-of-code-6d087063f6ff", "snippet": "Train <b>Object Detection</b> AI with 6 lines of code. <b>Object detection</b> is one of the most profound aspects of <b>computer</b> vision as it allows you to locate, <b>identify</b>, count and track any object-of-interest ...", "dateLastCrawled": "2022-02-02T19:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Calculating global accuracy and <b>IoU</b> using confusion matrix. | Download ...", "url": "https://researchgate.net/figure/Calculating-global-accuracy-and-IoU-using-confusion-matrix_fig4_329622664", "isFamilyFriendly": true, "displayUrl": "https://researchgate.net/figure/Calculating-global-accuracy-and-<b>IoU</b>-using-confusion...", "snippet": "With the development of deep <b>learning</b>, many training methods are advanced to solve somewhat-aware problems <b>like</b> difficult-aware [20] and attribute-aware [21] SS. Li et al. [20] considered that ...", "dateLastCrawled": "2021-07-31T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Introduction to Image Segmentation in Deep Learning</b> - DebuggerCafe", "url": "https://debuggercafe.com/introduction-to-image-segmentation-in-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://debuggercafe.com/introduction-to-image", "snippet": "This means that when we visualize the output from the deep <b>learning</b> model, all the <b>objects</b> belonging to the same class are color coded with the same color. For example, take the case where an image contains cars and buildings. In this image, we can color code all the pixels labeled as a car with red color and all the pixels labeled as building with the yellow color. Similarly, we will color code all the other pixels in the image. Figure 5. Example of color-coding the differently labeled ...", "dateLastCrawled": "2022-02-03T06:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "10 <b>Computer</b> Vision Terms Everyone Must Know About! | by Bharath K ...", "url": "https://towardsdatascience.com/10-computer-vision-terms-everyone-must-know-about-687a98845fc8", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/10-<b>computer</b>-vision-terms-everyone-must-know-about-687a...", "snippet": "Edge detection helps to <b>identify</b> the various portions of an image with varying brightness or discontinuities in patterns due to which the required area can be found. It is also used to extract the structure of particular <b>objects</b> from an image and finds its utility in other <b>computer</b> vision applications <b>like</b> object detection. The above image is an example of how a certain action of edge detection can be performed and how you can vary the detection capabilities by varying the thresholding ...", "dateLastCrawled": "2022-01-31T04:14:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>gentle guide to deep learning object detection</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2018/05/14/a-<b>gentle-guide-to-deep-learning-object-detection</b>", "snippet": "Figure 5: In this visual example of Intersection over Union (<b>IoU</b>), the ground-truth bounding box (green) can be compared to the predicted bounding box (red).<b>IoU</b> is used with mean Average Precision (mAP) to evaluate the accuracy of a deep <b>learning</b> object detector. The simple equation to calculate <b>IoU</b> is shown on the right.. You\u2019ll typically find <b>IoU</b> and mAP used to evaluate the performance of HOG + Linear SVM detectors, Haar cascades, and deep <b>learning</b>-based methods; however, keep in mind ...", "dateLastCrawled": "2022-01-26T13:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The average intersection over union (<b>IOU</b>) comparison of the three ...", "url": "https://www.researchgate.net/figure/The-average-intersection-over-union-IOU-comparison-of-the-three-models_fig8_329409946", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/The-average-intersection-over-union-<b>IOU</b>-comparison...", "snippet": "The experiment proves that the method has a better effect on small targets obscured by shadows and under the color <b>similar</b> to the background of the picture, and the accuracy is significantly ...", "dateLastCrawled": "2022-01-20T17:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Intersection Over Union (<b>IOU</b>). | Download Scientific Diagram", "url": "https://www.researchgate.net/figure/Intersection-Over-Union-IOU_fig2_343194514", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/Intersection-Over-Union-<b>IOU</b>_fig2_343194514", "snippet": "Such a <b>learning</b> problem is challenging due to the small size of the detected object, the differences in the light conditions at which <b>pictures</b> were taken, and the lack of enough data to train the ...", "dateLastCrawled": "2022-02-02T19:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Object Detection Tutorial with SSD &amp; Faster RCNN - DataCamp", "url": "https://www.datacamp.com/community/tutorials/object-detection-guide", "isFamilyFriendly": true, "displayUrl": "https://www.datacamp.com/community/tutorials/object-detection-guide", "snippet": "With recent advancements in deep <b>learning</b> based <b>computer</b> vision models , object detection applications are easier to develop than ever before. Besides significant performance improvements, these techniques have also been leveraging massive image datasets to reduce the need for large datasets. In addition, with current approaches focussing on full end-to-end pipelines, performance has also improved significantly, enabling real-time use cases. <b>Similar</b> to the blogpost I wrote on the different ...", "dateLastCrawled": "2022-02-03T02:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Object detection with neural networks \u2014 a simple tutorial using keras ...", "url": "https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491", "snippet": "Overall, the network achieves a mean <b>IOU</b> of 0.5 on the training data (I haven\u2019t calculated the one for the test dataset, but it should be pretty <b>similar</b>). Not as perfect as for a single rectangle, but pretty good (especially considering that it\u2019s such a simple network). Note that the leftmost image is the same as in the plot before (the one without flipping) \u2014 you can clearly see that the predictors have learned to specialize on the rectangles.", "dateLastCrawled": "2022-01-30T01:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Object detection with deep <b>learning</b> and OpenCV - <b>PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2017/09/11/object-detection-with-deep-<b>learning</b>-and-opencv", "snippet": "If you&#39;re serious about <b>learning</b> <b>computer</b> vision, your next stop should be <b>PyImageSearch</b> University, the most comprehensive <b>computer</b> vision, deep <b>learning</b>, and OpenCV course online today. Here you\u2019ll learn how to successfully and confidently apply <b>computer</b> vision to your work, research, and projects. Join me in <b>computer</b> vision mastery. Inside <b>PyImageSearch</b> University you&#39;ll find: &amp;check; 30+ courses on essential <b>computer</b> vision, deep <b>learning</b>, and OpenCV topics &amp;check; 30+ Certificates of ...", "dateLastCrawled": "2022-01-30T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Object Detection Guide</b> | Fritz AI", "url": "https://www.fritz.ai/object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.fritz.ai/<b>object-detection</b>", "snippet": "<b>Object detection</b> is a <b>computer</b> vision technique that allows us to <b>identify</b> and locate <b>objects</b> in an image or video. With this kind of identification and localization, <b>object detection</b> can be used to count <b>objects</b> in a scene and determine and track their precise locations, all while accurately labeling them. Imagine, for example, an image that contains two cats and a person. <b>Object detection</b> allows us to at once classify the types of things found while also locating instances of them within ...", "dateLastCrawled": "2022-01-29T01:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Gentle Introduction to Object Recognition With Deep <b>Learning</b>", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/object-recognition-with-deep-learnin", "snippet": "A <b>computer</b> vision technique is used to propose candidate regions or bounding boxes of potential <b>objects</b> in the image called \u201cselective search,\u201d although the flexibility of the design allows other region proposal algorithms to be used. The feature extractor used by the model was the AlexNet deep CNN that won the ILSVRC-2012 image classification competition. The output of the CNN was a 4,096 element vector that describes the contents of the image that is fed to a linear SVM for ...", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Introduction to Image Segmentation in Deep Learning</b> - DebuggerCafe", "url": "https://debuggercafe.com/introduction-to-image-segmentation-in-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://debuggercafe.com/introduction-to-image", "snippet": "This means that when we visualize the output from the deep <b>learning</b> model, all the <b>objects</b> belonging to the same class are color coded with the same color. For example, take the case where an image contains cars and buildings. In this image, we can color code all the pixels labeled as a car with red color and all the pixels labeled as building with the yellow color. Similarly, we will color code all the other pixels in the image. Figure 5. Example of color-coding the differently labeled ...", "dateLastCrawled": "2022-02-03T06:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Detection of <b>Two wheelers Helmet Using Machine Learning</b>", "url": "https://turkjphysiotherrehabil.org/pub/pdf/322/32-2-1.pdf", "isFamilyFriendly": true, "displayUrl": "https://turkjphysiotherrehabil.org/pub/pdf/322/32-2-1.pdf", "snippet": "<b>identify</b> protective caps in surveillance video recordings. This method crops the moving object and afterward distinguishes bikes from the other <b>objects</b> and bike rider&#39;s heads. This framework k couldn&#39;t distinguish the minute varieties and brightening impacts of moving <b>objects</b>. [4] In [2] two steps were implemented fo r helmet detection. In the main stage, moving vehicles were processed where a cross-line was obtained. In the subsequent procedure, an SVM classifier was utilized to classify ...", "dateLastCrawled": "2022-02-03T17:52:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>Learning</b>(<b>Computer</b> Vision): Object Detection &amp; Infection ...", "url": "https://medium.com/analytics-vidhya/deep-learning-computer-vision-object-detection-infection-classification-on-malaria-images-3769b4f51de9", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/deep-<b>learning</b>-<b>computer</b>-vision-object-detection...", "snippet": "One <b>can</b> simply ask, why <b>can</b>\u2019t we use object detection in each frame in the whole video and we <b>can</b> track the object. There are a few problems with that. If the image has multiple <b>objects</b>, then we ...", "dateLastCrawled": "2022-01-29T19:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Object detection with deep <b>learning</b> and OpenCV - <b>PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2017/09/11/object-detection-with-deep-<b>learning</b>-and-opencv", "snippet": "When it comes to deep <b>learning</b>-based object detection there are three primary object detection methods that you\u2019ll likely encounter: Faster R-CNNs (Ren et al., 2015); You Only Look Once (YOLO) (Redmon et al., 2015) Single Shot Detectors (SSDs) (Liu et al., 2015) Faster R-CNNs are likely the most \u201cheard of\u201d method for object detection using deep <b>learning</b>; however, the technique <b>can</b> be difficult to understand (especially for beginners in deep <b>learning</b>), hard to implement, and challenging ...", "dateLastCrawled": "2022-01-30T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Object <b>Detection</b> using Google AI Open Images | by Alyson Brown ...", "url": "https://towardsdatascience.com/object-detection-using-google-ai-open-images-541ea601cfa5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/object-<b>detection</b>-using-google-ai-open-images-541ea601cfa5", "snippet": "Use a YOLO v2 model which was trained to <b>identify</b> certain <b>objects</b>. Leverage transfer <b>learning</b> to train the last convolutional layer to recognize previously unseen <b>objects</b> such as guitar, house, man/woman, bird, etc. Inputs for YOLO . The YOLO algorithm requires some specific inputs - Input image size \u2014 YOLO network is designed to work with specific input image sizes. We sent in images with a size of 608 * 608. Number of Classes \u2014 43. This is required to define the dimensions of the ...", "dateLastCrawled": "2022-02-03T10:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Anchor</b> Boxes \u2014 The key to quality object detection | Towards Data Science", "url": "https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>anchor</b>-boxes-the-key-to-quality-object-detection-ddf9d...", "snippet": "Predictors <b>can</b> specialize in certain size <b>objects</b>, <b>objects</b> with a certain aspect ratio (tall vs. wide), or <b>objects</b> in different parts of the image. Most networks use all three criteria. In our example of the pear/apple image, we could have Prediction 1 be for <b>objects</b> on the left and Prediction 2 for <b>objects</b> on the right side of the image. Then we would have our answer for what the network should be predicting: Prediction 1: Pear Prediction 2: Apple. <b>Anchor</b> Boxes in Practice. State of the art ...", "dateLastCrawled": "2022-02-03T03:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Real-time multiple object tracking using deep <b>learning</b> methods ...", "url": "https://link.springer.com/article/10.1007/s00521-021-06391-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-021-06391-y", "snippet": "Multiple-object tracking is a fundamental <b>computer</b> vision task which is gaining increasing attention due to its academic and commercial potential. Multiple-object detection, recognition and tracking are quite desired in many domains and applications. However, accurate object tracking is very challenging, and things are even more challenging when multiple <b>objects</b> are involved. The main challenges that multiple-object tracking is facing include the similarity and the high density of detected ...", "dateLastCrawled": "2022-02-03T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Gentle Introduction to Object Recognition With Deep <b>Learning</b>", "url": "https://machinelearningmastery.com/object-recognition-with-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/object-recognition-with-deep-learnin", "snippet": "A <b>computer</b> vision technique is used to propose candidate regions or bounding boxes of potential <b>objects</b> in the image called \u201cselective search,\u201d although the flexibility of the design allows other region proposal algorithms to be used. The feature extractor used by the model was the AlexNet deep CNN that won the ILSVRC-2012 image classification competition. The output of the CNN was a 4,096 element vector that describes the contents of the image that is fed to a linear SVM for ...", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Note on various <b>Object Detection Algorithms</b> | by Himadri Sankar ...", "url": "https://medium.com/analytics-vidhya/a-note-on-various-object-detection-algorithms-66ded1152773", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/a-note-on-var<b>iou</b>s-<b>object-detection-algorithms</b>-66...", "snippet": "Given an image, a Convolution Neural Network <b>can</b> classify it into different classes. But the real problem lies in detecting multiple <b>objects</b> in a single image. When there are more than one object ...", "dateLastCrawled": "2022-01-29T16:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Practical Machine <b>Learning</b> for <b>Computer</b> Vision: End-to-End Machine ...", "url": "https://ebin.pub/practical-machine-learning-for-computer-vision-end-to-end-machine-learning-for-images-1nbsped-1098102363-9781098102364.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/practical-machine-<b>learning</b>-for-<b>computer</b>-vision-end-to-end-machine...", "snippet": "Many previously difficult problems <b>can</b> now be solved by train\u2010 ing machine <b>learning</b> (ML) models to <b>identify</b> <b>objects</b> in images. Our aim in this book is to provide intuitive explanations of the ML architectures that underpin this fastadvancing field, and to provide practical code to employ these ML models to solve problems involving classification, measurement, detection, segmentation, representa\u2010 tion, generation, counting, and more. Image classification is the \u201chello world\u201d of deep ...", "dateLastCrawled": "2022-01-16T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>AI-driven object detection software</b>", "url": "https://dlabs.ai/resources/whitepapers/ai-driven-object-detection-software/", "isFamilyFriendly": true, "displayUrl": "https://dlabs.ai/resources/whitepapers/<b>ai-driven-object-detection-software</b>", "snippet": "Object Detection <b>can</b> also involve a <b>computer</b> program that identifies the position of all <b>objects</b> (e.g. pedestrians) ... we use and optimize pre-trained models to <b>identify</b> hundreds of classes of <b>objects</b>: including people, activities, animals, plants, and places. Google provides starter image classification models with accompanied labels capable of <b>learning</b> how to use image classification models within a mobile app. Once we have the starter model up-and-running on our target device, we <b>can</b> ...", "dateLastCrawled": "2022-02-03T08:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Perform Object Detection With YOLOv3 in Keras", "url": "https://machinelearningmastery.com/how-to-perform-object-detection-with-yolov3-in-keras/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/how-to-perform-object-detection-with-yolov3-in-keras", "snippet": "In recent years, deep <b>learning</b> techniques are achieving state-of-the-art results for object detection, such as on standard benchmark datasets and in <b>computer</b> vision competitions. Notable is the \u201cYou Only Look Once,\u201d or YOLO, family of Convolutional Neural Networks that achieve near state-of-the-art results with a single end-to-end model that <b>can</b> perform object detection in real-time.", "dateLastCrawled": "2022-02-03T02:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The average intersection over union (<b>IOU</b>) comparison of the three ...", "url": "https://www.researchgate.net/figure/The-average-intersection-over-union-IOU-comparison-of-the-three-models_fig8_329409946", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/The-average-intersection-over-union-<b>IOU</b>-comparison...", "snippet": "In this paper, we propose a method that <b>can</b> locate and classify vehicular <b>objects</b> from a given densely crowded image using YOLOv5. The shortcoming of YOLO was solved my ensembling 4 different ...", "dateLastCrawled": "2022-01-20T17:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A <b>gentle guide to deep learning object detection</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2018/05/14/a-<b>gentle-guide-to-deep-learning-object-detection</b>", "snippet": "Figure 5: In this visual example of Intersection over Union (<b>IoU</b>), the ground-truth bounding box (green) <b>can</b> <b>be compared</b> to the predicted bounding box (red). <b>IoU</b> is used with mean Average Precision (mAP) to evaluate the accuracy of a deep <b>learning</b> object detector. The simple equation to calculate <b>IoU</b> is shown on the right. You\u2019ll typically find <b>IoU</b> and mAP used to evaluate the performance of HOG + Linear SVM detectors, Haar cascades, and deep <b>learning</b>-based methods; however, keep in mind ...", "dateLastCrawled": "2022-01-26T13:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Object Detection and Classification using R</b>-CNNs | Telesens", "url": "https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/", "isFamilyFriendly": true, "displayUrl": "https://www.telesens.co/2018/03/11/<b>object-detection-and-classification-using-r</b>-cnns", "snippet": "Intersection over Union (<b>IoU</b>) Overlap: ... It is difficult to <b>identify</b> precisely how this <b>learning</b> takes place, but I\u2019d imagine the RPN convolutional and fully connected layers learn how to interpret the various image features generated by the neural network into deciphering good object bounding boxes. When we consider Inference in the next section, we\u2019ll see how these regression coefficients are used. The second set of bounding box coefficients is generated by the classification layer ...", "dateLastCrawled": "2022-01-31T21:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Object detection with deep <b>learning</b> and OpenCV - <b>PyImageSearch</b>", "url": "https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>pyimagesearch</b>.com/2017/09/11/object-detection-with-deep-<b>learning</b>-and-opencv", "snippet": "When it comes to deep <b>learning</b>-based object detection there are three primary object detection methods that you\u2019ll likely encounter: Faster R-CNNs (Ren et al., 2015); You Only Look Once (YOLO) (Redmon et al., 2015) Single Shot Detectors (SSDs) (Liu et al., 2015) Faster R-CNNs are likely the most \u201cheard of\u201d method for object detection using deep <b>learning</b>; however, the technique <b>can</b> be difficult to understand (especially for beginners in deep <b>learning</b>), hard to implement, and challenging ...", "dateLastCrawled": "2022-01-30T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Object Detection Guide</b> | Fritz AI", "url": "https://www.fritz.ai/object-detection/", "isFamilyFriendly": true, "displayUrl": "https://www.fritz.ai/<b>object-detection</b>", "snippet": "<b>Object detection</b> is a <b>computer</b> vision technique that allows us to <b>identify</b> and locate <b>objects</b> in an image or video. With this kind of identification and localization, <b>object detection</b> <b>can</b> be used to count <b>objects</b> in a scene and determine and track their precise locations, all while accurately labeling them. Imagine, for example, an image that contains two cats and a person. <b>Object detection</b> allows us to at once classify the types of things found while also locating instances of them within ...", "dateLastCrawled": "2022-01-29T01:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Deep <b>learning</b> based real-time tourist spots detection and recognition ...", "url": "https://journals.sagepub.com/doi/pdf/10.1177/00368504211044228", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/pdf/10.1177/00368504211044228", "snippet": "not only use the camera of mobile devices to take <b>pictures</b> of sights in real-time, but <b>can</b> also <b>identify</b> scenic spots from photos of scenic spots collected on the Internet, which solves the dilemma of users who are interested, but do not know where the location in the photo is. In addition, many attractions have a certain history, but if there ...", "dateLastCrawled": "2022-01-25T15:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Note on various <b>Object Detection Algorithms</b> | by Himadri Sankar ...", "url": "https://medium.com/analytics-vidhya/a-note-on-various-object-detection-algorithms-66ded1152773", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/a-note-on-var<b>iou</b>s-<b>object-detection-algorithms</b>-66...", "snippet": "Given an image, a Convolution Neural Network <b>can</b> classify it into different classes. But the real problem lies in detecting multiple <b>objects</b> in a single image. When there are more than one object ...", "dateLastCrawled": "2022-01-29T16:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Object Detection Using Mask R</b>-CNN with TensorFlow | <b>Paperspace Blog</b>", "url": "https://blog.paperspace.com/mask-r-cnn-in-tensorflow-2-0/", "isFamilyFriendly": true, "displayUrl": "https://blog.paperspace.com/mask-r-cnn-in-tensorflow-2-0", "snippet": "Mask R-CNN is an object detection model based on deep convolutional neural networks (CNN) developed by a group of Facebook AI researchers in 2017. The model <b>can</b> return both the bounding box and a mask for each detected object in an image. The model was originally developed in Python using the Caffe2 deep <b>learning</b> library. The original source code is available on GitHub.To support the Mask R-CNN model with more popular libraries, such as TensorFlow, there is a popular open-source project ...", "dateLastCrawled": "2022-02-02T16:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to <b>use a convolutional neural networks to find</b> circles in ... - Quora", "url": "https://www.quora.com/How-to-use-a-convolutional-neural-networks-to-find-circles-in-an-image", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-to-<b>use-a-convolutional-neural-networks-to-find</b>-circles-in-an...", "snippet": "Answer (1 of 4): Like others mentioned, we <b>can</b> use small CNN (maybe 2 layered one). And after flattening, bring down the last layer to output 4 values. Now that you have the model ready, you <b>can</b> create a custom loss which checks the <b>IOU</b> between the predicted and actual labels. Remember, <b>IOU</b> in it...", "dateLastCrawled": "2022-01-16T19:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Rapid Object Detection in C#</b> - <b>CodeProject</b>", "url": "https://www.codeproject.com/articles/826377/rapid-object-detection-in-csharp", "isFamilyFriendly": true, "displayUrl": "https://<b>www.codeproject.com</b>/articles/826377/<b>rapid-object-detection-in</b>-csharp", "snippet": "The procedure <b>can</b> <b>be compared</b> as convolution process with a big kernel which obviously <b>can</b> take some time. The template <b>can</b> be represented in many ways: as color image, gradient magnitude image, orientation image. It has been shown that gradient orientations are quite robust against illumination changes, thus the gradient orientation image representation is frequently used. The novel procedure appeared in 2012 [1] also uses gradient orientation image as input. The different part is the ...", "dateLastCrawled": "2022-01-31T14:04:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Difference Between <b>Iou</b> And Map", "url": "https://groups.google.com/g/wjtvxlz/c/V9yHAwM4mAQ", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/wjtvxlz/c/V9yHAwM4mAQ", "snippet": "When a difference between these parts of using <b>machine</b> <b>learning</b> images using generated different <b>iou</b> is limited support for help debug in. It harder for different. It is bleak if you want its use darknet with a GPU. The architectures discussed so vivid are heard much designed for accuracy and noun for speed. The differences btw appearance changes caused by a scan across many places such as discussed together and autonomous driving scenarios of. Renters still owe landlords back rent. That ...", "dateLastCrawled": "2022-01-20T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>What is intersection over union in deep</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-intersection-over-union-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-intersection-over-union-in-deep</b>-<b>learning</b>", "snippet": "Answer (1 of 2): Generally Intersection over union(<b>IOU</b>) is a measure of overlap between two bounding box . In computer vision it is used for correctly detecting an object.To know object detection first you have to know about object localization . Object localization refers to figuring out where i...", "dateLastCrawled": "2022-01-19T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning Gist</b> \u00b7 GitHub", "url": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "snippet": "<b>Machine Learning Gist</b>. GitHub Gist: instantly share code, notes, and snippets. ... to solve one problem - The TV knob <b>analogy</b> and the car <b>analogy</b>. Chain of assumptions in <b>Machine</b> <b>Learning</b> and different knobs to say improve performance on train/dev set. Andrew Ng does not recommend Early stopping, as it is a knob that affects multiple thing at once. Setting up your goal. Set a SINGLE NUMBER for metrics- precision and recall- but these are two numbers, and you ideally need one number. ENTER ...", "dateLastCrawled": "2022-01-29T03:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Understanding the 3 most common loss functions for <b>Machine</b> <b>Learning</b> ...", "url": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for...", "snippet": "A <b>loss function</b> in <b>Machine</b> <b>Learning</b> is a measure of how accurately your ML model is able to predict the expected outcome i.e the ground truth. The <b>loss function</b> will take two items as input: the output value of our model and the ground truth expected value. The output of the <b>loss function</b> is called the loss which is a measure of how well our model did at predicting the outcome. A high value for the loss means our model performed very poorly. A low value for the loss means our model performed ...", "dateLastCrawled": "2022-02-02T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Calculating IOU of masks using tensorflow</b> : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/ns8c8q/calculating_iou_of_masks_using_tensorflow/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/ns8c8q/calculating_<b>iou</b>_of_masks...", "snippet": "<b>Calculating IOU of masks using tensorflow</b>. Hello! I&#39;m trying to speed up a process from my computer vision pipeline where I calculate <b>IOU</b> of two binary masks by using tensorflow 1.15. I&#39;ll post a snippet of code showing how I&#39;m doing it with numpy and how I&#39;m trying to do it with tensorflow, so far tensorflow is waaaay slower and was hoping someone could point out why that is happening. ...", "dateLastCrawled": "2021-12-28T03:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) On the role of interpretive <b>analogy</b> in <b>learning</b> | bipin8@gmail ...", "url": "https://www.academia.edu/1930318/On_the_role_of_interpretive_analogy_in_learning", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/1930318/On_the_role_of_interpretive_<b>analogy</b>_in_<b>learning</b>", "snippet": "4 <b>Analogy</b> in <b>Learning</b> With the distinction between the three modes of <b>analogy</b> clarified, let us now an- alyze what role, if any, each of them might play in <b>learning</b>. Let us begin with simple <b>analogy</b>. It may seem at first that there cannot possibly be any <b>learning</b> in simple <b>analogy</b>, since all it does is notice connections between existing knowledge structures. However, this argument would also disqualify all mathematical theo- rems and facts from being learnable. As any reasonable ...", "dateLastCrawled": "2022-01-05T22:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Deep Learning applied to Follow-Me</b> in robotics | by Bruno Santos ...", "url": "https://towardsdatascience.com/drone-follow-me-ed0d15e62498", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/drone-follow-me-ed0d15e62498", "snippet": "As an <b>analogy</b>, 1x1 convolution layer works like a Fully Connected Layer since combines linearly the depth layers and input a RELU , although reversely to Fully Connected Layers it preserves spatial information. 1x1 convolution. Finally, the decoder is composed by bilinear upsampling layers followed by convolution layer+ batch-normalization and skip connections with encoder layers to improve lost spatial features resolution. Let\u2019s break down these three important concepts: Bilinear ...", "dateLastCrawled": "2022-01-26T12:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Explaining <b>precision</b> and <b>recall</b>. The first days and weeks of getting ...", "url": "https://medium.com/@klintcho/explaining-precision-and-recall-c770eb9c69e9", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@klintcho/explaining-<b>precision</b>-and-<b>recall</b>-c770eb9c69e9", "snippet": "The first days and weeks of getting into NLP, I had a hard time grasping the concepts of <b>precision</b>, <b>recall</b> and F1-score. Accuracy is also a metric which is tied to these, as well as micro-<b>precision</b>\u2026", "dateLastCrawled": "2022-01-27T17:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "13.4. <b>Anchor</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/anchor.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>anchor</b>.html", "snippet": "After changing the shape of the <b>anchor</b> box variable Y to (image height, image width, number of <b>anchor</b> boxes centered on the same pixel, 4), we can obtain all the <b>anchor</b> boxes centered on a specified pixel position. In the following, we access the first <b>anchor</b> box centered on (250, 250). It has four elements: the \\((x, y)\\)-axis coordinates at the upper-left corner and the \\((x, y)\\)-axis coordinates at the lower-right corner of the <b>anchor</b> box.The coordinate values of both axes are divided by ...", "dateLastCrawled": "2022-01-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Understanding <b>Focal Loss</b> in 5 mins | Medium | VisionWizard", "url": "https://medium.com/visionwizard/understanding-focal-loss-a-quick-read-b914422913e7", "isFamilyFriendly": true, "displayUrl": "https://medium.com/visionwizard/understanding-<b>focal-loss</b>-a-quick-read-b914422913e7", "snippet": "The <b>focal loss</b> gives less weight to easy examples and gives more weight to hard misclassified examples. This, in turn, helps to solve the class imbalance problem.", "dateLastCrawled": "2022-01-29T23:03:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Know Your English | Fireman (Steam Engine) | Stress (Linguistics)", "url": "https://es.scribd.com/document/49395857/Know-Your-English", "isFamilyFriendly": true, "displayUrl": "https://es.scribd.com/document/49395857/Know-Your-English", "snippet": "The \u2018ct&#39; is like the \u2018sh&#39; in \u2018ship&#39; and \u2018shape&#39;, and the \u2018<b>iou&#39; is like</b> the \u2018a&#39; in \u2018china&#39;. The word is pronounced \u2018ram-BUNK-shes&#39; with the stress on the second syllable. When you refer to a child or a puppy as being rambunctious, you mean that they are full of youthful energy, and therefore somewhat difficult to control. The word can also be used to mean very noisy and disorderly. Some people say that the word is an alteration of \u2018rumbustious&#39;. *The rambunctious entertainer ...", "dateLastCrawled": "2021-11-20T18:01:00.0000000Z", "language": "es", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Hindu Kye Final-9!10!2013 | Misdemeanor | Stress (Linguistics) - Scribd", "url": "https://www.scribd.com/document/234733183/The-Hindu-Kye-Final-9-10-2013", "isFamilyFriendly": true, "displayUrl": "https://www.scribd.com/document/234733183/<b>The-Hindu-Kye-Final-9-10-2013</b>", "snippet": "The Hindu Kye Final-9!10!2013 - Free ebook download as PDF File (.pdf), Text File (.txt) or read book online for free. This file is the consolidated collection from The Hindu&#39;s Know Your English by Mr.S.Upendran. I feel it is very useful for the readers and develop their vocabulary. The information provided in the coloumns is crystal clear with suitable examples and usage. I am very much thankful to Mr.S.Upendran for this valuable work.", "dateLastCrawled": "2021-12-12T00:30:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Object-based <b>detection of vehicles</b> using combined <b>optical and elevation</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0924271617303672", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0924271617303672", "snippet": "While for the Zeebrugge dataset, the mean <b>IoU is similar</b> to S (L v \u222a L e), the recall is 0.96. For the Vaihingen dataset, this is reversed, with a recall even slightly above S (L v \u222a L e), but a significantly reduced mean IoU. As all these methods used both data sources, it is evident that data fusion is crucial for high quality results. However, reasonable results could also be obtained even with single sensor data. If the threshold of the IoU is set to 0.5, the distances between the ...", "dateLastCrawled": "2021-12-21T22:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Towards a Meaningful 3D Map Using a</b> 3D Lidar and a Camera", "url": "https://www.researchgate.net/publication/326875064_Towards_a_Meaningful_3D_Map_Using_a_3D_Lidar_and_a_Camera", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/326875064_<b>Towards_a_Meaningful_3D_Map_Using_a</b>...", "snippet": "In this study, we developed semantic 3D mapping by fusing a 3D Lidar with a camera. Our goal. is to create a semantic 3D map with the following seven labels: road, sidewalk, building, fence, pole ...", "dateLastCrawled": "2022-01-31T02:23:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(iou)  is like +(computer learning how to identify objects in pictures)", "+(iou) is similar to +(computer learning how to identify objects in pictures)", "+(iou) can be thought of as +(computer learning how to identify objects in pictures)", "+(iou) can be compared to +(computer learning how to identify objects in pictures)", "machine learning +(iou AND analogy)", "machine learning +(\"iou is like\")", "machine learning +(\"iou is similar\")", "machine learning +(\"just as iou\")", "machine learning +(\"iou can be thought of as\")", "machine learning +(\"iou can be compared to\")"]}