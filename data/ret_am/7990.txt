{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Logistic Regression</b>: Calculating a <b>Probability</b> | Machine Learning Crash ...", "url": "https://developers.google.com/machine-learning/crash-course/logistic-regression/calculating-a-probability", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/crash-course/<b>logistic-regression</b>/...", "snippet": "If z represents the output of the linear layer of a model trained with <b>logistic regression</b>, then s i g m o i d ( z) will yield a value (a <b>probability</b>) between 0 and 1. In mathematical terms: y \u2032 = 1 1 + e \u2212 z. where: y \u2032 is the output of the <b>logistic regression</b> model for a particular example. z = b + w 1 x 1 + w 2 x 2 + \u2026 + w N x N.", "dateLastCrawled": "2022-02-02T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Regularization</b> &amp; logical regression | Develop Paper", "url": "https://developpaper.com/regularization-logical-regression/", "isFamilyFriendly": true, "displayUrl": "https://developpaper.com/<b>regularization</b>-logical-regression", "snippet": "<b>Regularization</b>: simplicity. Look at the following generalization curve, which shows the loss of <b>training</b> and validation sets relative to the number of <b>training</b> iterations. The figure above shows that the <b>training</b> loss of a model decreases gradually, but the verification loss increases finally. In other words, the generalization curve shows that the model is over fitted with the data in the <b>training</b> set. According to Okam\u2019s razor law, maybe we canReduce the complexity of complex models to ...", "dateLastCrawled": "2021-10-13T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Can recursive neural tensor networks learn logical reasoning? \u2013 arXiv ...", "url": "https://www.arxiv-vanity.com/papers/1312.6192/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1312.6192", "snippet": "To evaluate this, I train a recursive model on a new corpus of constructed examples of logical reasoning in short sentences, <b>like</b> the inference of some animal walks from some <b>dog</b> walks or some cat walks, given that dogs and cats are animals. This model learns representations that generalize well to new types of reasoning pattern in all but a few cases, a result which is promising for the ability of learned representation models to capture logical reasoning.", "dateLastCrawled": "2021-09-27T02:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Environmental sound classification using a regularized</b> deep ...", "url": "https://www.researchgate.net/publication/341172446_Environmental_sound_classification_using_a_regularized_deep_convolutional_neural_network_with_data_augmentation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341172446_Environmental_sound_classification...", "snippet": "This study is to employ deep convolutional neural networks (DCNN) with <b>regularization</b> and data enhancement with basic audio features that have verified to be efficient on ESC tasks. In this study ...", "dateLastCrawled": "2021-12-07T20:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Hands-On Transfer Learning with Python: Implement advanced deep ...", "url": "https://dokumen.pub/hands-on-transfer-learning-with-python-implement-advanced-deep-learning-and-neural-network-models-using-tensorflow-and-keras-1788831306-9781788831307.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/hands-on-transfer-learning-with-python-implement-advanced-deep...", "snippet": "Data points in this set are <b>not</b> used for the <b>training</b> phase (this dataset is further divided into the validation set as well; we will discuss this in more detail in subsequent chapters). Learned function: This is the output of the <b>training</b> phase. Also termed as inferred function or the model. This function is inferred based on the <b>training</b> examples (input data points and their corresponding outputs) from the <b>training</b> dataset. An ideal model/learned function would learn the mapping in such a ...", "dateLastCrawled": "2021-12-15T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "\u5b66\u4e60\u7b14\u8bb0\u4e4bMachine Learning Crash Course | Google Developers_weixin_34166472 ...", "url": "https://its401.com/article/weixin_34166472/93303327", "isFamilyFriendly": true, "displayUrl": "https://its401.com/article/weixin_34166472/93303327", "snippet": "<b>L1</b> <b>regularization</b> will encourage most of the non-informative weights to be exactly 0.0. In general, <b>L1</b> <b>regularization</b> of sufficient lambda tends to encourage non-informative features to weights of exactly 0.0. Unlike L2 <b>regularization</b>, <b>L1</b> <b>regularization</b> &quot;pushes&quot; just as hard toward 0.0 no matter how far the weight is from 0.0.", "dateLastCrawled": "2022-01-10T20:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "ML Cheatsheet documentation", "url": "https://www.iamsiddharth.com/ML-Cheatsheet/", "isFamilyFriendly": true, "displayUrl": "https://www.iamsiddharth.com/ML-Cheatsheet", "snippet": "By the end of our <b>training</b>, our equation will approximate the line of best fit. Code. def predict_sales (radio, weight, bias): return weight * radio + bias. Cost function \u00b6 The prediction function is nice, but for our purposes we don\u2019t really need it. What we need is a cost function so we can start optimizing our weights. Let\u2019s use MSE (L2) as our cost function. MSE measures the average squared difference between an observation\u2019s actual and predicted values. The output is a single ...", "dateLastCrawled": "2022-01-25T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A practical guide to <b>MaxEnt for modeling species&#39; distributions: What</b> ...", "url": "https://www.researchgate.net/publication/264532217_A_practical_guide_to_MaxEnt_for_modeling_species'_distributions_What_it_does_and_why_inputs_and_settings_matter", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/264532217_A_practical_guide_to_MaxEnt_for...", "snippet": "Each feature class transforms the environmental variables according to a <b>regularization</b> parameter \u03b2, which also depends on the number of occurrences (Merow et al., 2013; Phillips et al., 2017 ...", "dateLastCrawled": "2022-01-29T00:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "learning | Thoughts on learning and work", "url": "https://bessiechu.wordpress.com/category/learning/", "isFamilyFriendly": true, "displayUrl": "https://bessiechu.wordpress.com/category/learning", "snippet": "The Manager\u2019s Path. Key Points: \u201cYour manager should be the person who shows you the larger picture of how your work fits into the team\u2019s goals, and helps you feel a sense of purpose in the day-to-day work\u201d. \u201cDeveloping a sense of ownership and authority for your work and <b>not</b> relying for manager to set the tone\u201d.", "dateLastCrawled": "2022-01-28T22:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Speech and Language Processing An Introduction to Natural Language ...", "url": "https://ebin.pub/speech-and-language-processing-an-introduction-to-natural-language-processing-computational-linguistics-and-speech-recognition-3nbsped.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/speech-and-language-processing-an-introduction-to-natural-language...", "snippet": "Thus if our <b>training</b> corpus contains, say the words low, new, newer, but <b>not</b> lower, then if the word lower appears in our test corpus, our system will <b>not</b> know what to do with it. To deal with this unknown word problem, modern tokenizers often automatically induce sets of tokens that include tokens smaller than words, called subwords. Subwords can be arbitrary substrings, or they can be meaning-bearing units <b>like</b> the morphemes -est or -er. (A morpheme is the smallest meaning-bearing unit of ...", "dateLastCrawled": "2022-01-18T13:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Regularization</b> &amp; logical regression | Develop Paper", "url": "https://developpaper.com/regularization-logical-regression/", "isFamilyFriendly": true, "displayUrl": "https://developpaper.com/<b>regularization</b>-logical-regression", "snippet": "<b>Regularization</b>: simplicity. Look at the following generalization curve, which shows the loss of <b>training</b> and validation sets relative to the number of <b>training</b> iterations. The figure above shows that the <b>training</b> loss of a model decreases gradually, but the verification loss increases finally. In other words, the generalization curve shows that the model is over fitted with the data in the <b>training</b> set. According to Okam\u2019s razor law, maybe we canReduce the complexity of complex models to ...", "dateLastCrawled": "2021-10-13T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Can recursive neural tensor networks learn logical reasoning? \u2013 arXiv ...", "url": "https://www.arxiv-vanity.com/papers/1312.6192/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1312.6192", "snippet": "To evaluate this, I train a recursive model on a new corpus of constructed examples of logical reasoning in short sentences, like the inference of some animal walks from some <b>dog</b> walks or some cat walks, given that dogs and cats are animals. This model learns representations that generalize well to new types of reasoning pattern in all but a few cases, a result which is promising for the ability of learned representation models to capture logical reasoning.", "dateLastCrawled": "2021-09-27T02:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "ML Cheatsheet documentation", "url": "https://www.iamsiddharth.com/ML-Cheatsheet/", "isFamilyFriendly": true, "displayUrl": "https://www.iamsiddharth.com/ML-Cheatsheet", "snippet": "E.g. My <b>dog</b> barks, so all dogs must <b>bark</b>. In machine learning we often run into trouble when we extrapolate outside the range of our <b>training</b> data. Feature With respect to a dataset, a feature represents an attribute and value combination. Color is an attribute. \u201cColor is blue\u201d is a feature. In Excel terms, features are <b>similar</b> to cells ...", "dateLastCrawled": "2022-01-25T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "COMBINING HETEROGENEOUS MODELS FOR MEASURING RELATIONAL SIMILARITY", "url": "http://nlp.cic.ipn.mx/~alisa/papers/COMBINING_HETEROGENEOUS_MODELS-ed.pptx", "isFamilyFriendly": true, "displayUrl": "nlp.cic.ipn.mx/~alisa/papers/COMBINING_HETEROGENEOUS_MODELS-ed.pptx", "snippet": "<b>dog</b> : <b>bark</b> . car : vroom . cat : meow Binarydecisionon a relation loses these shades. Intuition of Degrees of Relational Similarities: <b>Not</b> just simple discrete relation classification, but also the \u201cdegree\u201d (e.g., more formally Prob[(whale,mammal) \u2208 Is-A]),continuous real values. Intuition of Degrees of Relational Similarities:", "dateLastCrawled": "2021-12-04T18:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Glossary</b> \u2014 \u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f ML Cheatsheet", "url": "https://ml-cheatsheet-russian.readthedocs.io/ru/latest/glossary.html", "isFamilyFriendly": true, "displayUrl": "https://ml-cheatsheet-russian.readthedocs.io/ru/latest/<b>glossary</b>.html", "snippet": "E.g. My <b>dog</b> barks, so all dogs must <b>bark</b>. In machine learning we often run into trouble when we extrapolate outside the range of our <b>training</b> data. Feature With respect to a dataset, a feature represents an attribute and value combination. Color is an attribute. \u00abColor is blue\u00bb is a feature. In Excel terms, features are <b>similar</b> to cells. The ...", "dateLastCrawled": "2021-12-14T22:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Environmental sound classification using a regularized</b> deep ...", "url": "https://www.researchgate.net/publication/341172446_Environmental_sound_classification_using_a_regularized_deep_convolutional_neural_network_with_data_augmentation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341172446_Environmental_sound_classification...", "snippet": "This study is to employ deep convolutional neural networks (DCNN) with <b>regularization</b> and data enhancement with basic audio features that have verified to be efficient on ESC tasks. In this study ...", "dateLastCrawled": "2021-12-07T20:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "\u5b66\u4e60\u7b14\u8bb0\u4e4bMachine Learning Crash Course | Google Developers_weixin_34166472 ...", "url": "https://its401.com/article/weixin_34166472/93303327", "isFamilyFriendly": true, "displayUrl": "https://its401.com/article/weixin_34166472/93303327", "snippet": "<b>L1</b> <b>regularization</b> will encourage most of the non-informative weights to be exactly 0.0. In general, <b>L1</b> <b>regularization</b> of sufficient lambda tends to encourage non-informative features to weights of exactly 0.0. Unlike L2 <b>regularization</b>, <b>L1</b> <b>regularization</b> &quot;pushes&quot; just as hard toward 0.0 no matter how far the weight is from 0.0.", "dateLastCrawled": "2022-01-10T20:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A practical guide to <b>MaxEnt for modeling species&#39; distributions: What</b> ...", "url": "https://www.researchgate.net/publication/264532217_A_practical_guide_to_MaxEnt_for_modeling_species'_distributions_What_it_does_and_why_inputs_and_settings_matter", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/264532217_A_practical_guide_to_MaxEnt_for...", "snippet": "Each feature class transforms the environmental variables according to a <b>regularization</b> parameter \u03b2, which also depends on the number of occurrences (Merow et al., 2013; Phillips et al., 2017 ...", "dateLastCrawled": "2022-01-29T00:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Hands-On Transfer Learning with Python: Implement advanced deep ...", "url": "https://dokumen.pub/hands-on-transfer-learning-with-python-implement-advanced-deep-learning-and-neural-network-models-using-tensorflow-and-keras-1788831306-9781788831307.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/hands-on-transfer-learning-with-python-implement-advanced-deep...", "snippet": "It is also an invaluable technique for tasks where the large amounts of <b>training</b> data typically required for <b>training</b> a model from scratch are <b>not</b> available. Becoming familiar with complex concepts and implementing these concepts in practice are two very different things, and this is where Hands-On Transfer Learning with Python shines. The book starts with a deep dive into both deep learning and transfer learning, conceptually. This is followed by practical implementations of these concepts ...", "dateLastCrawled": "2021-12-15T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Speech and Language Processing An Introduction to Natural Language ...", "url": "https://ebin.pub/speech-and-language-processing-an-introduction-to-natural-language-processing-computational-linguistics-and-speech-recognition-3nbsped.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/speech-and-language-processing-an-introduction-to-natural-language...", "snippet": "One step is to be sure to use a <b>training</b> corpus that has a <b>similar</b> genre to whatever task we are trying to accomplish. To build a language model for translating legal documents, we need a <b>training</b> corpus of legal documents. To build a language model for a question-answering system, we need a <b>training</b> corpus of questions. It is equally important to get <b>training</b> data in the appropriate dialect or variety, especially when processing social media posts or spoken transcripts. For example some ...", "dateLastCrawled": "2022-01-18T13:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Deep Learning With PyTorch | Azizi Othman - Academia.edu", "url": "https://www.academia.edu/49004210/Deep_Learning_With_PyTorch", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/49004210/Deep_Learning_With_PyTorch", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-02T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "product management | <b>Thoughts on learning and work</b>", "url": "https://bessiechu.wordpress.com/category/product-management/", "isFamilyFriendly": true, "displayUrl": "https://bessiechu.wordpress.com/category/product-management", "snippet": "Posts about product management written by bessiechu. what you\u2019re doing is aligned with what you want to be doing", "dateLastCrawled": "2022-01-16T22:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Lexical Configuration and Lexical Engagement: When</b> Adults Learn New ...", "url": "https://www.researchgate.net/publication/6439215_Lexical_Configuration_and_Lexical_Engagement_When_Adults_Learn_New_Words", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/6439215", "snippet": "Following the <b>training</b>, responses were slower to the trained, but <b>not</b> to the untrained, words, indicating competition between newly-acquired and well-established meanings. This effect was smaller ...", "dateLastCrawled": "2021-09-17T15:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "product | Thoughts on learning and work", "url": "https://bessiechu.wordpress.com/category/product/", "isFamilyFriendly": true, "displayUrl": "https://bessiechu.wordpress.com/category/product", "snippet": "focusing outside of work somtimes. paths to passion are different. DVF. you havea vision and you create a product, and he product takes over. \u201cpeople say I made the wrap dress, but the wrap dress made me\u201d. \u201cevery successful person feels like a loser at least twice a week. only losers don\u2019t feel like losers.\u201d.", "dateLastCrawled": "2022-02-01T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "CRL <b>Talks</b> - Past <b>Talks</b>", "url": "https://crl.ucsd.edu/talks/pasttalks.php", "isFamilyFriendly": true, "displayUrl": "https://crl.ucsd.edu/<b>talks</b>/past<b>talks</b>.php", "snippet": "Study 1 did <b>not</b> find evidence that bilinguals recruit executive functions to manage language competition; In contrast, Study 2 demonstrated that bilinguals <b>can</b> use perceptual cues to facilitate language control, and Study 3 found that trilinguals <b>can</b> and do apply higher-order cognitive abilities to support their comprehension across languages. Taken together, results of these studies do <b>not</b> support a strict specialization of language, but rather suggest complex and reciprocal language ...", "dateLastCrawled": "2022-01-19T09:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Hands-On Transfer Learning with Python: Implement advanced deep ...", "url": "https://dokumen.pub/hands-on-transfer-learning-with-python-implement-advanced-deep-learning-and-neural-network-models-using-tensorflow-and-keras-1788831306-9781788831307.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/hands-on-transfer-learning-with-python-implement-advanced-deep...", "snippet": "Now, instead of using all n <b>training</b> example to calculate the derivative, if we take a small random sample of the <b>training</b> example, we <b>can</b> still reasonably approximate the derivative. The \u2207E gradient gives an estimate of the weight update. We <b>can</b> control it further by multiplying it by a constant, \u03b5, called the learning rate. Taking a very high learning rate may increase of the optimization-objective function value instead of minimizing it. In SGD, weights are updated after each mini ...", "dateLastCrawled": "2021-12-15T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Machine <b>Learning in Asset Pricing 0691218706, 9780691218700</b> - DOKUMEN.PUB", "url": "https://dokumen.pub/machine-learning-in-asset-pricing-0691218706-9780691218700.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/machine-<b>learning-in-asset-pricing-0691218706-9780691218700</b>.html", "snippet": "From the <b>training</b> data set of alreadylabeled images, the ML algorithm learns the relationship between image pixels and the classification as a hot <b>dog</b> or <b>not</b> hot <b>dog</b>. Figure 1.2 provides a stylized illustration. Once trained, the algorithm <b>can</b> then be used to predict, for <b>not</b>-yet-classified images, whether they show a hot <b>dog</b> or <b>not</b> a hot <b>dog</b>. In other applications, trained ML algorithms may classify email as spam based on email content, predict tumors based on gene expression data, or ...", "dateLastCrawled": "2022-01-03T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ML Cheatsheet documentation", "url": "https://www.iamsiddharth.com/ML-Cheatsheet/", "isFamilyFriendly": true, "displayUrl": "https://www.iamsiddharth.com/ML-Cheatsheet", "snippet": "E.g. My <b>dog</b> barks, so all dogs must <b>bark</b>. In machine learning we often run into trouble when we extrapolate outside the range of our <b>training</b> data. Feature With respect to a dataset, a feature represents an attribute and value combination. Color is an attribute. \u201cColor is blue\u201d is a feature. In Excel terms, features are similar to cells. The term feature has other definitions in different contexts. Feature Selection Feature selection is the process of selecting relevant features from a ...", "dateLastCrawled": "2022-01-25T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Speech and Language Processing An Introduction to Natural Language ...", "url": "https://ebin.pub/speech-and-language-processing-an-introduction-to-natural-language-processing-computational-linguistics-and-speech-recognition-3nbsped.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/speech-and-language-processing-an-introduction-to-natural-language...", "snippet": "Thus if our <b>training</b> corpus contains, say the words low, new, newer, but <b>not</b> lower, then if the word lower appears in our test corpus, our system will <b>not</b> know what to do with it. To deal with this unknown word problem, modern tokenizers often automatically induce sets of tokens that include tokens smaller than words, called subwords. Subwords <b>can</b> be arbitrary substrings, or they <b>can</b> be meaning-bearing units like the morphemes -est or -er. (A morpheme is the smallest meaning-bearing unit of ...", "dateLastCrawled": "2022-01-18T13:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "\u80e1\u58ee\u9e9f\u8bed\u8a00\u5b66\u590d\u4e60\u53ca\u7b54\u6848_\u6587\u6863\u4e4b\u5bb6", "url": "http://www.doczj.com/doc/93194aa9d1f34693daef3efe.html", "isFamilyFriendly": true, "displayUrl": "www.doczj.com/doc/93194aa9d1f34693daef3efe.html", "snippet": "B. <b>can</b> <b>not</b> be combined with other morphemes. C. <b>can</b> either be free or bound. D. have to be combined with other morphemes. 28. ____ modify the meaning of the stem, but usually do <b>not</b> change the part of speech of the original word. A. Prefixes. B. Suffixes. C. Roots. D. Affixes. 29. _____ are often <b>thought</b> to be the smallest meaningful units of ...", "dateLastCrawled": "2022-01-07T22:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Environmental sound classification using a regularized</b> deep ...", "url": "https://www.sciencedirect.com/science/article/pii/S0003682X2030493X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0003682X2030493X", "snippet": "1. Introduction. The use of sound classification tasks has a huge potential in intelligent audio surveillance systems , classification of different musical instruments , , robot navigation , health care or medical problems , customer&#39;s or buyers alerts , crime alert systems , voice activity recognition , audio-based disaster identification , environment monitoring , etc.The involvement of sound classification in numerous applications indicates its importance.", "dateLastCrawled": "2022-01-30T05:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Can</b> recursive neural tensor networks learn logical reasoning? \u2013 arXiv ...", "url": "https://www.arxiv-vanity.com/papers/1312.6192/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1312.6192", "snippet": "Deep learning methods in NLP which learn vector representations for words have seen successful uses in recent years on increasingly sophisticated tasks [1, 2, 3, 4].Given the still modest performance of semantically rich NLP systems in many domains\u2014question answering and machine translation, for instance\u2014it is worth exploring the degree to which learned vectors <b>can</b> serve as general purpose semantic representations.", "dateLastCrawled": "2021-09-27T02:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Deep Learning With PyTorch | Azizi Othman - Academia.edu", "url": "https://www.academia.edu/49004210/Deep_Learning_With_PyTorch", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/49004210/Deep_Learning_With_PyTorch", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-02T22:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Environmental sound classification using a regularized</b> deep ...", "url": "https://www.researchgate.net/publication/341172446_Environmental_sound_classification_using_a_regularized_deep_convolutional_neural_network_with_data_augmentation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/341172446_Environmental_sound_classification...", "snippet": "As <b>can</b> be seen from Table 5, our model has better performance than DS-CNN 37 and <b>can</b> compete with M-LM-C CNN 38. Although <b>compared</b> with the best models such as Two-Stream CNN 40 and TSCNN-DS 41 ...", "dateLastCrawled": "2021-12-07T20:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "ML Cheatsheet documentation", "url": "https://www.iamsiddharth.com/ML-Cheatsheet/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.iamsiddharth.com/ML-Cheatsheet/index.html", "snippet": "E.g. My <b>dog</b> barks, so all dogs must <b>bark</b>. In machine learning we often run into trouble when we extrapolate outside the range of our <b>training</b> data. Feature With respect to a dataset, a feature represents an attribute and value combination. Color is an attribute. \u201cColor is blue\u201d is a feature. In Excel terms, features are similar to cells. The term feature has other definitions in different contexts. Feature Selection Feature selection is the process of selecting relevant features from a ...", "dateLastCrawled": "2022-02-01T15:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Texture images classification using improved local quinary pattern and ...", "url": "https://link.springer.com/article/10.1007/s00521-021-06454-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s00521-021-06454-0", "snippet": "Texture images classification plays an important role in machine vision that <b>can</b> be used to distinguish the surface and objects of an image from each other. Texture classification is a two-phases process consisting of feature extraction and classification. Feature extraction is a very important step in texture classification. Thus, we use improved local quinary pattern (ILQP) as descriptor to detect texture information of the images in feature extraction phase. Besides, in the classification ...", "dateLastCrawled": "2021-12-13T12:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A practical guide to <b>MaxEnt for modeling species&#39; distributions: What</b> ...", "url": "https://www.researchgate.net/publication/264532217_A_practical_guide_to_MaxEnt_for_modeling_species'_distributions_What_it_does_and_why_inputs_and_settings_matter", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/264532217_A_practical_guide_to_MaxEnt_for...", "snippet": "To avoid over-fitting, which <b>can</b> result in predictions that reflect idiosyncrasies in the data rather than ecological requirements of the species ), we increased <b>regularization</b> to a beta value of ...", "dateLastCrawled": "2022-01-29T00:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Hands-On Transfer Learning with Python: Implement advanced deep ...", "url": "https://dokumen.pub/hands-on-transfer-learning-with-python-implement-advanced-deep-learning-and-neural-network-models-using-tensorflow-and-keras-1788831306-9781788831307.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/hands-on-transfer-learning-with-python-implement-advanced-deep...", "snippet": "Simply put, transfer learning <b>can</b> save <b>training</b> time and extend the usefulness of existing machine learning models. It is also an invaluable technique for tasks where the large amounts of <b>training</b> data typically required for <b>training</b> a model from scratch are <b>not</b> available. Becoming familiar with complex concepts and implementing these concepts in practice are two very different things, and this is where Hands-On Transfer Learning with Python shines. The book starts with a deep dive into both ...", "dateLastCrawled": "2021-12-15T01:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "product management | <b>Thoughts on learning and work</b>", "url": "https://bessiechu.wordpress.com/category/product-management/", "isFamilyFriendly": true, "displayUrl": "https://bessiechu.wordpress.com/category/product-management", "snippet": "Posts about product management written by bessiechu. what you\u2019re doing is aligned with what you want to be doing", "dateLastCrawled": "2022-01-16T22:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "product | Thoughts on learning and work", "url": "https://bessiechu.wordpress.com/category/product/", "isFamilyFriendly": true, "displayUrl": "https://bessiechu.wordpress.com/category/product", "snippet": "focusing outside of work somtimes. paths to passion are different. DVF. you havea vision and you create a product, and he product takes over. \u201cpeople say I made the wrap dress, but the wrap dress made me\u201d. \u201cevery successful person feels like a loser at least twice a week. only losers don\u2019t feel like losers.\u201d.", "dateLastCrawled": "2022-02-01T13:12:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Regularization</b> \u2014 Understanding <b>L1</b> and L2 <b>regularization</b> for Deep <b>Learning</b>", "url": "https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2-regularization-for-deep-learning-a7b9e4a409bf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>regularization</b>-understanding-<b>l1</b>-and-l2...", "snippet": "Understanding what <b>regularization</b> is and why it is required for <b>machine</b> <b>learning</b> and diving deep to clarify the importance of <b>L1</b> and L2 <b>regularization</b> in Deep <b>learning</b>.", "dateLastCrawled": "2022-02-01T00:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Regularization</b> : What? Why? and How? (Part -1) | by Siddhant Rai ...", "url": "https://medium.com/mlearning-ai/regularization-what-why-and-how-part-1-ef6bdb6bafea", "isFamilyFriendly": true, "displayUrl": "https://medium.com/m<b>learning</b>-ai/<b>regularization</b>-what-why-and-how-part-1-ef6bdb6bafea", "snippet": "Like, a penalty term that accounts for larger weights as well as sparsity as in case of <b>L1</b> <b>regularization</b>. We have an entire section on <b>L1</b> and l2, so, bear with me. We have an entire section on <b>L1</b> ...", "dateLastCrawled": "2022-01-28T00:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> Succinct Models: Pipelined Compression with <b>L1</b>-<b>Regularization</b> ...", "url": "https://aclanthology.org/C16-1261.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/C16-1261.pdf", "snippet": "<b>Learning</b> Succinct Models: Pipelined Compression with <b>L1</b>-<b>Regularization</b>, Hashing, Elias Fano Indices, and Quantization Hajime Senumay z and Akiko Aizawaz y yUniversity of Tokyo, Tokyo, Japan zNational Institute of Informatics, Tokyo, Japan fsenuma,aizawa g@nii.ac.jp Abstract The recent proliferation of smart devices necessitates methods to learn small-sized models. This paperdemonstratesthat ifthere arem featuresin totalbutonlyn = o(p m) featuresare required to distinguish examples, with (log ...", "dateLastCrawled": "2021-11-20T08:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "CPSC 340: Data Mining <b>Machine</b> <b>Learning</b>", "url": "https://www.cs.ubc.ca/~schmidtm/Courses/340-F16/L35.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~schmidtm/Courses/340-F16/L35.pdf", "snippet": "\u2022Exam <b>analogy</b> for types of supervised/semi-supervised <b>learning</b>: \u2013Regular supervised <b>learning</b>: ... Feature Selection and <b>L1</b>-<b>Regularization</b> \u2022Feature selection is task of finding relevant variables. \u2013Can be hard to precisely define relevant _. \u2022Hypothesis testing methods: \u2013Do tests trying to make variable j conditionally independent of y. \u2013Ignores effect size. \u2022Search and score methods: \u2013Define score (L0-norm) and search for variables that optimize it. \u2013Finding optimal ...", "dateLastCrawled": "2021-11-22T01:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What\u2019<b>s the fuss about Regularization</b>? | by Sagar Mainkar | Towards Data ...", "url": "https://towardsdatascience.com/whats-the-fuss-about-regularization-24a4a1eadb1", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/what<b>s-the-fuss-about-regularization</b>-24a4a1eadb1", "snippet": "If you are someone who would like to understand what is \u201c<b>Regularization</b>\u201d and how it helps then read on. Let me start w i th an <b>analogy</b> , <b>machine</b> <b>learning</b> models are like parents, they have an affinity towards their children the more time they spend with their children more is the affinity and the children become their world. Same is the ...", "dateLastCrawled": "2022-02-01T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Bias-<b>variance</b> tradeoff in <b>machine</b> <b>learning</b>: an intuition | by Mahbubul ...", "url": "https://towardsdatascience.com/bias-variance-tradeoff-in-machine-learning-an-intuition-da85228c5074", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/bias-<b>variance</b>-tradeoff-in-<b>machine</b>-<b>learning</b>-an-intuition...", "snippet": "Two types of <b>regularization</b> are commonly used \u2014 <b>L1</b> (LASSO regression) and L2 (Ridge regression) and they are controlled by a hyperparameter \u03bb. Summary. To summarize the concept of bias-<b>variance</b> tradeoff: If a model is too simple and underfits the training data, it performs poorly in real prediction as well. A model highly tuned on training data may not perform well either. The bias-<b>variance</b> tradeoff allows for examining the balance to find a suitable model. There are two ways to examine ...", "dateLastCrawled": "2022-02-02T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Model 1: accuracy = 92%. Model 2: accuracy = 95%. Model 2 has higher accuracy than model 1, but model 2 is useless. This is called accuracy paradox, which means the model with higher accuracy may not have better generalization power. In general, when TP &lt; FP, the accuracy will always increase when we change the classifier to always output &#39;negative&#39;.Conversely, when TN &lt; FN, the same will happen when we change the classifier to always output &#39;positive&#39; [1].. Recall@k", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "lasso - Why do we only see $<b>L_1</b>$ and $L_2$ <b>regularization</b> but not other ...", "url": "https://stats.stackexchange.com/questions/269298/why-do-we-only-see-l-1-and-l-2-regularization-but-not-other-norms", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/269298", "snippet": "That covers the gamut. In effect, a linear combination of an <b>L 1</b> and L 2 norm approximates any norm to second order at the origin--and this is what matters most in regression without outlying residuals. (**) The l 0 -&quot;norm&quot; lacks homogeneity, which is one of the axioms for norms. Homogeneity means for \u03b1 \u2265 0 that \u2016 \u03b1 x \u2016 = \u03b1 \u2016 x \u2016.", "dateLastCrawled": "2022-02-01T12:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "regression - Why <b>L1</b> norm for sparse models - Cross Validated", "url": "https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/45643", "snippet": "$\\begingroup$ @AlexYashin that is correct - if we only updated the weights based on <b>L1</b> <b>regularization</b>, we might end up having weights that oscillate near 0. But we never use <b>regularization</b> alone to adjust the weights. We use the <b>regularization</b> in combination with optimizing a loss function. In that way, the <b>regularization</b> pushes the weights towards zero while we at the same time try to push the weights to a value that optimize the predictions. A second aspect is the <b>learning</b> rate. With a ...", "dateLastCrawled": "2022-01-26T23:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Summed up 200 bat <b>machine</b> <b>learning</b> interview questions, which are worth ...", "url": "https://chowdera.com/2022/01/202201111148358002.html", "isFamilyFriendly": true, "displayUrl": "https://chowdera.com/2022/01/202201111148358002.html", "snippet": "<b>Machine</b> <b>learning</b> L1 Regularization and L2 The difference between regularization is \uff1f \uff08AD\uff09 A. Use L1 You can get sparse weights . B. Use L1 You can get the smooth weight . C. Use L2 You can get sparse weights . D. Use L2 You can get the smooth weight . right key \uff1a\uff08AD\uff09 @ Liu Xuan 320. L1 Regularization tends to be sparse , It automatically selects features , Remove some useless features , In other words, the corresponding weight of these features is set to 0. L2 The main function ...", "dateLastCrawled": "2022-01-31T12:24:00.0000000Z", "language": "ja", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>learning</b> in the prediction of cancer therapy", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321893/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8321893", "snippet": "The least absolute shrinkage and selection operator (lasso) regularization (known as <b>L1 regularization) is similar</b> to the ridge regularization, but in this case, the added value is the absolute value of the slope multiplied by \u03bb. The elastic net algorithm adds contributions from both L1 and L2 regularization; the cost function = min (sum of the squared residuals + \u03bb * squared value of slope + \u03bb * absolute value of slope). The \u03bb parameter is a positive number that represents ...", "dateLastCrawled": "2022-01-26T21:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How to <b>Explain</b> Each <b>Machine</b> <b>Learning</b> Model at an Interview | by Terence ...", "url": "https://towardsdatascience.com/how-to-explain-each-machine-learning-model-at-an-interview-499d82f91470", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-<b>explain</b>-each-<b>machine</b>-<b>learning</b>-model-at-an...", "snippet": "Lasso Regression, also known as <b>L1 Regularization, is similar</b> to Ridge regression. The only difference is that the penalty is calculated with the absolute value of the slope instead. Logistic Regression . Logistic Regression is a classification technique that also finds a \u2018line of best fit\u2019. However, unlike linear regression where the line of best fit is found using least squares, logistic regression finds the line (logistic curve) of best fit using maximum likelihood. This is done ...", "dateLastCrawled": "2022-02-03T13:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>learning</b> in the prediction of cancer therapy - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S2001037021002932", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2001037021002932", "snippet": "The least absolute shrinkage and selection operator (lasso) regularization (known as <b>L1 regularization) is similar</b> to the ridge regularization, but in this case, the added value is the absolute value of the slope multiplied by \u03bb. The elastic net algorithm adds contributions from both L1 and L2 regularization; the cost function = min (sum of the squared residuals + \u03bb * squared value of slope + \u03bb * absolute value of slope). The \u03bb parameter is a positive number that represents ...", "dateLastCrawled": "2022-01-05T00:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Brief Guide on Key <b>Machine</b> <b>Learning</b> Algorithms | i2tutorials", "url": "https://www.i2tutorials.com/brief-guide-on-key-machine-learning-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.i2tutorials.com/brief-guide-on-key-<b>machine</b>-<b>learning</b>-algorithms", "snippet": "Brief Guide on Key <b>Machine</b> <b>Learning</b> Algorithms Linear Regression Linear Regression includes finding a \u2018line of best fit\u2019 that represents a dataset using the least squares technique. The least squares method involves finding a linear equation that limits the sum of squared residuals. A residual is equivalent to the actual minus predicted value. To give a model, the red line is a better line of best fit compared to the green line because it is closer to the points, and thus, the residuals ...", "dateLastCrawled": "2022-01-27T12:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Deep Learning</b> - GitHub Pages", "url": "https://srdas.github.io/DLBook/ImprovingModelGeneralization.html", "isFamilyFriendly": true, "displayUrl": "https://srdas.github.io/DLBook/ImprovingModelGeneralization.html", "snippet": "The first three techniques are well known from <b>Machine</b> <b>Learning</b> days, and continue to be used for DLN models. The last three techniques on the other hand have been specially designed for DLNs, and were discovered in the last few years. They also tend to be more effective than the older ML techniques. Batch Normalization was already described in Chapter 7 as a way of Normalizing activations within a model, and it is also very effective as a Regularization technique. These techniques are ...", "dateLastCrawled": "2022-02-02T20:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to Explain Key <b>Machine</b> <b>Learning</b> Algorithms at an Interview - <b>KDnuggets</b>", "url": "https://www.kdnuggets.com/2020/10/explain-machine-learning-algorithms-interview.html", "isFamilyFriendly": true, "displayUrl": "https://www.<b>kdnuggets</b>.com/2020/10/explain-<b>machine</b>-<b>learning</b>-algorithms-interview.html", "snippet": "Also, since we are solving for y, P(X) is a constant, which means that we can remove it from the equation and introduce a proportionality.. Thus, the probability of each value of y is calculated as the product of the conditional probability of x n given y.. Support Vector Machines . Support Vector Machines are a classification technique that finds an optimal boundary, called the hyperplane, which is used to separate different classes.", "dateLastCrawled": "2022-01-21T10:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>learning</b> in the prediction of cancer therapy - researchgate.net", "url": "https://www.researchgate.net/publication/353107491_Machine_learning_in_the_prediction_of_cancer_therapy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353107491_<b>Machine</b>_<b>learning</b>_in_the_prediction...", "snippet": "PDF | Resistance to therapy remains a major cause of cancer treatment failures, resulting in many cancer-related deaths. Resistance can occur at any... | Find, read and cite all the research you ...", "dateLastCrawled": "2021-10-24T07:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Python <b>Machine</b> <b>Learning</b>: <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> with Python ...", "url": "https://ebin.pub/python-machine-learning-machine-learning-and-deep-learning-with-python-scikit-learn-and-tensorflow-2-3rd-edition-3nbsped-9781789955750-1789955750.html", "isFamilyFriendly": true, "displayUrl": "https://ebin.pub/python-<b>machine</b>-<b>learning</b>-<b>machine</b>-<b>learning</b>-and-deep-<b>learning</b>-with...", "snippet": "Many <b>machine</b> <b>learning</b> algorithms that we will encounter throughout this book require some sort of feature scaling for optimal performance, which we will discuss in more detail in Chapter 3, A Tour of <b>Machine</b> <b>Learning</b> Classifiers Using scikit-learn, and Chapter 4, Building Good Training Datasets \u2013 Data Preprocessing. Gradient descent is one of the many algorithms that benefit from feature scaling. In this section, we will use a feature scaling method called standardization, which gives our ...", "dateLastCrawled": "2022-01-31T17:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine</b> <b>Learning with SAS Viya 9781951685317, 1951685318</b> - DOKUMEN.PUB", "url": "https://dokumen.pub/machine-learning-with-sas-viya-9781951685317-1951685318.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>machine</b>-<b>learning-with-sas-viya-9781951685317-1951685318</b>.html", "snippet": "<b>Machine</b> <b>learning</b> is a branch of artificial intelligence (AI) that automates the building of models that learn from data, identify patterns, and predict future results\u2014with minimal human intervention. <b>Machine</b> <b>learning</b> is not all science fiction. Common examples in use today include self-driving cars, online recommenders such as movies that you might like on Netflix or products from Amazon, sentiment detection on Twitter, or real-time credit card fraud detection. Statistical Modeling Versus ...", "dateLastCrawled": "2022-01-05T15:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Python Machine Learning 9781783555130, 1783555130</b> - DOKUMEN.PUB", "url": "https://dokumen.pub/python-machine-learning-9781783555130-1783555130-s-7419445.html", "isFamilyFriendly": true, "displayUrl": "https://dokumen.pub/<b>python-machine-learning-9781783555130-1783555130</b>-s-7419445.html", "snippet": "Many <b>machine</b> <b>learning</b> algorithms also require that the selected features are on the same scale for optimal performance, which is often achieved by transforming the features in the range [0, 1] or a standard normal distribution with zero mean and unit variance, as we will see in the later chapters. Some of the selected features may be highly correlated and therefore redundant to a certain degree. In those cases, dimensionality reduction techniques are useful for compressing the features onto ...", "dateLastCrawled": "2022-01-31T17:51:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Regularization</b> in Deep <b>Learning</b> \u2014 L1, L2, and Dropout | Towards Data ...", "url": "https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>regularization</b>-in-deep-<b>learning</b>-l1-l2-and-dropout-377e...", "snippet": "On the other hand, the <b>L1 regularization can be thought of as</b> an equation where the sum of modules of weight values is less than or equal to a value s. This would look like the following expression: |W1| + |W2| \u2264 s. Basically the introduced equations for L1 and L2 regularizations are constraint functions, which we can visualize: Source: An Introduction to Statistical <b>Learning</b> by Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. The left image shows the constraint function ...", "dateLastCrawled": "2022-02-02T18:48:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(l1 regularization)  is like +(training a dog not to bark)", "+(l1 regularization) is similar to +(training a dog not to bark)", "+(l1 regularization) can be thought of as +(training a dog not to bark)", "+(l1 regularization) can be compared to +(training a dog not to bark)", "machine learning +(l1 regularization AND analogy)", "machine learning +(\"l1 regularization is like\")", "machine learning +(\"l1 regularization is similar\")", "machine learning +(\"just as l1 regularization\")", "machine learning +(\"l1 regularization can be thought of as\")", "machine learning +(\"l1 regularization can be compared to\")"]}