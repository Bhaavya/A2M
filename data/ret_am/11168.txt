{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "The main concept behind <b>bias</b> mitigation is similar, however: <b>given</b> a set of fairness metrics, the goal is to either adapt the algorithm, the predictions, or the data to increase fairness. Yao and Huang (2017) provide an in-processing approach for including fairness aspects when building collaborative filtering recommender systems. Specifically, they include the respective fairness <b>metric</b> into the derivative formulation used in the matrix factorization step, and adjust the derivatives ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Fairness metrics overview</b> - <b>IBM</b>", "url": "https://www.ibm.com/docs/SSQNUZ_2.5.0/wos/wos-fairness-ovr.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ibm.com</b>/docs/SSQNUZ_2.5.0/wos/wos-fairness-ovr.html", "snippet": "When potential <b>bias</b> is detected, Watson OpenScale performs several functions to confirm whether the <b>bias</b> is real. Watson OpenScale perturbs the data by flipping the monitored value to the reference value and then running this new record through the model. It then surfaces the resulting output as the de-biased output. Watson OpenScale also trains a shadow de-biased model that it then uses to detect when a model is going to make a biased prediction.", "dateLastCrawled": "2022-01-26T00:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Predicting Outcomes of Legal Cases</b> <b>based</b> on Legal Factors using ...", "url": "https://www.sciencedirect.com/science/article/pii/S1877050920307584", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050920307584", "snippet": "Hence, descriptors considered for <b>predicting</b> <b>outcomes</b> are extra-judicial factors that may generate or represent human <b>bias</b>. Examples of these factors are votes of other justices [7], justice gender, case origin [8], petitioner type, respondent type, the ideological direction of the court [9], etc. The research works following this approach are [5-10]. 2) Linguistic <b>based</b> Approach: Another approach considers the linguistic features of legal judgments for <b>predicting</b> <b>outcomes</b>. Ngo [11] tried to ...", "dateLastCrawled": "2022-02-02T04:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Understanding <b>Bias</b> in Machine Learning Models - Arize AI", "url": "https://arize.com/blog/understanding-bias-in-ml-models/", "isFamilyFriendly": true, "displayUrl": "https://arize.com/blog/understanding-<b>bias</b>-in-ml-models", "snippet": "Also, to decrease feature <b>bias</b>, you need to account for factors that have a large effect on the model\u2019s <b>outcomes</b> being extremely skewed when deployed to a whole population \u2014 such as gender, socioeconomic status, racial characteristics, and regional preferences. For example, if we are training a model to predict heart failure in US adults and the dataset used to train the model is predominantly white males, the final model won\u2019t be properly representative of women or non-white males ...", "dateLastCrawled": "2022-02-01T07:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>How to Best Understand Forecast Bias</b> - <b>Brightwork Research &amp; Analysis</b>", "url": "https://www.brightworkresearch.com/forecastbias/", "isFamilyFriendly": true, "displayUrl": "https://www.brightworkresearch.com/forecast<b>bias</b>", "snippet": "Forecasting <b>bias</b> can be <b>like</b> any other forecasting error, <b>based</b> upon a statistical model or judgment method that is not sufficiently predictive, or it can be quite different when it is premeditated in response to incentives. <b>Bias</b> is easy to demonstrate but difficult to eliminate, as exemplified by the financial services industry. Forecast <b>Bias</b> List. Forecast <b>bias</b> is a tendency for a forecast to be consistently higher or lower than the actual value. Forecast <b>bias</b> is distinct from forecast ...", "dateLastCrawled": "2022-02-03T02:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Eliminating AI <b>Bias</b>. Identifying AI <b>Bias</b> and knowing how to\u2026 | by ...", "url": "https://towardsdatascience.com/eliminating-ai-bias-5b8462a84779", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/eliminating-ai-<b>bias</b>-5b8462a84779", "snippet": "An example is where a model was developed to predict how much nitrogen-<b>based</b> fertilizer should be <b>given</b> to wheat, barley, and canola plants. When developing the training set for this model, only features such as the type of plant, the date the plant was planted, the date the plant yield was measured, and UV light wavelengths emitted by the plant were considered for training the machine learning algorithm. The xgboost model (gradient-boosted tree regression model) that is known to perform ...", "dateLastCrawled": "2022-02-02T06:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Bias Mitigation \u2014 Methods</b>. How to build a Fair Model | by Abhishek ...", "url": "https://adabhishekdabas.medium.com/bias-mitigation-methods-a2a6618dbdc7", "isFamilyFriendly": true, "displayUrl": "https://adabhishekdabas.medium.com/<b>bias-mitigation-methods</b>-a2a6618dbdc7", "snippet": "Provides favorable <b>outcomes</b> to unprivileged groups and unfavorable <b>outcomes</b> to privileged groups in a confidence band around the decision boundary with the highest uncertainty. 6. FairML: It is a toolbox written in python to audit the Machine Learning Models for fairness and <b>Bias</b>. The main idea behind FairML is to measure the dependence of the model on its inputs. The model examines if the model is sensitive to a particular feature. Perturbation is one of the techniques used in the library ...", "dateLastCrawled": "2022-01-27T02:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Predicting Horse Racing Outcomes</b> | Data Science Blog", "url": "https://nycdatascience.com/blog/student-works/capstone/predicting-horse-racing-outcomes/", "isFamilyFriendly": true, "displayUrl": "https://nycdatascience.com/blog/student-works/capstone/<b>predicting-horse-racing-outcomes</b>", "snippet": "<b>Given</b> the focus on strictly <b>predicting</b> horses that finished first, the team elected to develop a baseline model using only the data provided and compare the results to strategies of selecting winners using the TIPS Index and predictions made by the \u201cwisdom of crowds\u201d inherent in the Odds favorite. This choice was made to a large extent so that the results could be clear to the client, and the team would be able to present options of how to remedy issues that were encountered in the data ...", "dateLastCrawled": "2022-02-03T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Machine Learning Algorithm for <b>Predicting</b> <b>Outcomes</b> of MLB Games | by ...", "url": "https://towardsdatascience.com/a-machine-learning-algorithm-for-predicting-outcomes-of-mlb-games-fa17710f3c04", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-machine-learning-algorithm-for-<b>predicting</b>-<b>outcomes</b>-of...", "snippet": "Raw data is impervious to cognitive <b>bias</b> \u2014 devoid of human emoti o n and predisposition. Guided by this precept, Billy Beane\u2019s 2001 Oakland As designed a new statistical blueprint for championship-aspiring ballclubs, and precipitated a data analytics revolution that spread <b>like</b> wildfire throughout all facets of professional sports. As Beane discovered, baseball\u2019s wealth of data makes it conducive to predictive analytics. The problem I have chosen to explore is employing machine ...", "dateLastCrawled": "2022-02-03T07:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 9, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>List of cognitive biases</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/List_of_cognitive_biases", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>List_of_cognitive_biases</b>", "snippet": "The Normalcy <b>bias</b>, a form of cognitive dissonance, is the refusal to plan for, or react to, a disaster which has never happened before.; Effort justification is a person&#39;s tendency to attribute greater value to an outcome if they had to put effort into achieving it. This can result in more value being applied to an outcome than it actually has. An example of this is the IKEA effect, the tendency for people to place a disproportionately high value on objects that they partially assembled ...", "dateLastCrawled": "2022-01-30T07:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "The main concept behind <b>bias</b> mitigation <b>is similar</b>, however: <b>given</b> a set of fairness metrics, the goal is to either adapt the algorithm, the predictions, or the data to increase fairness. Yao and Huang (2017) provide an in-processing approach for including fairness aspects when building collaborative filtering recommender systems. Specifically, they include the respective fairness <b>metric</b> into the derivative formulation used in the matrix factorization step, and adjust the derivatives ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Latent Class Analysis With Distal <b>Outcomes</b>: A Flexible Model-<b>Based</b> Approach", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4240499/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4240499", "snippet": "Common Approaches <b>to Predicting</b> a Distal Outcome From Latent Class Membership. There are two common classify-analyze approaches to estimating the effect of C on Z.The most straightforward approach is to assign individuals to latent classes <b>based</b> on their maximum posterior probability (see, e.g., Nagin, 2005).Specifically, a latent class model that only includes manifest indicators (i.e., an unconditional latent class model) is fit to the observed X variables and each individual\u2019s vector of ...", "dateLastCrawled": "2022-01-29T05:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Predicting Outcomes of Legal Cases</b> <b>based</b> on Legal Factors using ...", "url": "https://www.sciencedirect.com/science/article/pii/S1877050920307584", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050920307584", "snippet": "Hence, descriptors considered for <b>predicting</b> <b>outcomes</b> are extra-judicial factors that may generate or represent human <b>bias</b>. Examples of these factors are votes of other justices [7], justice gender, case origin [8], petitioner type, respondent type, the ideological direction of the court [9], etc. The research works following this approach are [5-10]. 2) Linguistic <b>based</b> Approach: Another approach considers the linguistic features of legal judgments for <b>predicting</b> <b>outcomes</b>. Ngo [11] tried to ...", "dateLastCrawled": "2022-02-02T04:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Effective deep learning approaches for <b>predicting</b> COVID-19 <b>outcomes</b> ...", "url": "https://www.nature.com/articles/s41598-022-05532-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-022-05532-0", "snippet": "The most accurate prognostic models for COVID-19 <b>outcomes</b> will rely <b>on information</b> that is most specific to risk for severe COVID-19 disease. In the setting of limited patient data, it is ...", "dateLastCrawled": "2022-02-03T03:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Measure <b>Posttraining Data and Model Bias</b> - Amazon SageMaker", "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-bias.html", "isFamilyFriendly": true, "displayUrl": "https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-<b>bias</b>.html", "snippet": "Amazon SageMaker Clarify provides eleven <b>posttraining data and model bias</b> metrics to help quantify various conceptions of fairness. These concepts cannot all be satisfied simultaneously and the selection depends on specifics of the cases involving potential <b>bias</b> being analyzed. Most of these metrics are a combination of the numbers taken from the binary classification confusion matrices for the different demographic groups. Because fairness and <b>bias</b> can be defined by a wide range of metrics ...", "dateLastCrawled": "2022-01-29T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Predicting Horse Racing Outcomes</b> | Data Science Blog", "url": "https://nycdatascience.com/blog/student-works/capstone/predicting-horse-racing-outcomes/", "isFamilyFriendly": true, "displayUrl": "https://nycdatascience.com/blog/student-works/capstone/<b>predicting-horse-racing-outcomes</b>", "snippet": "<b>Given</b> the focus on strictly <b>predicting</b> horses that finished first, the team elected to develop a baseline model using only the data provided and compare the results to strategies of selecting winners using the TIPS Index and predictions made by the \u201cwisdom of crowds\u201d inherent in the Odds favorite. This choice was made to a large extent so that the results could be clear to the client, and the team would be able to present options of how to remedy issues that were encountered in the data ...", "dateLastCrawled": "2022-02-03T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Machine learning v. traditional regression models <b>predicting</b> treatment ...", "url": "https://www.cambridge.org/core/journals/psychological-medicine/article/machine-learning-v-traditional-regression-models-predicting-treatment-outcomes-for-bingeeating-disorder-from-a-randomized-controlled-trial/A1CB0BF829A2D86CC791A40F5FCDC053", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/psychological-medicine/article/machine...", "snippet": "The primary goal was to determine whether ML was superior to traditional models for <b>predicting</b> treatment <b>outcomes</b>. The secondary goal was to compare predictive accuracy across different ML models paired with different forms of resampling, to serve as an example for future researchers considering using ML. A final goal was to identify variables that most strongly predict BED treatment <b>outcomes</b>. We acknowledge that this last goal diverges from ML&#39;s primary purpose/promise, which is increasing ...", "dateLastCrawled": "2022-01-15T09:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Exploiting oddsmaker <b>bias</b> to improve the prediction of NFL <b>outcomes</b> ...", "url": "https://deepai.org/publication/exploiting-oddsmaker-bias-to-improve-the-prediction-of-nfl-outcomes", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../exploiting-oddsmaker-<b>bias</b>-to-improve-the-prediction-of-nfl-<b>outcomes</b>", "snippet": "Since <b>bias</b> can be considered the amount of <b>information</b> the spread provides about the outcome, we can use Shannon entropy (Shannon ) as an effective <b>metric</b> to for this purpose. In this respect, Shannon entropy ( H ( s ) = \u2212 \u2211 t p ( o = t | s ) log 2 ( p ( o = t | s ) ) ) reflects the amount of uncertainty associated with <b>information</b> carried by spread estimates in their ability to predict <b>outcomes</b> (for each team ( t )).", "dateLastCrawled": "2021-12-05T06:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>How to Best Understand Forecast Bias</b> - <b>Brightwork Research &amp; Analysis</b>", "url": "https://www.brightworkresearch.com/forecastbias/", "isFamilyFriendly": true, "displayUrl": "https://www.brightworkresearch.com/forecast<b>bias</b>", "snippet": "Forecast <b>bias</b> is generally not tracked in most forecasting applications in terms of outputting a specific <b>metric</b>. However one can very easily compare the historical demand to the historical forecast line, to see if the historical forecast is above or below the historical demand. The problem in doing this is is that normally just the final forecast ends up being tracked in forecasting application (the other forecasts are often in other systems), and each forecast has to be measured for ...", "dateLastCrawled": "2022-02-03T02:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 9, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>List of cognitive biases</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/List_of_cognitive_biases", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>List_of_cognitive_biases</b>", "snippet": "The Normalcy <b>bias</b>, a form of cognitive dissonance, is the refusal to plan for, or react to, a disaster which has never happened before.; Effort justification is a person&#39;s tendency to attribute greater value to an outcome if they had to put effort into achieving it. This can result in more value being applied to an outcome than it actually has. An example of this is the IKEA effect, the tendency for people to place a disproportionately high value on objects that they partially assembled ...", "dateLastCrawled": "2022-02-02T06:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "First, in both datasets the <b>bias</b> mitigation approach is successful in increasing fairness according to the specific target <b>metric</b>;i.e.,value-<b>based</b> <b>bias</b> mitigation reduces value unfairness, parity-<b>based</b> adjustment reduces parity in the empirical MovieLens dataset. Second, the effects of the <b>bias</b> mitigation on other metrics is complex, and thus representative of the complexity of using and comparing different definitions of fairness. In general, while the target fairness <b>metric</b> <b>can</b> be improved ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias Mitigation \u2014 Methods</b>. How to build a Fair Model | by Abhishek ...", "url": "https://adabhishekdabas.medium.com/bias-mitigation-methods-a2a6618dbdc7", "isFamilyFriendly": true, "displayUrl": "https://adabhishekdabas.medium.com/<b>bias-mitigation-methods</b>-a2a6618dbdc7", "snippet": "This <b>can</b> <b>be thought</b> of as something similar to a verified list of Nutrition Facts we see at the back of every food product!! Conclusion: There is no single definition of Fairness that <b>can</b> be quantified and integrated into the system. It is highly related to the real-world scenario where it is being implemented. 21 Fairness definitions and their policies by Arvind Narayanan. With all these tools and libraries for fairness, we input the sensitive attribute and select the performance <b>metric</b> ...", "dateLastCrawled": "2022-01-27T02:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>How to Best Understand Forecast Bias</b> - <b>Brightwork Research &amp; Analysis</b>", "url": "https://www.brightworkresearch.com/forecastbias/", "isFamilyFriendly": true, "displayUrl": "https://www.brightworkresearch.com/forecast<b>bias</b>", "snippet": "Forecast <b>bias</b> is generally not tracked in most forecasting applications in terms of outputting a specific <b>metric</b>. However one <b>can</b> very easily compare the historical demand to the historical forecast line, to see if the historical forecast is above or below the historical demand. The problem in doing this is is that normally just the final forecast ends up being tracked in forecasting application (the other forecasts are often in other systems), and each forecast has to be measured for ...", "dateLastCrawled": "2022-02-03T02:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Predicting</b> clinical <b>outcomes</b> in chordoma patients receiving ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4995658/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4995658", "snippet": "It is <b>thought</b> that volumes better reflect actual changes in tumor size and better reflect clinical <b>outcomes</b> . ... The use of clinical criteria retrospectively is perilous due to the possibility of <b>bias</b> influencing the <b>outcomes</b>. However, the clinical outcome groups were determined prior to the volumetric assessment and comparison to RECIST, limiting this concern. The heterogeneity of tumor locations is a major reason for the need to identify better imaging methods for chordoma and represents ...", "dateLastCrawled": "2022-01-20T21:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Addressing <b>bias</b> <b>from non-random missing attributes in health data</b>", "url": "http://hippo.ece.ufl.edu/wp-content/uploads/sites/63/2020/05/Addressing-Bias-from-Non-Random-Missing-Attributes-in-Health-Data.pdf", "isFamilyFriendly": true, "displayUrl": "hippo.ece.ufl.edu/wp-content/uploads/sites/63/2020/05/Addressing-<b>Bias</b>-from-Non-Random...", "snippet": "exhibit how failure to account for <b>bias</b> <b>can</b> distort performance, illustrating the importance of the proposed method. I. INTRODUCTION With the revolution of big data, health care systems <b>can</b> now utilize data to improve care delivery, quality, and processes. The idea of evidence-<b>based</b> medicine, with roots reaching back to the 19th century and earlier, has continued to develop as the health care \ufb01eld becomes more data-driven and literature-<b>based</b> [1]. Evidence-<b>based</b> medicine analyzes data to ...", "dateLastCrawled": "2021-11-10T01:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Machine learning v. traditional regression models <b>predicting</b> treatment ...", "url": "https://www.cambridge.org/core/journals/psychological-medicine/article/machine-learning-v-traditional-regression-models-predicting-treatment-outcomes-for-bingeeating-disorder-from-a-randomized-controlled-trial/A1CB0BF829A2D86CC791A40F5FCDC053", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/psychological-medicine/article/machine...", "snippet": "The primary goal was to determine whether ML was superior to traditional models for <b>predicting</b> treatment <b>outcomes</b>. The secondary goal was to compare predictive accuracy across different ML models paired with different forms of resampling, to serve as an example for future researchers considering using ML. A final goal was to identify variables that most strongly predict BED treatment <b>outcomes</b>. We acknowledge that this last goal diverges from ML&#39;s primary purpose/promise, which is increasing ...", "dateLastCrawled": "2022-01-15T09:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Predicting</b> first-time-in-college students\u2019 degree completion <b>outcomes</b> ...", "url": "https://link.springer.com/article/10.1007%2Fs10734-021-00790-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10734-021-00790-9", "snippet": "Machine learning learns from existing data by building models to achieve tasks such as classifying cases into categories, identifying natural subgroups in a population, or <b>predicting</b> future <b>outcomes</b> <b>based</b> on current <b>information</b> (Ayodele, 2010). In supervised machine learning (SML), algorithms identify patterns in data where <b>outcomes</b> are known, which <b>can</b> then be used to predict future, unknown <b>outcomes</b>. SML models the distribution of different <b>outcomes</b> <b>based</b> on predictor features (Kotsiantis,", "dateLastCrawled": "2022-01-29T14:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Building Comprehensible Customer <b>Churn</b> Prediction Models | by Rashid ...", "url": "https://medium.com/swlh/building-comprehensible-customer-churn-prediction-models-ca61ecce529d", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/building-comprehensible-customer-<b>churn</b>-prediction-models-ca61...", "snippet": "As a very rough rule of thumb, AUC <b>can</b> <b>be thought</b> of as letter grade, where 0.9 is \u201cA\u201d a, 0.8 is a \u201cB\u201d, 0.7 is \u201cC\u201d and 0.5 if \u201cF\u201d and so on. I\u2019m in generally happy with a model ...", "dateLastCrawled": "2022-01-26T02:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Predicting</b> adverse <b>outcomes</b> due <b>to diabetes complications with machine</b> ...", "url": "https://www.nature.com/articles/s41746-021-00394-8", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41746-021-00394-8", "snippet": "We aimed to develop a machine learning-<b>based</b> model for <b>predicting</b> adverse <b>outcomes</b> due to diabetes complications using administrative health data from the single-payer health system in Ontario ...", "dateLastCrawled": "2022-01-30T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Measurement of Health Outcomes: Reliability, Validity and</b> Re... : JPO ...", "url": "https://journals.lww.com/jpojournal/Fulltext/2006/01001/Measurement_of_Health_Outcomes__Reliability,.3.aspx", "isFamilyFriendly": true, "displayUrl": "https://<b>journals.lww.com</b>/jpojournal/Fulltext/2006/01001/Measurement_of_Health_<b>Outcomes</b>...", "snippet": "alth <b>outcomes</b>, including disability and quality of life. Reliability is a necessary but not sufficient characteristic of an outcome measure. It also is necessary to determine whether the measure actually captures the aspect of the phenomenon of interest. Validity is not a characteristic of an instrument. It <b>can</b> be determined only in relation to a particular question as it pertains to a defined population. Finally, outcome measures used to evaluate changes in patients over time must be ...", "dateLastCrawled": "2021-12-03T20:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Fairness metrics and <b>bias</b> mitigation strategies for rating predictions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0306457321001369", "snippet": "First, in both datasets the <b>bias</b> mitigation approach is successful in increasing fairness according to the specific target <b>metric</b>;i.e.,value-<b>based</b> <b>bias</b> mitigation reduces value unfairness, parity-<b>based</b> adjustment reduces parity in the empirical MovieLens dataset. Second, the effects of the <b>bias</b> mitigation on other metrics is complex, and thus representative of the complexity of using and comparing different definitions of fairness. In general, while the target fairness <b>metric</b> <b>can</b> be improved ...", "dateLastCrawled": "2022-02-03T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Exploiting oddsmaker <b>bias</b> to improve the prediction of NFL <b>outcomes</b> ...", "url": "https://deepai.org/publication/exploiting-oddsmaker-bias-to-improve-the-prediction-of-nfl-outcomes", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../exploiting-oddsmaker-<b>bias</b>-to-improve-the-prediction-of-nfl-<b>outcomes</b>", "snippet": "Since <b>bias</b> <b>can</b> be considered the amount of <b>information</b> the spread provides about the outcome, we <b>can</b> use Shannon entropy (Shannon ) as an effective <b>metric</b> to for this purpose. In this respect, Shannon entropy ( H ( s ) = \u2212 \u2211 t p ( o = t | s ) log 2 ( p ( o = t | s ) ) ) reflects the amount of uncertainty associated with <b>information</b> carried by spread estimates in their ability to predict <b>outcomes</b> (for each team ( t )).", "dateLastCrawled": "2021-12-05T06:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Predicting Outcomes of Legal Cases</b> <b>based</b> on Legal Factors using ...", "url": "https://www.sciencedirect.com/science/article/pii/S1877050920307584", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050920307584", "snippet": "Hence, descriptors considered for <b>predicting</b> <b>outcomes</b> are extra-judicial factors that may generate or represent human <b>bias</b>. Examples of these factors are votes of other justices [7], justice gender, case origin [8], petitioner type, respondent type, the ideological direction of the court [9], etc. The research works following this approach are [5-10]. 2) Linguistic <b>based</b> Approach: Another approach considers the linguistic features of legal judgments for <b>predicting</b> <b>outcomes</b>. Ngo [11] tried to ...", "dateLastCrawled": "2022-02-02T04:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>How to Best Understand Forecast Bias</b> - <b>Brightwork Research &amp; Analysis</b>", "url": "https://www.brightworkresearch.com/forecastbias/", "isFamilyFriendly": true, "displayUrl": "https://www.brightworkresearch.com/forecast<b>bias</b>", "snippet": "Forecast <b>bias</b> is generally not tracked in most forecasting applications in terms of outputting a specific <b>metric</b>. However one <b>can</b> very easily compare the historical demand to the historical forecast line, to see if the historical forecast is above or below the historical demand. The problem in doing this is is that normally just the final forecast ends up being tracked in forecasting application (the other forecasts are often in other systems), and each forecast has to be measured for ...", "dateLastCrawled": "2022-02-03T02:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Bias</b> and Fairness reference: DataRobot docs", "url": "https://docs.datarobot.com/en/docs/modeling/analyze-models/bias/bias-ref.html", "isFamilyFriendly": true, "displayUrl": "https://docs.datarobot.com/en/docs/modeling/analyze-models/<b>bias</b>/<b>bias</b>-ref.html", "snippet": "To help understand the ideal context/use case for applying a <b>given</b> fairness <b>metric</b>, this section covers hypothetical examples for each fairness <b>metric</b>. The examples are <b>based</b> on an HR hiring use case, where the fairness metrics evaluate a model that predicts the target Hired (Yes or No). Disclaimer: The hypothetical examples do not reflect the views of DataRobot; they are meant solely for illustrative purposes. Notation\u00b6 d: decision of the model (i.e., Yes or No) PF: protected feature; s ...", "dateLastCrawled": "2022-01-25T14:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Measure <b>Posttraining Data and Model Bias</b> - Amazon SageMaker", "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-bias.html", "isFamilyFriendly": true, "displayUrl": "https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-<b>bias</b>.html", "snippet": "Amazon SageMaker Clarify provides eleven <b>posttraining data and model bias</b> metrics to help quantify various conceptions of fairness. These concepts cannot all be satisfied simultaneously and the selection depends on specifics of the cases involving potential <b>bias</b> being analyzed. Most of these metrics are a combination of the numbers taken from the binary classification confusion matrices for the different demographic groups. Because fairness and <b>bias</b> <b>can</b> be defined by a wide range of metrics ...", "dateLastCrawled": "2022-01-29T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Predicting Horse Racing Outcomes</b> | Data Science Blog", "url": "https://nycdatascience.com/blog/student-works/capstone/predicting-horse-racing-outcomes/", "isFamilyFriendly": true, "displayUrl": "https://nycdatascience.com/blog/student-works/capstone/<b>predicting-horse-racing-outcomes</b>", "snippet": "<b>Given</b> the focus on strictly <b>predicting</b> horses that finished first, the team elected to develop a baseline model using only the data provided and compare the results to strategies of selecting winners using the TIPS Index and predictions made by the \u201cwisdom of crowds\u201d inherent in the Odds favorite. This choice was made to a large extent so that the results could be clear to the client, and the team would be able to present options of how to remedy issues that were encountered in the data ...", "dateLastCrawled": "2022-02-03T07:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Machine learning v. traditional regression models <b>predicting</b> treatment ...", "url": "https://www.cambridge.org/core/journals/psychological-medicine/article/machine-learning-v-traditional-regression-models-predicting-treatment-outcomes-for-bingeeating-disorder-from-a-randomized-controlled-trial/A1CB0BF829A2D86CC791A40F5FCDC053", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/psychological-medicine/article/machine...", "snippet": "Machine learning is a promising method for improving the accuracy of difficult-to-predict <b>outcomes</b>. We <b>compared</b> the accuracy of traditional and machine-learning approaches for <b>predicting</b> BED treatment <b>outcomes</b>. Methods. Participants were 191 adults with BED in a randomized controlled trial testing 6-month behavioral and stepped-care treatments. <b>Outcomes</b>, determined by independent assessors, were binge-eating (% reduction, abstinence), eating-disorder psychopathology, and weight loss (% loss ...", "dateLastCrawled": "2022-01-15T09:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Effective deep learning approaches for <b>predicting</b> COVID-19 <b>outcomes</b> ...", "url": "https://www.nature.com/articles/s41598-022-05532-0", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-022-05532-0", "snippet": "The most accurate prognostic models for COVID-19 <b>outcomes</b> will rely <b>on information</b> that is most specific to risk for severe COVID-19 disease. In the setting of limited patient data, it is ...", "dateLastCrawled": "2022-02-03T03:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A Machine Learning Algorithm for <b>Predicting</b> <b>Outcomes</b> of MLB Games | by ...", "url": "https://towardsdatascience.com/a-machine-learning-algorithm-for-predicting-outcomes-of-mlb-games-fa17710f3c04", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-machine-learning-algorithm-for-<b>predicting</b>-<b>outcomes</b>-of...", "snippet": "Raw data is impervious to cognitive <b>bias</b> \u2014 devoid of human emoti o n and predisposition. Guided by this precept, Billy Beane\u2019s 2001 Oakland As designed a new statistical blueprint for championship-aspiring ballclubs, and precipitated a data analytics revolution that spread like wildfire throughout all facets of professional sports. As Beane discovered, baseball\u2019s wealth of data makes it conducive to predictive analytics. The problem I have chosen to explore is employing machine ...", "dateLastCrawled": "2022-02-03T07:33:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Short Discussion On <b>Bias</b> In <b>Machine</b> <b>Learning</b>", "url": "https://www.encora.com/insights/a-short-discussion-on-bias-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.encora.com/insights/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "A typical <b>machine</b> <b>learning</b> lifecycle might start with a Scoping stage. At this point, an important decision to be made by the analysts regards the level of performance the <b>machine</b> <b>learning</b> system should have. The <b>machine</b> <b>learning</b> team, along with the stakeholders involved, should decide on a <b>metric</b> to be used as a measure of success. This ...", "dateLastCrawled": "2022-02-03T02:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bias</b>, Variance, and <b>Overfitting</b> Explained, Step by Step", "url": "https://machinelearningcompass.com/model_optimization/bias_and_variance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>compass.com/model_optimization/<b>bias</b>_and_variance", "snippet": "The <b>bias</b> of a specific <b>machine learning</b> model trained on a specific dataset describes how well this <b>machine learning</b> model can capture the relationship between the features and the targets. So for our example, the <b>bias</b> of any one model would tell us how well this particular model can predict the exam points received for any number of hours studied in our specific dataset. That seems like a reasonable definition. Practical Examples (<b>Bias</b>) Let\u2019s take a look at three of the above models and ...", "dateLastCrawled": "2022-01-31T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Short Discussion on <b>Bias</b> in <b>Machine</b> <b>Learning</b> | by Daitan | Daitan ...", "url": "https://medium.com/daitan-tech/a-short-discussion-on-bias-in-machine-learning-5bb2066afabc", "isFamilyFriendly": true, "displayUrl": "https://medium.com/daitan-tech/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>-5bb2066afabc", "snippet": "The problem of <b>bias</b> in <b>machine</b> <b>learning</b> is very serious. Moreover, though it seems to be a \u201cdata related\u201d problem, one might think that it can be solved by simply curating datasets so that ...", "dateLastCrawled": "2021-08-05T05:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Short Discussion on <b>Bias</b> in <b>Machine</b> <b>Learning</b> - Adolfo Eliaz\u00e0t ...", "url": "https://adolfoeliazat.com/2021/06/16/a-short-discussion-on-bias-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://adolfoeliazat.com/2021/06/16/a-short-discussion-on-<b>bias</b>-in-<b>machine</b>-<b>learning</b>", "snippet": "The problem of <b>bias</b> in <b>machine</b> <b>learning</b> is very serious. Moreover, though it seems to be a \u201cdata related\u201d problem, one might think that it can be solved by simply curating datasets so that classes and ethical groups are well represented. This line of thinking is a trap and must be avoided. Overall, <b>bias</b> in technology can happen anywhere or anytime a decision must be taken by a human. In such situations, it is very common to consider aspects that make sense from a marketing or profit ...", "dateLastCrawled": "2022-01-16T17:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Evaluating a <b>Machine</b> <b>Learning</b> Model: Regression and Classification ...", "url": "https://arnavbansal-8232.medium.com/evaluating-a-machine-learning-model-regression-and-classification-metrics-4f2316e180b4", "isFamilyFriendly": true, "displayUrl": "https://arnavbansal-8232.medium.com/evaluating-a-<b>machine</b>-<b>learning</b>-model-regression-and...", "snippet": "<b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> plays a vital role in all this. ... Note that R\u00b2 score calculated unadjusted R\u00b2 without correcting for <b>bias</b> in sample variance of y. Classification Metrics, 1. Confusion Matrix, A confusion matrix is a table that is often used to describe the performance of a classification model (or \u201cclassifier\u201d) on a set of test data for which the true values are known. The confusion matrix itself is relatively simple to understand, but the related terminology can ...", "dateLastCrawled": "2022-01-05T00:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Considerations for the Interpretation of Bias Measures</b> of Word ...", "url": "https://deepai.org/publication/considerations-for-the-interpretation-of-bias-measures-of-word-embeddings", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>considerations-for-the-interpretation-of-bias-measures</b>...", "snippet": "Moreover, we feel publications utilizing these <b>bias</b> metrics would benefit from including information regarding the variance or confidence intervals of the <b>metric</b> under <b>bias</b>-term sampling, if the absolute values of the <b>metric</b> must be published. Regarding the use of the <b>metric</b> as a model selection tool intended to minimize the <b>bias</b> of downstream models employing the embedding space in question, we feel it is important to understand how the properties of the <b>metric</b> employed vary with embedding ...", "dateLastCrawled": "2022-01-18T03:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Fairness Metrics - Data Analytics - Data Science, <b>Machine</b> <b>Learning</b>, AI", "url": "https://vitalflux.com/fairness-metrics-ml-model-sensitivity-bias-detection/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>fairness-metrics-ml-model-sensitivity</b>-<b>bias</b>-detection", "snippet": "There are many different ways in which <b>machine</b> <b>learning</b> (ML) models\u2019 fairness could be determined. Some of them are statistical parity, the relative significance of features, model sensitivity etc. In this post, you would learn about how model sensitivity could be used to determine model fairness or <b>bias</b> of model towards the privileged or unprivileged group.The following are some of the topics covered in this post:", "dateLastCrawled": "2022-01-20T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A New <b>Metric</b> for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare ...", "url": "https://towardsdatascience.com/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare-closedloop-ai-fc07b9c83487", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-new-<b>metric</b>-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "The <b>analogy</b> would be the difference between a Pearson correlation or a residual sum of squared errors in regression. While both quantify the models performance, the former is significantly easier to understand and explain; unsurprisingly, it is the <b>metric</b> most individuals use to describe a regression model. In order to achieve this effect, many fairness metrics are presented as the quotient of a protected subgroup to a base subgroup[2]. As the goal of healthcare is to deliver interventions ...", "dateLastCrawled": "2022-01-17T14:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A New <b>Metric</b> for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare", "url": "https://www.closedloop.ai/post/a-new-metric-for-quantifying-machine-learning-fairness-in-healthcare", "isFamilyFriendly": true, "displayUrl": "https://www.closedloop.ai/post/a-new-<b>metric</b>-for-quantifying-<b>machine</b>-<b>learning</b>-fairness...", "snippet": "A New <b>Metric</b> for Quantifying <b>Machine</b> <b>Learning</b> Fairness in Healthcare. Joseph Gartner. March 2, 2020. Background. Several recent, high profile cases of unfair AI algorithms have highlighted the vital need to address <b>bias</b> early in the development of any AI system. For the most part, <b>bias</b> does not come into algorithms due to malicious intent by the individual creating the algorithm. <b>Bias</b> comes from a lack of diligence in ensuring that the AI system is fair for everyone. In order to combat <b>bias</b> ...", "dateLastCrawled": "2022-02-01T00:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why is there a trade-off between <b>bias</b> and variance in <b>machine</b> <b>learning</b> ...", "url": "https://www.quora.com/Why-is-there-a-trade-off-between-bias-and-variance-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-is-there-a-trade-off-between-<b>bias</b>-and-variance-in-<b>machine</b>...", "snippet": "Answer: There are some interesting of canonical examples of biased estimators that have a lower variance than the best possible unbiased estimator, but fundamentally the trade-off exists for the same reason most trade-offs in life exist. Low <b>bias</b> and low variance are both desirable. If someone i...", "dateLastCrawled": "2022-01-21T18:21:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(bias metric)  is like +(predicting outcomes based on information given)", "+(bias metric) is similar to +(predicting outcomes based on information given)", "+(bias metric) can be thought of as +(predicting outcomes based on information given)", "+(bias metric) can be compared to +(predicting outcomes based on information given)", "machine learning +(bias metric AND analogy)", "machine learning +(\"bias metric is like\")", "machine learning +(\"bias metric is similar\")", "machine learning +(\"just as bias metric\")", "machine learning +(\"bias metric can be thought of as\")", "machine learning +(\"bias metric can be compared to\")"]}