{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Player</b> of Games \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2112.03178/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2112.03178", "snippet": "<b>Player</b> of Games is the first algorithm to achieve strong performance in challenge domains with both perfect and imperfect information \u2014 an important step towards truly general algorithms that can learn in arbitrary environments. Applications of traditional search suffer well-known problems in imperfect information games [].Evaluation has remained focused on single domains (e.g. <b>poker</b>) despite recent progress toward sound search in imperfect information games [55, 10, 84].<b>Player</b> of Games ...", "dateLastCrawled": "2022-01-25T16:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "IFT 6756 - Lecture 23 Evaluation of Multi-Agent Systems", "url": "https://gauthiergidel.github.io/courses/notes/Lecture23.pdf", "isFamilyFriendly": true, "displayUrl": "https://gauthiergidel.github.io/courses/notes/Lecture23.pdf", "snippet": "for one <b>player</b> is equivalent to losing that strategy for its opponent. Strategic games <b>like</b> Chess, Go, <b>Poker</b> (with randomized initialization) can be represented in such manner. This setting can also be generalized for non-zero sum settings (though it would be computationally heavy because of the two losses). For sake of simplicity, we will focus on the zero-sum <b>game</b> throughout this lecture. 1. IFT 6756 - <b>Game</b> Theory and Machine Learning Lecture 23 3 Estimating Elo for AvA In this section, we ...", "dateLastCrawled": "2021-09-02T13:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Reinforcement Learning and DQN</b>, learning to play from pixels - Ruben ...", "url": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-Reinforcement-Learning-and-DQN.html", "isFamilyFriendly": true, "displayUrl": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-<b>Reinforcement-Learning-and-DQN</b>.html", "snippet": "A single <b>player</b> <b>game</b> has a natural translation into a MDP. The states represent the moment where the <b>player</b> is in control. The observations from those states are all the information accumulated between states (eg: as many pixel frame as there are in-between frames of control). An action is all the available command at the disposal of the <b>player</b> (In doom, go up, right, left, shoot, etc \u2026). <b>Reinforcement learning</b> can also be applied to adversarial games by self-play: The agent plays against ...", "dateLastCrawled": "2022-01-31T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Poker</b> Hand Induction: Multi-Class Classi\ufb01cation of Extreme Imbalanced ...", "url": "https://angeland.no/projects/codeshare/Poker_Hand_Induction__Multi_Class_Classification_of_Extreme_Imbalanced_Data_with_Machine_Learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://angeland.no/projects/codeshare/<b>Poker</b>_Hand_Induction__Multi_Class...", "snippet": "In a traditional \ufb01ve hand <b>poker</b> <b>game</b>, each <b>player</b> will be assigned 5 cards from a shu ed card deck of 52 unique cards. Based on what kind of cards the <b>player</b> receives, a type of hand is then naturally assigned based on multiple criterion. There are 10 distinct, ranked types of hands. The <b>player</b> with the best type of hand wins the <b>game</b>. When order matters, there are 311 875 200 unique <b>poker</b> hands. The probabilities of each type of hand are quite imbal-anced. The most likely type of hand a ...", "dateLastCrawled": "2022-01-17T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "AI in Games: Techniques, Challenges and Opportunities | DeepAI", "url": "https://deepai.org/publication/ai-in-games-techniques-challenges-and-opportunities", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/ai-in-<b>games</b>-techniques-challenges-and-opportunities", "snippet": "Even though StarCraft is a two-payer competitive <b>game</b>, each <b>player</b> needs to control a large number of units, which need to be well cooperated. Overall, how to obtain the Nash equilibrium strategy or a better learned strategy under the multi-agent cooperation is a hard problem, because specially designed agent interaction or alignment needs to be carefully considered. Fig. 2: A brief framework of AlphaGo series. In summary, differen games share different characteristics and aim to find ...", "dateLastCrawled": "2022-02-02T10:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to shuffle a <b>poker</b> deck between 4 players, with least required ...", "url": "https://www.quora.com/How-do-you-shuffle-a-poker-deck-between-4-players-with-least-required-entropy-combinatorics-algorithms-random-entropy-card-games-math", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-do-you-shuffle-a-<b>poker</b>-deck-between-4-<b>players</b>-with-least...", "snippet": "Answer: You are basically asking how to shuffle a deck of cards. Here&#39;s a cut-and-paste from Wikipedia. The Fisher\u2013Yates shuffle is an algorithm for generating a random permutation of a finite sequence\u2014in plain terms, the algorithm shuffles the sequence. The algorithm effectively puts all the el...", "dateLastCrawled": "2022-01-24T23:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "what <b>game</b> are we playing - statwiki", "url": "https://wiki.math.uwaterloo.ca/statwiki/index.php?title=what_game_are_we_playing", "isFamilyFriendly": true, "displayUrl": "https://wiki.math.uwaterloo.ca/statwiki/index.php?title=what_<b>game</b>_are_we_playing", "snippet": "The effectiveness of this model is demonstrated using the games \u201cRock, Paper, Scissors\u201d, one-card <b>poker</b>, and a security defense <b>game</b>. This could represent a substantial step forward in understanding how <b>game</b>-theoretic methods can be applied to uncertain settings by the ability to learn solely from observed actions and the relevant parameters. Learning and Quantal Response in Normal Form Games . The <b>game</b>-solving module provides all elements required in differentiable learning, which maps ...", "dateLastCrawled": "2021-12-11T20:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Solving the playing strategy of <b>Dou Dizhu</b> using convolutional neural ...", "url": "https://content.iospress.com/articles/journal-of-computational-methods-in-sciences-and-engineering/jcm204344", "isFamilyFriendly": true, "displayUrl": "https://content.iospress.com/articles/journal-of-computational-methods-in-sciences-and...", "snippet": "<b>Poker</b> is a typical <b>game</b> of incomplete information, where the information of the <b>game</b> state is only partially observable. In <b>Poker</b>, each <b>player</b> dealt the private cards, thus causing information asymmetry about the <b>game</b> state. From the perspective of the AI <b>game</b> agent, the hidden information of opponents brings many challenges for reasoning. <b>Dou Dizhu</b> is a popular and entertaining trick-taking card <b>game</b> in China, and it is primarily played by three or four players. Besides, the <b>game</b> has been ...", "dateLastCrawled": "2022-01-06T00:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Mastering the <b>game</b> <b>of Go without human knowledge</b>", "url": "https://www.researchgate.net/publication/320473480_Mastering_the_game_of_Go_without_human_knowledge", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320473480", "snippet": "focuses greedily on capturing stones, much <b>like</b> a human beginner. At 19 hours, the <b>game</b> exhibits the fundamentals. of life-and-death, in\ufb02uence and territory. At 70 hours, the <b>game</b> is beautifully ...", "dateLastCrawled": "2022-01-29T17:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Is there a <b>game</b> or sport that has no draw? - Quora", "url": "https://www.quora.com/Is-there-a-game-or-sport-that-has-no-draw", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-there-a-<b>game</b>-or-sport-that-has-no-draw", "snippet": "Answer (1 of 3): I don\u2019t know about \u201cgames\u201d (far too many to ponder), but with regard to the sports I know of, I\u2019m inclined to say regular-season baseball and basketball. I qualify the former because playing to a draw in preseason is allowed in MLB (exhibition) baseball, but not when the games c...", "dateLastCrawled": "2022-01-05T14:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "AI in Games: Techniques, Challenges and Opportunities | DeepAI", "url": "https://deepai.org/publication/ai-in-games-techniques-challenges-and-opportunities", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/ai-in-<b>games</b>-techniques-challenges-and-opportunities", "snippet": "Even though StarCraft is a two-payer competitive <b>game</b>, each <b>player</b> needs to control a large number of units, which need to be well cooperated. Overall, how to obtain the Nash equilibrium strategy or a better learned strategy under the multi-agent cooperation is a hard problem, because specially designed agent interaction or alignment needs to be carefully considered. Fig. 2: A brief framework of AlphaGo series. In summary, differen games share different characteristics and aim to find ...", "dateLastCrawled": "2022-02-02T10:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Tutorial #4: <b>auxiliary tasks in deep reinforcement learning</b>", "url": "https://www.borealisai.com/en/blog/tutorial-4-auxiliary-tasks-deep-reinforcement-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.borealisai.com/en/blog/tutorial-4-auxiliary-tasks-deep-reinforcement-learning", "snippet": "The use of auxiliary tasks is not limited to actor-critic algorithms; they have also been implemented on top of Q-learning algorithms such as DRQN (Hausknecht &amp; Stone 2015).For example, Lample &amp; Chaplot (2017) extended the DRQN architecture with another head used to predict <b>game</b> features. In this case, the loss is the standard DRQN loss and the <b>cross-entropy</b> loss of the auxiliary task.", "dateLastCrawled": "2022-01-30T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Reinforcement Learning and DQN</b>, learning to play from pixels - Ruben ...", "url": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-Reinforcement-Learning-and-DQN.html", "isFamilyFriendly": true, "displayUrl": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-<b>Reinforcement-Learning-and-DQN</b>.html", "snippet": "A single <b>player</b> <b>game</b> has a natural translation into a MDP. The states represent the moment where the <b>player</b> is in control. The observations from those states are all the information accumulated between states (eg: as many pixel frame as there are in-between frames of control). An action is all the available command at the disposal of the <b>player</b> (In doom, go up, right, left, shoot, etc \u2026). <b>Reinforcement learning</b> can also be applied to adversarial games by self-play: The agent plays against ...", "dateLastCrawled": "2022-01-31T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "2110.02924v1.pdf - No-Press Diplomacy from Scratch arXiv:2110.02924v1 ...", "url": "https://www.coursehero.com/file/110836130/211002924v1pdf/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/110836130/211002924v1pdf", "snippet": "The value of this <b>game</b> to each <b>player</b> assuming this NE is then used as the target values of Q (s, a). The update rule is thus: Q (s, a) \u2190 (1-\u03b1) Q (s, a) + \u03b1 r (s, a) + \u03b3 X a 0 \u03c3 (a 0) Q (s 0, a 0), (1) where \u03b1 is the learning rate, \u03b3 is the discount factor, and \u03c3 (a) := Q i \u03c3 i (a i) is the probability of joint action a. As presented later in Section 3.1, the foundation of our algorithm is an adaptation of Nash Q-Learning, with several modifications to make it suitable for deep RL ...", "dateLastCrawled": "2021-12-24T05:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Player</b> of Games \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2112.03178/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2112.03178", "snippet": "<b>Player</b> of Games is the first algorithm to achieve strong performance in challenge domains with both perfect and imperfect information \u2014 an important step towards truly general algorithms that can learn in arbitrary environments. Applications of traditional search suffer well-known problems in imperfect information games [].Evaluation has remained focused on single domains (e.g. <b>poker</b>) despite recent progress toward sound search in imperfect information games [55, 10, 84].<b>Player</b> of Games ...", "dateLastCrawled": "2022-01-25T16:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Machine learning in digital games</b>: a survey | Leo ... - Academia.edu", "url": "https://www.academia.edu/9482603/Machine_learning_in_digital_games_a_survey", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/9482603/<b>Machine_learning_in_digital_games</b>_a_survey", "snippet": "2.1 Digital <b>game</b> environment related issues Research has shown that a <b>player</b>\u2019s interest <b>in a game</b> can be partially considered as a product of interactions with <b>game</b> agents within a <b>game</b> environment, where the <b>game</b> environment is characteristically nondeterministic and dynamic, containing multiple <b>game</b> agents with potentially discontinuous inputs (Duan et al. 2002; Kirby 2004; Yannakakis et al. 2004; Yannakakis and Hallam 2004). Due to the real-time nature of digital games, <b>game</b> agents are ...", "dateLastCrawled": "2021-12-29T22:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Research on integrated computer <b>game</b> algorithm for dots and boxes - Li ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/joe.2019.1185", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/joe.2019.1185", "snippet": "The dots and boxes <b>game</b> is a well-known two-<b>player</b> board <b>game</b> that has been incorporated into the International Computer Olympiad Competition and the China Computer Gaming Competition for many years. It has many names, such as dot-to-square checkerboard, encircle chess and so on. The rule of dots and boxes is as follows: In a rectangular array of a certain size and evenly distributed, two players alternately draw horizontal or vertical straight lines in their own turn, connecting two ...", "dateLastCrawled": "2022-02-02T08:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Solving the playing strategy of <b>Dou Dizhu</b> using convolutional neural ...", "url": "https://content.iospress.com/articles/journal-of-computational-methods-in-sciences-and-engineering/jcm204344", "isFamilyFriendly": true, "displayUrl": "https://content.iospress.com/articles/journal-of-computational-methods-in-sciences-and...", "snippet": "<b>Poker</b> is a typical <b>game</b> of incomplete information, where the information of the <b>game</b> state is only partially observable. In <b>Poker</b>, each <b>player</b> dealt the private cards, thus causing information asymmetry about the <b>game</b> state. From the perspective of the AI <b>game</b> agent, the hidden information of opponents brings many challenges for reasoning. <b>Dou Dizhu</b> is a popular and entertaining trick-taking card <b>game</b> in China, and it is primarily played by three or four players. Besides, the <b>game</b> has been ...", "dateLastCrawled": "2022-01-06T00:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Mastering the <b>game</b> <b>of Go without human knowledge</b>", "url": "https://www.researchgate.net/publication/320473480_Mastering_the_game_of_Go_without_human_knowledge", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320473480", "snippet": "focuses greedily on capturing stones, much like a human beginner. At 19 hours, the <b>game</b> exhibits the fundamentals. of life-and-death, in\ufb02uence and territory. At 70 hours, the <b>game</b> is beautifully ...", "dateLastCrawled": "2022-01-29T17:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Is there a <b>game</b> or sport that has no draw? - Quora", "url": "https://www.quora.com/Is-there-a-game-or-sport-that-has-no-draw", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-there-a-<b>game</b>-or-sport-that-has-no-draw", "snippet": "Answer (1 of 3): I don\u2019t know about \u201cgames\u201d (far too many to ponder), but with regard to the sports I know of, I\u2019m inclined to say regular-season baseball and basketball. I qualify the former because playing to a draw in preseason is allowed in MLB (exhibition) baseball, but not when the games c...", "dateLastCrawled": "2022-01-05T14:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Playing Connect 4 with Deep Q-<b>Learning</b> | by Lee Schmalz | Towards Data ...", "url": "https://towardsdatascience.com/playing-connect-4-with-deep-q-learning-76271ed663ca", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/playing-connect-4-with-deep-q-<b>learning</b>-76271ed663ca", "snippet": "In Connect 4, we have 42 entries that <b>can</b> be filled by any of a <b>player</b> 1 chip, a <b>player</b> 2 chip, or no chip. We must also give gravity its due; in that a chip <b>can</b> only be played in a location of the grid if there is a previously played chip in the space underneath it. Further, if any 4 chips of the same color are lined up, the <b>game</b> is over and thus future situations cannot be included in the observation space. This amounts to be a somewhat complex calculation as we\u2019ve laid out; nonetheless ...", "dateLastCrawled": "2022-02-01T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Computer Vision for Card Games</b> - cs229.stanford.edu", "url": "http://cs229.stanford.edu/proj2017/final-reports/5233806.pdf", "isFamilyFriendly": true, "displayUrl": "cs229.stanford.edu/proj2017/final-reports/5233806.pdf", "snippet": "such as a <b>game</b> <b>of poker</b> or blackjack to turn the odds in your favor. II. DATA AUGMENTATION AND ENGINEERING Most of the data sets available on the internet only contain perfectly aligned images of playing cards. For our application, we were interested in being able to recognize real images taken with a smartphone\u2019s camera, to simulate a real-world application. For this purpose we decided to develop our own data set. We purchased a deck of cards and took our own pictures. For the data set ...", "dateLastCrawled": "2022-02-02T06:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Reinforcement Learning and DQN</b>, learning to play from pixels - Ruben ...", "url": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-Reinforcement-Learning-and-DQN.html", "isFamilyFriendly": true, "displayUrl": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-<b>Reinforcement-Learning-and-DQN</b>.html", "snippet": "A single <b>player</b> <b>game</b> has a natural translation into a MDP. The states represent the moment where the <b>player</b> is in control. The observations from those states are all the information accumulated between states (eg: as many pixel frame as there are in-between frames of control). An action is all the available command at the disposal of the <b>player</b> (In doom, go up, right, left, shoot, etc \u2026). <b>Reinforcement learning</b> <b>can</b> also be applied to adversarial games by self-play: The agent plays against ...", "dateLastCrawled": "2022-01-31T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 11. Basics of deep reinforcement learning \u2013 Deep Learning with ...", "url": "http://devguis.com/chapter-11-basics-of-deep-reinforcement-learning-deep-learning-with-javascript.html", "isFamilyFriendly": true, "displayUrl": "devguis.com/chapter-11-basics-of-deep-reinforcement-learning-deep-learning-with...", "snippet": "At any step of the <b>game</b>, the board configuration (plus which <b>player</b>\u2019s turn it is) fully characterizes the <b>game</b> state and provides all the information the <b>player</b> needs for calculating the next move. In other words, it is possible to resume a chess <b>game</b> from the board configuration without knowing the previous moves. (Incidentally, this is why newspapers <b>can</b> post chess puzzles in a very space-efficient way.) Video games such as snake are also consistent with the MDP formulation. The ...", "dateLastCrawled": "2022-01-04T05:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The <b>vanishing gradient problem</b> and ReLUs \u2013 a TensorFlow investigation ...", "url": "https://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/", "isFamilyFriendly": true, "displayUrl": "https://adventuresinmachinelearning.com/<b>vanishing-gradient-problem</b>-tensorflow", "snippet": "The loss used in this instance is the handy TensorFlow softmax_<b>cross_entropy</b>_with_logits_v2 (the original version is soon to be deprecated). This loss function will apply the softmax operation to the un-activated output of the network, then apply the <b>cross entropy</b> loss to this outcome. After this loss operation is created, it\u2019s output value is added to the tf.summary framework. This framework allows scalar values to be logged and subsequently visualized in the TensorBoard web-based ...", "dateLastCrawled": "2022-01-31T21:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Solving Common-Payoff Games with Approximate Policy ... - arxiv-vanity.com", "url": "https://www.arxiv-vanity.com/papers/2101.04237/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2101.04237", "snippet": "For artificially intelligent learning systems to have widespread applicability in real-world settings, it is important that they be able to operate decentrally. Unfortunately, decentralized control is difficult\u2014computing even an epsilon-optimal joint policy is a NEXP complete problem. Nevertheless, a recently rediscovered insight\u2014that a team of agents <b>can</b> coordinate via common knowledge\u2014has given rise to algorithms capable of finding optimal joint policies in small common-payoff games ...", "dateLastCrawled": "2021-11-14T16:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The Future-Predicting <b>Game</b> Show Host | David Bieber", "url": "https://davidbieber.com/snippets/2020-02-08-future-gameshow-host/", "isFamilyFriendly": true, "displayUrl": "https://davidbieber.com/snippets/2020-02-08-future-<b>game</b>show-host", "snippet": "A <b>game</b> show host reveals 2 boxes, box A and box B. In box A is either $1 million or $0, in box B there is $1000. You\u2019re told, choose either just box A or both A and B. You keep the contents of the boxes you choose. Also, the host knows what box you will choose, and has placed $1 million in A if you will choose only A, and $0 in A if you will choose both A and B.", "dateLastCrawled": "2022-01-10T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to shuffle a <b>poker</b> deck between 4 players, with least required ...", "url": "https://www.quora.com/How-do-you-shuffle-a-poker-deck-between-4-players-with-least-required-entropy-combinatorics-algorithms-random-entropy-card-games-math", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-do-you-shuffle-a-<b>poker</b>-deck-between-4-<b>players</b>-with-least...", "snippet": "Answer: You are basically asking how to shuffle a deck of cards. Here&#39;s a cut-and-paste from Wikipedia. The Fisher\u2013Yates shuffle is an algorithm for generating a random permutation of a finite sequence\u2014in plain terms, the algorithm shuffles the sequence. The algorithm effectively puts all the el...", "dateLastCrawled": "2022-01-24T23:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "DES algorithm explanation With example PDF \u2014 algorithm described later ...", "url": "https://l-parie.com/~rajeev/cs3810/slides/3810-08pv-z1897t30tg.pdf", "isFamilyFriendly": true, "displayUrl": "https://l-parie.com/~rajeev/cs3810/slides/3810-08pv-z1897t30tg.pdf", "snippet": "So, for example, if a <b>player</b>&#39;s rating is 1850 and the RD is 50, the interval would go from 1750 to 1950. We would then say that we&#39;re 95% con dent that the <b>player</b>&#39;s actual strength is between 1750 and 1950. When a <b>player</b> has a low RD, the interval would be narrow, so that we would be 95% con dent about a <b>player</b>&#39;s strength being in a small interval of values. The formulas: To apply the. Traditional Algorithm Animation (AA) systems usually aim for teaching algorithms in higher education, see ...", "dateLastCrawled": "2021-08-28T06:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Artificial Intelligence, Machine Learning, and Deep Learning ...", "url": "https://in.b-ok.africa/book/16294282/e2efdc", "isFamilyFriendly": true, "displayUrl": "https://in.b-ok.africa/book/16294282/e2efdc", "snippet": "You <b>can</b> write a book review and share your experiences. Other readers will always be interested in your opinion of the books you&#39;ve read. Whether you&#39;ve loved the book or not, if you give your honest and detailed thoughts then people will find new books that are right for them. / / Since 2009. Free ebooks since 2009. Free ebooks since 2009. support@bookmail ...", "dateLastCrawled": "2022-01-06T16:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Cross-Entropy for Monte-Carlo Tree Search</b>.", "url": "https://www.researchgate.net/publication/220174560_Cross-Entropy_for_Monte-Carlo_Tree_Search", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220174560_<b>Cross-Entropy_for_Monte-Carlo_Tree</b>...", "snippet": "<b>game</b> <b>of Poker</b> and for the <b>game</b> of LOA. In this paper we investigate the use of the <b>Cr oss-Entropy</b> Method (CEM) (Rubinstein, 1999) for parameter tuning in general, i.e., for any <b>game</b> engine.", "dateLastCrawled": "2021-11-08T13:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Poker</b> Hand Induction: Multi-Class Classi\ufb01cation of Extreme Imbalanced ...", "url": "https://angeland.no/projects/codeshare/Poker_Hand_Induction__Multi_Class_Classification_of_Extreme_Imbalanced_Data_with_Machine_Learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://angeland.no/projects/codeshare/<b>Poker</b>_Hand_Induction__Multi_Class...", "snippet": "challenging <b>compared</b> to binary imbalanced learning [4]. In a traditional \ufb01ve hand <b>poker</b> <b>game</b>, each <b>player</b> will be assigned 5 cards from a shu ed card deck of 52 unique cards. Based on what kind of cards the <b>player</b> receives, a type of hand is then naturally assigned based on multiple criterion. There are 10 distinct, ranked types of hands. The <b>player</b> with the best type of hand wins the <b>game</b>. When order matters, there are 311 875 200 unique <b>poker</b> hands. The probabilities of each type of hand ...", "dateLastCrawled": "2022-01-17T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "IFT 6756 - Lecture 23 Evaluation of Multi-Agent Systems", "url": "https://gauthiergidel.github.io/ift_6756_gt_ml/notes/Lecture23.pdf", "isFamilyFriendly": true, "displayUrl": "https://gauthiergidel.github.io/ift_6756_gt_ml/notes/Lecture23.pdf", "snippet": "Elo\u2019s central assumption was that the (chess) performance of a <b>player</b> in each <b>game</b> is a random variable, and that it follows a normally distributed bell-shaped curve over time. Thus, while a <b>player</b> might perform signi\ufb01cantly better or worse from one <b>game</b> to the next, the mean value of their performances (a re\ufb02ection of their true skill) would remain the same. The assumption here is that this mean value of the performances for any given <b>player</b> only changes slowly over time. Suppose ...", "dateLastCrawled": "2021-09-24T17:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "AI in Games: Techniques, Challenges and Opportunities | DeepAI", "url": "https://deepai.org/publication/ai-in-games-techniques-challenges-and-opportunities", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/ai-in-<b>games</b>-techniques-challenges-and-opportunities", "snippet": "<b>Compared</b> with the perfect information <b>game</b>, a subgame in an imperfect information <b>game</b> cannot be solved isolated from each other , ... Even though StarCraft is a two-payer competitive <b>game</b>, each <b>player</b> needs to control a large number of units, which need to be well cooperated. Overall, how to obtain the Nash equilibrium strategy or a better learned strategy under the multi-agent cooperation is a hard problem, because specially designed agent interaction or alignment needs to be carefully ...", "dateLastCrawled": "2022-02-02T10:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Reinforcement Learning and DQN</b>, learning to play from pixels - Ruben ...", "url": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-Reinforcement-Learning-and-DQN.html", "isFamilyFriendly": true, "displayUrl": "https://rubenfiszel.github.io/posts/rl4j/2016-08-24-<b>Reinforcement-Learning-and-DQN</b>.html", "snippet": "A single <b>player</b> <b>game</b> has a natural translation into a MDP. The states represent the moment where the <b>player</b> is in control. The observations from those states are all the information accumulated between states (eg: as many pixel frame as there are in-between frames of control). An action is all the available command at the disposal of the <b>player</b> (In doom, go up, right, left, shoot, etc \u2026). <b>Reinforcement learning</b> <b>can</b> also be applied to adversarial games by self-play: The agent plays against ...", "dateLastCrawled": "2022-01-31T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Computer Vision for Card Games</b> - cs229.stanford.edu", "url": "http://cs229.stanford.edu/proj2017/final-reports/5233806.pdf", "isFamilyFriendly": true, "displayUrl": "cs229.stanford.edu/proj2017/final-reports/5233806.pdf", "snippet": "such as a <b>game</b> <b>of poker</b> or blackjack to turn the odds in your favor. II. DATA AUGMENTATION AND ENGINEERING Most of the data sets available on the internet only contain perfectly aligned images of playing cards. For our application, we were interested in being able to recognize real images taken with a smartphone\u2019s camera, to simulate a real-world application. For this purpose we decided to develop our own data set. We purchased a deck of cards and took our own pictures. For the data set ...", "dateLastCrawled": "2022-02-02T06:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Player</b> of Games \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2112.03178/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2112.03178", "snippet": "<b>Player</b> of Games is the first algorithm to achieve strong performance in challenge domains with both perfect and imperfect information \u2014 an important step towards truly general algorithms that <b>can</b> learn in arbitrary environments. Applications of traditional search suffer well-known problems in imperfect information games [].Evaluation has remained focused on single domains (e.g. <b>poker</b>) despite recent progress toward sound search in imperfect information games [55, 10, 84].<b>Player</b> of Games ...", "dateLastCrawled": "2022-01-25T16:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Solving the playing strategy of <b>Dou Dizhu</b> using convolutional neural ...", "url": "https://content.iospress.com/articles/journal-of-computational-methods-in-sciences-and-engineering/jcm204344", "isFamilyFriendly": true, "displayUrl": "https://content.iospress.com/articles/journal-of-computational-methods-in-sciences-and...", "snippet": "<b>Poker</b> is a typical <b>game</b> of incomplete information, where the information of the <b>game</b> state is only partially observable. In <b>Poker</b>, each <b>player</b> dealt the private cards, thus causing information asymmetry about the <b>game</b> state. From the perspective of the AI <b>game</b> agent, the hidden information of opponents brings many challenges for reasoning. <b>Dou Dizhu</b> is a popular and entertaining trick-taking card <b>game</b> in China, and it is primarily played by three or four players. Besides, the <b>game</b> has been ...", "dateLastCrawled": "2022-01-06T00:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Research on integrated computer <b>game</b> algorithm for dots and boxes - Li ...", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/joe.2019.1185", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/joe.2019.1185", "snippet": "The dots and boxes <b>game</b> is a well-known two-<b>player</b> board <b>game</b> that has been incorporated into the International Computer Olympiad Competition and the China Computer Gaming Competition for many years. It has many names, such as dot-to-square checkerboard, encircle chess and so on. The rule of dots and boxes is as follows: In a rectangular array of a certain size and evenly distributed, two players alternately draw horizontal or vertical straight lines in their own turn, connecting two ...", "dateLastCrawled": "2022-02-02T08:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Is there a <b>game</b> or sport that has no draw? - Quora", "url": "https://www.quora.com/Is-there-a-game-or-sport-that-has-no-draw", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Is-there-a-<b>game</b>-or-sport-that-has-no-draw", "snippet": "Answer (1 of 3): I don\u2019t know about \u201cgames\u201d (far too many to ponder), but with regard to the sports I know of, I\u2019m inclined to say regular-season baseball and basketball. I qualify the former because playing to a draw in preseason is allowed in MLB (exhibition) baseball, but not when the games c...", "dateLastCrawled": "2022-01-05T14:16:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>machine</b> <b>learning</b> - <b>Cross-entropy loss</b> explanation - Data Science Stack ...", "url": "https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/20296", "snippet": "The answer from Neil is correct. However I think its important to point out that while the loss does not depend on the distribution between the incorrect classes (only the distribution between the correct class and the rest), the gradient of this loss function does effect the incorrect classes differently depending on how wrong they are. So when you use cross-ent in <b>machine</b> <b>learning</b> you will change weights differently for [0.1 0.5 0.1 0.1 0.2] and [0.1 0.6 0.1 0.1 0.1].", "dateLastCrawled": "2022-01-27T03:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Cross-Entropy</b> Demystified. What is it? Is there any relation to\u2026 | by ...", "url": "https://naokishibuya.medium.com/demystifying-cross-entropy-e80e3ad54a8", "isFamilyFriendly": true, "displayUrl": "https://naokishibuya.medium.com/demystifying-<b>cross-entropy</b>-e80e3ad54a8", "snippet": "However, the <b>machine</b> <b>learning</b> application uses the base e logarithm for implementation convenience. Binary <b>Cross-Entropy</b>. We can use the binary <b>cross-entropy</b> for binary classification where we have yes/no answer. For example, there are only dogs or cats in images. For the binary classifications, the <b>cross-entropy</b> formula contains only two ...", "dateLastCrawled": "2022-01-26T13:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Why and How to use <b>Cross Entropy</b>. The fundamental reasons for ...", "url": "https://towardsdatascience.com/why-and-how-to-use-cross-entropy-4e983cbdd873", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/why-and-how-to-use-<b>cross-entropy</b>-4e983cbdd873", "snippet": "The fundamental reasons for minimizing binary <b>cross entropy</b> (log loss) with probabilistic classification models . Will Arliss. Sep 26, 2020 \u00b7 7 min read. Introduction. This post discusses why logistic regression necessarily uses a different loss function than linear regression. First, the simple yet inefficient way to solve logistic regression will be presented, then the slightly less simple but much more efficient way will be explained and compared. The simple way. Linear regression is the ...", "dateLastCrawled": "2022-01-31T14:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Shannon <b>entropy</b> in the context of <b>machine</b> <b>learning</b> and AI | by Frank ...", "url": "https://medium.com/swlh/shannon-entropy-in-the-context-of-machine-learning-and-ai-24aee2709e32", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/shannon-<b>entropy</b>-in-the-context-of-<b>machine</b>-<b>learning</b>-and-ai-24...", "snippet": "Closely related to <b>cross entropy</b>, the KL divergence from q to p, written DKL(p||q), is another similarity measure often used in <b>machine</b> <b>learning</b>. In the language of Bayesian Inference, DKL(p||q ...", "dateLastCrawled": "2022-01-30T12:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> Concepts for Revision | by Raunak Sarada | Medium", "url": "https://raunaksarada-cse21.medium.com/machine-learning-concepts-for-revision-491384952d27", "isFamilyFriendly": true, "displayUrl": "https://raunaksarada-cse21.medium.com/<b>machine</b>-<b>learning</b>-concepts-for-revision-491384952d27", "snippet": "ML Concepts. A.I \u2014 Intelligence showed by machines which is common for humans <b>Machine</b> <b>Learning</b>- Recognize the pattern in data and automatically learn and improve through experience without explicitly being programmed Deep <b>Learning</b>- branch of <b>machine</b> <b>learning</b>.We have to deal with lots of data so in that case problems can\u2019t be solved with simple ML algorithms.", "dateLastCrawled": "2022-01-25T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Main concepts behind Machine Learning</b> | by Bruno Eidi Nishimoto ...", "url": "https://medium.com/neuronio/main-concepts-behind-machine-learning-22cd81d68a11", "isFamilyFriendly": true, "displayUrl": "https://medium.com/neuronio/<b>main-concepts-behind-machine-learning</b>-22cd81d68a11", "snippet": "<b>Machine</b> <b>Learning</b> is a concept that is currently trending. It is a subarea from Artificial Intelligence and it consists on the fact that the <b>machine</b> can learn by itself without being explicitly ...", "dateLastCrawled": "2022-01-19T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Gentle Introduction to Information Entropy - <b>Machine</b> <b>Learning</b> Mastery", "url": "https://machinelearningmastery.com/what-is-information-entropy/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/what-is-information-entropy", "snippet": "Calculating information and entropy is a useful tool in <b>machine</b> <b>learning</b> and is used as the basis for techniques such as feature selection, building decision trees, and, more generally, fitting classification models. As such, a <b>machine</b> <b>learning</b> practitioner requires a strong understanding and intuition for information and entropy. In this post, you will discover a gentle introduction to information entropy. After reading this post, you will know: Information theory is concerned with data ...", "dateLastCrawled": "2022-02-02T13:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Deep Learning and Information Theory</b> \u2013 Deep &amp; Shallow", "url": "https://deep-and-shallow.com/2020/01/09/deep-learning-and-information-theory/", "isFamilyFriendly": true, "displayUrl": "https://deep-and-shallow.com/2020/01/09/<b>deep-learning-and-information-theory</b>", "snippet": "If you have tried to understand the maths behind <b>machine</b> <b>learning</b>, including deep <b>learning</b>, you would have come across topics from Information Theory \u2013 Entropy, <b>Cross Entropy</b>, KL Divergence, etc. The concepts from information theory is ever prevalent in the realm of <b>machine</b> <b>learning</b>, right from the splitting criteria of a Decision Tree to loss functions in Generative Adversarial Networks.", "dateLastCrawled": "2022-02-01T00:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[D] A Short Introduction to Entropy, <b>Cross-Entropy</b> and KL-Divergence ...", "url": "https://www.reddit.com/r/MachineLearning/comments/7vhmp7/d_a_short_introduction_to_entropy_crossentropy/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/<b>MachineLearning</b>/comments/7vhmp7/d_a_short_introduction_to...", "snippet": "I am having trouble reconciling the concept with the <b>analogy</b>. At 2:35 even if a rainy day was 25% likely, there&#39;s still only two states, rainy and sunny, and therefor only 1 bit of information is needed to convey that, so only one bit of data needs to be sent, even though the 1 bit of data reduces the uncertainty of a rainy day by a factor of 4. I quite don&#39;t get what he means by this being 2 bits of information. I guess where I am stuck is how the uncertainty reduction factor translates to ...", "dateLastCrawled": "2021-08-20T08:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Lecture 4 Fundamentals of deep <b>learning</b> and neural networks", "url": "https://web.stanford.edu/class/biods388/downloads/BIODS388_Lecture_4.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/biods388/downloads/BIODS388_Lecture_4.pdf", "snippet": "Deep <b>learning</b>: <b>Machine</b> <b>learning</b> models based on \u201cdeep\u201d neural networks comprising millions (sometimes billions) of parameters organized into hierarchical layers. Features are multiplied and added together repeatedly, with the outputs from one layer of parameters being fed into the next layer -- before a prediction is made. Contrast with linear regression: Agenda for today - More on the structure of neural network models - <b>Machine</b> <b>learning</b> training loop and concept of loss, in the context ...", "dateLastCrawled": "2022-02-02T09:07:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Beat the Bookmakers With Tree-Based <b>Machine</b> <b>Learning</b> Algorithms | by ...", "url": "https://medium.com/analytics-vidhya/beat-the-bookmakers-with-tree-based-machine-learning-algorithms-1d349335b54", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/beat-the-bookmakers-with-tree-based-<b>machine</b>...", "snippet": "<b>Cross-entropy is similar</b> to Gini Impurity, but it involves using the concept of entropy from information theory. This article won\u2019t go in depth about it, but essentially, as the cross-entropy ...", "dateLastCrawled": "2022-01-26T04:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>A Traveler\u2019s Diary on the Road to Machine</b> <b>Learning</b> - Chapter 1 | by ...", "url": "https://medium.com/swlh/a-travelers-diary-on-the-road-to-machine-learning-chapter-1-8850ec5b4243", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/<b>a-travelers-diary-on-the-road-to-machine</b>-<b>learning</b>-chapter-1...", "snippet": "Types of <b>Machine</b> <b>Learning</b> algorithms: ... Sparse categorical <b>cross entropy is similar</b> to categorical cross entropy, only difference is it uses only one value as target. It saves memory as well as ...", "dateLastCrawled": "2021-05-21T04:27:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Deep Learning for Computer Architects</b> | Chen Jeff - Academia.edu", "url": "https://www.academia.edu/40860009/Deep_Learning_for_Computer_Architects", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/40860009/<b>Deep_Learning_for_Computer_Architects</b>", "snippet": "This text serves as a primer for computer architects in a new and rapidly evolving \ufb01eld. We review how <b>machine</b> <b>learning</b> has evolved since its inception in the 1960s and track the key developments leading up to the emergence of the powerful deep <b>learning</b> techniques that emerged in the last decade.", "dateLastCrawled": "2022-01-28T02:18:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(cross-entropy)  is like +(player in a game of poker)", "+(cross-entropy) is similar to +(player in a game of poker)", "+(cross-entropy) can be thought of as +(player in a game of poker)", "+(cross-entropy) can be compared to +(player in a game of poker)", "machine learning +(cross-entropy AND analogy)", "machine learning +(\"cross-entropy is like\")", "machine learning +(\"cross-entropy is similar\")", "machine learning +(\"just as cross-entropy\")", "machine learning +(\"cross-entropy can be thought of as\")", "machine learning +(\"cross-entropy can be compared to\")"]}