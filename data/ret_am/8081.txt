{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Markov Decision process</b> - Artificial Inteligence", "url": "https://leonardoaraujosantos.gitbook.io/artificial-inteligence/artificial_intelligence/markov_decision_process", "isFamilyFriendly": true, "displayUrl": "https://leonardoaraujosantos.gitbook.io/.../<b>markov_decision_process</b>", "snippet": "<b>Machine</b> <b>Learning</b>. Artificial Intelligence. OpenAI Gym. Tree Search. <b>Markov Decision process</b>. Reinforcement <b>Learning</b>. Natural Language Processing. Appendix . Powered By GitBook. <b>Markov Decision process</b>. Introduction. <b>Markov Decision process</b>(<b>MDP</b>) is a framework <b>used</b> to help to make decisions on a stochastic environment. Our goal is to find a policy, which is a map that gives us all optimal actions on each state on our environment. <b>MDP</b> is somehow more powerful than simple planning, because your ...", "dateLastCrawled": "2022-01-27T15:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>using markov decision process (MDP) to create</b> a policy \u2013 hands on ...", "url": "https://g-stat.com/using-markov-decision-process-mdp-to-create-a-policy-hands-on-python-example/", "isFamilyFriendly": true, "displayUrl": "https://<b>g-stat</b>.com/<b>using-markov-decision-process-mdp-to-create</b>-a-policy-hands-on...", "snippet": "Just a quick reminder, <b>MDP</b>, which we will implement, is a discrete time stochastic control <b>process</b>. It provides <b>a mathematical</b> framework for modeling <b>decision</b> making in situations where outcomes are partly random and partly under the control of a <b>decision</b> maker. <b>Markov</b> <b>Decision</b> Processes are a <b>tool</b> for modeling sequential <b>decision</b>-making problems where a <b>decision</b> maker interacts with the environment in a sequential fashion.", "dateLastCrawled": "2022-01-30T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "MDPs: overview", "url": "https://stanford-cs221.github.io/winter2021-extra/modules/mdps/markov-decision-processes.pdf", "isFamilyFriendly": true, "displayUrl": "https://stanford-cs221.github.io/winter2021-extra/modules/<b>mdp</b>s/<b>markov</b>-<b>decision</b>...", "snippet": "<b>Markov</b> <b>decision</b> processes Adversarial games States Constraint satisfaction problems <b>Markov</b> networks Bayesian networks Variables Logic &quot;Low-level intelligence&quot; &quot;High-level intelligence&quot; <b>Machine</b> <b>learning</b> CS221 2. So far: search problems S A D C B E F G state s, action a state Succ (s;a ) deterministic CS221 4 Last week, we looked at search problems, a powerful paradigm that can be <b>used</b> to solve a diverse range of problems ranging from word segmentation to package delivery to route nding. The ...", "dateLastCrawled": "2021-10-13T17:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Artificial Intelligence AI Interview Questions</b> and Answers - 3RI ...", "url": "https://www.3ritechnologies.com/artificial-intelligence-ai-interview-questions-and-answers/", "isFamilyFriendly": true, "displayUrl": "https://www.3ritechnologies.com/<b>artificial-intelligence-ai-interview-questions</b>-and-answers", "snippet": "The <b>Markov decision process</b> or <b>MDP</b> can be <b>used</b> to solve a reinforcement <b>learning</b> problem. <b>MDP</b> is then <b>used</b> to formalize RL. The <b>mathematical</b> method can be <b>used</b> to solve a problem in reinforcement <b>learning</b>. This <b>process</b>\u2019s primary objective is to achieve the possible benefits by selecting the best policy.", "dateLastCrawled": "2022-01-29T15:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "27 questions with answers in <b>MARKOV DECISION PROCESS</b> | Science topic", "url": "https://www.researchgate.net/topic/Markov-Decision-Process", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Markov-Decision-Process</b>", "snippet": "A <b>Markov</b> Game also known as Stochastic Game is an extension of <b>Markov Decision Process</b> (<b>MDP</b>) to the multi-agent case. There are a couple of third-party Matlab toolboxes for solving MDPs available ...", "dateLastCrawled": "2022-01-20T05:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Applications of Markov Decision Processes</b> (MDPs) in the Internet of T\u2026", "url": "https://www.slideshare.net/mabualsh/applications-of-markov-decision-processes-mdps-in-the-internet-of-things-iot-and-sensor-networks", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/mabualsh/<b>applications-of-markov-decision-processes</b>-<b>mdp</b>s-in...", "snippet": "<b>Markov</b> <b>Decision</b> Processes (MDPs): Overview The <b>Markov Decision Process</b> Framework De\ufb01nition An <b>MDP</b> is de\ufb01ned as a tuple S, A, P, R, T where, S is a \ufb01nite set of states, A is a \ufb01nite set of actions, P is a transition probability function from state s to state s after action a is taken, R is the immediate reward obtained after action a is made, and T is the set of <b>decision</b> epoch, which can be \ufb01nite or in\ufb01nite. \u03c0 denotes a \u201cpolicy\u201d which is a mapping from a state to an action ...", "dateLastCrawled": "2021-12-24T23:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Review on <b>Applications of Markov Decision Process</b> Model and Energy ...", "url": "https://www.sciencedirect.com/science/article/pii/S1877050920307493", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050920307493", "snippet": "<b>Markov</b> <b>Decision</b> Processes The optimization model designed in uncertain environment for <b>decision</b> making is referred to as a <b>Markov Decision Process</b> (<b>MDP</b>). In a particular environment or a system where the agent interacts for a stochastic <b>decision</b> <b>process</b> is described by the <b>MDP</b>. The system remains, at each <b>decision</b> time, in a particular state s and the agent chooses an action a, existing at this state. Once the action a is performed, an intermediary reward R is received by the agent and thus ...", "dateLastCrawled": "2021-12-20T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Reinforcement Learning Tutorial</b> - Javatpoint", "url": "https://www.javatpoint.com/reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/reinforcement-<b>learning</b>", "snippet": "<b>Markov Decision Process</b>. <b>Markov Decision Process</b> or <b>MDP</b>, is <b>used</b> to formalize the reinforcement <b>learning</b> problems. If the environment is completely observable, then its dynamic can be modeled as a <b>Markov</b> <b>Process</b>. In <b>MDP</b>, the agent constantly interacts with the environment and performs actions; at each action, the environment responds and ...", "dateLastCrawled": "2022-02-02T06:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Reinforcement <b>Learning</b>: What is, Algorithms, Types &amp; Examples", "url": "https://www.guru99.com/reinforcement-learning-tutorial.html", "isFamilyFriendly": true, "displayUrl": "https://www.guru99.com/reinforcement-<b>learning</b>-tutorial.html", "snippet": "The <b>mathematical</b> approach for mapping a solution in reinforcement <b>Learning</b> is recon as a <b>Markov Decision Process</b> or (<b>MDP</b>). Q-<b>Learning</b> Q <b>learning</b> is a value-based method of supplying information to inform which action an agent should take.", "dateLastCrawled": "2022-02-03T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What <b>is the mathematical backbone behind Markov</b> <b>Decision</b> Processes? - Quora", "url": "https://www.quora.com/What-is-the-mathematical-backbone-behind-Markov-Decision-Processes", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-<b>is-the-mathematical-backbone-behind-Markov</b>-<b>Decision</b>-<b>Process</b>es", "snippet": "Answer (1 of 4): In order to understand the <b>Markov Decision process</b>, it helps to understand Stochastic <b>Process</b> with &#39; State space&#39; and &#39; Parameter Space&#39;. Difference between a Discrete Stochastic <b>Process</b> and a Continuous Stochastic <b>Process</b>. The difference between a <b>Markov</b> Chain and a <b>Markov</b> Proce...", "dateLastCrawled": "2022-01-18T17:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Markov</b> <b>Decision</b> Processes in Artificial Intelligence: MDPs, beyond MDPs ...", "url": "https://www.researchgate.net/publication/297831446_Markov_Decision_Processes_in_Artificial_Intelligence_MDPs_beyond_MDPs_and_applications", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/297831446_<b>Markov</b>_<b>Decision</b>_<b>Process</b>es_in...", "snippet": "Deep reinforcement <b>learning</b> (DRL) is <b>used</b> to illustrate the hierarchical <b>decision</b>-making <b>process</b>, in which the dynamic energy conversion problem is formulated as a discrete finite <b>Markov</b> <b>decision</b> ...", "dateLastCrawled": "2022-01-30T02:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "27 questions with answers in <b>MARKOV DECISION PROCESS</b> | Science topic", "url": "https://www.researchgate.net/topic/Markov-Decision-Process", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Markov-Decision-Process</b>", "snippet": "A <b>Markov</b> Game also known as Stochastic Game is an extension of <b>Markov Decision Process</b> (<b>MDP</b>) to the multi-agent case. There are a couple of third-party Matlab toolboxes for solving MDPs available ...", "dateLastCrawled": "2022-01-20T05:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Reinforcement <b>Learning</b> for Clinical <b>Decision</b> Support in Critical Care ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7400046/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7400046", "snippet": "Mathematically, this sequential <b>decision</b>-making <b>process</b> is called the <b>Markov decision process</b> (<b>MDP</b>) . An <b>MDP</b> is defined by 4 major components: (1) a state that represents the environment at each time; (2) an action the agent takes at each time that influences the next state; (3) a transition probability that provides an estimate for reaching different subsequent states, which reflects the environment for an agent to interact with; (4) a reward function is the observed feedback given a state ...", "dateLastCrawled": "2022-01-07T08:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Artificial Intelligence AI Interview Questions</b> and Answers - 3RI ...", "url": "https://www.3ritechnologies.com/artificial-intelligence-ai-interview-questions-and-answers/", "isFamilyFriendly": true, "displayUrl": "https://www.3ritechnologies.com/<b>artificial-intelligence-ai-interview-questions</b>-and-answers", "snippet": "The <b>Markov decision process</b> or <b>MDP</b> can be <b>used</b> to solve a reinforcement <b>learning</b> problem. <b>MDP</b> is then <b>used</b> to formalize RL. The <b>mathematical</b> method can be <b>used</b> to solve a problem in reinforcement <b>learning</b>. This <b>process</b>\u2019s primary objective is to achieve the possible benefits by selecting the best policy. <b>MDP</b> has four elements, which are: A set of finite states S Policy Pa Rewards A set of finite actions A. In this <b>process</b>, the agent takes action A to move from state S1 to S2 or state to the ...", "dateLastCrawled": "2022-01-29T15:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Role of <b>Machine</b> <b>Learning</b> in Resource Allocation Strategy over Vehicular ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8512744/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8512744", "snippet": "A discussion of several <b>machine</b> <b>learning</b> scenarios <b>used</b> by previous researchers in managing and allocating network resources; ... <b>Markov Decision Process</b>. The <b>Markov decision process</b> (<b>MDP</b>) is the basic framework for RL. <b>MDP</b> is an algorithm with a discrete-time state-transition system. <b>MDP</b> has four components in its <b>learning</b> <b>process</b>, namely states S, actions A, transition model probabilities P r s t + 1 | s t, a t, and reward utility R. The transition model in <b>MDP</b> is a next-state function ...", "dateLastCrawled": "2022-01-04T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Applications of Markov Decision Processes</b> (MDPs) in the Internet of T\u2026", "url": "https://www.slideshare.net/mabualsh/applications-of-markov-decision-processes-mdps-in-the-internet-of-things-iot-and-sensor-networks", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/mabualsh/<b>applications-of-markov-decision-processes</b>-<b>mdp</b>s-in...", "snippet": "<b>Markov</b> <b>Decision</b> Processes (MDPs): Overview The <b>Markov Decision Process</b> Framework De\ufb01nition An <b>MDP</b> is de\ufb01ned as a tuple S, A, P, R, T where, S is a \ufb01nite set of states, A is a \ufb01nite set of actions, P is a transition probability function from state s to state s after action a is taken, R is the immediate reward obtained after action a is made, and T is the set of <b>decision</b> epoch, which can be \ufb01nite or in\ufb01nite. \u03c0 denotes a \u201cpolicy\u201d which is a mapping from a state to an action ...", "dateLastCrawled": "2021-12-24T23:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Reinforcement Learning Tutorial</b> - Javatpoint", "url": "https://www.javatpoint.com/reinforcement-learning", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/reinforcement-<b>learning</b>", "snippet": "<b>Markov Decision Process</b>. <b>Markov Decision Process</b> or <b>MDP</b>, is <b>used</b> to formalize the reinforcement <b>learning</b> problems. If the environment is completely observable, then its dynamic can be modeled as a <b>Markov</b> <b>Process</b>. In <b>MDP</b>, the agent constantly interacts with the environment and performs actions; at each action, the environment responds and ...", "dateLastCrawled": "2022-02-02T06:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Review on <b>Applications of Markov Decision Process</b> Model and Energy ...", "url": "https://www.sciencedirect.com/science/article/pii/S1877050920307493", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050920307493", "snippet": "<b>Markov</b> <b>Decision</b> Processes The optimization model designed in uncertain environment for <b>decision</b> making is referred to as a <b>Markov Decision Process</b> (<b>MDP</b>). In a particular environment or a system where the agent interacts for a stochastic <b>decision</b> <b>process</b> is described by the <b>MDP</b>. The system remains, at each <b>decision</b> time, in a particular state s and the agent chooses an action a, existing at this state. Once the action a is performed, an intermediary reward R is received by the agent and thus ...", "dateLastCrawled": "2021-12-20T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Reinforcement <b>Learning</b>: What is, Algorithms, Types &amp; Examples", "url": "https://www.guru99.com/reinforcement-learning-tutorial.html", "isFamilyFriendly": true, "displayUrl": "https://www.guru99.com/reinforcement-<b>learning</b>-tutorial.html", "snippet": "The <b>mathematical</b> approach for mapping a solution in reinforcement <b>Learning</b> is recon as a <b>Markov Decision Process</b> or (<b>MDP</b>). Q-<b>Learning</b> Q <b>learning</b> is a value-based method of supplying information to inform which action an agent should take.", "dateLastCrawled": "2022-02-03T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What <b>is the mathematical backbone behind Markov</b> <b>Decision</b> Processes? - Quora", "url": "https://www.quora.com/What-is-the-mathematical-backbone-behind-Markov-Decision-Processes", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-<b>is-the-mathematical-backbone-behind-Markov</b>-<b>Decision</b>-<b>Process</b>es", "snippet": "Answer (1 of 4): In order to understand the <b>Markov Decision process</b>, it helps to understand Stochastic <b>Process</b> with &#39; State space&#39; and &#39; Parameter Space&#39;. Difference between a Discrete Stochastic <b>Process</b> and a Continuous Stochastic <b>Process</b>. The difference between a <b>Markov</b> Chain and a <b>Markov</b> Proce...", "dateLastCrawled": "2022-01-18T17:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Top 50 Artificial Intelligence Questions</b> and Answers (2022) - javatpoint", "url": "https://www.javatpoint.com/artificial-intelligence-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/artificial-intelligence-interview-questions", "snippet": "The solution for a reinforcement <b>learning</b> problem <b>can</b> be achieved using the <b>Markov decision process</b> or <b>MDP</b>. Hence, <b>MDP</b> is <b>used</b> to formalize the RL problem. It <b>can</b> be said as the <b>mathematical</b> approach to solve a reinforcement <b>learning</b> problem. The main aim of this <b>process</b> is to gain maximum positive rewards by choosing the optimum policy.", "dateLastCrawled": "2022-01-31T12:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Reinforcement <b>Learning</b> for Clinical <b>Decision</b> Support in Critical Care ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7400046/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7400046", "snippet": "Mathematically, this sequential <b>decision</b>-making <b>process</b> is called the <b>Markov decision process</b> (<b>MDP</b>) . An <b>MDP</b> is defined by 4 major components: (1) a state that represents the environment at each time; (2) an action the agent takes at each time that influences the next state; (3) a transition probability that provides an estimate for reaching different subsequent states, which reflects the environment for an agent to interact with; (4) a reward function is the observed feedback given a state ...", "dateLastCrawled": "2022-01-07T08:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Getting Started with Next-Generation Artificial Intelligence through ...", "url": "https://w3sdev.com/getting-started-with-next-generation-artificial-intelligence-through-reinforcement-learning-artificial-intelligence-by-example-second-edition.html", "isFamilyFriendly": true, "displayUrl": "https://w3sdev.com/getting-started-with-next-generation-artificial-intelligence...", "snippet": "The <b>Markov decision process</b> (<b>MDP</b>), a reinforcement <b>learning</b> (RL) algorithm, perfectly illustrates how machines have become intelligent in their own unique way. Humans build their <b>decision</b> <b>process</b> on experience. MDPs are memoryless. Humans use logic and reasoning to think problems through. MDPs apply random decisions 100% of the time. Humans think in words, labeling everything they perceive. MDPs have an unsupervised approach that uses no labels or training data. MDPs boost the <b>machine</b> ...", "dateLastCrawled": "2022-01-01T04:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "K-<b>spin Hamiltonian for quantum-resolvable Markov decision processes</b> ...", "url": "https://deepai.org/publication/k-spin-hamiltonian-for-quantum-resolvable-markov-decision-processes", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../k-<b>spin-hamiltonian-for-quantum-resolvable-markov-decision-processes</b>", "snippet": "The <b>Markov decision process</b> is the <b>mathematical</b> formalization underlying the modern field of reinforcement <b>learning</b> when transition and reward functions are unknown. We derive a pseudo-Boolean cost function that is equivalent to a K-spin Hamiltonian representation of the discrete, finite, discounted <b>Markov decision process</b> with infinite horizon. This K-spin Hamiltonian furnishes a starting point from which to solve for an optimal policy using", "dateLastCrawled": "2022-01-11T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "On Joint Transfer of Energy and Information: A <b>Markov</b> <b>Decision</b> Problem ...", "url": "https://sangbumchoi.github.io/files/final-jkim-stk-choi.pdf", "isFamilyFriendly": true, "displayUrl": "https://sangbumchoi.github.io/files/final-jkim-stk-choi.pdf", "snippet": "as a <b>Markov decision process</b> (<b>MDP</b>). The solution approach is inspired by the classic river crossing problem [2] and its connection to the Bellman equation [3]. Due to the information structure of the problem, a stochastic <b>decision</b> making scenario is presented and the Bellman equation is presented. I. INTRODUCTION Optimal control theory serves as a powerful <b>tool</b> for ana-lyzing and interpreting a variety of problems in other \ufb01elds e.g.: <b>machine</b> <b>learning</b>, reinforcement <b>learning</b>, \ufb01ltering ...", "dateLastCrawled": "2021-07-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "K-spin Hamiltonian for quantum-resolvable <b>Markov</b> <b>decision</b> processes ...", "url": "https://link.springer.com/article/10.1007/s42484-020-00026-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s42484-020-00026-6", "snippet": "The <b>Markov decision process</b> is the <b>mathematical</b> formalization underlying the modern field of reinforcement <b>learning</b> when transition and reward functions are unknown. We derive a pseudo-Boolean cost function that is equivalent to a K-spin Hamiltonian representation of the discrete, finite, discounted <b>Markov decision process</b> with infinite horizon. This K-spin Hamiltonian furnishes a starting point from which to solve for an optimal policy using heuristic quantum algorithms such as adiabatic ...", "dateLastCrawled": "2021-11-23T02:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Policy <b>learning</b> in <b>continuous-time Markov decision processes</b> using ...", "url": "https://www.sciencedirect.com/science/article/pii/S016653161730086X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S016653161730086X", "snippet": "1. Introduction. <b>Continuous-time Markov Decision Processes</b> (CTMDPs) are a very powerful modelling <b>tool</b> employed in many <b>decision</b>-making problems that arise in systems featuring both probabilistic and nondeterministic behaviours. CTMDPs are generally <b>used</b> to solve control and dependability problems in a wide range of applications, including the control of populations (i.e., epidemics , and bird flocking ), power management , queuing systems , and cyber\u2013physical systems . A CTMDP extends ...", "dateLastCrawled": "2021-11-27T16:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Top 8 <b>Open Source Machine Learning Frameworks</b>", "url": "https://www.opensourceforu.com/2017/01/best-open-source-machine-learning-frameworks/", "isFamilyFriendly": true, "displayUrl": "https://www.opensourceforu.com/2017/01/best-<b>open-source-machine-learning-frameworks</b>", "snippet": "<b>In machine</b> <b>learning</b>, the environment is formulated as a <b>Markov decision process</b> (<b>MDP</b>) due to dynamic programming techniques. The application of <b>machine</b> <b>learning</b> to diverse areas of computing is gaining popularity rapidly, not only because of cheap and powerful hardware, but also because of the increasing availability of free and open source software, which enable <b>machine</b> <b>learning</b> to be implemented easily. <b>Machine</b> <b>learning</b> practitioners and researchers, being a part of the software ...", "dateLastCrawled": "2022-01-18T08:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Per-<b>Decision</b> Option Discounting - Proceedings of <b>Machine</b> <b>Learning</b> Research", "url": "http://proceedings.mlr.press/v97/harutyunyan19a/harutyunyan19a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v97/harutyunyan19a/harutyunyan19a.pdf", "snippet": "lying <b>Markov Decision Process</b>. We propose a modi\ufb01cation to the options framework that natu-rally scales the agent\u2019s horizon with option length. We show that the proposed option-step discount controls a bias-variance trade-off, with larger dis-counts (counter-intuitively) leading to less estima-tion variance. 1. Introduction Reinforcement <b>learning</b> agents have to solve the problem of reasoning about actions that improve long-term perfor-mance. This objective <b>can</b> be formulated either in the ...", "dateLastCrawled": "2021-09-01T10:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Solving SpaceNet Road Detection Challenge With</b> Deep <b>Learning</b> | NVIDIA ...", "url": "https://developer.nvidia.com/blog/solving-spacenet-road-detection-challenge-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://developer.nvidia.com/blog/<b>solving-spacenet-road-detection-challenge</b>-deep-<b>learning</b>", "snippet": "At the core, reinforcement <b>learning</b> (RL) is a dressed up <b>Markov decision process</b> (<b>MDP</b>) which is itself a form of discrete-time stochastic control <b>process</b>. Here MDPs provide a <b>mathematical</b> framework for modeling <b>decision</b> making in environments where outcomes are partly random and loosely under the control of a <b>decision</b> maker. MDPs are widely <b>used</b> in optimization problems and solved using", "dateLastCrawled": "2022-01-30T10:00:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>using markov decision process (MDP) to create</b> a policy \u2013 hands on ...", "url": "https://g-stat.com/using-markov-decision-process-mdp-to-create-a-policy-hands-on-python-example/", "isFamilyFriendly": true, "displayUrl": "https://<b>g-stat</b>.com/<b>using-markov-decision-process-mdp-to-create</b>-a-policy-hands-on...", "snippet": "<b>Markov</b> <b>Decision</b> Processes are a <b>tool</b> for modeling sequential <b>decision</b>-making problems where a <b>decision</b> maker interacts with the environment in a sequential fashion. So, the problem we have in front of us goes like this, we have a world of 12 states, 1 obstacle initial state (state 5) and an 2 end states (states 10, 11). for each state we have a ...", "dateLastCrawled": "2022-01-30T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Review on <b>Applications of Markov Decision Process</b> Model and Energy ...", "url": "https://www.sciencedirect.com/science/article/pii/S1877050920307493", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050920307493", "snippet": "<b>Markov</b> <b>Decision</b> Processes The optimization model designed in uncertain environment for <b>decision</b> making is referred to as a <b>Markov Decision Process</b> (<b>MDP</b>). In a particular environment or a system where the agent interacts for a stochastic <b>decision</b> <b>process</b> is described by the <b>MDP</b>. The system remains, at each <b>decision</b> time, in a particular state s and the agent chooses an action a, existing at this state. Once the action a is performed, an intermediary reward R is received by the agent and thus ...", "dateLastCrawled": "2021-12-20T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Markov</b> <b>Decision</b> Processes: A <b>Tool</b> for Sequential <b>Decision</b> Making ...", "url": "https://www.researchgate.net/publication/40821814_Markov_Decision_Processes_A_Tool_for_Sequential_Decision_Making_under_Uncertainty", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/40821814_<b>Markov</b>_<b>Decision</b>_<b>Process</b>es_A_<b>Tool</b>_for...", "snippet": "<b>Markov decision process</b> (<b>MDP</b>). MDPs build the theoretical foundation for modeling sequential <b>decision</b>-making problems under uncertainty [133, 134]. An <b>MDP</b> comprises the tuple (S, A, R, p, \u03b3 ...", "dateLastCrawled": "2021-12-31T09:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Top 50 Artificial Intelligence Questions</b> and Answers (2022) - javatpoint", "url": "https://www.javatpoint.com/artificial-intelligence-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/artificial-intelligence-interview-questions", "snippet": "The solution for a reinforcement <b>learning</b> problem <b>can</b> be achieved using the <b>Markov decision process</b> or <b>MDP</b>. Hence, <b>MDP</b> is <b>used</b> to formalize the RL problem. It <b>can</b> be said as the <b>mathematical</b> approach to solve a reinforcement <b>learning</b> problem. The main aim of this <b>process</b> is to gain maximum positive rewards by choosing the optimum policy.", "dateLastCrawled": "2022-01-31T12:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Reinforcement <b>Learning</b> for Clinical <b>Decision</b> Support in Critical Care ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7400046/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7400046", "snippet": "Mathematically, this sequential <b>decision</b>-making <b>process</b> is called the <b>Markov decision process</b> ... This problem is not unique to RL but seems harder to address in RL <b>compared</b> with other <b>machine</b> <b>learning</b> approaches, such as prediction and classification algorithms, where accuracy and precision recall are more straightforward to implement. However, it is worth noting that RL has a distinct advantage over other <b>machine</b> <b>learning</b> approaches, that one <b>can</b> choose which outcome to optimize by ...", "dateLastCrawled": "2022-01-07T08:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Mathematics of 2048: <b>Optimal Play with Markov Decision Processes</b>", "url": "https://jdlm.info/articles/2018/03/18/markov-decision-process-2048.html", "isFamilyFriendly": true, "displayUrl": "https://<b>jdlm.info</b>/articles/2018/03/18/<b>markov-decision-process</b>-2048.html", "snippet": "So far in this series on the mathematics of 2048, we\u2019ve <b>used</b> <b>Markov</b> chains to learn that it takes at least 938.8 moves on average to win, and we\u2019ve explored the number of possible board configurations in the game using combinatorics and then exhaustive enumeration.. In this post, we\u2019ll use a <b>mathematical</b> framework called a <b>Markov Decision Process</b> to find provably optimal strategies for 2048 when played on the 2x2 and 3x3 boards, and also on the 4x4 board up to the 64 tile. For example ...", "dateLastCrawled": "2022-01-27T06:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Reinforcement <b>Learning</b>: What is, Algorithms, Types &amp; Examples", "url": "https://www.guru99.com/reinforcement-learning-tutorial.html", "isFamilyFriendly": true, "displayUrl": "https://www.guru99.com/reinforcement-<b>learning</b>-tutorial.html", "snippet": "The <b>mathematical</b> approach for mapping a solution in reinforcement <b>Learning</b> is recon as a <b>Markov Decision Process</b> or (<b>MDP</b>). Q-<b>Learning</b> Q <b>learning</b> is a value-based method of supplying information to inform which action an agent should take.", "dateLastCrawled": "2022-02-03T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Irrigation optimization with a deep reinforcement <b>learning</b> model: Case ...", "url": "https://www.sciencedirect.com/science/article/pii/S0378377422000270", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0378377422000270", "snippet": "Before talking about reinforcement <b>learning</b>, it is necessary to explain a <b>Markov Decision Process</b> (<b>MDP</b>). <b>MDP</b> is the <b>mathematical</b> model <b>used</b> to describe the <b>learning</b> problem (Sutton and Barto, 2018). There is an agent that makes the decisions and learns within an environment that interacts with the agent at each time t.", "dateLastCrawled": "2022-01-27T09:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "K-<b>spin Hamiltonian for quantum-resolvable Markov decision processes</b> ...", "url": "https://deepai.org/publication/k-spin-hamiltonian-for-quantum-resolvable-markov-decision-processes", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../k-<b>spin-hamiltonian-for-quantum-resolvable-markov-decision-processes</b>", "snippet": "The <b>Markov decision process</b> is the <b>mathematical</b> formalization underlying the modern field of reinforcement <b>learning</b> when transition and reward functions are unknown. We derive a pseudo-Boolean cost function that is equivalent to a K-spin Hamiltonian representation of the discrete, finite, discounted <b>Markov decision process</b> with infinite horizon. This K-spin Hamiltonian furnishes a starting point from which to solve for an optimal policy using", "dateLastCrawled": "2022-01-11T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>the difference between Markov Models and</b> Hidden <b>Markov</b> ... - Quora", "url": "https://www.quora.com/What-is-the-difference-between-Markov-Models-and-Hidden-Markov-Models", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-difference-between-Markov-Models-and</b>-Hidden-<b>Markov</b>...", "snippet": "Answer (1 of 5): A &quot;<b>Markov</b> Model&quot; <b>process</b> is basically one that does not have any memory -- the distribution of the next state/observation depends exclusively on the current state. A <b>Markov</b> Model may be autonomous or controlled -- an autonomous <b>Markov</b> <b>process</b> will evolve by itself, and in the cas...", "dateLastCrawled": "2022-01-16T06:32:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Markov decision process</b>: value iteration with code implementation | by ...", "url": "https://medium.com/@ngao7/markov-decision-process-value-iteration-2d161d50a6ff", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@ngao7/<b>markov-decision-process</b>-value-iteration-2d161d50a6ff", "snippet": "<b>Markov decision process</b>, <b>MDP</b>, value iteration, policy iteration, policy evaluation, policy improvement, sweep, iterative policy evaluation, policy, optimal policy ...", "dateLastCrawled": "2022-01-08T01:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Why does <b>Markov Decision Process</b> matter in Reinforcement <b>Learning</b>? | by ...", "url": "https://towardsdatascience.com/why-does-malkov-decision-process-matter-in-reinforcement-learning-b111b46b41bd", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/why-does-malkov-<b>decision</b>-<b>process</b>-matter-in...", "snippet": "It is named by <b>analogy</b> to \u201cone-armed bandit\u201d(= a slot <b>machine</b>) although the framework has k levers instead of one. ... we introduce <b>Markov Decision Process</b>(<b>MDP</b>) to solve such a problem. An <b>MDP</b> consists of two elements; the agent and the environment. The agent is a learner or <b>decision</b>-maker. In the above example, the agent is the rabbit. The environment is everything surrounding the agent. In the example, the environment includes everything in the field where the rabbit is with food and ...", "dateLastCrawled": "2022-01-31T01:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "<b>Markov decision process</b> (<b>MDP</b>): In reinforcement <b>learning</b>, <b>MDP</b> is a mathematical framework for modeling <b>decision</b>-making of an agent in situations or environments where outcomes are partly random and partly under control. In this model, environment is modeled as a set of states and actions that can be performed by an agent to control the system\u2019s state. The objective is to control the system in such a way that the agent\u2019s total payoff is maximized.", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Introduction to <b>Machine</b> <b>Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-machine-learning-3/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-<b>machine</b>-<b>learning</b>-3", "snippet": "<b>Markov decision process</b> (<b>MDP</b>): In reinforcement <b>learning</b>, <b>MDP</b> is a mathematical framework for modeling <b>decision</b>-making of an agent in situations or environments where outcomes are partly random and partly under control. In this model, environment is modeled as a set of states and actions that can be performed by an agent to control the system\u2019s state. The objective is to control the system in such a way that the agent\u2019s total payoff is maximized.", "dateLastCrawled": "2022-01-28T18:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "CSE599i: Online and Adaptive <b>Machine</b> <b>Learning</b> Winter 2018 Lecture 19 ...", "url": "https://courses.cs.washington.edu/courses/cse599i/18wi/resources/lecture19/lecture19.pdf", "isFamilyFriendly": true, "displayUrl": "https://courses.cs.washington.edu/courses/cse599i/18wi/resources/lecture19/lecture19.pdf", "snippet": "1.1Summary of <b>Markov</b> <b>Decision</b> Processes A <b>Markov Decision Process</b> (<b>MDP</b>) is a probabilistic model for reward-incentivized, memoryless, sequential <b>decision</b>-making. An <b>MDP</b> models a scenario in which an agent (the <b>decision</b> maker) iteratively observes the", "dateLastCrawled": "2021-09-07T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Markov decision process</b>: policy iteration with code implementation | by ...", "url": "https://medium.com/@ngao7/markov-decision-process-policy-iteration-42d35ee87c82?source=post_internal_links---------0-------------------------------", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@ngao7/<b>markov-decision-process</b>-policy-iteration-42d35ee87c82?source=...", "snippet": "<b>Markov decision process</b>: policy iteration with code implementation . Nan. Dec 19, 2021 \u00b7 16 min read. In today\u2019s story we focus on policy iteration of <b>MDP</b>. We are still using the grid world ...", "dateLastCrawled": "2022-01-22T13:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "AI and Reinforcement <b>Learning</b> \u2014 Machines that Learn through Experience ...", "url": "https://www.cantorsparadise.com/ai-and-reinforcement-learning-machines-that-learn-through-experience-e7eea7bb6765", "isFamilyFriendly": true, "displayUrl": "https://www.cantorsparadise.com/ai-and-reinforcement-<b>learning</b>-<b>machines</b>-that-learn...", "snippet": "This <b>process</b> can be mathematically represented as a <b>Markov Decision Process</b> (<b>MDP</b>). \u201cMDPs are a mathematically idealized form of the reinforcement <b>learning</b> problem for which precise theoretical statements can be made.\u201d \u2014 Richard S. Sutton . The <b>MDP</b> framework is an abstraction of the problem of goal-directed <b>learning</b> from interaction. It proposes that any problem of <b>learning</b> goal-directed behavior can be reduced to three signals passing back and forth between an agent and its environment ...", "dateLastCrawled": "2022-01-25T17:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Reinforcement <b>Learning</b> \u2014 Controversy over Reward | by OperAI ...", "url": "https://operai.medium.com/reinforcement-learning-reward-controversy-issue-e9b88167d238", "isFamilyFriendly": true, "displayUrl": "https://operai.medium.com/reinforcement-<b>learning</b>-reward-controversy-issue-e9b88167d238", "snippet": "Example of RL algorithm is the <b>Markov Decision Process</b> (<b>MDP</b>) and there is a package for applying <b>MDP</b>. Other algorithms and packages are also under development such as the \u201cReinforcementLearning\u201d package, which is intended to partially close this gap and offers the ability to perform model-free reinforcement <b>learning</b> in a highly customizable framework.", "dateLastCrawled": "2022-02-01T20:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - Why is the <b>optimal policy</b> in <b>Markov Decision Process</b> ...", "url": "https://stats.stackexchange.com/questions/132890/why-is-the-optimal-policy-in-markov-decision-process-mdp-independent-of-the-i", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/132890", "snippet": "The intuition behind the argument saying that the <b>optimal policy</b> is independent of initial state is the following: The <b>optimal policy</b> is defined by a function that selects an action for every possible state and actions in different states are independent.. Formally speaking, for an unknown initial distribution, the value function to maximize would be the following (not conditioned on initial state)", "dateLastCrawled": "2022-01-25T23:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine</b> <b>learning</b> and AI <b>in marketing \u2013 Connecting computing power to</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0167811620300410", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167811620300410", "snippet": "These tasks are often formulated as a <b>Markov decision process</b> (<b>MDP</b>), a structure familiar to marketing researchers who investigate forward-looking behaviors using dynamic programming models. The <b>learning</b> algorithm needs to determine the actions to take to both learn the environment&#39;s characteristics and craft optimal policy of actions given the states. This type of <b>machine</b> <b>learning</b> tasks has received heightened attention due to recent methodological advancement and increasing usages in the ...", "dateLastCrawled": "2022-01-12T18:25:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Overview: Representation Techniques", "url": "https://webcms3.cse.unsw.edu.au/static/uploads/course/COMP4418/17s2/9c0e19e0e02df66fffb5d0bd4c20697922f5ffbf9a602b66bec3f74ac83fb77c/DecisionMaking.pdf", "isFamilyFriendly": true, "displayUrl": "https://webcms3.cse.unsw.edu.au/static/uploads/course/COMP4418/17s2/9c0e19e0e02df66...", "snippet": "<b>Markov Decision Process MDP is like</b> a Markov process, except every round we make a decision Transition probabilities depend on actions taken P(St+1 = S&#39; | St = s, At = a) = P(S, a, S&#39;) Rewards for every state, action pair u(St = s, At = a) Discount factor \u03b4 Example. A <b>machine</b> can be in one of three states: good, deteriorating, broken Can take ...", "dateLastCrawled": "2022-01-21T05:20:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(markov decision process (mdp))  is like +(a mathematical tool used in machine learning)", "+(markov decision process (mdp)) is similar to +(a mathematical tool used in machine learning)", "+(markov decision process (mdp)) can be thought of as +(a mathematical tool used in machine learning)", "+(markov decision process (mdp)) can be compared to +(a mathematical tool used in machine learning)", "machine learning +(markov decision process (mdp) AND analogy)", "machine learning +(\"markov decision process (mdp) is like\")", "machine learning +(\"markov decision process (mdp) is similar\")", "machine learning +(\"just as markov decision process (mdp)\")", "machine learning +(\"markov decision process (mdp) can be thought of as\")", "machine learning +(\"markov decision process (mdp) can be compared to\")"]}