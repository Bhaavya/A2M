{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "a) <b>false</b> <b>positive</b> <b>rate</b> for background classes b) <b>false</b> negative <b>rate</b> ...", "url": "https://www.researchgate.net/figure/a-false-positive-rate-for-background-classes-b-false-negative-rate-for-background_fig2_221365411", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/a-<b>false</b>-<b>positive</b>-<b>rate</b>-for-background-classes-b...", "snippet": "a) <b>false</b> <b>positive</b> <b>rate</b> for background classes b) <b>false</b> negative <b>rate</b> for background classes. The experimental result on different background knowledge sets shows that the full knowledge approach ...", "dateLastCrawled": "2021-11-11T20:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification: <b>True</b> vs. <b>False</b> and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-<b>false</b>-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model correctly predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model correctly predicts the negative class.. A <b>false</b> <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a <b>false</b> negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Evaluation of Classification Model Accuracy</b>: Essentials - Articles - STHDA", "url": "http://www.sthda.com/english/articles/36-classification-methods-essentials/143-evaluation-of-classification-model-accuracy-essentials/", "isFamilyFriendly": true, "displayUrl": "www.sthda.com/english/articles/36-classification-methods-essentials/143-evaluation-of...", "snippet": "Since we don\u2019t usually know the probability cutoff in advance, the ROC curve is typically used to plot the true <b>positive</b> <b>rate</b> (or sensitivity on y-axis) against the <b>false</b> <b>positive</b> <b>rate</b> (or \u201c1-specificity\u201d on x-axis) at all possible probability cutoffs. This shows the trade off between the <b>rate</b> at which you can correctly predict something with the <b>rate</b> of incorrectly predicting something. Another visual representation of the ROC plot is to simply display the sensitive against the ...", "dateLastCrawled": "2022-02-03T05:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Evaluating Deep <b>Learning Models: The Confusion Matrix</b>, Accuracy ...", "url": "https://www.kdnuggets.com/2021/02/evaluating-deep-learning-models-confusion-matrix-accuracy-precision-recall.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2021/02/evaluating-deep-learning-models-confusion-matrix...", "snippet": "When the model makes many <b>incorrect</b> <b>Positive</b> <b>classifications</b>, or few correct ... Thus, the True <b>Positive</b> <b>rate</b> is 2 and the <b>False</b> <b>Positive</b> <b>rate</b> is 1, and the precision is 2/(2+1)=0.667. In other words, the trustiness <b>percentage</b> of the model when it says that a sample is <b>Positive</b> is 66.7%. The goal of the precision is to classify all the <b>Positive</b> samples as <b>Positive</b>, and not misclassify a negative sample as <b>Positive</b>. According to the next figure, if all the three <b>Positive</b> samples are correctly ...", "dateLastCrawled": "2022-01-31T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Confusion Matrix</b> in <b>Machine Learning</b> with EXAMPLE", "url": "https://www.guru99.com/confusion-matrix-machine-learning-example.html", "isFamilyFriendly": true, "displayUrl": "https://www.guru99.com/<b>confusion-matrix</b>-<b>machine-learning</b>-example.html", "snippet": "The total <b>of incorrect</b> predictions of each class. After that, these numbers are organized in the below-given methods: ... Roc curve shows the true <b>positive</b> rates against the <b>false</b> <b>positive</b> <b>rate</b> at various cut points. It also demonstrates a trade-off between sensitivity (recall and specificity or the true negative <b>rate</b>). Precision: The precision metric shows the accuracy of the <b>positive</b> class. It measures how likely the prediction of the <b>positive</b> class is correct. The maximum score is 1 when ...", "dateLastCrawled": "2022-02-02T20:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Accuracy, Precision, and Recall</b> in Deep Learning | Paperspace Blog", "url": "https://blog.paperspace.com/deep-learning-metrics-precision-recall-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://blog.paperspace.com/deep-learning-metrics-precision-recall-accuracy", "snippet": "The model makes fewer <b>incorrect</b> <b>Positive</b> <b>classifications</b> (minimize <b>False</b> <b>Positive</b>). Imagine a man who is trusted by others; when he predicts something, others believe him. The precision <b>is like</b> this man. When the precision is high, you can trust the model when it predicts a sample as <b>Positive</b>. Thus, the precision helps to know how the model is accurate when it says that a sample is <b>Positive</b>. Based on the previous discussion, here is a definition of precision: The precision reflects how ...", "dateLastCrawled": "2022-02-02T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The \u2018<b>Percentage Correct\u2019 and other Performance Prediction Methods</b> ...", "url": "https://www.joe0.com/2017/02/19/the-percentage-correct-and-other-performance-prediction-methods/", "isFamilyFriendly": true, "displayUrl": "https://www.joe0.com/2017/02/19/the-<b>percentage-correct-and-other-performance</b>...", "snippet": "For example, \u201cwhen predicting time series <b>like</b> currency exchange <b>rate</b> variation over time or risk of being specific cyber criminals\u2019 target, <b>percentage</b> correct prediction is not applicable\u201d. (Herron, 1999). The reason it is not perfectly applicable to all types of data sets it due to its most praised quality of summarizing performance into a single <b>percentage</b> number, which isn\u2019t always the best method in situations where we encounter and want to report on several different factors ...", "dateLastCrawled": "2022-02-03T03:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to evaluate my <b>Classification</b> Model results | by Songhao Wu ...", "url": "https://towardsdatascience.com/top-5-metrics-for-evaluating-classification-model-83ede24c7584", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/top-5-metrics-for-evaluating-<b>classification</b>-model-83ede...", "snippet": "For example, if I cannot tolerate any <b>false</b> <b>positive</b> <b>rate</b> (&lt;0.01), then the true <b>positive</b> <b>rate</b> I can reach is around 0.6(see the green dot on the graph). If I loosen my criteria a bit and I only need to control FPR below 0.1, then my TPR can reach 0.9(see the red dot on the graph).", "dateLastCrawled": "2022-02-02T13:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to Calculate Precision, Recall, and F-Measure for Imbalanced ...", "url": "https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/precision-recall-and-f-measure-for-", "snippet": "Precision quantifies the number of <b>positive</b> class predictions that actually belong to the <b>positive</b> class. Recall quantifies the number of <b>positive</b> class predictions made out of all <b>positive</b> examples in the dataset. F-Measure provides a single score that balances both the concerns of precision and recall in one number. Kick-start your project with my new book Imbalanced Classification with Python, including step-by-step tutorials and the Python source code files for all examples. Let\u2019s get ...", "dateLastCrawled": "2022-02-03T02:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Guide to <b>Classification</b> on Imbalanced Datasets | by Matthew Stewart ...", "url": "https://towardsdatascience.com/guide-to-classification-on-imbalanced-datasets-d6653aa5fa23", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/guide-to-<b>classification</b>-on-imbalanced-<b>dataset</b>s-d6653aa5fa23", "snippet": "For an ideal classifier, the AUC equals 1, since we are multiplying 100% (1.0) true <b>positive</b> <b>rate</b> by 100% (1.0) <b>false</b>-<b>positive</b> <b>rate</b>. If a particular classifier has an ROC of 0.6 and another has an ROC of 0.8, the latter is clearly a better classifier. The AUC has the benefit that it is independent of the decision criteria \u2014 the <b>classification</b> threshold \u2014 and thus makes it easier to compare these classifiers.", "dateLastCrawled": "2022-02-03T01:27:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "a) <b>false</b> <b>positive</b> <b>rate</b> for background classes b) <b>false</b> negative <b>rate</b> ...", "url": "https://www.researchgate.net/figure/a-false-positive-rate-for-background-classes-b-false-negative-rate-for-background_fig2_221365411", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/a-<b>false</b>-<b>positive</b>-<b>rate</b>-for-background-classes-b...", "snippet": "a) <b>false</b> <b>positive</b> <b>rate</b> for background classes b) <b>false</b> negative <b>rate</b> for background classes. The experimental result on different background knowledge sets shows that the full knowledge approach ...", "dateLastCrawled": "2021-11-11T20:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification Model for <b>Loan Default</b> Risk Prediction | by Tanmoy ...", "url": "https://medium.com/analytics-vidhya/classification-model-for-loan-default-risk-prediction-98c2cc7ef1bf", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/classification-model-for-<b>loan-default</b>-risk...", "snippet": "TPR or true <b>positive</b> <b>rate</b> is a measure for \u2018recall\u2019 or sensitivity. FPR or <b>false</b> <b>positive</b> <b>rate</b> is a measure for expectancy of the <b>false</b> positives from the model.", "dateLastCrawled": "2022-02-02T21:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Classification: <b>True</b> vs. <b>False</b> and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-<b>false</b>-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model correctly predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model correctly predicts the negative class.. A <b>false</b> <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a <b>false</b> negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Evaluating Deep <b>Learning Models: The Confusion Matrix</b>, Accuracy ...", "url": "https://www.kdnuggets.com/2021/02/evaluating-deep-learning-models-confusion-matrix-accuracy-precision-recall.html", "isFamilyFriendly": true, "displayUrl": "https://www.kdnuggets.com/2021/02/evaluating-deep-learning-models-confusion-matrix...", "snippet": "The model makes fewer <b>incorrect</b> <b>Positive</b> <b>classifications</b> (minimize ... Thus, the True <b>Positive</b> <b>rate</b> is 2 and the <b>False</b> <b>Positive</b> <b>rate</b> is 1, and the precision is 2/(2+1)=0.667. In other words, the trustiness <b>percentage</b> of the model when it says that a sample is <b>Positive</b> is 66.7%. The goal of the precision is to classify all the <b>Positive</b> samples as <b>Positive</b>, and not misclassify a negative sample as <b>Positive</b>. According to the next figure, if all the three <b>Positive</b> samples are correctly ...", "dateLastCrawled": "2022-01-31T15:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Accuracy, Precision, Recall &amp; F1-Score - Python</b> Examples - <b>Data Analytics</b>", "url": "https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>accuracy-precision-recall-f1-score-python</b>-example", "snippet": "<b>False</b> <b>Positive</b> (FP): <b>False</b> <b>positive</b> represents the value <b>of incorrect</b> <b>positive</b> predictions. This value represents the number of negatives (out of 64) which gets falsely predicted as <b>positive</b>. Out of 64 actual negative, 3 is falsely predicted as <b>positive</b>. Thus, the value of <b>False</b> <b>Positive</b> is 3. True Negative (TN): True negative represents the value of correct predictions of negatives out of actual negative cases. Out of 64 actual negative, 61 is correctly predicted negative. Thus, the value ...", "dateLastCrawled": "2022-02-02T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to evaluate my <b>Classification</b> Model results | by Songhao Wu ...", "url": "https://towardsdatascience.com/top-5-metrics-for-evaluating-classification-model-83ede24c7584", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/top-5-metrics-for-evaluating-<b>classification</b>-model-83ede...", "snippet": "For example, if I cannot tolerate any <b>false</b> <b>positive</b> <b>rate</b> (&lt;0.01), then the true <b>positive</b> <b>rate</b> I can reach is around 0.6(see the green dot on the graph). If I loosen my criteria a bit and I only need to control FPR below 0.1, then my TPR can reach 0.9(see the red dot on the graph).", "dateLastCrawled": "2022-02-02T13:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "8 popular Evaluation Metrics for Machine Learning Models - Just into Data", "url": "https://www.justintodata.com/machine-learning-model-evaluation-metrics/", "isFamilyFriendly": true, "displayUrl": "https://www.justintodata.com/machine-learning-model-evaluation-metrics", "snippet": "The ROC (Receiver Operating Characteristic) curve plots the True <b>Positive</b> <b>Rate</b> (TPR) against the <b>False</b> <b>Positive</b> <b>Rate</b> (FPR) at different classification thresholds. The threshold value determines the boundary between classes when using the classifier to predict. For example, a value above a threshold can be classified as Unicorn, a value below ...", "dateLastCrawled": "2022-02-03T07:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The \u2018<b>Percentage Correct\u2019 and other Performance Prediction Methods</b> ...", "url": "https://www.joe0.com/2017/02/19/the-percentage-correct-and-other-performance-prediction-methods/", "isFamilyFriendly": true, "displayUrl": "https://www.joe0.com/2017/02/19/the-<b>percentage-correct-and-other-performance</b>...", "snippet": "For example, \u201cwhen predicting time series like currency exchange <b>rate</b> variation over time or risk of being specific cyber criminals\u2019 target, <b>percentage</b> correct prediction is not applicable\u201d. (Herron, 1999). The reason it is not perfectly applicable to all types of data sets it due to its most praised quality of summarizing performance into a single <b>percentage</b> number, which isn\u2019t always the best method in situations where we encounter and want to report on several different factors ...", "dateLastCrawled": "2022-02-03T03:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Top <b>10 Evaluation Metrics for Classification</b> Models", "url": "https://www.explorium.ai/blog/top-10-evaluation-metrics-for-classification-models/", "isFamilyFriendly": true, "displayUrl": "https://www.explorium.ai/blog/top-<b>10-evaluation-metrics-for-classification</b>-models", "snippet": "3. Detection <b>rate</b>. This metric basically shows the number of correct <b>positive</b> class predictions made as a proportion of all of the predictions made. Detection <b>Rate</b> = TP / TP + FP + FN + TN. 4. Logarithmic loss. Also known as log loss, logarithmic loss basically functions by penalizing all <b>false</b>/<b>incorrect</b> <b>classifications</b>. The classifier must ...", "dateLastCrawled": "2022-01-25T01:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Calculate Precision, Recall, and F-Measure for Imbalanced ...", "url": "https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/precision-recall-and-f-measure-for-", "snippet": "Consider a model that predicts 150 examples for the <b>positive</b> class, 95 are correct (true positives), meaning five were missed (<b>false</b> negatives) and 55 are <b>incorrect</b> (<b>false</b> positives). We can calculate the precision as follows: Precision = TruePositives / (TruePositives + FalsePositives) Precision = 95 / (95 + 55) Precision = 0.633", "dateLastCrawled": "2022-02-03T02:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>False positive tests</b> | Dr. Malcolm Kendrick", "url": "https://drmalcolmkendrick.org/2020/09/28/false-positive-tests/", "isFamilyFriendly": true, "displayUrl": "https://drmalcolmkendrick.org/2020/09/28/<b>false-positive-tests</b>", "snippet": "And you don\u2019t need a high <b>percentage</b> of <b>false positive tests</b> to do this. If the <b>false</b> <b>positive</b> <b>rate</b> is as little as just one per cent (1%) this means the majority of people told they are <b>positive</b> for COVID19, do not have COVID19! I know that most people find this a difficult one. It goes like this. First, you have to know the estimated prevalence of the disease in the community. That is, the total number currently infected. Last time I looked it was one in nine hundred. For the sake of ...", "dateLastCrawled": "2021-12-23T04:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Noninvasive Prenatal Testing for Trisomies 21, 18, and 13, Sex ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6395059/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6395059", "snippet": "The <b>false</b>-<b>positive</b> <b>rate</b> for NIPT from preliminary local data was much higher than that found in the clinical evidence review and published meta-analyses (about 0.1%). 19,67 A Cochrane review found that the combined NIPT <b>false</b>-<b>positive</b> <b>rate</b> for trisomies 21, 18, and 13 was approximately 0.1%. 67 We used various NIPT <b>false</b>-<b>positive</b> rates in the sensitivity analyses. For first-tier NIPT, we estimated test performance for trisomies 18 and 13 based on our clinical evidence review of the average ...", "dateLastCrawled": "2022-02-03T02:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Entry 23: Scoring Classification Models - Theory</b> - Data Science Diaries", "url": "https://julielinx.github.io/blog/23_class_score_theory/", "isFamilyFriendly": true, "displayUrl": "https://julielinx.github.io/blog/23_class_score_theory", "snippet": "While a <b>false</b> <b>positive</b> still means that non-spam was identified as spam and a <b>false</b> negative means that spam was incorrectly classified as not spam, the consequences are different. Here including a good email in the spam folder has higher repercussions than letting some spam through. The metric here should be biased toward ensuring most or all good emails are retained instead of catching all spam.", "dateLastCrawled": "2022-01-29T03:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The <b>False</b> <b>positive</b> problem of automatic bot detection in social science ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0241045", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0241045", "snippet": "The true <b>positive</b> <b>rate</b> on the y-axis is plotted against the <b>false</b> <b>positive</b> <b>rate</b> on the x-axis. While this statistic is useful to directly compare the overall performance of different models and labelled data sets with regard to the accuracy of the <b>classifications</b>, this evaluation method also has its limitations [ 30 , 31 ].", "dateLastCrawled": "2021-11-17T21:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How To Model Your AML Data To Avoid <b>False Positives</b>", "url": "https://www.zencos.com/whitepapers/ml-monitoring-false-positives/", "isFamilyFriendly": true, "displayUrl": "https://www.zencos.com/whitepapers/ml-monitoring-<b>false-positives</b>", "snippet": "While there are several excellent AML solutions on the market, the incredibly high <b>rate</b> of <b>false</b>-<b>positive</b> alerts generated each day is a growing problem. Unproductive alerts cause investigator burnout and cost organisations billions of dollars each year. Organisations <b>can</b> use the data generated by these solutions and supplement the monitoring process with predictive models. These models bring additional logic to their solutions and help identify which alerts should in fact be investigated.", "dateLastCrawled": "2022-01-28T09:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Classification Accuracy is Not Enough: More Performance Measures You ...", "url": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-", "snippet": "Put another way it is the number of <b>positive</b> predictions divided by the number of <b>positive</b> class values in the test data. It is also called Sensitivity or the True <b>Positive</b> <b>Rate</b>. Recall <b>can</b> <b>be thought</b> of as a measure of a classifiers completeness. A low recall indicates many <b>False</b> Negatives. The recall of the All No Recurrence model is 0/(0+85 ...", "dateLastCrawled": "2022-02-03T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Top 70+ <b>Data Science Interview Questions and Answers</b> for 2022 - Intellipaat", "url": "https://intellipaat.com/blog/interview-question/data-science-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://intellipaat.com/blog/interview-question/data-science-interview-", "snippet": "It is basically a plot between a true <b>positive</b> <b>rate</b> and a <b>false</b> <b>positive</b> <b>rate</b>, and it helps us to find out the right tradeoff between the true <b>positive</b> <b>rate</b> and the <b>false</b> <b>positive</b> <b>rate</b> for different probability thresholds of the predicted values. So, the closer the curve to the upper left corner, the better the model is. In other words, whichever curve has greater area under it that would be the better model. You <b>can</b> see this in the below graph:", "dateLastCrawled": "2022-02-03T02:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Accuracy and reliability of forensic latent fingerprint decisions | <b>PNAS</b>", "url": "https://www.pnas.org/content/108/19/7733", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/108/19/7733", "snippet": "The true negative <b>rate</b> was greater than the true <b>positive</b> <b>rate</b>. Much of this difference may be explained by three factors: The amount of information necessary for an exclusion decision is typically less than for an individualization decision, examiners operate within a culture where <b>false</b> positives are seen as more serious errors than <b>false</b> negatives (), and the mated pairs included a greater proportion of poor-quality prints than the nonmated pairs (SI Appendix, section 1.3).Whereas poor ...", "dateLastCrawled": "2022-02-03T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Machine Learning Model Performance</b> and Error Analysis", "url": "https://www.linkedin.com/pulse/machine-learning-model-performance-error-analysis-payam-mokhtarian", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/<b>machine-learning-model-performance</b>-error-analysis-payam...", "snippet": "One <b>can</b> easily see from the ROC curves then that the goal is to find and tune a model that maximises the true <b>positive</b> <b>rate</b>, while simultaneously minimising the <b>false</b> <b>positive</b> <b>rate</b>. Said another ...", "dateLastCrawled": "2022-01-22T01:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Validity Test</b> Flashcards | <b>Quizlet</b>", "url": "https://quizlet.com/385251830/validity-test-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/385251830/<b>validity-test</b>-flash-cards", "snippet": "C. evaluating the <b>percentage</b> of passing and failing grades on the test D. evaluating test scores as they relate to predictions from a particular theory . evaluating the <b>percentage</b> of passing and failing grades on the test. 33. Predictive and concurrent validity <b>can</b> be subsumed under A. content validity. B. criterion-related validity. C. face validity. D. true score validity. criterion-related validity. 34. Relating scores obtained on a test to other test scores or data from other assessment ...", "dateLastCrawled": "2021-12-14T14:07:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification: <b>True</b> vs. <b>False</b> and <b>Positive</b> vs. Negative | Machine ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/.../crash-course/classification/<b>true</b>-<b>false</b>-<b>positive</b>-negative", "snippet": "A <b>true</b> <b>positive</b> is an outcome where the model correctly predicts the <b>positive</b> class. Similarly, a <b>true</b> negative is an outcome where the model correctly predicts the negative class.. A <b>false</b> <b>positive</b> is an outcome where the model incorrectly predicts the <b>positive</b> class. And a <b>false</b> negative is an outcome where the model incorrectly predicts the negative class.. In the following sections, we&#39;ll look at how to evaluate classification models using metrics derived from these four outcomes.", "dateLastCrawled": "2022-02-02T23:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Classification: <b>Accuracy</b> | Machine Learning Crash Course | Google ...", "url": "https://developers.google.com/machine-learning/crash-course/classification/accuracy", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/machine-learning/crash-course/classification/<b>accuracy</b>", "snippet": "Formally, <b>accuracy</b> has the following definition: <b>Accuracy</b> = Number of correct predictions Total number of predictions. For binary classification, <b>accuracy</b> <b>can</b> also be calculated in terms of positives and negatives as follows: <b>Accuracy</b> = T P + T N T P + T N + F P + F N. Where TP = True Positives, TN = True Negatives, FP = <b>False</b> Positives, and FN ...", "dateLastCrawled": "2022-02-02T21:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The <b>False</b> <b>positive</b> problem of automatic bot detection in social science ...", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0241045", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0241045", "snippet": "The true <b>positive</b> <b>rate</b> on the y-axis is plotted against the <b>false</b> <b>positive</b> <b>rate</b> on the x-axis. While this statistic is useful to directly compare the overall performance of different models and labelled data sets with regard to the accuracy of the <b>classifications</b>, this evaluation method also has its limitations [ 30 , 31 ].", "dateLastCrawled": "2021-11-17T21:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Comparative Study of Classification Algorithms using Data Mining ...", "url": "https://researchoutput.csu.edu.au/files/12305724/12305550_published_article.pdf", "isFamilyFriendly": true, "displayUrl": "https://researchoutput.csu.edu.au/files/12305724/12305550_published_article.pdf", "snippet": "correct classification, <b>incorrect</b> classification, True <b>Positive</b> <b>Rate</b> (TP), <b>False</b> <b>Positive</b> <b>Rate</b> (FP), Precision (P), Recall (R) and F-measure (F). These outputs are captured by using two different test methods: k-fold cross-validation and <b>percentage</b> split. Outputs are then <b>compared</b> to understand the classifier performances. Our analysis illustrates that JRip has classified the highest number of correct <b>classifications</b> by 73.71% followed by decision table with 73.66% of correct predictions ...", "dateLastCrawled": "2022-01-17T13:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning Model Performance</b> and Error Analysis", "url": "https://www.linkedin.com/pulse/machine-learning-model-performance-error-analysis-payam-mokhtarian", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/<b>machine-learning-model-performance</b>-error-analysis-payam...", "snippet": "An ROC curve is a two-dimensional plot of sensitivity (recall, or true <b>positive</b> <b>rate</b>) vs specificity (<b>false</b> <b>positive</b> <b>rate</b>). The area under the curve is referred to as the AUC, and is a numeric ...", "dateLastCrawled": "2022-01-22T01:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>False</b>-<b>positive</b> results released by direct-to-consumer genetic tests ...", "url": "https://www.nature.com/articles/gim201838", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/gim201838", "snippet": "Both <b>false</b>-<b>positive</b> results and misclassification of variants <b>can</b> result in significant implications for an individual, including unnecessary stress, medical procedures (e.g., surgery, frequent ...", "dateLastCrawled": "2022-01-30T12:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Accuracy and reliability of forensic latent fingerprint decisions | <b>PNAS</b>", "url": "https://www.pnas.org/content/108/19/7733", "isFamilyFriendly": true, "displayUrl": "https://<b>www.pnas.org</b>/content/108/19/7733", "snippet": "The true negative <b>rate</b> was greater than the true <b>positive</b> <b>rate</b>. Much of this difference may be explained by three factors: The amount of information necessary for an exclusion decision is typically less than for an individualization decision, examiners operate within a culture where <b>false</b> positives are seen as more serious errors than <b>false</b> negatives (), and the mated pairs included a greater proportion of poor-quality prints than the nonmated pairs (SI Appendix, section 1.3).Whereas poor ...", "dateLastCrawled": "2022-02-03T05:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to Calculate Precision, Recall, and F-Measure for Imbalanced ...", "url": "https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/precision-recall-and-f-measure-for-", "snippet": "Consider a model that predicts 150 examples for the <b>positive</b> class, 95 are correct (true positives), meaning five were missed (<b>false</b> negatives) and 55 are <b>incorrect</b> (<b>false</b> positives). We <b>can</b> calculate the precision as follows: Precision = TruePositives / (TruePositives + FalsePositives) Precision = 95 / (95 + 55) Precision = 0.633", "dateLastCrawled": "2022-02-03T02:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Classification Accuracy is Not Enough: More Performance Measures You ...", "url": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/classification-accuracy-is-not-enough-", "snippet": "It is also called Sensitivity or the True <b>Positive</b> <b>Rate</b>. Recall <b>can</b> be thought of as a measure of a classifiers completeness. A low recall indicates many <b>False</b> Negatives. The recall of the All No Recurrence model is 0/(0+85) or 0. The recall of the All Recurrence model is 85/(85+0) or 1. The recall of CART is 10/(10+75) or 0.12. As you would expect, the All Recurrence model has a perfect recall because it predicts \u201crecurrence\u201d for all instances. The recall for CART is lower than that of ...", "dateLastCrawled": "2022-02-03T05:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Classification</b>", "url": "http://banner.tbr.edu/E11882_01/datamine.112/e16808/classify.htm", "isFamilyFriendly": true, "displayUrl": "banner.tbr.edu/E11882_01/datamine.112/e16808/classify.htm", "snippet": "Basically, lift <b>can</b> be understood as a ratio of two percentages: the <b>percentage</b> of correct <b>positive</b> <b>classifications</b> made by the model to the <b>percentage</b> of actual <b>positive</b> <b>classifications</b> in the test data. For example, if 40% of the customers in a marketing survey have responded favorably (the <b>positive</b> <b>classification</b>) to a promotional campaign in the past and the model accurately predicts 75% of them, the lift would be obtained by dividing .75 by .40. The resulting lift would be 1.875.", "dateLastCrawled": "2021-08-07T17:21:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning Accuracy</b>: True vs. <b>False</b> <b>Positive</b>/Negative", "url": "https://research.aimultiple.com/machine-learning-accuracy/", "isFamilyFriendly": true, "displayUrl": "https://research.aimultiple.com/<b>machine-learning-accuracy</b>", "snippet": "There are various theoretical approaches to measuring accuracy* of competing <b>machine</b> <b>learning</b> models however, in most commercial applications, you simply need to assign a business value to 4 types of results: true positives, true negatives, <b>false</b> positives and <b>false</b> negatives.By multiplying number of results in each bucket with the associated business values, you will ensure that you use the best model available.", "dateLastCrawled": "2022-02-03T04:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "It essentially shows the True <b>Positive</b> <b>Rate</b> (TPR) against the <b>False</b> <b>Positive</b> <b>Rate</b> (FPR) for various threshold values. AUC The Area Under the Curve (AUC), is an aggregated measure of performance of a binary classifier on all possible threshold values (and therefore it is threshold invariant). AUC calculates the area under the ROC curve, and therefore it is between 0 and 1. One way of interpreting AUC is the probability that the model ranks a random <b>positive</b> example more highly than a random ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning from positive</b> and unlabeled data: a survey - <b>Machine</b> <b>Learning</b>", "url": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-020-05877-5", "snippet": "The SCAR assumption was introduced in <b>analogy</b> with the Missing Completely A Random assumption (MCAR) that is common when ... the true <b>positive</b> <b>rate</b>, the <b>false</b> <b>positive</b> <b>rate</b>, and precision. Hence, it is possible in this circumstance to report estimates of these metrics. PU <b>learning</b> methods. This section provides an overview of the methods that address PU <b>learning</b>. Most methods can be divided into the following three categories: Two-step techniques, biased <b>learning</b> and class prior ...", "dateLastCrawled": "2022-02-02T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "The Receiver Operating Curve (ROC) and The Scale \u2014 Understanding ROC ...", "url": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the-scale-understanding-roc-through-an-analogy-8b8f9d954f84", "isFamilyFriendly": true, "displayUrl": "https://medium.com/data-science-everyday/the-receiver-operating-curve-roc-and-the...", "snippet": "The <b>rate</b> of True Positives is also called Sensitivity. Similarly, the <b>rate</b> of <b>False</b> Positives means counting the <b>False</b> Positives as part of the actual Negatives. In other words, represents the ...", "dateLastCrawled": "2021-02-13T00:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is the best example for <b>false negative, false positive, true</b> ...", "url": "https://www.quora.com/What-is-the-best-example-for-false-negative-false-positive-true-negative-and-true-positive-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-best-example-for-<b>false-negative-false-positive-true</b>...", "snippet": "Answer (1 of 6): There was a funny picture I\u2019d come across a while ago [1]: Extending this example, a man whose test results say \u201cNot pregnant\u201d is True Negative, and a pregnant woman whose test results say \u201cPregnant\u201d is True <b>Positive</b>. A good way to understand it is this: * First, define what...", "dateLastCrawled": "2022-01-22T02:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Evaluation Metric Special ROC-AUC Candra\u2019s blog", "url": "https://saltfarmer.github.io/blog/machine%20learning/Evaluation-Metrics-Special-ROCAUC/", "isFamilyFriendly": true, "displayUrl": "https://saltfarmer.github.io/blog/<b>machine</b> <b>learning</b>/Evaluation-Metrics-Special-ROCAUC", "snippet": "The ROC curve is created by plotting the true <b>positive</b> <b>rate</b> (TPR) against the <b>false</b> <b>positive</b> <b>rate</b> (FPR) at various threshold settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s ...", "dateLastCrawled": "2022-02-03T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b> for Drug <b>Discovery</b> in a Nutshell \u2014 Part I | by Stefan ...", "url": "https://medium.com/atomwise/machine-learning-for-drug-discovery-in-a-nutshell-part-i-24ae3f65c135", "isFamilyFriendly": true, "displayUrl": "https://medium.com/atomwise/<b>machine</b>-<b>learning</b>-for-drug-<b>discovery</b>-in-a-nutshell-part-i...", "snippet": "In <b>analogy</b> to that, virtual ... it is independent of the <b>positive</b> <b>rate</b> and has an intuitive probabilistic interpretation. Its drawback is that it is a classification measure \u2014 instead, we should ...", "dateLastCrawled": "2022-01-26T14:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Chi-squared tests to <b>compare two machine learning models and determine</b> ...", "url": "https://towardsdatascience.com/chi-squared-tests-to-compare-two-machine-learning-models-and-determine-whether-they-are-random-2a405fc55181", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/chi-squared-tests-to-compare-two-<b>machine</b>-<b>learning</b>...", "snippet": "Take T as the random variable describing the number of true <b>positive</b> instances (Heads by the coin <b>analogy</b>). Doesn\u2019t T follow a binomial distribution with p=0.65 (probability of <b>positive</b>) and n=69 (total data instances)? Sure it does. I assume you know that binomial distribution can be approximated from a normal distribution, provided both np and n(1-p) exceed 10. Accordingly, we get a normal variable z~N(0,1)", "dateLastCrawled": "2022-01-29T04:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>False</b> <b>Positive</b> and <b>False</b> Negative in Statistics | <b>365 Data Science</b>", "url": "https://365datascience.com/tutorials/statistics-tutorials/false-positive-vs-false-negative/", "isFamilyFriendly": true, "displayUrl": "https://<b>365datascience</b>.com/tutorials/statistics-tutorials/<b>false</b>-<b>positive</b>-vs-<b>false</b>-negative", "snippet": "So simply enough, a <b>false</b> <b>positive</b> would result in an innocent party being found guilty, while a <b>false</b> negative would produce an innocent verdict for a guilty person. If there is a lack of evidence, Accepting the null hypothesis much more likely to occur than rejecting it.", "dateLastCrawled": "2022-02-02T07:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine</b> <b>Learning</b> \u2014 Multiclass <b>Classification</b> with Imbalanced Dataset ...", "url": "https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-multiclass-<b>classification</b>-with...", "snippet": "The skewed distribution makes many conventional <b>machine</b> <b>learning</b> algorithms less effective, especially in predicting minority class examples. In order to do so, let us first understand the problem at hand and then discuss the ways to overcome those. Multiclass <b>Classification</b>: A <b>classification</b> task with more than two classes; e.g., classify a set of images of fruits which may be oranges, apples, or pears. Multi-class <b>classification</b> makes the assumption that each sample is assigned to one and ...", "dateLastCrawled": "2022-02-02T22:23:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Computer-aided Detection: The Impact of <b>Machine</b> <b>Learning</b> ...", "url": "https://www.researchgate.net/publication/220500492_Computer-aided_Detection_The_Impact_of_Machine_Learning_Classifier_and_Image_Feature_Selection_on_Scheme_Performance", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220500492_Computer-aided_Detection_The_Impact...", "snippet": "A support vector <b>machine</b> (SVM) uses a cons tructive <b>machine</b> <b>learning</b> process based on the statistical <b>learning</b> theory. Unlike A NN that minimizes the mean square er ror over the training dataset,", "dateLastCrawled": "2022-01-18T05:52:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(false positive rate)  is like +(percentage of incorrect classifications)", "+(false positive rate) is similar to +(percentage of incorrect classifications)", "+(false positive rate) can be thought of as +(percentage of incorrect classifications)", "+(false positive rate) can be compared to +(percentage of incorrect classifications)", "machine learning +(false positive rate AND analogy)", "machine learning +(\"false positive rate is like\")", "machine learning +(\"false positive rate is similar\")", "machine learning +(\"just as false positive rate\")", "machine learning +(\"false positive rate can be thought of as\")", "machine learning +(\"false positive rate can be compared to\")"]}