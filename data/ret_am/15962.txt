{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "<b>Learning</b> Curves in <b>Machine Learning</b>. Generally, a <b>learning</b> <b>curve</b> is a plot that shows time or experience on the x-axis and <b>learning</b> or improvement on the y-axis. <b>Learning</b> curves (LCs) are deemed effective tools for monitoring the performance of workers exposed to a <b>new</b> task. LCs provide a mathematical representation of the <b>learning</b> process that takes place as task repetition occurs. \u2014 <b>Learning</b> <b>curve</b> models and applications: Literature review and research directions, 2011. For example, if ...", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning curve vs training (loss) curve</b>? - <b>Cross Validated</b>", "url": "https://stats.stackexchange.com/questions/476339/learning-curve-vs-training-loss-curve", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/476339/<b>learning-curve-vs-training-loss-curve</b>", "snippet": "The <b>learning</b> <b>curve</b> gives you an idea of how the model benefits from being incrementally fed more and more data observations, therefore focusing on inputs external to the model, thereby quantifying the marginal benefit of each <b>new</b> data point.. The training <b>curve</b> gives you an idea of how the model benefits from having its bias-variance trade-off managed while cycling its algorithm back from start to finish repeatedly, therefore, focusing on processes or parameter calibration inputs internal to ...", "dateLastCrawled": "2022-02-03T01:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> <b>Curve</b> to identify <b>Overfitting</b> and Underfitting in <b>Machine</b> ...", "url": "https://towardsdatascience.com/learning-curve-to-identify-overfitting-underfitting-problems-133177f38df5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>learning</b>-<b>curve</b>-to-identify-<b>overfitting</b>-underfitting...", "snippet": "<b>Learning</b> curves plot the training and validation <b>loss</b> of a sample of training examples by incrementally adding <b>new</b> training examples. <b>Learning</b> curves help us in identifying whether adding additional training examples would improve the validation score (score on unseen data). If a model is overfit, then adding additional training examples might improve the model performance on unseen data. Similarly, if a model is underfit, then adding training examples doesn\u2019t help. \u2018<b>learning</b>_<b>curve</b> ...", "dateLastCrawled": "2022-02-03T01:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is a <b>Learning</b> <b>Curve</b> in <b>Machine</b> <b>Learning</b>? - Baeldung on Computer ...", "url": "https://www.baeldung.com/cs/learning-curve-ml", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/cs/<b>learning</b>-<b>curve</b>-ml", "snippet": "It requires lots of \u201cbabysitting\u201d; monitoring, data preparation, and experimentation, especially if it\u2019s a <b>new</b> project. In all that process, <b>learning</b> curves play a fundamental role. A <b>learning</b> <b>curve</b> is just a plot showing the progress over the experience of a specific metric related to <b>learning</b> during the training of a <b>machine</b> <b>learning</b> ...", "dateLastCrawled": "2022-02-03T06:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "neural network - <b>Loss &amp; accuracy - Are these reasonable learning curves</b> ...", "url": "https://stackoverflow.com/questions/47817424/loss-accuracy-are-these-reasonable-learning-curves", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/47817424", "snippet": "I am <b>learning</b> neural networks and I built a simple one in Keras for the iris dataset classification from the UCI <b>machine</b> <b>learning</b> repository. I used a one hidden layer network with a 8 hidden nodes. Adam optimizer is used with a <b>learning</b> rate of 0.0005 and is run for 200 Epochs. Softmax is used at the output with <b>loss</b> as catogorical-crossentropy. I am getting the following <b>learning</b> curves. As you can see, the <b>learning</b> <b>curve</b> for the accuracy has a lot of flat regions and I don&#39;t understand ...", "dateLastCrawled": "2022-01-28T04:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Learning</b> <b>Curve</b> Theory: Meaning, Formulas, Graphs", "url": "https://www.valamis.com/hub/learning-curve", "isFamilyFriendly": true, "displayUrl": "https://www.valamis.com/hub/<b>learning</b>-<b>curve</b>", "snippet": "An example of where a <b>learning</b> <b>curve</b> can be applied could be a measurable task <b>like</b> a factory worker <b>learning</b> to operate a <b>new</b> <b>machine</b> that requires specific, repeatable steps. As the worker learns to operate the <b>machine</b> following the procedural steps, he becomes faster and more proficient at using it. A <b>learning</b> <b>curve</b> would measure this rate of progression and mastery.", "dateLastCrawled": "2022-02-03T03:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Tune XGBoost Performance With Learning Curves</b>", "url": "https://machinelearningmastery.com/tune-xgboost-performance-with-learning-curves/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>tune-xgboost-performance-with-learning-curves</b>", "snippet": "The shape and dynamics of a <b>learning</b> <b>curve</b> can be used to diagnose the behavior of a <b>machine</b> <b>learning</b> model, and in turn, perhaps suggest the type of configuration changes that may be made to improve <b>learning</b> and/or performance. There are three common dynamics that you are likely to observe in <b>learning</b> curves; they are: Underfit. Overfit. Good Fit.", "dateLastCrawled": "2022-01-31T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Loss Functions in Machine Learning</b> | Working | Different Types", "url": "https://www.educba.com/loss-functions-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>loss-functions-in-machine-learning</b>", "snippet": "Types of <b>Loss Functions in Machine Learning</b>. Below are the different types of the <b>loss</b> function in <b>machine</b> <b>learning</b> which are as follows: 1. Regression <b>loss</b> functions. Linear regression is a fundamental concept of this function. Regression <b>loss</b> functions establish a linear relationship between a dependent variable (Y) and an independent variable (X); hence we try to fit the best line in space on these variables. Popular Course in this category. <b>Machine</b> <b>Learning</b> Training (19 Courses, 27 ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - <b>Noisy training loss</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/48579315/noisy-training-loss", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/48579315", "snippet": "I&#39;d <b>like</b> to understand what could be the reason of such shape of <b>loss</b> <b>curve</b>. <b>machine</b>-<b>learning</b> neural-network deep-<b>learning</b> tensorboard <b>loss</b>. Share . Follow asked Feb 2 &#39;18 at 9:14. DavidS1992 DavidS1992. 661 6 6 silver badges 16 16 bronze badges. 3. Too high <b>learning</b> rate ? \u2013 mxdbld. Feb 2 &#39;18 at 9:37. 2. The batch size is really small, try using 32 samples. The less samples in the batch size, the more importance is given to single samples, the more strong is the effect of outliers ...", "dateLastCrawled": "2022-02-03T02:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "is anyone familiar with such <b>loss</b> <b>curve</b> performance : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/shoip1/is_anyone_familiar_with_such_loss_curve/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/shoip1/is_anyone_familiar_with_such_<b>loss</b>_<b>curve</b>", "snippet": "Twitter is (Mostly) Garbage for <b>Learning</b> <b>Machine</b> <b>Learning</b>. There are a few good tweets which will pop up every once in a while <b>like</b> projects done by Google AI, but following topics <b>like</b> <b>Machine</b> <b>Learning</b> has just shown useless information from people who really know nothing about <b>machine</b> <b>learning</b>, data science, or anything related.", "dateLastCrawled": "2022-02-01T08:01:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a plot of model <b>learning</b> performance over experience or time. <b>Learning</b> curves are a widely used diagnostic tool in <b>machine learning</b> for algorithms that learn from a training dataset incrementally. The model can be evaluated on the training dataset and on a hold out validation dataset after each update during training and plots of the measured performance", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "neural network - <b>Loss &amp; accuracy - Are these reasonable learning curves</b> ...", "url": "https://stackoverflow.com/questions/47817424/loss-accuracy-are-these-reasonable-learning-curves", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/47817424", "snippet": "<b>Loss</b> and accuracy are different things; roughly speaking, the accuracy is what we are actually interested in from a business perspective, while the <b>loss</b> is the objective function that the <b>learning</b> algorithms (optimizers) are trying to minimize from a mathematical perspective. Even more roughly speaking, you can think of the <b>loss</b> as the &quot;translation&quot; of the business objective (accuracy) to the mathematical domain, a translation which is necessary in classification problems (in regression ones ...", "dateLastCrawled": "2022-01-28T04:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>machine</b> <b>learning</b> - Why training and validation <b>similar</b> <b>loss</b> curves lead ...", "url": "https://datascience.stackexchange.com/questions/31860/why-training-and-validation-similar-loss-curves-lead-to-poor-performance", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/31860", "snippet": "to prevent overfitting in a model the training <b>curve</b> in a <b>loss</b> graph should be <b>similar</b> to the validation <b>curve</b>. but in the current situation the third graph shows <b>curve</b> where validation <b>curve</b> <b>is similar</b> to training although the overall accuracy is low as compared to the <b>curve</b> where the two <b>curve</b> diverges in the above plot. WHy this is happening and what I am doing wrong in understanding these curves? <b>machine</b>-<b>learning</b> classification matlab. Share. Improve this question. Follow asked May 19 ...", "dateLastCrawled": "2022-01-20T17:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Tutorial: <b>Learning Curves for Machine Learning</b> in Python", "url": "https://www.dataquest.io/blog/learning-curves-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.dataquest.io/blog/<b>learning</b>-<b>curves</b>-<b>machine</b>-<b>learning</b>", "snippet": "If you\u2019re <b>new</b> to <b>machine</b> <b>learning</b> and have never tried scikit, a good place to start is this blog post. We begin with a brief introduction to bias and variance. The bias-variance trade-off . In supervised <b>learning</b>, we assume there\u2019s a real relationship between feature(s) and target and estimate this unknown relationship with a model. Provided the assumption is true, there really is a model, which we\u2019ll call \\(f\\), which describes perfectly the relationship between features and target ...", "dateLastCrawled": "2022-02-02T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "The <b>loss</b> <b>curve</b> and the average IoU <b>curve</b>, K = 9. | Download Scientific ...", "url": "https://www.researchgate.net/figure/The-loss-curve-and-the-average-IoU-curve-K-9_fig2_346942589", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/The-<b>loss</b>-<b>curve</b>-and-the-average-IoU-<b>curve</b>-K-9_fig2...", "snippet": "Download scientific diagram | The <b>loss</b> <b>curve</b> and the average IoU <b>curve</b>, K = 9. from publication: High precision detection algorithm based on improved RetinaNet for defect recognition of ...", "dateLastCrawled": "2021-11-02T17:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Diagnosing Model Performance with <b>Learning</b> Curves", "url": "https://rstudio-conf-2020.github.io/dl-keras-tf/notebooks/learning-curve-diagnostics.nb.html", "isFamilyFriendly": true, "displayUrl": "https://rstudio-conf-2020.github.io/dl-keras-tf/notebooks/<b>learning-curve</b>-diagnostics...", "snippet": "The shape and dynamics of a <b>learning curve</b> can be used to diagnose the behavior of a <b>machine</b> <b>learning</b> model and in turn perhaps suggest at the type of configuration changes that may be made to improve <b>learning</b> and/or performance. There are three common dynamics that you are likely to observe in <b>learning</b> curves: Underfit; Overfit; Optimal Fit; We will take a closer look at each with examples. The examples will assume that we are looking at a minimizing <b>loss</b> metric, meaning that smaller ...", "dateLastCrawled": "2022-01-29T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning</b> <b>Curve</b> Theory: Meaning, Formulas, Graphs", "url": "https://www.valamis.com/hub/learning-curve", "isFamilyFriendly": true, "displayUrl": "https://www.valamis.com/hub/<b>learning</b>-<b>curve</b>", "snippet": "An example of where a <b>learning</b> <b>curve</b> can be applied could be a measurable task like a factory worker <b>learning</b> to operate a <b>new</b> <b>machine</b> that requires specific, repeatable steps. As the worker learns to operate the <b>machine</b> following the procedural steps, he becomes faster and more proficient at using it. A <b>learning</b> <b>curve</b> would measure this rate of progression and mastery.", "dateLastCrawled": "2022-02-03T03:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Loss</b> and <b>Loss</b> <b>Functions for Training Deep Learning Neural Networks</b>", "url": "https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>loss</b>-and-<b>loss</b>-<b>functions-for-training-deep-learning</b>...", "snippet": "Neural networks are trained using stochastic gradient descent and require that you choose a <b>loss</b> function when designing and configuring your model. There are many <b>loss</b> functions to choose from and it can be challenging to know what to choose, or even what a <b>loss</b> function is and the role it plays when training a neural network. In this post, you will", "dateLastCrawled": "2022-02-02T20:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "neural networks - Explanation of <b>Spikes</b> in training <b>loss</b> vs. iterations ...", "url": "https://stats.stackexchange.com/questions/303857/explanation-of-spikes-in-training-loss-vs-iterations-with-adam-optimizer", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/303857/explanation-of-<b>spikes</b>-in-training...", "snippet": "I am training a neural network using i) SGD and ii) Adam Optimizer. When using normal SGD, I get a smooth training <b>loss</b> vs. iteration <b>curve</b> as seen below (the red one). However, when I used the Adam Optimizer, the training <b>loss</b> <b>curve</b> has some <b>spikes</b>.", "dateLastCrawled": "2022-01-27T23:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - What is the best way to smoothen out a <b>loss</b> <b>curve</b> ...", "url": "https://ai.stackexchange.com/questions/17360/what-is-the-best-way-to-smoothen-out-a-loss-curve-plot", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/.../what-is-the-best-way-to-smoothen-out-a-<b>loss</b>-<b>curve</b>-plot", "snippet": "This method is used in tensorbaord as a way to smoothen a <b>loss</b> <b>curve</b> plot. The algorithm is as follow: However there is a small problem doing it this way. As you can see S_t is initialized with the starting value, which makes the starting <b>curve</b> inaccurate. The green <b>curve</b> is the ideal <b>curve</b> for the algorithm, but the purple <b>curve</b> is the predicted <b>curve</b>. The <b>curve</b> is not correct on the start. To solve this, a correction factor is added in, thus making the algorithm this: This introduces ...", "dateLastCrawled": "2022-01-22T03:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a plot of model <b>learning</b> performance over experience or time. <b>Learning</b> curves are a widely used diagnostic tool in <b>machine learning</b> for algorithms that learn from a training dataset incrementally. The model <b>can</b> be evaluated on the training dataset and on a hold out validation dataset after each update during training and plots of the measured performance", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning</b> <b>Curve</b> Theory: Meaning, Formulas, Graphs", "url": "https://www.valamis.com/hub/learning-curve", "isFamilyFriendly": true, "displayUrl": "https://www.valamis.com/hub/<b>learning</b>-<b>curve</b>", "snippet": "An example of where a <b>learning</b> <b>curve</b> <b>can</b> be applied could be a measurable task like a factory worker <b>learning</b> to operate a <b>new</b> <b>machine</b> that requires specific, repeatable steps. As the worker learns to operate the <b>machine</b> following the procedural steps, he becomes faster and more proficient at using it. A <b>learning</b> <b>curve</b> would measure this rate of progression and mastery. The <b>learning</b> <b>curve</b> model is used most commonly in organizational or industrial management to improve output by way of ...", "dateLastCrawled": "2022-02-03T03:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How do I interpret my validation and training <b>loss</b> <b>curve</b> if there is a ...", "url": "https://stats.stackexchange.com/questions/335890/how-do-i-interpret-my-validation-and-training-loss-curve-if-there-is-a-large-dif", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/335890/how-do-i-interpret-my-validation-and...", "snippet": "I <b>thought</b> maybe its because my <b>learning</b> rate is too large, causing the training <b>loss</b> to plunge initially. I tried reducing <b>learning</b> rate. But doesn&#39;t change much. I <b>thought</b> maybe its due to initial overfitting and that I am \u201clucky\u201d to have the validation <b>loss</b> eventually find its way lower, so I tried adding dropouts to my model", "dateLastCrawled": "2022-01-22T00:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>machine</b> <b>learning</b> - What is the best way to smoothen out a <b>loss</b> <b>curve</b> ...", "url": "https://ai.stackexchange.com/questions/17360/what-is-the-best-way-to-smoothen-out-a-loss-curve-plot", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/.../what-is-the-best-way-to-smoothen-out-a-<b>loss</b>-<b>curve</b>-plot", "snippet": "This method is used in tensorbaord as a way to smoothen a <b>loss</b> <b>curve</b> plot. The algorithm is as follow: However there is a small problem doing it this way. As you <b>can</b> see S_t is initialized with the starting value, which makes the starting <b>curve</b> inaccurate. The green <b>curve</b> is the ideal <b>curve</b> for the algorithm, but the purple <b>curve</b> is the predicted <b>curve</b>. The <b>curve</b> is not correct on the start. To solve this, a correction factor is added in, thus making the algorithm this: This introduces ...", "dateLastCrawled": "2022-01-22T03:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "data mining - Help <b>Interpreting a Active Learning Learning</b> <b>Curve</b> - Data ...", "url": "https://datascience.stackexchange.com/questions/29972/help-interpreting-a-active-learning-learning-curve", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/29972", "snippet": "<b>Data Science Stack Exchange</b> is a question and answer site for Data science professionals, <b>Machine</b> <b>Learning</b> specialists, and those interested in <b>learning</b> more about the field. It only takes a minute to sign up. Sign up to join this community", "dateLastCrawled": "2022-01-20T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "python - What to make of a flat validation accuracy <b>curve</b> in a <b>learning</b> ...", "url": "https://stackoverflow.com/questions/64879731/what-to-make-of-a-flat-validation-accuracy-curve-in-a-learning-curve-graph", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/64879731", "snippet": "First of all, although your implementation seem correct, yet you should validate your implementation of the <b>learning</b>_<b>curve</b>.A quick way to do it is to compare it with the already-made <b>learning</b>_<b>curve</b> function by Scikit-Learn (side note: You don&#39;t need to reinvent the wheel, if I were you, I would have just used the one by Scikit-Learn).. Since you did not provide any data, I had to create some classification dataset.", "dateLastCrawled": "2022-01-06T03:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Regularization</b> in Deep <b>Learning</b> \u2014 L1, L2, and Dropout | Towards Data ...", "url": "https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>regularization</b>-in-deep-<b>learning</b>-l1-l2-and-dropout-377e...", "snippet": "In the next step we <b>can</b> compute the gradient of the <b>new</b> <b>loss</b> function and put the gradient into the update rule for the weights: Eq. 3 Gradient Descent during L2 <b>Regularization</b>. Some reformulations of the update rule lead to the expression which very much looks like the update rule for the weights during regular gradient descent: Eq.4 Gradient Descent during L2 <b>Regularization</b>. The only difference is that by adding the <b>regularization</b> term we introduce an additional subtraction from the ...", "dateLastCrawled": "2022-02-02T18:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "13. Newton\u2019s method is seldom used in <b>machine</b> <b>learning</b> because a. common <b>loss</b> functions are not self-concordant b. Newton\u2019s method does not work well on noisy data c. <b>machine</b> <b>learning</b> researchers don\u2019t really understand linear algebra d. it is generally not practical to form or store the Hessian in such problems, due to large problem size ...", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Overfitting</b> in Deep Neural Networks &amp; how to prevent it. | Analytics Vidhya", "url": "https://medium.com/analytics-vidhya/the-perfect-fit-for-a-dnn-596954c9ea39", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/the-perfect-fit-for-a-dnn-596954c9ea39", "snippet": "The primary objective in deep <b>learning</b> is to have a network that performs its best on both training data &amp; the test data/<b>new</b> data it hasn\u2019t seen before. However, in the case of <b>overfitting</b> &amp;\u2026", "dateLastCrawled": "2022-02-02T10:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - <b>Advantages</b> of ROC curves - Cross Validated", "url": "https://stats.stackexchange.com/questions/28745/advantages-of-roc-curves", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/28745", "snippet": "They seem to <b>be thought</b> of as obligatory by many statisticians and even more <b>machine</b> <b>learning</b> practitioners. And make sure your problem is really a classification problem and not a risk estimation problem. At the heart of problems with ROC curves is that they invite users to use cutpoints for continuous variables, and they use backwards probabilities, i.e., probabilities of events that are in reverse time order (sensitivity and specificity). ROC curves cannot be used to find optimum ...", "dateLastCrawled": "2022-02-03T03:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to use <b>Learning</b> Curves to Diagnose <b>Machine Learning</b> Model Performance", "url": "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>learning</b>-<b>curve</b>", "snippet": "A <b>learning</b> <b>curve</b> is a plot of model <b>learning</b> performance over experience or time. <b>Learning</b> curves are a widely used diagnostic tool in <b>machine learning</b> for algorithms that learn from a training dataset incrementally. The model <b>can</b> be evaluated on the training dataset and on a hold out validation dataset after each update during training and plots of the measured performance", "dateLastCrawled": "2022-02-03T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Learning</b> <b>Curve</b> to identify <b>Overfitting</b> and Underfitting in <b>Machine</b> ...", "url": "https://towardsdatascience.com/learning-curve-to-identify-overfitting-underfitting-problems-133177f38df5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>learning</b>-<b>curve</b>-to-identify-<b>overfitting</b>-underfitting...", "snippet": "Introduction <b>to learning</b> <b>curve</b>. <b>Learning</b> curves plot the training and validation <b>loss</b> of a sample of training examples by incrementally adding <b>new</b> training examples. <b>Learning</b> curves help us in identifying whether adding additional training examples would improve the validation score (score on unseen data). If a model is overfit, then adding ...", "dateLastCrawled": "2022-02-03T01:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Tutorial: <b>Learning Curves for Machine Learning</b> in Python", "url": "https://www.dataquest.io/blog/learning-curves-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.dataquest.io/blog/<b>learning</b>-<b>curves</b>-<b>machine</b>-<b>learning</b>", "snippet": "If you\u2019re <b>new</b> to <b>machine</b> <b>learning</b> and have never tried scikit, a good place to start is this blog post. We begin with a brief introduction to bias and variance. The bias-variance trade-off. In supervised <b>learning</b>, we assume there\u2019s a real relationship between feature(s) and target and estimate this unknown relationship with a model. Provided the assumption is true, there really is a model, which we\u2019ll call \\(f\\), which describes perfectly the relationship between features and target ...", "dateLastCrawled": "2022-02-02T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Importance of the shape of <b>loss</b> curves in deep <b>learning</b>", "url": "https://stats.stackexchange.com/questions/518887/importance-of-the-shape-of-loss-curves-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/518887/importance-of-the-shape-of-<b>loss</b>...", "snippet": "Based on the shape of the <b>loss</b> <b>curve</b> we <b>can</b> deduce certain properties e.g. is the <b>learning</b> rate too high/low, is the network too complex, is the dataset representative, etc. Given this information, we <b>can</b> then tweak our model. However, the question I struggle with is if we <b>can</b> say something about the performance of the model <b>compared</b> to others ...", "dateLastCrawled": "2022-01-25T23:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Diagnosing Model Performance with <b>Learning</b> Curves", "url": "https://rstudio-conf-2020.github.io/dl-keras-tf/notebooks/learning-curve-diagnostics.nb.html", "isFamilyFriendly": true, "displayUrl": "https://rstudio-conf-2020.github.io/dl-keras-tf/notebooks/<b>learning-curve</b>-diagnostics...", "snippet": "The shape and dynamics of a <b>learning curve</b> <b>can</b> be used to diagnose the behavior of a <b>machine</b> <b>learning</b> model and in turn perhaps suggest at the type of configuration changes that may be made to improve <b>learning</b> and/or performance. There are three common dynamics that you are likely to observe in <b>learning</b> curves: Underfit; Overfit; Optimal Fit; We will take a closer look at each with examples. The examples will assume that we are looking at a minimizing <b>loss</b> metric, meaning that smaller ...", "dateLastCrawled": "2022-01-29T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "CCF RESEARCH| Model Diagnostics with <b>Learning</b> Curves", "url": "https://www.ccfr.cz/en/model-diagnostics-with-learning-curves/", "isFamilyFriendly": true, "displayUrl": "https://www.ccfr.cz/en/model-diagnostics-with-<b>learning</b>-<b>curves</b>", "snippet": "The shape and dynamics of a <b>learning</b> <b>curve</b> <b>can</b> be used to diagnose the behavior of a <b>machine</b> <b>learning</b> model and in turn, perhaps suggest as the type of configuration changes. This option may be used to improve <b>learning</b> and/or performance. In general, we <b>can</b> observe 3 types of dynamics: Underfitting; Overfitting; Well-fitting. Diagnosing Unrepresentative Datasets. An unrepresentative dataset means a dataset that may not capture the statistical characteristics relative to another dataset drawn ...", "dateLastCrawled": "2022-01-26T05:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning</b> <b>Curve</b> Theory: Meaning, Formulas, Graphs", "url": "https://www.valamis.com/hub/learning-curve", "isFamilyFriendly": true, "displayUrl": "https://www.valamis.com/hub/<b>learning</b>-<b>curve</b>", "snippet": "An example of where a <b>learning</b> <b>curve</b> <b>can</b> be applied could be a measurable task like a factory worker <b>learning</b> to operate a <b>new</b> <b>machine</b> that requires specific, repeatable steps. As the worker learns to operate the <b>machine</b> following the procedural steps, he becomes faster and more proficient at using it. A <b>learning</b> <b>curve</b> would measure this rate of progression and mastery. The <b>learning</b> <b>curve</b> model is used most commonly in organizational or industrial management to improve output by way of ...", "dateLastCrawled": "2022-02-03T03:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Loss Functions in Machine Learning</b> | Working | Different Types", "url": "https://www.educba.com/loss-functions-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>loss-functions-in-machine-learning</b>", "snippet": "Types of <b>Loss Functions in Machine Learning</b>. Below are the different types of the <b>loss</b> function in <b>machine</b> <b>learning</b> which are as follows: 1. Regression <b>loss</b> functions. Linear regression is a fundamental concept of this function. Regression <b>loss</b> functions establish a linear relationship between a dependent variable (Y) and an independent variable (X); hence we try to fit the best line in space on these variables. Popular Course in this category. <b>Machine</b> <b>Learning</b> Training (19 Courses, 27 ...", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The accuracy and <b>loss</b> <b>curve</b> of the deep CNN model, (a) accuracy <b>curve</b> ...", "url": "https://www.researchgate.net/figure/The-accuracy-and-loss-curve-of-the-deep-CNN-model-a-accuracy-curve-b-loss-curve_fig2_335376232", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/The-accuracy-and-<b>loss</b>-<b>curve</b>-of-the-deep-CNN-model...", "snippet": "The accuracy and <b>loss</b> <b>curve</b> of the deep CNN model, (a) accuracy <b>curve</b>, (b) <b>loss</b> <b>curve</b>. Source publication Classification of Power Quality Disturbances Using Wigner-Ville Distribution and Deep ...", "dateLastCrawled": "2022-01-04T20:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How do I interpret my validation and training <b>loss</b> <b>curve</b> if there is a ...", "url": "https://stats.stackexchange.com/questions/335890/how-do-i-interpret-my-validation-and-training-loss-curve-if-there-is-a-large-dif", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/335890/how-do-i-interpret-my-validation-and...", "snippet": "Validation <b>loss</b> is indeed expected to decrease as the model learns and increase later as the model begins to overfit on the training set. One reason why your training and validation set behaves so different could be that they are indeed partitioned differently and the base distributions of the two are different.", "dateLastCrawled": "2022-01-22T00:01:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Learning to Teach with Dynamic Loss Functions</b>", "url": "https://proceedings.neurips.cc/paper/2018/file/8051a3c40561002834e59d566b7430cf-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2018/file/8051a3c40561002834e59d566b7430cf-Paper.pdf", "snippet": "<b>loss</b> function of a <b>machine</b> <b>learning</b> model (we call it student) is de\ufb01ned by another <b>machine</b> <b>learning</b> model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end, similar to human teaching, the teacher, a parametric model, dynamically outputs different <b>loss</b> functions that will be used and optimized by its student model at different training stages. We develop an ef\ufb01cient <b>learning</b> ...", "dateLastCrawled": "2022-01-26T01:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Estimate <b>dataset size</b> requirements using a <b>learning</b> <b>curve</b> graph ...", "url": "https://towardsdatascience.com/learning-curve-graphs-part-1-countering-the-data-requirement-curse-6bdeb7750edf", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>learning</b>-<b>curve</b>-graphs-part-1-countering-the-data...", "snippet": "Broadly speaking, most <b>machine</b> <b>learning</b> algorithms fall into one of two categories: linear models or non-linear models. Linear models are easy to interpret, faster to train and deploy, and don\u2019t require exorbitant amounts of compute resources. A linear model learns and produces a weighted sum of the inputs, plus a bias (intercept) term such that it maps a single input feature, X, to a single target, f(X).", "dateLastCrawled": "2022-02-03T03:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Introduction to <b>Machine</b> <b>Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-machine-learning-3/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/30/introduction-to-<b>machine</b>-<b>learning</b>-3", "snippet": "Required to assume shape of the model <b>curve</b> prior to perform model fitting on the data (for example, linear, polynomial, and so on). Does not need to assume underlying shape, as <b>machine</b> <b>learning</b> algorithms can learn complex patterns automatically based on the provided data. Statistical model predicts the output with accuracy of 85 percent and having 90 percent confidence about it. <b>Machine</b> <b>learning</b> just predicts the output with accuracy of 85 percent. In statistical modeling, various ...", "dateLastCrawled": "2022-01-28T18:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>learning</b> fundamentals (I): Cost functions and gradient descent ...", "url": "https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-fundamentals-via-linear-regression-41a...", "snippet": "In this post I\u2019ll use a simple linear regression model to explain two <b>machine</b> <b>learning</b> (ML) fundamentals; (1) cost functions and; (2) gradient descent. The linear regression isn\u2019t the most powerful model in the ML tool kit, but due to its familiarity and interpretability, it is still in widespread use in research and industry. Simply, linear regression is used to estimate linear relationships between continuous or/and categorical data and a continuous output variable \u2014 you can see an ...", "dateLastCrawled": "2022-01-30T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine Learning</b> <b>Evaluation Metrics</b> - GitHub Pages", "url": "https://kevalnagda.github.io/evaluation-metrics", "isFamilyFriendly": true, "displayUrl": "https://kevalnagda.github.io/<b>evaluation-metrics</b>", "snippet": "Introduction Evaluating your <b>machine learning</b> model is a crucial part of any project. Your model may give satisfactory results when evaluated using metrics such as accuracy but may perform poorly when evaluated against other metrics such as <b>loss</b> or F1 score. In most cases, we use accuracy to measure the model performance, however, it is not enough to truly judge our model. Thus, let\u2019s take a look at different <b>evaluation metrics</b> available. Confusion Matrix Confusion Matrix is a performance ...", "dateLastCrawled": "2021-10-13T19:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "PREDICTION OF RESEARCH TOPICS USING COMBINATION OF <b>MACHINE</b> <b>LEARNING</b> AND ...", "url": "http://www.jatit.org/volumes/Vol49No3/14Vol49No3.pdf", "isFamilyFriendly": true, "displayUrl": "www.jatit.org/volumes/Vol49No3/14Vol49No3.pdf", "snippet": "Extreme <b>Learning</b> <b>Machine</b> and Support Vector <b>Machine</b>. The prediction result is then finally refined by logistic <b>curve</b>. The dataset used in this study is a research report on Bioinformatics from Microsoft Research and NCBI (National Center for Biotechnology Information), over the past 30 years. Experimental result indicates that the combination of <b>machine</b> <b>learning</b> approaches and logistic-<b>curve</b> may improve the prediction accuracy. In addition, the emerging topic of the same dataset can be ...", "dateLastCrawled": "2021-11-21T16:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "B. <b>Analogy</b> C. Deduction D. Memorization Answer : A Explanation: Different <b>learning</b> methods does not include the introduction. 8. The model will be trained with data in one single batch is known as ? A. Batch <b>learning</b> B. Offline <b>learning</b> C. Both A and B D. None of the above Ans : C Explanation: we have end-to-end <b>Machine</b> <b>Learning</b> systems in which we need to train the model in one go by using whole available training data. Such kind of <b>learning</b> method or algorithm is called Batch or Offline ...", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "deep <b>learning</b> - How can both generator and discriminator losses ...", "url": "https://datascience.stackexchange.com/questions/32699/how-can-both-generator-and-discriminator-losses-decrease", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/32699", "snippet": "In the subsection of the figure, they compute the average <b>loss</b> across 100 iterations, which is why the <b>loss</b> is monotonically decreasing because on average the <b>loss</b> does decrease with the training. You are correct in inferring that if this was reported on an iteration to iteration basis, the <b>loss</b> would be a zig zag <b>curve</b>, which is less nice to look at than a smooth <b>curve</b>.", "dateLastCrawled": "2022-01-28T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Has anyone experience val <b>loss</b> curves like this? : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/s2h03q/has_anyone_experience_val_loss_curves_like_this/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/s2h03q/has_anyone_experience...", "snippet": "\ud83c\udfc3 Although a relatively simple optimization algorithm, gradient descent (and its variants) has found an irreplaceable place in the heart of <b>machine</b> <b>learning</b>. This is majorly due to the fact that it has shown itself to be quite handy when optimizing deep neural networks and other models. The models behind the latest advances in ML and computer vision are majorly optimized using gradient descent and its variants like Adam and gradient descent with momentum.", "dateLastCrawled": "2022-01-13T05:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>All Unit MCQ questions of ML</b> \u2013 TheCodingShef", "url": "https://thecodingshef.com/all-unit-mcq-questions-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://thecodingshef.com/<b>all-unit-mcq-questions-of</b>-<b>machine</b>-<b>learning</b>", "snippet": "A kind of supervised <b>learning</b>; Design of NN as <b>curve</b> fitting problem; Use of multidimensional surface to interpolate the test data; All of these Correct option is D. Application of CBR; Design; Planning; Diagnosis; All of these; Correct option is A. What is/are advantages of CBR? A local approx. is found for each test case; Knowledge is in a form understandable to human; Fast to train; All of these Correct option is D. 112 In k-NN algorithm, given a set of training examples and the value of ...", "dateLastCrawled": "2022-01-30T22:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "PINN deep <b>learning</b> method for the Chen\u2013Lee\u2013Liu equation: Rogue wave on ...", "url": "https://www.sciencedirect.com/science/article/pii/S1007570421003798", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1007570421003798", "snippet": "<b>Machine</b> <b>learning</b> with the neural network method ... Interestingly, from Fig. 5(d), we can observe that the <b>loss curve is like</b> \u201cstair\u201d, which does not exist in that one of periodic wave solution. 4.3. The data-driven soliton wave solution. As shown in Ref. , the expression (59) of Ref. will be the bright soliton solution with taking a = c = 1, \u03b2 = 0. 5, and be the dark soliton solution with taking a = c = 1, \u03b2 = \u2212 0. 5. Let [x 0, x 1] and [t 0, t 1] in Eq. as [\u2212 6. 0, 6. 0] and [\u2212 ...", "dateLastCrawled": "2022-01-17T00:12:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(loss curve)  is like +(learning curve of a new machine)", "+(loss curve) is similar to +(learning curve of a new machine)", "+(loss curve) can be thought of as +(learning curve of a new machine)", "+(loss curve) can be compared to +(learning curve of a new machine)", "machine learning +(loss curve AND analogy)", "machine learning +(\"loss curve is like\")", "machine learning +(\"loss curve is similar\")", "machine learning +(\"just as loss curve\")", "machine learning +(\"loss curve can be thought of as\")", "machine learning +(\"loss curve can be compared to\")"]}