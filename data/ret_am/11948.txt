{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>SUPERVISED</b> CLUSTERING: <b>ALGORITHMS</b> AND APPLICATIONS", "url": "https://www.uh.edu/nsm/_docs/cosc/technical-reports/2006/06_10.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>www.uh.edu</b>/nsm/_docs/cosc/technical-reports/2006/06_10.pdf", "snippet": "<b>supervised</b> clustering are significantly different from the fitness functions used by <b>traditional</b> clustering <b>algorithms</b>. <b>Supervised</b> clustering evaluates a clustering based on the following two criteria: \u2022 <b>Class</b> impurity, Impurity(X). This is measured by the percentage of <b>minority</b> examples in the different clusters of a clustering X. A <b>minority</b> ...", "dateLastCrawled": "2022-01-01T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Classification Algorithms for Imbalanced Datasets</b> - BLOCKGENI", "url": "https://blockgeni.com/classification-algorithms-for-imbalanced-datasets/", "isFamilyFriendly": true, "displayUrl": "https://blockgeni.com/<b>classification-algorithms-for-imbalanced-datasets</b>", "snippet": "Although not designed for these types of problems, one-<b>class</b> classification <b>algorithms</b> can be effective for imbalanced classification datasets where there are none or very few examples of the <b>minority</b> <b>class</b>, or datasets where there is no coherent structure to separate the classes that could be learned by a <b>supervised</b> algorithm. In this tutorial, you will discover how to use one-<b>class</b> classification <b>algorithms</b> for datasets with severely skewed <b>class</b> distributions. After completing this ...", "dateLastCrawled": "2022-02-02T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Rarity Problem in <b>Supervised</b> Fraud Detection", "url": "https://info.nice.com/rs/338-EJP-431/images/DS_Rarity%20Problem%20in%20Supervised%20Fraud%20Detection%20Insights%20Article_3JUNE20.pdf", "isFamilyFriendly": true, "displayUrl": "https://info.nice.com/rs/338-EJP-431/images/DS_Rarity Problem in <b>Supervised</b> Fraud...", "snippet": "<b>minority</b> <b>class</b> samples or, furthermore, treating them as noise. Building classification models from such imbalanced datasets is a relatively new challenge in the machine <b>learning</b> and data mining community because many <b>traditional</b> classification <b>algorithms</b> assume similar proportions of majority and <b>minority</b> classes. When the data is imbalanced, these <b>algorithms</b> generate models that achieve good classification accuracy for the majority <b>class</b>, but poor accuracy for the <b>minority</b> <b>class</b>. Such ...", "dateLastCrawled": "2021-09-01T20:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Supervised Clustering \u2013 Algorithms and Benefits</b>", "url": "http://www2.cs.uh.edu/~ceick/kdd/EZZ04.pdf", "isFamilyFriendly": true, "displayUrl": "www2.cs.uh.edu/~ceick/kdd/EZZ04.pdf", "snippet": "<b>class</b>. Moreover, in <b>supervised</b> clustering, we also <b>like</b> to keep the number of clusters small, and objects are assigned to clusters using a notion of closeness with respect to a given distance function. Fig. 1 illustrates the differences between <b>traditional</b> and <b>supervised</b> clustering. Let us assume that the black examples and the white examples in the figure represent subspecies of Iris plants named Setosa and Virginica, respectively. A <b>traditional</b> clustering algorithm would, very likely ...", "dateLastCrawled": "2022-02-01T01:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "2. Undersampling Techniques - Machine <b>Learning</b> Concepts", "url": "https://www.ml-concepts.com/2-undersampling-techniques/", "isFamilyFriendly": true, "displayUrl": "https://www.ml-concepts.com/2-undersampling-techniques", "snippet": "These <b>algorithms</b> are easy to understand and straightforward too. 1. EasyEnsemble: At first, it extracts several subsets of independent samples (with replacement) from the majority <b>class</b>. Then, it develops multiple classifiers based on the combination of each subset with the <b>minority</b> <b>class</b>. Informative undersampling \u2013 EasyEnsemble. As you see, it works just <b>like</b> an unsupervised <b>learning</b> algorithm. 2. BalanceCascade: It takes a <b>supervised</b> <b>learning</b> approach where it develops an ensemble of ...", "dateLastCrawled": "2022-01-15T11:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Pick and Choose: A GNN-based Imbalanced <b>Learning</b> Approach for Fraud ...", "url": "https://ponderly.github.io/pub/PCGNN_WWW2021.pdf", "isFamilyFriendly": true, "displayUrl": "https://ponderly.github.io/pub/PCGNN_WWW2021.pdf", "snippet": "<b>minority</b> <b>class</b> [5, 24], or under-sampling the majority <b>class</b> [32]. Re-weighting methods assign different weights to different classes or even different samples by cost-sensitive adjustments [4, 9, 19, 21] or meta-<b>learning</b> based methods [14, 35, 37]. While the <b>class</b> imbalanced <b>supervised</b> <b>learning</b> in <b>traditional</b> feature space is well-studied, graph neural network <b>algorithms</b> that exclusively study the <b>class</b> imbalance problem are underex-plored. DR-GCN [36] is a pioneer work to tackle the <b>class</b> ...", "dateLastCrawled": "2022-02-03T13:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to Calculate Precision, Recall, and F-Measure for Imbalanced ...", "url": "https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/precision-recall-and-f-measure-for-", "snippet": "Classification accuracy is the total number of correct predictions divided by the total number of predictions made for a dataset. As a performance measure, accuracy is inappropriate for imbalanced classification problems. The main reason is that the overwhelming number of examples from the majority <b>class</b> (or classes) will overwhelm the number of examples in the <b>minority</b> <b>class</b>, meaning that even unskillful models", "dateLastCrawled": "2022-02-03T02:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "170 Machine <b>Learning</b> Interview Question and Answers in 2022", "url": "https://www.mygreatlearning.com/blog/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>machine-learning-interview-questions</b>", "snippet": "If the <b>minority</b> <b>class</b> label\u2019s performance is not so good, we could do the following: We can use under sampling or over sampling to balance the data. We can change the prediction threshold value. We can assign weights to labels such that the <b>minority</b> <b>class</b> labels get larger weights. We could detect anomalies. 18. Explain the handling of missing or corrupted values in the given dataset. An easy way to handle missing values or corrupted values is to drop the corresponding rows or columns. If ...", "dateLastCrawled": "2022-02-03T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "GitHub - NanditaA/<b>ML-Supervised-Classification</b>: Using Machine <b>Learning</b> ...", "url": "https://github.com/NanditaA/ML-Supervised-Classification", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/NanditaA/<b>ML-Supervised-Classification</b>", "snippet": "This \u2018<b>traditional</b>\u2019 method of diagnosis can often be retrospective as recurrence events are picked up after symptoms reoccur leading to poorer outcomes.Surveillance methods <b>like</b> Mammography, PET, Breast MRI, Ultrasound are expensive and their efficacy is as yet clinically unproven via randomised controlled trials. Hence their use is reserved for symptomatic patients with highest risk of recurrence.", "dateLastCrawled": "2021-08-27T20:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Comparison of Different Machine Learning Algorithms for</b> the Prediction ...", "url": "https://www.scirp.org/journal/paperinformation.aspx?paperid=99402", "isFamilyFriendly": true, "displayUrl": "https://www.scirp.org/journal/paperinformation.aspx?paperid=99402", "snippet": "In 2017, Forssen systematically implemented and evaluated two <b>Supervised</b> <b>Learning</b> <b>Algorithms</b> used were Logistic Regression, Penalized Logistic Regression and Random Forest and compared them to <b>traditional</b> regression approaches for Coronary Artery Disease prediction. The data was collected from the Clinical Cohorts in Coronary disease Collaboration (4C) study containing 3409 number of recruited patients with acute or stable chest pain from four UK National Health Service (NHS) hospitals. In ...", "dateLastCrawled": "2022-01-26T04:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Rarity Problem in <b>Supervised</b> Fraud Detection", "url": "https://info.nice.com/rs/338-EJP-431/images/DS_Rarity%20Problem%20in%20Supervised%20Fraud%20Detection%20Insights%20Article_3JUNE20.pdf", "isFamilyFriendly": true, "displayUrl": "https://info.nice.com/rs/338-EJP-431/images/DS_Rarity Problem in <b>Supervised</b> Fraud...", "snippet": "<b>minority</b> <b>class</b> samples or, furthermore, treating them as noise. Building classification models from such imbalanced datasets is a relatively new challenge in the machine <b>learning</b> and data mining community because many <b>traditional</b> classification <b>algorithms</b> assume <b>similar</b> proportions of majority and <b>minority</b> classes. When the data is imbalanced, these <b>algorithms</b> generate models that achieve good classification accuracy for the majority <b>class</b>, but poor accuracy for the <b>minority</b> <b>class</b>. Such ...", "dateLastCrawled": "2021-09-01T20:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "An active <b>learning</b> based classification strategy for the <b>minority</b> <b>class</b> ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3284114/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3284114", "snippet": "We have combined AL with <b>class</b> balancing to yield a general training strategy applicable to most <b>supervised</b> classification problems where the dataset is expensive to obtain and which suffers from the <b>minority</b> <b>class</b> problem. An intelligent training strategy is a critical component of <b>supervised</b> classification, but the integration of AL and intelligent choice of <b>class</b> ratios, as well as the application of a general cost model, will help researchers to plan the training process more quickly and ...", "dateLastCrawled": "2021-09-28T18:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Pick and Choose: A GNN-based Imbalanced <b>Learning</b> Approach for Fraud ...", "url": "https://ponderly.github.io/pub/PCGNN_WWW2021.pdf", "isFamilyFriendly": true, "displayUrl": "https://ponderly.github.io/pub/PCGNN_WWW2021.pdf", "snippet": "<b>minority</b> <b>class</b> [5, 24], or under-sampling the majority <b>class</b> [32]. Re-weighting methods assign different weights to different classes or even different samples by cost-sensitive adjustments [4, 9, 19, 21] or meta-<b>learning</b> based methods [14, 35, 37]. While the <b>class</b> imbalanced <b>supervised</b> <b>learning</b> in <b>traditional</b> feature space is well-studied, graph neural network <b>algorithms</b> that exclusively study the <b>class</b> imbalance problem are underex-plored. DR-GCN [36] is a pioneer work to tackle the <b>class</b> ...", "dateLastCrawled": "2022-02-03T13:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A Partial Label Metric <b>Learning</b> Algorithm for <b>Class</b> Imbalanced Data", "url": "https://proceedings.mlr.press/v157/liu21f/liu21f.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.mlr.press/v157/liu21f/liu21f.pdf", "snippet": "balanced problem a ects the prediction accuracy of <b>minority</b> <b>class</b> samples, but the current partial label metric <b>learning</b> <b>algorithms</b> rarely consider the problem. In this paper, we pro- pose two partial label metric <b>learning</b> <b>algorithms</b> (PL-CCML-SFN and PL-CCML-LDD) that can solve the <b>class</b> imbalanced problem. The basic idea is to add a regularization term to the objective function of the PL-CCML model, which can induce each <b>class</b> to be uniformly distributed in the new metric space and thus ...", "dateLastCrawled": "2022-01-30T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Probability Density Machine: A New Solution of <b>Class</b> Imbalance <b>Learning</b>", "url": "https://www.hindawi.com/journals/sp/2021/7555587/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/sp/2021/7555587", "snippet": "As shown in Figure 1, the classification boundary has been obviously pushed toward the <b>minority</b> <b>class</b>, owing to the fact that is larger than . Considering the context of GNB, the classification boundary associates with the condition which can be equivalently expressed as; hence if, then it means only when, we can select the corresponding X as the classification boundary. Therefore, we can say that the negative impact of <b>class</b> imbalance for <b>traditional</b> <b>supervised</b> <b>learning</b> models only ...", "dateLastCrawled": "2021-12-03T22:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "ABC: Auxiliary Balanced Classifier for <b>Class</b>-imbalanced Semi-<b>supervised</b> ...", "url": "https://deepai.org/publication/abc-auxiliary-balanced-classifier-for-class-imbalanced-semi-supervised-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/abc-auxiliary-balanced-<b>class</b>ifier-for-<b>class</b>-imbalanced...", "snippet": "Existing semi-<b>supervised</b> <b>learning</b> (SSL) <b>algorithms</b> typically assume <b>class</b>-balanced datasets, although the <b>class</b> distributions of many real-world datasets are imbalanced. In general, classifiers trained on a <b>class</b>-imbalanced dataset are biased toward the majority classes. This issue becomes more problematic for SSL <b>algorithms</b> because they utilize the biased prediction of unlabeled data for training.", "dateLastCrawled": "2022-01-31T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Comparing Within- and Cross-Project Machine <b>Learning</b> <b>Algorithms</b> for ...", "url": "https://fabiano-pecorelli.github.io/publications/workshops/W4.pdf", "isFamilyFriendly": true, "displayUrl": "https://fabiano-pecorelli.github.io/publications/workshops/W4.pdf", "snippet": "<b>minority</b> <b>class</b> (i.e., smelly instances). In this paper, we propose a cross-project machine <b>learning</b> approach and compare its perfor-mance with a within-project alternative. The core idea is to use transfer <b>learning</b> to increase the overall number of smelly instances in the training datasets. Our results have shown that cross-project", "dateLastCrawled": "2022-02-03T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Machine <b>learning</b> in medicine: a practical introduction to natural ...", "url": "https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01347-1", "isFamilyFriendly": true, "displayUrl": "https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01347-1", "snippet": "Broadly, <b>supervised</b> machine <b>learning</b> <b>algorithms</b> fall into two categories: regression <b>algorithms</b> and classification <b>algorithms</b>. Regression <b>algorithms</b> aim to predict a continuous outcome (e.g., blood pressure or risk of death) while classification <b>algorithms</b> (or classifiers) aim to predict categorical outcomes (e.g., positive or negative, benign or malignant). It is worth noting that in ML, the term \u201cregression\u201d is used slightly differently <b>to traditional</b> statistics, where regression can ...", "dateLastCrawled": "2022-01-30T18:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>GitHub</b> - <b>Suraj-Patro/Fraud_Detection</b>: Implement an Ensemble Classifier ...", "url": "https://github.com/Suraj-Patro/Fraud_Detection", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>Suraj-Patro/Fraud_Detection</b>", "snippet": "The <b>minority</b> <b>class</b> is now much more prominently visible in our data. To see the results of SMOTE even better, we&#39;ll compare it to the original data in the next exercise. Compare SMOTE to original data. In the last exercise, you saw that using SMOTE suddenly gives us more observations of the <b>minority</b> <b>class</b>. Let&#39;s compare those results to our ...", "dateLastCrawled": "2021-10-16T15:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "170 Machine <b>Learning</b> Interview Question and Answers in 2022", "url": "https://www.mygreatlearning.com/blog/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>machine-learning-interview-questions</b>", "snippet": "Machine <b>Learning</b> for beginners will consist of the basic concepts such as types of Machine <b>Learning</b> (<b>Supervised</b>, Unsupervised, Reinforcement <b>Learning</b>). Each of these types of ML have different <b>algorithms</b> and libraries within them, such as, Classification and Regression. There are various classification <b>algorithms</b> and regression <b>algorithms</b> such as Linear Regression. This would be the first thing you will learn before moving ahead with other concepts.", "dateLastCrawled": "2022-02-03T05:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "CiteSeerX \u2014 SMOTE: Synthetic <b>Minority</b> Over-sampling Technique", "url": "https://citeseer.ist.psu.edu/viewdoc/citations?doi=10.1.1.18.5547", "isFamilyFriendly": true, "displayUrl": "https://citeseer.ist.psu.edu/viewdoc/citations?doi=10.1.1.18.5547", "snippet": "This paper also shows that a combination of our method of over-sampling the <b>minority</b> <b>class</b> and under-sampling the majority <b>class</b> <b>can</b> achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or <b>class</b> priors in Naive Bayes. Our method of over-sampling the <b>minority</b> <b>class</b> involves creating synthetic <b>minority</b> <b>class</b> ...", "dateLastCrawled": "2022-01-21T13:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Insider Threat Detection Using <b>Supervised</b> Machine <b>Learning</b> <b>Algorithms</b> ...", "url": "https://www.researchgate.net/publication/340357501_Insider_Threat_Detection_Using_Supervised_Machine_Learning_Algorithms_on_an_Extremely_Imbalanced_Dataset", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/340357501_Insider_Threat_Detection_Using...", "snippet": "This problem <b>can</b> affect of being difficult at obtaining a good predictive model for <b>minority</b> <b>class</b> dataset. The prediction accuracy generated will be good for majority <b>class</b> but not for <b>minority</b> ...", "dateLastCrawled": "2022-01-19T11:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Supervised</b> Classification <b>Algorithms</b> in Machine <b>Learning</b>: A Survey and ...", "url": "https://www.researchgate.net/publication/334521664_Supervised_Classification_Algorithms_in_Machine_Learning_A_Survey_and_Review", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334521664_<b>Supervised</b>_<b>Class</b>ification...", "snippet": "<b>ALGORITHMS</b> With the advent of Machine <b>Learning</b> [101] where automation modelling using data remains relevant, <b>traditional</b> <b>algorithms</b> [102][103] [104] used in solving SDN-IoT related task is unfeasible.", "dateLastCrawled": "2022-02-01T01:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "AWSMOTE: An SVM-Based <b>Adaptive Weighted SMOTE for Class-Imbalance Learning</b>", "url": "https://www.hindawi.com/journals/sp/2021/9947621/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/sp/2021/9947621", "snippet": "In <b>class</b>-imbalance <b>learning</b>, Synthetic <b>Minority</b> Oversampling Technique (SMOTE) is a widely used technique to tackle <b>class</b>-imbalance problems from the data level, whereas SMOTE blindly selects neighboring <b>minority</b> <b>class</b> points when performing an interpolation among them and inevitably brings collinearity between the generated new points and the original ones. To combat these problems, we propose in this study an adaptive-weighting SMOTE method, termed as AWSMOTE. AWSMOTE applies two types of ...", "dateLastCrawled": "2022-01-29T21:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "8 <b>Tactics to Combat Imbalanced Classes</b> in Your Machine <b>Learning</b> Dataset", "url": "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/tactics", "snippet": "There are systematic <b>algorithms</b> that you <b>can</b> use to generate synthetic samples. The most popular of such <b>algorithms</b> is called SMOTE or the Synthetic <b>Minority</b> Over-sampling Technique. As its name suggests, SMOTE is an oversampling method. It works by creating synthetic samples from the minor <b>class</b> instead of creating copies. The algorithm selects two or more similar instances (using a distance measure) and perturbing an instance one attribute at a time by a random amount within the difference", "dateLastCrawled": "2022-02-02T06:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Semi-<b>supervised</b> machine <b>learning</b> <b>with word embedding for classification</b> ...", "url": "https://www.cambridge.org/core/journals/data-and-policy/article/semisupervised-machine-learning-with-word-embedding-for-classification-in-price-statistics/F1FE2D347C28210B7C7D6C59B46D0C8F", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/data-and-policy/article/semi<b>supervised</b>-machine...", "snippet": "Label propagation is part of a group of semi-<b>supervised</b> ML <b>algorithms</b>. Given our limited pool of labeled data points, semi-<b>supervised</b> <b>learning</b> <b>can</b> use these known labels in the <b>learning</b> process to steer an unsupervised <b>learning</b> approach to label the rest of the data, hence semi-<b>supervised</b>. In this work, we make use of the label propagation and label spreading <b>algorithms</b> from the scikit-learn python library (Pedregosa et al., Reference Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel ...", "dateLastCrawled": "2021-12-30T21:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Cost-<b>Sensitive Learning for Imbalanced Classification</b>", "url": "https://machinelearningmastery.com/cost-sensitive-learning-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/cost-<b>sensitive-learning-for-imbalanced-classification</b>", "snippet": "Most machine <b>learning</b> <b>algorithms</b> assume that all misclassification errors made by a model are equal. This is often not the case for imbalanced classification problems where missing a positive or <b>minority</b> <b>class</b> case is worse than incorrectly classifying an example from the negative or majority <b>class</b>. There are many real-world examples, such as detecting spam email, diagnosing a medical condition, or", "dateLastCrawled": "2022-01-30T18:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Pedestrian Detection using HOGs in Python - simplest way - easy project ...", "url": "https://machinelearningprojects.net/pedestrian-detection-using-hog/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>projects.net/pedestrian-detection-using-hog", "snippet": "While <b>traditional</b> machine <b>learning</b> <b>algorithms</b> are linear, deep <b>learning</b> <b>algorithms</b> are stacked in a hierarchy of increasing complexity. Its name came from the fact that these networks are really very deep containing 10 or 20 or 30 or even more hidden layers of neurons. Dummy Variables. A dummy variable is a numerical variable used in regression analysis to represent different classes of a feature in your data. These are basically 0s and 1s. E EarlyStopping. Early stopping is a method that ...", "dateLastCrawled": "2022-01-26T22:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Dealing with the Lack of <b>Data</b> in <b>Machine Learning</b> | by Alexandre ...", "url": "https://medium.com/predict/dealing-with-the-lack-of-data-in-machine-learning-725f2abd2b92", "isFamilyFriendly": true, "displayUrl": "https://medium.com/predict/dealing-with-the-lack-of-<b>data</b>-in-<b>machine-learning</b>-725f2abd2b92", "snippet": "In general, different <b>machine learning</b> <b>algorithms</b> <b>can</b> be used to determine the missing values. This works by turning missing features to labels themselves and now using columns without missing ...", "dateLastCrawled": "2022-01-18T18:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to decide whether to use <b>supervised</b> machine <b>learning</b> or ...", "url": "https://www.quora.com/How-do-I-decide-whether-to-use-supervised-machine-learning-or-reinforcement-learning-models", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-do-I-decide-whether-to-use-<b>supervised</b>-machine-<b>learning</b>-or...", "snippet": "Answer (1 of 2): Although one could cast a <b>supervised</b> <b>learning</b> problem as a reinforcement <b>learning</b> problem, that is generally a bad idea, and you cannot always do the inverse. So generally speaking, the model you should use depends on which problem you\u2019re trying to solve: is it a <b>supervised</b> learn...", "dateLastCrawled": "2022-01-18T21:34:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "An active <b>learning</b> based classification strategy for the <b>minority</b> <b>class</b> ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3284114/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3284114", "snippet": "This yields high accuracy with a smaller training set size <b>compared</b> with random <b>learning</b> (RL). Previous AL methods have not explicitly accounted for the <b>minority</b> <b>class</b> problem in biomedical images. Pre-specifying a target <b>class</b> ratio mitigates the problem of training bias. Finally, we develop a mathematical model to predict the number of annotations (cost) required to achieve balanced training classes. In addition to predicting training cost, the model reveals the theoretical properties of ...", "dateLastCrawled": "2021-09-28T18:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Supervised Clustering \u2013 Algorithms and Benefits</b>", "url": "http://www2.cs.uh.edu/~ceick/kdd/EZZ04.pdf", "isFamilyFriendly": true, "displayUrl": "www2.cs.uh.edu/~ceick/kdd/EZZ04.pdf", "snippet": "<b>class</b>. Moreover, in <b>supervised</b> clustering, we also like to keep the number of clusters small, and objects are assigned to clusters using a notion of closeness with respect to a given distance function. Fig. 1 illustrates the differences between <b>traditional</b> and <b>supervised</b> clustering. Let us assume that the black examples and the white examples in the figure represent subspecies of Iris plants named Setosa and Virginica, respectively. A <b>traditional</b> clustering algorithm would, very likely ...", "dateLastCrawled": "2022-02-01T01:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Partial Label Metric <b>Learning</b> Algorithm for <b>Class</b> Imbalanced Data", "url": "https://proceedings.mlr.press/v157/liu21f/liu21f.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.mlr.press/v157/liu21f/liu21f.pdf", "snippet": "balanced problem a ects the prediction accuracy of <b>minority</b> <b>class</b> samples, but the current partial label metric <b>learning</b> <b>algorithms</b> rarely consider the problem. In this paper, we pro- pose two partial label metric <b>learning</b> <b>algorithms</b> (PL-CCML-SFN and PL-CCML-LDD) that <b>can</b> solve the <b>class</b> imbalanced problem. The basic idea is to add a regularization term to the objective function of the PL-CCML model, which <b>can</b> induce each <b>class</b> to be uniformly distributed in the new metric space and thus ...", "dateLastCrawled": "2022-01-30T16:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Comparison of Different Machine Learning Algorithms for</b> the Prediction ...", "url": "https://www.scirp.org/journal/paperinformation.aspx?paperid=99402", "isFamilyFriendly": true, "displayUrl": "https://www.scirp.org/journal/paperinformation.aspx?paperid=99402", "snippet": "In 2017, Forssen systematically implemented and evaluated two <b>Supervised</b> <b>Learning</b> <b>Algorithms</b> used were Logistic Regression, Penalized Logistic Regression and Random Forest and <b>compared</b> them <b>to traditional</b> regression approaches for Coronary Artery Disease prediction. The data was collected from the Clinical Cohorts in Coronary disease Collaboration (4C) study containing 3409 number of recruited patients with acute or stable chest pain from four UK National Health Service (NHS) hospitals. In ...", "dateLastCrawled": "2022-01-26T04:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Probability Density Machine: A New Solution of <b>Class</b> Imbalance <b>Learning</b>", "url": "https://www.hindawi.com/journals/sp/2021/7555587/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/sp/2021/7555587", "snippet": "As shown in Figure 1, the classification boundary has been obviously pushed toward the <b>minority</b> <b>class</b>, owing to the fact that is larger than . Considering the context of GNB, the classification boundary associates with the condition which <b>can</b> be equivalently expressed as; hence if, then it means only when, we <b>can</b> select the corresponding X as the classification boundary. Therefore, we <b>can</b> say that the negative impact of <b>class</b> imbalance for <b>traditional</b> <b>supervised</b> <b>learning</b> models only ...", "dateLastCrawled": "2021-12-03T22:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A comparison of <b>supervised</b> machine <b>learning</b> <b>algorithms</b> for mosquito ...", "url": "https://www.sciencedirect.com/science/article/pii/S1574954120300406", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1574954120300406", "snippet": "In this contribution, <b>supervised</b> machine <b>learning</b> <b>algorithms</b> such as Linear Discriminant Analysis, Decision Trees, Support Vector Machine, K-Nearest Neighbors and Na\u00efve Bayes are <b>compared</b> for the identification of mosquitoes through optical signals. Based on predictor variables derived from the wing beat frequency and optical cross section of mosquitoes, these <b>algorithms</b> were trained to perform different classification tasks: the identification of species, sex and/or gravidity of mosquitoes ...", "dateLastCrawled": "2022-01-24T09:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "ABC: Auxiliary Balanced Classifier for <b>Class</b>-imbalanced Semi-<b>supervised</b> ...", "url": "https://deepai.org/publication/abc-auxiliary-balanced-classifier-for-class-imbalanced-semi-supervised-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/abc-auxiliary-balanced-<b>class</b>ifier-for-<b>class</b>-imbalanced...", "snippet": "Existing semi-<b>supervised</b> <b>learning</b> (SSL) <b>algorithms</b> typically assume <b>class</b>-balanced datasets, although the <b>class</b> distributions of many real-world datasets are imbalanced. In general, classifiers trained on a <b>class</b>-imbalanced dataset are biased toward the majority classes. This issue becomes more problematic for SSL <b>algorithms</b> because they utilize the biased prediction of unlabeled data for training.", "dateLastCrawled": "2022-01-31T03:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "A Comparative Study of Machine <b>Learning</b> <b>Algorithms</b> in Predicting Severe ...", "url": "https://res.mdpi.com/d_attachment/jcm/jcm-08-00668/article_deploy/jcm-08-00668-v2.pdf", "isFamilyFriendly": true, "displayUrl": "https://res.mdpi.com/d_attachment/jcm/jcm-08-00668/article_deploy/jcm-08-00668-v2.pdf", "snippet": "for severe complication after bariatric surgery. Methods: We trained and <b>compared</b> 29 <b>supervised</b> ML <b>algorithms</b> using information from 37,811 patients that operated with a bariatric surgical procedure between 2010 and 2014 in Sweden. The <b>algorithms</b> were then tested on 6250 patients operated in 2015. We performed the synthetic <b>minority</b> oversampling technique tackling the issue that only 3% of patients experienced severe complications. Results: Most of the ML <b>algorithms</b> showed high accuracy (&gt;90 ...", "dateLastCrawled": "2021-11-22T16:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to Calculate Precision, Recall, and F-Measure for Imbalanced ...", "url": "https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machine<b>learning</b>mastery.com/precision-recall-and-f-measure-for-", "snippet": "In this way, recall provides some notion of the coverage of the positive <b>class</b>. For imbalanced <b>learning</b>, recall is typically used to measure the coverage of the <b>minority</b> <b>class</b>. \u2014 Page 27, Imbalanced <b>Learning</b>: Foundations, <b>Algorithms</b>, and Applications, 2013. Recall for Binary Classification", "dateLastCrawled": "2022-02-03T02:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "170 Machine <b>Learning</b> Interview Question and Answers in 2022", "url": "https://www.mygreatlearning.com/blog/machine-learning-interview-questions/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>machine-learning-interview-questions</b>", "snippet": "If the <b>minority</b> <b>class</b> label\u2019s performance is not so good, we could do the following: We <b>can</b> use under sampling or over sampling to balance the data. We <b>can</b> change the prediction threshold value. We <b>can</b> assign weights to labels such that the <b>minority</b> <b>class</b> labels get larger weights. We could detect anomalies. 18. Explain the handling of missing or corrupted values in the given dataset. An easy way to handle missing values or corrupted values is to drop the corresponding rows or columns. If ...", "dateLastCrawled": "2022-02-03T05:58:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> \u2014 Multiclass <b>Classification</b> with Imbalanced Dataset ...", "url": "https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine</b>-<b>learning</b>-multi<b>class</b>-<b>classification</b>-with...", "snippet": "The skewed distribution makes many conventional <b>machine</b> <b>learning</b> algorithms less effective, especially in predicting <b>minority</b> <b>class</b> examples. In order to do so, let us first understand the problem at hand and then discuss the ways to overcome those. Multiclass <b>Classification</b>: A <b>classification</b> task with more than two classes; e.g., classify a set of images of fruits which may be oranges, apples, or pears. Multi-<b>class</b> <b>classification</b> makes the assumption that each sample is assigned to one and ...", "dateLastCrawled": "2022-02-02T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Reliable and explainable machine-learning</b> methods for accelerated ...", "url": "https://www.nature.com/articles/s41524-019-0248-2", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41524-019-0248-2", "snippet": "However, in practice, correctly classifying and <b>learning</b> from the <b>minority</b> <b>class</b> of interest may be more important than possibly misclassifying the majority classes. Fig. 1", "dateLastCrawled": "2022-02-02T00:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Techniques to handle <b>class</b> imbalance using python", "url": "https://www.letthedataconfess.com/blog/2020/06/10/techniques-to-handle-class-imbalance/", "isFamilyFriendly": true, "displayUrl": "https://www.letthedataconfess.com/blog/2020/06/10/techniques-to-handle-<b>class</b>-imbalance", "snippet": "Cost Sensitive <b>Learning</b>. Another approach to deal with <b>class</b> imbalance is cost function is modified in such a way that penalty for misclassification of <b>minority</b> instances will be more. In the sklearn library, there is one argument \u201c<b>class</b> weight\u201d. Using this argument, we can penalize the <b>minority</b> <b>class</b> according to how much less proportion ...", "dateLastCrawled": "2022-01-27T15:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Evaluation of Supervised and Unsupervised <b>Machine</b> <b>Learning</b> Classifiers ...", "url": "https://link.springer.com/chapter/10.1007/978-3-030-74753-4_11", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-74753-4_11", "snippet": "We used Synthetic <b>Minority</b> Over-sampling Technique (SMOTE) for the upsampling of <b>minority</b> <b>class</b> and train the classifiers with a balanced dataset. The experiment results show that the balanced dataset reduces bias towards the majority <b>class</b> and increases the <b>machine</b> <b>learning</b> classifiers\u2019 accuracy. Using this approach, we successfully achieved higher accuracy for five <b>machine</b> <b>learning</b> algorithms with a low false-positive rate.", "dateLastCrawled": "2022-01-09T21:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A method for solving the <b>class</b> imbalance Problem in Classification ...", "url": "http://www.ijsrd.com/articles/IJSRDV2I4101.pdf", "isFamilyFriendly": true, "displayUrl": "www.ijsrd.com/articles/IJSRDV2I4101.pdf", "snippet": "attention in areas such as <b>Machine</b> <b>Learning</b> and Pattern Recognition. A two-<b>class</b> dataset is said to be imbalanced when one of the classes (the <b>minority</b> one) is heavily under- represented in comparison to the other <b>class</b> (the majority one) .The resulting model (classier) will Enable us to predict the outcome for new unseen examples. We describe the basic classification techniques. Several major kinds of classification method including Decision tree induction, Bayesian networks, K-nearest ...", "dateLastCrawled": "2022-01-11T06:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>machine</b> <b>learning</b> - <b>Logistic regression on biased data</b> - Data Science ...", "url": "https://datascience.stackexchange.com/questions/12234/logistic-regression-on-biased-data", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/12234", "snippet": "<b>machine</b>-<b>learning</b> r logistic-regression. Share. Improve this question. Follow asked Jun 16 &#39;16 at 12:54. Anonymint Anonymint. 155 2 2 ... (<b>analogy</b>, decision trees, bagging, Bayesian). Finally... Unbalanced Classes. There are two typical methods for dealing with unbalanced classes. These include oversampling the <b>minority</b> <b>class</b>, and fixing the model by altering the hyperplane (SVM) or changing priors (Bayes). There are lots of summaries of this problem and solution if you search for &quot;unbalanced ...", "dateLastCrawled": "2022-02-01T17:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Values and inductive risk in <b>machine</b> <b>learning</b> modelling: the case of ...", "url": "https://link.springer.com/article/10.1007/s13194-021-00405-1", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13194-021-00405-1", "snippet": "For instance, in medical applications, patients having cancer constitute the <b>minority</b> <b>class</b> in a given population, while those not having cancer constitutes the majority <b>class</b>. The cost of a false negative, i.e., misclassifying a cancer case as non-cancer, has a much higher cost than a false positive, i.e., misclassifying a non-cancer case as cancer. This is because the former case might result in the delay of the treatment of the case, which is a life-threatening situation, while the former ...", "dateLastCrawled": "2022-01-04T15:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "From <b>imbalanced</b> datasets to boosting algorithms | by Linda Chen ...", "url": "https://towardsdatascience.com/from-imbalanced-dataset-to-boosting-algorithms-1-2-798cd6384ecc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/from-<b>imbalanced</b>-dataset-to-boosting-algorithms-1-2-798...", "snippet": "Tools Overview. Downsampling: randomly select some points from the majority <b>class</b> and delete them. Upsampling: randomly select a point from the <b>minority</b> <b>class</b>, copy and paste it to make a new point. Repeat the process until you have the same amount of samples as the majority <b>class</b>. SMOTE: it creates more samples in the <b>minority</b> <b>class</b>. However, not by replicating the existing data points but by creating new points within the range of possibility.", "dateLastCrawled": "2022-01-28T07:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - When should I balance classes in a training data set ...", "url": "https://stats.stackexchange.com/questions/227088/when-should-i-balance-classes-in-a-training-data-set", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/227088", "snippet": "The <b>class</b> imbalance problem is caused by there not being enough patterns belonging to the <b>minority</b> <b>class</b>, not by the ratio of positive and negative patterns itself per se. Generally if you have enough data, the &quot;<b>class</b> imbalance problem&quot; doesn&#39;t arise. As a conclusion, artificial balancing is rarely useful if training set is large enough.", "dateLastCrawled": "2022-01-28T03:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "In <b>machine learning, what\u2019s the purpose of splitting data up</b> into test ...", "url": "https://www.quora.com/In-machine-learning-what-s-the-purpose-of-splitting-data-up-into-test-sets-and-training-sets", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-<b>machine-learning-what-s-the-purpose-of-splitting-data-up</b>-into...", "snippet": "Answer (1 of 13): Naturally, the concept of train, validation, and test influences the way you should process your data as you are getting ready for training and deployment of your computer vision model. Preprocessing steps are image transformations that are used to standardize your dataset acro...", "dateLastCrawled": "2022-01-26T16:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Prediction of Web Service Anti-patterns Using Aggregate Software ...", "url": "https://www.researchgate.net/publication/340138873_Prediction_of_Web_Service_Anti-patterns_Using_Aggregate_Software_Metrics_and_Machine_Learning_Techniques", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/340138873_Prediction_of_Web_Service_Anti...", "snippet": "Prediction of Web Service Anti-pa erns Using Aggregate So ware Metrics and <b>Machine</b> <b>Learning</b> T echniques ISEC 2020, February 27\u201329, 2020, Jabalpur, India the metrics respectively. Figure 3, 6 and ...", "dateLastCrawled": "2021-11-27T20:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs</b> ...", "url": "https://deepai.org/publication/evolvegcn-evolving-graph-convolutional-networks-for-dynamic-graphs", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>evolvegcn-evolving-graph-convolutional-networks-for</b>...", "snippet": "Code Repositories EvolveGCN. Code for <b>EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs</b>. view repo AMLSim. The AMLSim project is intended to provide a multi-agent based simulator that generates synthetic banking transaction data together with a set of known money laundering patterns - mainly for the purpose of testing <b>machine</b> <b>learning</b> models and graph algorithms.", "dateLastCrawled": "2022-01-31T23:44:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(minority class)  is like +(traditional supervised learning algorithms)", "+(minority class) is similar to +(traditional supervised learning algorithms)", "+(minority class) can be thought of as +(traditional supervised learning algorithms)", "+(minority class) can be compared to +(traditional supervised learning algorithms)", "machine learning +(minority class AND analogy)", "machine learning +(\"minority class is like\")", "machine learning +(\"minority class is similar\")", "machine learning +(\"just as minority class\")", "machine learning +(\"minority class can be thought of as\")", "machine learning +(\"minority class can be compared to\")"]}