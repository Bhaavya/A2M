{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse</b> Matrix Libraries for C++: A Tour", "url": "http://jefftrull.github.io/c++/eigen/csparse/suitesparse/2017/02/10/a-tour-of-sparse-matrices-for-cplusplus.html", "isFamilyFriendly": true, "displayUrl": "jefftrull.github.io/c++/eigen/c<b>sparse</b>/suite<b>sparse</b>/2017/02/10/a-tour-of-<b>sparse</b>-matrices...", "snippet": "<b>Sparse</b> Matrix Libraries for C++: A Tour. Feb 10, 2017. In my last post I described my ideal <b>sparse</b> matrix <b>library</b>. In this post I\u2019ll demonstrate the use of some real life libraries. The Test Case. In days past I was a VLSI circuit designer, and later, an EDA software engineer. On-chip electrical circuits are naturally represented as <b>sparse</b> ...", "dateLastCrawled": "2022-02-03T05:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "SparseX: A <b>Library</b> for High-Performance <b>Sparse</b> Matrix-<b>Vector</b> ...", "url": "https://people.csail.mit.edu/jshun/6886-s19/lectures/lecture19-2.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.csail.mit.edu/jshun/6886-s19/lectures/lecture19-2.pdf", "snippet": "SparseX: A <b>Library</b> for High-Performance <b>Sparse</b> Matrix-<b>Vector</b> Multiplication on Multicore Platforms Athena Elafrou, VasileiosKarakasis, TheodorosGkountouvas, Kornilios Kourtis, Georgios Goumasand NectariosKoziris Presenter: Rawn Henry April 25 2019", "dateLastCrawled": "2022-01-04T03:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Implementing <b>Sparse</b> <b>Vector</b> in <b>Java</b> - GeeksforGeeks", "url": "https://www.geeksforgeeks.org/implementing-sparse-vector-in-java/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/implementing-<b>sparse</b>-<b>vector</b>-in-<b>java</b>", "snippet": "<b>Like</b> Article. Implementing <b>Sparse</b> <b>Vector</b> in <b>Java</b>. Difficulty Level : Hard; Last Updated : 02 Dec, 2020. A <b>vector</b> or arraylist is a one-dimensional array of elements. The elements of a <b>Sparse</b> <b>Vector</b> have mostly zero values. It is inefficient to use a one-dimensional array to store a <b>sparse</b> <b>vector</b>. It is also inefficient to add elements whose values are zero in forming sums of <b>sparse</b> vectors. We convert the one-dimensional <b>vector</b> to a <b>vector</b> of (index, value) pairs. Examples Input: Enter size ...", "dateLastCrawled": "2022-01-30T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>sparse matrix</b> <b>library</b> for C++ - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/17241227/sparse-matrix-library-for-c", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/17241227", "snippet": "What are the most widely used C++ <b>vector</b>/matrix math/linear algebra libraries, and their cost and benefit tradeoffs? If you recommend, please tell me the advantages and disadvantages of it, and the reason why you recommend it. When it comes to large-scale <b>sparse</b> stuff, I personally use the Harwell Subroutine <b>library</b>. It&#39;s written in Fortran and ...", "dateLastCrawled": "2022-01-19T20:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "arrays - <b>unboxing, (sparse) matrices, and haskell vector library</b> ...", "url": "https://stackoverflow.com/questions/2737961/unboxing-sparse-matrices-and-haskell-vector-library", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/2737961", "snippet": "I would <b>like</b> to manipulate matrices (full or <b>sparse</b>) efficiently with haskell&#39;s <b>vector</b> <b>library</b>. Here is a matrix type. import qualified Data.<b>Vector</b>.Unboxed as U import qualified Data.<b>Vector</b> as V data Link a = Full (V.<b>Vector</b> (U.<b>Vector</b> a)) | <b>Sparse</b> (V.<b>Vector</b> (U.<b>Vector</b> (Int,a))) type <b>Vector</b> a = U.<b>Vector</b> a", "dateLastCrawled": "2022-01-17T01:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Library</b> for Parallel <b>Sparse</b> Matrix <b>Vector</b> Multiplies", "url": "http://www.cs.bilkent.edu.tr/tech-reports/2005/BU-CE-0506.pdf", "isFamilyFriendly": true, "displayUrl": "www.cs.bilkent.edu.tr/tech-reports/2005/BU-CE-0506.pdf", "snippet": "A <b>Library</b> for Parallel <b>Sparse</b> Matrix <b>Vector</b> ... <b>like</b> operation is referred to here as expand operation. 2.2 Column-parallel algorithm Consider matrix-<b>vector</b> multiply of the form y \u2190Ax, where y and x are col-umn vectors of size m and n, respectively, and the matrix A is partitioned columnwise. The columnwise partition of matrix A de\ufb01nes a partition on the input <b>vector</b> x. The output <b>vector</b> y is assumed to be partitioned conformably with the row permutation of matrix A. In particular, y and ...", "dateLastCrawled": "2022-01-24T12:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "sprs - A <b>sparse</b> matrix <b>library</b>", "url": "https://reposhub.com/rust/data-structures/vbarrielle-sprs.html", "isFamilyFriendly": true, "displayUrl": "https://reposhub.com/rust/data-structures/vbarrielle-sprs.html", "snippet": "sprs, <b>sparse</b> matrices for Rust. sprs implements some <b>sparse</b> matrix data structures and linear algebra algorithms in pure Rust. The API is a work in progress, and feedback on its rough edges is highly appreciated :)", "dateLastCrawled": "2022-01-08T23:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Benchmark of C++ Libraries for <b>Sparse</b> Matrix Computation", "url": "http://grh.mur.at/sites/default/files/SparseLibraryBenchmark.pdf", "isFamilyFriendly": true, "displayUrl": "grh.mur.at/sites/default/files/<b>SparseLibrary</b>Benchmark.pdf", "snippet": "(neural network <b>like</b> operations) and should therefore not be seen as a general benchmark of these libraries. In particular I benchmarked a (<b>sparse</b>) matrix-<b>vector</b> multiplication (see2.2), a neural network <b>like</b> operation (see2.3) and the initialization time of the <b>sparse</b> matrix (see 2.1). Results to these examples can be found in section3. A more ...", "dateLastCrawled": "2021-09-04T00:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "dlib C++ <b>Library</b> - svm_<b>sparse</b>_ex.cpp", "url": "http://www.dlib.net/svm_sparse_ex.cpp.html", "isFamilyFriendly": true, "displayUrl": "www.dlib.net/svm_<b>sparse</b>_ex.cpp.html", "snippet": "See LICENSE_FOR_EXAMPLE_PROGRAMS.txt /* This is an example showing how to use <b>sparse</b> feature vectors with the dlib C++ <b>library</b>&#39;s machine learning tools. This example creates a simple binary classification problem and shows you how to train a support <b>vector</b> machine on that data. The data used in this example will be 100 dimensional data and will come from a simple linearly separable distribution. */ #include &lt;iostream&gt; #include &lt;ctime&gt; #include &lt;<b>vector</b>&gt; #include &lt;dlib/svm.h&gt; using namespace ...", "dateLastCrawled": "2021-12-27T17:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>cuSPARSE</b> :: CUDA Toolkit Documentation", "url": "https://docs.nvidia.com/cuda/cusparse/index.html", "isFamilyFriendly": true, "displayUrl": "https://docs.nvidia.com/cuda/<b>cusparse</b>", "snippet": "The <b>cuSPARSE</b> <b>library</b> supports dense and <b>sparse</b> <b>vector</b>, and dense and <b>sparse</b> matrix formats. 3.1. Index Base Format. The <b>library</b> supports zero- and one-based indexing. The index base is selected through the cusparseIndexBase_t type, which is passed as a standalone parameter or as a field in the matrix descriptor cusparseMatDescr_t type. 3.1.1. <b>Vector</b> Formats. This section describes dense and <b>sparse</b> <b>vector</b> formats. 3.1.1.1. Dense Format. Dense vectors are represented with a single data array ...", "dateLastCrawled": "2022-02-03T05:38:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>sparse_vector</b> \u00b7 PyPI", "url": "https://pypi.org/project/sparse_vector/", "isFamilyFriendly": true, "displayUrl": "https://pypi.org/project/<b>sparse_vector</b>", "snippet": "A <b>sparse vector</b> is a 1D numerical list where most (say, more than 95% of) values will be 0 (or some other default) and for reasons of memory efficiency you don\u2019t wish to store these. (cf. <b>Sparse</b> array) This implementation has a <b>similar</b> interface to Python\u2019s 1D numpy.ndarray but stores the values and indices in linked lists to preserve memory. <b>sparse_vector</b> is for numerical data only, if you want any type of data, have a look at <b>sparse</b>_list, the parent <b>library</b>, a dictionary-of-keys ...", "dateLastCrawled": "2022-01-27T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>cuSPARSE</b> :: CUDA Toolkit Documentation", "url": "https://docs.nvidia.com/cuda/cusparse/index.html", "isFamilyFriendly": true, "displayUrl": "https://docs.nvidia.com/cuda/<b>cusparse</b>", "snippet": "The <b>cuSPARSE</b> <b>library</b> supports dense and <b>sparse</b> <b>vector</b>, and dense and <b>sparse</b> matrix formats. 3.1. Index Base Format. The <b>library</b> supports zero- and one-based indexing. The index base is selected through the cusparseIndexBase_t type, which is passed as a standalone parameter or as a field in the matrix descriptor cusparseMatDescr_t type. 3.1.1. <b>Vector</b> Formats. This section describes dense and <b>sparse</b> <b>vector</b> formats. 3.1.1.1. Dense Format. Dense vectors are represented with a single data array ...", "dateLastCrawled": "2022-02-03T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Calculating Text Similarity With <b>Gensim</b> | by Riley Huang | Better ...", "url": "https://betterprogramming.pub/introduction-to-gensim-calculating-text-similarity-9e8b55de342d", "isFamilyFriendly": true, "displayUrl": "https://betterprogramming.pub/introduction-to-<b>gensim</b>-calculating-text-<b>similar</b>ity-9e8b...", "snippet": "If the vectors in the two documents are <b>similar</b>, the documents must be <b>similar</b> too. <b>Sparse</b> <b>Vector</b>. Documents in <b>Gensim</b> are represented by <b>sparse</b> vectors. <b>Gensim</b> omits all vectors with value 0.0, and each <b>vector</b> is a pair of (feature_id, feature_value). Model. A Model can be thought of as a transformation from one <b>vector</b> space to another. By ...", "dateLastCrawled": "2022-01-30T03:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>SPARSEKIT</b> - <b>Sparse</b> Matrix Utility Package", "url": "https://people.math.sc.edu/Burkardt/f_src/sparsekit/sparsekit.html", "isFamilyFriendly": true, "displayUrl": "https://people.math.sc.edu/Burkardt/f_src/<b>sparsekit</b>/<b>sparsekit</b>.html", "snippet": "<b>SPARSEKIT</b> is a FORTRAN90 <b>library</b> which carries out a number of operations on <b>sparse</b> matrices, particularly conversion between various <b>sparse</b> formats.. <b>SPARSEKIT</b> can manipulate <b>sparse</b> matrices in a variety of formats, and can convert from one to another. For example, a matrix can be converted from the generalized diagonal format used by ELLPACK and ITPACK to the format used by the Harwell-Boeing <b>Sparse</b> Matrix Collection or into LINPACK banded format.", "dateLastCrawled": "2022-01-08T09:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "OSKI: A <b>library of automatically tuned sparse matrix kernels</b>", "url": "https://bebop.cs.berkeley.edu/pubs/jop2005-SciDAC-OSKI.pdf", "isFamilyFriendly": true, "displayUrl": "https://bebop.cs.berkeley.edu/pubs/jop2005-SciDAC-OSKI.pdf", "snippet": "The kernels include <b>sparse</b> matrix-<b>vector</b> multiply (SpMV) and <b>sparse</b> triangular solve (SpTS), among others; \u201ctuning\u201d refers to the process of selecting the data structure and code transformations that lead to the fastest implementation of a kernel, given a machine and matrix. While conventional implementations of SpMV have historically run at 10% of machine peak or less, careful tuning can achieve up to 31% of peak and 4\u00d7speedups [1, Chap. 1]. The challenge is that we must often defer ...", "dateLastCrawled": "2021-09-17T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>GitHub</b> - PASSIONLab/CombBLAS: The Combinatorial BLAS (CombBLAS) is an ...", "url": "https://github.com/PASSIONLab/CombBLAS", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/PASSIONLab/CombBLAS", "snippet": "<b>Sparse</b> and dense vectors are distributed along all processors. This is very space efficient and provides good load balance for SpMSV (<b>sparse</b> matrix-<b>sparse</b> <b>vector</b> multiplication). New since version 1.6: Connected components in distributed memory, found in Applications/CC.h [15,16], compile with &quot;make cc&quot; in that folder. Usage self explanatory ...", "dateLastCrawled": "2022-01-25T19:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A <b>Sparse</b> Matrix <b>Library</b> in C++ for High P", "url": "http://www.netlib.org/lapack/lawnspdf/lawn74.pdf", "isFamilyFriendly": true, "displayUrl": "www.netlib.org/lapack/lawnspdf/lawn74.pdf", "snippet": "ted C++ <b>library</b> for <b>sparse</b> matrix com-putations whic h pro vides a uni ed in terface for v ar-ious iterativ e solution tec hniques across a v ariet yof <b>sparse</b> data formats. The design of the <b>library</b> is based on the follo wing principles: Clarit y: Implemen tations of n umerical algorithms should resem ble the mathematical algorithms on whic h they are based. This is in con trast to F or-h can require complicated subrou-tine calls, often with parameter lists that stretc h o v er sev eral ...", "dateLastCrawled": "2022-02-02T13:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>What is the best numerical library c</b>/c++ - ResearchGate", "url": "https://www.researchgate.net/post/What-is-the-best-numerical-library-c-c", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/<b>What-is-the-best-numerical-library-c</b>-c", "snippet": "The syntax (API) <b>is similar</b> to MATLAB. Blaze is an open-source, high-performance C++ math <b>library</b> for dense and <b>sparse</b> arithmetic. Blitz++ is a high-performance <b>vector</b> mathematics <b>library</b> written ...", "dateLastCrawled": "2022-02-02T16:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>An Introduction to SuanShu</b> | Baeldung", "url": "https://www.baeldung.com/suanshu", "isFamilyFriendly": true, "displayUrl": "https://www.baeldung.com/suanshu", "snippet": "The implementation of a dense <b>vector</b> simply uses a Java array of real/complex numbers while the implementation of a <b>sparse</b> <b>vector</b> uses a Java array of entries, where each entry has an index and a real/complex value.. We can see how that would make a huge difference in storage when we have a large <b>vector</b> where most values are zero. Most mathematical libraries use an approach like this when they need to support vectors of large sizes.", "dateLastCrawled": "2022-02-02T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Sparse</b> representation based direction-of-arrival ... - Wiley Online <b>Library</b>", "url": "https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/rsn2.12086", "isFamilyFriendly": true, "displayUrl": "https://ietresearch.online<b>library</b>.wiley.com/doi/full/10.1049/rsn2.12086", "snippet": "p \u223c = [p \u223c 1, p \u223c 2, \u2026, p \u223c K] T \u2208 C K \u00d7 1 is a <b>sparse</b> <b>vector</b> with L non-zero coefficients. K is the number of columns of the over-complete dictionary and \u03b7 is a user-defined constant related to the estimation accuracy of the covariance matrix R \u02c6 .", "dateLastCrawled": "2022-01-31T21:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Sparse</b> Matrix-Vektor multiplikation: Bandwidth Compression doesn&#39;t have ...", "url": "https://community.intel.com/t5/Intel-oneAPI-Math-Kernel-Library/Sparse-Matrix-Vektor-multiplikation-Bandwidth-Compression-doesn/m-p/1301541", "isFamilyFriendly": true, "displayUrl": "https://community.intel.com/t5/Intel-oneAPI-Math-Kernel-<b>Library</b>/<b>Sparse</b>-Matrix-Vektor...", "snippet": "I am performing a <b>sparse</b> matrix <b>vector</b> multiplication and <b>thought</b> it might be beneficial to reduce the bandwidth of the matrix, such that fewer loading operations must be performed. I implemented the bandwidth compression via similarity transformation that uses the permutation matrices generated through the Cuthill McKee algorithm from the boost <b>library</b>.", "dateLastCrawled": "2021-12-03T01:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "e04nqc (qpconvex2_ <b>sparse</b>_ solve) : NAG <b>Library</b> CL Interface, Mark 27", "url": "https://www.nag.com/numeric/nl/nagdoc_latest/clhtml/e04/e04nqc.html", "isFamilyFriendly": true, "displayUrl": "https://www.nag.com/numeric/nl/nagdoc_latest/clhtml/e04/e04nqc.html", "snippet": "Storing c as part of A is recommended if c is a <b>sparse</b> <b>vector</b>. Storing c as an explicit <b>vector</b> is recommended for a sequence of problems, each with a different objective (see arguments c and lenc). The upper and lower bounds on the m elements of A x are said to define the general constraints of the problem. Internally, e04nqc converts the general constraints to equalities by introducing a set of slack variables s, where s = (s 1, s 2, \u2026, s m) T. For example, the linear constraint 5 \u2264 2 x ...", "dateLastCrawled": "2022-01-12T04:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Dense and <b>Sparse</b> Matrices \u2014 CVXOPT User&#39;s Guide", "url": "http://abel.ee.ucla.edu/cvxopt/userguide/matrices.html", "isFamilyFriendly": true, "displayUrl": "abel.ee.ucla.edu/cvxopt/userguide/matrices.html", "snippet": "A general spmatrix object <b>can</b> <b>be thought</b> of as a triplet description of a <b>sparse</b> matrix, i.e., a list of entries of the matrix, with for each entry the value, row index, and column index. Entries that are not included in the list are assumed to be zero. For example, the <b>sparse</b> matrix . has the triplet description. The list may include entries with a zero value, so triplet descriptions are not necessarily unique. The list. is another triplet description of the same matrix. An spmatrix object ...", "dateLastCrawled": "2022-01-23T11:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "nag_opt_<b>sparse</b>_convex_qp (e04nkc) : NAG <b>Library</b>, Mark 26", "url": "https://www.nag.com/numeric/cl/nagdoc_cl26/html/e04/e04nkc.html", "isFamilyFriendly": true, "displayUrl": "https://www.nag.com/numeric/cl/nagdoc_cl26/html/e04/e04nkc.html", "snippet": "NAG <b>Library</b> Function Document nag_opt_<b>sparse</b>_convex_qp (e04nkc) ... the bounds on A x and x <b>can</b> simply <b>be thought</b> of as bounds on the combined <b>vector</b> x, s. (In order to indicate their special role in QP problems, the original variables x are sometimes known as \u2018column variables\u2019, and the slack variables s are known as \u2018row variables\u2019.) Each LP or QP problem is solved using an active-set method. This is an iterative procedure with two phases: a feasibility phase, in which the sum of ...", "dateLastCrawled": "2021-12-28T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Extract elements from a <b>vector</b> using a <b>sparse</b> matrix in R without ...", "url": "https://stackoverflow.com/questions/54331067/extract-elements-from-a-vector-using-a-sparse-matrix-in-r-without-converting-to", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/54331067", "snippet": "I would like to extract all the elements from <b>vector</b> x1 where the ith column exists in a <b>sparse</b> matrix. I need all of the <b>sparse</b> elements removed, but the results should live line-by-line in their ...", "dateLastCrawled": "2022-01-17T23:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "NAG <b>Library</b> Function Document nag opt nlp <b>sparse</b> (e04ugc)", "url": "https://www.originlab.com/pdfs/nagcl09/manual/pdf/e04/e04ugc.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.originlab.com/pdfs/nagcl09/manual/pdf/e04/e04ugc.pdf", "snippet": "The problem de\ufb01ned by (1) <b>can</b> therefore be re-written in the following equivalent form: minimize x2Rn;s2Rm fx\u00f0\u00de subject to Fx\u00f0\u00de Gx s \u00bc 0, l x s u. \u00f02\u00de Since the slack variables s are subject to the same upper and lower bounds as the elements of F and Gx, the bounds on F and Gx <b>can</b> simply <b>be thought</b> of as bounds on the combined <b>vector</b> ...", "dateLastCrawled": "2022-01-27T03:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>GitHub</b> - <b>clMathLibraries/clSPARSE</b>: a software <b>library</b> containing <b>Sparse</b> ...", "url": "https://github.com/clMathLibraries/clSPARSE", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/clMathLibraries/cl<b>SPARSE</b>", "snippet": "A great deal of <b>thought</b> and effort went into designing the API\u2019s to make them less \u2018cluttered\u2019 compared to the older clMath libraries. OpenCL state is not explicitly passed through the API, which enables the <b>library</b> to be forward compatible when users are ready to switch from OpenCL 1.2 to OpenCL 2.0 3. Google Groups", "dateLastCrawled": "2022-02-03T17:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fast Sparse ConvNets</b> - CVF Open Access", "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Elsen_Fast_Sparse_ConvNets_CVPR_2020_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Elsen_<b>Fast_Sparse_ConvNets</b>_CVPR...", "snippet": "<b>can</b> <b>be thought</b> of as a hand-crafted sparsi\ufb01cation of full convolutions with a prede\ufb01ned <b>sparse</b> topology, and which are responsible for the parameter ef\ufb01ciency of these archi- tectures. MobileNet v1 (MBv1) used layers of 1\u00d71convo-lutions followed by depthwise convolutions. MobileNet v2 (MBv2) introduced the inverted residual block which con-sists of a 1\u00d7 1convolution expanding the channel count, a depthwise convolution on the expanded channel count, and then a 1\u00d71convolution reducing ...", "dateLastCrawled": "2022-02-02T12:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "dlib C++ <b>Library</b> - svm_struct_ex.cpp", "url": "http://www.dlib.net/svm_struct_ex.cpp.html", "isFamilyFriendly": true, "displayUrl": "www.dlib.net/svm_struct_ex.cpp.html", "snippet": "At a high level, a structural SVM <b>can</b> <b>be thought</b> of as searching the parameter space of F(x,y) for the set of parameters that make the following inequality true as often as possible: F(x_i,y_i) &gt; max{over all incorrect labels of x_i} F(x_i, y_incorrect) That is, it seeks to find the parameter <b>vector</b> such that F(x,y) always gives the highest score to the correct output. To define the structural SVM optimization problem precisely, we first introduce some notation: - let PSI(x,y) == the joint ...", "dateLastCrawled": "2021-11-02T00:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Vector</b> in Eigen <b>Library</b> is indeed much faster \u00b7 Issue #197 \u00b7 husky-team ...", "url": "https://github.com/husky-team/husky/issues/197", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/husky-team/husky/issues/197", "snippet": "This set of APIs should only be used when the input <b>sparse</b> vectors are sorted ascendingly according to the feature number. kygx-legend assigned Kelvin-Ng on Jan 23, 2017. Kelvin-Ng added a commit to Kelvin-Ng/husky that referenced this issue on Jan 24, 2017. [Lib] Add some infrastructure for using Eigen <b>library</b>. 0035846. Issue husky-team#197.", "dateLastCrawled": "2021-08-16T14:43:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Picasso : A <b>Sparse</b> Learning <b>Library</b> for High Dimensional Data Analysis ...", "url": "https://mran.microsoft.com/snapshot/2021-09-12/web/packages/picasso/vignettes/vignette.pdf", "isFamilyFriendly": true, "displayUrl": "https://mran.microsoft.com/snapshot/2021-09-12/web/packages/picasso/vignettes/vignette.pdf", "snippet": "To demonstrate the superior e ciency of our <b>library</b>, we compare picasso with a popular R <b>library</b> ncvreg (version 3.9.1) for nonconvex regularized <b>sparse</b> regression, the most popular Rlibrary glmnet (version 2.0-13) for convex regularized <b>sparse</b> regression, and two Rlibraries scalreg-v1.0 and flare-v1.5.0 for scaled <b>sparse</b> linear regression. All ...", "dateLastCrawled": "2022-01-30T14:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Computing the <b>sparse</b> matrix <b>vector</b> product using block-based kernels ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7924463/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7924463", "snippet": "While the gain of using a <b>sparse</b> matrix instead of a dense one <b>can</b> be huge in terms of memory occupancy and speed, the effective Flop rate of a <b>sparse</b> kernel generally remains low <b>compared</b> to its dense counterpart. In fact, in a <b>sparse</b> matrix storage, we provide a way to know the respective column and row of each non-zero value (NNZ). Therefore, the general SpMV is a bandwidth/memory bound operation because it pays the price of this extra storage and leads to a low ratio of", "dateLastCrawled": "2021-12-20T03:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A <b>Library for Pattern-based Sparse Matrix Vector Multiply</b>", "url": "https://eprints.cs.vt.edu/archive/00001103/01/PBR_Technical_Report.pdf", "isFamilyFriendly": true, "displayUrl": "https://eprints.cs.vt.edu/archive/00001103/01/PBR_Technical_Report.pdf", "snippet": "A <b>Library for Pattern-based Sparse Matrix Vector Multiply</b> Mehmet Belgin Godmar Back Calvin J. Ribbens December 30, 2009 Abstract Pattern-based Representation (PBR) is a novel approach to improving the performance of <b>Sparse</b> Matrix-<b>Vector</b> Multiply (SMVM) numerical kernels. Motivated by our observation that many matrices <b>can</b> be divided into blocks that share a small number of distinct patterns, we generate custom multipli-cation kernels for frequently recurring block patterns. The resulting ...", "dateLastCrawled": "2021-11-06T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Sparse</b> Matrices - <b>Sparse</b> Vectors and Matrices - <b>Vector</b> and Matrix ...", "url": "https://www.extremeoptimization.com/Documentation/Vector-and-Matrix/Sparse-Vectors-and-Matrices/Sparse-Matrices.aspx", "isFamilyFriendly": true, "displayUrl": "https://www.extremeoptimization.com/Documentation/<b>Vector</b>-and-Matrix/<b>Sparse</b>-<b>Vectors</b>-and...", "snippet": "Several common formats exist to exchange <b>sparse</b> matrices between applications. The Matrix Market format was inspired by the Matrix Market, an online repository of <b>sparse</b> test matrices and problems.You <b>can</b> import Matrix Market files into <b>sparse</b> matrices using the MatrixMarketFile class. This class has one static method, ReadMatrix, which has three overloads.Each of these takes one argument.", "dateLastCrawled": "2022-01-30T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Sparse</b> VAR (sparsevar) - The Comprehensive R Archive Network", "url": "https://cran.r-project.org/web/packages/sparsevar/readme/README.html", "isFamilyFriendly": true, "displayUrl": "https://<b>cran.r-project.org</b>/web/packages/<b>sparse</b>var/readme/README.html", "snippet": "<b>library</b> (sparsevar) Using the function included in the package, we simply generate a 20x20 VAR(2) process. set.seed (1) sim &lt;-simulateVAR (N = 20, p = 2) This command will generate a model with two <b>sparse</b> matrices with 5% of non-zero entries and a Toeplitz variance-covariance matrix with rho = 0.5. We <b>can</b> estimate the matrices of the process using for example. fit &lt;-fitVAR (sim $ series, p = 2, threshold = TRUE) The results <b>can</b> be seen by plotting the two var objects. plotVAR (sim, fit) the ...", "dateLastCrawled": "2022-01-28T16:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Sparse Matrix</b>-<b>Vector</b> Multiplication with CUDA | by Georgii Evtushenko ...", "url": "https://medium.com/analytics-vidhya/sparse-matrix-vector-multiplication-with-cuda-42d191878e8f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>sparse-matrix</b>-<b>vector</b>-multiplication-with-cuda-42d...", "snippet": "To answer the question how naive described implementation really is I\u2019ve <b>compared</b> it with the NVIDIA CUDA <b>Sparse Matrix</b> <b>library</b> (cuSPARSE) CSR implementation (tab. 2), which has a better average ...", "dateLastCrawled": "2022-01-28T17:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) FastSpMM: An efficient <b>library</b> for <b>sparse</b> matrix matrix product ...", "url": "https://www.researchgate.net/publication/236658267_FastSpMM_An_efficient_library_for_sparse_matrix_matrix_product_on_GPUs", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/236658267_FastSpMM_An_efficient_<b>library</b>_for...", "snippet": "Algorithm 1 Pseudocode of SSFastSpMM to compute SpMM on GPUs. It computes the product C L c = AB L c where A is <b>sparse</b>. matrix of dimensions N \u00d7 M, B L c and C L c are dense matrices of ...", "dateLastCrawled": "2021-12-19T08:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Is sparse matrix-vector multiplication faster</b> in Matlab than in Python ...", "url": "https://stackoverflow.com/questions/45516690/is-sparse-matrix-vector-multiplication-faster-in-matlab-than-in-python", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/45516690", "snippet": "Edit 2: I read here that &quot;For <b>sparse</b> matrices, all level 2 [BLAS] operations except for the <b>sparse</b> triangular solvers are threaded&quot; in the Intel MKL. This suggests to me that scipy is not using Intel MKL to perform <b>sparse</b> matrix-<b>vector</b> multiplication. It seems that @hpaulj (in an answer posted below) has confirmed this conclusion by inspecting the code for the function csr_matvec.", "dateLastCrawled": "2022-01-23T12:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Any <b>Sparse</b> Linear Algebra package in Haskell? - Stack Overflow", "url": "https://stackoverflow.com/questions/3995323/any-sparse-linear-algebra-package-in-haskell", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/3995323", "snippet": "A study of <b>sparse</b> matrix representations for solving linear systems in a functional language. J. Functional Programming, 2(1):61-72, Jan. 1992. , where they <b>compared</b> Quad-tree, Binary tree and run-length encoding <b>sparse</b> matrix representations in Miranda. Quad-trees were superiour on the CG method, and run-length encoding did well with SOR. There was an implementation of the FEM in Haskell in 1993, Some issues in a functional implementation of a finite element algorithm. They used quad-trees ...", "dateLastCrawled": "2022-01-25T09:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>GitHub</b> - <b>clMathLibraries/clSPARSE</b>: a software <b>library</b> containing <b>Sparse</b> ...", "url": "https://github.com/clMathLibraries/clSPARSE", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/clMathLibraries/cl<b>SPARSE</b>", "snippet": "A great deal of thought and effort went into designing the API\u2019s to make them less \u2018cluttered\u2019 <b>compared</b> to the older clMath libraries. OpenCL state is not explicitly passed through the API, which enables the <b>library</b> to be forward compatible when users are ready to switch from OpenCL 1.2 to OpenCL 2.0 3. Google Groups", "dateLastCrawled": "2022-02-03T17:48:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Gentle Introduction to Vectors for <b>Machine</b> <b>Learning</b>", "url": "https://machinelearningmastery.com/gentle-introduction-vectors-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>vectors</b>-<b>machine</b>-<b>learning</b>", "snippet": "It is common to introduce vectors using a geometric <b>analogy</b>, where a <b>vector</b> represents a point or coordinate in an n-dimensional space, where n is the number of dimensions, such as 2. The <b>vector</b> can also be thought of as a line from the origin of the <b>vector</b> space with a direction and a magnitude. These analogies are good as a starting point, but should not be held too tightly as we often consider very high dimensional vectors in <b>machine</b> <b>learning</b>. I find the <b>vector</b>-as-coordinate the most ...", "dateLastCrawled": "2022-02-01T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "TensorFlow is an interface for expressing <b>machine</b> <b>learning</b> algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PPT) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> | Colleen Farrelly - Academia.edu", "url": "https://www.academia.edu/30404581/Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/30404581/<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> Colleen M. Farrelly Overview of Problem Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics ...", "dateLastCrawled": "2022-01-02T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Word Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond king - man ...", "url": "https://aclanthology.org/C16-1332.pdf", "isFamilyFriendly": true, "displayUrl": "https://aclanthology.org/C16-1332.pdf", "snippet": "Word Embeddings, Analogies, and <b>Machine</b> <b>Learning</b>: Beyond King - Man + Woman = Queen Aleksandr Drozd y, Anna Gladkova z, Satoshi Matsuoka y yTokyo Institute of Technology, Meguro-ku, Tokyo 152-8550, Japan alex@smg.is.titech.ac.jp, matsu@is.titech.ac.jp z The University of Tokyo, Meguro-ku, Tokyo 153-8902 Japan gladkova@phiz.c.u-tokyo.ac.jp Abstract Solving word analogies became one of the most popular benchmarks for word embeddings on the assumption that linear relations between word pairs ...", "dateLastCrawled": "2022-01-20T00:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Introduction to Matrices and Matrix Arithmetic for <b>Machine Learning</b>", "url": "https://machinelearningmastery.com/introduction-matrices-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/introduction-matrices-<b>machine-learning</b>", "snippet": "The geometric <b>analogy</b> used to help understand vectors and some of their operations does not hold with matrices. Further, a <b>vector</b> itself may be considered a matrix with one column and multiple rows. Often the dimensions of the matrix are denoted as m and n for the number of rows and the number of columns. Now that we know what a matrix is, let\u2019s look at defining one in Python. Defining a Matrix. We can represent a matrix in Python using a two-dimensional NumPy array. A NumPy array can be ...", "dateLastCrawled": "2022-02-02T11:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning :: Cosine Similarity for Vector</b> Space Models (Part III ...", "url": "https://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/", "isFamilyFriendly": true, "displayUrl": "https://blog.christianperone.com/2013/09/<b>machine</b>-<b>learning</b>-", "snippet": "<b>Machine Learning :: Cosine Similarity for Vector</b> Space Models (Part III) 12/09/2013 19/01/2020 Christian S. Perone <b>Machine</b> <b>Learning</b> , Programming , Python * It has been a long time since I wrote the TF-IDF tutorial ( Part I and Part II ) and as I promissed, here is the continuation of the tutorial.", "dateLastCrawled": "2022-01-29T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Word Embedding: Syntactics or Semantics</b> \u00b7 Shengbin&#39;s Studio", "url": "https://wushbin.github.io/2017/10/09/Word-Embedding-Syntactics-or-Semantics/", "isFamilyFriendly": true, "displayUrl": "https://wushbin.github.io/2017/10/09/<b>Word-Embedding-Syntactics-or-Semantics</b>", "snippet": "From all the result of the two method, we know that the dense <b>vector</b> method get a better result than the <b>sparse</b> PPMI method in <b>analogy</b> analysis and similar word search. In addition, the computational efficiency of the dense <b>vector</b> is also better than the PPMI. Short vectors may be easier to use as features in <b>machine</b> <b>learning</b>. Dense vectors may generalize better than storing explicit counts. In addition, dense vectors may perform better in capturing synonymy than <b>sparse</b> vectors.", "dateLastCrawled": "2022-01-09T18:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Word Embeddings in NLP - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/word-embeddings-in-nlp/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/word-embeddings-in-nlp", "snippet": "Word Embeddings are a method of extracting features out of text so that we can input those features into a <b>machine</b> <b>learning</b> model to work with text data. They try to preserve syntactical and semantic information. The methods such as Bag of Words(BOW), CountVectorizer and TFIDF rely on the word count in a sentence but do not save any syntactical or semantic information. In these algorithms, the size of the <b>vector</b> is the number of elements in the vocabulary. We can get a <b>sparse</b> matrix if most ...", "dateLastCrawled": "2022-01-30T08:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the difference between a <b>Vector</b> and a Tensor in <b>Machine</b> <b>Learning</b>?", "url": "https://www.quora.com/What-is-the-difference-between-a-Vector-and-a-Tensor-in-Machine-Learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-a-<b>Vector</b>-and-a-Tensor-in-<b>Machine</b>...", "snippet": "Answer (1 of 2): A <b>vector</b> is a tensor of rank 1, a matrix is a tensor of rank 2. For a tensor with more than 2 dimensions, we refer to it as a tensor. Note that, rank of a matrix [1] from linear algebra is not the same as tensor rank [2] 1. Rank (linear algebra) - Wikipedia 2. Tensor - Wikipedia", "dateLastCrawled": "2022-01-13T06:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(sparse vector)  is like +(library)", "+(sparse vector) is similar to +(library)", "+(sparse vector) can be thought of as +(library)", "+(sparse vector) can be compared to +(library)", "machine learning +(sparse vector AND analogy)", "machine learning +(\"sparse vector is like\")", "machine learning +(\"sparse vector is similar\")", "machine learning +(\"just as sparse vector\")", "machine learning +(\"sparse vector can be thought of as\")", "machine learning +(\"sparse vector can be compared to\")"]}