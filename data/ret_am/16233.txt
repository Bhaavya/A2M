{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Probability in Python \u2013 <b>Dataquest</b>", "url": "https://www.dataquest.io/blog/basic-statistics-in-python-probability/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>dataquest</b>.io/blog/basic-statistics", "snippet": "If we don\u2019t want to make the <b>assumption</b> that the <b>coin</b> is fair, what can we do? We can gather data! We can use statistics to calculate probabilities based on observations from the real world and check how it compares to the ideal. From statistics to probability. Our data will be generated by flipping <b>a coin</b> 10 <b>times</b> and counting how many <b>times</b> we get <b>heads</b>. We will call a set of 10 <b>coin</b> tosses a trial. Our data point will be the number of <b>heads</b> we observe. We may not get the \u201cideal\u201d 5 ...", "dateLastCrawled": "2022-02-02T21:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "probability - What is the name of the statistical fallacy whereby ...", "url": "https://stats.stackexchange.com/questions/101590/what-is-the-name-of-the-statistical-fallacy-whereby-outcomes-of-previous-coin-fl", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/101590", "snippet": "$\\begingroup$ If <b>you</b> <b>flip</b> <b>a coin</b> <b>100</b> <b>times</b> and it lands <b>heads</b> <b>100</b> <b>times</b>, the odds are that it is not an unbiased <b>coin</b> ... {29}$ different ways to have <b>50</b> flips <b>come</b> <b>up</b> <b>heads</b> and <b>50</b> flips <b>come</b> <b>up</b> tails. $\\endgroup$ \u2013 Lagerbaer. Jun 9 &#39;14 at 19:03. 4 $\\begingroup$ Robert&#39;s idea is perfectly valid and may be the source of &quot;the fallacy&quot; in the first place. Our brains are wired in the Bayesian, not frequentist sense. The &quot;perfect&quot; information such as the &quot;absolutely fair <b>coin</b>&quot; rarely exists in ...", "dateLastCrawled": "2022-01-23T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The Analysis of Knowledge (Stanford Encyclopedia of Philosophy)", "url": "https://plato.stanford.edu/entries/knowledge-analysis/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/knowledge-analysis", "snippet": "If <b>you</b> <b>flip</b> <b>a coin</b> and never check how it landed, it may be true that it landed <b>heads</b>, even if nobody has any way to tell. Truth is a metaphysical, as opposed to epistemological, notion: truth is a matter of how things are, not how they can be shown to be. So when we say that only true things can be known, we\u2019re not (yet) saying anything about how anyone can access the truth. As we\u2019ll see, the other conditions have important roles to play here. Knowledge is a kind of relationship with ...", "dateLastCrawled": "2022-02-02T21:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "statistics - If I <b>flip</b> <b>a coin</b> 1000 <b>times</b> in a row and it lands on <b>heads</b> ...", "url": "https://math.stackexchange.com/questions/1346528/if-i-flip-a-coin-1000-times-in-a-row-and-it-lands-on-heads-all-1000-times-what", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/1346528", "snippet": "In your case, if <b>you</b> assume the confidence level of 0.999, and <b>you</b> have 1000 <b>heads</b> in 1000 throws, then <b>you</b> can say, &quot;the <b>assumption</b> of the null hypothesis must be wrong, and the <b>coin</b> must be unfair&quot;. Same with <b>50</b> <b>heads</b> in <b>50</b> throws, or 20 <b>heads</b> in 20 throws. But not with 7, not at this confidence level. With 7 <b>heads</b> (or tails), the probability is $2 \\<b>times</b> 1/2 ^ {7}$ , which is more than 0.001.", "dateLastCrawled": "2022-02-03T02:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Discrete Bayes Filter</b> - GitHub Pages", "url": "https://rlabbe.github.io/blog/2016/02/16/discrete-bayes-filter/", "isFamilyFriendly": true, "displayUrl": "https://rlabbe.github.io/blog/2016/02/16/<b>discrete-bayes-filter</b>", "snippet": "It is either <b>heads</b> or tails, we just don&#39;t know which. Bayes treats this as a <b>belief</b> about a single event - the strength of my <b>belief</b> or knowledge that this specific <b>coin</b> <b>flip</b> is <b>heads</b> is <b>50</b>%. Bayesian statistics takes past information (the <b>prior</b>) into account. We observe that it rains 4 <b>times</b> every <b>100</b> days. From this I could state that the ...", "dateLastCrawled": "2022-01-22T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Chapter 9 <b>Hypothesis</b> testing | Statistical Thinking for the 21st Century", "url": "https://statsthinking21.github.io/statsthinking21-core-site/hypothesis-testing.html", "isFamilyFriendly": true, "displayUrl": "https://statsthinking21.github.io/statsthinking21-core-site/<b>hypothesis</b>-testing.html", "snippet": "Let\u2019s say that we wish to determine whether a particular <b>coin</b> is biased towards landing <b>heads</b>. To collect data, we <b>flip</b> the <b>coin</b> <b>100</b> <b>times</b>, and let\u2019s say we count 70 <b>heads</b>. In this example, \\(H_0: P(<b>heads</b>) \\le 0.5\\) and \\(H_A: P(<b>heads</b>) &gt; 0.5\\), and our test statistic is simply the number of <b>heads</b> that we counted. The question that we then want to ask is: How likely is it that we would observe 70 or more <b>heads</b> in <b>100</b> <b>coin</b> flips if the true probability of <b>heads</b> is 0.5? We can imagine that ...", "dateLastCrawled": "2022-01-31T08:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Understanding Bayes: A Look at the Likelihood</b> | The Etz-Files", "url": "https://alexanderetz.com/2015/04/15/understanding-bayes-a-look-at-the-likelihood/", "isFamilyFriendly": true, "displayUrl": "https://alexanderetz.com/2015/04/15/<b>understanding-bayes-a-look-at-the-likelihood</b>", "snippet": "(footnote) Obtaining 60 <b>heads</b> in <b>100</b> tosses is equivalent to obtaining 6 <b>heads</b> in 10 tosses 10 separate <b>times</b>. To obtain this new likelihood ratio we can simply multiply our ratios together. That is, raise the first ratio to the power of 10; 1.4^10 \u2248 28.9, which is just slightly off from the correct value of 29.9 due to rounding. R Code", "dateLastCrawled": "2022-02-01T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "27 Probability Interview Questions (ANSWERED) For Data Scientists &amp; ML ...", "url": "https://www.mlstack.cafe/blog/probability-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.mlstack.cafe/blog/probability-interview-questions", "snippet": "<b>A coin</b> was flipped 1000 <b>times</b>, and 550 <b>times</b> it showed <b>up</b> <b>heads</b>. Do <b>you</b> think the <b>coin</b> is biased? Mid Probability 34 . Answer. To answer this question let&#39;s say X X X is the number of <b>heads</b> and let&#39;s assume that the <b>coin</b> is not biased. Since each individual <b>flip</b> is a Bernoulli random variable, we can assume it has a probability of showing <b>up</b> <b>heads</b> as p = 0.5, so this will lead to the following expected number of <b>heads</b>: \u03bc = n p = <b>1 0 0</b> 0 \u00d7 0. 5 = <b>5 0</b> 0 \\mu = np = 1000 \\<b>times</b> 0.5 = 500 \u03bc ...", "dateLastCrawled": "2022-02-03T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Hey\u2014guess <b>what? There really is a hot</b> hand! | Statistical Modeling ...", "url": "https://statmodeling.stat.columbia.edu/2015/07/09/hey-guess-what-there-really-is-a-hot-hand/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2015/07/09/hey-guess-<b>what-there-really-is-a-hot</b>...", "snippet": "Jack takes <b>a coin</b> from his pocket and decides that he will <b>flip</b> it 4 <b>times</b> in a row, writing down the outcome of each <b>flip</b> on a scrap of paper. After he is done flipping, he will look at the flips that immediately followed an outcome of <b>heads</b>, and compute the relative frequency of <b>heads</b> on those flips. Because the <b>coin</b> is fair, Jack of course expects this conditional relative frequency to be equal to the probability of flipping a <b>heads</b>: 0.5. Shockingly, Jack is wrong. If he were to sample 1 ...", "dateLastCrawled": "2021-11-22T12:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "probability - Does 10 <b>heads</b> <b>in a row</b> increase the chance of the next ...", "url": "https://stats.stackexchange.com/questions/136870/does-10-heads-in-a-row-increase-the-chance-of-the-next-toss-being-a-tail", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/136870", "snippet": "The probability that having already flipped tail 10 <b>times</b> that the next <b>flip</b> will also be a tail though is still <b>50</b>%. They are trying to apply the unlikeliness of the 1 in 1024 odds of 10 T to the chance of another T, when in fact that has already happened so the probability of it happening is no longer important. 11 tails <b>in a row</b> are no more or less likely than 10 tails followed by one head. The probability that 11 flips are all tails is unlikely but since it has already happened it doesn ...", "dateLastCrawled": "2022-01-24T13:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The Analysis of Knowledge (Stanford Encyclopedia of Philosophy)", "url": "https://plato.stanford.edu/entries/knowledge-analysis/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/knowledge-analysis", "snippet": "If <b>you</b> <b>flip</b> <b>a coin</b> and never check how it landed, it may be true that it landed <b>heads</b>, even if nobody has any way to tell. Truth is a metaphysical, as opposed to epistemological, notion: truth is a matter of how things are, not how they can be shown to be. So when we say that only true things can be known, we\u2019re not (yet) saying anything about how anyone can access the truth. As we\u2019ll see, the other conditions have important roles to play here. Knowledge is a kind of relationship with ...", "dateLastCrawled": "2022-02-02T21:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 1, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>List of cognitive biases</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/List_of_cognitive_biases", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>List_of_cognitive_biases</b>", "snippet": "For example, &quot;I&#39;ve flipped <b>heads</b> with this <b>coin</b> five <b>times</b> consecutively, so the chance of tails coming out on the sixth <b>flip</b> is much greater than <b>heads</b>.&quot; [62] Hot-hand fallacy (also known as &quot;hot hand phenomenon&quot; or &quot;hot hand&quot;), the <b>belief</b> that a person who has experienced success with a random event has a greater chance of further success in additional attempts.", "dateLastCrawled": "2022-02-02T06:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Discrete Bayes Filter</b> - GitHub Pages", "url": "https://rlabbe.github.io/blog/2016/02/16/discrete-bayes-filter/", "isFamilyFriendly": true, "displayUrl": "https://rlabbe.github.io/blog/2016/02/16/<b>discrete-bayes-filter</b>", "snippet": "It is either <b>heads</b> or tails, we just don&#39;t know which. Bayes treats this as a <b>belief</b> about a single event - the strength of my <b>belief</b> or knowledge that this specific <b>coin</b> <b>flip</b> is <b>heads</b> is <b>50</b>%. Bayesian statistics takes past information (the <b>prior</b>) into account. We observe that it rains 4 <b>times</b> every <b>100</b> days. From this I could state that the ...", "dateLastCrawled": "2022-01-22T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 9 <b>Hypothesis</b> testing | Statistical Thinking for the 21st Century", "url": "https://statsthinking21.github.io/statsthinking21-core-site/hypothesis-testing.html", "isFamilyFriendly": true, "displayUrl": "https://statsthinking21.github.io/statsthinking21-core-site/<b>hypothesis</b>-testing.html", "snippet": "Let\u2019s say that we wish to determine whether a particular <b>coin</b> is biased towards landing <b>heads</b>. To collect data, we <b>flip</b> the <b>coin</b> <b>100</b> <b>times</b>, and let\u2019s say we count 70 <b>heads</b>. In this example, \\(H_0: P(<b>heads</b>) \\le 0.5\\) and \\(H_A: P(<b>heads</b>) &gt; 0.5\\), and our test statistic is simply the number of <b>heads</b> that we counted. The question that we then want to ask is: How likely is it that we would observe 70 or more <b>heads</b> in <b>100</b> <b>coin</b> flips if the true probability of <b>heads</b> is 0.5? We can imagine that ...", "dateLastCrawled": "2022-01-31T08:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Probability in Python \u2013 <b>Dataquest</b>", "url": "https://www.dataquest.io/blog/basic-statistics-in-python-probability/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>dataquest</b>.io/blog/basic-statistics", "snippet": "Our data will be generated by flipping <b>a coin</b> 10 <b>times</b> and counting how many <b>times</b> we get <b>heads</b>. We will call a set of 10 <b>coin</b> tosses a trial. Our data point will be the number of <b>heads</b> we observe. We may not get the \u201cideal\u201d 5 <b>heads</b>, but we won\u2019t worry too much since one trial is only one data point. If we perform many, many trials, we expect the average number of <b>heads</b> over all of our trials to approach the <b>50</b>%. The code below simulates 10, <b>100</b>, 1000, and 1000000 trials, and then ...", "dateLastCrawled": "2022-02-02T21:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "1 Flipping <b>a Coin</b> (and Basic Probabilities) | Gambling Statistics", "url": "https://bodhi-root.github.io/gambling-stats-bookdown/flipping-a-coin.html", "isFamilyFriendly": true, "displayUrl": "https://bodhi-root.github.io/gambling-stats-bookdown/<b>flip</b>ping-<b>a-coin</b>.html", "snippet": "A fair <b>coin</b> will have a <b>50</b>% chance of coming <b>up</b> <b>heads</b> and <b>50</b>% chance of coming <b>up</b> tails. A fair bet is one that pays even money. That means <b>that if you</b> bet $1 on a particular outcome (<b>heads</b> or tails), <b>you</b> win $1 if <b>you</b>\u2019re right and lose $1 if <b>you</b>\u2019re wrong. In gambling terms the \u201codds\u201d are 1-to-1, meaning there is an equal probability of each outcome, and a fair bet will pay 1-to-1, meaning that the dollar <b>you</b> bet is matched with 1 dollar <b>you</b> win. The expected value of such a wager is ...", "dateLastCrawled": "2021-12-24T21:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "27 Probability Interview Questions (ANSWERED) For Data Scientists &amp; ML ...", "url": "https://www.mlstack.cafe/blog/probability-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.mlstack.cafe/blog/probability-interview-questions", "snippet": "<b>A coin</b> was flipped 1000 <b>times</b>, and 550 <b>times</b> it showed <b>up</b> <b>heads</b>. Do <b>you</b> think the <b>coin</b> is biased? Mid Probability 34 . Answer. To answer this question let&#39;s say X X X is the number of <b>heads</b> and let&#39;s assume that the <b>coin</b> is not biased. Since each individual <b>flip</b> is a Bernoulli random variable, we can assume it has a probability of showing <b>up</b> <b>heads</b> as p = 0.5, so this will lead to the following expected number of <b>heads</b>: \u03bc = n p = <b>1 0 0</b> 0 \u00d7 0. 5 = <b>5 0</b> 0 \\mu = np = 1000 \\<b>times</b> 0.5 = 500 \u03bc ...", "dateLastCrawled": "2022-02-03T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "probability - What is the name of the statistical fallacy whereby ...", "url": "https://stats.stackexchange.com/questions/101590/what-is-the-name-of-the-statistical-fallacy-whereby-outcomes-of-previous-coin-fl", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/101590", "snippet": "$\\begingroup$ If <b>you</b> <b>flip</b> <b>a coin</b> <b>100</b> <b>times</b> and it lands <b>heads</b> <b>100</b> <b>times</b>, the odds are that it is not an unbiased <b>coin</b> ... {29}$ different ways to have <b>50</b> flips <b>come</b> <b>up</b> <b>heads</b> and <b>50</b> flips <b>come</b> <b>up</b> tails. $\\endgroup$ \u2013 Lagerbaer. Jun 9 &#39;14 at 19:03. 4 $\\begingroup$ Robert&#39;s idea is perfectly valid and may be the source of &quot;the fallacy&quot; in the first place. Our brains are wired in the Bayesian, not frequentist sense. The &quot;perfect&quot; information such as the &quot;absolutely fair <b>coin</b>&quot; rarely exists in ...", "dateLastCrawled": "2022-01-23T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Hey\u2014guess <b>what? There really is a hot</b> hand! | Statistical Modeling ...", "url": "https://statmodeling.stat.columbia.edu/2015/07/09/hey-guess-what-there-really-is-a-hot-hand/", "isFamilyFriendly": true, "displayUrl": "https://statmodeling.stat.columbia.edu/2015/07/09/hey-guess-<b>what-there-really-is-a-hot</b>...", "snippet": "Jack takes <b>a coin</b> from his pocket and decides that he will <b>flip</b> it 4 <b>times</b> in a row, writing down the outcome of each <b>flip</b> on a scrap of paper. After he is done flipping, he will look at the flips that immediately followed an outcome of <b>heads</b>, and compute the relative frequency of <b>heads</b> on those flips. Because the <b>coin</b> is fair, Jack of course expects this conditional relative frequency to be equal to the probability of flipping a <b>heads</b>: 0.5. Shockingly, Jack is wrong. If he were to sample 1 ...", "dateLastCrawled": "2021-11-22T12:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "probability - Does 10 <b>heads</b> <b>in a row</b> increase the chance of the next ...", "url": "https://stats.stackexchange.com/questions/136870/does-10-heads-in-a-row-increase-the-chance-of-the-next-toss-being-a-tail", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/136870", "snippet": "The probability that having already flipped tail 10 <b>times</b> that the next <b>flip</b> will also be a tail though is still <b>50</b>%. They are trying to apply the unlikeliness of the 1 in 1024 odds of 10 T to the chance of another T, when in fact that has already happened so the probability of it happening is no longer important. 11 tails <b>in a row</b> are no more or less likely than 10 tails followed by one head. The probability that 11 flips are all tails is unlikely but since it has already happened it doesn ...", "dateLastCrawled": "2022-01-24T13:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "The Analysis of Knowledge (Stanford Encyclopedia of Philosophy)", "url": "https://plato.stanford.edu/entries/knowledge-analysis/", "isFamilyFriendly": true, "displayUrl": "https://<b>plato.stanford.edu</b>/entries/knowledge-analysis", "snippet": "If <b>you</b> <b>flip</b> <b>a coin</b> and never check how it landed, it may be true that it landed <b>heads</b>, even if nobody has any way to tell. Truth is a ... The general idea behind the <b>belief</b> condition is that <b>you</b> <b>can</b> only know what <b>you</b> believe. Failing to believe something precludes knowing it. \u201c<b>Belief</b>\u201d in the context of the JTB theory means full <b>belief</b>, or outright <b>belief</b>. In a weak sense, one might \u201cbelieve\u201d something by virtue of being pretty confident that it\u2019s probably true\u2014in this weak sense ...", "dateLastCrawled": "2022-02-02T21:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>The Power and the Problem with the</b> P-Value - Medical Statistics Made ...", "url": "https://www.coursera.org/lecture/medical-research/the-power-and-the-problem-with-the-p-value-KztPc", "isFamilyFriendly": true, "displayUrl": "https://<b>www.coursera.org</b>/lecture/medical-research/<b>the-power-and-the-problem-with-the</b>-p...", "snippet": "<b>You</b> <b>can</b> say that if we <b>flip</b> it once, our chance of getting <b>heads</b> assuming the <b>coin</b> is just a normal run-of-the-mill <b>coin</b>, a single <b>flip</b> back, <b>50</b>% chance of getting <b>heads</b>. So that&#39;s <b>50</b>% probability there. 2 <b>heads</b> in a row, assuming <b>you</b> have a normal quarter, 25% chance, 0.25. Okay, three in a row 12.5%, and so on down the line. If I&#39;d have a normal quarter, it&#39;s pretty unusual to get ten <b>heads</b> in a row around about 1 in 1,000 <b>times</b>. <b>You</b> might get 10 <b>heads</b> in a row like that. All right, so <b>you</b> ...", "dateLastCrawled": "2022-01-26T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "27 Probability Interview Questions (ANSWERED) For Data Scientists &amp; ML ...", "url": "https://www.mlstack.cafe/blog/probability-interview-questions", "isFamilyFriendly": true, "displayUrl": "https://www.mlstack.cafe/blog/probability-interview-questions", "snippet": "Since each individual <b>flip</b> is a Bernoulli random variable, we <b>can</b> assume it has a probability of showing <b>up</b> <b>heads</b> as p = 0.5, so this will lead to the following expected number of <b>heads</b>: \u03bc = n p = <b>1 0 0</b> 0 \u00d7 0 . 5 = <b>5 0</b> 0 \\mu = np = 1000 \\<b>times</b> 0.5 = 500 \u03bc = n p = <b>1 0 0</b> 0 \u00d7 0 . 5 = <b>5 0</b> 0", "dateLastCrawled": "2022-02-03T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 9 <b>Hypothesis</b> testing | Statistical Thinking for the 21st Century", "url": "https://statsthinking21.github.io/statsthinking21-core-site/hypothesis-testing.html", "isFamilyFriendly": true, "displayUrl": "https://statsthinking21.github.io/statsthinking21-core-site/<b>hypothesis</b>-testing.html", "snippet": "Let\u2019s say that we wish to determine whether a particular <b>coin</b> is biased towards landing <b>heads</b>. To collect data, we <b>flip</b> the <b>coin</b> <b>100</b> <b>times</b>, and let\u2019s say we count 70 <b>heads</b>. In this example, \\(H_0: P(<b>heads</b>) \\le 0.5\\) and \\(H_A: P(<b>heads</b>) &gt; 0.5\\), and our test statistic is simply the number of <b>heads</b> that we counted. The question that we then want to ask is: How likely is it that we would observe 70 or more <b>heads</b> in <b>100</b> <b>coin</b> flips if the true probability of <b>heads</b> is 0.5? We <b>can</b> imagine that ...", "dateLastCrawled": "2022-01-31T08:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Full Hypothesis Test Examples</b> \u2013 Introductory Business Statistics", "url": "https://opentextbc.ca/introbusinessstatopenstax/chapter/full-hypothesis-test-examples/", "isFamilyFriendly": true, "displayUrl": "https://opentextbc.ca/introbusinessstatopenstax/chapter/<b>full-hypothesis-test-examples</b>", "snippet": "<b>You</b> <b>flip</b> <b>a coin</b> and record whether it shows <b>heads</b> or tails. <b>You</b> know the probability of getting <b>heads</b> is <b>50</b>%, but <b>you</b> think it is less for this particular <b>coin</b>. What type of test would <b>you</b> use? a left-tailed test. If the alternative hypothesis has a not equals ( \u2260 ) symbol, <b>you</b> know to use which type of test? Assume the null hypothesis states that the mean is at least 18. Is this a left-tailed, right-tailed, or two-tailed test? This is a left-tailed test. Assume the null hypothesis states ...", "dateLastCrawled": "2022-02-02T22:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A Beginner&#39;s Guide to <b>Markov Chain Monte Carlo</b>, Machine Learning ...", "url": "https://wiki.pathmind.com/markov-chain-monte-carlo", "isFamilyFriendly": true, "displayUrl": "https://wiki.pathmind.com/<b>markov-chain-monte-carlo</b>", "snippet": "Flipping <b>a coin</b> <b>100</b> <b>times</b> would be a sample of the population of all <b>coin</b> tosses and would allow us to reason inductively about all the <b>coin</b> flips we cannot see. Distribution (or probability distribution) - <b>You</b> <b>can</b> think of a distribution as table that links outcomes with probabilities. <b>A coin</b> toss has two possible outcomes, <b>heads</b> (H) or tails (T ). Flipping it twice <b>can</b> result in either HH, TT, HT or TH. So let\u2019s contruct a table that shows the outcomes of two <b>coin</b> tosses as measured by ...", "dateLastCrawled": "2022-02-03T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "probability - What is the name of the statistical fallacy whereby ...", "url": "https://stats.stackexchange.com/questions/101590/what-is-the-name-of-the-statistical-fallacy-whereby-outcomes-of-previous-coin-fl", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/101590", "snippet": "$\\begingroup$ If <b>you</b> <b>flip</b> <b>a coin</b> <b>100</b> <b>times</b> and it lands <b>heads</b> <b>100</b> <b>times</b>, the odds are that it is not an unbiased <b>coin</b> ... {29}$ different ways to have <b>50</b> flips <b>come</b> <b>up</b> <b>heads</b> and <b>50</b> flips <b>come</b> <b>up</b> tails. $\\endgroup$ \u2013 Lagerbaer. Jun 9 &#39;14 at 19:03. 4 $\\begingroup$ Robert&#39;s idea is perfectly valid and may be the source of &quot;the fallacy&quot; in the first place. Our brains are wired in the Bayesian, not frequentist sense. The &quot;perfect&quot; information such as the &quot;absolutely fair <b>coin</b>&quot; rarely exists in ...", "dateLastCrawled": "2022-01-23T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Discrete Bayes Filter</b> - GitHub Pages", "url": "https://rlabbe.github.io/blog/2016/02/16/discrete-bayes-filter/", "isFamilyFriendly": true, "displayUrl": "https://rlabbe.github.io/blog/2016/02/16/<b>discrete-bayes-filter</b>", "snippet": "It is either <b>heads</b> or tails, we just don&#39;t know which. Bayes treats this as a <b>belief</b> about a single event - the strength of my <b>belief</b> or knowledge that this specific <b>coin</b> <b>flip</b> is <b>heads</b> is <b>50</b>%. Bayesian statistics takes past information (the <b>prior</b>) into account. We observe that it rains 4 <b>times</b> every <b>100</b> days. From this I could state that the ...", "dateLastCrawled": "2022-01-22T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Schools of</b> <b>thought</b> in Probability Theory | <b>ScienceBlogs</b>", "url": "https://scienceblogs.com/goodmath/2008/04/07/schools-of-thought-in-probabil", "isFamilyFriendly": true, "displayUrl": "https://<b>scienceblogs.com</b>/goodmath/2008/04/07/<b>schools-of</b>-<b>thought</b>-in-probabil", "snippet": "I apologize in advance for my complete ignorance of this topic (aside from my child&#39;s-level exposure to the fact <b>that if you</b> <b>flip</b> <b>a coin</b> the probability is 0.5 that <b>it will come</b> <b>up</b> <b>heads</b>).", "dateLastCrawled": "2022-02-01T12:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "probability - <b>Two envelope problem revisited</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/95694/two-envelope-problem-revisited", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/95694", "snippet": "<b>You</b> pay me \\$10 and I will <b>flip</b> a fair <b>coin</b>. <b>Heads</b> I give <b>you</b> \\$5 and Tails I give <b>you</b> \\$20. The expectation is \\$12.5 so <b>you</b> will always play the game. Problem 2: I will give <b>you</b> an envelope with \\$10, the envelope is open and <b>you</b> <b>can</b> check. I then show <b>you</b> another envelope, closed this time and tell <b>you</b>: This envelope either has \\$5 or $20 in it with equal probability. Do <b>you</b> want to swap? I feel this is exactly the same as problem 1, <b>you</b> forgo \\$10 for a \\$5 or a \\$20, so again <b>you</b> will ...", "dateLastCrawled": "2022-01-17T10:44:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>The Power and the Problem with the</b> P-Value - Medical Statistics Made ...", "url": "https://www.coursera.org/lecture/medical-research/the-power-and-the-problem-with-the-p-value-KztPc", "isFamilyFriendly": true, "displayUrl": "https://<b>www.coursera.org</b>/lecture/medical-research/<b>the-power-and-the-problem-with-the</b>-p...", "snippet": "<b>You</b> <b>can</b> say that if we <b>flip</b> it once, our chance of getting <b>heads</b> assuming the <b>coin</b> is just a normal run-of-the-mill <b>coin</b>, a single <b>flip</b> back, <b>50</b>% chance of getting <b>heads</b>. So that&#39;s <b>50</b>% probability there. 2 <b>heads</b> in a row, assuming <b>you</b> have a normal quarter, 25% chance, 0.25. Okay, three in a row 12.5%, and so on down the line. If I&#39;d have a normal quarter, it&#39;s pretty unusual to get ten <b>heads</b> in a row around about 1 in 1,000 <b>times</b>. <b>You</b> might get 10 <b>heads</b> in a row like that. All right, so <b>you</b> ...", "dateLastCrawled": "2022-01-26T09:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "9 Difference-in-<b>Differences</b> | Causal Inference", "url": "https://mixtape.scunning.com/difference-in-differences.html", "isFamilyFriendly": true, "displayUrl": "https://mixtape.scunning.com/difference-in-<b>differences</b>.html", "snippet": "Just because <b>a coin</b> came <b>up</b> <b>heads</b> three <b>times</b> in a row does not mean <b>it will come</b> <b>up</b> <b>heads</b> the fourth time\u2014not without further assumptions. Likewise, we are not obligated to believe that that counterfactual trends would be the same post-treatment because they had been similar pre-treatment without further assumptions about the predictive power of pre-treatment trends. But to make such assumptions is again to make untestable assumptions, and so we are back where we started.", "dateLastCrawled": "2022-01-30T02:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Understanding Bayes: A Look at the Likelihood</b> | The Etz-Files", "url": "https://alexanderetz.com/2015/04/15/understanding-bayes-a-look-at-the-likelihood/", "isFamilyFriendly": true, "displayUrl": "https://alexanderetz.com/2015/04/15/<b>understanding-bayes-a-look-at-the-likelihood</b>", "snippet": "In short the data favor .60 over the a priori hypothesis .<b>50</b>, which is the null-hypothesis that the odds for <b>heads</b> and tail are equal (.<b>50</b> \u2013 .<b>50</b> = 0). A traditional significance test would have shown that the probability of obtaining 300 out of 500 <b>heads</b> for a fair <b>coin</b> (a priori hypothesis .<b>50</b>) is p &lt; .00001. It is therefore very safe to ...", "dateLastCrawled": "2022-02-01T22:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Probability in Python \u2013 <b>Dataquest</b>", "url": "https://www.dataquest.io/blog/basic-statistics-in-python-probability/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>dataquest</b>.io/blog/basic-statistics", "snippet": "If we don\u2019t want to make the <b>assumption</b> that the <b>coin</b> is fair, what <b>can</b> we do? We <b>can</b> gather data! We <b>can</b> use statistics to calculate probabilities based on observations from the real world and check how it compares to the ideal. From statistics to probability. Our data will be generated by flipping <b>a coin</b> 10 <b>times</b> and counting how many <b>times</b> we get <b>heads</b>. We will call a set of 10 <b>coin</b> tosses a trial. Our data point will be the number of <b>heads</b> we observe. We may not get the \u201cideal\u201d 5 ...", "dateLastCrawled": "2022-02-02T21:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Chapter 11 <b>Bayesian</b> statistics | Statistical Thinking for the 21st Century", "url": "https://statsthinking21.github.io/statsthinking21-core-site/bayesian-statistics.html", "isFamilyFriendly": true, "displayUrl": "https://statsthinking21.github.io/statsthinking21-core-site/<b>bayesian</b>-statistics.html", "snippet": "Chapter 11 <b>Bayesian</b> statistics. In this chapter we will take <b>up</b> the approach to statistical modeling and inference that stands in contrast to the null hypothesis testing framework that <b>you</b> encountered in Chapter 9.This is known as \u201c<b>Bayesian</b> statistics\u201d after the Reverend Thomas Bayes, whose theorem <b>you</b> have already encountered in Chapter 6.In this chapter <b>you</b> will learn how Bayes\u2019 theorem provides a way of understanding data that solves many of the conceptual problems that we discussed ...", "dateLastCrawled": "2022-02-02T00:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Chapter 9 <b>Hypothesis</b> testing | Statistical Thinking for the 21st Century", "url": "https://statsthinking21.github.io/statsthinking21-core-site/hypothesis-testing.html", "isFamilyFriendly": true, "displayUrl": "https://statsthinking21.github.io/statsthinking21-core-site/<b>hypothesis</b>-testing.html", "snippet": "Let\u2019s say that we wish to determine whether a particular <b>coin</b> is biased towards landing <b>heads</b>. To collect data, we <b>flip</b> the <b>coin</b> <b>100</b> <b>times</b>, and let\u2019s say we count 70 <b>heads</b>. In this example, \\(H_0: P(<b>heads</b>) \\le 0.5\\) and \\(H_A: P(<b>heads</b>) &gt; 0.5\\), and our test statistic is simply the number of <b>heads</b> that we counted. The question that we then want to ask is: How likely is it that we would observe 70 or more <b>heads</b> in <b>100</b> <b>coin</b> flips if the true probability of <b>heads</b> is 0.5? We <b>can</b> imagine that ...", "dateLastCrawled": "2022-01-31T08:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "probability - <b>Two envelope problem revisited</b> - Cross Validated", "url": "https://stats.stackexchange.com/questions/95694/two-envelope-problem-revisited", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/95694", "snippet": "<b>You</b> pay me \\$10 and I will <b>flip</b> a fair <b>coin</b>. <b>Heads</b> I give <b>you</b> \\$5 and Tails I give <b>you</b> \\$20. The expectation is \\$12.5 so <b>you</b> will always play the game. Problem 2: I will give <b>you</b> an envelope with \\$10, the envelope is open and <b>you</b> <b>can</b> check. I then show <b>you</b> another envelope, closed this time and tell <b>you</b>: This envelope either has \\$5 or $20 in it with equal probability. Do <b>you</b> want to swap? I feel this is exactly the same as problem 1, <b>you</b> forgo \\$10 for a \\$5 or a \\$20, so again <b>you</b> will ...", "dateLastCrawled": "2022-01-17T10:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Statistics \u00b7 Phylogenetic Comparative Methods", "url": "https://lukejharmon.github.io/pcm/chapter2_stats/", "isFamilyFriendly": true, "displayUrl": "https://lukejharmon.github.io/pcm/chapter2_stats", "snippet": "As an experiment, <b>you</b> <b>flip</b> the lizard <b>100</b> <b>times</b>, and obtain <b>heads</b> 63 of those <b>times</b>. Thus, 63 <b>heads</b> out of <b>100</b> lizard flips is your data; we will use model comparisons to try to see what these data tell us about models of lizard flipping. Section 2.2: Standard statistical hypothesis testing. Standard hypothesis testing approaches focus almost entirely on rejecting null hypotheses. In the framework (usually referred to as the frequentist approach to statistics) one first defines a null ...", "dateLastCrawled": "2022-02-01T22:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>19 Significance Testing</b> | Odds &amp; Ends - Jonathan Weisberg", "url": "https://jonathanweisberg.org/vip/significance-testing.html", "isFamilyFriendly": true, "displayUrl": "https://jonathanweisberg.org/vip/<b>significance-testing</b>.html", "snippet": "Suppose we <b>flip</b> <b>a coin</b> ten <b>times</b> and it lands <b>heads</b> every single time. That would be too much of a coincidence if the <b>coin</b> were fair. So the hypothesis that it is fair has been tested, and failed. Conclusion: the <b>coin</b> is biased toward <b>heads</b>. Or imagine we divide a thousand patients with Disease X into two, equal-sized groups. We give the first group Drug Y, the second group gets a placebo. After a month, \\(90\\%\\) of the patients who got the drug are cured, <b>compared</b> to only \\(10\\%\\) of the ...", "dateLastCrawled": "2022-02-02T11:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why is the probability of getting 60% <b>heads</b> when tossing 10 coins ...", "url": "https://www.quora.com/Why-is-the-probability-of-getting-60-heads-when-flipping-10-coins-different-than-the-probability-of-getting-60-heads-when-flipping-10000-coins", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Why-is-the-probability-of-getting-60-<b>heads</b>-when-<b>flip</b>ping-10...", "snippet": "Answer (1 of 3): Here are a few ways to think about it. Suppose <b>you</b> were drawing one number at random from 0 to 10, the probability of getting 6 (or any specific number) is 1 in 11. If the numbers go from 0 to 10,000, it\u2019s 1 in 10,001. So one reason 6,000 out of 10,000 is less likely than 6 out ...", "dateLastCrawled": "2022-01-19T17:01:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A <b>machine</b> <b>learning</b> approach to Bayesian parameter estimation | npj ...", "url": "https://www.nature.com/articles/s41534-021-00497-w", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41534-021-00497-w", "snippet": "Bayesian estimation is a powerful theoretical paradigm for the operation of the approach to parameter estimation. However, the Bayesian method for statistical inference generally suffers from ...", "dateLastCrawled": "2022-02-03T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Tour of the <b>Most Popular Machine Learning Algorithms</b> | by Athreya ...", "url": "https://towardsdatascience.com/a-tour-of-the-most-popular-machine-learning-algorithms-b57d50c2eb51", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tour-of-the-<b>most-popular-machine-learning-algorithms</b>...", "snippet": "In <b>machine</b> <b>learning</b>, it is tradition to categorize algorithms by their <b>learning</b> style. In general, <b>learning</b> style is just a fancy way of saying what data you have readily available to train your algorithm. Let\u2019s look at some! 1. Supervised <b>Learning</b>. In supervised <b>learning</b>, input data is called training data and has a known label/result. An example of an input could be a picture of an animal and a label could be the name of it (i.e. elephant, cat, etc.). Another example can be emails as ...", "dateLastCrawled": "2022-01-29T22:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Preliminary performance study of a brief review on <b>machine</b> <b>learning</b> ...", "url": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12652-021-03427-y", "snippet": "<b>Analogy</b>-based effort estimation is the major task of software engineering which estimates the effort required for new software projects using existing histories for corresponding development and management. In general, the high accuracy of software effort estimation techniques can be a non-solvable problem we named as multi-objective problem. Recently, most of the authors have been used <b>machine</b> <b>learning</b> techniques for the same process however not possible to meet the higher performance ...", "dateLastCrawled": "2022-01-02T12:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "CPSC 540: <b>Machine</b> <b>Learning</b>", "url": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W16/L21.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W16/L21.pdf", "snippet": "CPSC 540: <b>Machine</b> <b>Learning</b> MCMC and Non-Parametric Bayes Mark Schmidt University of British Columbia Winter 2016. Gibbs SamplingMarkov Chain Monte CarloMetropolis-HastingsNon-Parametric Bayes Admin I went through project proposals: Some of you got a message on Piazza. No news is good news. A5 coming tomorrow. Project submission details coming next week. Gibbs SamplingMarkov Chain Monte CarloMetropolis-HastingsNon-Parametric Bayes Overview of Bayesian Inference Tasks InBayesianapproach, we ...", "dateLastCrawled": "2021-11-07T15:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "AI Qual Summary: <b>Learning</b> - Stanford University", "url": "http://www-cs-students.stanford.edu/~pdoyle/quail/notes/pdoyle/learning.html", "isFamilyFriendly": true, "displayUrl": "www-cs-students.stanford.edu/~pdoyle/quail/notes/pdoyle/<b>learning</b>.html", "snippet": "<b>learning</b> by <b>analogy</b> Inductive <b>learning</b> in which a system transfers knowledge from one database into a that of a different domain. discovery Both inductive and deductive <b>learning</b> in which an agent learns without help from a teacher. It is deductive if it proves theorems and discovers concepts about those theorems; it is inductive when it raises conjectures. Inductive <b>Learning</b>. Inductive <b>learning</b> is a kind of <b>learning</b> in which, given a set of examples an agent tries to estimate or create an ...", "dateLastCrawled": "2022-02-01T20:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Lecture9 - Bayesian-Decision-Theory</b> - SlideShare", "url": "https://www.slideshare.net/aorriols/lecture9-bayesiandecisiontheory", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/aorriols/<b>lecture9-bayesiandecisiontheory</b>", "snippet": "<b>Lecture9 - Bayesian-Decision-Theory</b> 1. Introduction to <b>Machine</b> <b>Learning</b> <b>Lecture 9 Bayesian decision theory</b> \u2013 An introduction Albert Orriols i Puig aorriols@salle.url.edu i l @ ll ld Artificial Intelligence \u2013 <b>Machine</b> <b>Learning</b> Enginyeria i Arquitectura La Salle gy q Universitat Ramon Llull", "dateLastCrawled": "2022-01-24T22:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "BAYESIAN <b>MACHINE</b> <b>LEARNING</b> FOR THE PROGNOSIS OF COMBUSTION INSTABILITIES ...", "url": "http://www2.eng.cam.ac.uk/~mpj1001/papers/ASME_Sengupta_2020.pdf", "isFamilyFriendly": true, "displayUrl": "www2.eng.cam.ac.uk/~mpj1001/papers/ASME_Sengupta_2020.pdf", "snippet": "Bayesian <b>machine</b> <b>learning</b> tech-niques with correctly speci\ufb01ed priors can also work with smaller amounts of data and are resistant to over\ufb01tting [24]. They can also be used in continual <b>learning</b> without catastrophic forget-ting [25], which is particularly important if we want to keep <b>learning</b> from data throughout the operating lifetime of a ...", "dateLastCrawled": "2022-02-03T03:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>All Unit MCQ questions of ML</b> \u2013 TheCodingShef", "url": "https://thecodingshef.com/all-unit-mcq-questions-of-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://thecodingshef.com/<b>all-unit-mcq-questions-of</b>-<b>machine</b>-<b>learning</b>", "snippet": "Correct option is C. Choose the correct option regarding <b>machine</b> <b>learning</b> (ML) and artificial intelligence (AI) ML is a set of techniques that turns a dataset into a software. AI is a software that can emulate the human mind. ML is an alternate way of programming intelligent machines. All of the above. Correct option is D.", "dateLastCrawled": "2022-01-30T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - <b>Relation between MAP, EM, and</b> MLE - Cross Validated", "url": "https://stats.stackexchange.com/questions/235070/relation-between-map-em-and-mle", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/235070/<b>relation-between-map-em-and</b>-mle", "snippet": "In the M&amp;M <b>analogy</b>, what is the probability of a red M&amp;M given a package of M&amp;Ms. Mathmatically put, this would look like \\begin{equation} P(red\\ M\\&amp;M|package\\ of\\ M\\&amp;Ms) \\propto L(package\\ of\\ M\\&amp;Ms|red\\ M\\&amp;M) \\end{equation} Lets get a bit more hands-on. A good idea could be, to just buy 100 packages of M&amp;Ms and just count the number of occurances of red M&amp;Ms in each of the packages. So, we come to the conclusion that the amount of red M&amp;Ms in the packages are somewhat uniformly distributed ...", "dateLastCrawled": "2022-01-19T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Solving Bandit <b>Machine</b> Problem Using Bayesian Algorithm | by Wening ...", "url": "https://medium.com/it-paragon/solving-bandit-machine-problem-using-bayes-4c73b0653d29", "isFamilyFriendly": true, "displayUrl": "https://medium.com/it-paragon/solving-bandit-<b>machine</b>-problem-using-bayes-4c73b0653d29", "snippet": "Some Claw Crane Machines. The claw crane <b>machine</b> actually reminds me of the bandit <b>machine</b> problem. A bandit is a thief. A bandit <b>machine</b> is a <b>machine</b> that steals your money because most of the ...", "dateLastCrawled": "2021-01-12T01:18:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(prior belief)  is like +(assumption that if you flip a coin 100 times, it will come up heads 50 times)", "+(prior belief) is similar to +(assumption that if you flip a coin 100 times, it will come up heads 50 times)", "+(prior belief) can be thought of as +(assumption that if you flip a coin 100 times, it will come up heads 50 times)", "+(prior belief) can be compared to +(assumption that if you flip a coin 100 times, it will come up heads 50 times)", "machine learning +(prior belief AND analogy)", "machine learning +(\"prior belief is like\")", "machine learning +(\"prior belief is similar\")", "machine learning +(\"just as prior belief\")", "machine learning +(\"prior belief can be thought of as\")", "machine learning +(\"prior belief can be compared to\")"]}