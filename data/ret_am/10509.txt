{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Q function and Error functions : demystified</b> - GaussianWaves", "url": "https://www.gaussianwaves.com/2012/07/q-function-and-error-functions/", "isFamilyFriendly": true, "displayUrl": "https://www.gaussianwaves.com/2012/07/<b>q-function</b>-and-error-<b>functions</b>", "snippet": "Thus <b>Q function</b> gives the area of the shaded curve with the transformation . applied to the Gaussian probability density <b>function</b>. Essentially, <b>Q function</b> evaluates the tail probability of normal distribution (area of shaded area in the above figure).", "dateLastCrawled": "2022-01-30T05:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "An <b>introduction to Q-Learning: reinforcement learning</b>", "url": "https://www.freecodecamp.org/news/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc/", "isFamilyFriendly": true, "displayUrl": "https://www.freecodecamp.org/news/an-<b>introduction-to-q-learning-reinforcement-learning</b>...", "snippet": "<b>Mathematics</b>: the Q-Learning algorithm <b>Q-function</b>. The <b>Q-function</b> uses the Bellman equation and takes two inputs: state (s) and action (a). Using the above <b>function</b>, we get the values of Q for the cells in the table. When we start, all the values in the Q-table are zeros. There is an iterative process of updating the values. As we start to explore the environment, the <b>Q-function</b> gives us better and better approximations by continuously updating the Q-values in the table. Now, let\u2019s ...", "dateLastCrawled": "2022-02-02T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The <b>Bellman Equation</b>. V-<b>function</b> and <b>Q-function</b> Explained | by Jordi ...", "url": "https://towardsdatascience.com/the-bellman-equation-59258a0d3fa7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-<b>bellman-equation</b>-59258a0d3fa7", "snippet": "The <b>Q-function</b>: The value of the action. In post 2 we extended the definition of state-value <b>function</b> to state-action pairs, defining a value for each state-action pair, which is called the action-value <b>function</b>, also known as <b>Q-function</b> or simply Q. It defines the value of taking action a in state s under a policy \u03c0, denoted by Q\ud835\udf0b(\ud835\udc60,\ud835\udc4e), as the expected Return G starting from s, taking the action \ud835\udc4e, and thereafter following policy \u03c0: In this <b>equation</b> again it is used ...", "dateLastCrawled": "2022-02-03T05:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) A <b>Q FUNCTION IN FRACTIONAL CALCULUS</b>", "url": "https://www.researchgate.net/publication/309235890_A_Q_FUNCTION_IN_FRACTIONAL_CALCULUS", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/309235890_A_<b>Q_FUNCTION_IN_FRACTIONAL_CALCULUS</b>", "snippet": "This paper presents a <b>Q function</b> using Generalized Mittag-Leffler <b>function in Fractional Calculus</b> and also some relations and results related to this new special <b>function</b>.", "dateLastCrawled": "2022-01-03T18:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>6. Functions</b> - Q for Mortals", "url": "https://code.kx.com/q4m3/6_Functions/", "isFamilyFriendly": true, "displayUrl": "https://code.kx.com/q4m3/<b>6_Functions</b>", "snippet": "A <b>function</b> is a first-class value \u2013 i.e., it is data just <b>like</b> a long or float. In particular, a <b>function</b> can be assigned to a variable, whereupon it acquires a name. This variable can be used in place of the <b>function</b>. q)f:{[x] x*x} q)f[3] _ 6.1.2 <b>Function</b> Notation and Terminology\u00b6 The formal notation for <b>function</b> definition is,", "dateLastCrawled": "2022-02-02T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "probability - <b>Expected Value Problem (Q-function</b>...inside a <b>function</b> ...", "url": "https://math.stackexchange.com/questions/332585/expected-value-problem-q-function-inside-a-function", "isFamilyFriendly": true, "displayUrl": "https://math.<b>stackexchange</b>.com/questions/332585", "snippet": "All you really need to do here is use the fact that a is very small. You have everything else written down OK: E [ P ( X)] = 1 2 a \u222b \u2212 a a d x Q ( 2 E b N 0 | cos. \u2061. x |) When a is small, you can approximate the integral by 2 a times the integrand evaluated at a. Thus. E [ P ( X)] \u2248 Q ( 2 E b N 0 cos. \u2061.", "dateLastCrawled": "2022-01-15T04:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "integration - <b>Integral involving the Q-Function</b> - <b>Mathematics</b> Stack ...", "url": "https://math.stackexchange.com/questions/1515821/integral-involving-the-q-function", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/1515821/<b>integral-involving-the-q-function</b>", "snippet": "<b>Mathematics Stack Exchange</b> is a question and answer site for people studying math at any level and professionals in related fields. It only takes a minute to sign up. Sign up to join this community. Anybody can ask a question Anybody can answer The best answers are voted up and rise to the top Home Public; Questions; Tags Users Unanswered Teams. Stack Overflow for Teams \u2013 Collaborate and share knowledge with a private group. Create a free Team What is Teams? Teams. Create free Team Teams ...", "dateLastCrawled": "2021-12-23T03:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Inverse <b>Function</b> (Definition and Examples)", "url": "https://byjus.com/maths/inverse-functions/", "isFamilyFriendly": true, "displayUrl": "https://byjus.com/maths/<b>inverse-functions</b>", "snippet": "Inverse Rational <b>Function</b>. A rational <b>function</b> is a <b>function</b> of form f(x) = P(x)/Q(x) where Q(x) \u2260 0. To find the inverse of a rational <b>function</b>, follow the following steps. An example is also given below which can help you to understand the concept better. Step 1: Replace f(x) = y; Step 2: Interchange x and y; Step 3: Solve for y in terms of x", "dateLastCrawled": "2022-02-03T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Math Functions in C#</b> | Properties | <b>Functions in</b> Math C#", "url": "https://www.educba.com/math-functions-in-c-sharp/", "isFamilyFriendly": true, "displayUrl": "https://www.educba.com/<b>math-functions-in</b>-c-sharp", "snippet": "Note: Note that this is different from Round <b>function</b>. The round <b>function</b> returns an integer nearest to the number. It may be an integer greater than the number itself. Whereas, Truncate <b>function</b> would always return the integer part of the number as is. E.g. \u2013 Round(4.9) results in 5. Truncate(4.9) results in 4.", "dateLastCrawled": "2022-02-03T05:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is a <b>Function</b>", "url": "https://www.mathsisfun.com/sets/function.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mathsisfun.com</b>/sets/<b>function</b>.htm", "snippet": "At the top we said that a <b>function</b> was <b>like</b> a machine. But a <b>function</b> doesn&#39;t really have belts or cogs or any moving parts - and it doesn&#39;t actually destroy what we put into it! A <b>function</b> relates an input to an output. Saying &quot;f(4) = 16&quot; <b>is like</b> saying 4 is somehow related to 16. Or 4 \u2192 16. Example: this tree grows 20 cm every year, so the height of the tree is related to its age using the <b>function</b> h: h(age) = age \u00d7 20. So, if the age is 10 years, the height is: h(10) = 10 \u00d7 20 = 200 ...", "dateLastCrawled": "2022-02-02T06:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Approximation of Inverse <b>Q-Function</b> | Download Scientific Diagram", "url": "https://www.researchgate.net/figure/Approximation-of-Inverse-Q-Function_fig4_233947091", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/Approximation-of-Inverse-<b>Q-Function</b>_fig4_233947091", "snippet": "Although there are many <b>Q-function</b> approximations available in the literature for the problem, for example [22] [23] [24][25][26][27][28][29], we will use the <b>Q-function</b> approximation recently ...", "dateLastCrawled": "2022-01-20T09:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>6. Functions</b> - Q for Mortals", "url": "https://code.kx.com/q4m3/6_Functions/", "isFamilyFriendly": true, "displayUrl": "https://code.kx.com/q4m3/<b>6_Functions</b>", "snippet": "Application of a <b>function</b> is the process of evaluating the expressions in sequence, substituting actual arguments for any formal parameters. The result of the evaluation, should there be one, is the <b>function</b>&#39;s output value. Because a <b>q function</b> can modify global variables, q is not a pure functional language. A mathematical <b>function</b> can never ...", "dateLastCrawled": "2022-02-02T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "On Ramanujan&#39;s <b>Q-function</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/0377042793E0258N", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/0377042793E0258N", "snippet": "On Ramanujan&#39;s <b>Q-function</b> ... This study provides a detailed analysis of a <b>function</b> which Knuth discovered to play a central r\u00f4le in the analysis of hashing with linear probing. The <b>function</b>, named after Knuth Q(n), is related to several of Ramanujan&#39;s investigations. It surfaces in the analysis of a variety of algorithms and discrete probability problems including hashing, the birthday paradox, random mapping statistics, the \u201crho\u201d method for integer factorization, union-find algorithms ...", "dateLastCrawled": "2022-01-04T08:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is Q-<b>learning with respect to reinforcement</b> ... - <b>Tutorialspoint</b>", "url": "https://www.tutorialspoint.com/what-is-q-learning-with-respect-to-reinforcement-learning-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://<b>www.tutorialspoint.com</b>/what-is-q-<b>learning-with-respect-to-reinforcement</b>...", "snippet": "Q-learning is a type of reinforcement learning algorithm that contains an \u2018agent\u2019 that takes actions required to reach the optimal solution. Reinforcement learning is a part of the \u2018semi-supervised\u2019 machine learning algorithms. When an input dataset is provided to a reinforcement learning algorithm, it learns from such a dataset ...", "dateLastCrawled": "2022-01-30T15:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Inverse <b>Function</b> (Definition and Examples)", "url": "https://byjus.com/maths/inverse-functions/", "isFamilyFriendly": true, "displayUrl": "https://byjus.com/maths/<b>inverse-functions</b>", "snippet": "Inverse Rational <b>Function</b>. A rational <b>function</b> is a <b>function</b> of form f (x) = P (x)/Q (x) where Q (x) \u2260 0. To find the inverse of a rational <b>function</b>, follow the following steps. An example is also given below which can help you to understand the concept better. Step 1: Replace f (x) = y. Step 2: Interchange x and y.", "dateLastCrawled": "2022-02-03T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>On some properties of the Marcum Q function</b>", "url": "https://www.researchgate.net/publication/233152406_On_some_properties_of_the_Marcum_Q_function", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/.../233152406_<b>On_some_properties_of_the_Marcum_Q_function</b>", "snippet": "<b>Mathematics</b> Subject Classi\ufb01cation: 33E20. The generalized Marcum <b>Q function</b> is de\ufb01ned by the integral. Q \u03bd (a, b) = 1. a \u03bd \u2212 1 \u221e. b. x \u03bd e \u2212 (x 2 + a 2 )/ 2 I \u03bd \u2212 1 (ax ) d x, (1 ...", "dateLastCrawled": "2022-02-01T15:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "calculus - <b>Doubt about Q function</b> - <b>Mathematics</b> Stack Exchange", "url": "https://math.stackexchange.com/questions/3702599/doubt-about-q-function", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/3702599/<b>doubt-about-q-function</b>", "snippet": "Use an example in your book with a <b>similar</b> problem for orientation. Usually, there is a small diagram on the table with a shaded area to let you know what probabilities are in the body of your table.] If you use statistical software, you can get a more exact answer. Here is how to use R to get the exact answer $0.1855467:$", "dateLastCrawled": "2021-12-23T16:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is a <b>Function</b>", "url": "https://www.mathsisfun.com/sets/function.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mathsisfun.com</b>/sets/<b>function</b>.htm", "snippet": "a <b>function</b> relates inputs to outputs. a <b>function</b> takes elements from a set (the domain) and relates them to elements in a set (the codomain ). all the outputs (the actual values related to) are together called the range. a <b>function</b> is a special type of relation where: every element in the domain is included, and.", "dateLastCrawled": "2022-02-02T06:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Error and Complementary Error Functions", "url": "http://www.mhtlab.uwaterloo.ca/courses/me755/web_chap2.pdf", "isFamilyFriendly": true, "displayUrl": "www.mhtlab.uwaterloo.ca/courses/me755/web_chap2.pdf", "snippet": "Gaussian <b>Function</b> The Gaussian <b>function</b> or the Gaussian probability distribution is one of the most fundamen-tal functions. The Gaussian probability distribution with mean and standard deviation \u02d9 is a normalized Gaussian <b>function</b> of the form G(x) = 1 p 2\u02c7\u02d9 e (x )2=(2\u02d92) (1.1) where G(x), as shown in the plot below, gives the probability that a variate with a Gaussian distribution takes on a value in the range [x;x+ dx]. Statisticians commonly call this distribution the normal ...", "dateLastCrawled": "2022-02-03T11:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Operations with Functions", "url": "https://www.mathsisfun.com/sets/functions-operations.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mathsisfun.com</b>/sets/<b>functions</b>-operations.html", "snippet": "The result is a new <b>function</b>. Let us try doing those operations on f(x) and g(x): Addition: We can add two functions: (f+g)(x) = f(x) + g(x) Note: we put the f+g inside to show they both work on x. Example: f(x) = 2x+3 and g(x) = x 2 (f+g)(x) = (2x+3) + (x 2) = x 2 +2x+3. Sometimes we may need to combine like terms: Example: v(x) = 5x+1, w(x) = 3x-2 (v+w)(x) = (5x+1) + (3x-2) = 8x-1. The only other thing to worry about is the Domain (the set of numbers that go into the <b>function</b>), but I will ...", "dateLastCrawled": "2022-02-02T15:10:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>6. Functions</b> - Q for Mortals", "url": "https://code.kx.com/q4m3/6_Functions/", "isFamilyFriendly": true, "displayUrl": "https://code.kx.com/q4m3/<b>6_Functions</b>", "snippet": "Before diving in, you may wish to review the <b>Mathematics</b> Refresher in Chapter 0 for the approach and terminology we adopt. We describe various built-in functions along the way in this tutorial. Sometimes we shall use a built-in <b>function</b> with minimal explanation; simply look it up in Appendix A, which contains specifics and examples of nearly all the q built-in functions. 6.1 <b>Function</b> Specification\u00b6 The notion of a <b>function</b> in q corresponds to a (mathematical) map that is specified by an ...", "dateLastCrawled": "2022-02-02T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Integrals involving Gaussian <b>Q function</b> - <b>Mathematics</b> Stack Exchange", "url": "https://math.stackexchange.com/questions/3491489/integrals-involving-gaussian-q-function", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/3491489/integrals-involving-gaussian-<b>q-function</b>", "snippet": "I am trying to find the following definite integral: I = \u222b 0 b Q ( ( b \u2212 x) a) x \u03c3 2 exp. \u2061. ( \u2212 x 2 2 \u03c3 2) d x, where a, b, \u03c3 2 are some positive constants, and Q ( u) = \u222b u + \u221e exp. \u2061. ( \u2212 t 2 / 2) 2 \u03c0 d t is the Gaussian <b>Q function</b>. I have tried to use integration by parts and use some table of integrals to solve it but ...", "dateLastCrawled": "2022-01-08T02:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Some Integrals Involving The <b>Q Function</b> Dtic", "url": "https://www.fortifyprogram.org/some-integrals-involving-the-q-function-dtic-pdf", "isFamilyFriendly": true, "displayUrl": "https://www.fortifyprogram.org/some-integrals-involving-the-<b>q-function</b>-dtic-pdf", "snippet": "Read PDF Some Integrals Involving The <b>Q Function</b> Dtic A massive compendium of useful information, this volume represents a valuable tool for applied mathematicians in many areas of academia and industry. A dozen useful tables supplement the text. 1962 edition. Integrals of Bessel Functions", "dateLastCrawled": "2022-02-01T12:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Some Integrals Involving The <b>Q Function</b> Dtic", "url": "https://vs3.nagios.org/some-integrals-involving-the-q-function-dtic-pdf", "isFamilyFriendly": true, "displayUrl": "https://vs3.nagios.org/some-integrals-involving-the-<b>q-function</b>-dtic-pdf", "snippet": "Read PDF Some Integrals Involving The <b>Q Function</b> Dtic session in honor of Leonard Gross held at the annual Joint <b>Mathematics</b> Meetings in New Orleans (LA). The speakers were specialists in a variety of fields, and many were Professor Gross&#39; former Ph.D. students and their descendants. Papers in this volume present results from", "dateLastCrawled": "2022-01-21T20:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Some Integrals Involving The <b>Q Function</b> Dtic", "url": "https://www.fortifyprogram.org/some%20integrals%20involving%20the%20q%20function%20dtic%20pdf", "isFamilyFriendly": true, "displayUrl": "https://www.fortifyprogram.org/some integrals involving the q <b>function</b> dtic pdf", "snippet": "Download Free Some Integrals Involving The <b>Q Function</b> Dtic Irresistible Integrals This book contains the proceedings of the special session in honor of Leonard Gross held at the annual Joint <b>Mathematics</b> Meetings in New Orleans (LA). The speakers were specialists in a variety of fields, and many were Professor Gross&#39; former Ph.D. students and their descendants. Papers in this volume present results from several areas of <b>mathematics</b>. They illustrate applications of powerful ideas that ...", "dateLastCrawled": "2022-01-19T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Some Integrals Involving The <b>Q Function</b> Dtic", "url": "https://opinionua.com/some-integrals-involving-the-q-function-dtic-pdf", "isFamilyFriendly": true, "displayUrl": "https://opinionua.com/some-integrals-involving-the-<b>q-function</b>-dtic-pdf", "snippet": "Bell able to do something with it. O. Heaviside <b>Mathematics</b> is a tool for <b>thought</b>. A highly necessary tool in a world where both feedback and non linearities abound. Similarly, all kinds of parts of <b>mathematics</b> serve as tools for other parts and for other sciences. Applying a simple rewriting rule to", "dateLastCrawled": "2022-01-18T10:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Some Integrals Involving The <b>Q Function</b> Dtic", "url": "https://stores.btech.eg/some-integrals-involving-the-q-function-dtic-pdf", "isFamilyFriendly": true, "displayUrl": "https://stores.btech.eg/some-integrals-involving-the-<b>q-function</b>-dtic-pdf", "snippet": "<b>Mathematics</b> Class 12 with Objective Questions &amp; 3 Sample Papers 3rd EditionReport of the Annual MeetingIndian Science AbstractsZeta and q-Zeta Functions and Associated Series and IntegralsConference RecordOperator-Valued Measures and Integrals for Cone-Valued FunctionsProgramma van de plechtige godsdienstoefening ter herdenking van het honderdvijftigjarig bestaan der synagoge aan de Uilenburgerstraat, van de Ned. Isr. Hoofdsynagoge te Amsterdam op Vrijdag 22. September 1916, des Middags te 5 ...", "dateLastCrawled": "2022-01-20T18:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Mathematics</b>-08-01640 - <b>mathematics</b> Review Comprehensive Review of Deep ...", "url": "https://www.studocu.com/in/document/university-of-lucknow/computer-system-security/mathematics-08-01640/11317653", "isFamilyFriendly": true, "displayUrl": "https://www.studocu.com/.../computer-system-security/<b>mathematics</b>-08-01640/11317653", "snippet": "The easy way of estimating the <b>Q-function</b> is to exchange it with a cumulative return from entire trajectories. A value-based method such as the actor-critic method <b>can</b> be used to estimate the return efficiently. In general, an entropy <b>function</b> <b>can</b> be used for the policy randomness and efficient exploration purpose. Additionally, it is common to employ an advantage value <b>function</b> where conducts a measurement of comparison to the expected return for each action. In practice, this replacement ...", "dateLastCrawled": "2022-01-31T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "An Intuitive Explanation of <b>Policy Gradient</b> | by Adrien Lucas Ecoffet ...", "url": "https://towardsdatascience.com/an-intuitive-explanation-of-policy-gradient-part-1-reinforce-aa4392cbfd3c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-intuitive-explanation-of-<b>policy-gradient</b>-part-1...", "snippet": "Indeed, this is very similar to the <b>Q function</b> that we know from Q-Learning, though there is a subtle and important difference that will make it easier to learn and that we will learn about later. For now, let\u2019s just assume that this <b>Q function</b> is a given. We get the following gradient ascent update, that we <b>can</b> now apply to each action in turn instead of just to the optimal action: Let\u2019s weigh our updates to the simulated <b>policy gradient</b> using a noisy version of the Q values of the ...", "dateLastCrawled": "2022-02-03T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "[SOLVED] Convolution of L^p and L^<b>q function</b> is uniformly continuous or ...", "url": "https://www.mathematics-master.com/question/convolution-of-l-p-and-l-q-function-is-uniformly-continuous-or-not", "isFamilyFriendly": true, "displayUrl": "https://www.<b>mathematics</b>-master.com/question/convolution-of-l-p-and-l-<b>q-function</b>-is...", "snippet": "Convolution of L^p and L^<b>q function</b> is uniformly continuous or not? This is a homework question (the due date has passed) and I have been thinking of it for a while. We are asked to prove or disprove the following statement:", "dateLastCrawled": "2021-12-07T05:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "An <b>introduction to Q-Learning: reinforcement learning</b>", "url": "https://www.freecodecamp.org/news/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc/", "isFamilyFriendly": true, "displayUrl": "https://www.freecodecamp.org/news/an-<b>introduction-to-q-learning-reinforcement-learning</b>...", "snippet": "<b>Mathematics</b>: the Q-Learning algorithm <b>Q-function</b>. The <b>Q-function</b> uses the Bellman equation and takes two inputs: state (s) and action (a). Using the above <b>function</b>, we get the values of Q for the cells in the table. When we start, all the values in the Q-table are zeros. There is an iterative process of updating the values. As we start to explore the environment, the <b>Q-function</b> gives us better and better approximations by continuously updating the Q-values in the table. Now, let\u2019s ...", "dateLastCrawled": "2022-02-02T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The <b>Bellman Equation</b>. V-<b>function</b> and <b>Q-function</b> Explained | by Jordi ...", "url": "https://towardsdatascience.com/the-bellman-equation-59258a0d3fa7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-<b>bellman-equation</b>-59258a0d3fa7", "snippet": "The <b>Q-function</b>: The value of the action. In post 2 we extended the definition of state-value <b>function</b> to state-action pairs, defining a value for each state-action pair, which is called the action-value <b>function</b>, also known as <b>Q-function</b> or simply Q. It defines the value of taking action a in state s under a policy \u03c0, denoted by Q\ud835\udf0b(\ud835\udc60,\ud835\udc4e), as the expected Return G starting from s, taking the action \ud835\udc4e, and thereafter following policy \u03c0: In this <b>equation</b> again it is used ...", "dateLastCrawled": "2022-02-03T05:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Approximation of Inverse <b>Q-Function</b> | Download Scientific Diagram", "url": "https://www.researchgate.net/figure/Approximation-of-Inverse-Q-Function_fig4_233947091", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/Approximation-of-Inverse-<b>Q-Function</b>_fig4_233947091", "snippet": "Although there are many <b>Q-function</b> approximations available in the literature for the problem, for example [22] [23] [24][25][26][27][28][29], we will use the <b>Q-function</b> approximation recently ...", "dateLastCrawled": "2022-01-20T09:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Class of tight bounds on the <b>Q\u2010function</b> <b>with closed\u2010form upper bound on</b> ...", "url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/mma.5555", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/mma.5555", "snippet": "In this paper, we propose a novel class of parametric bounds on the <b>Q \u2010function</b>, which are lower bounds for 1 \u2264 a &lt; 3 and x &gt; x t = (a (a \u20101) / (3\u2010a )) 1/2, and upper bound for a = 3. We prove that the lower and upper bounds on the <b>Q \u2010function</b> <b>can</b> have the same analytical form that is asymptotically equal, which is a unique feature of our class of tight bounds.", "dateLastCrawled": "2020-05-26T13:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>A Simple Polynomial Approximation to the Gaussian</b> <b>Q-function</b> and Its ...", "url": "https://www.researchgate.net/publication/220302960_A_Simple_Polynomial_Approximation_to_the_Gaussian_Q-function_and_Its_Application", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220302960_A_Simple_Polynomial_Approximation...", "snippet": "Sami Muhaidat. Ibrahim Abualhaol. In this paper, a novel approximation for the Gaussian <b>Q-function</b> in the form of Q (\u221ax) is presented. The proposed approximation is <b>compared</b> with other known ...", "dateLastCrawled": "2022-01-15T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Class of tight bounds on the <b>Q\u2010function</b> with closed\u2010form upper bound on ...", "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/mma.5555", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/abs/10.1002/mma.5555", "snippet": "In this paper, we propose a novel class of parametric bounds on the <b>Q-function</b>, which are lower bounds for 1 \u2264 a &lt; 3 and x &gt; x t = (a (a-1) / (3-a)) 1/2, and upper bound for a = 3. We prove that the lower and upper bounds on the <b>Q -function</b> <b>can</b> have the same analytical form that is asymptotically equal, which is a unique feature of our class of tight bounds.", "dateLastCrawled": "2021-05-26T23:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>6. Functions</b> - Q for Mortals", "url": "https://code.kx.com/q4m3/6_Functions/", "isFamilyFriendly": true, "displayUrl": "https://code.kx.com/q4m3/<b>6_Functions</b>", "snippet": "The result of the evaluation, should there be one, is the <b>function</b>&#39;s output value. Because a <b>q function</b> <b>can</b> modify global variables, q is not a pure functional language. A mathematical <b>function</b> <b>can</b> never reach outside its own body and have side effects. You should minimize such behavior for code maintainability. 6.1.1 <b>Function</b> Definition\u00b6", "dateLastCrawled": "2022-02-02T12:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Highly Accurate Analytic Approximation to the Gaussian <b>Q-function</b> Based ...", "url": "https://www.deepdyve.com/lp/springer-journals/highly-accurate-analytic-approximation-to-the-gaussian-q-function-QuySKa5rAl", "isFamilyFriendly": true, "displayUrl": "https://www.deepdyve.com/lp/springer-journals/highly-accurate-analytic-approximation...", "snippet": "In this paper, as an extension of a previous study, an improved approximation for the Gaussian <b>Q-function</b> is presented. The nonlinear least squares algorithm is employed to optimize the coefficients of the proposed approximation. The accuracy of the presented approximation is evaluated using extensive computer simulations. Results show that the proposed approximation has superior accuracy in high arguments\u2019 region when <b>compared</b> to the performance of other approaches introduced in the ...", "dateLastCrawled": "2021-11-25T11:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "New inequalities of Mill&#39;s ratio and Its Application to The Inverse Q ...", "url": "https://www.arxiv-vanity.com/papers/1212.4899/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1212.4899", "snippet": "In this paper, we investigate the Mill\u2019s ratio estimation problem and get two new inequalities. <b>Compared</b> to the well known results obtained by Gordon, they becomes tighter. Furthermore, we also discuss the inverse <b>Q-function</b> approximation problem and present some useful results on the inverse solution. Numerical results confirm the validness of our theoretical analysis. In addition, we also present a conjecture on the bounds of inverse solution on <b>Q-function</b>.", "dateLastCrawled": "2021-12-30T17:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>ERROR PROBABILITY</b> IN BPSK | what is <b>error probability</b> of bpsk formula ...", "url": "https://www.sbistudy.com/error-probability-in-bpsk/", "isFamilyFriendly": true, "displayUrl": "https://www.sbistudy.com/<b>error-probability</b>-in-bpsk", "snippet": "The expression in equation (8.126) <b>can</b> also be expressed in terms of the <b>Q function</b> as under: P e = Q This is because the relation between erfc and <b>Q function</b> is given by Q(x) = and NOTE Let us compare equations (7.126) and (7.117). The `erfc\u2019 <b>function</b> is a monotonic decreasing <b>function</b>. Therefore, the value of erfc is less than erfc Hence ...", "dateLastCrawled": "2022-02-01T01:49:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "An <b>introduction to Q-Learning: Reinforcement Learning</b>", "url": "https://blog.floydhub.com/an-introduction-to-q-learning-reinforcement-learning/", "isFamilyFriendly": true, "displayUrl": "https://blog.floydhub.com/an-<b>introduction-to-q-learning-reinforcement-learning</b>", "snippet": "In this article, we are going to step into the world of reinforcement <b>learning</b>, another beautiful branch of artificial intelligence, which lets machines learn on their own in a way different from traditional <b>machine</b> <b>learning</b>. Particularly, we will be covering the simplest reinforcement <b>learning</b> algorithm i.e. the Q-<b>Learning</b> algorithm in great detail.", "dateLastCrawled": "2022-01-31T09:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "<b>Q-function</b>: input the state-atcion pair, output the Q-value. The letter \u201cQ\u201d is used to represent the quality of taking a given action in a given state. Q-<b>learning</b>. It is used for <b>learning</b> the optimal policy by <b>learning</b> the optimal Q-values for each state-action pair in a Markov Decision Process", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Relationship between state (V) and action(Q) value function in ...", "url": "https://medium.com/intro-to-artificial-intelligence/relationship-between-state-v-and-action-q-value-function-in-reinforcement-learning-bb9a988c0127", "isFamilyFriendly": true, "displayUrl": "https://medium.com/intro-to-artificial-intelligence/relationship-between-state-v-and...", "snippet": "Value function can be defined as the expected value of an agent in a certain state. There are two types of value functions in RL: State-value and action-value. It is important to understand the\u2026", "dateLastCrawled": "2022-02-03T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>GitHub</b> - gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "<b>Q-function</b>: input the state-atcion pair, output the Q-value. The letter \u201cQ\u201d is used to represent the quality of taking a given action in a given state. Q-<b>learning</b>. It is used for <b>learning</b> the optimal policy by <b>learning</b> the optimal Q-values for each state-action pair in a Markov Decision Process", "dateLastCrawled": "2021-09-12T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "IERG 5350 Reinforcement <b>Learning</b> Lecture 1: Course Overview", "url": "https://cuhkrlcourse.github.io/slides/2021_ierg5350_lecture1.pdf", "isFamilyFriendly": true, "displayUrl": "https://cuhkrlcourse.github.io/slides/2021_ierg5350_lecture1.pdf", "snippet": "Why deep reinforcement <b>learning</b>? \u2022<b>Analogy</b> to traditional CV and deep CV. Why deep reinforcement <b>learning</b>? \u2022Standard RL and deep RL Approximators for value function, <b>Q-function</b>, policy networks TD-Gammon, 1995 game of backgammon. Why RL works now? \u2022One of the most exciting areas in <b>machine</b> <b>learning</b> Game playing Robotics Beating best human player Playing Atari with Deep Reinforcement <b>Learning</b> Mastering the game of Go without Human Knowledge. Why RL works now? \u2022Computation power: many ...", "dateLastCrawled": "2022-01-29T19:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine Learning Gist</b> \u00b7 GitHub", "url": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "snippet": "Orthogonalization - Adjust one knob to adjust one parameter, to solve one problem - The TV knob <b>analogy</b> and the car <b>analogy</b>. Chain of assumptions in <b>Machine</b> <b>Learning</b> and different knobs to say improve performance on train/dev set. Andrew Ng does not recommend Early stopping, as it is a knob that affects multiple thing at once. Setting up your goal", "dateLastCrawled": "2022-01-29T03:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "On using Huber loss in (Deep) Q-<b>learning</b> | \u30e4\u30ed\u30df\u30eb", "url": "https://jaromiru.wordpress.com/2017/05/27/on-using-huber-loss-in-deep-q-learning/", "isFamilyFriendly": true, "displayUrl": "https://jaromiru.wordpress.com/2017/05/27/on-using-huber-loss-in-deep-q-<b>learning</b>", "snippet": "<b>MACHINE</b> <b>LEARNING</b> &amp; AI. Menu. Let\u2019s make a DQN. Theory; Implementation; Debugging; Full DQN; Double <b>Learning</b> and Prioritized Experience Replay; Let\u2019s make an A3C. Theory ; Implementation; About me; On using Huber loss in (Deep) Q-<b>learning</b>. Posted on May 27, 2017 May 30, 2017 by \u30e4\u30ed\u30df\u30eb. I\u2019ve been recently working on a problem where I put a plain DQN to use. The problem is very simple, deterministic, partially observable and states are quite low-dimensional. The agent however can ...", "dateLastCrawled": "2021-12-26T09:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) The <b>machine learning in software project management: A journey</b> ...", "url": "https://www.researchgate.net/publication/289958721_The_machine_learning_in_software_project_management_A_journey_Part_II", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/289958721_The_<b>machine</b>_<b>learning</b>_in_software...", "snippet": "The <b>machine learning in software project management: A journey</b>. Part I. Software Project Management (SPM) is the most important and toughest job in software engineering organizations. For ...", "dateLastCrawled": "2021-12-07T16:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Why doesn&#39;t <b>Q-learning</b> converge when using function approximation ...", "url": "https://ai.stackexchange.com/questions/11679/why-doesnt-q-learning-converge-when-using-function-approximation", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/11679/why-doesnt-<b>q-learning</b>-converge-when-using...", "snippet": "$\\begingroup$ @nbro The proof doesn&#39;t say that explicitly, but it assumes an exact representation of the <b>Q-function</b> (that is, that exact values are computed and stored for every state/action pair). For infinite state spaces, it&#39;s clear that this exact representation can be infinitely large in the worst case (simple example: let Q(s,a) = sth digit of pi).", "dateLastCrawled": "2022-01-28T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Applications of <b>Reinforcement Learning</b> in Real World | by garychl ...", "url": "https://towardsdatascience.com/applications-of-reinforcement-learning-in-real-world-1a94955bcd12", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/applications-of-<b>reinforcement-learning</b>-in-real-world-1a...", "snippet": "<b>Reinforcement Learning</b> is a very general framework for <b>learning</b> sequential decision making tasks. And Deep <b>Learning</b>, on the other hand, is of course the best set of algorithms we have to learn representations. And combinations of these two different models is the best answer so far we have in terms of <b>learning</b> very good state representations of very challenging tasks that are not just for solving toy domains but actually to solve challenging real world problems.\u201d", "dateLastCrawled": "2022-02-02T20:37:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Using <b>Keras and Deep Q-Network to Play FlappyBird</b> | Ben Lau", "url": "https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html", "isFamilyFriendly": true, "displayUrl": "https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html", "snippet": "You just follow the guidiance from the strategy book. Here, <b>Q-function is similar</b> to a strategy guide. Suppose you are in state s and you need to decide whether you take action a or b. If you have this magical Q-function, the answers become really simple \u2013 pick the action with highest Q-value! Here, represents the policy, which you will often see in the ML literature. How do we get the Q-function? That\u2019s where Q-<b>learning</b> is coming from. Let me quickly derive here: Define total future ...", "dateLastCrawled": "2022-01-30T05:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Learn to Make Decision <b>with Small Data for Autonomous Driving: Deep</b> ...", "url": "https://www.hindawi.com/journals/jat/2020/8495264/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/jat/2020/8495264", "snippet": "GP is a Bayesian nonparametric <b>machine</b> <b>learning</b> framework for regression, classification, and unsupervised <b>learning</b> . A GP ... In addition, the <b>learning</b> method of <b>Q function is similar</b> to that in DQN as well. In our case, we train a deep neural network by DDPG to achieve successful loop trip. It takes about 16 hours and 4000 episodes to achieve a high performance deep neural network. And tens of thousands of data will be updated in the centralized experience replay buffer during training ...", "dateLastCrawled": "2022-01-22T01:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Efficient Navigation of Colloidal Robots in an Unknown Environment via ...", "url": "https://onlinelibrary.wiley.com/doi/10.1002/aisy.201900106", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1002/aisy.201900106", "snippet": "In free space navigation (Figure 2a), the navigation strategy derived from the learned optimal <b>Q* function is similar</b> to previous studies 18, 43, 44 and can be summarized approximately as \u03c0 * (s) = {v max, d n \u2208 [d c, \u221e) v max, d n \u2208 [0, d c), \u03b1 n \u2208 [\u2212 \u03b1 c, \u03b1 c] 0, otherwise (3) where d n is the projection of the target-particle vector onto the orientation vector n = (cos\u03b8, sin\u03b8), \u03b1 n is the angle between target-particle distance vector and n, and parameters d c and \u03b1 c are ...", "dateLastCrawled": "2022-01-20T08:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Adapting Soft Actor Critic for Discrete Action Spaces | by Felix ...", "url": "https://towardsdatascience.com/adapting-soft-actor-critic-for-discrete-action-spaces-a20614d4a50a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/adapting-soft-actor-critic-for-discrete-action-spaces-a...", "snippet": "This should accelerate <b>learning</b> in the later stages of training and help with avoiding local optima. Just as before we want to find \u03b8 that optimizes the expected return. To do so in the entropy regularized setting we can simply add an estimate of the entropy to our estimate of the expected return: Entropy Regularized Actor Cost Function. Figure 7: Entropy regularized critic cost functions. How we adapt the Bellman equation for our <b>Q-function is similar</b> to what we have seen in the definition ...", "dateLastCrawled": "2022-02-03T12:06:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep Reinforcement <b>Learning</b> for Agriculture: Principles and Use Cases ...", "url": "https://link.springer.com/chapter/10.1007/978-981-16-5847-1_4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-981-16-5847-1_4", "snippet": "In other words, the Q-function captures the expected total future rewards agent i can receive in state s t by taking action a t. <b>Q-function can be thought of as</b> a table look up, where rows of the table are states s and columns represent actions a.Ultimately, the <b>learning</b> agent i needs to find the best action given current state s.This is called a policy \u03c0(s).Policy captures the <b>learning</b> agent&#39;s behavior at any given time.", "dateLastCrawled": "2022-01-27T09:13:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(q-function)  is like +(function in mathematics)", "+(q-function) is similar to +(function in mathematics)", "+(q-function) can be thought of as +(function in mathematics)", "+(q-function) can be compared to +(function in mathematics)", "machine learning +(q-function AND analogy)", "machine learning +(\"q-function is like\")", "machine learning +(\"q-function is similar\")", "machine learning +(\"just as q-function\")", "machine learning +(\"q-function can be thought of as\")", "machine learning +(\"q-function can be compared to\")"]}