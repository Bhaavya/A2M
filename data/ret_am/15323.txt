{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What Are <b>Bounding</b> Boxes? An Easy Overview in 2021", "url": "https://www.jigsawacademy.com/blogs/ai-ml/bounding-box", "isFamilyFriendly": true, "displayUrl": "https://www.jigsawacademy.com/blogs/ai-ml/<b>bounding</b>-<b>box</b>", "snippet": "A <b>bounding</b> <b>box</b> is an abstract rectangle that acts as a reference point for object detection and produces a collision <b>box</b> for that object. These rectangles are drawn over images by data annotators, who identify the X and Y coordinates of the point of interest within each image. This helps machine learning algorithms find what they\u2019re looking for, evaluate collision paths, and saves precious computational power. In deep learning, <b>bounding</b> boxes are one of the most commonly used image ...", "dateLastCrawled": "2022-01-18T16:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "how to get <b>Bounding Box</b> of <b>room</b> element when it is in 3d? - <b>Autodesk</b> ...", "url": "https://forums.autodesk.com/t5/revit-api-forum/how-to-get-bounding-box-of-room-element-when-it-is-in-3d/td-p/9732508", "isFamilyFriendly": true, "displayUrl": "https://<b>forums.autodesk.com</b>/t5/revit-api-forum/how-to-get-<b>bounding-box</b>-of-<b>room</b>-element...", "snippet": "BoundingBoxXYZ <b>boundingBox</b> = <b>room</b>.get_<b>BoundingBox</b>(revitDocument.ActiveView); In 2D min,max are (52.255591027, 17.974775141, 50.196850394)} {(60.255591027, 23.974775141, 57.102362205) min,max are important in my case because calculating <b>room</b> size by this. as whole purpose of getting <b>bounding box</b> to get <b>room</b> size.", "dateLastCrawled": "2022-02-02T16:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Introduction to <b>bounding</b> <b>box</b> annotation: Best practices", "url": "https://blog.superannotate.com/introduction-to-bounding-box-annotation-best-practices/", "isFamilyFriendly": true, "displayUrl": "https://blog.superannotate.com/introduction-to-<b>bounding</b>-<b>box</b>-annotation-best-practices", "snippet": "<b>Bounding</b> <b>box</b> annotated images advance the object detection of visual perception models by spotting targets across multiple industries. The latter ones keep expanding, opening up <b>room</b> for wider applications of <b>bounding</b> boxes and adding up to the list of precautions when annotating data. We hope this article provided you with a basic understanding of how this annotation technique facilitates object detection. Let us know if we can be of further help.", "dateLastCrawled": "2022-02-02T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "What is <b>Bounding</b> <b>Box</b> Annotation, and why is It So Important? - The ...", "url": "https://www.europeanbusinessreview.com/what-is-bounding-box-annotation-and-why-is-it-so-important/", "isFamilyFriendly": true, "displayUrl": "https://www.europeanbusinessreview.com/what-is-<b>bounding</b>-<b>box</b>-annotation-and-why-is-it...", "snippet": "For starters, <b>Bounding</b> <b>Box</b> annotation is one of the primary forms of image annotation, where object-specific data is fed by outlining the entities in the first place. Put simply, <b>bounding</b> boxes are more <b>like</b> standard 2D rectangles that assist with referenced object detection in training Computer Vision models to perfection.", "dateLastCrawled": "2022-02-02T03:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>bounding</b> <b>box</b> - Revit <b>room</b> boundingbox and levels offset - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/59091459/revit-room-boundingbox-and-levels-offset", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/59091459", "snippet": "For our Revit addin (in c#), I need to get some <b>room</b> boundingbox (based on model values) For this I use element.Get_BoundingBox function, but it seems , the Z coordinates do not respect the base and limit offsets of the <b>room</b> for example, a <b>room</b> has a level to 0 coordinate, a base offest equal to -400.0, in this case the <b>box</b>.min.z value is 0 in place of -400.0", "dateLastCrawled": "2022-01-23T06:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Solved: Get <b>the door bounding box intersection with room</b> outline ...", "url": "https://forums.autodesk.com/t5/revit-api-forum/get-the-door-bounding-box-intersection-with-room-outline/td-p/8515875", "isFamilyFriendly": true, "displayUrl": "https://<b>forums.autodesk.com</b>/t5/revit-api-forum/get-<b>the-door-bounding-box-intersection</b>...", "snippet": "It doesn&#39;t need to be perfect, the <b>bounding</b> <b>box</b> outline at floor level will do. Just as simple as it can within reason. This is my guess at a plan of how to achieve this. 1. collect all doors interesecting a <b>room</b> to a list. 2. intersect the <b>room</b> outlines with the doors and get those points . 3. get the door facing direction, to get the offset direction for the points at the doors centre or wall centre. 4. make new segments with the first point of rm segment 1, first door intersect. half wall ...", "dateLastCrawled": "2021-12-22T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to get <b>bounding</b> boxes around rectangular rooms which are rotated by ...", "url": "https://www.mathworks.com/matlabcentral/answers/553138-how-to-get-bounding-boxes-around-rectangular-rooms-which-are-rotated-by-some-angle", "isFamilyFriendly": true, "displayUrl": "https://www.mathworks.com/matlabcentral/answers/553138-how-to-get-<b>bounding</b>-<b>box</b>es...", "snippet": "Can I get the <b>bounding</b> <b>box</b> around the rooms in floor plan . If it is not rotated, using regionprops(), I am able to get the <b>bounding</b> boxes. But if it is rotated, since the <b>bounding</b> <b>box</b> do not rotates, I am unable to get the <b>bounding</b> <b>box</b> around the rooms. I want to get the coordinates of those rooms. Is there any other way to get the coordinates of the rooms with/without using <b>bounding</b> <b>box</b> method?Or I sit possible to get the coordinates of the 4 line segments of each <b>room</b> which bound the ...", "dateLastCrawled": "2021-11-24T03:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Room</b> <b>walls that are non-bounding act like bounding in</b> Revit | Revit ...", "url": "https://knowledge.autodesk.com/support/revit/troubleshooting/caas/sfdcarticles/sfdcarticles/Revit-non-room-bounding-walls-act-like-they-are-room-bounding.html", "isFamilyFriendly": true, "displayUrl": "https://knowledge.autodesk.com/support/revit/troubleshooting/caas/sfdcarticles/sfdc...", "snippet": "Non-<b>room</b>-<b>bounding</b> walls in Revit act <b>like</b> they are <b>room</b> <b>bounding</b>. Use one of the solutions bellow. Refresh the <b>room</b>-<b>bounding</b> parameter to reset the behavior Select the wall. In Properties, check the <b>Room</b> <b>Bounding</b> <b>box</b>. Then deselect the <b>box</b>. The <b>room</b> boundary will then heal to include the area previously blocked by the wall. Reset the computation height of the level Open an elevation or section view. Select the level, and in Properties, change the computation height value", "dateLastCrawled": "2022-01-29T08:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to limit the map window to a <b>bounding</b> <b>box</b> for Mapbox/Maplibre | by ...", "url": "https://proandroiddev.com/how-to-limit-the-map-window-to-a-bounding-box-for-mapbox-maplibre-e504d3df1ae4", "isFamilyFriendly": true, "displayUrl": "https://proandroiddev.com/how-to-limit-the-map-window-to-a-<b>bounding</b>-<b>box</b>-for-map<b>box</b>...", "snippet": "<b>Bounding</b> <b>box</b> around Paris. Mapbox API does provide a method to limit the map view to a bbox. mapboxMap.setLatLngBoundsForCameraTarget(bounds) The full code can be found here.The demo can be tried from the Mapbox Demo app on the play store and then by going to Camera (in the side bar) then \u201cRestrict Map panning\u201d example.", "dateLastCrawled": "2022-02-02T15:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Room Bounding Check box for Linked files NOT working</b> - Revit Forum", "url": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general-revit-questions/17592-", "isFamilyFriendly": true, "displayUrl": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general...", "snippet": "<b>Room Bounding Check box for Linked files NOT working</b>. November 15, 2013, 07:45 PM. I&#39;m working with another architecture firm on a project, and we have three models that we&#39;re linking together to create our working drawings. I am controlling two of them (existing conditions and Core and Shell for the proposed structure) and they control the ...", "dateLastCrawled": "2022-01-26T08:25:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "What Are <b>Bounding</b> Boxes? An Easy Overview in 2021", "url": "https://www.jigsawacademy.com/blogs/ai-ml/bounding-box", "isFamilyFriendly": true, "displayUrl": "https://www.jigsawacademy.com/blogs/ai-ml/<b>bounding</b>-<b>box</b>", "snippet": "A <b>bounding</b> <b>box</b> is an abstract rectangle that acts as a reference point for object detection and produces a collision <b>box</b> for that object. These rectangles are drawn over images by data annotators, who identify the X and Y coordinates of the point of interest within each image. This helps machine learning algorithms find what they\u2019re looking for, evaluate collision paths, and saves precious computational power. In deep learning, <b>bounding</b> boxes are one of the most commonly used image ...", "dateLastCrawled": "2022-01-18T16:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Bounding</b> Boxes - DataGenetics", "url": "https://www.datagenetics.com/blog/march12014/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.datagenetics.com/blog/march12014/index.html", "snippet": "These types of problems are appropriately called \u2019<b>Bounding</b> <b>Box</b> ... to turn it clockwise or counter-clockwise, the calliper will need to move up to make <b>room</b> for one of the corners, that was flush on the bottom, to rotate. NOTE: There is a slightly different, but very <b>similar</b>, calculation sometimes used. This is the calculation of the shortest perimeter of the <b>bounding</b> <b>box</b>. The calliper algorithm is still used to generate the potential rectangles, but instead of minimizing the product of ...", "dateLastCrawled": "2022-02-01T21:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The Types of <b>Bounding</b> <b>Box</b>. | Download Scientific Diagram", "url": "https://www.researchgate.net/figure/The-Types-of-Bounding-Box_fig2_327640315", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/The-Types-of-<b>Bounding</b>-<b>Box</b>_fig2_327640315", "snippet": "Building on [60], the axis-aligned <b>bounding</b> <b>box</b> (AABB) and the oriented <b>bounding</b> <b>box</b> (OBB) are developed to isolate the RoI in the 2D enhanced matte. The AABB, whose axis is parallel to the ...", "dateLastCrawled": "2022-01-13T11:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Introduction to <b>bounding</b> <b>box</b> annotation: Best practices", "url": "https://blog.superannotate.com/introduction-to-bounding-box-annotation-best-practices/", "isFamilyFriendly": true, "displayUrl": "https://blog.superannotate.com/introduction-to-<b>bounding</b>-<b>box</b>-annotation-best-practices", "snippet": "Perception models trained on <b>similar</b> data can recognize objects like fashion items, pieces of furniture, skincare products, and so forth when labeled correctly. Here are several problems <b>bounding</b> <b>box</b> annotations address in retail: Incorrect search results: Incorrect catalog data leads to incorrect search results, and this can be a significant disadvantage given that searching is how customers bump into an eCommerce store. The continuous digitization process: All products need to be digitized ...", "dateLastCrawled": "2022-02-02T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>5 Uses of Bounding Boxes</b> - Outsource2india", "url": "https://blog.outsource2india.com/5-uses-of-bounding-boxes/", "isFamilyFriendly": true, "displayUrl": "https://blog.outsource2india.com/<b>5-uses-of-bounding-boxes</b>", "snippet": "<b>Bounding</b> <b>box</b> is much needed in object classification of images and to localize images for computer vision. It can also be used for semantic segmentation like retail clothing, autonomous vehicle driving, satellite imagers and furniture detection to name a few. Let us explore the different <b>uses of bounding boxes</b> image annotation and how it used for object detection and classification in various fields. <b>Bounding</b> boxes are used for object localization for autonomous vehicle driving <b>Bounding</b> ...", "dateLastCrawled": "2022-01-17T05:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Use Of <b>Bounding</b> Boxes in Image Annotation for Object Detection | by ...", "url": "https://medium.com/anolytics/the-use-of-bounding-boxes-in-image-annotation-for-object-detection-6371711eabba", "isFamilyFriendly": true, "displayUrl": "https://medium.com/anolytics/the-use-of-<b>bounding</b>-<b>box</b>es-in-image-annotation-for-object...", "snippet": "Indoor Objects Detection with <b>Bounding</b> Boxes. The use of <b>bounding</b> boxes is also very much high in detecting the indoor objects like furniture, tables, chairs, cupboards and electronic systems. For ...", "dateLastCrawled": "2022-01-19T21:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Drawing a <b>bounding</b> <b>box</b> <b>similar</b> to <b>box</b> collider - Unity Answers", "url": "https://answers.unity.com/questions/461588/drawing-a-bounding-box-similar-to-box-collider.html", "isFamilyFriendly": true, "displayUrl": "https://answers.unity.com/questions/461588/drawing-a-<b>bounding</b>-<b>box</b>-<b>similar</b>-to-<b>box</b>...", "snippet": "Help <b>Room</b>; META; Moderators. Topics; Questions; Users; Badges; Home / This post has been wikified, any user with enough reputation can edit it. 3. Question by seanlloydbooth \u00b7 May 22, 2013 at 10:06 PM \u00b7 collider area boundingbox. Drawing a <b>bounding</b> <b>box</b> <b>similar</b> to <b>box</b> collider. I&#39;m creating a script which spawns objects inside an area, and I&#39;d like to be able to see the area inside the editor <b>similar</b> to how I can see the bounds on a <b>box</b> collider. Is there a simple way of doing this? My ...", "dateLastCrawled": "2022-01-25T21:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Room</b> <b>bounding</b> property for walls - Revit Forum", "url": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general-revit-questions/13361-", "isFamilyFriendly": true, "displayUrl": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general...", "snippet": "The way I&#39;ve been able to get walls to default <b>to Room</b> <b>Bounding</b> is this: 1. Edit the Type Properties of the wall 2. Toggle the walls Function to be &quot;Exterior&quot; (which <b>Room</b> <b>Bounding</b> on by default). 3. Hit OK to save the setting. 4. Try placing that same wall to verify that the <b>Room</b> <b>Bounding</b> checkbox is still checked. 5. If it is, toggle the ...", "dateLastCrawled": "2022-01-29T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "keras - What model should I use for <b>bounding</b> <b>box</b> detection? - Data ...", "url": "https://datascience.stackexchange.com/questions/55014/what-model-should-i-use-for-bounding-box-detection", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/55014", "snippet": "There are 2 object detectors that are quite popular: Haar Cascade Classifier, introduced by Viola and Jones: available on OpenCV (Python, Java and C++) and on Matlab computer vision toolbox (and probably on many other languages) is a great model for when deep learning is not a option.. Yolo, You Only Look Once: It is a real-time object detector and classifier, it uses a DL CNN and if I am not mistaken has cows on it&#39;s training dataset (so you can use transfer learning).It is part of the ...", "dateLastCrawled": "2022-01-21T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Room boundary issues - not working suddenly for</b> new walls - Revit Forum", "url": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general-revit-questions/20767-", "isFamilyFriendly": true, "displayUrl": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general...", "snippet": "Rooms have stopped reading boundaries for any newly created or moved existing walls or <b>room</b> separation lines (which are all <b>room</b> <b>bounding</b> and were totally fine two days ago). e.g. if I create a new wall running midway through an existing <b>room</b>, the <b>room</b> will not adjust to the new boundaries. Neither if we moved one of the existing walls inwards or outwards, the <b>room</b> will not adjust to new boundaries and stay as per previous configuration.", "dateLastCrawled": "2022-01-15T03:57:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Quick Answer: What Is A <b>Bounding</b> <b>Box</b> - SeniorCare2Share", "url": "https://www.seniorcare2share.com/what-is-a-bounding-box/", "isFamilyFriendly": true, "displayUrl": "https://www.seniorcare2share.com/what-is-a-<b>bounding</b>-<b>box</b>", "snippet": "The <b>bounding</b> <b>box</b> is defined as the position of the voxels at the two opposite corners of the cuboid encompassing an image, when each voxel is assumed to have a single position (sometimes <b>thought</b> of as its centre) and no physical extent. What is <b>bounding</b> <b>box</b> Matlab? [ xlim , ylim ] = boundingbox( polyin ) returns the x and y bounds of the smallest rectangle enclosing a polyshape . xlim and ylim are two-element row vectors whose first elements correspond to the lower x and y bounds, and whose ...", "dateLastCrawled": "2022-01-17T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "What Are <b>Bounding</b> Boxes? An Easy Overview in 2021", "url": "https://www.jigsawacademy.com/blogs/ai-ml/bounding-box", "isFamilyFriendly": true, "displayUrl": "https://www.jigsawacademy.com/blogs/ai-ml/<b>bounding</b>-<b>box</b>", "snippet": "A <b>bounding</b> <b>box</b> is an abstract rectangle that acts as a reference point for object detection and produces a collision <b>box</b> for that object. These rectangles are drawn over images by data annotators, who identify the X and Y coordinates of the point of interest within each image. This helps machine learning algorithms find what they\u2019re looking for, evaluate collision paths, and saves precious computational power. In deep learning, <b>bounding</b> boxes are one of the most commonly used image ...", "dateLastCrawled": "2022-01-18T16:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Solved: Get <b>the door bounding box intersection with room</b> outline ...", "url": "https://forums.autodesk.com/t5/revit-api-forum/get-the-door-bounding-box-intersection-with-room-outline/td-p/8515875", "isFamilyFriendly": true, "displayUrl": "https://<b>forums.autodesk.com</b>/t5/revit-api-forum/get-<b>the-door-bounding-box-intersection</b>...", "snippet": "It doesn&#39;t need to be perfect, the <b>bounding</b> <b>box</b> outline at floor level will do. Just as simple as it <b>can</b> within reason. This is my guess at a plan of how to achieve this. 1. collect all doors interesecting a <b>room</b> to a list. 2. intersect the <b>room</b> outlines with the doors and get those points. 3. get the door facing direction, to get the offset direction for the points at the doors centre or wall centre. 4. make new segments with the first point of rm segment 1, first door intersect. half wall ...", "dateLastCrawled": "2021-12-22T02:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Box061: Sandcastles \u2013 The <b>Bounding</b> <b>Box</b>", "url": "https://blog.tobiasrevell.com/2022/01/17/box061-sandcastles/", "isFamilyFriendly": true, "displayUrl": "https://blog.tobiasrevell.com/2022/01/17/<b>box</b>061-sandcastles", "snippet": "The <b>Bounding</b> <b>Box</b>. Navigation #247 (no title) Box061: Sandcastles 17.01.22. DS061: A dimly lit <b>room</b> with three large frames in. Each frame contains a suspended weighted pendulum with a sandcastle bucket on one end. The bucket fills with sand from a pipe at the top of the frame then falls to the bottom where it \u2018drops\u2019 a sandcastle on a tray table at the bottom of the frame. The sand is pumped out of the tray table and back to the pipe at the top. The <b>room</b> also contains a folding chair and ...", "dateLastCrawled": "2022-01-17T09:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to limit the map window to a <b>bounding</b> <b>box</b> for Mapbox/Maplibre | by ...", "url": "https://proandroiddev.com/how-to-limit-the-map-window-to-a-bounding-box-for-mapbox-maplibre-e504d3df1ae4", "isFamilyFriendly": true, "displayUrl": "https://proandroiddev.com/how-to-limit-the-map-window-to-a-<b>bounding</b>-<b>box</b>-for-map<b>box</b>...", "snippet": "<b>Bounding</b> <b>box</b> around Paris. Mapbox API does provide a method to limit the map view to a bbox. mapboxMap.setLatLngBoundsForCameraTarget(bounds) The full code <b>can</b> be found here.The demo <b>can</b> be tried from the Mapbox Demo app on the play store and then by going to Camera (in the side bar) then \u201cRestrict Map panning\u201d example.", "dateLastCrawled": "2022-02-02T15:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to limit the map window to a <b>bounding</b> <b>box</b> for Mapbox/Maplibre ...", "url": "https://www.droidcon.com/2021/12/07/how-to-limit-the-map-window-to-a-bounding-box-for-mapbox-maplibre/", "isFamilyFriendly": true, "displayUrl": "https://www.droidcon.com/2021/12/07/how-to-limit-the-map-window-to-a-<b>bounding</b>-<b>box</b>-for...", "snippet": "The way this works is that only the center of the map is not allowed to leave the <b>bounding</b> <b>box</b>. You <b>can</b> see that the green dot is not allowed to leave the red <b>bounding</b> <b>box</b>. What I wanted is that the whole map never moves out of the red <b>bounding</b> <b>box</b> area itself since the area outside of that <b>bounding</b> <b>box</b> wont have any map data. On closer <b>thought</b>, I realised I needed to create a new <b>bounding</b> <b>box</b> which would dynamically change size. This bbox would only be to restrict the map movement and it ...", "dateLastCrawled": "2022-02-02T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Room Bounding Check box for Linked files NOT working</b> - Revit Forum", "url": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general-revit-questions/17592-", "isFamilyFriendly": true, "displayUrl": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general...", "snippet": "When I link all three models together I <b>can</b> activate the <b>room</b> <b>bounding</b> check <b>box</b> in the type properties for the link and functions properly. When they link in my two models they are not able to tags rooms that exist in the linked models even though they have checked the <b>room</b> <b>bounding</b> <b>box</b>. I tried opening their model on my system to see if it ...", "dateLastCrawled": "2022-01-26T08:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Room</b> <b>bounding</b> property for walls - Revit Forum", "url": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general-revit-questions/13361-", "isFamilyFriendly": true, "displayUrl": "https://www.revitforum.org/forum/revit-architecture-forum-rac/architecture-and-general...", "snippet": "All of mine are <b>room</b> <b>bounding</b> by default. I <b>thought</b> that you may be able to check it after, then use the create similar command to make it stick (thinking it would remember the last setting). But that&#39;s not working on my end. It&#39;s always checked no matter what. Try creating a different wall or doing it in a different template and see if it works. Dan. Comment. Post Cancel. nealmac Senior Member Find all posts. View Profile. Close. nealmac. Senior Member. Join Date: April 18, 2012; Posts: 119 ...", "dateLastCrawled": "2022-01-29T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "algorithms - Query all <b>bounding</b> boxes which contain a point - Computer ...", "url": "https://cs.stackexchange.com/questions/68307/query-all-bounding-boxes-which-contain-a-point", "isFamilyFriendly": true, "displayUrl": "https://cs.stackexchange.com/questions/68307/query-all-<b>bounding</b>-<b>box</b>es-which-contain-a...", "snippet": "The <b>bounding</b> boxes may vary greatly in size, and multiple <b>bounding</b> boxes may overlap a single point. Both points and <b>bounding</b> boxes are stored as signed integers. For example, in the diagram below, if I were to query points B and C, I&#39;d expect a single <b>bounding</b> <b>box</b> in return. However, if I query point A, I&#39;d expect an array containing both ...", "dateLastCrawled": "2022-01-16T23:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "geometry - <b>Revit API</b>. How <b>can</b> I get <b>bounding</b> <b>box</b> for several elements ...", "url": "https://stackoverflow.com/questions/63083938/revit-api-how-can-i-get-bounding-box-for-several-elements", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/63083938", "snippet": "Search there for &quot;<b>bounding</b> <b>box</b>&quot;. I am sure they <b>can</b> be further optimised as well for your case. For instance, you may be able to extract all the X coordinates from all the individual elements&#39; <b>bounding</b> <b>box</b> Max values and use a generic Max function to determine their maximum in one single call instead of comparing them one by one. Benchmark your code to discover optimisation possibilities and analyse their effect on the performance. Please do share your final results for others to learn from ...", "dateLastCrawled": "2022-01-28T20:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to <b>bounding</b> <b>box</b> annotation: Best practices", "url": "https://blog.superannotate.com/introduction-to-bounding-box-annotation-best-practices/", "isFamilyFriendly": true, "displayUrl": "https://blog.superannotate.com/introduction-to-<b>bounding</b>-<b>box</b>-annotation-best-practices", "snippet": "<b>Bounding</b> <b>box</b> annotated images advance the object detection of visual perception models by spotting targets across multiple industries. The latter ones keep expanding, opening up <b>room</b> for wider applications of <b>bounding</b> boxes and adding up to the list of precautions when annotating data. We hope this article provided you with a basic understanding of how this annotation technique facilitates object detection. Let us know if we <b>can</b> be of further help.", "dateLastCrawled": "2022-02-02T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Types of <b>Bounding</b> <b>Box</b>. | Download Scientific Diagram", "url": "https://www.researchgate.net/figure/The-Types-of-Bounding-Box_fig2_327640315", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/figure/The-Types-of-<b>Bounding</b>-<b>Box</b>_fig2_327640315", "snippet": "Building on [60], the axis-aligned <b>bounding</b> <b>box</b> (AABB) and the oriented <b>bounding</b> <b>box</b> (OBB) are developed to isolate the RoI in the 2D enhanced matte. The AABB, whose axis is parallel to the ...", "dateLastCrawled": "2022-01-13T11:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Review of <b>Bounding Box</b> Algorithm Based on 3D Point Cloud", "url": "https://exeley.com/international_journal_advanced_network_monitoring_controls/doi/10.21307/ijanmc-2021-003", "isFamilyFriendly": true, "displayUrl": "https://exeley.com/international_journal_advanced_network_monitoring_controls/doi/10...", "snippet": "When <b>compared</b> to other <b>bounding</b> boxes, the advantage of the <b>bounding</b> sphere is obvious. It requires the least amount of computation <b>compared</b> to other <b>bounding</b> boxes. By reason of the foregoing, although the calculation of the <b>bounding</b> sphere is small, its tightness is also poor. There are too many redundant calculations for most objects with uneven spatial distribution such as irregular geometric models or elongated objects. Because of its structural characteristics, it is suitable for the ...", "dateLastCrawled": "2022-01-29T00:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>OmniDetector: With Neural Networks to Bounding Boxes</b> | DeepAI", "url": "https://deepai.org/publication/omnidetector-with-neural-networks-to-bounding-boxes", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>omnidetector-with-neural-networks-to-bounding-boxes</b>", "snippet": "Subsequently, we create a new dataset with multiple persons moving in a <b>room</b>, that we call Flat. ... Through the back transformation of the <b>bounding</b> <b>box</b> corners the new boxes become larger. 6.1 <b>Bounding</b> <b>Box</b> Refinement. For the grouping of <b>bounding</b> boxes based on their confidences the YOLOv2 object detector has an included NMS, as described in Section 5. If the IoU is higher than a threshold N t, then multiple boxes of an object are merged. With the help of a small test set, we evaluate ...", "dateLastCrawled": "2021-12-13T18:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Drafting Views <b>placed on sheets have unexpectedly large bounding box</b> in ...", "url": "https://knowledge.autodesk.com/support/revit/troubleshooting/caas/sfdcarticles/sfdcarticles/Drafting-Views-placed-on-Revit-sheets-have-large-crop-boundaries.html", "isFamilyFriendly": true, "displayUrl": "https://knowledge.autodesk.com/support/revit/troubleshooting/caas/sfdcarticles/sfdc...", "snippet": "The <b>bounding</b> <b>box</b> surrounding a Revit drafting view placed into a Sheet appears to have a large gap from any visible detail items within the view. A crop region has been turned on in the view. Note: Crop Regions should not be used with drafting views, and this option has been disabled in the View Control Bar. However, a crop <b>can</b> be enabled using a keyboard shortcut.. Confirm that a crop has been applied to the view Review the drafting view on the sheet. Open the drafting view directly", "dateLastCrawled": "2022-01-24T20:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Solved: <b>Bounding</b> <b>box</b> in Dynamo &amp; Revit API vs Revit View it&#39;s not the ...", "url": "https://forums.autodesk.com/t5/revit-api-forum/bounding-box-in-dynamo-amp-revit-api-vs-revit-view-it-s-not-the/td-p/10408765", "isFamilyFriendly": true, "displayUrl": "https://<b>forums.autodesk.com</b>/t5/revit-api-forum/<b>bounding</b>-<b>box</b>-in-dynamo-amp-revit-api-vs...", "snippet": "<b>Bounding</b> <b>box</b> in Dynamo &amp; Revit API vs Revit View it&#39;s not the same. 5 REPLIES 5. SOLVED Back to Revit Products Category. Reply. Topic Options. Subscribe to RSS Feed ; Mark Topic as New; Mark Topic as Read; Float this Topic for Current User; Bookmark; Subscribe; Printer Friendly Page; Back to Topic Listing; Previous; Next; Filter by Labels. Categories &quot;PostCommand&quot; &quot;ModalDialog&quot; 1 &quot;Revit&quot; &quot;Void&quot; &quot;Solid&quot; 1.net 2.NET API 3.NET FRAMEWORK 3.Pat 1; 2020 1; 2021 2; 2021 Revit 1; 2022 1; 2D 1; 2D ...", "dateLastCrawled": "2022-01-26T21:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "deep learning - <b>Anchor Boxes</b> in YOLO : How are they decided - Stack ...", "url": "https://stackoverflow.com/questions/52710248/anchor-boxes-in-yolo-how-are-they-decided", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/52710248", "snippet": "The predictions are interpreted as offsets to anchors from which to calculate a <b>bounding</b> <b>box</b>. (The predictions also include a confidence/objectness score and a class label.) YOLO&#39;s loss function compares each object in the ground truth with one <b>anchor</b>. It picks the <b>anchor</b> (before any offsets) with highest IoU <b>compared</b> to the ground truth. Then the predictions are added as offsets to the <b>anchor</b>. All other anchors are designated as background. If anchors which have been assigned to objects ...", "dateLastCrawled": "2022-01-27T10:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "python - NumPy filling values inside given <b>bounding</b> <b>box</b> coordinates for ...", "url": "https://stackoverflow.com/questions/70204990/numpy-filling-values-inside-given-bounding-box-coordinates-for-a-large-array", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/70204990/numpy-filling-values-inside-given...", "snippet": "The classical algorithm is a bit too complex for your simple case. For each scanline, iterating over the filtered <b>bounding</b>-<b>box</b> and overwriting the their indices in each pixel is enough. This operation <b>can</b> be done using Numba in parallel. It is very fast because the computation is mainly performed in the CPU cache. The final operation is to perform the actual data writes based on the previous indices (still using Numba in parallel). This operation is still memory bound, but the output array ...", "dateLastCrawled": "2022-01-27T09:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "YOLO <b>object detection with OpenCV</b> - PyImageSearch", "url": "https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2018/11/12/yolo-<b>object-detection-with-opencv</b>", "snippet": "Scale <b>bounding</b> <b>box</b> coordinates so we <b>can</b> display them properly on our original image (Line 81). Extract coordinates and dimensions of the <b>bounding</b> <b>box</b> (Line 82). YOLO returns <b>bounding</b> <b>box</b> coordinates in the form: (centerX, centerY, width, and height). Use this information to derive the top-left (x, y)-coordinates of the <b>bounding</b> <b>box</b> (Lines 86 ...", "dateLastCrawled": "2022-02-02T04:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>the difference between image classification and</b> image ... - Quora", "url": "https://www.quora.com/What-is-the-difference-between-image-classification-and-image-annotation", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-difference-between-image-classification-and</b>-image...", "snippet": "Answer (1 of 10): Image classification is something you do when the image has a dominant single object usually an automatic task performed by the computer. While image annotation is where you label your image that has multiple dominant objects for detection with each <b>bounding</b> <b>box</b> or do a pixel-l...", "dateLastCrawled": "2022-01-17T06:26:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "13.3. Object Detection and <b>Bounding</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0 ...", "url": "http://d2l.ai/chapter_computer-vision/bounding-box.html", "isFamilyFriendly": true, "displayUrl": "d2l.ai/chapter_computer-vision/<b>bounding</b>-<b>box</b>.html", "snippet": "13.3.1. <b>Bounding</b> Boxes\u00b6. In object detection, we usually use a <b>bounding</b> <b>box</b> to describe the spatial location of an object. The <b>bounding</b> <b>box</b> is rectangular, which is determined by the \\(x\\) and \\(y\\) coordinates of the upper-left corner of the rectangle and the such coordinates of the lower-right corner. Another commonly used <b>bounding</b> <b>box</b> representation is the \\((x, y)\\)-axis coordinates of the <b>bounding</b> <b>box</b> center, and the width and height of the <b>box</b>. Here we define functions to convert ...", "dateLastCrawled": "2022-02-02T00:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "5 Main Types of <b>Machine</b> <b>Learning</b> Systems | by Jean de Dieu Nyandwi | Medium", "url": "https://jeande.medium.com/5-main-types-of-machine-learning-systems-fb07b0cc3d35", "isFamilyFriendly": true, "displayUrl": "https://jeande.medium.com/5-main-types-of-<b>machine</b>-<b>learning</b>-systems-fb07b0cc3d35", "snippet": "Semi-supervised <b>learning</b> is most notable in problems that involve working with massive datasets like internet image searches, image and audio recognition, and webpages classification. 4. Self-supervised <b>learning</b>. Self-supervised <b>learning</b> is one of the most exciting types of <b>machine</b> <b>learning</b> that is most applicable in computer vision and robotics.", "dateLastCrawled": "2022-01-25T04:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "In <b>machine-learning</b> image-detection tasks, IoU is used to measure the accuracy of the model\u2019s predicted <b>bounding</b> <b>box</b> with respect to the ground-truth <b>bounding</b> <b>box</b>. In this case, the IoU for the two boxes is the ratio between the overlapping area and the total area, and its value ranges from 0 (no overlap of predicted <b>bounding</b> <b>box</b> and ground-truth <b>bounding</b> <b>box</b>) to 1 (predicted <b>bounding</b> <b>box</b> and ground-truth <b>bounding</b> <b>box</b> have the exact same coordinates).", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> in <b>Computer Vision</b> - Princeton University", "url": "https://www.cs.princeton.edu/courses/archive/spring07/cos424/lectures/li-guest-lecture.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.princeton.edu/courses/archive/spring07/cos424/lectures/li-guest-lecture.pdf", "snippet": "<b>Machine</b> <b>learning</b> Speech Information retrieval Maths Computer Science Information Engineering Physics Biology Robotics Cognitive sciences Psychology. Quiz? What about this? A picture is worth a thousand words.--- Confucius or Printers\u2019 Ink Ad (1921) horizontal lines vertical blue on the top porous oblique white shadow to the left textured large green patches A picture is worth a thousand words.--- Confucius or Printers\u2019 Ink Ad (1921) A picture is worth a thousand words.--- Confucius or ...", "dateLastCrawled": "2022-01-29T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "13.4. <b>Anchor</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/anchor.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>anchor</b>.html", "snippet": "In order to train an object detection model, we need class and offset labels for each <b>anchor</b> <b>box</b>, where the former is the class of the object relevant to the <b>anchor</b> <b>box</b> and the latter is the offset of the ground-truth <b>bounding</b> <b>box</b> relative to the <b>anchor</b> <b>box</b>. During the prediction, for each image we generate multiple <b>anchor</b> boxes, predict classes and offsets for all the <b>anchor</b> boxes, adjust their positions according to the predicted offsets to obtain the predicted <b>bounding</b> boxes, and finally ...", "dateLastCrawled": "2022-01-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Why <b>Deep Learning</b> over Traditional <b>Machine</b> <b>Learning</b>? | by Sambit ...", "url": "https://towardsdatascience.com/why-deep-learning-is-needed-over-traditional-machine-learning-1b6a99177063", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/why-<b>deep-learning</b>-is-needed-over-traditional-<b>machine</b>...", "snippet": "In a simpler way, <b>Machine</b> <b>Learning</b> is set of algorithms that parse data, learn from them, and then apply what they\u2019ve learned to make ... \u201cThe <b>analogy</b> to <b>deep learning</b> is that the rocket engine is the <b>deep learning</b> models and the fuel is the huge amounts of data we can feed to these algorithms.\u201d <b>Deep Learning</b> requires high-end machines contrary to traditional <b>Machine</b> <b>Learning</b> algorithms. GPU has become a integral part now to execute any <b>Deep Learning</b> algorithm. In traditional <b>Machine</b> ...", "dateLastCrawled": "2022-01-30T13:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning and its Applications</b> - SlideShare", "url": "https://www.slideshare.net/ganeshn9/machine-learning-and-its-applications-138639251", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ganeshn9/<b>machine-learning-and-its-applications</b>-138639251", "snippet": "Problem Solving Approach - Example \u2022 In a <b>machine</b> <b>learning</b> approach, we will divide problem in to two parts \u2013 object detection and object recognition \u2022 We will use an algorithm like <b>bounding</b> <b>box</b> detection as an example to scan through image and detect all objects then use object recognition algorithm to recognize relevant objects \u2022 When ...", "dateLastCrawled": "2022-01-30T19:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ODAM: Object Detection, Association, and Mapping Using Posed RGB Video", "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Li_ODAM_Object_Detection_Association_and_Mapping_Using_Posed_RGB_Video_ICCV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021/papers/Li_ODAM_Object_Detection...", "snippet": "<b>analogy</b> to the use of 2D <b>bounding</b> boxes (BBs) in images, a 3D <b>bounding</b> volume presents a valuable abstraction of location and space, enabling for example, object-level plan- ningforrobots[13,15],learningscene-levelpriorsoverob-jects [55], or anchoring information on object instances. A robust way of inferring <b>bounding</b> volumes and associated views of individual objects in a scene is a stepping stone to-ward reconstructing, embedding and describing the objects with advanced state-of-the-art ...", "dateLastCrawled": "2022-02-01T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A Deep-<b>Learning</b> Model with <b>Task-Specific Bounding Box Regressors</b> and ...", "url": "https://www.mdpi.com/1424-8220/20/18/5269/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/20/18/5269/htm", "snippet": "This paper proposes a deep-<b>learning</b> model with <b>task-specific bounding box regressors</b> (TSBBRs) and conditional back-propagation mechanisms for detection of objects in motion for advanced driver assistance system (ADAS) applications. The proposed model separates the object detection networks for objects of different sizes and applies the proposed algorithm to achieve better detection results for both larger and tinier objects. For larger objects, a neural network with a larger visual receptive ...", "dateLastCrawled": "2022-01-01T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A comprehensive guide to OCR with <b>Tesseract</b>, OpenCV and Python | by ...", "url": "https://medium.com/nanonets/a-comprehensive-guide-to-ocr-with-tesseract-opencv-and-python-fd42f69e8ca8", "isFamilyFriendly": true, "displayUrl": "https://medium.com/nanonets/a-comprehensive-guide-to-ocr-with-<b>tesseract</b>-opencv-and...", "snippet": "Deep <b>learning</b> based models (such as named entity recognition) have managed to obtain unprecedented text recognition accuracy, far beyond traditional feature extraction and <b>machine</b> <b>learning</b> approaches.", "dateLastCrawled": "2022-02-02T15:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Solved: <b>Checking in features</b> - <b>Autodesk</b> Community", "url": "https://forums.autodesk.com/t5/autocad-map-3d-forum/checking-in-features/td-p/6270481", "isFamilyFriendly": true, "displayUrl": "https://<b>forums.autodesk.com</b>/t5/autocad-map-3d-forum/<b>checking-in-features</b>/td-p/6270481", "snippet": "The &quot;<b>bounding box&quot; is like</b> a spatial filter defining the lef bottom and the right upper corner for legal objects. Are you working with UTM coordinates without zone information e.g. 32(N) and inside the shape it is define with 32(N)? 32(N) means a addition of 32000000 to the x-value. When that is true you are out of the bounding box and your ...", "dateLastCrawled": "2022-01-25T23:26:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "arXiv:2007.04499v1 [cs.RO] 9 Jul 2020", "url": "https://arxiv.org/pdf/2007.04499.pdf", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/2007.04499.pdf", "snippet": "contains the observed object, and the <b>bounding box is similar</b> for each valid object detected. However, for robotic grasping, there may be several methods to grasp an object. But it is essential to pick the one with the highest grasp success or with the most stable grasp, thus relying on <b>machine</b> <b>learning</b> techniques to \ufb01nd the best possible grasp. The use of convolutional neural networks is a popular technique used for <b>learning</b> features and visual models that uses a sliding window detection ...", "dateLastCrawled": "2020-07-12T09:31:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "YOLOv3 Tutorial: Understanding What is YOLOv3 and How it works?", "url": "https://bestinau.com.au/yolov3-architecture-best-model-in-object-detection/", "isFamilyFriendly": true, "displayUrl": "https://bestinau.com.au/<b>yolov3-architecture-best-model-in-object-detection</b>", "snippet": "In many <b>machine</b> <b>learning</b> models (Logistic Regression, SVMs), in loss functions we have loss as well as a regularizer multiplied by. The job of this is to make a choice between minimizing loss and regularizing the model. Because of the scale of these two numbers being different, it is sensible to actually weigh them differently. Initially, they didn\u2019t do it and weren\u2019t getting good performance, but later thought that if they could create a weighted model, that might do the trick. These ...", "dateLastCrawled": "2022-02-02T01:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Using AI to Detect Social Distancing Violations - <b>Deep Learning Analytics</b>", "url": "https://deeplearninganalytics.org/using-ai-to-detect-social-distancing-violations/", "isFamilyFriendly": true, "displayUrl": "https://<b>deeplearninganalytics</b>.org/using-ai-to-detect-social-distancing-violations", "snippet": "Each track is basically a bounding box with an ID. So a <b>bounding box can be compared to</b> another bounding using the euclidean distance between them. Now we start our modeling. The code for that is shared below. This is the same code as in my Github. Modeling Social Distancing. The main steps that are run for every frame are: Compare the pixel distance between each track and every other track; If distance &lt; proximity threshold then, two people are too close to each other. So put safe =1 in the ...", "dateLastCrawled": "2022-01-31T21:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Using AI to Detect <b>Social Distancing</b> Violations | by Priya Dwivedi ...", "url": "https://medium.com/swlh/using-ai-to-detect-social-distancing-violations-4707301844be", "isFamilyFriendly": true, "displayUrl": "https://medium.com/swlh/using-ai-to-detect-<b>social-distancing</b>-violations-4707301844be", "snippet": "<b>Social Distancing</b> Violations Detection and Counting. At Deep <b>Learning</b> Analytics, we are very passionate about using data science and <b>machine</b> <b>learning</b> to solve problems.Please reach out to us if ...", "dateLastCrawled": "2022-01-28T16:11:00.0000000Z", "language": "en", "isNavigational": false}]], "all_bing_queries": ["+(bounding box)  is like +(room)", "+(bounding box) is similar to +(room)", "+(bounding box) can be thought of as +(room)", "+(bounding box) can be compared to +(room)", "machine learning +(bounding box AND analogy)", "machine learning +(\"bounding box is like\")", "machine learning +(\"bounding box is similar\")", "machine learning +(\"just as bounding box\")", "machine learning +(\"bounding box can be thought of as\")", "machine learning +(\"bounding box can be compared to\")"]}