{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "r - <b>Area under</b> the ROC <b>curve</b> or <b>area under</b> <b>the PR</b> <b>curve</b> for imbalanced ...", "url": "https://stats.stackexchange.com/questions/90779/area-under-the-roc-curve-or-area-under-the-pr-curve-for-imbalanced-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/90779", "snippet": "If you want to compare different models in imbalanced settings, <b>area under</b> <b>the PR</b> <b>curve</b> will likely exhibit larger differences than <b>area under</b> the ROC <b>curve</b>. That said, ROC curves are much more common (even if they are less suited). Depending on your audience, ROC curves may be the lingua franca so using those is probably the safer choice. If one model completely dominates another in <b>PR</b> space (e.g. always have higher precision over the entire recall range), it will also dominate in ROC space ...", "dateLastCrawled": "2022-02-03T13:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Area Under</b> the Precision-Recall <b>Curve</b>: Point Estimates and Con dence ...", "url": "http://pages.cs.wisc.edu/~boyd/aucpr_final.pdf", "isFamilyFriendly": true, "displayUrl": "pages.cs.wisc.edu/~boyd/aucpr_final.pdf", "snippet": "Abstract. The <b>area under</b> the precision-recall <b>curve</b> (AUCPR) is a sin-gle number summary of the information in the precision-recall (<b>PR</b>) <b>curve</b>. Similar to the receiver operating characteristic <b>curve</b>, <b>the PR</b> <b>curve</b> has its own unique properties that make estimating its enclosed <b>area</b> challenging. Besides a point estimate of the <b>area</b>, an interval ...", "dateLastCrawled": "2022-01-30T22:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "scikit learn - <b>Area</b> <b>under</b> <b>Precision-Recall</b> <b>Curve</b> (AUC of <b>PR</b>-<b>curve</b>) and ...", "url": "https://stats.stackexchange.com/questions/157012/area-under-precision-recall-curve-auc-of-pr-curve-and-average-precision-ap", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/157012", "snippet": "for my classifer I have something <b>like</b>: <b>Area</b> <b>Under</b> <b>PR</b> <b>Curve</b>(AP): 0.65 AP 0.676101781304 AP 0.676101781304 AP 0.676101781304 AP 0.676101781304 scikit-learn <b>precision-recall</b> auc average-<b>precision</b>. Share. Cite. Improve this question. Follow edited Nov 9 &#39;16 at 16:50. Mads Jensen . 23 5 5 bronze badges. asked Jun 15 &#39;15 at 9:37. mrgloom mrgloom. 1,687 4 4 gold badges 25 25 silver badges 32 32 bronze badges $\\endgroup$ Add a comment | 2 Answers Active Oldest Score. 24 $\\begingroup$ Short answer ...", "dateLastCrawled": "2022-02-02T04:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Precision - Recall Curve, a Different View of Imbalanced Classifiers</b> ...", "url": "https://sinyi-chou.github.io/classification-pr-curve/", "isFamilyFriendly": true, "displayUrl": "https://sinyi-chou.github.io/classification-<b>pr</b>-<b>curve</b>", "snippet": "The <b>area</b> <b>under</b> <b>the PR</b> ROC <b>curve</b> (<b>PR</b> AUC) provides a different perspective on evaluating the result of binary classifier. Lager <b>PR</b> AUC value indicates better model performance \u2014 <b>the PR</b> <b>curve</b> would move towards the upper left corner. Not all the value between 0 to 1 is achievable for <b>PR</b> AUC. Varying by data, the baseline of <b>PR</b> <b>curve</b> is the horizontal line with y equals the value of the positive rate \u2014 P/(P+N) \u2014 the smallest value of precision. When the threshold goes to 0 (i.e. the ...", "dateLastCrawled": "2022-02-02T18:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How to Use ROC Curves and <b>Precision-Recall Curves for Classification</b> in ...", "url": "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/roc-<b>curves</b>-and-precision-recall-<b>curves</b>-for...", "snippet": "<b>Area</b> <b>Under</b> <b>Curve</b>: <b>like</b> the AUC, summarizes the integral or an approximation of the <b>area</b> <b>under</b> the precision-recall <b>curve</b>. In terms of model selection, F-Measure summarizes model skill for a specific probability threshold (e.g. 0.5), whereas the <b>area</b> <b>under</b> <b>curve</b> summarize the skill of a model across thresholds, <b>like</b> ROC AUC. This makes precision-recall and a plot of precision vs. recall and summary measures useful tools for binary classification problems that have an imbalance in the ...", "dateLastCrawled": "2022-02-03T04:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "F1 <b>Score</b> vs ROC AUC vs Accuracy vs <b>PR</b> AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-accuracy-roc-auc-<b>pr</b>-auc", "snippet": "AUC means <b>area</b> <b>under</b> the <b>curve</b> so to speak about ROC AUC <b>score</b> we need to define ROC <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart.", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "ROC Curves and <b>Precision-Recall Curves for Imbalanced Classification</b>", "url": "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/roc-<b>curves</b>-and-precision-recall-<b>curves</b>-for...", "snippet": "This is called the ROC <b>area</b> <b>under</b> <b>curve</b> or ROC AUC or sometimes ROCAUC. The score is a value between 0.0 and 1.0 for a perfect classifier. AUCROC can be interpreted as the probability that the scores given by a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one. \u2014 Page 54, Learning from Imbalanced Data Sets, 2018. This single score can be used to compare binary classifier models directly. As such, this score might be the most commonly used ...", "dateLastCrawled": "2022-02-02T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Standard Normal Distribution</b> - Z-Score, <b>Area</b> and Examples", "url": "https://byjus.com/maths/standard-normal-distribution/", "isFamilyFriendly": true, "displayUrl": "https://byjus.com/maths/<b>standard-normal-distribution</b>", "snippet": "A <b>standard normal distribution</b> table is utilized to determine the region <b>under</b> the bend (f(z)) to discover the probability of a specified range of distribution. The normal distribution density function f(z) is called the Bell <b>Curve</b> since its shape looks <b>like</b> a bell. What does it mean? Is that on the off chance that you need to discover the probability of a value is not exactly or more than a fixed positive z value. You can discover it by finding it on the table. This is known as <b>area</b> \u03a6. A ...", "dateLastCrawled": "2022-02-03T00:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Area</b> <b>Under</b> the <b>Curve</b> Bounded by a Line: Calculation, Videos, Examples", "url": "https://www.toppr.com/guides/maths/application-of-integrals/area-bounded-by-a-curve-and-a-line/", "isFamilyFriendly": true, "displayUrl": "https://www.toppr.com/guides/maths/application-of-integrals/<b>area-bounded-by-a-curve</b>...", "snippet": "Calculation of <b>Area</b> <b>Under</b> the <b>Curve</b> Bounded by a Line. Let the <b>graph</b> of the <b>curve</b> and the straight line look something <b>like</b> this: Clearly, we need to calculate the <b>area</b> of the mentioned region in the <b>graph</b>. This region can be viewed as the region common to the \u2018<b>Area</b> <b>under</b> the <b>curve</b>\u2019 for both, the straight line as well as the given <b>curve</b> ...", "dateLastCrawled": "2022-02-02T05:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "On a P-V diagram, what does the <b>area</b> <b>under the process curve represent</b> ...", "url": "https://www.quora.com/On-a-P-V-diagram-what-does-the-area-under-the-process-curve-represent", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/On-a-P-V-diagram-what-does-the-<b>area</b>-<b>under</b>-the-process-<b>curve</b>...", "snippet": "Answer: From Google search: As described on the work slide, the <b>area</b> <b>under</b> a process <b>curve</b> on a p-V diagram is equal to the work performed by gas during the process. ... The <b>area</b> <b>under</b> a process <b>curve</b> on a T-s diagram is related to the amount of heat transferred to the gas. More here: P-V and T-...", "dateLastCrawled": "2022-01-22T08:13:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "r - <b>Area under</b> the ROC <b>curve</b> or <b>area under</b> <b>the PR</b> <b>curve</b> for imbalanced ...", "url": "https://stats.stackexchange.com/questions/90779/area-under-the-roc-curve-or-area-under-the-pr-curve-for-imbalanced-data", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/90779", "snippet": "If you want to compare different models in imbalanced settings, <b>area under</b> <b>the PR</b> <b>curve</b> will likely exhibit larger differences than <b>area under</b> the ROC <b>curve</b>. That said, ROC curves are much more common (even if they are less suited). Depending on your audience, ROC curves may be the lingua franca so using those is probably the safer choice. If one model completely dominates another in <b>PR</b> space (e.g. always have higher precision over the entire recall range), it will also dominate in ROC space ...", "dateLastCrawled": "2022-02-03T13:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "F1 <b>Score</b> vs ROC AUC vs Accuracy vs <b>PR</b> AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-accuracy-roc-auc-<b>pr</b>-auc", "snippet": "AUC means <b>area</b> <b>under</b> the <b>curve</b> so to speak about ROC AUC <b>score</b> we need to define ROC <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart. Of course, the higher TPR and the lower FPR is for each threshold the better and so classifiers that have curves that are more top-left-side are better. An extensive discussion of ROC <b>Curve</b> and ROC AUC <b>score</b> ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Ml Roc <b>Pr</b> - plotly.com", "url": "https://plotly.com/r/roc-and-pr-curves/", "isFamilyFriendly": true, "displayUrl": "https://plotly.com/r/roc-and-<b>pr</b>-<b>curves</b>", "snippet": "Plotting <b>the PR</b> <b>curve</b> is very <b>similar</b> to plotting the ROC <b>curve</b>. The following examples are slightly modified from the previous examples: ... which is an alternative scoring method to the <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. library (plotly) library (tidymodels) library (fastDummies) # Artificially add noise to make task harder data (iris) ind &lt;-sample.int (150, 50) samples &lt;-sample (x = iris $ Species, size = 50) iris [ind, &#39;Species&#39;] = samples # Define the inputs and outputs X &lt;-subset (iris, select ...", "dateLastCrawled": "2022-02-02T11:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Precision - Recall Curve, a Different View of Imbalanced Classifiers</b> ...", "url": "https://sinyi-chou.github.io/classification-pr-curve/", "isFamilyFriendly": true, "displayUrl": "https://sinyi-chou.github.io/classification-<b>pr</b>-<b>curve</b>", "snippet": "The <b>area</b> <b>under</b> <b>the PR</b> ROC <b>curve</b> (<b>PR</b> AUC) provides a different perspective on evaluating the result of binary classifier. Lager <b>PR</b> AUC value indicates better model performance \u2014 <b>the PR</b> <b>curve</b> would move towards the upper left corner. Not all the value between 0 to 1 is achievable for <b>PR</b> AUC. Varying by data, the baseline of <b>PR</b> <b>curve</b> is the horizontal line with y equals the value of the positive rate \u2014 P/(P+N) \u2014 the smallest value of precision. When the threshold goes to 0 (i.e. the ...", "dateLastCrawled": "2022-02-02T18:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>precision and recall</b> - GitHub Pages", "url": "https://bbabenko.github.io/prs/", "isFamilyFriendly": true, "displayUrl": "https://bbabenko.github.io/prs", "snippet": "it\u2019s easy to see that a perfect <b>PR</b> <b>curve</b> (and a perfect ROC <b>curve</b>) would end up with an <b>area</b> of 1.0. this is usually referred to as \u201caverage precision\u201d when talking about <b>PR</b>, and \u201c<b>area</b> <b>under</b> the <b>curve</b>\u201d when talking about ROC. i personally don\u2019t like these metrics, especially for <b>PR</b> curves, for two reasons: 1) there\u2019s a surprising amount of nuance in implementing average precision \u2013 see section 4 of", "dateLastCrawled": "2022-02-03T01:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Ml Roc <b>Pr</b> - Plotly", "url": "https://plotly.com/python/roc-and-pr-curves/", "isFamilyFriendly": true, "displayUrl": "https://plotly.com/python/<b>roc-and-pr-curves</b>", "snippet": "Plotting <b>the PR</b> <b>curve</b> is very <b>similar</b> to plotting the ROC <b>curve</b>. The following examples are slightly modified from the previous examples: In [5]: import plotly.express as px from sklearn.linear_model import LogisticRegression from sklearn.metrics import precision_recall_<b>curve</b>, auc from sklearn.datasets import make_classification X, y = make_classification (n_samples = 500, random_state = 0) model = LogisticRegression model. fit (X, y) y_score = model. predict_proba (X)[:, 1] precision ...", "dateLastCrawled": "2022-01-31T05:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "machine learning - <b>ROC</b> vs precision-and-recall curves - Cross Validated", "url": "https://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/7207", "snippet": "Finally, we show that an algorithm that optimizes the <b>area</b> <b>under</b> the <b>ROC</b> <b>curve</b> is not guaranteed to optimize the <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. In other words, in principle, <b>ROC</b> and <b>PR</b> are equally suited to compare results. But for the example case of a result of 20 hits and 1980 misses they show that the differences can be rather drastic, as shown in Figures 11 and 12. Result/<b>curve</b> (I) describes a result where 10 of the 20 hits are in the top ten ranks and the remaining 10 hits are then evenly ...", "dateLastCrawled": "2022-01-27T09:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "ROC Curves and <b>Precision-Recall Curves for Imbalanced Classification</b>", "url": "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/roc-<b>curves</b>-and-precision-recall-<b>curves</b>-for...", "snippet": "This is called the ROC <b>area</b> <b>under</b> <b>curve</b> or ROC AUC or sometimes ROCAUC. The score is a value between 0.0 and 1.0 for a perfect classifier. AUCROC can be interpreted as the probability that the scores given by a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one. \u2014 Page 54, Learning from Imbalanced Data Sets, 2018. This single score can be used to compare binary classifier models directly. As such, this score might be the most commonly used ...", "dateLastCrawled": "2022-02-02T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How to Use ROC Curves and <b>Precision-Recall Curves for Classification</b> in ...", "url": "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/roc-<b>curves</b>-and-precision-recall-<b>curves</b>-for...", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (AUC) can be used as a summary of the model skill. The shape of the <b>curve</b> contains a lot of information, including what we might care about most for a problem, the expected false positive rate, and the false negative rate. To make this clear: Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives. Larger values on the y-axis of the plot indicate higher true positives and lower false negatives. If you are confused, remember ...", "dateLastCrawled": "2022-02-03T04:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The <b>area under force - displacement curve represents</b>.", "url": "https://www.toppr.com/ask/question/the-area-under-forcedisplacement-curve-represents/", "isFamilyFriendly": true, "displayUrl": "https://www.toppr.com/ask/question/the-<b>area-under-forcedisplacement-curve-represents</b>", "snippet": "The <b>area</b> <b>under</b> the <b>force-displacement curve represents</b> the work done. It is the distance (s) of the object displaced by the application of the force (f). In this case force (f) is presented on the y-axis and displacement (s) on the x-axis. The work done (w) is a scalar quantity. Was this answer helpful? 0. 0. <b>Similar</b> questions. Which one of the following physical quantities is represented by the shaded <b>area</b> in the given <b>graph</b>? Medium. View solution &gt; Work done is equal <b>to area</b> <b>under</b> the ...", "dateLastCrawled": "2022-01-24T16:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "F1 <b>Score</b> vs ROC AUC vs Accuracy vs <b>PR</b> AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-accuracy-roc-auc-<b>pr</b>-auc", "snippet": "AUC means <b>area</b> <b>under</b> the <b>curve</b> so to speak about ROC AUC <b>score</b> we need to define ROC <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart. Of course, the higher TPR and the lower FPR is for each threshold the better and so classifiers that have curves that are more top-left-side are better. An extensive discussion of ROC <b>Curve</b> and ROC AUC <b>score</b> ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Area</b> <b>under</b> the ROC <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-the-roc-<b>curve</b>-assessing-discrimination...", "snippet": "Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a model with no discrimination ability. The <b>area</b> <b>under</b> the ROC <b>curve</b> is also sometimes referred to as the c-statistic (c for concordance). The <b>area</b> <b>under</b> the estimated ROC <b>curve</b> (AUC) is reported when we plot the ROC <b>curve</b> in R&#39;s Console.", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The <b>Area Under</b> an ROC <b>Curve</b>", "url": "http://gim.unmc.edu/dxtests/RoC3.htm", "isFamilyFriendly": true, "displayUrl": "gim.unmc.edu/dxtests/RoC3.htm", "snippet": "The <b>graph</b> at right shows three ROC curves representing excellent, good, and worthless tests plotted on the same <b>graph</b>. The accuracy of the test depends on how well the test separates the group being tested into those with and without the disease in question. Accuracy is measured by the <b>area under</b> the ROC <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the accuracy of a diagnostic test is the traditional academic point ...", "dateLastCrawled": "2022-01-28T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "classification - What is a <b>good</b> AUC for a precision-recall <b>curve</b> ...", "url": "https://stats.stackexchange.com/questions/113326/what-is-a-good-auc-for-a-precision-recall-curve", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/113326", "snippet": "An ideal <b>PR</b>-<b>curve</b> goes from the topleft corner horizontically to the topright corner and straight down to the bottomright corner, resulting in a <b>PR</b>-AUC of 1. In some applications, <b>the PR</b>-<b>curve</b> shows instead a strong spike at the beginning to quickly drop again close to the &quot;random estimator line&quot; (the horizontal line at 0.09 precision in your case). This would indicate a <b>good</b> detection of &quot;strong&quot; positive outcomes, but poor performance on the less clear candidates.", "dateLastCrawled": "2022-02-02T22:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What is the value of the <b>area</b> <b>under</b> the roc <b>curve</b> (AUC) to conclude ...", "url": "https://www.researchgate.net/post/What-is-the-value-of-the-area-under-the-roc-curve-AUC-to-conclude-that-a-classifier-is-excellent", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What-is-the-value-of-the-<b>area</b>-<b>under</b>-the-roc-<b>curve</b>...", "snippet": "&quot;Accuracy is measured by the <b>area</b> <b>under</b> the ROC <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the accuracy of a diagnostic ...", "dateLastCrawled": "2022-02-01T16:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>AUC-ROC Curve - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/auc-roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/auc-roc-<b>curve</b>", "snippet": "If you have participated in any online machine learning competition/hackathon then you must have come across <b>Area</b> <b>Under</b> <b>Curve</b> Receiver Operator Characteristic a.k.a AUC-ROC, many of them have it as their evaluation criteria for their classification problems. Let\u2019s admit when you had first heard about it, this <b>thought</b> once must have crossed your mind, what\u2019s with the long name? Well, the origin of ROC <b>curve</b> goes way back in World War II, it was originally used for the analysis of radar ...", "dateLastCrawled": "2022-01-30T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "machine learning - Advantages of AUC vs standard <b>accuracy</b> - Data ...", "url": "https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/806", "snippet": "Really great question, and one that I find that most people don&#39;t really understand on an intuitive level. AUC is in fact often preferred over <b>accuracy</b> for binary classification for a number of different reasons. First though, let&#39;s talk about exactly what AUC is. Honestly, for being one of the most widely used efficacy metrics, it&#39;s surprisingly obtuse to figure out exactly how AUC works.. AUC stands for <b>Area</b> <b>Under</b> the <b>Curve</b>, which <b>curve</b> you ask?Well, that would be the ROC <b>curve</b>.ROC stands ...", "dateLastCrawled": "2022-01-27T15:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>ROC Curve</b>, a Complete Introduction | by Reza Bagheri | Towards Data Science", "url": "https://towardsdatascience.com/roc-curve-a-complete-introduction-2f2da2e0434c", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>roc-curve</b>-a-complete-introduction-2f2da2e0434c", "snippet": "To do that we calculate the <b>area</b> <b>under</b> the <b>ROC curve</b> as shown in Fig 22. Figure 22. We call this quantity AUC (<b>Area</b> <b>under</b> the <b>Curve</b>). For an ideal classifier, AUC is the <b>area</b> of a rectangle with length 1, so it is just 1. For a random classifier, it is roughly the <b>area</b> of the lower triangle which is 0.5. For other classifiers, AUC lies between 0.5 and 1. The higher the AUC, the better the classifier is, since it is closer to an ideal classifier. To calculate the AUC in Scikit-learn, you <b>can</b> ...", "dateLastCrawled": "2022-01-30T19:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is <b>ROC AUC</b> and how to visualize it in <b>python</b> | by Angela ... - Medium", "url": "https://medium.com/@kunanba/what-is-roc-auc-and-how-to-visualize-it-in-python-f35708206663", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@kunanba/what-is-<b>roc-auc</b>-and-how-to-visualize-it-in-<b>python</b>-f35708206663", "snippet": "We <b>can</b> also qunatify <b>area</b> <b>under</b> the <b>curve</b> also know as <b>AUC</b> using scikit-learn\u2019s <b>roc_auc</b>_score metric, in order to assess the performance of the model. The closer the score to 1 the better the ...", "dateLastCrawled": "2022-02-02T21:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Explaining the 68-95-99.7 rule for a Normal Distribution | by Michael ...", "url": "https://towardsdatascience.com/understanding-the-68-95-99-7-rule-for-a-normal-distribution-b7b7cbf760c2", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-the-68-95-99-7-rule-for-a-normal...", "snippet": "The <b>graph</b> above does not show you the probability of events but their probability density. To get the probability of an event within a given range we will need to integrate. Suppose we are interested in finding the probability of a random data point landing within 1 <b>standard</b> deviation of the mean, we need to integrate from -1 to 1. This <b>can</b> be done with SciPy. # Make a PDF for the normal distribution a function def normalProbabilityDensity(x): constant = 1.0 / np.sqrt(2*np.pi) return ...", "dateLastCrawled": "2022-02-02T06:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "F1 <b>Score</b> vs ROC AUC vs Accuracy vs <b>PR</b> AUC: Which Evaluation Metric ...", "url": "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/f1-<b>score</b>-accuracy-roc-auc-<b>pr</b>-auc", "snippet": "AUC means <b>area</b> <b>under</b> the <b>curve</b> so to speak about ROC AUC <b>score</b> we need to define ROC <b>curve</b> first. It is a chart that visualizes the tradeoff between true positive rate (TPR) and false positive rate (FPR). Basically, for every threshold, we calculate TPR and FPR and plot it on one chart. Of course, the higher TPR and the lower FPR is for each threshold the better and so classifiers that have curves that are more top-left-side are better. An extensive discussion of ROC <b>Curve</b> and ROC AUC <b>score</b> ...", "dateLastCrawled": "2022-01-29T12:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Precision-Recall Curve | ML - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/precision-recall-curve-ml/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/precision-recall-<b>curve</b>-ml", "snippet": "The figure below shows a juxtaposition of sample <b>PR</b> and ROC curves. Interpreting a <b>PR</b> <b>Curve</b> \u2013 It is desired that the algorithm should have both high precision, and high recall. However, most machine learning algorithms often involve a trade-off between the two. A good <b>PR</b> <b>curve</b> has greater AUC (<b>area</b> <b>under</b> <b>curve</b>). In the figure above, the ...", "dateLastCrawled": "2022-02-02T06:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Area</b> <b>Under</b> Curves: <b>Simple Curves</b>, Definition, Calculation, Videos, Q&amp;As", "url": "https://www.toppr.com/guides/maths/application-of-integrals/area-under-simple-curves/", "isFamilyFriendly": true, "displayUrl": "https://www.toppr.com/guides/maths/application-of-integrals/<b>area-under-simple-curves</b>", "snippet": "In such cases, the <b>area</b> <b>under</b> <b>a curve</b> would be the one with respect to the y-axis. The figure given below would make things clear to you. You <b>can</b> see that here by constructing horizontal rectangular strips of length f(y 0) and breadth dy, one <b>can</b> derive another form of the formula for the <b>area</b> <b>under</b> <b>a curve</b>. $$ {A = \\int_{y = b}^{y = a} f(y)dy} $$", "dateLastCrawled": "2022-02-02T19:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to <b>make a precision recall curve in R</b> | R-bloggers", "url": "https://www.r-bloggers.com/2019/12/how-to-make-a-precision-recall-curve-in-r/", "isFamilyFriendly": true, "displayUrl": "https://www.r-bloggers.com/2019/12/how-to-<b>make-a-precision-recall-curve-in-r</b>", "snippet": "In these cases, the ROC is pretty insensitive and <b>can</b> be misleading, whereas <b>PR</b> curves reign supreme. The <b>area</b> <b>under</b> <b>the PR</b> <b>curve</b> does not have a probabilistic interpretation like ROC. <b>The PR</b> gain <b>curve</b> was made to deal with some of the above problems with <b>PR</b> curves, although it still is intended for extreme class imbalance situations. The main ...", "dateLastCrawled": "2022-02-03T01:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "ROC Curves and <b>Precision-Recall Curves for Imbalanced Classification</b>", "url": "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/roc-<b>curves</b>-and-precision-recall-<b>curves</b>-for...", "snippet": "ROC <b>Area</b> <b>Under</b> <b>Curve</b> (AUC) Score. Although the ROC <b>Curve</b> is a helpful diagnostic tool, it <b>can</b> be challenging to compare two or more classifiers based on their curves. Instead, the <b>area</b> <b>under</b> the <b>curve</b> <b>can</b> be calculated to give a single score for a classifier model across all threshold values. This is called the ROC <b>area</b> <b>under</b> <b>curve</b> or ROC AUC ...", "dateLastCrawled": "2022-02-02T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Difference</b> between the areas <b>under</b> two curves &gt; Diagnostic performance ...", "url": "https://analyse-it.com/docs/user-guide/diagnostic-performance/auc-difference", "isFamilyFriendly": true, "displayUrl": "https://analyse-it.com/docs/user-guide/diagnostic-performance/auc-<b>difference</b>", "snippet": "A point estimate of the <b>difference</b> between the <b>area</b> <b>under</b> two curves is a single value that is the best estimate of the true unknown parameter; a confidence interval indicates the uncertainty of the estimate. If the tests are independent, the confidence interval uses the combined variance of the curves and a large sample Wald approximation. If ...", "dateLastCrawled": "2022-01-29T23:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to Use ROC Curves and <b>Precision-Recall Curves for Classification</b> in ...", "url": "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/roc-<b>curves</b>-and-precision-recall-<b>curves</b>-for...", "snippet": "The <b>area</b> <b>under</b> the <b>curve</b> (AUC) <b>can</b> be used as a summary of the model skill. The shape of the <b>curve</b> contains a lot of information, including what we might care about most for a problem, the expected false positive rate, and the false negative rate. To make this clear: Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives. Larger values on the y-axis of the plot indicate higher true positives and lower false negatives. If you are confused, remember ...", "dateLastCrawled": "2022-02-03T04:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Area</b> <b>under</b> the ROC <b>curve \u2013 assessing discrimination in logistic</b> ...", "url": "https://thestatsgeek.com/2014/05/05/area-under-the-roc-curve-assessing-discrimination-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://thestatsgeek.com/2014/05/05/<b>area</b>-<b>under</b>-the-roc-<b>curve</b>-assessing-discrimination...", "snippet": "Thus the <b>area</b> <b>under</b> the <b>curve</b> ranges from 1, corresponding to perfect discrimination, to 0.5, corresponding to a model with no discrimination ability. The <b>area</b> <b>under</b> the ROC <b>curve</b> is also sometimes referred to as the c-statistic (c for concordance). The <b>area</b> <b>under</b> the estimated ROC <b>curve</b> (AUC) is reported when we plot the ROC <b>curve</b> in R&#39;s Console.", "dateLastCrawled": "2022-01-29T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "How <b>to Calculate AUC (Area Under Curve</b>) in R - Statology", "url": "https://www.statology.org/auc-in-r/", "isFamilyFriendly": true, "displayUrl": "https://www.statology.org/auc-in-r", "snippet": "How <b>to Calculate AUC (Area Under Curve</b>) in R. Logistic Regression is a statistical method that we use to fit a regression model when the response variable is binary. To assess how well a logistic regression model fits a dataset, we <b>can</b> look at the following two metrics: Sensitivity: The probability that the model predicts a positive outcome for an observation when indeed the outcome is positive. This is also called the \u201ctrue positive rate.\u201d Specificity: The probability that the model ...", "dateLastCrawled": "2022-01-30T17:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is the value of the <b>area</b> <b>under</b> the roc <b>curve</b> (AUC) to conclude ...", "url": "https://www.researchgate.net/post/What-is-the-value-of-the-area-under-the-roc-curve-AUC-to-conclude-that-a-classifier-is-excellent", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/What-is-the-value-of-the-<b>area</b>-<b>under</b>-the-roc-<b>curve</b>...", "snippet": "&quot;Accuracy is measured by the <b>area</b> <b>under</b> the ROC <b>curve</b>. An <b>area</b> of 1 represents a perfect test; an <b>area</b> of .5 represents a worthless test. A rough guide for classifying the accuracy of a diagnostic ...", "dateLastCrawled": "2022-02-01T16:59:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "<b>area</b> <b>under</b> <b>the PR</b> <b>curve</b>. See <b>PR</b> AUC (<b>Area</b> <b>under</b> <b>the PR</b> <b>Curve</b>). <b>area</b> <b>under</b> the ROC <b>curve</b> . See AUC (<b>Area</b> <b>under</b> the ROC <b>curve</b>). artificial general intelligence. A non-human mechanism that demonstrates a broad range of problem solving, creativity, and adaptability. For example, a program demonstrating artificial general intelligence could translate text, compose symphonies, and excel at games that have not yet been invented. artificial intelligence. A non-human program or model that can solve ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Learning</b> Curves in <b>Machine</b> <b>Learning</b>", "url": "https://www.researchgate.net/publication/247934703_Learning_Curves_in_Machine_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/247934703_<b>Learning</b>_<b>Curves</b>_in_<b>Machine</b>_<b>Learning</b>", "snippet": "The <b>area</b> <b>under</b> the receiver operating characteristic (ROC) <b>curve</b> (AUC) was 0.62 (95% confidence interval [CI]: 0.57, 0.68) and the <b>area</b> <b>under</b> the precision\u2010recall <b>curve</b> was 0.58. <b>Learning</b> <b>curve</b> ...", "dateLastCrawled": "2021-12-15T10:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Understanding <b>AUC</b> - ROC <b>Curve</b> | by Sarang Narkhede | Towards Data Science", "url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>under</b>standing-<b>auc</b>-roc-<b>curve</b>-68b2303cc9c5", "snippet": "In <b>Machine</b> <b>Learning</b>, performance measurement is an essential task. So when it comes to a classification problem, we can count on an <b>AUC</b> - ROC <b>Curve</b>. When we need to check or visualize the performance of the multi-class classification problem, we use the <b>AUC</b> <b>Area</b> <b>Under</b> The <b>Curve</b>) ROC (Receiver Operating Characteristics) <b>curve</b>. It is one of the most important evaluation metrics for checking any classification model\u2019s performance. It is also written as AUROC (<b>Area</b> <b>Under</b> the Receiver Operating ...", "dateLastCrawled": "2022-01-30T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Differential and Integral Calculus - Differentiate with Respect to Anything", "url": "https://machinelearningmastery.com/differential-and-integral-calculus-differentiate-with-respect-to-anything/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/differential-and-integral-calculus-differentiate...", "snippet": "The Sweeping <b>Area</b> <b>Analogy</b>. Perhaps a simpler <b>analogy</b> to help us relate integration to differentiation, is to imagine holding one of the thinly cut slices and dragging it rightwards <b>under</b> the <b>curve</b> in infinitesimally small steps. As it moves rightwards, the thinly cut slice will sweep a larger <b>area</b> <b>under</b> the <b>curve</b>, while its height will change according to the shape of the <b>curve</b>. The question that we would like to answer is, at which rate does the <b>area</b> accumulate as the thin slice sweeps ...", "dateLastCrawled": "2022-01-28T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>What is</b> AUC - <b>ROC</b> in <b>Machine</b> <b>Learning</b> | Overview of <b>ROC</b>", "url": "https://www.mygreatlearning.com/blog/roc-curve/", "isFamilyFriendly": true, "displayUrl": "https://www.mygreat<b>learning</b>.com/blog/<b>roc</b>-<b>curve</b>", "snippet": "By <b>analogy</b>, Higher the AUC, better the model is at distinguishing between patients with the disease and no disease. The <b>ROC</b> <b>curve</b> is plotted with TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis. Defining terms used in AUC and <b>ROC</b> <b>Curve</b>. Consider a two-class prediction problem, in which the outcomes are labeled either as positive (p) or negative (n). There are four possible outcomes from a binary classifier. If the outcome from a prediction is p and the actual value is ...", "dateLastCrawled": "2022-01-30T19:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Applying <b>machine</b> <b>learning</b> algorithms to predict default probability in ...", "url": "https://www.sciencedirect.com/science/article/pii/S1057521921002878", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1057521921002878", "snippet": "The results show that, first, based on the AUC (<b>area</b> <b>under</b> the ROC <b>curve</b>) value, accuracy rate and Brier score, the <b>machine</b> <b>learning</b> models can accurately predict the default risk of online borrowers. Second, the integrated discrimination improvement (IDI) test results show that the prediction performance of the <b>machine</b> <b>learning</b> algorithms is significantly better than that of the logistic model. Third, after constructing the investor profit function with misclassification cost, we find that ...", "dateLastCrawled": "2022-01-27T19:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Cohort-Derived <b>Machine Learning</b> Models for Individual Prediction of ...", "url": "https://academic.oup.com/jid/article/224/7/1198/5835004", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/jid/article/224/7/1198/5835004", "snippet": "Of 12 761 eligible individuals (median baseline eGFR, 103 mL/minute/1.73 m 2), 1192 (9%) developed a CKD after a median of 8 years.We used 64 static and 502 time-changing variables: Across prediction horizons and algorithms and in contrast to expert-based standard models, most <b>machine learning</b> models achieved state-of-the-art predictive performances with areas <b>under</b> the receiver operating characteristic <b>curve</b> and precision recall <b>curve</b> ranging from 0.926 to 0.996 and from 0.631 to 0.956 ...", "dateLastCrawled": "2021-12-15T15:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Bishop Pattern Recognition And Machine Learning Springer</b> | Xinyue ...", "url": "https://www.academia.edu/34528598/Bishop_Pattern_Recognition_And_Machine_Learning_Springer", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/34528598/<b>Bishop_Pattern_Recognition_And_Machine_Learning_Springer</b>", "snippet": "<b>Bishop Pattern Recognition And Machine Learning Springer</b>. 758 Pages. <b>Bishop Pattern Recognition And Machine Learning Springer</b>. Xinyue Liu. Download Download PDF. Full PDF Package Download Full PDF Package. This Paper. A short summary of this paper. 36 Full PDFs related to this paper. Read Paper. Download Download PDF. Download Full PDF Package ...", "dateLastCrawled": "2022-02-02T07:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Driving skill analysis using <b>machine</b> <b>learning</b> The full <b>curve</b> and ...", "url": "https://www.researchgate.net/publication/261398439_Driving_skill_analysis_using_machine_learning_The_full_curve_and_curve_segmented_cases", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/261398439_Driving_skill_analysis_using...", "snippet": "In the full <b>curve</b> driving scene, principal component analysis and a support vector <b>machine</b>-based method accurately classified drivers in 95.7 % of cases when using driving data about high- and low ...", "dateLastCrawled": "2022-01-07T09:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>machine</b> <b>learning</b> - What is the <b>convex hull</b> in ROC <b>curve</b>? - Cross Validated", "url": "https://stats.stackexchange.com/questions/120361/what-is-the-convex-hull-in-roc-curve", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/120361/what-is-the-<b>convex-hull</b>-in-roc-<b>curve</b>", "snippet": "Taking the <b>convex hull</b> of the ROC <b>curve</b> points is just a way of enforcing a constraint that the estimated ROC <b>curve</b> be <b>convex</b> (concave down in this case). It is equivalent to assuming that the distributions of the marker in the cases and in the controls are unimodal. In situations where this assumption is reasonable then imposing the convexity constraint is warranted.", "dateLastCrawled": "2022-01-18T16:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) <b>Performance Evaluation of Machine Learning Algorithms in Apache</b> ...", "url": "https://www.researchgate.net/publication/330478085_Performance_Evaluation_of_Machine_Learning_Algorithms_in_Apache_Spark_for_Intrusion_Detection", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330478085_Performance_Evaluation_of_<b>Machine</b>...", "snippet": "The <b>area under the PR curve is like</b> the ROC. The . difference is that instead of it being a ratio bet ween the true and . false positive rates, it is a r atio between precision and t rue ...", "dateLastCrawled": "2021-11-04T12:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], []], "all_bing_queries": ["+(area under the pr curve)  is like +(area under a curve on a graph)", "+(area under the pr curve) is similar to +(area under a curve on a graph)", "+(area under the pr curve) can be thought of as +(area under a curve on a graph)", "+(area under the pr curve) can be compared to +(area under a curve on a graph)", "machine learning +(area under the pr curve AND analogy)", "machine learning +(\"area under the pr curve is like\")", "machine learning +(\"area under the pr curve is similar\")", "machine learning +(\"just as area under the pr curve\")", "machine learning +(\"area under the pr curve can be thought of as\")", "machine learning +(\"area under the pr curve can be compared to\")"]}