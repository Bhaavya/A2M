{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Partial Derivative</b> (Definition, Formulas and Examples) | <b>Partial</b> ...", "url": "https://byjus.com/maths/partial-derivative/", "isFamilyFriendly": true, "displayUrl": "https://byjus.com/maths/<b>partial-derivative</b>", "snippet": "The formula for <b>partial derivative</b> of f with respect to x <b>taking</b> y as a constant is given by; <b>Partial</b> Differentiation. The process of finding the <b>partial</b> derivatives of a given <b>function</b> is called <b>partial</b> differentiation. <b>Partial</b> differentiation is used when we take one of the tangent lines of the graph of the given <b>function</b> and obtaining its slope. Let\u2019s understand this with the help of the below example. Example: Suppose that f is a <b>function</b> of more than one variable such that, f = x 2 ...", "dateLastCrawled": "2022-02-03T03:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "multivariable calculus - <b>Partial</b> <b>derivative</b> in <b>gradient descent</b> for two ...", "url": "https://math.stackexchange.com/questions/70728/partial-derivative-in-gradient-descent-for-two-variables", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/70728/<b>partial</b>-<b>derivative</b>-in-<b>gradient-descent</b>...", "snippet": "To compute for the <b>partial</b> <b>derivative</b> of the cost <b>function</b> with respect to \u03b8 0, the whole cost <b>function</b> is treated as a single term, so the denominator 2M remains the same. We will find the <b>partial</b> <b>derivative</b> of the numerator with respect to \u03b8 0, \u03b8 1, \u03b8 2. Using the combination of the rule in finding the <b>derivative</b> of a summation, chain ...", "dateLastCrawled": "2022-01-25T08:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Partial</b> <b>Derivative</b> Rules and Examples", "url": "https://byjus.com/jee/basics-of-partial-differentiation/", "isFamilyFriendly": true, "displayUrl": "https://byjus.com/jee/<b>basics-of-partial-differentiation</b>", "snippet": "<b>Partial</b> <b>Derivative</b> Examples . Given below are some of the examples on <b>Partial</b> Derivatives. Question 1: Determine the <b>partial</b> <b>derivative</b> <b>of a function</b> f x and f y: if f(x, y) is given by f(x, y) = tan(xy) + sin x. Solution: Given <b>function</b> is f(x, y) = tan(xy) + sin x. <b>Derivative</b> <b>of a function</b> with respect to x is given as follows:", "dateLastCrawled": "2022-02-02T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "2A. Functions and <b>Partial</b> Derivatives", "url": "https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/2.-partial-derivatives/part-a-functions-of-two-variables-tangent-approximation-and-optimization/problem-set-4/MIT18_02SC_SupProb2.pdf", "isFamilyFriendly": true, "displayUrl": "https://<b>ocw.mit.edu</b>/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/2...", "snippet": "2. <b>PARTIAL</b> DIFFERENTIATION 3 2C-5 The following equations de\ufb01ne w implicitly as a <b>function</b> of the other variables. Find dw in terms of all the variables by <b>taking</b> the di\ufb00erential of both sides and solving algebraically for dw. 1 1 1 1 a) = + + b) u2 +2v2 +3w2 = 10 w t u v 2D. <b>Gradient</b> and Directional <b>Derivative</b>", "dateLastCrawled": "2022-02-03T18:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Is backpropagation a fancy way of saying &quot;calculate <b>gradient</b> by <b>taking</b> ...", "url": "https://stats.stackexchange.com/questions/554764/is-backpropagation-a-fancy-way-of-saying-calculate-gradient-by-taking-partial-d", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/554764/is-backpropagation-a-fancy-way-of...", "snippet": "$\\begingroup$ You have to think computationally.Any differentiation on a neural network will use the chain rule. you could calculate <b>the gradient</b> of each weight independently (without reusing intermediate results). Back propagation is the calculation by first finding errror <b>derivative</b> with respect to output layer, then using that to calculate <b>gradient</b> wrt weights leading into output layer...", "dateLastCrawled": "2022-01-09T19:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Why does <b>gradient</b> descent take the <b>partial</b> <b>derivative</b> rather than the ...", "url": "https://www.reddit.com/r/compsci/comments/4lsga6/why_does_gradient_descent_take_the_partial/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/4lsga6/why_does_<b>gradient</b>_descent_take_the_<b>partial</b>", "snippet": "Sure, you can do a total <b>derivative</b>. But it will be a scalar value that tells you nothing about the direction, which is frequently more important. By <b>taking</b> the <b>partial</b> derivatives, you get a <b>gradient</b> vector. Calculating the scalar value of <b>the gradient</b> from the vector is a piece of cake, and you&#39;ll know the direction too.", "dateLastCrawled": "2021-12-13T14:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Activation Functions and Their Gradients - GitHub Pages", "url": "https://aew61.github.io/blog/artificial_neural_networks/1_background/1.b_activation_functions_and_derivatives.html", "isFamilyFriendly": true, "displayUrl": "https://aew61.github.io/.../1_background/1.b_activation_<b>functions</b>_and_<b>derivatives</b>.html", "snippet": "This matters when computing <b>the gradient</b> of our <b>activation function</b> with respect to an input vector $\\textbf{x}$. So how do we compute gradients of element-wise independent activation functions? Well, technically we need to compute a Jacobian matrix that computes the <b>partial</b> <b>derivative</b> of each input variable to each output variable. For an ...", "dateLastCrawled": "2022-01-30T04:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Derivative</b> and <b>partial</b> <b>derivative</b> of <b>complex</b> functions - Mathematics ...", "url": "https://math.stackexchange.com/questions/2362811/derivative-and-partial-derivative-of-complex-functions", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/.../<b>derivative</b>-and-<b>partial</b>-<b>derivative</b>-of-<b>complex</b>-<b>functions</b>", "snippet": "In the first, the <b>function</b> variations with x and y are completely independent, whereas in a <b>complex</b> <b>function</b> the variable (x+iy) transforms wholly. Accordintly, whatever happens to x, happens to y too (and hence z as well) in terms of the slope, which is the (<b>partial</b>) <b>derivative</b>. Hope this helps. Masoud. Share.", "dateLastCrawled": "2022-01-28T01:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Calculus</b> \u2014 ML Glossary documentation", "url": "https://ml-cheatsheet.readthedocs.io/en/latest/calculus.html", "isFamilyFriendly": true, "displayUrl": "https://ml-cheatsheet.readthedocs.io/en/latest/<b>calculus</b>.html", "snippet": "Each iteration produces a <b>partial</b> <b>derivative</b> which we store in <b>the gradient</b>. ... The directional <b>derivative</b> is computed by <b>taking</b> the dot product of <b>the gradient</b> of \\(f\\) and a unit vector \\(\\vec{v}\\) of \u201ctiny nudges\u201d representing the direction. The unit vector describes the proportions we want to move in each direction. The output of this calculation is a scalar number representing how much \\(f\\) will change if the current input moves with vector \\(\\vec{v}\\). Let\u2019s say you have the ...", "dateLastCrawled": "2022-01-30T22:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why does <b>taking</b> the <b>partial</b> <b>derivative</b> of a stream <b>function</b> in the y ...", "url": "https://physics.stackexchange.com/questions/511921/why-does-taking-the-partial-derivative-of-a-stream-function-in-the-y-axis-gives", "isFamilyFriendly": true, "displayUrl": "https://physics.stackexchange.com/questions/511921", "snippet": "What happens if we take the <b>partial</b> <b>derivative</b> with the axis corresponding with the flow vector? I couldn&#39;t wrap my head around the idea of this concept. I also couldn&#39;t understand this statement that defines the stream <b>function</b>. So the stream <b>function</b> $\\psi$ is the volume flux through the curve $\\ AP$, that is: the integral of the dot product of the flow velocity vector $\\ (u,v)$ and the normal $(+\\ dy,-\\ dx)$ to the curve element $(\\ dx,\\ dy)$.The point $\\ A$ is a reference point defining ...", "dateLastCrawled": "2022-01-26T03:23:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Partial</b> Derivatives, <b>Gradient</b>, Divergence, and Curl <b>Partial</b> Derivatives", "url": "https://www.utm.utoronto.ca/asc/sites/files/asc/public/shared/pdf/tip_sheets_math/RGASC%20-%20Physics%20Math%20-%20Partial%20Derivatives%2C%20Gradient%2C%20Divergence%2C%20and%20Curl.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.utm.utoronto.ca/asc/sites/files/asc/public/shared/pdf/tip_sheets_math/RGASC...", "snippet": "The notation <b>is similar</b> for higher order <b>partial</b> derivatives. Clairaut\u2019s Theorem Suppose that is defined on a disk that contains the point . If the functions and are both continuous on , then . In essence, if is a \u201cnice\u201d <b>function</b>, then a mixed <b>partial</b> <b>derivative</b> is independent of the order we take the derivatives, i.e. . Del Operator The del operator is denoted as which is called nabla. The del operator is a vector written as Basically, the presence of the tells us we are <b>taking</b> a ...", "dateLastCrawled": "2022-01-30T15:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Lecture 9: <b>Partial</b> derivatives", "url": "https://people.math.harvard.edu/~knill/teaching/summer2012/handouts/week3.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.math.harvard.edu/~knill/teaching/summer2012/handouts/week3.pdf", "snippet": "Lecture 9: <b>Partial</b> derivatives If f(x,y) is a <b>function</b> of two variables, then \u2202 \u2202x f(x,y) is de\ufb01ned as the <b>derivative</b> of the <b>function</b> g(x) = f(x,y), where y is considered a constant. It is called <b>partial</b> <b>derivative</b> of f with respect to x. The <b>partial</b> <b>derivative</b> with respect to y is de\ufb01ned similarly. We also use the short hand notation ...", "dateLastCrawled": "2022-02-03T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "multivariable calculus - <b>Partial</b> <b>derivative</b> in <b>gradient descent</b> for two ...", "url": "https://math.stackexchange.com/questions/70728/partial-derivative-in-gradient-descent-for-two-variables", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/70728/<b>partial</b>-<b>derivative</b>-in-<b>gradient-descent</b>...", "snippet": "To compute for the <b>partial</b> <b>derivative</b> of the cost <b>function</b> with respect to \u03b8 0, the whole cost <b>function</b> is treated as a single term, so the denominator 2M remains the same. We will find the <b>partial</b> <b>derivative</b> of the numerator with respect to \u03b8 0, \u03b8 1, \u03b8 2. Using the combination of the rule in finding the <b>derivative</b> of a summation, chain ...", "dateLastCrawled": "2022-01-25T08:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "machine learning - How to interpret <b>gradient</b> and the <b>partial</b> <b>derivative</b> ...", "url": "https://stackoverflow.com/questions/60405965/how-to-interpret-gradient-and-the-partial-derivative-when-updating-the-weights-o", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/60405965", "snippet": "In ANN a neuron is mathematical <b>function</b> or formula, and weights of a neuron are <b>similar</b> to the level of chemical concentration in a human neuron. The weights should be adjusted so that a fix formula can encode all the information to perform all the desired predictions as, encoded in human neuron through concentration of chemical. In order to find out the correct weights ANN is trained by huge data for the problem for which ANN is being trained.", "dateLastCrawled": "2022-01-26T08:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Calculus III - <b>Partial Derivatives</b>", "url": "https://tutorial.math.lamar.edu/Classes/CalcIII/PartialDerivatives.aspx", "isFamilyFriendly": true, "displayUrl": "https://<b>tutorial.math.lamar.edu</b>/Classes/CalcIII/<b>PartialDerivatives</b>.aspx", "snippet": "In this case we call h\u2032(b) h \u2032 ( b) the <b>partial</b> <b>derivative</b> of f (x,y) f ( x, y) with respect to y y at (a,b) ( a, b) and we denote it as follows, f y(a,b) = 6a2b2 f y ( a, b) = 6 a 2 b 2. Note that these two <b>partial derivatives</b> are sometimes called the first order <b>partial derivatives</b>. Just as with functions of one variable we can have ...", "dateLastCrawled": "2022-02-02T04:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Partial</b> <b>derivative</b>. <b>Total differential</b>. Total <b>derivative</b>. Chain rule ...", "url": "https://solitaryroad.com/c353.html", "isFamilyFriendly": true, "displayUrl": "https://solitaryroad.com/c353.html", "snippet": "The <b>partial</b> <b>derivative</b> <b>of a function</b> z = f(x, y, ...) with respect to the variable x is commonly written in any of the following ways: Its <b>derivative</b> with respect to any other variable is written in a <b>similar</b> fashion. Geometric interpretation. The geometric interpretation of a <b>partial</b> <b>derivative</b> is the same as that for an ordinary <b>derivative</b>. It represents the slope of the tangent to that curve represented by the <b>function</b> at a particular point P. In the case <b>of a function</b> of two variables z ...", "dateLastCrawled": "2022-02-02T23:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Partial Derivatives</b> - <b>mathsisfun.com</b>", "url": "https://www.mathsisfun.com/calculus/derivatives-partial.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.mathsisfun.com</b>/calculus/<b>derivatives</b>-<b>partial</b>.html", "snippet": "But what about a <b>function</b> of two variables (x and y): f(x, y) = x 2 + y 3. We can find its <b>partial</b> <b>derivative</b> with respect to x when we treat y as a constant (imagine y is a number like 7 or something): f \u2019 x = 2x + 0 = 2x. Explanation: the <b>derivative</b> of x 2 (with respect to x) is 2x; we treat y as a constant, so y 3 is also a constant (imagine y=7, then 7 3 =343 is also a constant), and the <b>derivative</b> of a constant is 0; To find the <b>partial</b> <b>derivative</b> with respect to y, we treat x as a ...", "dateLastCrawled": "2022-02-02T06:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Can&#39;t make sense of <b>taking</b> <b>partial</b> derivatives of functions of related ...", "url": "https://math.stackexchange.com/questions/3222431/cant-make-sense-of-taking-partial-derivatives-of-functions-of-related-variables", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/3222431/cant-make-sense-of-<b>taking</b>-<b>partial</b>...", "snippet": "Just as in single-variable calculus it is shown that not every <b>function</b> is the <b>derivative</b> of some <b>function</b> (for short, a <b>function</b> that skips intermediate values cannot represent the derived <b>function</b> of some <b>function</b>), we have a <b>similar</b> result that says not every bidimensional vector is <b>the gradient</b> of some bivariable <b>function</b>. The condition that such vectors must satisfy in order to be considered as gradients is that their cross derivatives must be equal and continuous. That is, given the vector", "dateLastCrawled": "2022-01-20T22:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Why does <b>taking</b> the <b>partial</b> <b>derivative</b> of a stream <b>function</b> in the y ...", "url": "https://physics.stackexchange.com/questions/511921/why-does-taking-the-partial-derivative-of-a-stream-function-in-the-y-axis-gives", "isFamilyFriendly": true, "displayUrl": "https://physics.stackexchange.com/questions/511921", "snippet": "So the stream <b>function</b> $\\psi$ is the volume flux through the curve $\\ AP$, that is: the integral of the dot product of the flow velocity vector $\\ (u,v)$ and the normal $(+\\ dy,-\\ dx)$ to the curve element $(\\ dx,\\ dy)$.The point $\\ A$ is a reference point defining where the stream <b>function</b> is zero: a shift of $\\ A$ results in adding a constant to the stream <b>function</b> $\\psi$.", "dateLastCrawled": "2022-01-26T03:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What is <b>the difference between partial derivative and derivative</b>? - Quora", "url": "https://www.quora.com/What-is-the-difference-between-partial-derivative-and-derivative", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-<b>the-difference-between-partial-derivative-and-derivative</b>", "snippet": "Answer (1 of 2): Say you have a <b>function</b> of a single variable, f(x). Then there is no ambiguity about what you are <b>taking</b> the <b>derivative</b> with respect to (it is always with respect to x). But what if I have a <b>function</b> of a few variables, f(x,y,z)? Now, I can take the <b>derivative</b> with respect to x,...", "dateLastCrawled": "2022-01-28T10:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Partial derivative</b> | Math Wiki | Fandom", "url": "https://math.fandom.com/wiki/Partial_derivative", "isFamilyFriendly": true, "displayUrl": "https://math.fandom.com/wiki/<b>Partial_derivative</b>", "snippet": "The <b>partial derivative</b> extends the concept of the <b>derivative</b> in the one-dimensional case by studying real-valued functions defined on subsets of . Informally, the <b>partial derivative</b> of a scalar field may <b>be thought</b> of as the <b>derivative</b> of said <b>function</b> with respect to a single variable. In it is common to write in place of , and we usually speak of the <b>partial derivative</b> of with respect to or , defined by respectively. Fix a vector , and define a <b>function</b> by Then the <b>partial derivative</b> of with r", "dateLastCrawled": "2022-01-23T21:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Calculus III - <b>Partial Derivatives</b>", "url": "https://tutorial.math.lamar.edu/Classes/CalcIII/PartialDerivatives.aspx", "isFamilyFriendly": true, "displayUrl": "https://<b>tutorial.math.lamar.edu</b>/Classes/CalcIII/<b>PartialDerivatives</b>.aspx", "snippet": "In this case we call h\u2032(b) h \u2032 ( b) the <b>partial</b> <b>derivative</b> of f (x,y) f ( x, y) with respect to y y at (a,b) ( a, b) and we denote it as follows, f y(a,b) = 6a2b2 f y ( a, b) = 6 a 2 b 2. Note that these two <b>partial derivatives</b> are sometimes called the first order <b>partial derivatives</b>. Just as with functions of one variable we <b>can</b> have ...", "dateLastCrawled": "2022-02-02T04:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "multivariable calculus - <b>Partial</b> <b>derivative</b> in <b>gradient descent</b> for two ...", "url": "https://math.stackexchange.com/questions/70728/partial-derivative-in-gradient-descent-for-two-variables", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/70728/<b>partial</b>-<b>derivative</b>-in-<b>gradient-descent</b>...", "snippet": "To compute for the <b>partial</b> <b>derivative</b> of the cost <b>function</b> with respect to \u03b8 0, the whole cost <b>function</b> is treated as a single term, so the denominator 2M remains the same. We will find the <b>partial</b> <b>derivative</b> of the numerator with respect to \u03b8 0, \u03b8 1, \u03b8 2. Using the combination of the rule in finding the <b>derivative</b> of a summation, chain ...", "dateLastCrawled": "2022-01-25T08:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Why does <b>taking</b> the <b>partial</b> <b>derivative</b> of a stream <b>function</b> in the y ...", "url": "https://physics.stackexchange.com/questions/511921/why-does-taking-the-partial-derivative-of-a-stream-function-in-the-y-axis-gives", "isFamilyFriendly": true, "displayUrl": "https://physics.stackexchange.com/questions/511921", "snippet": "I <b>thought</b> dot products were scalars. I <b>can</b>&#39;t seem to understand why the <b>partial</b> <b>derivative</b> is taken with respect of the axis that is perpendicular to the flow velocity vector. What happens if we take the <b>partial</b> <b>derivative</b> with the axis corresponding with the flow vector? I couldn&#39;t wrap my head around the idea of this concept. I also couldn&#39;t understand this statement that defines the stream <b>function</b>. So the stream <b>function</b> $\\psi$ is the volume flux through the curve $\\ AP$, that is: the ...", "dateLastCrawled": "2022-01-26T03:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Gradient</b> (video) | <b>Khan Academy</b>", "url": "https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient", "isFamilyFriendly": true, "displayUrl": "https://<b>www.khanacademy.org</b>/.../<b>gradient</b>-and-directional-<b>derivatives</b>/v/<b>gradient</b>", "snippet": "<b>The gradient</b> is a way of packing together all the <b>partial</b> <b>derivative</b> information <b>of a function</b>. So let&#39;s just start by computing the <b>partial</b> derivatives of this guy. So <b>partial</b> of f with respect to x is equal to, so we look at this and we consider x the variable and y the constant. Well in that case sine of y is also a constant. As far as x is concerned, the <b>derivative</b> of x is 2x so we see that this will be 2x times that constant sine of y, sine of y. Whereas the <b>partial</b> <b>derivative</b> with ...", "dateLastCrawled": "2022-02-02T14:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Partial Derivatives</b> \u2013 Calculus Volume 3", "url": "https://opentextbc.ca/calculusv3openstax/chapter/partial-derivatives/", "isFamilyFriendly": true, "displayUrl": "https://opentextbc.ca/calculusv3openstax/chapter/<b>partial-derivatives</b>", "snippet": "A <b>partial</b> <b>derivative</b> is a <b>derivative</b> involving a <b>function</b> of more than one independent variable. To calculate a <b>partial</b> <b>derivative</b> with respect to a given variable, treat all the other variables as constants and use the usual differentiation rules. Higher-order <b>partial derivatives</b> <b>can</b> be calculated in the same way as higher-order derivatives.", "dateLastCrawled": "2022-02-03T07:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is the difference between <b>the gradient</b> and the directional <b>derivative</b>?", "url": "https://math.stackexchange.com/questions/661195/what-is-the-difference-between-the-gradient-and-the-directional-derivative", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/661195/what-is-the-difference-between-the...", "snippet": "For example <b>partial</b> <b>derivative</b> w.r.t x <b>of a function</b> <b>can</b> also be written as directional <b>derivative</b> of that <b>function</b> along x direction. <b>Gradient</b> is a vector and for a given direction, directional <b>derivative</b> <b>can</b> be written as projection of <b>gradient</b> along that direction.", "dateLastCrawled": "2022-02-03T02:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>The Gradient</b> of a Complex Exponential <b>Function</b>", "url": "https://blog.cupcakephysics.com/math%20methods/2014/09/21/the-gradient-of-a-complex-exponential-function.html", "isFamilyFriendly": true, "displayUrl": "https://blog.cupcakephysics.com/math methods/2014/09/21/<b>the-gradient</b>-of-a-complex...", "snippet": "<b>Gradient</b> of a Complex Exponential <b>Function</b> 3D Space. We are interested in <b>taking</b> <b>the gradient</b> of a complex exponential <b>function</b>. This expression pops up all over the place in physics; for example, we see it in Maxwell\u2019s equations and the momentum operator in quantum mechanics. Consider the following expression: \\[\\begin{equation} \\nabla \\left [ e^{i(\\vec{k} \\cdot \\vec{r} - \\omega t)} \\right ] \\end{equation}\\] The vector \\(\\vec{k}\\) is the wavevector of some wave. It is given by: \\[\\vec{k ...", "dateLastCrawled": "2022-01-27T01:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is the <b>inverse of a partial derivative? - Quora</b>", "url": "https://www.quora.com/What-is-the-inverse-of-a-partial-derivative", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-<b>inverse-of-a-partial-derivative</b>", "snippet": "Answer (1 of 9): Just a simple example might give some clues. (I won\u2019t bother with math symbols, apologies for that :-) Take a <b>function</b> z = x + y This is a plane with a double slope: its <b>partial</b> derivatives to x and y being = 1. For a fixed value y=y0, the \u201c<b>partial</b> integral\u201d to x would then be...", "dateLastCrawled": "2022-01-29T02:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Maximum <b>Rate of Change</b> of Surface for Hill : <b>Gradient</b> of scalar field ...", "url": "https://madhavuniversity.edu.in/change-of-surface-for-hill.html", "isFamilyFriendly": true, "displayUrl": "https://madhavuniversity.edu.in/change-of-surface-for-hill.html", "snippet": "<b>Gradient</b>: In mathematics, <b>the gradient</b> is a multi-variable generalization of the <b>derivative</b>. While a <b>derivative</b> <b>can</b> be defined on functions of a single variable, for functions of several variables, <b>the gradient</b> takes its place. <b>The gradient</b> is a vector-valued <b>function</b>, as opposed to a <b>derivative</b>, which is scalar-valued. Like the <b>derivative</b>, the ...", "dateLastCrawled": "2022-02-02T14:20:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introduction to <b>partial</b> derivatives (article) | <b>Khan Academy</b>", "url": "https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/introduction-to-partial-derivatives", "isFamilyFriendly": true, "displayUrl": "https://<b>www.khanacademy.org</b>/.../a/introduction-to-<b>partial</b>-<b>derivatives</b>", "snippet": "With respect to three-dimensional graphs, you <b>can</b> picture the <b>partial</b> <b>derivative</b> by slicing the graph of with a plane representing a constant -value and measuring the slope of the resulting curve along the cut. Intersecting y=0 plane with the graph.", "dateLastCrawled": "2022-02-03T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Lecture 9: <b>Partial</b> derivatives", "url": "https://people.math.harvard.edu/~knill/teaching/summer2012/handouts/week3.pdf", "isFamilyFriendly": true, "displayUrl": "https://people.math.harvard.edu/~knill/teaching/summer2012/handouts/week3.pdf", "snippet": "Lecture 9: <b>Partial</b> derivatives If f(x,y) is a <b>function</b> of two variables, then \u2202 \u2202x f(x,y) is de\ufb01ned as the <b>derivative</b> of the <b>function</b> g(x) = f(x,y), where y is considered a constant. It is called <b>partial</b> <b>derivative</b> of f with respect to x. The <b>partial</b> <b>derivative</b> with respect to y is de\ufb01ned similarly. We also use the short hand notation ...", "dateLastCrawled": "2022-02-03T05:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>gradient</b> descent - <b>Partial</b> derviative of prediction (sigmoid applied ...", "url": "https://datascience.stackexchange.com/questions/47402/partial-derviative-of-prediction-sigmoid-applied-with-respect-to-weight", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/47402", "snippet": "The above is <b>taking</b> the <b>derivative</b> of a sigmoid so why isn&#39;t it just $$=\\sigma(Wx+b)(1-\\sigma(Wx+b)$$ but rather has $\\frac{\\<b>partial</b>}{\\<b>partial</b> w_j}(Wx+b)$ tacked on the tail? <b>gradient</b>-descent. Share. Improve this question. Follow edited Mar 16 &#39;19 at 10:17. mLstudent33. asked ...", "dateLastCrawled": "2022-01-20T22:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "calculus - What is the <b>difference between</b> <b>partial</b> and normal ...", "url": "https://math.stackexchange.com/questions/1435065/what-is-the-difference-between-partial-and-normal-derivatives", "isFamilyFriendly": true, "displayUrl": "https://math.stackexchange.com/questions/1435065", "snippet": "I hope this answers your question. The <b>partial</b> <b>derivative</b> notation is used to specify the <b>derivative</b> <b>of a function</b> of more than one variable with respect to one of its variables.", "dateLastCrawled": "2022-02-02T18:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 4, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Partial derivative</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Partial_derivative", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Partial_derivative</b>", "snippet": "In mathematics, a <b>partial derivative</b> <b>of a function</b> of several variables is its <b>derivative</b> with respect to one of those variables, with the others held constant (as opposed to the total <b>derivative</b>, in which all variables are allowed to vary).<b>Partial</b> derivatives are used in vector calculus and differential geometry.. The <b>partial derivative</b> <b>of a function</b> (,, \u2026) with respect to the variable is variously denoted by \u2032, , , , , or . Sometimes, for = (,, \u2026), the <b>partial derivative</b> of with ...", "dateLastCrawled": "2022-02-03T00:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Gradient Descent</b> vs Stochastic GD vs Mini-Batch SGD | by Ethan Irby ...", "url": "https://medium.com/analytics-vidhya/gradient-descent-vs-stochastic-gd-vs-mini-batch-sgd-fbd3a2cb4ba4", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>gradient-descent</b>-vs-stochastic-gd-vs-mini-batch...", "snippet": "This means 800,000 <b>partial</b> derivatives computed to reach the lowest loss <b>function</b> value. So, <b>Gradient descent</b> requires calculating <b>the gradient</b> using the entire dataset to perform updates to the ...", "dateLastCrawled": "2022-01-26T08:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "An Introduction to <b>Gradient</b> Descent | by Yang S | Towards Data Science", "url": "https://towardsdatascience.com/an-introduction-to-gradient-descent-c9cca5739307", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/an-introduction-to-<b>gradient</b>-descent-c9cca5739307", "snippet": "1. <b>Gradient</b>. <b>Gradient</b> is a vector that is tangent <b>of a function</b> and points in the direction of greatest increase of this <b>function</b>. <b>Gradient</b> is zero at a local maximum or minimum because there is no single direction of increase. In mathematics, <b>gradient</b> is defined as <b>partial</b> <b>derivative</b> for every input variable of <b>function</b>. For example, we have a ...", "dateLastCrawled": "2022-01-31T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is a <b>partial derivative x/partial derivative</b> y? - Quora", "url": "https://www.quora.com/What-is-a-partial-derivative-x-partial-derivative-y", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-a-<b>partial-derivative-x-partial-derivative</b>-y", "snippet": "Answer (1 of 2): A <b>Partial Derivative</b> is a <b>derivative</b> where we hold some variables constant. For a <b>function</b> with multiple variables, we <b>can</b> find the <b>derivative</b> of one variable holding other variables constant. We use f\u2019x to mean &quot;the <b>partial derivative</b> with respect to x&quot;, but another very common...", "dateLastCrawled": "2022-01-20T00:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "python - How to do a <b>gradient</b> descent problem (machine learning ...", "url": "https://stackoverflow.com/questions/55093279/how-to-do-a-gradient-descent-problem-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/55093279", "snippet": "The same logic as above applies except now we take the <b>partial</b> derivatives instead of <b>derivative</b>. Update rule is. x = x - dpf_dx*lr y = y - dpf_dy*lr Where dpf_dx is the <b>partial</b> <b>derivative</b> of f with respect to x. The above algorithm is called <b>the gradient</b> decent algorithm. In Machine learning the f(x,y) is a cost/loss <b>function</b> whose minimum we ...", "dateLastCrawled": "2022-01-07T09:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "python pandas: how to calculate <b>derivative</b>/<b>gradient</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/41780489/python-pandas-how-to-calculate-derivative-gradient", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/41780489", "snippet": "&gt; <b>Can</b> you explain why np.<b>gradient</b> doesn&#39;t produce the same results as the first proposed answer. \u2013 Darthtrader May 5 at 9:58 np.<b>gradient</b> uses a 2nd order scheme while .diff() uses a 1st order scheme. This means that the results from np.<b>gradient</b> will be continuous as will the <b>derivative</b>. The results from .diff() do not have to have a continuous <b>derivative</b>. Essentially np.<b>gradient</b> gives &#39;smoother&#39; results.", "dateLastCrawled": "2022-01-28T08:10:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine learning derivatives</b> - Geoffrey Huck", "url": "https://geoffreyhuck.com/articles/machine-learning-derivatives", "isFamilyFriendly": true, "displayUrl": "https://geoffreyhuck.com/articles/<b>machine-learning-derivatives</b>", "snippet": "An <b>analogy</b> would be finding which direction you should take to reach the highest mountain but with the restriction of only being able to see one meter away. In this article, we will first recall the rules of derivatives and <b>partial</b> derivatives. Then we will feature a few derivatives of functions that are commonly used in <b>machine</b> <b>learning</b>. The derivatives rules. The basics. Let\u2019s start by the derivatives of common functions. In the following : is a constant. is the variable by which we ...", "dateLastCrawled": "2021-12-29T05:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Analogues in thermodynamics: the <b>Partial</b> <b>Derivative</b> <b>Machine</b> and ...", "url": "https://osuper.science.oregonstate.edu/sites/osuper.science.oregonstate.edu/files/VignalPDMPERC2017.pdf", "isFamilyFriendly": true, "displayUrl": "https://osuper.science.oregonstate.edu/sites/osuper.science.oregonstate.edu/files/...", "snippet": "an e ort to foster student <b>learning</b> in thermodynamics, the Oregon State University Physics Education Research Group developed the <b>Partial</b> <b>Derivative</b> <b>Machine</b> (PDM) as a mechanical analogue to a thermodynamic system [2]. The PDM (Fig. 1) can be used to help students explore many challenging aspects of thermodynamics, in-cluding inaccessible variables and thermodynamic poten-tials, on a mechanical system that students can under-stand without having to rst learn new physical concepts [3 ...", "dateLastCrawled": "2021-12-01T18:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Learning</b> in <b>Machine</b> <b>Learning</b>", "url": "https://cambum.net/CCE/LearningParameter.pdf", "isFamilyFriendly": true, "displayUrl": "https://cambum.net/CCE/<b>Learning</b>Parameter.pdf", "snippet": "<b>Learning</b> Rate \u2013 Basic Algorithm 21 The delta-bar-delta algorithm is an early heuristic approach to adapting individual <b>learning</b> rates for model parameters during training. If the <b>partial</b> <b>derivative</b> of the loss, with respect to a given model parameter, remains the same sign, then the <b>learning</b> rate should increase.", "dateLastCrawled": "2022-01-29T04:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Analogues in thermodynamics: the <b>Partial</b> <b>Derivative</b> <b>Machine</b> and ...", "url": "https://www.compadre.org/per/items/4833.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.compadre.org/per/items/4833.pdf", "snippet": "foster student <b>learning</b> in thermodynamics, the Oregon State University Physics Education Research Group de-veloped the <b>Partial</b> <b>Derivative</b> <b>Machine</b> (PDM) as a me-chanical analogue to a thermodynamic system [2]. The PDM (Fig. 1) allows students to explore challenging aspects of thermodynamics, including inaccessible vari-ables and thermodynamic potentials, on a mechanical system that students can understand without having to rst learn new thermodynamic concepts [3]. We con-ducted post ...", "dateLastCrawled": "2021-10-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Mathematics <b>for Machine Learning: Multivariate Calculus</b> | by Isaac Ng ...", "url": "https://medium.com/@isaacng/mathematics-for-machine-learning-multivariate-calculus-7102c7a586c6", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@isaacng/mathematics-<b>for-machine-learning-multivariate-calculus</b>...", "snippet": "Graph with no <b>derivative</b> at 0. Finding the gradient. The gradient of a variable in a function is the rise over run against the other variables. In the classic x, y coordinate plot, the rise over ...", "dateLastCrawled": "2022-01-25T18:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>machine</b> <b>learning</b> - <b>Neural Network Regularization and derivation</b> - Cross ...", "url": "https://stats.stackexchange.com/questions/502047/neural-network-regularization-and-derivation", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/502047/neural-network-regularization-and...", "snippet": "The p index is there for us to carry out matrix multiplication. Recall that to perform matrix-vector multiplication A x where A \u2208 R m \u00d7 n and x \u2208 R n, the i -th entry is equal to \u2211 p = 1 n A i p x p . Notice that we are using <b>partial</b> <b>derivative</b> and hence \u2202 W j p [ l] \u2202 W j k [ l] = { 1, p = k 0, p \u2260 k.", "dateLastCrawled": "2022-01-22T09:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Notes on <b>Deep Learning and Differential Equations</b>. \u2013 Cloud Computing ...", "url": "https://cloud4scieng.org/2020/06/10/notes-on-deep-learning-and-differential-equations/", "isFamilyFriendly": true, "displayUrl": "https://cloud4scieng.org/2020/06/10/notes-on-<b>deep-learning-and-differential-equations</b>", "snippet": "We now turn to the work on using neural networks to solve <b>partial</b> differential equations. The examples we will study are from four papers. Raissi, Perdikaris, and Karniadakis, \u201cPhysics Informed Deep <b>Learning</b> (Part II): Data-driven Discovery of Nonlinear <b>Partial</b> Di\ufb00erential Equations\u201d, Nov 2017, is the paper that introduces PINNS and demonstrates the concept by showing how to solve several \u201cclassical\u201d PDEs. Yang, Zhang, and Karniadakis, \u201cPhysics-Informed Generative Adversarial ...", "dateLastCrawled": "2022-02-03T00:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "neural network - Gradient descent and <b>partial derivatives</b> - Data ...", "url": "https://datascience.stackexchange.com/questions/28691/gradient-descent-and-partial-derivatives", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/28691", "snippet": "Data Science Stack Exchange is a question and answer site for Data science professionals, <b>Machine</b> <b>Learning</b> specialists, and those interested in <b>learning</b> more about the field.", "dateLastCrawled": "2022-02-01T18:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Gradient Descent</b> in Python. When you venture into <b>machine</b> <b>learning</b> ...", "url": "https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>gradient-descent</b>-in-python-a0d07285742f", "snippet": "<b>Gradient descent</b> is the backbone of an <b>machine</b> <b>learning</b> algorithm. In this article I am going to attempt to explain the fundamentals of <b>gradient descent</b> using python code. Once you get hold of <b>gradient descent</b> things start to be more clear and it is easy to understand different algorithms.Much has been already written on this topic so it is not going to be a ground breaking one. To follow along and build your own <b>gradient descent</b> you will need some basic python packages viz. numpy and ...", "dateLastCrawled": "2022-02-02T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Why are <b>Partial</b> Differential Equations and Ordinary Differential ...", "url": "https://smg.quora.com/Why-are-Partial-Differential-Equations-and-Ordinary-Differential-Equations-taught-as-two-separate-subjects-True-at-my-s", "isFamilyFriendly": true, "displayUrl": "https://smg.quora.com/Why-are-<b>Partial</b>-Differential-Equations-and-Ordinary-Differential...", "snippet": "Differential Equations are very relevant for a number of <b>machine</b> <b>learning</b> methods, mostly those inspired by <b>analogy</b> to some mathematical models in physics. Differential equations are one of the most fundamental tools in physics to model the dynamics of a system. With differential equations you basically link the rate of change of one quantity to other properties of the system (with many variations on this topic). So when you want to model your learner as some dynamical model (for example, a ...", "dateLastCrawled": "2022-01-19T16:45:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "[1\uc8fc\ucc28] Coursera <b>Machine</b> <b>Learning</b> : <b>Regression</b>", "url": "https://enthan.tistory.com/41", "isFamilyFriendly": true, "displayUrl": "https://enthan.tistory.com/41", "snippet": "<b>partial derivative is like</b> a derivative with respect to w1, treating all variables as constants . Convex =&gt; solution is unique + gradient descent algorithm will converge to minimum . \ubc18\uc751\ud615 . \uacf5\uc720\ud558\uae30. \uae00 \uc694\uc18c. \uad6c\ub3c5\ud558\uae30 \uc5d4\uc9c0\ub2c8\uc5b4\uc758 \ub534\uc0dd\uac01 &#39;Data Science &gt; <b>Machine</b> <b>Learning</b>&#39; \uce74\ud14c\uace0\ub9ac\uc758 \ub2e4\ub978 \uae00 (0) 2021.05.27 [2\uc8fc\ucc28] Multiple <b>Regression</b> (0) 2021.05.27 [1\uc8fc\ucc28] Coursera <b>Machine</b> <b>Learning</b> : <b>Regression</b> (0) 2021.05.27: Scikit-Learn\uc744 \uc774\uc6a9\ud55c \uba38\uc2e0\ub7ec\ub2dd (0) 2020.10 ...", "dateLastCrawled": "2021-12-25T20:07:00.0000000Z", "language": "ko", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>Learning</b>", "url": "https://feisky.xyz/machine-learning/tensorflow/getting-started.html", "isFamilyFriendly": true, "displayUrl": "https://feisky.xyz/<b>machine</b>-<b>learning</b>/tensorflow/getting-started.html", "snippet": "Too large # jumps risk inaccuracy, too small slow the <b>learning</b>. <b>learning</b>_rate = 0.002 # In TensorFlow, we need to run everything in the context of a session. with tf. Session() as sess: # Set up all the tensors. # Our input layer is the x value and the bias node. input = tf. constant(x_with_bias) # Our target is the y values.", "dateLastCrawled": "2021-05-17T21:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Gradient Descent | Programming <b>Machine</b> <b>Learning</b> by Paolo Perrotta | The ...", "url": "https://medium.com/pragmatic-programmers/gradient-descent-1a227b6ddba5", "isFamilyFriendly": true, "displayUrl": "https://medium.com/pragmatic-programmers/gradient-descent-1a227b6ddba5", "snippet": "Programming <b>Machine</b> <b>Learning</b> \u2014 by Paolo Perrotta (20 / 133) Let\u2019s look for a better train algorithm. The job of train is to find the parameters that minimize the loss, so let\u2019s start by ...", "dateLastCrawled": "2021-08-23T13:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "October | 2012 | <b>SLog of the most illogical mind</b>", "url": "https://slogofillogicalmind.wordpress.com/2012/10/", "isFamilyFriendly": true, "displayUrl": "https://slogofillogicalmind.wordpress.com/2012/10", "snippet": "Abstract data type is like a imaginary <b>machine</b> that have some skills that we need to use. Programmer is the engineer to build this robot. But if you just simply want to this robot, you just need to know what operation you can use with this. For example there is a stack in ADT. Just think of one robot called \u201cstack\u201d and what it does is stores all the things that you put in it and take it back to you the item but in reverse order that you put in. So the item that you put in at the last ...", "dateLastCrawled": "2022-01-26T01:55:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Predicting <b>cell phone adoption metrics</b> using <b>machine</b> <b>learning</b> and ...", "url": "https://www.sciencedirect.com/science/article/pii/S0736585321000617", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0736585321000617", "snippet": "In this paper we present a <b>machine</b> <b>learning</b> method that uses publicly available satellite imagery to predict telecoms demand metrics, including cell phone adoption and spending on mobile services, and apply the method to Malawi and Ethiopia. Our predictive <b>machine</b> <b>learning</b> approach consistently outperforms baseline models which use population density or nightlight luminosity, with an improvement in data variance prediction of at least 40%. The method is a starting point for developing more ...", "dateLastCrawled": "2021-10-21T14:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) <b>Predicting cell phone adoption metrics using machine learning</b> and ...", "url": "https://www.researchgate.net/publication/350756678_Predicting_cell_phone_adoption_metrics_using_machine_learning_and_satellite_imagery", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/350756678_Predicting_cell_phone_adoption...", "snippet": "<b>machine</b> <b>learning</b> with call records and satellite image ry, to address a similar set of questions relating to poverty estimation (Ayush et al., 2020; Jean et al., 2016; Perez et al., 2017; Steele ...", "dateLastCrawled": "2021-12-25T00:20:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(partial derivative)  is like +(taking the gradient of a function)", "+(partial derivative) is similar to +(taking the gradient of a function)", "+(partial derivative) can be thought of as +(taking the gradient of a function)", "+(partial derivative) can be compared to +(taking the gradient of a function)", "machine learning +(partial derivative AND analogy)", "machine learning +(\"partial derivative is like\")", "machine learning +(\"partial derivative is similar\")", "machine learning +(\"just as partial derivative\")", "machine learning +(\"partial derivative can be thought of as\")", "machine learning +(\"partial derivative can be compared to\")"]}