{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>High-Resolution</b>, Pixel-<b>Dense</b> Displays: Why Megapixels are Important", "url": "https://www.azosensors.com/article.aspx?ArticleID=2346", "isFamilyFriendly": true, "displayUrl": "https://www.azosensors.com/article.aspx?ArticleID=2346", "snippet": "Simply put, to measure a <b>high-resolution</b> display, a <b>high-resolution</b> system is needed. <b>High resolution</b> is important not only for big screens <b>like</b> televisions but also for small displays such as smartphones and smartwatches that are viewed close up. Users expect a crystal-clear <b>image</b>. Shown here: the Apple Watch 5 and iPhone 11 Pro.", "dateLastCrawled": "2022-01-27T17:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>High resolution non-rigid</b> <b>dense</b> matching based on optimized sampling ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231217302485", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231217302485", "snippet": "A <b>high resolution</b> <b>dense</b> matching algorithm is presented for non-rigid <b>image</b> <b>feature</b> matching in the paper. For <b>high resolution non-rigid</b> images, telephoto lens is helpful in capturing fine scale features <b>like</b> cloth fold, pigmentation and skin pores. It brings us serious <b>image</b> noises which are less texture and bokeh, respectively. In order to avoid mismatch and non-uniform matching, we propose an optimized sampling method based on Gibbs <b>dense</b> sampling considering both texture <b>feature</b> ...", "dateLastCrawled": "2021-12-06T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Why Megapixels Matter: Measuring <b>High-Resolution</b>, Pixel-<b>Dense</b> Displays ...", "url": "https://www.radiantvisionsystems.com/blog/why-megapixels-matter-measuring-high-resolution-pixel-dense-displays", "isFamilyFriendly": true, "displayUrl": "https://www.radiantvisionsystems.com/blog/why-megapixels-matter-measuring-high...", "snippet": "By combining <b>high-resolution</b> sensors with careful engineering, Radiant\u2019s new ProMetric imaging systems can perform inspection of <b>high-resolution</b>, pixel-<b>dense</b> displays at high speeds to keep pace with manufacturing production lines. With the new 45MP and 61MP ProMetric models in our product portfolio, we are positioned to solve measurement challenges for display manufacturers now and into the future as microLEDs, quantum dots (QD), and other nano-scale display pixel technologies become ...", "dateLastCrawled": "2022-02-01T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>HIGH-RESOLUTION IMAGE CLASSIFICATION WITH CONVOLUTIONAL NETWORKS</b>", "url": "https://www.lri.fr/~gcharpia/highres_igarss2017.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.lri.fr/~gcharpia/highres_igarss2017.pdf", "snippet": "<b>Dense</b> <b>image</b> classi\ufb01cation, or semantic labeling, is the prob-lem of assigning a semantic class to every pixel in an <b>image</b>. In certain application domains, such as urban mapping, it is important to provide \ufb01ne-grained classi\ufb01cation maps where object boundaries are precisely located. Over the last few years, deep learning and more speci\ufb01cally convolutional neural networks (CNNs) have gained signi\ufb01cant attention in the community. In particular, fully convolutional networks (FCNs) [1 ...", "dateLastCrawled": "2021-08-29T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Generic Object Detection with <b>Dense</b> Neural Patterns and Regionlets", "url": "https://ai.stanford.edu/~wzou/bmvc2014_ZouWangSunLin.pdf", "isFamilyFriendly": true, "displayUrl": "https://ai.stanford.edu/~wzou/bmvc2014_ZouWangSunLin.pdf", "snippet": "After the deep CNN training on large-scale <b>image</b> classi\ufb01cation, the recognition module is employed to produce <b>dense</b> <b>feature</b> maps on <b>high-resolution</b> detection images. We call the combination of this technique and the resulting <b>feature</b> set <b>Dense</b> Neural Patterns (DNPs).", "dateLastCrawled": "2022-01-07T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>High Resolution Image Correspondences for Video Post-Production</b> \u2014 JVRB ...", "url": "https://www.jvrb.org/past-issues/9.2012/3554", "isFamilyFriendly": true, "displayUrl": "https://www.jvrb.org/past-issues/9.2012/3554", "snippet": "Establishing <b>dense</b> <b>image</b> correspondences between images is still a challenging problem, especially when the input images <b>feature</b> long-range motion and large occluded areas. With the increasing availability of <b>high-resolution</b> content, the requirements for correspondence estimation between images are further increased. <b>High resolution</b> images often exhibit many ambiguous details in places where their low resolution predecessors only show uniformly colored areas, thus the need for smarter and ...", "dateLastCrawled": "2021-12-26T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Object Detection in Very <b>High-Resolution</b> Aerial Images Using One-Stage ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6210269/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC6210269", "snippet": "The <b>feature</b> map C7 is calculated by first applying ReLU activation function on the <b>feature</b> map C6 then convolving the resultant output by 256 kernels with kernel sizes equal to (3, 3) and strides equal to (2, 2) on vertical and horizontal directions. Thus, the bottom-up pathway produces <b>feature</b> maps {C3, C4, C5, C6, and C7} where the strides are {8, 16, 32, 64, and 128} for each <b>feature</b> map, respectively. Top-down pathway is obtained by constructing densely connected <b>feature</b> pyramid network ...", "dateLastCrawled": "2022-01-07T07:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Dense</b> <b>matching in high resolution oblique airborne images</b>", "url": "https://www.researchgate.net/publication/228338400_Dense_matching_in_high_resolution_oblique_airborne_images", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/228338400_<b>Dense</b>_matching_in_<b>high_resolution</b>...", "snippet": "<b>Dense</b> <b>image</b> matching results in <b>dense</b> point cloud data by exploiting forward intersection of maximum corresponding <b>feature</b> points in object space (Gerke, 2009). Semi-Global matching (SGM ...", "dateLastCrawled": "2021-10-18T04:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "An efficient <b>image</b> super resolution model with <b>dense</b> skip connections ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417421011489", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417421011489", "snippet": "Instead of using pixel-wise difference, <b>feature</b>-wise difference is calculated to generate a <b>high resolution</b> <b>image</b>. SRGAN architecture and loss functions are reanalyzed by Wang et al. (2018) . They introduced the concept of <b>dense</b> residual blocks with relativistic discriminator to further enhance the perceptual quality of <b>image</b>.", "dateLastCrawled": "2021-11-21T23:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Remote Sensing | Free Full-Text | Classification for <b>High Resolution</b> ...", "url": "https://www.mdpi.com/2072-4292/9/5/498/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/9/5/498/htm", "snippet": "The most significant <b>feature</b> of the FCN model is: on the one hand, FCN inherits the high accuracy <b>feature</b> for <b>image</b>-label classification from standard CNN. On the other hand, it maintains the 2-D spatial information of the input <b>image</b>, thus achieving <b>dense</b> class prediction. However, pooling operations cause serious reduction of the resolution. The output is not fine enough, which will result in the loss of valuable detail information. As can be seen from", "dateLastCrawled": "2022-01-28T16:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Single <b>Image</b> Super-Resolution Based on Global <b>Dense</b> <b>Feature</b> Fusion ...", "url": "https://res.mdpi.com/sensors/sensors-19-00316/article_deploy/sensors-19-00316-v2.pdf", "isFamilyFriendly": true, "displayUrl": "https://res.mdpi.com/sensors/sensors-19-00316/article_deploy/sensors-19-00316-v2.pdf", "snippet": "It aims to reconstruct a visually pleasing <b>high resolution</b> (HR) <b>image</b> from the degraded low resolution (LR) one. SISR has been applied in various \ufb01elds, such as facial recognition, medical imaging, and surveillance systems [1,2]. The relationship between HR <b>image</b> and LR <b>image</b> is based on the situation, thus, SISR is a highly ill-posed inverse problem. A common assumption is that the LR <b>image</b> is a bicubic downsampled version of the HR <b>image</b> but, in practical application, there are so many ...", "dateLastCrawled": "2022-01-26T21:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Single <b>Image</b> Super-Resolution Based on Global <b>Dense</b> <b>Feature</b> Fusion ...", "url": "https://europepmc.org/article/PMC/PMC6359588", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC6359588", "snippet": "Single <b>Image</b> Super-Resolution Based on Global <b>Dense</b> <b>Feature</b> Fusion Convolutional Network. ... It is essential to extract <b>image</b> features and perform non-linear representation to achieve <b>high resolution</b> <b>image</b> restoration. Recently, deep learning-based methods [12,13,14,15,16,17,18,19,20,21,22] have achieved superior performance over conventional methods in SISR. SRCNN firstly end-to-end learns the mapping between LR <b>image</b> and HR <b>image</b>. However, there are still existing problems, like lack of ...", "dateLastCrawled": "2022-01-27T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "FaPN: <b>Feature</b>-Aligned Pyramid Network for <b>Dense</b> <b>Image</b> Prediction", "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_FaPN_Feature-Aligned_Pyramid_Network_for_Dense_Image_Prediction_ICCV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_FaPN_<b>Feature</b>-Aligned...", "snippet": "FaPN: <b>Feature</b>-aligned Pyramid Network for <b>Dense</b> <b>Image</b> Prediction ... aggregate multi-scale context from <b>high-resolution</b> <b>feature</b> maps. Building upon ASPP, a family of methods [4\u20136] were 865. developed. However, the lack of the ability to generate <b>fea-ture</b> maps at multiple scales restricts the application of this type of methods to other <b>dense</b> prediction tasks beyond se-mantic segmentation. The second group of methods focuses on building an encoder-decoder network, i.e. bottom-up and top ...", "dateLastCrawled": "2022-02-03T06:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Reference guided image super-resolution via efficient dense warping</b> and ...", "url": "https://www.sciencedirect.com/science/article/pii/S092359652030196X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S092359652030196X", "snippet": "Due to the limited improvement of single-<b>image</b> based super-resolution (SR) methods in recent years, the reference based <b>image</b> SR (RefSR) methods, which super-resolve the low-resolution (LR) input with the guidance of <b>similar</b> <b>high-resolution</b> (HR) reference images are emerging. There are two main challenges in RefSR, i.e. reference <b>image</b> warping and exploring the guidance information from the warped references. For reference warping, we propose an efficient <b>dense</b> warping method to deal with ...", "dateLastCrawled": "2021-12-28T19:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>High Resolution Image Correspondences for Video Post-Production</b> \u2014 JVRB ...", "url": "https://www.jvrb.org/past-issues/9.2012/3554", "isFamilyFriendly": true, "displayUrl": "https://www.jvrb.org/past-issues/9.2012/3554", "snippet": "Establishing <b>dense</b> <b>image</b> correspondences between images is still a challenging problem, especially when the input images <b>feature</b> long-range motion and large occluded areas. With the increasing availability of <b>high-resolution</b> content, the requirements for correspondence estimation between images are further increased. <b>High resolution</b> images often exhibit many ambiguous details in places where their low resolution predecessors only show uniformly colored areas, thus the need for smarter and ...", "dateLastCrawled": "2021-12-26T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Generic Object Detection with <b>Dense</b> Neural Patterns and Regionlets", "url": "https://ai.stanford.edu/~wzou/bmvc2014_ZouWangSunLin.pdf", "isFamilyFriendly": true, "displayUrl": "https://ai.stanford.edu/~wzou/bmvc2014_ZouWangSunLin.pdf", "snippet": "This <b>is similar</b> to a HOG <b>feature</b> extractor, which produces the same histograms for <b>image</b> patches with the same appearance. Other architectures such as local re- ceptive \ufb01eld networks with untied weights (Le et al., 2012) o r fully-connected networks1 do not have these properties. Not only are these properties valid for a one-layer CNN, they are also valid for a deep CNN with many stacked layers and all dimensions of its <b>feature</b> maps2. By virtue of these desirable properties, we employ the ...", "dateLastCrawled": "2022-01-07T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What Is It Like Down There? Generating <b>Dense</b> Ground-Level Views and ...", "url": "https://dl.acm.org/doi/pdf/10.1145/3274895.3274969", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/pdf/10.1145/3274895.3274969", "snippet": "images to produce <b>dense</b> <b>feature</b> maps. This is the approach taken by Workman et al. in [33] to fuse VGG-16 features extracted from Google Street View images with <b>high-resolution</b> satellite imagery for <b>dense</b> land-use classification. However, as we showed in previ-ous work [5], this interpolate-then-classify approach assumes that", "dateLastCrawled": "2021-07-10T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Review: MSDNet \u2014 Multi-<b>Scale Dense Networks (Image Classification</b>) | by ...", "url": "https://towardsdatascience.com/review-msdnet-multi-scale-dense-networks-image-classification-4d949955f6d5", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/review-msdnet-multi-scale-<b>dense</b>-networks-<b>image</b>...", "snippet": "The horizontal connections preserve and progress <b>high-resolution</b> information, ... An MSDNet with six intermediate classifiers are used, and the three main components, multi-scale <b>feature</b> maps, <b>dense</b> connectivity, and intermediate classifiers, are removed one at a time. If all the three components in an MSDNet are removed, a regular VGG-like convolutional network is obtained. To make our comparisons fair, we keep the computational costs of the full networks <b>similar</b>, at around 3.0\u00d710\u2078 FLOPs ...", "dateLastCrawled": "2022-01-30T15:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Semantic Segmentation of Very-<b>High-Resolution</b> Remote Sensing Images via ...", "url": "https://www.mdpi.com/2072-4292/14/3/533/html", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/14/3/533/html", "snippet": "Consequently, we design a scheme of <b>dense</b> <b>feature</b> aggregation in order to fully exploit the strengths of each <b>feature</b>, to acquire valuable information and enhance the segmentation performance. First of all, con . feat F c o n and dis . feat F d i s are concatenated together and passed through a 1 \u00d7 1 convolutional layer to generate the resulting <b>feature</b> F c .", "dateLastCrawled": "2022-02-03T11:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Remote Sensing | Free Full-Text | Classification for <b>High Resolution</b> ...", "url": "https://www.mdpi.com/2072-4292/9/5/498/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/9/5/498/htm", "snippet": "The most significant <b>feature</b> of the FCN model is: on the one hand, FCN inherits the high accuracy <b>feature</b> for <b>image</b>-label classification from standard CNN. On the other hand, it maintains the 2-D spatial information of the input <b>image</b>, thus achieving <b>dense</b> class prediction. However, pooling operations cause serious reduction of the resolution. The output is not fine enough, which will result in the loss of valuable detail information. As can be seen from", "dateLastCrawled": "2022-01-28T16:04:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>High-Resolution Semantic Labeling with Convolutional Neural Networks</b> ...", "url": "https://deepai.org/publication/high-resolution-semantic-labeling-with-convolutional-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>high-resolution-semantic-labeling-with-convolutional</b>...", "snippet": "The <b>dense</b> semantic labeling problem <b>can</b> be seen as classifying the central pixel of an <b>image</b> patch, the size of the input patch being the receptive field used to classify it. To label the whole <b>image</b> the prediction must thus be performed on many overlapping <b>image</b> patches, which requires a huge amount of redundant operations.", "dateLastCrawled": "2021-12-20T22:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Responsive Images</b> Revisited\u2014<b>High Resolution Images</b>", "url": "https://vanseodesign.com/web-design/responsive-images-revisitedhigh-resolution-images/", "isFamilyFriendly": true, "displayUrl": "https://vanseodesign.com/web-design/<b>responsive-images</b>-revisited<b>high-resolution-images</b>", "snippet": "What makes for a <b>high resolution</b> <b>image</b>? Is it the pixels per inch (ppi)? Is it the dots per inch (dpi)? What distinguishes an <b>image</b> as @1x, @2x, or @3x? If we\u2019re going to create pixel <b>dense</b> images for <b>high resolution</b> devices, it probably makes sense to understand a little about what is a <b>high resolution</b> <b>image</b>. For the last couple of weeks I\u2019ve been talking about <b>responsive images</b>, specifically how the spec is stabilizing around the srcset attribute and the picture element. As part of the ...", "dateLastCrawled": "2021-11-28T06:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Semantic Segmentation using Fully Convolutional Networks</b> over the years", "url": "https://www.meetshah.dev/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html", "isFamilyFriendly": true, "displayUrl": "https://www.meetshah.dev/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/...", "snippet": "A general semantic segmentation architecture <b>can</b> be broadly <b>thought</b> of as an encoder network followed by a decoder network. The encoder is usually is a pre-trained classification network like VGG/ResNet followed by a decoder network. The decoder network/mechanism is mostly where these architectures differ. The task of the decoder is to semantically project the discriminative features (lower resolution) learnt by the encoder onto the pixel space (higher resolution) to get a <b>dense</b> ...", "dateLastCrawled": "2022-02-01T00:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Multimodal Images Classification using <b>Dense</b> SURF, Spectral ...", "url": "https://www.researchgate.net/publication/331309468_Multimodal_Images_Classification_using_Dense_SURF_Spectral_Information_and_Support_Vector_Machine", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/331309468_Multimodal_<b>Images</b>_Classification...", "snippet": "The learned hyper-planes separating one class from another in the multi-dimensional <b>feature</b> space <b>can</b> <b>be thought</b> of as a super <b>feature</b> which will then be used in developing the C (classifier) rule ...", "dateLastCrawled": "2021-11-03T01:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>SEMANTIC IMAGE SEGMENTATION VIA A DENSE PARALLEL</b> NETWORK", "url": "https://surface.syr.edu/cgi/viewcontent.cgi?article=1325&context=thesis", "isFamilyFriendly": true, "displayUrl": "https://surface.syr.edu/cgi/viewcontent.cgi?article=1325&amp;context=thesis", "snippet": "<b>high-resolution</b> <b>feature</b> maps but also <b>feature</b> reuse at deeper layers to solve the <b>image</b> segmentation problem. We have designed the <b>Dense</b> Parallel Network based on three main observations that we have gained from our initial trials and preliminary studies. First,", "dateLastCrawled": "2021-11-10T17:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Densely Based Multi-Scale and Multi-Modal Fully Convolutional Networks ...", "url": "https://www.researchgate.net/publication/335960161_Densely_Based_Multi-Scale_and_Multi-Modal_Fully_Convolutional_Networks_for_High-Resolution_Remote-Sensing_Image_Semantic_Segmentation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335960161_<b>Dense</b>ly_Based_Multi-Scale_and_Multi...", "snippet": "A Y-shaped convolutional network <b>can</b> effectively segment multi-scale roads from <b>high-resolution</b> images . A <b>dense</b> FCN <b>can</b> provide fine-grained semantic segmentation maps (Peng et al. 2019). These ...", "dateLastCrawled": "2021-12-23T18:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Convolutional Neural Networks \u2014 Image Classification</b> w. Keras ...", "url": "https://www.learndatasci.com/tutorials/convolutional-neural-networks-image-classification/", "isFamilyFriendly": true, "displayUrl": "https://www.learndatasci.com/tutorials/<b>convolutional-neural-networks-image-classification</b>", "snippet": "The outputted <b>feature</b> maps <b>can</b> <b>be thought</b> of as a <b>feature</b> stack. Fig 4. The yellow box is a filter, which is a matrix of 0s and 1s that defines a transformation, and the green box is an <b>image</b> matrix.", "dateLastCrawled": "2022-02-01T08:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>HIGH RESOLUTION</b> SAR IMAGING EMPLOYING GEOMETRIC FEATURES FOR EXTRACTING ...", "url": "https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-3/239/2018/isprs-archives-XLII-3-239-2018.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-3/239/2018/isprs...", "snippet": "of <b>thought</b> for finding suitable target detection and extraction methods. At present, the seismic damage of building is extracted mainly based on the double bounce backscattering <b>feature</b> of SAR <b>image</b>, while this method strongly depends on . The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-3, 2018 ISPRS TC III Mid-term Symposium Developments, Technologies and Applications in Remote Sensing , 7 10 May, Beijing, China This ...", "dateLastCrawled": "2022-01-30T11:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[D] <b>Convolutional Networks for High Resolution</b> Images", "url": "https://www.reddit.com/r/MachineLearning/comments/6r5zqb/d_convolutional_networks_for_high_resolution/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/.../comments/6r5zqb/d_<b>convolutional_networks_for_high_resolution</b>", "snippet": "I had a <b>thought</b> of possibly breaking the <b>image</b> into sub patches and feeding each patch into an LSTM, so that the patches are fed in as if they were frames of a video and each prediction feeds into the next. Not sure if it would work as I imagine it might. 23 comments. share. save. hide. report. 74% Upvoted. This thread is archived. New comments cannot be posted and votes cannot be cast. Sort by. best. level 1. 12 points \u00b7 3 years ago. Only downsampling or cropping <b>can</b> save you from the ...", "dateLastCrawled": "2021-01-14T03:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Change input shape dimensions for fine-tuning with Keras - PyImageSearch", "url": "https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/", "isFamilyFriendly": true, "displayUrl": "https://www.py<b>image</b>search.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning...", "snippet": "More importantly, you now know how to change the input <b>image</b> shape dimensions of a pre-trained network and then apply <b>feature</b> extraction/fine-tuning using Keras! Be sure to use this tutorial as a template for whenever you need to apply transfer learning to a pre-trained network with different <b>image</b> dimensions than what it was originally trained on.", "dateLastCrawled": "2022-02-01T06:15:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>High resolution non-rigid</b> <b>dense</b> matching based on optimized sampling ...", "url": "https://www.sciencedirect.com/science/article/pii/S0925231217302485", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0925231217302485", "snippet": "<b>Compared</b> with rigid <b>dense</b> matching research , , , non ... <b>Feature</b> noise and dokeh in <b>high resolution non-rigid</b> <b>image</b> pairs: number 1 and 2 mean the two matching images; Fig. a shows us the slight differences between <b>image</b> pairs, and Fig. b shows us the less texture and dokeh in <b>image</b> pairs. In order to avoid mismatch caused by <b>feature</b> noise and non-uniform matching caused by less texture and dokeh, we propose an optimized sampling method based on Gibbs <b>dense</b> sampling considering both texture ...", "dateLastCrawled": "2021-12-06T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>High-Resolution Aerial Imagery Semantic Labeling with</b> <b>Dense</b> Pyramid Network", "url": "https://pubmed.ncbi.nlm.nih.gov/30400591/", "isFamilyFriendly": true, "displayUrl": "https://pubmed.ncbi.nlm.nih.gov/30400591", "snippet": "Semantic segmentation of <b>high-resolution</b> aerial images is of great importance in certain fields, but the increasing spatial resolution brings large intra-class variance and small inter-class differences that <b>can</b> lead to classification ambiguities. Based on high-level contextual features, the deep convolutional neural network (DCNN) is an effective method to deal with semantic segmentation of <b>high-resolution</b> aerial imagery. In this work, a novel <b>dense</b> pyramid network (DPN) is proposed for ...", "dateLastCrawled": "2021-02-09T19:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Dual-<b>Dense</b> Convolution Network for Change Detection of <b>High-Resolution</b> ...", "url": "https://pdfs.semanticscholar.org/b043/5d8c4770a7645796058748da31ef9fd2d913.pdf", "isFamilyFriendly": true, "displayUrl": "https://pdfs.semanticscholar.org/b043/5d8c4770a7645796058748da31ef9fd2d913.pdf", "snippet": "The DCNN <b>can</b> achieve superior performance <b>compared</b> to conventional classi\ufb01cation algorithms with handcrafted features. Recently, several change detection methods using deep learning algorithms have been proposed [18\u201320]. A difference <b>image</b> is fed into the deep neural networks as input data [18]. In addition, the neighboring features on each pixel on the difference <b>image</b> are taken as inputs. The restricted Boltzmann machine (RBM) is used for pre-training and is then unrolled in order to ...", "dateLastCrawled": "2022-02-01T07:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Building Extraction in Very <b>High Resolution</b> Imagery by <b>Dense</b>-Attention ...", "url": "https://www.researchgate.net/publication/328833342_Building_Extraction_in_Very_High_Resolution_Imagery_by_Dense-Attention_Networks/fulltext/5be585ef4585150b2ba95f54/Building-Extraction-in-Very-High-Resolution-Imagery-by-Dense-Attention-Networks.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/328833342_Building_Extraction_in_Very_High...", "snippet": "Building Extraction in Very <b>High Resolution</b> Imagery by <b>Dense</b>-Attention Networks Hui Yang 1,2, Penghai Wu 2,3,4,* , Xuedong Yao 2, Yanlan Wu 2,3,4,*, Biao Wang 2,4 and Yongyang Xu 5 1 School of ...", "dateLastCrawled": "2022-01-14T21:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Dense</b> <b>feature</b> pyramid network for ship detection in SAR images - NASA/ADS", "url": "https://ui.adsabs.harvard.edu/abs/2020SPIE11584E..1EH/abstract", "isFamilyFriendly": true, "displayUrl": "https://ui.adsabs.harvard.edu/abs/2020SPIE11584E..1EH/abstract", "snippet": "In this paper, we present <b>Dense</b> <b>Feature</b> Pyramid Network (DenseFPN). Based on the hierarchy of backbone network, the cross-scale connections and lateral connections, the shallow features and deep features are processed differently in DenseFPN. <b>Compared</b> with conventional FPN, we integrate DenseFPN into Faster R-CNN framework and thus form a novel detector. Experiments on <b>high-resolution</b> SAR images dataset (HRSID) have verified the effectiveness of the enhanced hierarchical <b>feature</b> in the ...", "dateLastCrawled": "2021-12-06T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Single <b>Image</b> Super-Resolution Based on Global <b>Dense</b> <b>Feature</b> Fusion ...", "url": "https://europepmc.org/article/PMC/PMC6359588", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/article/PMC/PMC6359588", "snippet": "DFFNet <b>can</b> extract <b>dense</b> features from an original LR <b>image</b> to reconstruct a HR <b>image</b> directly, without any <b>image</b> scaling preprocessing. For an extremely deep network, it is not practical to extract every single layer\u2019s output <b>feature</b>. A <b>feature</b> fusion block (FFblock) is introduced as the basic module of DFFNet. FFblock consists of a global <b>feature</b> fusion (GFF) unit and a <b>feature</b> reduction and learning (FRL) unit, which <b>can</b> make full use of global features, learning the <b>feature</b> spatial ...", "dateLastCrawled": "2022-01-27T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Dense</b> Deformation Network for <b>High Resolution</b> Tissue Cleared <b>Image</b> ...", "url": "https://deepai.org/publication/dense-deformation-network-for-high-resolution-tissue-cleared-image-registration", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>dense</b>-deformation-network-for-<b>high-resolution</b>-tissue...", "snippet": "For <b>high resolution</b> images, a deformable <b>image</b> registration algorithm takes very long runtime which makes them inapplicable for quick analysis of biological data in the processing pipeline. Recently, a bio-chemical process named Tissue clearing is emerged that <b>can</b> remove light obstructing elements from soft-tissues and enable biologist to take images with very <b>high resolution</b>. The pixel spacing of these images are extremely small. Thus, the 3D images obtained from tissue clearing are ...", "dateLastCrawled": "2021-12-10T18:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Remote Sensing | Free Full-Text | Residual <b>Dense</b> Network Based on ...", "url": "https://www.mdpi.com/2072-4292/12/11/1887/html", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2072-4292/12/11/1887/html", "snippet": "Our designed method <b>can</b> enable the network to capture the <b>feature</b> information of each convolutional layer of the <b>high-resolution</b> remote sensing <b>image</b> and merge the local features of RDB to improve the <b>feature</b> propagation efficiency and the features utilization rate. That is to say, it is possible to extract more detailed features as a result of improving the overall performance of scene classification.", "dateLastCrawled": "2022-01-27T22:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "BlockCopy: <b>High-Resolution</b> Video Processing With Block-Sparse <b>Feature</b> ...", "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Verelst_BlockCopy_High-Resolution_Video_Processing_With_Block-Sparse_Feature_Propagation_and_Online_ICCV_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021/papers/Verelst_BlockCopy_High...", "snippet": "BlockCopy: <b>High-Resolution</b> Video Processing with Block-Sparse <b>Feature</b> Propagation and Online Policies Thomas Verelst Tinne Tuytelaars ESAT-PSI, KU Leuven Leuven, Belgium fthomas.verelst, tinne.tuytelaarsg@esat.kuleuven.be Abstract In this paper we propose BlockCopy, a scheme that ac-celerates pretrained frame-based CNNs to process video more ef\ufb01ciently, <b>compared</b> to standard frame-by-frame pro-cessing. To this end, a lightweight policy network deter-mines important regions in an <b>image</b>, and ...", "dateLastCrawled": "2022-02-01T21:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "FaPN: <b>Feature</b>-aligned Pyramid Network for <b>Dense</b> <b>Image</b> Prediction | DeepAI", "url": "https://deepai.org/publication/fapn-feature-aligned-pyramid-network-for-dense-image-prediction", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/fapn-<b>feature</b>-aligned-pyramid-network-for-<b>dense</b>-<b>image</b>...", "snippet": "<b>Feature</b> Pyramid Network Backbone: The existing <b>dense</b> <b>image</b> prediction methods <b>can</b> be broadly divided into two groups. The first group utilizes atrous convolutions to enlarge the receptive field of convolutional filters for capturing long-range information without reducing resolutions spatially. DeepLab is one of the earliest method that adopt atrous convolution for semantic segmentation. It introduced an Atrous Spatial Pyramid Pooling module (ASPP) comprised of atrous convolutions with ...", "dateLastCrawled": "2021-12-22T00:35:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Modern <b>Machine Learning</b> Algorithms: Strengths and Weaknesses", "url": "https://elitedatascience.com/machine-learning-algorithms", "isFamilyFriendly": true, "displayUrl": "https://elitedatascience.com/mac", "snippet": "Of course, the algorithms you try must be appropriate for your problem, which is where picking the right <b>machine learning</b> task comes in. As an <b>analogy</b>, if you need to clean your house, you might use a vacuum, a broom, or a mop, but you wouldn&#39;t bust out a shovel and start digging. <b>Machine Learning</b> Tasks. This is Part 1 of this series. In this ...", "dateLastCrawled": "2022-02-03T00:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> With Spark. A distributed <b>Machine Learning</b>\u2026 | by MA ...", "url": "https://towardsdatascience.com/machine-learning-with-spark-f1dbc1363986", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>machine-learning</b>-with-spark-f1dbc1363986", "snippet": "This section covers the basic steps involved in transformations of input <b>feature</b> data into the format <b>Machine Learning</b> algorithms accept. We will be covering the transformations coming with the SparkML library. To understand or read more about the available spark transformations in 3.0.3, follow the below link. Extracting, transforming and selecting features. This section covers algorithms for working with features, roughly divided into these groups: Extraction: Extracting\u2026 spark.apache ...", "dateLastCrawled": "2022-02-02T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Breast Cancer Detection and Diagnosis Using <b>Machine</b> <b>Learning</b>: A Survey", "url": "https://www.bhu.ac.in/research_pub/jsr/Volumes/JSR_65_05_2021/32.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.bhu.ac.in/research_pub/jsr/Volumes/JSR_65_05_2021/32.pdf", "snippet": "<b>Machine</b> <b>learning</b> (ML) models have been used to detect and diagnose breast cancer since the advancement in the medical modalities (Saxena &amp; Gyanchandani, 2020). In 1993, Street et al., were developed an ML-based CAD model and was firstly used at the University of Wisconsin (Saxena &amp; Gyanchandani, 2020). Accordingly, several researchers have been trying to develop varied CAD systems to be able to significantly reduce the danger of cancers that attack human kinds such as breast, skin, prostate ...", "dateLastCrawled": "2022-02-02T03:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "An <b>analogy</b> between various <b>machine</b>-<b>learning</b> techniques for detecting ...", "url": "https://link.springer.com/article/10.1007/s12205-015-0726-0", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s12205-015-0726-0", "snippet": "In this paper, the authors conducted a comparison study to evaluate the performance of different <b>machine</b> <b>learning</b> techniques for detection of three common categorists of building materials: Concrete, red brick, and OSB boards. The employed classifiers in this research are: Multilayer Perceptron (MLP), Radial Basis Function (RBF), and Support Vector <b>Machine</b> (SVM). To achieve this goal, the <b>feature</b> vectors extracted from image blocks are classified to perform a comparison between the ...", "dateLastCrawled": "2022-01-29T09:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Beyond Word Embeddings: <b>Dense</b> Representations for Multi-modal Data", "url": "https://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS19/paper/viewFile/18294/17411", "isFamilyFriendly": true, "displayUrl": "https://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS19/paper/viewFile/18294/17411", "snippet": "lates embeddings for data with multiple <b>feature</b> types, enforc-ing that all embeddings exist in a common space. We believe that we are the \ufb01rst to propose a method for <b>learning</b> self- supervised embeddings that leverage the structure of multiple <b>feature</b> types. Our experiments suggest that Feat2Vec outper-forms previously published methods, and that it may be use-ful for avoiding the cold-start problem. 1 Introduction Informally, in <b>machine</b> <b>learning</b> a <b>dense</b> representation, or embedding of a ...", "dateLastCrawled": "2021-12-14T17:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Transfer <b>Learning</b>: The Highest Leverage Deep <b>Learning</b> Skill You Can Learn", "url": "https://www.the-analytics.club/transfer-learning", "isFamilyFriendly": true, "displayUrl": "https://www.the-analytics.club/transfer-<b>learning</b>", "snippet": "<b>Feature</b> Extraction: If you want to transfer knowledge from one <b>machine</b> <b>learning</b> model to another but don\u2019t want to re-train the second, larger model on your data set, then <b>feature</b> extraction is the best way to do this. This is possible because you can take the learned features from one model and train another, much smaller model. Used in conjunction with fine-tuning, this process can give you outstanding results in a short amount of time.", "dateLastCrawled": "2022-01-29T09:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Scaling up <b>Analogy</b> with Crowdsourcing and <b>Machine</b> <b>Learning</b>", "url": "https://www.cs.huji.ac.il/~dshahaf/crowd-machine-learning16.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.huji.ac.il/~dshahaf/crowd-<b>machine</b>-<b>learning</b>16.pdf", "snippet": "Scaling up <b>Analogy</b> with Crowdsourcing and <b>Machine</b> <b>Learning</b> JoelChan 1,TomHope 2,DafnaShahaf andAniketKittur 1 Human-ComputerInteractionInstitute CarnegieMellonUniversity,PittsburghPA15213,USA joelchuc@cs.cmu.edu, nkittur@cs.cmu.edu,", "dateLastCrawled": "2021-11-01T13:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and-sample-codes ...", "url": "https://github.com/gaoisbest/Machine-Learning-and-Deep-Learning-basic-concepts-and-sample-codes/blob/master/README.md", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/gaoisbest/<b>Machine</b>-<b>Learning</b>-and-Deep-<b>Learning</b>-basic-concepts-and...", "snippet": "Usage: In fraud detection, use Auto-Encoder to compress all data to <b>dense</b> vector, then kNN is used to detect outliers; Reinforcement <b>Learning</b> Definitions. Reinforcement <b>learning</b> (RL) is an area of <b>machine</b> <b>learning</b> that focuses on how agent to act in an environment in order to maximize some given reward. Markov Decision Processes (MDPs) Components", "dateLastCrawled": "2021-09-22T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Using Deep <b>Learning</b> for Image Analogies | by Tomer Amit | Towards Data ...", "url": "https://towardsdatascience.com/using-deep-learning-for-image-analogies-aa2e7d7af337", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/using-deep-<b>learning</b>-for-image-analogies-aa2e7d7af337", "snippet": "(diagram taken from deeplearning.ai course by Andrew Ng, \u201cConvolutional Neural Networks\u201d). At the end of the network we have an additional flattening layer, two fully connected <b>dense</b> layers, and a softmax layer, which outputs a probability P(x\u2208i), that the image belongs to the i th label, for i=1,\u2026,1000 (number of labels).. Word Embeddings and Analogies. Another concept, related to language processing and deep <b>learning</b>, is Word Embeddings.Given a large corpus of text, say with ...", "dateLastCrawled": "2022-01-19T03:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Lecture 4: \\(k\\)-Nearest Neighbours and SVM RBFs \u2014 CPSC 330 Applied ...", "url": "https://ubc-cs.github.io/cpsc330/lectures/04_kNNs-SVM-RBF.html", "isFamilyFriendly": true, "displayUrl": "https://ubc-cs.github.io/cpsc330/lectures/04_kNNs-SVM-RBF.html", "snippet": "Overview\u00b6. Another popular similarity-based algorithm is Support Vector Machines with RBF Kernel (SVM RBFs) Superficially, SVM RBFs are more like weighted \\(k\\)-NNs.. The decision boundary is defined by a set of positive and negative examples and their weights together with their similarity measure.. A test example is labeled positive if on average it looks more like positive examples than the negative examples.", "dateLastCrawled": "2022-01-11T11:49:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Information | Free Full-Text | <b>Image Aesthetic Assessment Based on</b> ...", "url": "https://www.mdpi.com/2078-2489/11/4/223/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2078-2489/11/4/223/htm", "snippet": "Through <b>machine</b> <b>learning</b>, the classification accuracy rate reached 82.4%. Aesthetic assessment is subjective and difficult accurately model and quantify in engineering because the image aesthetics are ever-changing. Therefore, manual features often have an insufficient representation of aesthetic information, and it is difficult to fully express the aesthetics of images, but it is an approximate representation of aesthetic rules. Liu", "dateLastCrawled": "2021-12-06T06:09:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(dense feature)  is like +(high-resolution image)", "+(dense feature) is similar to +(high-resolution image)", "+(dense feature) can be thought of as +(high-resolution image)", "+(dense feature) can be compared to +(high-resolution image)", "machine learning +(dense feature AND analogy)", "machine learning +(\"dense feature is like\")", "machine learning +(\"dense feature is similar\")", "machine learning +(\"just as dense feature\")", "machine learning +(\"dense feature can be thought of as\")", "machine learning +(\"dense feature can be compared to\")"]}