{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Gesture Recognition Using Wearable Sensors With Bi-<b>Long</b> <b>Short-Term</b> ...", "url": "https://www.researchgate.net/publication/351061174_Gesture_Recognition_Using_Wearable_Sensors_With_Bi-Long_Short-Term_Memory_Convolutional_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/351061174_Gesture_Recognition_Using_Wearable...", "snippet": "One-dimensional convolutional neural networks and bi-<b>long short-term memory</b> (1D-CNN-biLSTM) are proposed for analyzing, learning, and representing features from the sensor signals. In addition, a ...", "dateLastCrawled": "2021-12-15T06:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Handwritten</b> Text Recognition using Deep Learning", "url": "http://cs231n.stanford.edu/reports/2017/pdfs/810.pdf", "isFamilyFriendly": true, "displayUrl": "cs231n.stanford.edu/reports/2017/pdfs/810.pdf", "snippet": "For the latter, we use <b>Long Short Term Memory</b> networks (<b>LSTM</b>) with convolution to con-struct bounding boxes for each character. We then pass the segmented characters to a CNN for classi\ufb01cation, and then reconstruct each word according to the results of classi\ufb01ca-tion and segmentation. 2. Introduction Despite the abundance of technological writing tools, many people still choose to take their notes traditionally: with pen and paper. However, there are drawbacks to hand-writing text. It ...", "dateLastCrawled": "2022-02-02T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Deep Recurrent Neural Networks for Human Activity Recognition</b>", "url": "https://www.researchgate.net/publication/320886290_Deep_Recurrent_Neural_Networks_for_Human_Activity_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320886290_<b>Deep_Recurrent_Neural_Networks_for</b>...", "snippet": "One class of RNNs is the <b>long short-term memory</b> (<b>LSTM</b>), which is used extensively in sequence modeling tasks, such as modeling language [55], forecasting weather [56] and traffic [57], recognizing ...", "dateLastCrawled": "2022-01-31T10:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Deep <b>learning algorithms for human activity recognition using mobile</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417418302136", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417418302136", "snippet": "For instance, studies such as (Chen et al., 2016, Ma et al., 2015) proposed <b>long short term memory</b> (<b>LSTM</b>) for feature extraction to recognise activity of daily living using WISDM data, a publicly available dataset by Wireless Sensor Data Mining Lab (Kwapisz, Weiss, &amp; Moore, 2011) and achieved a classification accuracy of 95.1%. Despite the high performance obtained, the result cannot be generalised due to the simplicity of the specified activities and small sample sizes of the dataset ...", "dateLastCrawled": "2022-01-16T02:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Extracting text from images with Tesseract OCR, OpenCV, and Python</b> - Opcito", "url": "https://www.opcito.com/blogs/extracting-text-from-images-with-tesseract-ocr-opencv-and-python", "isFamilyFriendly": true, "displayUrl": "https://www.opcito.com/blogs/<b>extracting-text-from-images-with-tesseract-ocr-opencv</b>-and...", "snippet": "Text that has arbitrary length and a sequence of characters is solved using Recurrent Neural Network (RNNs) and <b>Long short-term memory</b> (<b>LSTM</b>) where <b>LSTM</b> is a popular form of RNN. The Tesseract input image in LSM is processed in boxes (rectangle) line by line that inserts into the <b>LSTM</b> model and gives the output.", "dateLastCrawled": "2022-02-03T04:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What is <b>Deep Learning</b>?", "url": "https://machinelearningmastery.com/what-is-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/what-is-<b>deep-learning</b>", "snippet": "Jurgen Schmidhuber is the father of another popular algorithm that <b>like</b> MLPs and CNNs also scales with model size and dataset size and can be trained with backpropagation, but is instead tailored to learning sequence data, called the <b>Long Short-Term Memory</b> Network (<b>LSTM</b>), a type of recurrent neural network.. We do see some confusion in the phrasing of the field as \u201c<b>deep learning</b>\u201d. In his 2014 paper titled \u201c<b>Deep Learning</b> in Neural Networks: An Overview\u201d he does comment on the ...", "dateLastCrawled": "2022-02-03T01:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Keras <b>LSTM</b> tutorial \u2013 How to easily build a powerful deep learning ...", "url": "https://adventuresinmachinelearning.com/keras-lstm-tutorial/", "isFamilyFriendly": true, "displayUrl": "https://adventuresinmachinelearning.com/keras-<b>lstm</b>-tutorial", "snippet": "In previous posts, I introduced Keras for building convolutional neural networks and performing word embedding.The next natural step is to talk about implementing recurrent neural networks in Keras. In a previous tutorial of mine, I gave a very comprehensive introduction to recurrent neural networks and <b>long short term memory</b> (<b>LSTM</b>) networks, implemented in TensorFlow.In this tutorial, I\u2019ll concentrate on creating <b>LSTM</b> networks in Keras, briefly giving a recap or overview of how LSTMs work.", "dateLastCrawled": "2022-02-03T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Build Your First Ethereum <b>Smart</b> Contract with Solidity \u2014 Tutorial ...", "url": "https://sites.google.com/site/nttrungmtwiki/home/it/blockchain/ethereum/build-your-first-ethereum-smart-contract-with-solidity-tutorial", "isFamilyFriendly": true, "displayUrl": "https://<b>sites.google.com</b>/site/nttrungmtwiki/home/it/blockchain/ethereum/build-your...", "snippet": "Time Series Forecasting with the <b>Long Short-Term Memory</b> Network in Python part 1. TIME SERIES PREDICTION WITH <b>LSTM</b> ON KERAS PART 1. Time Series Prediction with <b>LSTM</b> on Keras part 2 . Time Series Prediction with <b>LSTM</b> on Keras part 3. Time series cross-validation: an R example. Time Series Forecasting Performance Metrics Comparison. Using R for Time Series Analysis. Weka \u2013 GUI way to learn Machine Learning. Weka 3 - Mining Big Data. Data Science - Python. A Complete Tutorial to Learn Data ...", "dateLastCrawled": "2022-01-27T18:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Encoder decoder <b>LSTM</b> time series forecasting | millones de productos ...", "url": "https://mastarealdrig.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction6lvpj76016lw1", "isFamilyFriendly": true, "displayUrl": "https://mastarealdrig.com/articles/a/<b>LSTM</b>-Neural-Network-for-Time-Series-Prediction6...", "snippet": "Recently, <b>long short-term memory</b> units (<b>LSTM</b>)[Hochre-iter and Schmidhuber, 1997] and the gated recurrent unit (GRU)[Choet al., 2014b] have overcome this limitation. Informer: Beyond Ef\ufb01cient Transformer for <b>Long</b> Sequence Time-Series Forecasting Haoyi Zhou, 1 Shanghang Zhang, 2 Jieqi Peng, 1 Shuai Zhang, 1 Jianxin Li, 1 Hui Xiong, 3 Wancai Zhang, 4 1 Beihang University 2 UC Berkeley 3 Rutgers University 4 Beijing Guowang Fuda Science &amp; Technology Development Company fzhouhy, pengjq, zhangs ...", "dateLastCrawled": "2022-01-02T08:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Forecasting Github <b>Lstm</b> Series Time Multivariate [Y2V6K3]", "url": "https://tappetimilano.mi.it/Multivariate_Time_Series_Forecasting_Lstm_Github.html", "isFamilyFriendly": true, "displayUrl": "https://tappetimilano.mi.it/Multivariate_Time_Series_Forecasting_<b>Lstm</b>_Github.html", "snippet": "Neural networks <b>like</b> <b>Long Short-Term Memory</b> (<b>LSTM</b>) recurrent neural networks are able to almost seamlessly model problems with multiple input variables. Correlations among features Machine-Leaning: <b>LSTM</b> Data Preparation and feature engineering This Notebook is a sort of tutorial for the beginners in Deep Learning and time-series data analysis. X= fx itg2RN T stands for the multivariate time-series input, where Nis the number of time-series (nodes), and Tis the number of timestamps. RNNs ...", "dateLastCrawled": "2022-01-04T19:42:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Sensors | Free Full-Text | Deep Convolutional and <b>LSTM</b> Recurrent Neural ...", "url": "https://www.mdpi.com/1424-8220/16/1/115/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/16/1/115/htm", "snippet": "<b>Long-short-term memory</b> recurrent (LSTMs) neural networks are recurrent networks that include a <b>memory</b> to model temporal dependencies in time series problems. The combination of CNNs and LSTMs in a unified framework has already offered state-of-the-art results in the speech recognition domain, where modelling temporal information is required [ 16 ].", "dateLastCrawled": "2022-01-30T13:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Build a <b>generative chatbot using recurrent neural networks</b> (<b>LSTM</b> RNNs ...", "url": "https://hub.packtpub.com/build-generative-chatbot-using-recurrent-neural-networks-lstm-rnns/", "isFamilyFriendly": true, "displayUrl": "https://hub.packtpub.com/build-<b>generative-chatbot-using-recurrent-neural-networks</b>-<b>lstm</b>...", "snippet": "7 min read. In today\u2019s tutorial we will learn to build <b>generative chatbot using recurrent neural networks</b>. The RNN used here is <b>Long Short Term Memory</b> (<b>LSTM</b>). Generative chatbots are very difficult to build and operate. Even today, most workable chatbots are retrieving in nature; they retrieve the best response for the given question based on ...", "dateLastCrawled": "2022-01-30T19:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Deep Convolutional and <b>LSTM</b> Recurrent Neural Networks for Multimodal ...", "url": "https://europepmc.org/articles/PMC4732148", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/articles/PMC4732148", "snippet": "<b>Long-short-term memory</b> recurrent (LSTMs) neural networks are recurrent networks that include a <b>memory</b> to model temporal dependencies in time series problems. The combination of CNNs and LSTMs in a unified framework has already offered state-of-the-art results in the speech recognition domain, where modelling temporal information is required [ 16 ].", "dateLastCrawled": "2022-01-20T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Malware Detection for Forensic <b>Memory</b> Using Deep Recurrent Neural ...", "url": "https://www.researchgate.net/publication/340896412_Malware_Detection_for_Forensic_Memory_Using_Deep_Recurrent_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/340896412_Malware_Detection_for_Forensic...", "snippet": "The base model chosen for this paper is the <b>long short-term memory</b> ... Block size 29 and 19 offers <b>similar</b> true positive rates (TPRs). In Figure 5, the true positive rate (TPR) block size of 19 ...", "dateLastCrawled": "2022-01-09T17:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Deep Recurrent Neural Networks for Human Activity Recognition ...", "url": "https://europepmc.org/articles/PMC5712979", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/articles/PMC5712979", "snippet": "In this paper, we propose the use of <b>long short-term memory</b> (<b>LSTM</b>)-based deep RNNs (DRNNs) to build HAR models for classifying activities mapped from variable-length input sequences. We develop architectures based on deep layers of unidirectional and bidirectional RNNs, independently, as well as a cascaded architecture progressing from bidirectional to unidirectional RNNs. These models are then tested on various benchmark datasets to validate their performance and generalizability for a ...", "dateLastCrawled": "2022-01-07T21:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Gesture Recognition Using Wearable Sensors With Bi-<b>Long</b> <b>Short-Term</b> ...", "url": "https://www.researchgate.net/publication/351061174_Gesture_Recognition_Using_Wearable_Sensors_With_Bi-Long_Short-Term_Memory_Convolutional_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/351061174_Gesture_Recognition_Using_Wearable...", "snippet": "One-dimensional convolutional neural networks and bi-<b>long short-term memory</b> (1D-CNN-biLSTM) are proposed for analyzing, learning, and representing features from the sensor signals. In addition, a ...", "dateLastCrawled": "2021-12-15T06:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Keras <b>LSTM</b> tutorial \u2013 How to easily build a powerful deep learning ...", "url": "https://adventuresinmachinelearning.com/keras-lstm-tutorial/", "isFamilyFriendly": true, "displayUrl": "https://adventuresinmachinelearning.com/keras-<b>lstm</b>-tutorial", "snippet": "In previous posts, I introduced Keras for building convolutional neural networks and performing word embedding.The next natural step is to talk about implementing recurrent neural networks in Keras. In a previous tutorial of mine, I gave a very comprehensive introduction to recurrent neural networks and <b>long short term memory</b> (<b>LSTM</b>) networks, implemented in TensorFlow.In this tutorial, I\u2019ll concentrate on creating <b>LSTM</b> networks in Keras, briefly giving a recap or overview of how LSTMs work.", "dateLastCrawled": "2022-02-03T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Handwritten</b> Text Recognition using Deep Learning", "url": "http://cs231n.stanford.edu/reports/2017/pdfs/810.pdf", "isFamilyFriendly": true, "displayUrl": "cs231n.stanford.edu/reports/2017/pdfs/810.pdf", "snippet": "For the latter, we use <b>Long Short Term Memory</b> networks (<b>LSTM</b>) with convolution to con-struct bounding boxes for each character. We then pass the segmented characters to a CNN for classi\ufb01cation, and then reconstruct each word according to the results of classi\ufb01ca-tion and segmentation. 2. Introduction Despite the abundance of technological writing tools, many people still choose to take their notes traditionally: with pen and paper. However, there are drawbacks to hand-writing text. It ...", "dateLastCrawled": "2022-02-02T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Generating Question Titles for Stack Overflow</b> from Mined Code ... - DeepAI", "url": "https://deepai.org/publication/generating-question-titles-for-stack-overflow-from-mined-code-snippets", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>generating-question-titles-for-stack-overflow</b>-from...", "snippet": "demonstrates the workflow used by our model. A <b>Long Short Term Memory</b> (<b>LSTM</b>) encoder-decoder architecture, is enhanced by . attention mechanism (Bahdanau et al., 2014), copy mechanism (Gu et al., 2016a) and coverage mechanism (Tu et al., 2016). In general, our model consists of two components: A Source-code Encoder and A Question Decoder.", "dateLastCrawled": "2022-01-24T08:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Deep <b>learning algorithms for human activity recognition using mobile</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417418302136", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417418302136", "snippet": "For instance, studies such as (Chen et al., 2016, Ma et al., 2015) proposed <b>long short term memory</b> (<b>LSTM</b>) for feature extraction to recognise activity of daily living using WISDM data, a publicly available dataset by Wireless Sensor Data Mining Lab (Kwapisz, Weiss, &amp; Moore, 2011) and achieved a classification accuracy of 95.1%. Despite the high performance obtained, the result cannot be generalised due to the simplicity of the specified activities and small sample sizes of the dataset ...", "dateLastCrawled": "2022-01-16T02:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Handwritten</b> Text Recognition using Deep Learning", "url": "http://cs231n.stanford.edu/reports/2017/pdfs/810.pdf", "isFamilyFriendly": true, "displayUrl": "cs231n.stanford.edu/reports/2017/pdfs/810.pdf", "snippet": "For the latter, we use <b>Long Short Term Memory</b> networks (<b>LSTM</b>) with convolution to con-struct bounding boxes for each character. We then pass the segmented characters to a CNN for classi\ufb01cation, and then reconstruct each word according to the results of classi\ufb01ca-tion and segmentation. 2. Introduction Despite the abundance of technological writing tools, many people still choose to take their notes traditionally: with pen and paper. However, there are drawbacks to hand-writing text. It ...", "dateLastCrawled": "2022-02-02T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "(PDF) Malware Detection for Forensic <b>Memory</b> Using Deep Recurrent Neural ...", "url": "https://www.researchgate.net/publication/340896412_Malware_Detection_for_Forensic_Memory_Using_Deep_Recurrent_Neural_Networks", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/340896412_Malware_Detection_for_Forensic...", "snippet": "The base model chosen for this paper is the <b>long short-term memory</b> (<b>LSTM</b>) model as it is excellent at retaining more extend ed periods of information and I. Karamitsos et al.", "dateLastCrawled": "2022-01-09T17:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "the computer case is open fatal error asus", "url": "https://www.plrct.com/yfonuvy/the-computer-case-is-open-fatal-error-asus", "isFamilyFriendly": true, "displayUrl": "https://www.plrct.com/yfonuvy/the-computer-case-is-open-fatal-error-asus", "snippet": "Found insideThe <b>Long Short-Term Memory</b> network, or <b>LSTM</b> for short, is a type of recurrent neural network that achieves state-of-the-art results on challenging prediction problems. Before you reset your computer, make sure to make a backup of your personal data (pictures, music, videos and other invaluable documents), to avoid losing them in the process. Yup, that&#39;s why I wanted to know if you could get into BIOS. Wednesday. I just recently got the Asus Rampage Extreme V. I have plugged in ...", "dateLastCrawled": "2022-01-12T09:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) Real-Time Activity Detection in a Multi-Talker Reverberated ...", "url": "https://www.academia.edu/4753561/Real_Time_Activity_Detection_in_a_Multi_Talker_Reverberated_Environment", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/4753561/Real_Time_Activity_Detection_in_a_Multi_Talker...", "snippet": "3.2 <b>Long Short-Term Memory</b> Building on recent studies in the field of context-sensitive affective computing and human behaviour analysis [42, 41, 38], an activity classification framework that is based on bidirectional <b>Long Short-Term Memory</b> has been designed. Real-Time Activity Detection in <b>a Multi-Talker Reverberated Environment</b> 11 Table 1 31 low-level descriptors. Energy &amp; Spectral (25) loudness (auditory model based), zero crossing rate, energy in bands from 250 \u2013 650 Hz, 1 kHz \u2013 4 ...", "dateLastCrawled": "2022-01-10T07:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Build Your First Ethereum <b>Smart</b> Contract with Solidity \u2014 Tutorial ...", "url": "https://sites.google.com/site/nttrungmtwiki/home/it/blockchain/ethereum/build-your-first-ethereum-smart-contract-with-solidity-tutorial", "isFamilyFriendly": true, "displayUrl": "https://<b>sites.google.com</b>/site/nttrungmtwiki/home/it/blockchain/ethereum/build-your...", "snippet": "Time Series Forecasting with the <b>Long Short-Term Memory</b> Network in Python part 1. TIME SERIES PREDICTION WITH <b>LSTM</b> ON KERAS PART 1. Time Series Prediction with <b>LSTM</b> on Keras part 2 . Time Series Prediction with <b>LSTM</b> on Keras part 3. Time series cross-validation: an R example. Time Series Forecasting Performance Metrics Comparison. Using R for Time Series Analysis. Weka \u2013 GUI way to learn Machine Learning. Weka 3 - Mining Big Data. Data Science - Python. A Complete Tutorial to Learn Data ...", "dateLastCrawled": "2022-01-27T18:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Frequently Asked Questions</b> - Machine Learning Mastery", "url": "https://machinelearningmastery.com/faq/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/faq", "snippet": "It <b>can</b> also <b>be thought</b> of as a confidence level of 95% calculated as (1.0 \u2013 alpha). The p-value <b>can</b> be interpreted with the significance level as follows: p-value &lt;= alpha: significant result, reject null hypothesis (H0), distributions differ. p-value &gt; alpha: not significant result, do not reject null hypothesis (H0), distributions same. A significance level of 5% means that there is a 95% likelihood that we will detect a result (reject H0), if there is a result to detect. Put another way ...", "dateLastCrawled": "2022-02-02T07:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Tech <b>roundup 87: a journal published</b> by a bot - <b>Javi L\u00f3pez G</b>.", "url": "https://javilopezg.com/tech-roundup-87/", "isFamilyFriendly": true, "displayUrl": "https://javilopezg.com/tech-roundup-87", "snippet": "<b>long</b>-standing AI problems, and in particular, answering queries from natural language text. These advances raise the question of whether they <b>can</b> be extended to a point where we <b>can</b> relax the fundamental assumption of database management, namely, that our data is represented as fields of a pre-defined schema. This paper presents a first step in answering that question. We describe NeuralDB, a database system with no pre-defined schema, in which updates and queries are given in natural ...", "dateLastCrawled": "2021-12-07T16:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "DataScienceCentral.com - Big Data News and Analysis", "url": "https://www.datasciencecentral.com/", "isFamilyFriendly": true, "displayUrl": "https://www.datasciencecentral.com", "snippet": "<b>Smart</b> code enables property ownership with a few lines of code. Its simplicity leads to a host of financial and legal co... How Mobile Point of Sale Terminals Are Evolving PragatiPa | January 31, 2022 at 5:19 am As per the business intelligence report by Transparency Market Research, the global mobile point of sale (mPOS) terminal... Environmental Sustainability of Assets emerges as Key Pivot for Uptake of IoT Solutions Nikita Godse | January 31, 2022 at 2:45 am Internet of things (IoT ...", "dateLastCrawled": "2022-02-02T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Monitoring Python Process [WZR7I5]", "url": "https://ostello.sardegna.it/Python_Process_Monitoring.html", "isFamilyFriendly": true, "displayUrl": "https://ostello.sardegna.it/Python_Process_Monitoring.html", "snippet": "The scripts trains a <b>Long Short Term Memory</b> (<b>LSTM</b>)-based predictive model using the data about historical, i. 9 or later, since Python versions beginning with 2. This article is a tour of what I&#39;ve developed, in the hope that it helps others with their thread progress monitoring needs in Python or in other languages. Process Monitor is an advanced monitoring tool for Windows that shows real-time file system, Registry and process/thread activity. The Apache HTTP Server Project is an effort to ...", "dateLastCrawled": "2022-01-22T01:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Python Gps Plot Track [USP9XT]", "url": "https://assistenzafiscale.roma.it/Python_Plot_Gps_Track.html", "isFamilyFriendly": true, "displayUrl": "https://assistenzafiscale.roma.it/Python_Plot_Gps_Track.html", "snippet": "The <b>Long Short-Term Memory</b> network or <b>LSTM</b> is a recurrent neural network that <b>can</b> learn and forecast <b>long</b> sequences. QC2SKY; Berne translators &amp; editors. The Python scientific stack is fairly mature, and there are libraries for a variety of use cases, including machine learning, and data analysis. 3, Python 2. track is dropped by vehicle 1 because vehicle 2 is coasting and there is no update by vehicle 1 sensors Track-level fusion Track-to-Track Fusion for Automotive Safety Applications ...", "dateLastCrawled": "2022-02-01T07:22:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep Recurrent Neural Networks for Human Activity Recognition ...", "url": "https://europepmc.org/articles/PMC5712979", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/articles/PMC5712979", "snippet": "3.2. <b>Long Short-Term Memory</b> (<b>LSTM</b>) Training regular RNNs <b>can</b> be challenging because of vanishing or exploding gradient problems that hinder the network\u2019s ability to backpropagate gradients through <b>long</b>-range temporal intervals . This precludes modeling wide-range dependencies between input data for human activities when learning movements ...", "dateLastCrawled": "2022-01-07T21:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep Convolutional and <b>LSTM</b> Recurrent Neural Networks for Multimodal ...", "url": "https://europepmc.org/articles/PMC4732148", "isFamilyFriendly": true, "displayUrl": "https://europepmc.org/articles/PMC4732148", "snippet": "<b>Long-short-term memory</b> recurrent (LSTMs) neural networks are recurrent networks that include a <b>memory</b> to model temporal dependencies in time series problems. The combination of CNNs and LSTMs in a unified framework has already offered state-of-the-art results in the speech recognition domain, where modelling temporal information is required [ 16 ].", "dateLastCrawled": "2022-01-20T16:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Sensors | Free Full-Text | Deep Recurrent Neural Networks for Human ...", "url": "https://www.mdpi.com/1424-8220/17/11/2556/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/17/11/2556/htm", "snippet": "In this paper, we propose the use of <b>long short-term memory</b> (<b>LSTM</b>)-based deep RNNs (DRNNs) to build HAR models for classifying activities mapped from variable-length input sequences. We develop architectures based on deep layers of unidirectional and bidirectional RNNs, independently, as well as a cascaded architecture progressing from bidirectional to unidirectional RNNs. These models are then tested on various benchmark datasets to validate their performance and generalizability for a ...", "dateLastCrawled": "2022-02-03T04:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Deep Recurrent Neural Networks for Human Activity Recognition</b>", "url": "https://www.researchgate.net/publication/320886290_Deep_Recurrent_Neural_Networks_for_Human_Activity_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/320886290_<b>Deep_Recurrent_Neural_Networks_for</b>...", "snippet": "One class of RNNs is the <b>long short-term memory</b> (<b>LSTM</b>), which is used extensively in sequence modeling tasks, such as modeling language [55], forecasting weather [56] and traffic [57], recognizing ...", "dateLastCrawled": "2022-01-31T10:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Keras <b>LSTM</b> tutorial \u2013 How to easily build a powerful deep learning ...", "url": "https://adventuresinmachinelearning.com/keras-lstm-tutorial/", "isFamilyFriendly": true, "displayUrl": "https://adventuresinmachinelearning.com/keras-<b>lstm</b>-tutorial", "snippet": "In a previous tutorial of mine, I gave a very comprehensive introduction to recurrent neural networks and <b>long short term memory</b> (<b>LSTM</b>) networks, implemented in TensorFlow. In this tutorial, I\u2019ll concentrate on creating <b>LSTM</b> networks in Keras, briefly giving a recap or overview of how LSTMs work. In this Keras <b>LSTM</b> tutorial, we\u2019ll implement a sequence-to-sequence text prediction model by utilizing a large text data set called the PTB corpus. All the code in this tutorial <b>can</b> be found on this", "dateLastCrawled": "2022-02-03T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Sensors | Free Full-Text | Deep Convolutional and <b>LSTM</b> Recurrent Neural ...", "url": "https://www.mdpi.com/1424-8220/16/1/115/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1424-8220/16/1/115/htm", "snippet": "<b>Long-short-term memory</b> recurrent (LSTMs) neural networks are recurrent networks that include a <b>memory</b> to model temporal dependencies in time series problems. The combination of CNNs and LSTMs in a unified framework has already offered state-of-the-art results in the speech recognition domain, where modelling temporal information is required [ 16 ].", "dateLastCrawled": "2022-01-30T13:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Handwritten</b> Text Recognition using Deep Learning", "url": "http://cs231n.stanford.edu/reports/2017/pdfs/810.pdf", "isFamilyFriendly": true, "displayUrl": "cs231n.stanford.edu/reports/2017/pdfs/810.pdf", "snippet": "For the latter, we use <b>Long Short Term Memory</b> networks (<b>LSTM</b>) with convolution to con-struct bounding boxes for each character. We then pass the segmented characters to a CNN for classi\ufb01cation, and then reconstruct each word according to the results of classi\ufb01ca-tion and segmentation. 2. Introduction Despite the abundance of technological writing tools, many people still choose to take their notes traditionally: with pen and paper. However, there are drawbacks to hand-writing text. It ...", "dateLastCrawled": "2022-02-02T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Enhanced Security Model for Pervasive Computing Using Machine Learning ...", "url": "https://www.atlantis-press.com/article/125960858.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.atlantis-press.com/article/125960858.pdf", "snippet": "<b>Long short-term memory</b> (<b>LSTM</b>)Model Back-Propagation Deep Neural Network At the -pervasive development of trusted model, the deep-learning-based pervasive architecture is used for the considered security issues 93.87% To find out the unfair recommender of the node in the dynamic accessing environment. Irfan Uddin et al. [15] single-layer", "dateLastCrawled": "2021-12-17T12:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep <b>learning algorithms for human activity recognition using mobile</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0957417418302136", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0957417418302136", "snippet": "For instance, studies such as (Chen et al., 2016, Ma et al., 2015) proposed <b>long short term memory</b> (<b>LSTM</b>) for feature extraction to recognise activity of daily living using WISDM data, a publicly available dataset by Wireless Sensor Data Mining Lab (Kwapisz, Weiss, &amp; Moore, 2011) and achieved a classification accuracy of 95.1%. Despite the high performance obtained, the result cannot be generalised due to the simplicity of the specified activities and small sample sizes of the dataset ...", "dateLastCrawled": "2022-01-16T02:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Encoder decoder <b>LSTM</b> time series forecasting | millones de productos ...", "url": "https://mastarealdrig.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction6lvpj76016lw1", "isFamilyFriendly": true, "displayUrl": "https://mastarealdrig.com/articles/a/<b>LSTM</b>-Neural-Network-for-Time-Series-Prediction6...", "snippet": "Recently, <b>long short-term memory</b> units (<b>LSTM</b>)[Hochre-iter and Schmidhuber, 1997] and the gated recurrent unit (GRU)[Choet al., 2014b] have overcome this limitation. Informer: Beyond Ef\ufb01cient Transformer for <b>Long</b> Sequence Time-Series Forecasting Haoyi Zhou, 1 Shanghang Zhang, 2 Jieqi Peng, 1 Shuai Zhang, 1 Jianxin Li, 1 Hui Xiong, 3 Wancai Zhang, 4 1 Beihang University 2 UC Berkeley 3 Rutgers University 4 Beijing Guowang Fuda Science &amp; Technology Development Company fzhouhy, pengjq, zhangs ...", "dateLastCrawled": "2022-01-02T08:57:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>Learning</b> : Intro to <b>LSTM</b> (<b>Long Short Term Memory</b>) | by HIMANSHU ...", "url": "https://medium.com/@himanshunpatel01/deep-learning-intro-to-lstm-long-short-term-memory-ce504dc6e585", "isFamilyFriendly": true, "displayUrl": "https://medium.com/.../deep-<b>learning</b>-intro-to-<b>lstm</b>-<b>long-short-term-memory</b>-ce504dc6e585", "snippet": "A simple <b>machine</b> <b>learning</b> model or an Artificial Neural Network may learn to predict the stock prices based on a number of features: the volume of the stock, the opening value etc. While the price ...", "dateLastCrawled": "2022-01-27T16:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Gentle Introduction to <b>Long Short-Term Memory</b> Networks by the Experts", "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>long-short-term-memory</b>-networks...", "snippet": "<b>Long Short-Term Memory</b> (<b>LSTM</b>) networks are a type of recurrent neural network capable of <b>learning</b> order dependence in sequence prediction problems. This is a behavior required in complex problem domains like <b>machine</b> translation, speech recognition, and more. LSTMs are a complex area of deep <b>learning</b>. It can be hard to get your hands around what LSTMs are, and how terms like bidirectional", "dateLastCrawled": "2022-01-31T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Long Short Term Memory</b>(<b>LSTM</b>) and <b>Gated Recurrent</b> Units(GRU) | by ...", "url": "https://prvnk10.medium.com/long-short-term-memory-lstm-and-gated-recurrent-units-gru-240d8a62db9", "isFamilyFriendly": true, "displayUrl": "https://prvnk10.medium.com/<b>long-short-term-memory</b>-<b>lstm</b>-and-<b>gated-recurrent</b>-units-gru...", "snippet": "<b>Long Short Term Memory</b> (<b>LSTM</b>) and <b>Gated Recurrent</b> Units (GRU) This article covers the content discussed in the LSTMs and GRU module of the Deep <b>Learning</b> course offered on the website: https://padhai.onefourthlabs.in. The problem with the RNN is that we want the output at every time step to b e dependent on the previous input and the way we do ...", "dateLastCrawled": "2022-01-30T07:27:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "9.2. <b>Long Short-Term Memory</b> (<b>LSTM</b>) \u2014 Dive into Deep <b>Learning</b> 0.17.2 ...", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_recurrent-modern/<b>lstm</b>.html", "snippet": "The challenge to address <b>long</b>-term information preservation and <b>short-term</b> input skipping in latent variable models has existed for a <b>long</b> time. One of the earliest approaches to address this was the <b>long short-term memory</b> (<b>LSTM</b>) [Hochreiter &amp; Schmidhuber, 1997]. It shares many of the properties of the GRU. Interestingly, LSTMs have a slightly more complex design than GRUs but predates GRUs by almost two decades. 9.2.1. Gated <b>Memory</b> Cell\u00b6 Arguably <b>LSTM</b>\u2019s design is inspired by logic gates ...", "dateLastCrawled": "2022-02-02T23:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>CPSC 540: Machine Learning</b>", "url": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W20/L32.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~schmidtm/Courses/540-W20/L32.pdf", "snippet": "<b>CPSC 540: Machine Learning</b> <b>Long Short Term Memory</b> Winter 2020. Previously: Sequence-to-Sequence \u2022Sequence-to-sequence: \u2013Recurrent neural network for sequences of different lengths. \u2022 ^Encoding phase that takes an input at each time. \u2022 ^Decoding phase that makes an output at each time. \u2013Encoding ends with BOS, decoding ends with EOS. x 1 z 1 x 2 z 2 x 3 z 0 z 3 z 4 z 5 y 1 y 2. Variations on Recurrent Neural Networks \u2022Bi-directional RNNs: feedforward from past and future ...", "dateLastCrawled": "2021-11-08T22:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Model Reduction with Memory and</b> <b>the Machine Learning of Dynamical</b> ...", "url": "https://deepai.org/publication/model-reduction-with-memory-and-the-machine-learning-of-dynamical-systems", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>model-reduction-with-memory-and</b>-the-<b>machine</b>-<b>learning</b>-of...", "snippet": "2.2 <b>Long short-term memory</b> networks. Theoretically, RNNs is capable of <b>learning</b> <b>long</b>-term <b>memory</b> effects in the time series. However, in practice it is hard for RNN to catch such dependencies, because of the exploding or shrinking gradient effects , . The <b>Long Short-Term Memory</b> (<b>LSTM</b>) network is designed to solve this problem. Proposed by Hochreiter et al. , the <b>LSTM</b> introduces a new group of hidden units called states, and uses gates to control the information flow through the states. Since ...", "dateLastCrawled": "2022-01-17T23:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Long Short Term Memory and Gated Recurrent Unit</b>\u2019s Explained \u2014 ELI5 Way ...", "url": "https://towardsdatascience.com/long-short-term-memory-and-gated-recurrent-units-explained-eli5-way-eff3d44f50dd", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>long-short-term-memory-and-gated-recurrent</b>-units...", "snippet": "Hi All, welcome to my blog \u201c<b>Long Short Term Memory and Gated Recurrent Unit</b>\u2019s Explained \u2014 ELI5 Way\u201d this is my last blog of the year 2019.My name is Niranjan Kumar and I\u2019m a Senior Consultant Data Science at Allstate India.. Recurrent Neural Networks(RNN) are a type of Neural Network where the output from the previous step is fed as input to the current step.", "dateLastCrawled": "2022-01-24T06:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "NPTEL :: Computer Science and Engineering - NOC:Deep <b>Learning</b>- Part 1", "url": "https://www.nptel.ac.in/courses/106/106/106106184/", "isFamilyFriendly": true, "displayUrl": "https://www.nptel.ac.in/courses/106/106/106106184", "snippet": "Selective Read, Selective Write, Selective Forget - The Whiteboard <b>Analogy</b>: Download: 109: <b>Long Short Term Memory</b>(<b>LSTM</b>) and Gated Recurrent Units(GRUs) Download: 110: How LSTMs avoid the problem of vanishing gradients: Download: 111: How LSTMs avoid the problem of vanishing gradients (Contd.) Download: 112: Introduction to Encoder Decoder ...", "dateLastCrawled": "2022-01-25T00:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Multistep Time Series Forecasting with</b> LSTMs in Python", "url": "https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>multi-step-time-series-forecasting</b>-<b>long</b>-<b>short-term</b>...", "snippet": "The <b>Long Short-Term Memory</b> network or <b>LSTM</b> is a recurrent neural network that can learn and forecast <b>long</b> sequences. A benefit of LSTMs in addition to <b>learning</b> <b>long</b> sequences is that they can learn to make a one-shot multi-step forecast which may be useful for <b>time series forecasting</b>. A difficulty with LSTMs is that they can be tricky to configure and it", "dateLastCrawled": "2022-02-02T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Introduction to Transformers in Machine Learning</b>", "url": "https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>machine</b>curve.com/.../12/28/<b>introduction-to-transformers-in-machine-learning</b>", "snippet": "Fortunately, in the 2010s, <b>Long Short-Term Memory</b> networks (LSTMs, top right) and Gated Recurrent Units (GRUs, bottom) were researched and applied to resolve many of the three issues above. LSTMs in particular, through the cell like structure where <b>memory</b> is retained, are robust to the vanishing gradients problem. What\u2019s more, because <b>memory</b> is now maintained separately from the previous cell output (the \\(c_{t}\\) flow in the", "dateLastCrawled": "2022-02-03T03:08:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>learning</b> hybrid model with Boruta-Random forest optimiser ...", "url": "https://www.sciencedirect.com/science/article/pii/S0022169421003978", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0022169421003978", "snippet": "The <b>long short-term memory (LSTM) is like</b> the recurrent neural network (RNN), popularly used in the deep <b>learning</b> field. Likewise, the RNN architecture, LSTM, has a feedback connection with the layers, which can establish the complete sequences of the inputs. The description of LSTM networks can be found different from researches Britz, 2015, Chollet, 2016, Ghimire et al., 2019c, Graves, 2012, Olah, 2015). The LSTM networks are introduced to solve the problems associated with conventional ...", "dateLastCrawled": "2022-01-26T05:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep <b>Learning</b> Approach for Aggressive Driving Behaviour Detection", "url": "https://arxiv.org/pdf/2111.04794v1", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/pdf/2111.04794v1", "snippet": "ML = <b>Machine</b> <b>Learning</b> DL = Deep <b>Learning</b> RNN = Recurrent Neural Network GRU = Gated Recurrent Unit LSTM = Long Short-Term Memory Introduction With the number of automobile accidents, fuel economy, and determining the level of driving talent, the DBA (Driving Behaviour Analysis) becomes a critical subject to be calculated. Depending on the types of car sensors, the inputs . and outputs can then be examined to establish if the DBC (Driving Behaviour Classification) is normal or deviant ...", "dateLastCrawled": "2021-12-09T07:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Deep <b>Learning</b> Methods Cancer Diagnosis", "url": "https://www.linkedin.com/pulse/deep-learning-methods-cancer-diagnosis-jims-vasant-kunj-ii", "isFamilyFriendly": true, "displayUrl": "https://www.linkedin.com/pulse/deep-<b>learning</b>-methods-cancer-diagnosis-jims-vasant-kunj-ii", "snippet": "Classifiers in <b>Machine</b> <b>Learning</b> and its Application: ... <b>Long Short-Term Memory (LSTM) is similar</b> to RNN. It is used for <b>learning</b> order dependence in sequential prediction problems. Conclusion ...", "dateLastCrawled": "2022-01-13T06:31:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(long short-term memory (lstm))  is like +(a \u201csmart\u201d notepad)", "+(long short-term memory (lstm)) is similar to +(a \u201csmart\u201d notepad)", "+(long short-term memory (lstm)) can be thought of as +(a \u201csmart\u201d notepad)", "+(long short-term memory (lstm)) can be compared to +(a \u201csmart\u201d notepad)", "machine learning +(long short-term memory (lstm) AND analogy)", "machine learning +(\"long short-term memory (lstm) is like\")", "machine learning +(\"long short-term memory (lstm) is similar\")", "machine learning +(\"just as long short-term memory (lstm)\")", "machine learning +(\"long short-term memory (lstm) can be thought of as\")", "machine learning +(\"long short-term memory (lstm) can be compared to\")"]}