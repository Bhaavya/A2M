{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Overview of Psychological Testing - Psychological Testing in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK305233/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK305233", "snippet": "Such two-<b>parameter</b> models are often used for tests <b>like</b> essay tests where one cannot achieve a high score by guessing or using other means to answer currently. The three-<b>parameter</b> IRT model contains a third <b>parameter</b>, that factor related to chance level correct scoring. This <b>parameter</b> is sometimes called the pseudo-guessing <b>parameter</b>, and this model is generally used for large-scale multiple-choice testing programs.", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Automatically adjusting <b>brightness</b> of image with OpenCV - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/57030125/automatically-adjusting-brightness-of-image-with-opencv", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/57030125", "snippet": "Here&#39;s a visualization of the clipping. Blue (original), Orange (after auto <b>adjustment</b>). Results with clipping at 35%. alpha 3.8059701492537314 . beta -201.71641791044777. Other methods could be using Histogram Equalization or CLAHE. import cv2 import numpy as np # from matplotlib import pyplot as plt # Automatic <b>brightness</b> and contrast optimization with optional histogram clipping def automatic_<b>brightness</b>_and_contrast(image, clip_hist_percent=25): gray = cv2.cvtColor(image, cv2.COLOR ...", "dateLastCrawled": "2022-01-25T01:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Keras</b> Loss Functions: Everything You Need to Know - neptune.ai", "url": "https://neptune.ai/blog/keras-loss-functions", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/<b>keras</b>-loss-functions", "snippet": "In deep learning, the loss is computed to get the gradients with respect to model weights and <b>update</b> those weights accordingly via backpropagation. Loss is calculated and the network is updated after every iteration until model updates don\u2019t bring any improvement in the desired evaluation metric. So while you keep using the same evaluation metric <b>like</b> f1 score or AUC on the validation set during (long parts) of your machine learning project, the loss can be changed, adjusted and modified ...", "dateLastCrawled": "2022-02-02T23:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "To retrain, or not to retrain? Let\u2019s get analytical about ML model updates.", "url": "https://evidentlyai.com/blog/retrain-or-not-retrain", "isFamilyFriendly": true, "displayUrl": "https://evidentlyai.com/blog/retrain-or-not-retrain", "snippet": "Such <b>adjustment</b> is computationally fast, and we can do it on the fly. These are only a few examples. Different models have different maintenance needs. They vary from minor online calibration to a complete offline <b>update</b> or a combination of both. Some models drift quickly, some not that much. We can run our training pipelines daily or do that once per month. We cannot define a universal schedule for all model types and applications. But at least when it comes to the regular model &quot;aging,&quot; we ...", "dateLastCrawled": "2022-01-31T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Gradient Descent</b> \u2014 ML Glossary documentation", "url": "https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html", "isFamilyFriendly": true, "displayUrl": "https://ml-cheatsheet.readthedocs.io/en/latest/<b>gradient_descent</b>.html", "snippet": "A Loss Functions tells us \u201chow good\u201d our model is at <b>making</b> predictions for a given set of parameters. The cost function has its own curve and its own gradients. The slope of this curve tells us how to <b>update</b> our parameters to make the model more accurate. Step-by-step\u00b6 Now let\u2019s run <b>gradient descent</b> using our new cost function. There are two parameters in our cost function we can control: \\(m\\) (weight) and \\(b\\) (bias). Since we need to consider the impact each one has on the final ...", "dateLastCrawled": "2022-01-30T21:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "6 Steps to Migrating Your Machine Learning Project to the Cloud | by ...", "url": "https://towardsdatascience.com/6-steps-to-migrating-your-machine-learning-project-to-the-cloud-6d9b6e4f18e0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/6-steps-to-migrating-your-machine-learning-project-to...", "snippet": "Photo by Jeremy Bishop on Unsplash. Whether you are an algorithm developer in a growing startup company, a data <b>scientist</b> in a universit y research lab, or a kaggle hobbyist, there may come a point in time when the training resources that you have onsite no longer meet your training demands. In this post we target development teams that are (finally) ready to move their machine learning (ML) workloads to the cloud.", "dateLastCrawled": "2022-01-28T09:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>3 Data visualisation</b> | R for Data Science: Exercise Solutions", "url": "https://jrnold.github.io/r4ds-exercise-solutions/data-visualisation.html", "isFamilyFriendly": true, "displayUrl": "https://jrnold.github.io/r4ds-exercise-solutions/<b>data-visualisation</b>.html", "snippet": "A simple scatter plot does not show how many observations there are for each (x, y) value.As such, scatterplots work best for plotting a continuous x and a continuous y variable, and when all (x, y) values are unique.Warning: The following code uses functions introduced in a later section. Come back to this after reading section 7.5.2, which introduces methods for plotting two categorical variables.The first is geom_count() which is similar to a scatterplot but uses the size of the points to ...", "dateLastCrawled": "2022-02-03T01:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Design of Experiments</b> (DOE) Tutorial - MoreSteam", "url": "https://www.moresteam.com/toolbox/design-of-experiments.cfm", "isFamilyFriendly": true, "displayUrl": "https://www.moresteam.com/toolbox/<b>design-of-experiments</b>.cfm", "snippet": "The term <b>experiment</b> is defined as the systematic procedure carried out under controlled conditions in order to discover an unknown effect, to test or establish a hypothesis, or to illustrate a known effect. When analyzing a process, experiments are often used to evaluate which process inputs have a significant impact on the process output, and what the target level of those inputs should be to achieve a desired result (output).", "dateLastCrawled": "2022-02-02T11:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Dealing with missing data in ANOVA models</b> | R-bloggers", "url": "https://www.r-bloggers.com/2018/06/dealing-with-missing-data-in-anova-models/", "isFamilyFriendly": true, "displayUrl": "https://www.r-bloggers.com/2018/06/<b>dealing-with-missing-data-in-anova-models</b>", "snippet": "The difference is not extreme, but it is easy to see that the imputed data tend to have more mass at the lower end of the distribution of y (especially in groups A and C).. This is again a result of how the data were simulated: Lower y values, through their relation with x, are missing more often, which is accounted for using MI.Conversely, using listwise deletion placed the group means more closely together than they should be, and this affected the results in the ANOVA.", "dateLastCrawled": "2022-02-02T08:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Straight, Level, and the Curvature</b> of the Earth | Math Encounters Blog", "url": "https://www.mathscinotes.com/2010/11/straight-level-and-the-curvature-of-the-earth/", "isFamilyFriendly": true, "displayUrl": "https://www.mathscinotes.com/2010/11/<b>straight-level-and-the-curvature</b>-of-the-earth", "snippet": "You\u2019re <b>making</b> the same mistake that many flat earthers continue to make. Just because a ship is too far away to see with the naked eye doesn\u2019t mean it\u2019s behind the horizon. A ship that\u2019s traveled beyond the limits of our vision, and a ship that\u2019s hidden by the horizon, are 2 very different things. And despite the number of times we\u2019ve explained this, it apparently has failed to sink in. I can pretty much guarantee that the ships you zoom in on aren\u2019t behind the horizon to begin ...", "dateLastCrawled": "2022-02-02T20:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Polymerase Chain Reaction: Basic Protocol Plus Troubleshooting and ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4846334/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4846334", "snippet": "1. Designing Primers. Designing appropriate primers is essential to the successful outcome of a PCR <b>experiment</b>. When designing a set of primers to a specific region of DNA desired for amplification, one primer should anneal to the plus strand, which by convention is oriented in the 5&#39; \u2192 3&#39; direction (also known as the sense or nontemplate strand) and the other primer should complement the minus strand, which is oriented in the 3&#39; \u2192 5&#39; direction (antisense or template strand).", "dateLastCrawled": "2022-02-03T07:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Overview of Psychological Testing - Psychological Testing in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK305233/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK305233", "snippet": "This <b>parameter</b> is sometimes called the pseudo-guessing <b>parameter</b>, and this model is generally used for large-scale multiple-choice testing programs. These models, because of their lessened reliance on the sampling of test-takers, are very useful in the equating of tests that is the setting of scores to be equivalent regardless of the form of the test one takes.", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "To retrain, or not to retrain? Let\u2019s get analytical about ML model updates.", "url": "https://evidentlyai.com/blog/retrain-or-not-retrain", "isFamilyFriendly": true, "displayUrl": "https://evidentlyai.com/blog/retrain-or-not-retrain", "snippet": "Such <b>adjustment</b> is computationally fast, and we can do it on the fly. These are only a few examples. Different models have different maintenance needs. They vary from minor online calibration to a complete offline <b>update</b> or a combination of both. Some models drift quickly, some not that much. We can run our training pipelines daily or do that once per month. We cannot define a universal schedule for all model types and applications. But at least when it comes to the regular model &quot;aging,&quot; we ...", "dateLastCrawled": "2022-01-31T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>3 Data visualisation</b> | R for Data Science: Exercise Solutions", "url": "https://jrnold.github.io/r4ds-exercise-solutions/data-visualisation.html", "isFamilyFriendly": true, "displayUrl": "https://jrnold.github.io/r4ds-exercise-solutions/<b>data-visualisation</b>.html", "snippet": "A simple scatter plot does not show how many observations there are for each (x, y) value.As such, scatterplots work best for plotting a continuous x and a continuous y variable, and when all (x, y) values are unique.Warning: The following code uses functions introduced in a later section. Come back to this after reading section 7.5.2, which introduces methods for plotting two categorical variables.The first is geom_count() which <b>is similar</b> to a scatterplot but uses the size of the points to ...", "dateLastCrawled": "2022-02-03T01:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "1 Simple Linear Regression I \u2013 <b>Least Squares</b> Estimation", "url": "http://users.stat.ufl.edu/~winner/qmb3250/notespart2.pdf", "isFamilyFriendly": true, "displayUrl": "users.stat.ufl.edu/~winner/qmb3250/notespart2.pdf", "snippet": "The <b>adjustment</b> people make is to write the mean response as a linear function of the predictor variable. This way, we allow for variation in individual responses (y), while associating the mean linearly with the predictor x. The model we \ufb01t is as follows: E(y|x)=\u03b20 +\u03b21x, and we write the individual responses as y = \u03b20 +\u03b21x+\u03b5, We can think of y as being broken into a systematic and a random component: y = \u03b20 +\u03b21x | {z } systematic + |{z}\u03b5 random where x is the level of the predictor ...", "dateLastCrawled": "2022-02-03T06:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Saponification - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/chemistry/saponification", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/chemistry/saponification", "snippet": "The saponification of \u03b1-hydroxy esters can be readily undertaken using well-tested procedures that are very <b>similar</b> to those employed for the hydrolysis of conventional ester groups (see Section 5.02.2.1.1 and references therein). The initial stages of an enantioselective synthesis of (R)-1-hydroxy-7-methoxy-1,2,3,4-tetrahydronaphthalene-1-carboxylic acid required saponification of the racemic \u03b1-hydroxy methyl ester 186.The hydrolysis was readily undertaken using aqueous lithium hydroxide ...", "dateLastCrawled": "2022-01-30T06:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Dealing with missing data in ANOVA models</b> | R-bloggers", "url": "https://www.r-bloggers.com/2018/06/dealing-with-missing-data-in-anova-models/", "isFamilyFriendly": true, "displayUrl": "https://www.r-bloggers.com/2018/06/<b>dealing-with-missing-data-in-anova-models</b>", "snippet": "The difference is not extreme, but it is easy to see that the imputed data tend to have more mass at the lower end of the distribution of y (especially in groups A and C).. This is again a result of how the data were simulated: Lower y values, through their relation with x, are missing more often, which is accounted for using MI.Conversely, using listwise deletion placed the group means more closely together than they should be, and this affected the results in the ANOVA.", "dateLastCrawled": "2022-02-02T08:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Automatically adjusting <b>brightness</b> of image with OpenCV - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/57030125/automatically-adjusting-brightness-of-image-with-opencv", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/57030125", "snippet": "There is a <b>similar</b> Python script here, which just matches one image to another, but doing so in LAB colorspace. However, it should be easy enough to change it to match one image to a set of mean and std arguments. (My scripts are available here) Share. Improve this answer. Follow edited Jul 17 &#39;19 at 22:04. nathancy. 31.7k 13 13 gold badges 81 81 silver badges 104 104 bronze badges. answered Jul 16 &#39;19 at 2:21. fmw42 fmw42. 34.1k 8 8 gold badges 44 44 silver badges 59 59 bronze badges. 1 ...", "dateLastCrawled": "2022-01-25T01:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Java Applet Basics - GeeksforGeeks", "url": "https://www.geeksforgeeks.org/java-applet-basics/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/java-applet-basics", "snippet": "Throwback of <b>making</b> GUI application: Java was launched on 23-Jan-1996(JDK 1.0) and at that time it only supported CUI(Character User Interface) application. But in 1996 VB(Visual Basic) of Microsoft was preferred for GUI programming. So the Java developers in hurry(i.e within 7 days) have given the support for GUI from Operating System(OS). Now ...", "dateLastCrawled": "2022-02-02T21:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Trustworthy Online Controlled Experiments: A Practical</b> Guide to A ...", "url": "https://www.researchgate.net/publication/339914315_Trustworthy_Online_Controlled_Experiments_A_Practical_Guide_to_AB_Testing", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/339914315_Trustworthy_Online_Controlled...", "snippet": "CUPED, acronym for Controlled-<b>experiment</b> Using Pre-<b>experiment</b> Data [6], is a variance reduction technique widely adopted in the A/B testing industry to improve the sensitivity of A/B tests [25, 30 ...", "dateLastCrawled": "2022-02-02T11:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Polymerase Chain Reaction: Basic Protocol Plus Troubleshooting and ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4846334/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4846334", "snippet": "Designing a PCR <b>experiment</b> requires <b>thought</b> and patience. The results shown in Figure 3 exemplify one of the major challenges when designing an optimization strategy for PCR. That is, as one <b>parameter</b> of PCR is changed, it may impact another. As an example, if the initial PCR was carried out at the sub-optimal annealing temperature (58\u00b0C) with an optimal Mg", "dateLastCrawled": "2022-02-03T07:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Overview of Psychological Testing - Psychological Testing in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK305233/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK305233", "snippet": "Psychological assessment contributes important information to the understanding of individual characteristics and capabilities, through the collection, integration, and interpretation of information about an individual (Groth-Marnat, 2009; Weiner, 2003). Such information is obtained through a variety of methods and measures, with relevant sources determined by the specific purposes of the evaluation. Sources of information may include", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Keras</b> Loss Functions: Everything You Need to Know - neptune.ai", "url": "https://neptune.ai/blog/keras-loss-functions", "isFamilyFriendly": true, "displayUrl": "https://neptune.ai/blog/<b>keras</b>-loss-functions", "snippet": "In deep learning, the loss is computed to get the gradients with respect to model weights and <b>update</b> those weights accordingly via backpropagation. Loss is calculated and the network is updated after every iteration until model updates don\u2019t bring any improvement in the desired evaluation metric. So while you keep using the same evaluation metric like f1 score or AUC on the validation set during (long parts) of your machine learning project, the loss <b>can</b> be changed, adjusted and modified ...", "dateLastCrawled": "2022-02-02T23:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>GitHub</b> - <b>iamtodor/data-science-interview-questions-and-answers</b>: Data ...", "url": "https://github.com/iamtodor/data-science-interview-questions-and-answers", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/<b>iamtodor/data-science-interview-questions-and-answers</b>", "snippet": "Regularization is the process of adding a tuning <b>parameter</b> to a model to induce smoothness in order to prevent overfitting. This is most often done by adding a constant multiple to an existing weight vector. This constant is often either the L1 (Lasso) or L2 (ridge), but <b>can</b> in actuality <b>can</b> be any norm. The model predictions should then minimize the mean of the loss function calculated on the regularized training set. It is well known, as explained by others, that L1 regularization helps ...", "dateLastCrawled": "2022-02-03T02:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 4, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Artificial neural network</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Artificial_neural_network", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Artificial_neural_network</b>", "snippet": "This <b>can</b> <b>be thought</b> of as learning with a &quot;teacher&quot;, in the form of a function that provides continuous feedback on the quality of solutions obtained thus far. Unsupervised learning. In unsupervised learning, input data is given along with the cost function, some function of the data and the network&#39;s output. The cost function is dependent on the task (the model domain) and any a priori assumptions (the implicit properties of the model, its parameters and the observed variables). As a ...", "dateLastCrawled": "2022-02-07T09:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Criteria for evaluating treatment guidelines</b>", "url": "https://www.apa.org/practice/guidelines/evaluating", "isFamilyFriendly": true, "displayUrl": "https://<b>www.apa.org</b>/practice/guidelines/evaluating", "snippet": "Each of these decisions <b>can</b> affect the study&#39;s construct validity \u2014 the extent to which the <b>experiment</b> truly addresses the underlying clinical question. As a consequence, even a treatment that is well supported in randomized controlled experiments may turn out to be of little value clinically if those studies have poor external validity. Panels have a fundamental responsibility to evaluate all these considerations when developing treatment guidelines.", "dateLastCrawled": "2022-02-02T18:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "An <b>Introduction to R</b>", "url": "https://cran.r-project.org/doc/manuals/r-devel/R-intro.html", "isFamilyFriendly": true, "displayUrl": "https://<b>cran.r-project.org</b>/doc/manuals/r-devel/R-intro.html", "snippet": "The usual operator, &lt;-, <b>can</b> <b>be thought</b> of as a syntactic short-cut to this. Assignments <b>can</b> also be made in the other direction, using the obvious change in the assignment operator. So the same assignment could be made using &gt; c(10.4, 5.6, 3.1, 6.4, 21.7) -&gt; x If an expression is used as a complete command, the value is printed and lost 8. So now if we were to use the command &gt; 1/x the reciprocals of the five values would be printed at the terminal (and the value of x, of course, unchanged ...", "dateLastCrawled": "2022-02-03T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "An <b>Introduction to Linear Mixed-Effects Modeling in</b> R - Violet A. Brown ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2515245920960351", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2515245920960351", "snippet": "Just as the modality and SNR effects <b>can</b> <b>be thought</b> of as adjustments to the intercept in particular conditions (e.g., estimates are shifted up 99 ms in the audiovisual relative to the audio-only condition, but only in the easy listening condition), the interaction term <b>can</b> <b>be thought</b> of as <b>an adjustment</b> to the modality or SNR slope when both predictors are set to 1 (note that interactions adjust coefficient estimates only for a single cell of the design because the interaction term drops ...", "dateLastCrawled": "2022-02-03T04:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "206 questions with answers in <b>TIME SERIES MODELING</b> | Science topic", "url": "https://www.researchgate.net/topic/Time-Series-Modeling", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Time-Series-Modeling</b>", "snippet": "The idea is that you <b>can</b> compare modelling performance with and without an exogenous <b>parameter</b> in order to empirically evaluate so-called Forecast-Value-Added (FVA), see the above article (pp. 47 ...", "dateLastCrawled": "2022-01-22T10:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Spencer: Global Urban Heat Island Effect Study \u2013 An <b>Update</b> \u2013 Watts Up ...", "url": "https://wattsupwiththat.com/2010/03/10/spencer-global-urban-heat-island-effect-study-an-update/", "isFamilyFriendly": true, "displayUrl": "https://<b>wattsupwiththat.com</b>/.../10/spencer-global-urban-heat-island-effect-study-an-<b>update</b>", "snippet": "by Roy W. Spencer, Ph. D. This is an <b>update</b> to my previous posts [here and here on WUWT] describing a new technique for estimating the average amount of urban heat island (UHI) warming accompanying an increase in population density.The analysis is based upon 4x per day temperature observations in the NOAA International Surface Hourly (ISH) dataset, and on 1 km population density data for the year 2000.", "dateLastCrawled": "2022-02-01T08:41:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Overview of Psychological Testing - Psychological Testing in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK305233/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK305233", "snippet": "Psychological assessment contributes important information to the understanding of individual characteristics and capabilities, through the collection, integration, and interpretation of information about an individual (Groth-Marnat, 2009; Weiner, 2003). Such information is obtained through a variety of methods and measures, with relevant sources determined by the specific purposes of the evaluation. Sources of information may include", "dateLastCrawled": "2022-02-03T02:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "To retrain, or not to retrain? Let\u2019s get analytical about ML model updates.", "url": "https://evidentlyai.com/blog/retrain-or-not-retrain", "isFamilyFriendly": true, "displayUrl": "https://evidentlyai.com/blog/retrain-or-not-retrain", "snippet": "Then, we <b>can</b> <b>experiment</b> with excluding old data bucket by bucket. Our goal is to evaluate the impact of this &quot;old&quot; data on performance. It is similar to the first check when we considered excluding old data from the initial training. But now, we use a defined test set (with the known decay) and likely a more precise step (think dropping months ...", "dateLastCrawled": "2022-01-31T20:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "1 Simple Linear Regression I \u2013 <b>Least Squares</b> Estimation", "url": "http://users.stat.ufl.edu/~winner/qmb3250/notespart2.pdf", "isFamilyFriendly": true, "displayUrl": "users.stat.ufl.edu/~winner/qmb3250/notespart2.pdf", "snippet": "this case, we make <b>an adjustment</b> for random variation in the process. 1.2 A Linear Probabilistic Model The <b>adjustment</b> people make is to write the mean response as a linear function of the predictor variable. This way, we allow for variation in individual responses (y), while associating the mean linearly with the predictor x. The model we \ufb01t is as follows: E(y|x)=\u03b20 +\u03b21x, and we write the individual responses as y = \u03b20 +\u03b21x+\u03b5, We <b>can</b> think of y as being broken into a systematic and a ...", "dateLastCrawled": "2022-02-03T06:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Java Applet Basics - GeeksforGeeks", "url": "https://www.geeksforgeeks.org/java-applet-basics/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/java-applet-basics", "snippet": "Throwback of <b>making</b> GUI application: ... So we <b>can</b> say that SWING is much more advanced as <b>compared</b> to AWT technology. What is Applet? An applet is a Java program that <b>can</b> be embedded into a web page. It runs inside the web browser and works at client side. An applet is embedded in an HTML page using the APPLET or OBJECT tag and hosted on a web server. Applets are used to make the website more dynamic and entertaining. Important points : All applets are sub-classes (either directly or ...", "dateLastCrawled": "2022-02-02T21:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Dealing with missing data in ANOVA models</b> | R-bloggers", "url": "https://www.r-bloggers.com/2018/06/dealing-with-missing-data-in-anova-models/", "isFamilyFriendly": true, "displayUrl": "https://www.r-bloggers.com/2018/06/<b>dealing-with-missing-data-in-anova-models</b>", "snippet": "The full and the reduced model <b>can</b> then <b>be compared</b> with the pooled version of the \\(F\\)-test (i.e., the Wald test), ... which <b>can</b> lead to distorted <b>parameter</b> estimates if other variables are related to the chance of observing y (see Example 1). In order to account for this, ML requires including these extra variables in the analysis model, which changes the meaning of the parameters (i.e., the ANOVA becomes ANCOVA, though the estimates for it would be unbiased!). One key advantage of MI is ...", "dateLastCrawled": "2022-02-02T08:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>K-means</b> Clustering: Algorithm, Applications, Evaluation Methods, and ...", "url": "https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>k-means</b>-clustering-algorithm-applications-evaluation...", "snippet": "Technically speaking, we differentiate J w.r.t. wik first and <b>update</b> cluster assignments (E-step). Then we differentiate J w.r.t. \u03bck and recompute the centroids after the cluster assignments from previous step (M-step). Therefore, E-step is: In other words, assign the data point xi to the closest cluster judged by its sum of squared distance from cluster\u2019s centroid. And M-step is: Which translates to recomputing the centroid of each cluster to reflect the new assignments. Few things to ...", "dateLastCrawled": "2022-02-02T23:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Design of Experiments</b> (DOE) Tutorial - MoreSteam", "url": "https://www.moresteam.com/toolbox/design-of-experiments.cfm", "isFamilyFriendly": true, "displayUrl": "https://www.moresteam.com/toolbox/<b>design-of-experiments</b>.cfm", "snippet": "The term <b>experiment</b> is defined as the systematic procedure carried out under controlled conditions in order to discover an unknown effect, to test or establish a hypothesis, or to illustrate a known effect. When analyzing a process, experiments are often used to evaluate which process inputs have a significant impact on the process output, and what the target level of those inputs should be to achieve a desired result (output).", "dateLastCrawled": "2022-02-02T11:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "206 questions with answers in <b>TIME SERIES MODELING</b> | Science topic", "url": "https://www.researchgate.net/topic/Time-Series-Modeling", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/topic/<b>Time-Series-Modeling</b>", "snippet": "The idea is that you <b>can</b> compare modelling performance with and without an exogenous <b>parameter</b> in order to empirically evaluate so-called Forecast-Value-Added (FVA), see the above article (pp. 47 ...", "dateLastCrawled": "2022-01-22T10:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Drug Solubility: Importance and Enhancement Techniques</b>", "url": "https://www.hindawi.com/journals/isrn/2012/195727/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/isrn/2012/195727", "snippet": "Solubility, the phenomenon of dissolution of solute in solvent to give a homogenous system, is one of the important parameters to achieve desired concentration of drug in systemic circulation for desired (anticipated) pharmacological response. Low aqueous solubility is the major problem encountered with formulation development of new chemical entities as well as for the generic development. More than 40&amp;#x25; NCEs (new chemical entities) developed in pharmaceutical industry are practically ...", "dateLastCrawled": "2022-02-01T01:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Saponification - an overview | ScienceDirect Topics", "url": "https://www.sciencedirect.com/topics/chemistry/saponification", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/topics/chemistry/saponification", "snippet": "The saponification of \u03b1-hydroxy esters <b>can</b> be readily undertaken using well-tested procedures that are very similar to those employed for the hydrolysis of conventional ester groups (see Section 5.02.2.1.1 and references therein). The initial stages of an enantioselective synthesis of (R)-1-hydroxy-7-methoxy-1,2,3,4-tetrahydronaphthalene-1-carboxylic acid required saponification of the racemic \u03b1-hydroxy methyl ester 186.The hydrolysis was readily undertaken using aqueous lithium hydroxide ...", "dateLastCrawled": "2022-01-30T06:34:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning</b> fundamentals I: An <b>analogy</b> | Finn Rietz.dev", "url": "http://www.finnrietz.dev/machine%20learning/part-1-analogy/", "isFamilyFriendly": true, "displayUrl": "www.finnrietz.dev/<b>machine</b> <b>learning</b>/part-1-<b>analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> fundamentals I: An <b>analogy</b> Tags: <b>Machine</b> <b>Learning</b> fundamentals. Categories: <b>Machine</b> <b>Learning</b>. Updated: March 3, 2020. 11 minute read On this page. Introduction and motivation; Setting the scene for supervised <b>learning</b>; Telling right from wrong ; About parameters and artificial <b>learning</b>; Summary; Introduction and motivation. I remember the first weeks of attending Professor Uc-Cetina\u2019s lecture on <b>Machine</b> <b>Learning</b>, which was my first \u201creal\u201d academic encounter with the ...", "dateLastCrawled": "2022-01-16T09:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning by Analogy</b> - SlideShare", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-59094152", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine-learning-by-analogy</b>-59094152", "snippet": "<b>Machine Learning by Analogy</b> 1. Colleen M. Farrelly 2. Many <b>machine</b> <b>learning</b> methods exist in the literature and in industry. What works well for one problem may not work well for the next problem. In addition to poor model fit, an incorrect application of methods can lead to incorrect inference. Implications for data-driven business decisions. Low future confidence in data science and its results. Lower quality software products. Understanding the intuition and mathematics behind these ...", "dateLastCrawled": "2022-01-31T07:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) <b>Machine</b> <b>Learning</b> by <b>Analogy</b> - ResearchGate", "url": "https://www.researchgate.net/publication/321341661_Machine_Learning_by_Analogy", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321341661_<b>Machine</b>_<b>Learning</b>_by_<b>Analogy</b>", "snippet": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b>. November 2017 ; Authors: Colleen Farrelly. Jenzabar; Download file PDF Read file. Download file PDF. Read file. Download citation. Copy link Link copied. Read file ...", "dateLastCrawled": "2022-01-04T23:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Introduction to Machine Learning</b> \u2013 Data and Beyond", "url": "https://dataandbeyond.wordpress.com/2017/08/24/introduction-to-machine-learning-2/", "isFamilyFriendly": true, "displayUrl": "https://dataandbeyond.wordpress.com/2017/08/24/<b>introduction-to-machine-learning</b>-2", "snippet": "Optimization methods are applied to minimize the loss function by changing the <b>parameter</b> values, which is the central theme of <b>machine</b> <b>learning</b>.Zero-one loss is L0-1 = 1 (m &lt;= 0); in zero-one loss, value of loss is 0 for m &gt;= 0 whereas 1 for m &lt; 0. The difficult part with this loss is it is not differentiable, non-convex, and also NP-hard. Hence, in order to make optimization feasible and solvable, these losses are replaced by different surrogate losses for different problems.", "dateLastCrawled": "2022-01-17T05:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Machine</b> <b>Learning</b> by <b>Analogy</b> II - slideshare.net", "url": "https://www.slideshare.net/ColleenFarrelly/machine-learning-by-analogy-ii", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/ColleenFarrelly/<b>machine</b>-<b>learning</b>-by-<b>analogy</b>-ii", "snippet": "Updated <b>Machine</b> <b>Learning</b> by <b>Analogy</b> presentation that builds to more advanced methods (TensorFlow, geometry/topology-based methods...) and adds a section on ti\u2026", "dateLastCrawled": "2021-12-31T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The Hitchhiker\u2019s Guide to Optimization in <b>Machine Learning</b> | by Aman ...", "url": "https://towardsdatascience.com/the-hitchhikers-guide-to-optimization-in-machine-learning-edcf5a104210", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-hitchhikers-guide-to-optimization-in-<b>machine</b>...", "snippet": "<b>Machine Learning</b> is the ideal culmination of Applied Mathematics and Computer Science, where we train and use data-driven applications to run inferences on the available data. Generally speaking, for an ML task, the type of inference (i.e., the prediction that the model makes) varies on the basis of the problem statement and the type of data one is dealing with for the task at hand. However, in contrast to these dissimilarities, these algorithms tend to share some similarities as well ...", "dateLastCrawled": "2022-02-02T19:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Artificial Intelligence Open Elective Module</b> 5: <b>Learning</b> CH15", "url": "https://hemanthrajhemu.github.io/FutureVisionBIE/DOWNLOAD/AI/AI_Module5_Learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://hemanthrajhemu.github.io/FutureVisionBIE/DOWNLOAD/AI/AI_Module5_<b>Learning</b>.pdf", "snippet": "\u2022 <b>Machine</b> <b>learning</b> systems perform the following iteratively: Produce a result Evaluate it against expected result Tweak a system \u2022 <b>Machine</b> <b>learning</b> systems also discover patterns without prior expected results \u2022 Open box: changes are clearly visible in the knowledge base and clearly interpretable by the human users. \u2022 Black box: changes done to the system are not readily visible or understandable. 5 Learner Architecture \u2022 <b>Machine</b> <b>learning</b> systems has the four main components ...", "dateLastCrawled": "2022-01-06T03:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>machine</b> <b>learning</b> - How does Gradient Descent work? - Data Science Stack ...", "url": "https://datascience.stackexchange.com/questions/102509/how-does-gradient-descent-work", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/102509/how-does-gradient-descent-work", "snippet": "I know the calculus and the famous hill and valley <b>analogy</b> (so to say) of gradient descent. However, I find the <b>update</b> rule of the weights and biases quite terrible. Let&#39;s say we have a couple of parameters, one weight &#39;w&#39; and one bias &#39;b&#39;. Using SGD, we can <b>update</b> both w and b after the evaluation of each mini-batch. If the size of the mini ...", "dateLastCrawled": "2022-01-16T12:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - <b>Relation between MAP, EM, and</b> MLE - Cross Validated", "url": "https://stats.stackexchange.com/questions/235070/relation-between-map-em-and-mle", "isFamilyFriendly": true, "displayUrl": "https://stats.stackexchange.com/questions/235070/<b>relation-between-map-em-and</b>-mle", "snippet": "The relation between data, <b>parameter</b> and model is described using likelihood function. L ( \u03b8 \u2223 X) = p ( X \u2223 \u03b8) To find the best fitting \u03b8 you have to look for such value that maximizes the conditional probability of \u03b8 given X. Here things start to get complicated, because you can have different views on what \u03b8 is.", "dateLastCrawled": "2022-01-19T15:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Gradient Descent in Logistic Regression [Explained</b> for ... - upGrad blog", "url": "https://www.upgrad.com/blog/gradient-descent-in-logistic-regression/", "isFamilyFriendly": true, "displayUrl": "https://www.upgrad.com/blog/<b>gradient-descent-in-logistic-regression</b>", "snippet": "The reason is simple: it needs to compute the gradient, and <b>update</b> values simultaneously for every <b>parameter</b>,and that too for every training example. So think about all those calculations! It\u2019s massive, and hence there was a need for a slightly modified Gradient Descent Algorithm, namely \u2013 Stochastic Gradient Descent Algorithm (SGD). The only difference SGD has with Normal Gradient Descent is that, in SGD, we don\u2019t deal with the entire training instance at a single time. In SGD, we ...", "dateLastCrawled": "2022-01-28T16:49:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(parameter update)  is like +(scientist making an adjustment to an experiment)", "+(parameter update) is similar to +(scientist making an adjustment to an experiment)", "+(parameter update) can be thought of as +(scientist making an adjustment to an experiment)", "+(parameter update) can be compared to +(scientist making an adjustment to an experiment)", "machine learning +(parameter update AND analogy)", "machine learning +(\"parameter update is like\")", "machine learning +(\"parameter update is similar\")", "machine learning +(\"just as parameter update\")", "machine learning +(\"parameter update can be thought of as\")", "machine learning +(\"parameter update can be compared to\")"]}