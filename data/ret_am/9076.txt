{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Use Timesteps in LSTM Networks for <b>Time Series Forecasting</b>", "url": "https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/use-<b>timesteps</b>-lstm-networks-<b>time-series-forecasting</b>", "snippet": "The Long Short-Term Memory (LSTM) network in Keras supports time steps. This raises the question as to whether lag observations for a univariate time series can be used as time steps for an LSTM and whether or not this improves forecast performance. In this tutorial, we will investigate the use of lag observations as time steps in LSTMs models in Python. After completing", "dateLastCrawled": "2022-02-02T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "HTML | DOM <b>Input Time step Property - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/html-dom-input-time-step-property/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/html-dom-input-<b>time-step</b>-property", "snippet": "<b>Like</b> Article. HTML | DOM Input <b>Time step</b> Property. Difficulty Level : Basic; Last Updated : 17 Apr, 2019. The DOM Input <b>Time step</b> Property is used to set or return the value of the <b>step</b> attribute of a number field. The <b>step</b> attribute in HTML is used to specify the legal interval for second and milliseconds in the Time field. The <b>step</b> attribute could be used with min and max attribute for creating a legal value. For eg. If the value of <b>step</b> attribute is \u201c2\u201d then the legal; number\u2019s will ...", "dateLastCrawled": "2022-01-29T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Time-series</b> Forecasting using Conv1D-LSTM : Multiple timesteps into ...", "url": "https://shivapriya-katta.medium.com/time-series-forecasting-using-conv1d-lstm-multiple-timesteps-into-future-acc684dcaaa", "isFamilyFriendly": true, "displayUrl": "https://shivapriya-katta.medium.com/<b>time-series</b>-forecasting-using-conv1d-lstm-multiple...", "snippet": "In this post, I would <b>like</b> to focus on many to many model. In this case we can solve the problem in two different ways. Iterated Forecasting or Auto-regressive method: Create a look-back window containing the previous time steps to predict the value at the current <b>step</b> and then make a prediction. Now, add back the current prediction into the ...", "dateLastCrawled": "2022-02-02T16:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "How to Calculate Autocorrelation in Python? - GeeksforGeeks", "url": "https://www.geeksforgeeks.org/how-to-calculate-autocorrelation-in-python/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/how-to-calculate-autocorrelation-in-python", "snippet": "Output: Method 2: Creating lagged variables at different time steps. As we are aware of the fact that, the values of the observation at the current and previous time steps are significant in predicting the future <b>step</b>, let\u2019s create lagged variables at different timesteps say, t+1, t+2, t+3. This is done using pandas.concat() and shift() function. Shift function shifts the <b>timestep</b> by a specified value and the Concat function joins the lagged variables at different timesteps as shown below ...", "dateLastCrawled": "2022-01-30T06:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Part-<b>time Step</b> Parenting", "url": "https://part-timestep.blogspot.com/", "isFamilyFriendly": true, "displayUrl": "https://part-<b>timestep</b>.blogspot.com", "snippet": "I hope you will come back in 2012 to see how things are progressing in my <b>step</b>-parenting <b>journey</b>. <b>Like</b> with most everything else in life, we learn from our experiences. Hopefully, I will not make the same mistakes next year, but I&#39;m sure I will have new challenges. My stepson just turned 16 and my stepdaughter will be 15 in the spring. They&#39;re not really &quot;kids&quot; anymore, so they&#39;ll be facing new challenges as well. I&#39;m looking forward to seeing what the new year has in store for them and I ...", "dateLastCrawled": "2021-12-09T05:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Spiking Neural Networks: where neuroscience meets artificial ...", "url": "https://theaisummer.com/spiking-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://theaisummer.com/spiking-neural-networks", "snippet": "Over a time window T T T and a small <b>timestep</b> d t dt d t, the resulting spiketrain of the encoded signal, at each <b>timestep</b> d t dt d t, has probability r d t rdt r d t of containing a spike. In this way, the higher the probability r r r, the more spikes the resulting spiketrain will have. Thus the information will be encoded more accurately.", "dateLastCrawled": "2022-02-02T11:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "RL Trading \u2013 code study of sl-quant | datafireball", "url": "https://datafireball.com/2018/01/09/rl-trading/", "isFamilyFriendly": true, "displayUrl": "https://datafireball.com/2018/01/09/rl-trading", "snippet": "Within the terminal_state = 0, there are two if statements all based on the value of signal[<b>timestep</b>] and signal[<b>timestep</b>-1]. Signal is \u201cSeries with capital to invest (long+,short-) or number of shares\u201d. In that case, signal[\u2018<b>timestep</b>\u2019] and signal[<b>timestep</b>-1] is the capital to invest for the current and previous <b>step</b>. The interesting part if the both of them are equal to 0, basically means nothing to invest, the author actually deduct 10 points from the reward variable, I think this ...", "dateLastCrawled": "2022-01-05T14:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fix your timestep \u2013 in MonoGame</b> \u2013 warning! The blog has been moved to ...", "url": "https://lajbert.wordpress.com/2021/05/02/fix-your-timestep-in-monogame/", "isFamilyFriendly": true, "displayUrl": "https://lajbert.wordpress.com/2021/05/02/<b>fix-your-timestep-in-monogame</b>", "snippet": "Let\u2019s take this one <b>step</b> further: Why would you even want to have more than 30 collision checks / second? First, it\u2019s useless because the user won\u2019t notice it anyways (if your implementation is correct). Second, on mobile/handheld devices, hammering the CPU will drain the battery really fast, and it\u2019s kind of hard to defend why a Super Mario-<b>like</b> game eats up the battery and heats up the phone \ud83d\ude42", "dateLastCrawled": "2022-02-01T04:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Journey</b> to GPT2 | Watt AI", "url": "https://watt-ai.github.io/blog/language_generation", "isFamilyFriendly": true, "displayUrl": "https://watt-ai.github.io/blog/language_generation", "snippet": "However, recurrent neural networks (RNN) process data in loops, with outputs of a layer being reused as part of the input in the next <b>time step</b>. This gives the architecture a method of remembering previous inputs, also allowing it to perform tasks <b>like</b> generating language. So, in attempting generation, an RNN uses its previous input or a seeded input to predict the next word in the sentence one at a time, feeding the new prediction of the previous <b>timestep</b> in as a new input.", "dateLastCrawled": "2021-12-01T12:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Attention Craving RNNS: Building Up To Transformer Networks</b> | by ...", "url": "https://towardsdatascience.com/attention-craving-rnns-a-journey-into-attention-mechanisms-eec840fbc26f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/attention-craving-rnns-a-<b>journey</b>-into-attention...", "snippet": "An RNN cell takes in two inputs, a word x, and a hidden state from the previous <b>time step</b> h. At every <b>time step</b>, it outputs a new h. RNN CELL: next_h= f(x, prev_h). *Tip: For the first <b>step</b> h is normally just zeros. # 1 word, RNN has 56 hidden units h_0 = np.zeros(1, 56) This is important: RNN cell is DIFFERENT from an RNN. There\u2019s a MAJOR point of confusion in RNN terminology. In deep learning frameworks <b>like</b> Pytorch and Tensorflow, the RNN CELL is the unit that performs this computation ...", "dateLastCrawled": "2022-02-02T21:56:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Use Timesteps in LSTM Networks for <b>Time Series Forecasting</b>", "url": "https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/use-<b>timesteps</b>-lstm-networks-<b>time-series-forecasting</b>", "snippet": "The Long Short-Term Memory (LSTM) network in Keras supports time steps. This raises the question as to whether lag observations for a univariate time series can be used as time steps for an LSTM and whether or not this improves forecast performance. In this tutorial, we will investigate the use of lag observations as time steps in LSTMs models in Python. After completing", "dateLastCrawled": "2022-02-02T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Make Your Inventory Simulation in Python | Towards Data Science", "url": "https://towardsdatascience.com/make-your-inventory-simulation-in-python-9cb950da8cf3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/make-your-inventory-simulation-in-python-9cb950da8cf3", "snippet": "A <b>journey</b> through inventory optimization: profit maximization, inventory policies optimization, demand and supply\u2026 towardsdatascience.com. Simulation Setup Demand and Supply Chain. Let\u2019s start by defining the variable time \u2014 it will set the duration of our simulation. We can then populate a demand array that follows a normal distribution. import numpy as np time = 200 d_mu = 100 d_std = 25 d = np.maximum(np.random.normal(d_mu, d_std, time).round(0).astype(int),0) In this simulation, we ...", "dateLastCrawled": "2022-01-31T08:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Journey</b> to GPT2 | Watt AI", "url": "https://watt-ai.github.io/blog/language_generation", "isFamilyFriendly": true, "displayUrl": "https://watt-ai.github.io/blog/language_generation", "snippet": "However, recurrent neural networks (RNN) process data in loops, with outputs of a layer being reused as part of the input in the next <b>time step</b>. This gives the architecture a method of remembering previous inputs, also allowing it to perform tasks like generating language. So, in attempting generation, an RNN uses its previous input or a seeded input to predict the next word in the sentence one at a time, feeding the new prediction of the previous <b>timestep</b> in as a new input.", "dateLastCrawled": "2021-12-01T12:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Case studing</b> - slideshare.net", "url": "https://www.slideshare.net/mohsensalehi8/case-studing", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/mohsensalehi8/<b>case-studing</b>", "snippet": "56 Moving and Deforming Mesh + Variable <b>Time Step</b> (7) A relation is needed to solve for the <b>timestep</b> size and velocity of the body: The <b>timestep</b> size and the corresponding velocity of the body are such that the body will move by the maximum allowable translational distance A cap on the <b>timestep</b> size is necessary to prevent an excessively large computed <b>timestep</b> size which can result in divergence The maximum allowable translational distance can be varied as function of time, if necessary The ...", "dateLastCrawled": "2022-02-02T01:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Part-<b>time Step</b> Parenting", "url": "https://part-timestep.blogspot.com/", "isFamilyFriendly": true, "displayUrl": "https://part-<b>timestep</b>.blogspot.com", "snippet": "I hope you will come back in 2012 to see how things are progressing in my <b>step</b>-parenting <b>journey</b>. Like with most everything else in life, we learn from our experiences. Hopefully, I will not make the same mistakes next year, but I&#39;m sure I will have new challenges. My stepson just turned 16 and my stepdaughter will be 15 in the spring. They&#39;re ...", "dateLastCrawled": "2021-12-09T05:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Understanding of LSTM Networks - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/understanding-of-lstm-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/understanding-of-lstm-networks", "snippet": "This results in a thorough process of inputs in each <b>time step</b>. Figure-C represents LSTM with the Recurrent Projection layer where the recurrent connections are taken from the projection layer to the LSTM layer input. This architecture was designed to reduce the high learning computational complexity (O(N)) for each <b>time step</b>) of the standard LSTM RNN. Figure-D represents Deep LSTM with a Recurrent Projection Layer consisting of multiple LSTM layers where each layer has its own projection ...", "dateLastCrawled": "2022-02-03T06:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Long Short <b>Term Memory Networks Explanation - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/long-short-term-memory-networks-explanation/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/long-short-term-memory-networks-explanation", "snippet": "In an LSTM, the term does not have a fixed pattern and can take any positive value at any <b>time step</b>. Thus, it is not guaranteed that for an infinite number of time steps, the term will converge to 0 or diverge completely. If the gradient starts converging towards zero, then the weights of the gates can be adjusted accordingly to bring it closer to 1. Since during the training phase, the network adjusts these weights only, it thus learns when to let the gradient converge to zero and when to ...", "dateLastCrawled": "2022-02-01T01:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Seq2Seq</b> model in TensorFlow. In this project, I am going to build\u2026 | by ...", "url": "https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>seq2seq</b>-model-in-tensorflow-ec0c557e560f", "snippet": "TF nn.embedding_lookup with manually created embedding parameters returns the <b>similar</b> result to the TF contrib.layers.embed_sequence. For the inference process, whenever the output of the current <b>time step</b> is calculated via decoder, it will be embeded by the shared embedding parameter and become the input for the next <b>time step</b>. You only need to provide the embedding parameter to the GreedyEmbeddingHelper, then it will help the process. How embedding_lookup works?: In short, it selects ...", "dateLastCrawled": "2022-02-01T09:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Spiking Neural Networks: where neuroscience meets artificial ...", "url": "https://theaisummer.com/spiking-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://theaisummer.com/spiking-neural-networks", "snippet": "<b>SIMILAR</b> ARTICLES. Machine Learning. Document clustering. Neural Network from scratch-part 1. Neural Network from scratch-part 2 . Deep Learning- The future or another AI buzzword. Explain Neural Arithmetic Logic Units (NALU) In-layer normalization techniques for training very deep neural networks . A <b>journey</b> into Optimization algorithms for Deep Neural Networks. Explainable AI (XAI): A survey of recents methods, applications and frameworks. Regularization techniques for training deep neural ...", "dateLastCrawled": "2022-02-02T11:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A Guide to the <b>Encoder-Decoder</b> Model and the Attention Mechanism | by ...", "url": "https://betterprogramming.pub/a-guide-on-the-encoder-decoder-model-and-the-attention-mechanism-401c836e2cdb", "isFamilyFriendly": true, "displayUrl": "https://betterprogramming.pub/a-guide-on-the-<b>encoder-decoder</b>-model-and-the-attention...", "snippet": "Today, we\u2019ll continue our <b>journey</b> through the world of NLP. In this article, we\u2019re going to describe the basic architecture of an <b>encoder-decoder</b> model that we\u2019ll apply to a neural machine translation problem, translating texts from English to Spanish. Later, we\u2019ll introduce a technique that has been a great <b>step</b> forward in the treatment of NLP tasks: the attention mechanism. We\u2019ll detail a basic processing of the attention applied to a scenario of a sequence-to-sequence model ...", "dateLastCrawled": "2022-01-24T15:06:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Use Timesteps in LSTM Networks for <b>Time Series Forecasting</b>", "url": "https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/use-<b>timesteps</b>-lstm-networks-<b>time-series-forecasting</b>", "snippet": "If this is exact what I <b>thought</b>, I think there should not be a time shift in the test set because the output value doesn\u2019t even exist before you make a prediction on this time stamp. And this may cause that the test set already contains the real value for prediction in its feature. What I <b>thought</b> is that you only <b>can</b> make predictions <b>step</b> by <b>step</b> in the test set. First generate the prediction of the first time stamp, and use that prediction in computing the output of next time stamp ...", "dateLastCrawled": "2022-02-02T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Multi-<b>Step</b> Time Series Forecasting - The Click Reader", "url": "https://www.theclickreader.com/multi-step-time-series-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://www.theclickreader.com/multi-<b>step</b>-time-series-forecasting", "snippet": "Multi-<b>step</b> forecasting <b>can</b> be done in the following two approaches, Direct method where the entire sequence of future values is predicted at once. Recursive method where the model only makes single-<b>step</b> predictions such that the prediction made is again fed back into the model as input recursively. This chapter will cover both approaches for multi-<b>step</b> forecasting. For the multi-<b>step</b> model, the training data will again consist of hourly samples. However, here, the models will learn to ...", "dateLastCrawled": "2021-12-28T08:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Let\u2019s jump into the world of LSTM, GRU and Attention models | by ...", "url": "https://prathibhar7.medium.com/lets-jump-into-the-world-of-lstm-gru-and-attention-models-829b1ab4f820", "isFamilyFriendly": true, "displayUrl": "https://prathibhar7.medium.com/lets-jump-into-the-world-of-lstm-gru-and-attention...", "snippet": "It <b>can</b> <b>be thought</b> as \u201cmemory\u201d of the network. The cell state, in theory, <b>can</b> carry relevant information throughout the processing of the sequence. So even information from the earlier time steps <b>can</b> make it\u2019s way to later time steps, reducing the effects of short-term memory. As the cell state goes on its <b>journey</b>, information gets added or removed to the cell state via gates. The gates are different neural networks that decide which information is allowed on the cell state. The gates ...", "dateLastCrawled": "2022-01-09T00:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>Journey</b> Backwards through Time with LSTMs | by SolveSmart ...", "url": "https://medium.com/solvesmart/a-journey-backwards-through-time-with-lstms-d05f554a9658?source=post_internal_links---------3----------------------------", "isFamilyFriendly": true, "displayUrl": "https://medium.com/solvesmart/a-<b>journey</b>-backwards-through-time-with-lstms-d05f554a9658?...", "snippet": "With a little <b>thought</b> it <b>can</b> in fact be noted that an LSTM <b>can</b> be set up with weights and activation functions such that this recall is (in practice) exact. We comment further on the use of ...", "dateLastCrawled": "2021-12-14T11:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Reinforcement learning: <b>Temporal-Difference</b>, SARSA, Q-Learning ...", "url": "https://towardsdatascience.com/reinforcement-learning-temporal-difference-sarsa-q-learning-expected-sarsa-on-python-9fecfda7467e", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/reinforcement-learning-<b>temporal-difference</b>-sarsa-q...", "snippet": "An environment <b>can</b> <b>be thought</b> of as a mini-world where an agent <b>can</b> observe discrete states, take actions and observe rewards by taking those actions. Think of a video game as an environment and yourself as the agent. In the game Doom, you as an agent will observe the states (screen frames) and take actions (press keys like Forward, backward, jump, shoot etc) and observe rewards. Killing an enemy would yield you pleasure (utility) and a positive reward while moving ahead won\u2019t yield you ...", "dateLastCrawled": "2022-02-03T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Seq2Seq</b> model in TensorFlow. In this project, I am going to build\u2026 | by ...", "url": "https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>seq2seq</b>-model-in-tensorflow-ec0c557e560f", "snippet": "<b>can</b> <b>be thought</b> as splitting into multiple tensors with the striding window size from begin to end; arguments: TF Tensor, Begin, End, Strides ; TF fill. creates a tensor filled with a scalar value. arguments: TF Tensor (must be int32/int64), value to fill; TF concat. concatenates tensors along one dimension. arguments: a list of TF Tensor (tf.fill and after_slice in this case), axis=1; After preprocessing the target label data, we will embed it later when implementing decoding_layer function ...", "dateLastCrawled": "2022-02-01T09:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Rayleigh\u2013Taylor and Richtmyer\u2013Meshkov instabilities</b>: A <b>journey</b> through ...", "url": "https://www.sciencedirect.com/science/article/pii/S0167278920308393", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0167278920308393", "snippet": "<b>Rayleigh\u2013Taylor and Richtmyer\u2013Meshkov instabilities</b>: A <b>journey</b> through scales ... This <b>can</b> either be a desired outcome, an unwelcome side effect, or just an unavoidable consequence, but must in all cases be characterized in any model. The RT instability occurs at an interface between different fluids, when the light fluid is accelerated into the heavy. The RM instability may be considered a special case of the RT instability, when the acceleration provided is impulsive in nature such as ...", "dateLastCrawled": "2022-01-20T22:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The <b>story of the non deterministic Replay</b> - Gemserk", "url": "https://blog.gemserk.com/2016/09/26/the-story-of-the-non-deterministic-replay/", "isFamilyFriendly": true, "displayUrl": "https://blog.gemserk.com/2016/09/26/the-<b>story-of-the-non-deterministic-replay</b>", "snippet": "After I had that done and working, it was pretty awesome to see I <b>can</b> replay the same game multiple times (food for another blog post by the way), however, I <b>thought</b> it could be fun and easy to play them faster, why not. Since I have a fixed <b>time step</b> logic, it should should be pretty straightforward, simply use a multiplied time and then the fixed <b>timestep</b> logic would do all the work and the game logic shouldn\u2019t notice the change. I decided to give it a try and it worked\u2026. almost, when ...", "dateLastCrawled": "2021-12-23T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Step</b> One Aa The Foundation Of Recovery", "url": "https://unms1.openbb.net/step_one_aa_the_foundation_of_recovery_pdf", "isFamilyFriendly": true, "displayUrl": "https://unms1.openbb.net/<b>step</b>_one_aa_the_foundation_of_recovery_pdf", "snippet": "EngineeringTwelve <b>Step</b> Facilitation Therapy ManualHigh-impact Educational PracticesStep 2 AA Coming to BelieveTwenty-Four Hours a DayHazelden 12 <b>Step</b> Pamphlet CollectionThe 12 <b>Step</b> Philosophy of Alcoholics Anonymous12-<b>Step</b> Workbook for Recovering Alcoholics, Including Powerful 4Th-<b>Step</b> WorksheetsTwenty-Four Hours A DayStep 1 AA Foundations of RecoveryA Day at a <b>TimeStep</b> 9 AA Repairing the PastDrop the Rock--The Ripple EffectStep OneThe Little Red BookResearch in the Social Scientific Study ...", "dateLastCrawled": "2022-01-20T16:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Step</b> One Aa The Foundation Of Recovery", "url": "https://lenz-umwelttechnik.de/step-one-aa-the-foundation-of-recovery-pdf", "isFamilyFriendly": true, "displayUrl": "https://lenz-umwelttechnik.de/<b>step</b>-one-aa-the-foundation-of-recovery-pdf", "snippet": "Acces PDF <b>Step</b> One Aa The Foundation Of Recovery &quot;This is the addict&#39;s <b>journey</b>: how it happens, how it progresses, and how it ends. Fortunately, this is also the <b>journey</b> of recovery: how it happens, and how it blossoms. There is always hope.&quot; --&quot;Dr. Drew&quot; Pinsky, M.D.Heroin addiction didn&#39;t make Tim a better person. It stole more than half of ...", "dateLastCrawled": "2022-01-06T18:54:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "How to Use Timesteps in LSTM Networks for <b>Time Series Forecasting</b>", "url": "https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/use-<b>timesteps</b>-lstm-networks-<b>time-series-forecasting</b>", "snippet": "The Long Short-Term Memory (LSTM) network in Keras supports time steps. This raises the question as to whether lag observations for a univariate time series <b>can</b> be used as time steps for an LSTM and whether or not this improves forecast performance. In this tutorial, we will investigate the use of lag observations as time steps in LSTMs models in Python. After completing", "dateLastCrawled": "2022-02-02T08:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Multi-<b>step</b> Time Series Forecasting with ARIMA, LightGBM, and Prophet ...", "url": "https://towardsdatascience.com/multi-step-time-series-forecasting-with-arima-lightgbm-and-prophet-cc9e3f95dfb0", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/multi-<b>step</b>-time-series-forecasting-with-arima-lightgbm...", "snippet": "As the model <b>can</b> only predict a one-<b>step</b> forecast, ... In this blog post, we <b>compared</b> the three different model algorithms on the different types of time series. LightGBM showed comparable or better performance than ARIMA except for the time series with seasonality (Airline). Model Forecast MAE by Time Series Dataset . As LightGBM is a non-linear model, it has a higher risk of overfitting to data than linear models. You might want to set up reliable cross-validation when you use it. The ...", "dateLastCrawled": "2022-02-01T06:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Learn Physics Optimization in Unity Easily", "url": "http://www.theappguruz.com/blog/learn-physics-optimization-in-unity-easily", "isFamilyFriendly": true, "displayUrl": "www.theappguruz.com/blog/learn-physics-optimization-in-unity-easily", "snippet": "Fasten your seat belts as this is going to be a long but enjoyable <b>journey</b>. LOWER FIXED <b>TIMESTEP</b>..! As Stated in Unity Docs, \u201cA framerate-independent interval that dictates when physics calculations and FixedUpdate() events are performed.\u201d Default value is 0.02 (in seconds), this shows that every 20ms Physics Update will be executed. All FixedUpdate() will also be called every 20ms. But if your game is not heavily dependent on physics, you <b>can</b> always increase the <b>TimeStep</b> to get better ...", "dateLastCrawled": "2022-01-30T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Fix your <b>timestep</b> \u2013 in MonoGame \u2013 warning! The blog has been moved to ...", "url": "https://lajbert.wordpress.com/2021/05/02/fix-your-timestep-in-monogame/comment-page-1/", "isFamilyFriendly": true, "displayUrl": "https://lajbert.wordpress.com/2021/05/02/fix-your-<b>timestep</b>-in-monogame/comment-page-1", "snippet": "Now, we have to change the Update() method to implement the fixed update. The idea is the following (although this is explained in Glenn Fiedler\u2019s Fix your <b>Timestep</b>! post): we are going to measure the elapsed time of the game in an accumulator. While accumulator is bigger than our desired fixed update delay, we are going to run one FixedUpdate and decrease the accumulator by the fixed update delay.", "dateLastCrawled": "2022-02-03T07:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Estimating the Highest <b>Time-Step</b> in Numerical Methods to Enhance ...", "url": "https://www.researchgate.net/publication/353929784_Estimating_the_Highest_Time-Step_in_Numerical_Methods_to_Enhance_the_Optimization_of_Chaotic_Oscillators", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353929784_Estimating_the_Highest_<b>Time-Step</b>_in...", "snippet": "behavior <b>can</b> be identi\ufb01ed in the one-<b>step</b> methods known as Backward Euler and T rape-zoidal. The numerical methods that do not have this property are said to be numerically . unstable, and this ...", "dateLastCrawled": "2021-09-25T12:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Understanding of LSTM Networks - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/understanding-of-lstm-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>geeksforgeeks</b>.org/understanding-of-lstm-networks", "snippet": "This results in a thorough process of inputs in each <b>time step</b>. Figure-C represents LSTM with the Recurrent Projection layer where the recurrent connections are taken from the projection layer to the LSTM layer input. This architecture was designed to reduce the high learning computational complexity (O(N)) for each <b>time step</b>) of the standard LSTM RNN. Figure-D represents Deep LSTM with a Recurrent Projection Layer consisting of multiple LSTM layers where each layer has its own projection ...", "dateLastCrawled": "2022-02-03T06:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Part-<b>time Step</b> Parenting", "url": "https://part-timestep.blogspot.com/", "isFamilyFriendly": true, "displayUrl": "https://part-<b>timestep</b>.blogspot.com", "snippet": "I hope you will come back in 2012 to see how things are progressing in my <b>step</b>-parenting <b>journey</b>. Like with most everything else in life, we learn from our experiences. Hopefully, I will not make the same mistakes next year, but I&#39;m sure I will have new challenges. My stepson just turned 16 and my stepdaughter will be 15 in the spring. They&#39;re ...", "dateLastCrawled": "2021-12-09T05:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Spiking Neural Networks: where neuroscience meets artificial ...", "url": "https://theaisummer.com/spiking-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://theaisummer.com/spiking-neural-networks", "snippet": "Typical ANNs transfer information in sync, wherein in one <b>step</b>, a layer reads an input, computes an output, and feeds it forward. Biological neurons, on the other hand, rely on the temporal dimension. At any moment, they <b>can</b> take an input signal and produce an output, regardless of the behavior of the rest of the neurons.", "dateLastCrawled": "2022-02-02T11:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "A review <b>of Reinforcement learning for financial time</b> series prediction ...", "url": "https://medium.com/journal-of-quantitative-finance/a-review-of-reinforcement-learning-for-financial-time-series-prediction-and-portfolio-optimisation-4cb2e92a23f3", "isFamilyFriendly": true, "displayUrl": "https://<b>medium</b>.com/journal-of-quantitative-finance/a-review-of-reinforcement-learning...", "snippet": "Reinforcement learning (RL) is a relatively new paradigm of Artificial intelligence and is becoming widely adopted for function optimization and control system problems. Reinforcement learning is\u2026", "dateLastCrawled": "2022-01-27T23:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "My attempt at achieving a low input lag. Am I doing it right? - Blur ...", "url": "https://forums.blurbusters.com/viewtopic.php?t=6491", "isFamilyFriendly": true, "displayUrl": "https://forums.blurbusters.com/viewtopic.php?t=6491", "snippet": "I also tried to have variable <b>timestep</b> in a way that the next frame <b>can</b> start earlier to be in sync with the screen refresh, but overall the update rate is the same. This what I call &quot;loose <b>timestep</b>&quot;. The program has a scene in which it displays 3 white bars when an input is pressed. I use a photodiode and a microcontroller to send keyboard inputs and measure how long it takes for the screen to go from black to white, and then how many frames are displayed before the program displays black ...", "dateLastCrawled": "2021-12-16T04:26:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Multistep Time Series Forecasting with</b> LSTMs in Python", "url": "https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/<b>multi-step-time-series-forecasting</b>-long-short-term...", "snippet": "How to Setup a Python Environment for <b>Machine</b> <b>Learning</b> and Deep <b>Learning</b> with Anaconda; Next, let\u2019s take a look at a standard <b>time series forecasting</b> problem that we can use as context for this experiment. Need help with Deep <b>Learning</b> for Time Series? Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course . Shampoo Sales Dataset. This dataset describes the monthly number of sales of ...", "dateLastCrawled": "2022-02-02T18:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "A distributed <b>machine learning</b> approach that trains <b>machine learning</b> models using decentralized examples residing on devices such as smartphones. In federated <b>learning</b>, a subset of devices downloads the current model from a central coordinating server. The devices use the examples stored on the devices to make improvements to the model. The devices then upload the model improvements (but not the training examples) to the coordinating server, where they are aggregated with other updates to ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A Gentle Introduction to <b>Long Short-Term Memory</b> Networks by the Experts", "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearning</b>mastery.com/gentle-introduction-<b>long-short-term-memory</b>-networks...", "snippet": "<b>Long Short-Term Memory</b> (LSTM) networks are a type of recurrent neural network capable of <b>learning</b> order dependence in sequence prediction problems. This is a behavior required in complex problem domains like <b>machine</b> translation, speech recognition, and more. LSTMs are a complex area of deep <b>learning</b>. It can be hard to get your hands around what LSTMs are, and how terms like bidirectional", "dateLastCrawled": "2022-01-31T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Everything you need to know about <b>Graph Theory</b> for Deep <b>Learning</b> | by ...", "url": "https://towardsdatascience.com/graph-theory-and-deep-learning-know-hows-6556b0e9891b", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>graph-theory</b>-and-deep-<b>learning</b>-know-hows-6556b0e9891b", "snippet": "An easy way to think about it is using an <b>analogy</b> to names, characters, and people: a node is a person, a node\u2019s label is a person\u2019s name, and the node\u2019s features are the person\u2019s characteristics. Graphs can be directed or undirected: Note that directed graphs can have undirected edges too. A node in the graph can even have an edge that points/connects to itself. This is known as a self-loop. Graphs can be either: Heterogeneous \u2014 composed of different types of nodes; Homogeneous ...", "dateLastCrawled": "2022-02-03T17:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Interpretability in <b>Machine</b> <b>Learning</b>: An Overview", "url": "https://thegradient.pub/interpretability-in-ml-a-broad-overview/", "isFamilyFriendly": true, "displayUrl": "https://thegradient.pub/interpretability-in-ml-a-broad-overview", "snippet": "First, interpretability in <b>machine</b> <b>learning</b> is useful because it can aid in trust. As humans, we may be reluctant to rely on <b>machine</b> <b>learning</b> models for certain critical tasks, e.g., medical diagnosis, unless we know &quot;how they work.&quot; There&#39;s often a fear of the unknown when trusting in something opaque, which we see when people confront new technology, and this can slow down adoption. Approaches to interpretability that focus on transparency could help mitigate some of these fears.", "dateLastCrawled": "2022-02-01T15:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Computing Time Part (I): Recurrent Neural Networks</b> \u2013 The Beauty of ...", "url": "https://thebeautyofml.wordpress.com/2017/01/01/computing-time-part-i-recurrent-neural-networks/", "isFamilyFriendly": true, "displayUrl": "https://thebeautyofml.wordpress.com/2017/01/01/<b>computing-time-part-i-recurrent-neural</b>...", "snippet": "Nothing will surprise you more than recurrent nets if you practice <b>machine</b> <b>learning</b>. Recurrent net is the most powerful, successful and the luckiest neural network ever. Today\u2019s research in deep <b>learning</b> relies heavily on recurrent nets, although they are not recognized as deep <b>learning</b> techniques. The history of recurrent nets returns back to 1980s but only saw this renaissance with the rise of deep <b>learning</b> and deep neural networks. Introduction. Before introducing how recurrent neural ...", "dateLastCrawled": "2022-01-23T05:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Learning</b> an Internal Dynamics Model from Control Demonstration", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3929129/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC3929129", "snippet": "Due to sensory feedback delay, the feedback available at <b>timestep</b> t represents the plant state at <b>timestep</b> t \u2212 \u03c4, where \u03c4 is the feedback delay. To predict the current plant state, the subject can use f 1 as a forward model, propagating y t\u2212\u03c4 (or a noise-corrupted function of it) forward in time using knowledge of the plant dynamics and previously issued controls u t\u2212\u03c4, \u2026, u t\u22121.In general, the subject\u2019s internal beliefs {x t} may be inconsistent with the actual plant states ...", "dateLastCrawled": "2017-01-01T08:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b> <b>learning</b> molecular dynamics for the simulation of infrared ...", "url": "https://pubs.rsc.org/en/content/articlelanding/2017/sc/c7sc02267k#!", "isFamilyFriendly": true, "displayUrl": "https://pubs.rsc.org/en/content/articlelanding/2017/sc/c7sc02267k", "snippet": "1 Introduction . <b>Machine</b> <b>learning</b> (ML) \u2013 the science of autonomously <b>learning</b> complex relationships from data \u2013 has experienced an immensely successful resurgence during the last decade. 1,2 Increasingly powerful ML algorithms form the basis of a wealth of fascinating applications, with image and speech recognition, search engines or even self-driving cars being only a few examples. In a similar manner, ML based techniques have lead to several exciting developments in the field of ...", "dateLastCrawled": "2022-02-03T01:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Learning</b> earth system models from observations: <b>machine</b> <b>learning</b> or ...", "url": "https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0089", "isFamilyFriendly": true, "displayUrl": "https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0089", "snippet": "1. Introduction. <b>Machine</b> <b>learning</b> (ML) has made rapid progress in diverse areas including the classification of images [1,2], translation between languages [3,4] and superseding human skill at the game of go (e.g. [5,6]).These applications can require neural networks with millions to billions of trainable parameters, large numbers of layers and specialized architectures, such as convolutional networks.", "dateLastCrawled": "2022-02-01T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Code <b>and Understand DeepMind&#39;s Neural Stack Machine</b> - i am trask", "url": "https://iamtrask.github.io/2016/02/25/deepminds-neural-stack-machine/", "isFamilyFriendly": true, "displayUrl": "https://iamtrask.github.io/2016/02/25/<b>deepminds-neural-stack-machine</b>", "snippet": "However, at each <b>timestep</b>, the memory can have more than one value v_t inside of it! This will have significant implications for the code later (and the memory overhead). Bottom Line: If V_t is the state of the stack&#39;s memory at time &quot;t&quot;, then V is a list of ALL of the memory states the stack goes through (at every <b>timestep</b>). So, V is a list of ...", "dateLastCrawled": "2022-01-29T11:33:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Novel Re-<b>weighting Method for Connectionist Temporal Classification</b> ...", "url": "https://deepai.org/publication/a-novel-re-weighting-method-for-connectionist-temporal-classification", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-novel-re-<b>weighting-method-for-connectionist-temporal</b>...", "snippet": "The connectionist temporal classification (CTC) enables end-to-end sequence <b>learning</b> by maximizing the probability of correctly recognizing sequences during training. With an extra blank class, the CTC implicitly converts recognizing a sequence into classifying each timestep within the sequence. But the CTC loss is not intuitive for such classification task, so the class imbalance within each sequence, caused by the overwhelming blank timesteps, is a knotty problem.", "dateLastCrawled": "2021-12-21T21:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Novel Re-weighting Method for <b>Connectionist Temporal Classification</b> ...", "url": "https://www.arxiv-vanity.com/papers/1904.10619/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1904.10619", "snippet": "The <b>connectionist temporal classification</b> (CTC) enables end-to-end sequence <b>learning</b> by maximizing the probability of correctly recognizing sequences during training. With an extra blank class, the CTC implicitly converts recognizing a sequence into classifying each timestep within the sequence. But the CTC loss is not intuitive for such classification task, so the class imbalance within each sequence, caused by the overwhelming blank timesteps, is a knotty problem. In this paper, we define ...", "dateLastCrawled": "2021-11-30T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "COWES: Web user clustering based on evolutionary web sessions ...", "url": "https://www.sciencedirect.com/science/article/pii/S0169023X09000792", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0169023X09000792", "snippet": "Let us look at novel clusters which can be discovered based on evolutionary characteristics of web usage data in our motivating example in Fig. 2.Pages accessed in a web session can be organized into a hierarchical structure, called web session tree, based on the URLs of the pages .For example, Fig. 1b is the web session tree constructed for the pages in the web session shown in Fig. 1a. A web session tree represents the information needs of a user.", "dateLastCrawled": "2021-12-12T14:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Neural network augmented wave-equation simulation", "url": "https://slim.gatech.edu/Publications/Public/TechReport/2019/siahkoohi2019TRnna/siahkoohi2019TRnna.html", "isFamilyFriendly": true, "displayUrl": "https://slim.gatech.edu/Publications/Public/TechReport/2019/siahkoohi2019TRnna/...", "snippet": "We describe how we augment low-fidelity physics with <b>learning</b> techniques to handle incomplete and/or inaccurate physics, where the low-fidelity physics is modeled via finite-difference method with a poor discretization of the Laplacian. To ensure accuracy, the temporal and spatial discretization in high-fidelity wave-equation simulations have to be chosen very fine, typically one to two orders of magnitude smaller than Nyquist sampling rate. As mentioned earlier, we will utilize a poor ...", "dateLastCrawled": "2021-12-16T11:54:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(timestep)  is like +(step in a journey)", "+(timestep) is similar to +(step in a journey)", "+(timestep) can be thought of as +(step in a journey)", "+(timestep) can be compared to +(step in a journey)", "machine learning +(timestep AND analogy)", "machine learning +(\"timestep is like\")", "machine learning +(\"timestep is similar\")", "machine learning +(\"just as timestep\")", "machine learning +(\"timestep can be thought of as\")", "machine learning +(\"timestep can be compared to\")"]}