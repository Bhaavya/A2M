{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Federated</b> <b>learning</b> in medicine: facilitating multi-institutional ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7387485/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7387485", "snippet": "<b>Federated</b> <b>learning</b> (FL) 16 is a data-private collaborative <b>learning</b> method where <b>multiple</b> collaborators train a machine <b>learning</b> model at the same time (i.e., each on their own data, in parallel) and then send their model updates to a central server to be aggregated into a consensus model (Fig. 1 b). The aggregation server then sends the consensus model to all <b>collaborating</b> institutions for use and/or further <b>training</b>. Each iteration of this process, i.e., parallel <b>training</b>, update ...", "dateLastCrawled": "2022-01-26T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Federated</b> <b>Learning</b>: A Guide to Collaborative <b>Training</b> with ...", "url": "https://www.inovex.de/de/blog/federated-learning-collaborative-training-part-1/", "isFamilyFriendly": true, "displayUrl": "https://www.inovex.de/de/blog/<b>federated</b>-<b>learning</b>-collaborative-<b>training</b>-part-1", "snippet": "In <b>Federated</b> <b>Learning</b>, <b>models</b> (more specifically model updates) are exchanged between the participants and a curator that manages the <b>Federated</b> <b>Learning</b> process. This process is visualized in Figure 1 featuring three participants in green, blue and red collaboratively <b>training</b> a central model. Initially, a central model architecture is defined and the parameters of the model are randomly initialized. Subsequently a <b>Federated</b> <b>Learning</b> itteration is run by executing the following steps: A copy ...", "dateLastCrawled": "2022-01-08T05:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Federated</b> <b>learning</b> in medicine: facilitating multi-institutional ...", "url": "https://www.nature.com/articles/s41598-020-69250-1", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-020-69250-1", "snippet": "<b>Federated</b> <b>learning</b> (FL) 16 is a data-private collaborative <b>learning</b> method where <b>multiple</b> collaborators train a machine <b>learning</b> model at the same time (i.e., each on their own data, in parallel ...", "dateLastCrawled": "2022-01-29T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "QuantumFed: A <b>Federated</b> <b>Learning</b> Framework for Collaborative Quantum ...", "url": "https://www.cs.wm.edu/~liqun/paper/arxiv21.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.wm.edu/~liqun/paper/arxiv21.pdf", "snippet": "<b>learning</b> [2], [9], [17], [18], [22]. In deep neural network model <b>training</b>, sometimes it is necessary to train a model through <b>multiple</b> machines in a distributed manner, e.g., <b>federated</b> <b>learning</b> [12], [16]. <b>Fed-erated</b> <b>learning</b> is a collaborative way to train a global model where each node has their private local data in classic machine <b>learning</b> ...", "dateLastCrawled": "2022-01-21T09:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "FSL: <b>Federated</b> Supermask <b>Learning</b> | DeepAI", "url": "https://deepai.org/publication/fsl-federated-supermask-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/fsl-<b>federated</b>-supermask-<b>learning</b>", "snippet": "<b>Federated</b> <b>Learning</b> (FL) is an emerging AI technology, where mutually untrusted clients (e.g., Android devices) collaborate to train a shared model, called the global model, without explicitly sharing their local <b>training</b> data.FL <b>training</b> involves a server (e.g., Google) which collects model updates from selected FL clients in each round of <b>training</b>, and uses them to update the global model. FL, although highly promising, faces <b>multiple</b> challenges (kairouz2019advances; li2020federated) to its ...", "dateLastCrawled": "2022-01-19T03:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Federated learning</b>: Why and how to get started? | by Jean-Christophe ...", "url": "https://medium.com/digital-catapult/federated-learning-why-and-how-to-get-started-811d7bdb468f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/digital-catapult/<b>federated-learning</b>-why-and-how-to-get-started-811d...", "snippet": "<b>Federated learning</b> (FL) is a particular approach for <b>training</b> machine <b>learning</b> (ML) algorithms in a way that means data stays private. Specifically, <b>federated learning</b> techniques aim to train ...", "dateLastCrawled": "2022-01-13T06:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How to choose the best <b>Federated</b> <b>Learning</b> Platform in 2022", "url": "https://www.apheris.com/blog-how-to-choose-the-best-federated-learning-platform-in-2021", "isFamilyFriendly": true, "displayUrl": "https://www.apheris.com/blog-how-to-choose-the-best-<b>federated</b>-<b>learning</b>-platform-in-2021", "snippet": "<b>Federated</b> <b>learning</b> is the most efficient technology out there that can help data scientists to build high-quality machine <b>learning</b> <b>models</b> in industries where data is extremely difficult or even impossible to obtain. These industries face many challenges, not only regarding sensitivity and data privacy but also internal restrictions with regards to protecting their own model IP.", "dateLastCrawled": "2022-02-03T07:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "1 Introduction \u2013 <b>Federated</b> <b>Learning</b> \u2013 Dev Guis", "url": "http://devguis.com/1-introduction-federated-learning.html", "isFamilyFriendly": true, "displayUrl": "devguis.com/1-introduction-<b>federated</b>-<b>learning</b>.html", "snippet": "How to enable the updating and sharing of <b>models</b> among the <b>multiple</b> sites in a secure and yet efficient way is a new challenge to the current computing methodologies. 1.2 <b>FEDERATED</b> <b>LEARNING</b> AS A SOLUTION . As mentioned previously, <b>multiple</b> reasons make the problem of data silos become impediment to the big data needed to train ML <b>models</b>. It is thus natural to seek solutions to build ML <b>models</b> that do not rely on collecting all data to a centralized storage where model <b>training</b> can happen. An ...", "dateLastCrawled": "2022-01-02T23:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Overview \u2039 <b>Split Learning: Distributed and collaborative learning</b> \u2014 MIT ...", "url": "https://www.media.mit.edu/projects/distributed-learning-and-collaborative-learning-1/overview/", "isFamilyFriendly": true, "displayUrl": "https://www.media.mit.edu/projects/distributed-<b>learning</b>-and-collaborative-<b>learning</b>-1/...", "snippet": "In terms of model performance, the accuracies of Split NN remained competitive to other distributed deep <b>learning</b> methods <b>like</b> <b>federated</b> <b>learning</b> and large batch synchronous SGD with a drastically smaller client side computational burden when <b>training</b> on a larger number of clients as shown below in terms of teraflops of computation and gigabytes of communication when split <b>learning</b> is used to train Resnet and VGG architectures over 100 and 500 clients with CIFAR 10 and CIFAR 100 datasets.", "dateLastCrawled": "2022-01-29T20:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Chained <b>Anomaly Detection Models for Federated Learning</b>: An ...", "url": "https://www.researchgate.net/publication/329758083_Chained_Anomaly_Detection_Models_for_Federated_Learning_An_Intrusion_Detection_Case_Study", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/329758083_Chained_Anomaly_Detection_<b>Models</b>...", "snippet": "By integrating <b>federated</b> <b>learning</b> with blockchain technology, our solution supports the auditing of machine <b>learning</b> <b>models</b> without the necessity to centralize the <b>training</b> data. Experiments with ...", "dateLastCrawled": "2022-01-21T03:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Federated</b> <b>learning</b> in medicine: facilitating multi-institutional ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7387485/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7387485", "snippet": "<b>Federated</b> <b>learning</b> (FL) 16 is a data-private collaborative <b>learning</b> method where <b>multiple</b> collaborators train a machine <b>learning</b> model at the same time (i.e., each on their own data, in parallel) and then send their model updates to a central server to be aggregated into a consensus model (Fig. 1 b). The aggregation server then sends the consensus model to all <b>collaborating</b> institutions for use and/or further <b>training</b>. Each iteration of this process, i.e., parallel <b>training</b>, update ...", "dateLastCrawled": "2022-01-26T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Federated</b> <b>learning</b> in medicine: facilitating multi-institutional ...", "url": "https://www.nature.com/articles/s41598-020-69250-1", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-020-69250-1", "snippet": "<b>Federated</b> <b>learning</b> (FL) 16 is a data-private collaborative <b>learning</b> method where <b>multiple</b> collaborators train a machine <b>learning</b> model at the same time (i.e., each on their own data, in parallel ...", "dateLastCrawled": "2022-01-29T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Top 10 Research Papers On <b>Federated</b> <b>Learning</b>", "url": "https://analyticsindiamag.com/top-10-research-papers-on-federated-learning/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/top-10-research-papers-on-<b>federated</b>-<b>learning</b>", "snippet": "Since the inception of <b>federated</b> <b>learning</b>, with a primary emphasis on mobile and edge devices, the researchers believe that interest in applying <b>federated</b> <b>learning</b> to other applications are increasing exponentially, including some which might involve a small number of relatively reliable clients. For example, <b>multiple</b> organisations <b>collaborating</b> to train a model; the researchers call these two <b>federated</b> <b>learning</b> environments \u2018cross-device\u2019 and \u2018cross-silo,\u2019 respectively.", "dateLastCrawled": "2022-01-30T13:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "QuantumFed: A <b>Federated</b> <b>Learning</b> Framework for Collaborative Quantum ...", "url": "https://www.cs.wm.edu/~liqun/paper/globecom21-2.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.wm.edu/~liqun/paper/globecom21-2.pdf", "snippet": "<b>learning</b> [2], [9], [17], [18], [22]. In deep neural network model <b>training</b>, sometimes it is necessary to train a model through <b>multiple</b> machines in a distributed manner, e.g., <b>federated</b> <b>learning</b> [12], [16]. <b>Fed-erated</b> <b>learning</b> is a collaborative way to train a global model where each node has their private local data in classic machine <b>learning</b> ...", "dateLastCrawled": "2022-01-28T12:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "1 Introduction \u2013 <b>Federated</b> <b>Learning</b> \u2013 Dev Guis", "url": "http://devguis.com/1-introduction-federated-learning.html", "isFamilyFriendly": true, "displayUrl": "devguis.com/1-introduction-<b>federated</b>-<b>learning</b>.html", "snippet": "How to enable the updating and sharing of <b>models</b> among the <b>multiple</b> sites in a secure and yet efficient way is a new challenge to the current computing methodologies. 1.2 <b>FEDERATED</b> <b>LEARNING</b> AS A SOLUTION . As mentioned previously, <b>multiple</b> reasons make the problem of data silos become impediment to the big data needed to train ML <b>models</b>. It is thus natural to seek solutions to build ML <b>models</b> that do not rely on collecting all data to a centralized storage where model <b>training</b> can happen. An ...", "dateLastCrawled": "2022-01-02T23:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Overview \u2039 <b>Split Learning: Distributed and collaborative learning</b> \u2014 MIT ...", "url": "https://www.media.mit.edu/projects/distributed-learning-and-collaborative-learning-1/overview/", "isFamilyFriendly": true, "displayUrl": "https://www.media.mit.edu/projects/distributed-<b>learning</b>-and-collaborative-<b>learning</b>-1/...", "snippet": "In terms of model performance, the accuracies of Split NN remained competitive to other distributed deep <b>learning</b> methods like <b>federated</b> <b>learning</b> and large batch synchronous SGD with a drastically smaller client side computational burden when <b>training</b> on a larger number of clients as shown below in terms of teraflops of computation and gigabytes of communication when split <b>learning</b> is used to train Resnet and VGG architectures over 100 and 500 clients with CIFAR 10 and CIFAR 100 datasets.", "dateLastCrawled": "2022-01-29T20:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Building Robust and Private <b>Federated</b> Deep <b>Learning</b> | by Feroz Ahmad ...", "url": "https://fz-29.medium.com/building-robust-and-private-federated-deep-learning-7fa08ca98c68", "isFamilyFriendly": true, "displayUrl": "https://fz-29.medium.com/building-robust-and-private-<b>federated</b>-deep-<b>learning</b>-7fa08ca98c68", "snippet": "What is <b>Federated</b> <b>Learning</b> trying to solve? The power of Deep <b>Learning</b> resides in the richness and precision of data we use to train the deep networks. Certainly, now we are at a stage where we have more data than the compute power to utilize the data. Hence, we have come up with strategies where we try to leverage several compute instances in order to learn a model collectively from a larger amount of datasets. ...", "dateLastCrawled": "2022-01-18T17:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Making Radiology AI <b>Models</b> more robust: <b>Federated</b> <b>Learning</b> and other", "url": "https://www.slideshare.net/imgcommcall/making-radiology-ai-models-more-robust-federated-learning-and-other-approaches", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/imgcommcall/making-radiology-ai-<b>models</b>-more-robust...", "snippet": "\u2013 Restrictions on amount of time data are available \u2013 Assurances about data composition, quality, provenance \u2022 Participation in evaluation/refinement of trained <b>models</b> \u2013 Value added by evaluation in real world data \u2013 Value added by participating in re\u2010<b>training</b> The future: A collaborative AI ecosystem \u2022 Each site specifies a dataset they wish to make available for building AI \u2022 \u201cPop\u2010up\u201d collaborations to build AI <b>models</b> using <b>federated</b> <b>learning</b> \u2022 Full control over data ...", "dateLastCrawled": "2022-01-24T00:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Privacy Preserving Vertical Federated Learning for</b> Tree-based <b>Models</b>", "url": "https://www.researchgate.net/publication/343689524_Privacy_Preserving_Vertical_Federated_Learning_for_Tree-based_Models", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343689524_Privacy_Preserving_Vertical...", "snippet": "<b>Federated</b> <b>learning</b> (FL) is an emerging paradigm that enables <b>multiple</b> organizations to jointly train a model without revealing their private data to each other. This paper studies {\\it vertical ...", "dateLastCrawled": "2021-10-21T16:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Training</b> a <b>machine learning model</b> with secure collaborations - Ericsson", "url": "https://www.ericsson.com/en/blog/2020/2/training-a-machine-learning-model", "isFamilyFriendly": true, "displayUrl": "https://www.ericsson.com/en/blog/2020/2/<b>training</b>-a-<b>machine-learning-model</b>", "snippet": "Secure collaborative <b>learning</b> mitigates these problems by building <b>models</b> using data from <b>multiple</b> operators, while keeping that data secure and separate. In this scenario, each operator\u2019s data resides in its own heterogeneous environment. Secure collaborative <b>learning</b> enables <b>training</b> across these operators by only allowing each operator to compute updates on its local data using a shared global model. Ericsson then acts as an aggregator that collects and combines each operator\u2019s local ...", "dateLastCrawled": "2021-12-24T11:58:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "FedComm: <b>Federated</b> <b>Learning</b> as a Medium for Covert Communication | DeepAI", "url": "https://deepai.org/publication/fedcomm-federated-learning-as-a-medium-for-covert-communication", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/fedcomm-<b>federated</b>-<b>learning</b>-as-a-medium-for-covert...", "snippet": "FedComm: <b>Federated</b> <b>Learning</b> as a Medium for Covert Communication. Proposed as a solution to mitigate the privacy implications related to the adoption of deep <b>learning</b> solutions, <b>Federated</b> <b>Learning</b> (FL) enables large numbers of participants to successfully train deep neural networks without having to reveal the actual private <b>training</b> data.", "dateLastCrawled": "2022-01-24T23:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "How TripleBlind Compares To <b>Federated</b> <b>Learning</b> - TripleBlind", "url": "https://tripleblind.ai/how-tripleblind-compares-to-federated-learning/", "isFamilyFriendly": true, "displayUrl": "https://tripleblind.ai/how-tripleblind-compares-to-<b>federated</b>-<b>learning</b>", "snippet": "<b>Federated</b> <b>Learning</b> is a <b>learning</b> paradigm that allows <b>multiple</b> parties to collectively train a global model using their decentralized data without the need to centrally store it; and, thus, without the need to transmit it outside the owner\u2019s infrastructure. Google coined the term <b>Federated</b> <b>Learning</b> in 2016, and the company has since been at the forefront of AI <b>training</b> through this method. From a high level of abstraction, <b>Federated</b> <b>Learning</b> goes through the following steps: A central ...", "dateLastCrawled": "2022-01-26T00:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Friendly <b>federated</b> <b>learning</b> \ud83c\udf3c with Daniel Beutel, one of the creators ...", "url": "https://changelog.com/practicalai/160", "isFamilyFriendly": true, "displayUrl": "https://changelog.com/practicalai/160", "snippet": "So <b>federated</b> <b>learning</b> is a way to train <b>models</b> across <b>multiple</b> data sets. That\u2019s the very easy take on it. So you might be wondering, how does this work? The way you do it in <b>federated</b> <b>learning</b> - and let\u2019s just start off by giving an example\u2026 Let\u2019s say we have, for example, a group of hospitals, they have some in-house data, but due to regulations, they cannot share this data, and they cannot put this data in the cloud, and they <b>can</b>\u2019t use the usual machine <b>learning</b> workflow where ...", "dateLastCrawled": "2022-01-29T14:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "FedGraphNN: A <b>Federated Learning</b> System and Benchmark for Graph Neural ...", "url": "https://deepai.org/publication/fedgraphnn-a-federated-learning-system-and-benchmark-for-graph-neural-networks", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/fedgraphnn-a-<b>federated-learning</b>-system-and-benchmark...", "snippet": "To address these issues, we present an open-source <b>federated learning</b> system for GNNs, namely . FedGraphNN, that enables the <b>training</b> of a variety of GNN <b>models</b> effectively and efficiently in a <b>federated</b> setting as well as benchmarks in non-I.I.D. graph datasets (e.g., molecular graphs).We first formulate <b>federated</b> graph neural networks to provide a unified framework for <b>federated</b> GNNs (Section 3).Under this formulation, we design a <b>federated learning</b> system to support <b>federated</b> GNNs with a ...", "dateLastCrawled": "2022-01-25T15:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How <b>Could Federated Learning Transform Healthcare</b>?", "url": "https://industrywired.com/how-could-federated-learning-transform-healthcare/", "isFamilyFriendly": true, "displayUrl": "https://industrywired.com/how-<b>could-federated-learning-transform-healthcare</b>", "snippet": "The healthcare industry is the most crucial industry that relies entirely on vast sets of data to deliver quality healthcare. This healthcare data is quite valuable and vulnerable as well to data theft. Machine <b>learning</b> <b>models</b> promise the security of patient data, but the traditional ML techniques <b>can</b> pose a risk to patient data privacy. This is where <b>federated</b> <b>learning</b> comes in, bringing ML <b>models</b> to the data source, instead of bringing the data to the model. It ensures the security of user ...", "dateLastCrawled": "2022-01-16T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Federated</b> <b>learning</b> under arbitrary communication patterns - Amazon Science", "url": "https://www.amazon.science/publications/federated-learning-under-arbitrary-communication-patterns", "isFamilyFriendly": true, "displayUrl": "https://www.amazon.science/publications/<b>federated</b>-<b>learning</b>-under-arbitrary...", "snippet": "<b>Federated</b> <b>Learning</b> is a distributed <b>learning</b> setting where the goal is to train a centralized model with <b>training</b> data distributed over a large number of heterogeneous clients, each with unreliable and relatively slow network connections. A common optimization approach used in <b>federated</b> <b>learning</b> is based on the idea of local SGD: each client runs some number of SGD steps locally and then the updated local <b>models</b> are averaged to form the updated global model on the coordinating server. In ...", "dateLastCrawled": "2022-02-02T23:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Self-Balancing Federated Learning With Global Imbalanced</b> Data in ...", "url": "https://www.researchgate.net/publication/342969773_Self-Balancing_Federated_Learning_With_Global_Imbalanced_Data_in_Mobile_Systems", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342969773_Self-Balancing_<b>Federated</b>_<b>Learning</b>...", "snippet": "<b>Federated</b> <b>learning</b> (FL) is a distributed deep <b>learning</b> method that enables <b>multiple</b> participants, such as mobile and IoT devices, to contribute a neural network while their private <b>training</b> data ...", "dateLastCrawled": "2022-01-27T10:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) The FeatureCloud AI Store for <b>Federated</b> <b>Learning</b> in Biomedicine ...", "url": "https://www.researchgate.net/publication/351536700_The_FeatureCloud_AI_Store_for_Federated_Learning_in_Biomedicine_and_Beyond", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/351536700_The_FeatureCloud_AI_Store_for...", "snippet": "Performance evaluation of <b>federated</b> AI methods. The boxplots show the results of a 10-fold CV for the different classification and regression <b>models</b> and datasets in <b>multiple</b> settings.", "dateLastCrawled": "2021-10-04T19:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Building Secure Aggregation into TensorFlow <b>Federated</b> | by Jason ...", "url": "https://medium.com/dropoutlabs/building-secure-aggregation-into-tensorflow-federated-4514fca40cc0", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dropoutlabs/building-secure-aggregation-into-tensorflow-<b>federated</b>...", "snippet": "While it\u2019s not a feature complete framework for production-level <b>federated</b> <b>learning</b>, it is extremely thoughtful in the way it <b>models</b> <b>federated</b> computations in the <b>Federated</b> Core language. The ...", "dateLastCrawled": "2022-01-23T00:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Knowledge Management</b>: in-Depth Guide [2022 update]", "url": "https://research.aimultiple.com/knowledge-management/", "isFamilyFriendly": true, "displayUrl": "https://research.ai<b>multiple</b>.com/<b>knowledge-management</b>", "snippet": "By <b>collaborating</b> with these end users to develop the knowledge-capture process, organizations <b>can</b> achieve better results than with a generic <b>knowledge management</b> procedure ; Technology: Having the right tools <b>can</b> be extremely advantageous when it comes to day-to-day practical applications and uses; Understanding and considering these enablers from the beginning <b>can</b> help an organization to ensure they stay on track to effective <b>knowledge management</b> practices. Implementing a reward system may ...", "dateLastCrawled": "2022-01-27T06:36:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Federated</b> <b>learning</b> in medicine: facilitating multi-institutional ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7387485/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7387485", "snippet": "<b>Federated</b> <b>learning</b> (FL) 16 is a data-private collaborative <b>learning</b> method where <b>multiple</b> collaborators train a machine <b>learning</b> model at the same time (i.e., each on their own data, in parallel) and then send their model updates to a central server to be aggregated into a consensus model (Fig. 1 b). The aggregation server then sends the consensus model to all <b>collaborating</b> institutions for use and/or further <b>training</b>. Each iteration of this process, i.e., parallel <b>training</b>, update ...", "dateLastCrawled": "2022-01-26T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Federated</b> <b>learning</b> in medicine: facilitating multi-institutional ...", "url": "https://www.nature.com/articles/s41598-020-69250-1", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-020-69250-1", "snippet": "<b>Federated</b> <b>learning</b> (FL) 16 is a data-private collaborative <b>learning</b> method where <b>multiple</b> collaborators train a machine <b>learning</b> model at the same time (i.e., each on their own data, in parallel ...", "dateLastCrawled": "2022-01-29T16:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>How Federated Learning Can Solve Security and Data Privacy Challenges</b>", "url": "https://www.digitalcreed.in/federated-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.digitalcreed.in/<b>federated</b>-<b>learning</b>", "snippet": "The study demonstrated that the <b>federated</b> <b>learning</b> method could train a deep <b>learning</b> model, with 99% accuracy of the same model trained with the traditional non-private method. The combined research also showed that institutions did on average 17% better when trained in the federation, <b>compared</b> to <b>training</b> with their own validation data (2.6%).", "dateLastCrawled": "2022-01-20T09:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Federated learning</b>: Why and how to get started? | by Jean-Christophe ...", "url": "https://medium.com/digital-catapult/federated-learning-why-and-how-to-get-started-811d7bdb468f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/digital-catapult/<b>federated-learning</b>-why-and-how-to-get-started-811d...", "snippet": "<b>Federated learning</b> <b>can</b> provide a solution to limit the volume of data transfer needed while allowing for real-time, continuous improvement for these applications, <b>compared</b> to classic centralised ...", "dateLastCrawled": "2022-01-13T06:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Top 10 Research Papers On <b>Federated</b> <b>Learning</b>", "url": "https://analyticsindiamag.com/top-10-research-papers-on-federated-learning/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/top-10-research-papers-on-<b>federated</b>-<b>learning</b>", "snippet": "Since the inception of <b>federated</b> <b>learning</b>, with a primary emphasis on mobile and edge devices, the researchers believe that interest in applying <b>federated</b> <b>learning</b> to other applications are increasing exponentially, including some which might involve a small number of relatively reliable clients. For example, <b>multiple</b> organisations <b>collaborating</b> to train a model; the researchers call these two <b>federated</b> <b>learning</b> environments \u2018cross-device\u2019 and \u2018cross-silo,\u2019 respectively.", "dateLastCrawled": "2022-01-30T13:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Federated Learning</b> - ResearchGate", "url": "https://www.researchgate.net/publication/338061081_Federated_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/338061081_<b>Federated_Learning</b>", "snippet": "<b>Federated Learning</b> (FL) enables <b>multiple</b> participants to collaboratively train AI <b>models</b> in a privacy-preserving manner, which incurs cost during the <b>training</b> processing. This <b>can</b> be a significant ...", "dateLastCrawled": "2021-11-12T07:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "FSL: <b>Federated</b> Supermask <b>Learning</b> | DeepAI", "url": "https://deepai.org/publication/fsl-federated-supermask-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/fsl-<b>federated</b>-supermask-<b>learning</b>", "snippet": "<b>Federated</b> <b>Learning</b> (FL) is an emerging AI technology, where mutually untrusted clients (e.g., Android devices) collaborate to train a shared model, called the global model, without explicitly sharing their local <b>training</b> data.FL <b>training</b> involves a server (e.g., Google) which collects model updates from selected FL clients in each round of <b>training</b>, and uses them to update the global model. FL, although highly promising, faces <b>multiple</b> challenges (kairouz2019advances; li2020federated) to its ...", "dateLastCrawled": "2022-01-19T03:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) <b>Federated</b> <b>learning</b> in medicine: facilitating multi-institutional ...", "url": "https://www.researchgate.net/publication/343262424_Federated_learning_in_medicine_facilitating_multi-institutional_collaborations_without_sharing_patient_data", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/343262424_<b>Federated</b>_<b>learning</b>_in_medicine...", "snippet": "<b>Federated</b> <b>learning</b> is a novel paradigm for data-private multi-institutional collaborations, where model-<b>learning</b> leverages all available data without sharing data between institutions, by ...", "dateLastCrawled": "2021-12-11T15:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "[PDF] <b>Federated Multi-Task Learning</b> | Semantic Scholar", "url": "https://www.semanticscholar.org/paper/Federated-Multi-Task-Learning-Smith-Chiang/276194e96ebd620b5cff35a9168bdda39a0be57b", "isFamilyFriendly": true, "displayUrl": "https://www.semanticscholar.org/paper/<b>Federated-Multi-Task-Learning</b>-Smith-Chiang/...", "snippet": "<b>Federated</b> <b>learning</b> poses new statistical and systems challenges in <b>training</b> machine <b>learning</b> <b>models</b> over distributed networks of devices. [...] Key Method Our method and theory for the first time consider issues of high communication cost, stragglers, and fault tolerance for distributed multi-task <b>learning</b>. The resulting method achieves significant speedups <b>compared</b> to alternatives in the <b>federated</b> setting, as we demonstrate through simulations on real-world <b>federated</b> datasets.", "dateLastCrawled": "2022-01-29T18:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Making Radiology AI <b>Models</b> more robust: <b>Federated</b> <b>Learning</b> and other", "url": "https://www.slideshare.net/imgcommcall/making-radiology-ai-models-more-robust-federated-learning-and-other-approaches", "isFamilyFriendly": true, "displayUrl": "https://www.slideshare.net/imgcommcall/making-radiology-ai-<b>models</b>-more-robust...", "snippet": "\u2013 Restrictions on amount of time data are available \u2013 Assurances about data composition, quality, provenance \u2022 Participation in evaluation/refinement of trained <b>models</b> \u2013 Value added by evaluation in real world data \u2013 Value added by participating in re\u2010<b>training</b> The future: A collaborative AI ecosystem \u2022 Each site specifies a dataset they wish to make available for building AI \u2022 \u201cPop\u2010up\u201d collaborations to build AI <b>models</b> using <b>federated</b> <b>learning</b> \u2022 Full control over data ...", "dateLastCrawled": "2022-01-24T00:26:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A brief introduction to <b>Federated</b> <b>Learning</b> \u2014 FL Series Part 1 | by OPEN ...", "url": "https://openzone.medium.com/a-brief-introduction-to-federated-learning-fl-series-part-1-b81c6ec15fb8", "isFamilyFriendly": true, "displayUrl": "https://openzone.medium.com/a-brief-introduction-to-<b>federated</b>-<b>learning</b>-fl-series-part...", "snippet": "<b>Federated</b> <b>learning</b> was first introduced by Google in 2017 (1) to improve text prediction in mobile keyboard using <b>machine</b> <b>learning</b> models trained by data across multiple devices. The new technology branch of <b>machine</b> <b>learning</b> has been sought-after ever since because it doesn\u2019t require uploading personal data to a central server to train the models, which was a breakthrough in traditional <b>machine</b> <b>learning</b> to address data privacy issues.", "dateLastCrawled": "2022-01-24T01:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "[2107.03770] <b>Federated</b> <b>Learning</b> as a Mean-Field Game", "url": "https://arxiv.org/abs/2107.03770", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2107.03770", "snippet": "Abstract: We establish a connection between <b>federated</b> <b>learning</b>, a concept from <b>machine</b> <b>learning</b>, and mean-field games, a concept from game theory and control theory. In this <b>analogy</b>, the local <b>federated</b> learners are considered as the players and the aggregation of the gradients in a central server is the mean-field effect. We present <b>federated</b> <b>learning</b> as a differential game and discuss the properties of the equilibrium of this game. We hope this novel view to <b>federated</b> <b>learning</b> brings ...", "dateLastCrawled": "2021-08-31T21:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Why Is <b>Federated</b> <b>Learning</b> Getting So Popular", "url": "https://analyticsindiamag.com/why-federated-learning-getting-so-popular/", "isFamilyFriendly": true, "displayUrl": "https://analyticsindiamag.com/why-<b>federated</b>-<b>learning</b>-getting-so-popular", "snippet": "<b>Federated</b> <b>Learning</b> leverages techniques from multiple research areas such as distributed systems, <b>machine</b> <b>learning</b>, and privacy. FL is best applied in situations where the on-device data is more relevant than the data that exists on servers. However, FLS faces various challenges such as effectiveness, efficiency, and privacy. FL enables multiple parties to jointly train a <b>machine</b> <b>learning</b> model without exchanging the local data. According to", "dateLastCrawled": "2022-01-29T22:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Federated</b> <b>Learning</b> as a Mean-Field Game | DeepAI", "url": "https://deepai.org/publication/federated-learning-as-a-mean-field-game", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>federated</b>-<b>learning</b>-as-a-mean-field-game", "snippet": "We establish a connection between <b>federated</b> <b>learning</b>, a concept from <b>machine</b> <b>learning</b>, and mean-field games, a concept from game theory and control theory. In this <b>analogy</b>, the local <b>federated</b> learners are considered as the players and the aggregation of the gradients in a central server is the mean-field effect. We present <b>federated</b> <b>learning</b> as a differential game and discuss the properties of the equilibrium of this game. We hope this novel view to <b>federated</b> <b>learning</b> brings together ...", "dateLastCrawled": "2022-01-28T18:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How will <b>federated</b> <b>learning</b> influence your everyday life? | by ...", "url": "https://medium.com/cybervein/how-will-federal-learning-influence-your-everyday-life-271250697378", "isFamilyFriendly": true, "displayUrl": "https://medium.com/cybervein/how-will-federal-<b>learning</b>-influence-your-everyday-life...", "snippet": "<b>Federated</b> <b>learning</b> is a type of distributed <b>learning</b> method that has the same modeling effect as traditional ML algorithms. However, rather than centralizing all the raw data like traditional ML ...", "dateLastCrawled": "2022-01-24T20:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "terminology - <b>What is Federated Learning</b>? - Artificial Intelligence ...", "url": "https://ai.stackexchange.com/questions/26421/what-is-federated-learning", "isFamilyFriendly": true, "displayUrl": "https://ai.stackexchange.com/questions/26421/<b>what-is-federated-learning</b>", "snippet": "The <b>analogy</b> is to a federal system of government. In a federation, smaller pieces follow the direction of a higher piece. In <b>federated</b> <b>machine</b> <b>learning</b>, you give your data for processing to the higher <b>machine</b>. The federation in this <b>analogy</b> is a collection of smaller computers. The central computer breaks up your data and gives portions of it to each smaller computer. When those computers are done they return the results and the central computer reassembles them into a single model. The main ...", "dateLastCrawled": "2022-01-26T03:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Privacy and Machine Learning</b>. In today\u2019s world of technology, it can ...", "url": "https://medium.com/dotstar/privacy-and-machine-learning-a0effbbdc658", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dotstar/<b>privacy-and-machine-learning</b>-a0effbbdc658", "snippet": "<b>Federated</b> <b>Learning</b>. In <b>analogy</b>, FL is like ordering dinner instead going to the restaurant yourself (what?). So, for example , if Alice refuses to send her data to train Bob\u2019s model on a sitting ...", "dateLastCrawled": "2021-08-14T18:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Fair Resource Allocation in <b>Federated</b> <b>Learning</b>", "url": "https://research.fb.com/wp-content/uploads/2020/02/Fair-Resource-Allocation-in-Federated-Learning.pdf", "isFamilyFriendly": true, "displayUrl": "https://research.fb.com/.../2020/02/Fair-Resource-Allocation-in-<b>Federated</b>-<b>Learning</b>.pdf", "snippet": "To draw an <b>analogy</b> between <b>federated</b> <b>learning</b> and the problem of resource allocation, one can think of the global model as a resource that is meant to serve the users (or devices). In this sense, it is natural to ask similar questions about the fairness of the service that users receive and use similar tools to promote fairness. Despite this, we are unaware of any works that use -fairness from resource allocation to modify objectives in <b>machine</b> <b>learning</b>. Inspired by the -fairness metric, we ...", "dateLastCrawled": "2021-12-08T04:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Federated</b> <b>Learning</b> Game Theory", "url": "https://www.learning-study.info/federated-learning-game-theory/", "isFamilyFriendly": true, "displayUrl": "https://www.<b>learning</b>-study.info/<b>federated</b>-<b>learning</b>-game-theory", "snippet": "(8 days ago) <b>Federated</b> <b>Learning</b> (FL) is a distributed <b>learning</b> framework that can deal with the distributed issue in <b>machine</b> <b>learning</b> and still guarantee high <b>learning</b> performance. However, it is impractical that all users will sacrifice their resources to join the FL algorithm. This motivates us to study the incentive mechanism design for FL.", "dateLastCrawled": "2022-01-27T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Non-iid <b>learning</b>: Continual <b>Learning</b> and <b>Federated</b> <b>Learning</b>", "url": "https://www.researchgate.net/post/Non-iid_learning_Continual_Learning_and_Federated_Learning", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/Non-iid_<b>learning</b>_Continual_<b>Learning</b>_and_<b>Federated</b>...", "snippet": "<b>Federated</b> <b>learning</b> is when the dataset is distributed in a non-iid manner over space ... There is an <b>analogy</b> between <b>machine</b> <b>learning</b> systems and economic entities in that they are both adaptive ...", "dateLastCrawled": "2021-12-26T05:21:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A survey on <b>federated learning</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0950705121000381", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0950705121000381", "snippet": "<b>Federated learning is similar</b> to multi-party computing and distributed <b>machine</b> <b>learning</b>. There are many types of distributed <b>machine</b> <b>learning</b>, including distributed publishing model results, distributed storage training data, and distributed computing tasks. The parameter server in distributed <b>machine</b> <b>learning</b> is one of the tools to accelerate the training speed of <b>machine</b> <b>learning</b> models. It stores data on different working nodes in a distributed manner and allocates resources through a ...", "dateLastCrawled": "2022-01-28T21:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Federated <b>Learning</b>: A Distributed Shared <b>Machine</b> <b>Learning</b> Method", "url": "https://www.hindawi.com/journals/complexity/2021/8261663/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/complexity/2021/8261663", "snippet": "Federated <b>learning</b> (FL) is a distributed <b>machine</b> <b>learning</b> (ML) framework. In FL, multiple clients collaborate to solve traditional distributed ML problems under the coordination of the central server without sharing their local private data with others. This paper mainly sorts out FLs based on <b>machine</b> <b>learning</b> and deep <b>learning</b>. First of all, this paper introduces the development process, definition, architecture, and classification of FL and explains the concept of FL by comparing it with ...", "dateLastCrawled": "2022-02-03T01:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A novel federated <b>learning</b> approach based on the confidence of ...", "url": "https://link.springer.com/article/10.1007%2Fs13042-021-01410-9", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13042-021-01410-9", "snippet": "<b>Federated learning is similar</b> to but not equal to federated Kalman filtering, so it is impossible to obtain federated filtering gains according to variance as the FKF generally does. Therefore, this paper chooses cross-entropy loss, which has been proven to be excellent in <b>machine</b> <b>learning</b> and deep <b>learning</b> algorithms, instead of variance. The traditional FKF allocates the total variance \\({P}_{f}\\) of the system noise in the main filter and partial filters through the allocation factor and ...", "dateLastCrawled": "2022-01-29T03:06:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Performance Analysis of Distributed and Federated Learning Models</b> on ...", "url": "https://www.sciencedirect.com/science/article/pii/S1877050920300478", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050920300478", "snippet": "The initial implementation of <b>federated learning is similar</b> to the distributed <b>machine</b> <b>learning</b> classifier. However, there are two major differences, which are as follows: First, we use the federated-average-optimizer, an API using which we optimize the federated averaging process. Second, we use a variable called interval-steps. This variable keeps a count of the pre-defined number of steps after which the workers have to update their weights in the parameter server so that the chief worker ...", "dateLastCrawled": "2022-01-14T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Federated <b>Learning</b>: A Distributed Shared <b>Machine</b> <b>Learning</b> Method", "url": "https://www.researchgate.net/publication/354244192_Federated_Learning_A_Distributed_Shared_Machine_Learning_Method", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/354244192_Federated_<b>Learning</b>_A_Distributed...", "snippet": "Federated <b>learning</b> (FL) is a distributed <b>machine</b> <b>learning</b> (ML) framework. In FL, multiple clients collaborate to solve traditional distributed ML problems under the coordination of the central ...", "dateLastCrawled": "2021-11-08T23:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "A <b>Privacy</b>-Protection Model for Patients - <b>Hindawi</b>", "url": "https://www.hindawi.com/journals/scn/2020/6647562/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/scn/2020/6647562", "snippet": "Vertical <b>federated learning is similar</b> to horizontal federated <b>learning</b>, but is different in data feature extraction, where vertical federated <b>learning</b> extracts data of the same user in different dimensions. For example, two organizations with different businesses conduct data analysis on users in the same area, which can analyse the characteristic values of the same users to achieve better data results. (3) Federated Transfer <b>Learning</b>. When the user characteristics and samples overlap in ...", "dateLastCrawled": "2022-01-26T22:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "From <b>federated learning</b> to federated neural architecture search: a ...", "url": "https://link.springer.com/article/10.1007/s40747-020-00247-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s40747-020-00247-z", "snippet": "<b>Federated learning</b> is a recently proposed distributed <b>machine</b> <b>learning</b> paradigm for privacy preservation, which has found a wide range of applications where data privacy is of primary concern. Meanwhile, neural architecture search has become very popular in deep <b>learning</b> for automatically tuning the architecture and hyperparameters of deep neural networks. While both <b>federated learning</b> and neural architecture search are faced with many open challenges, searching for optimized neural ...", "dateLastCrawled": "2022-02-02T17:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Private <b>federated learning on vertically partitioned</b> data via entity ...", "url": "https://www.researchgate.net/publication/321374782_Private_federated_learning_on_vertically_partitioned_data_via_entity_resolution_and_additively_homomorphic_encryption", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321374782_Private_federated_<b>learning</b>_on...", "snippet": "The main idea of federated <b>learning</b> is to perform an on-device collaborative training of a single <b>machine</b> <b>learning</b> model without having to share the raw training data with any third-party entity ...", "dateLastCrawled": "2022-01-25T03:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Assisted <b>Learning</b>: A Framework for Multi-Organization <b>Learning</b>", "url": "https://proceedings.neurips.cc/paper/2020/file/a7b23e6eefbe6cf04b8e62a6f0915550-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2020/file/a7b23e6eefbe6cf04b8e62a6f0915550-Paper.pdf", "snippet": "clients hold different features over the same group of subjects) in vertical <b>Federated Learning is similar</b> to that in Assisted <b>Learning</b>. Nevertheless, these two types of <b>learning</b> are fundamentally different. Conceptually, the objective of Federated <b>Learning</b> is to exploit resources of massive edge devices for achieving a global objective. At the same time, the general goal of Assisted <b>Learning</b> is to facilitate multiple participants (possibly with rich resources) to autonomously assist each ...", "dateLastCrawled": "2021-11-02T00:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Why the Future of AI is Federated | Richard Cornelius Suwandi", "url": "https://richardcsuwandi.github.io/post/federated-learning/", "isFamilyFriendly": true, "displayUrl": "https://richardcsuwandi.github.io/post/federated-<b>learning</b>", "snippet": "Thus, <b>federated learning can be thought of as</b> a new approach to <b>machine</b> <b>learning</b> that allows you to train models across devices without pooling the data. Instead of bringing users&#39; data to the server, federated <b>learning</b> brings the <b>machine</b> <b>learning</b> model to the users&#39; devices.", "dateLastCrawled": "2022-01-26T23:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Posts on Richard Cornelius Suwandi", "url": "https://richardcsuwandi.github.io/post/index.xml", "isFamilyFriendly": true, "displayUrl": "https://richardcsuwandi.github.io/post/index.xml", "snippet": "Thus, <b>federated learning can be thought of as</b> a new approach to <b>machine</b> <b>learning</b> that allows you to train models across devices without pooling the data. Instead of bringing users&#39; data to the server, federated <b>learning</b> brings the <b>machine</b> <b>learning</b> model to the users&#39; devices.", "dateLastCrawled": "2021-12-22T04:55:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(federated learning)  is like +(multiple training models collaborating)", "+(federated learning) is similar to +(multiple training models collaborating)", "+(federated learning) can be thought of as +(multiple training models collaborating)", "+(federated learning) can be compared to +(multiple training models collaborating)", "machine learning +(federated learning AND analogy)", "machine learning +(\"federated learning is like\")", "machine learning +(\"federated learning is similar\")", "machine learning +(\"just as federated learning\")", "machine learning +(\"federated learning can be thought of as\")", "machine learning +(\"federated learning can be compared to\")"]}