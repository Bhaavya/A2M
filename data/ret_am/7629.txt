{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep Q-Learning Tutorial: minDQN</b>. A Practical Guide to <b>Deep</b> Q-Networks ...", "url": "https://towardsdatascience.com/deep-q-learning-tutorial-mindqn-2a4c855abffc", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>deep-q-learning-tutorial-mindqn</b>-2a4c855abffc", "snippet": "<b>Deep</b> Q-<b>Learning</b> <b>uses</b> Experience Replay to learn in small batches in order to avoid skewing the dataset distribution of different states, actions, rewards, and next_states that the neural network will see. Importantly, the agent doesn\u2019t need to train after each step. In our implementation, we use Experience Replay to train on small batches once every 4 steps rather than every single step. We found this trick to really help speed up our <b>Deep</b> Q-<b>Learning</b> implementation.", "dateLastCrawled": "2022-02-03T02:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Deep</b> <b>Q-network</b> - msg <b>Machine Learning Catalogue</b>", "url": "https://machinelearningcatalogue.com/algorithm/alg_deep-q-network.html", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearningcatalogue</b>.com/algorithm/alg_<b>deep</b>-<b>q-network</b>.html", "snippet": "A <b>deep</b> <b>Q-network</b> (<b>DQN</b>) is a neural network used to learn a Q-function. As most reinforcement <b>learning</b> is associated with complex (typically visual) inputs, the initial layers of a <b>DQN</b> are normally convolutional. There are two ways of using a neural network to calculate expected rewards for actions: the network accepts the environment state and a possible action as input and outputs the expected reward; the network accepts the environment state as input and outputs a vector of possible ...", "dateLastCrawled": "2022-01-11T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "[2008.04109] <b>Deep</b> <b>Q-Network</b> Based <b>Multi-agent</b> Reinforcement <b>Learning</b> ...", "url": "https://arxiv.org/abs/2008.04109", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2008.04109", "snippet": "<b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) based <b>multi-agent</b> systems (MAS) for reinforcement <b>learning</b> (RL) use various schemes where in the agents have to learn and communicate. The <b>learning</b> is however specific to each agent and communication may be satisfactorily designed for the agents. As more complex <b>Deep</b> QNetworks come to the fore, the overall complexity of the <b>multi-agent</b> <b>system</b> increases leading to issues <b>like</b> difficulty in training, need for higher resources and more training time, difficulty in fine ...", "dateLastCrawled": "2021-12-25T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine</b> <b>Learning</b> Models - Javatpoint", "url": "https://www.javatpoint.com/machine-learning-models", "isFamilyFriendly": true, "displayUrl": "https://www.javatpoint.com/<b>machine</b>-<b>learning</b>-models", "snippet": "<b>Deep</b> <b>Q Network</b>: <b>DQN</b> or <b>Deep</b> Q Neural network is Q-<b>learning</b> within the neural network. It is basically employed in a big state space environment where defining a Q-table would be a complex task. So, in such a case, rather than using Q-table, the neural network <b>uses</b> Q-values for each action based on the state. Training <b>Machine</b> <b>Learning</b> Models. Once the <b>Machine</b> <b>learning</b> model is built, it is trained in order to get the appropriate results. To train a <b>machine</b> <b>learning</b> model, one needs a huge ...", "dateLastCrawled": "2022-02-02T20:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "[2008.04109v1] <b>Deep</b> <b>Q-Network</b> <b>Based Multi-agent Reinforcement Learning</b> ...", "url": "https://arxiv.org/abs/2008.04109v1", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2008.04109v1", "snippet": "<b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) based multi-agent systems (MAS) for reinforcement <b>learning</b> (RL) use various schemes where in the agents have to learn and communicate. The <b>learning</b> is however specific to each agent and communication may be satisfactorily designed for the agents. As more complex <b>Deep</b> QNetworks come to the fore, the overall complexity of the multi-agent <b>system</b> increases leading to issues <b>like</b> difficulty in training, need for higher resources and more training time, difficulty in fine ...", "dateLastCrawled": "2021-05-26T20:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Advanced DQNs: Playing <b>Pac-man</b> with <b>Deep</b> Reinforcement <b>Learning</b> | by ...", "url": "https://towardsdatascience.com/advanced-dqns-playing-pac-man-with-deep-reinforcement-learning-3ffbd99e0814", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/advanced-<b>dqn</b>s-playing-<b>pac-man</b>-with-<b>deep</b>-reinforcement...", "snippet": "In 2013, DeepMind published the first version of its <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>), <b>a computer</b> program capabl e of human-level performance on a number of classic Atari 2600 games. Just <b>like</b> a human, the algorithm played based on its vision of the screen. Starting from scratch, it discovered gameplay strategies that let it meet (and in many cases, exceed) human benchmarks. In the years since, researchers have made a number of improvements that super-charge performance and solve games faster than ever ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Reinforcement <b>Learning</b> (<b>DQN</b>) Tutorial \u2014 <b>PyTorch</b> Tutorials 1.10.1+cu102 ...", "url": "https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html", "isFamilyFriendly": true, "displayUrl": "https://<b>pytorch</b>.org/tutorials/intermediate/reinforcement_q_<b>learning</b>.html", "snippet": "Reinforcement <b>Learning</b> (<b>DQN</b>) Tutorial\u00b6 Author: Adam Paszke. This tutorial shows how to use <b>PyTorch</b> to train a <b>Deep</b> Q <b>Learning</b> (<b>DQN</b>) agent on the CartPole-v0 task from the OpenAI Gym. Task. The agent has to decide between two actions - moving the cart left or right - so that the pole attached to it stays upright. You can find an official leaderboard with various algorithms and visualizations at the Gym website. cartpole. As the agent observes the current state of the environment and chooses ...", "dateLastCrawled": "2022-02-03T02:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Reinforcement Learning Real-world examples</b> - Data Analytics", "url": "https://vitalflux.com/reinforcement-learning-real-world-examples/", "isFamilyFriendly": true, "displayUrl": "https://vitalflux.com/<b>reinforcement-learning-real-world-examples</b>", "snippet": "Using reinforcement <b>learning</b>, researchers at MIT created an algorithm called <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) that mimics the behavior of animals playing Atari games. As it moves through an environment, the reinforcement <b>learning</b> agent collects data. It <b>uses</b> this reinforcement <b>learning</b> data to evaluate possible actions and their consequences in order to determine which action will likely maximize its expected return of rewards .", "dateLastCrawled": "2022-02-01T17:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Deep Q-Learning - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/deep-q-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/<b>deep</b>-q-<b>learning</b>", "snippet": "This approximation of values does not hurt as long as the relative importance is preserved. The basic working step for <b>Deep</b> Q-<b>Learning</b> is that the initial state is fed into the neural network and it returns the Q-value of all possible actions as on output. The difference between Q-<b>Learning</b> and <b>Deep</b> Q-<b>Learning</b> can be illustrated as follows:-.", "dateLastCrawled": "2022-02-03T18:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "In a <b>deep</b> <b>Q-network</b>, what are the advantages/disadvantages of ...", "url": "https://www.quora.com/In-a-deep-Q-network-what-are-the-advantages-disadvantages-of-enumerating-all-possible-action-states-even-if-actions-are-independent", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-a-<b>deep</b>-<b>Q-network</b>-what-are-the-advantages-disadvantages-of...", "snippet": "Answer (1 of 3): Q <b>learning</b> requires the creation of a two-dimensional array. The first dimension is the number of possible states, while the second dimension is the number of possible actions. Each state-action pair maintains a Q value, which is the expected discounted long-term reward for selec...", "dateLastCrawled": "2022-01-14T00:33:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep</b> <b>Q-network</b> - msg <b>Machine Learning Catalogue</b>", "url": "https://machinelearningcatalogue.com/algorithm/alg_deep-q-network.html", "isFamilyFriendly": true, "displayUrl": "https://<b>machinelearningcatalogue</b>.com/algorithm/alg_<b>deep</b>-<b>q-network</b>.html", "snippet": "A <b>deep</b> <b>Q-network</b> (<b>DQN</b>) is a neural network used to learn a Q-function. As most reinforcement <b>learning</b> is associated with complex (typically visual) inputs, the initial layers of a <b>DQN</b> are normally convolutional. There are two ways of using a neural network to calculate expected rewards for actions: the network accepts the environment state and a possible action as input and outputs the expected reward; the network accepts the environment state as input and outputs a vector of possible ...", "dateLastCrawled": "2022-01-11T08:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Optimising a Microgrid <b>System</b> by <b>Deep</b> Reinforcement <b>Learning</b> ... - MDPI", "url": "https://www.mdpi.com/1996-1073/13/11/2830/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/1996-1073/13/11/2830/htm", "snippet": "In this paper, a <b>Deep</b> <b>Learning</b> version of Q-<b>Learning</b> called <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) is used , with a configuration and architecture <b>similar</b> to . This method <b>uses</b> an ANN to approximate its value function, called Q-function. This method is model-free, i.e., the model does not use experiences to create an internal model to generate synthetic experiences and learn with, unlike model-based such as Dyna-Q", "dateLastCrawled": "2021-12-22T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Advanced DQNs: Playing <b>Pac-man</b> with <b>Deep</b> Reinforcement <b>Learning</b> | by ...", "url": "https://towardsdatascience.com/advanced-dqns-playing-pac-man-with-deep-reinforcement-learning-3ffbd99e0814", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/advanced-<b>dqn</b>s-playing-<b>pac-man</b>-with-<b>deep</b>-reinforcement...", "snippet": "In 2013, DeepMind published the first version of its <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>), a <b>computer</b> program capabl e of human-level performance on a number of classic Atari 2600 games. Just like a human, the algorithm played based on its vision of the screen. Starting from scratch, it discovered gameplay strategies that let it meet (and in many cases, exceed) human benchmarks. In the years since, researchers have made a number of improvements that super-charge performance and solve games faster than ever ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Minibatch Recursive Least Squares Q-<b>Learning</b>", "url": "https://www.hindawi.com/journals/cin/2021/5370281/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/cin/2021/5370281", "snippet": "The <b>deep</b> <b>Q-network</b> (<b>DQN</b>) is one of the most successful reinforcement <b>learning</b> algorithms, but it has some drawbacks such as slow convergence and instability. In contrast, the traditional reinforcement <b>learning</b> algorithms with linear function approximation usually have faster convergence and better stability, although they easily suffer from the curse of dimensionality. In recent years, many improvements to <b>DQN</b> have been made, but they seldom make use of the advantage of traditional ...", "dateLastCrawled": "2022-02-02T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Using <b>Deep</b> Q-<b>Learning to Control Optimization Hyperparameters</b>", "url": "https://www.researchgate.net/publication/301846248_Using_Deep_Q-Learning_to_Control_Optimization_Hyperparameters", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/301846248_Using_<b>Deep</b>_Q-<b>Learning</b>_to_Control...", "snippet": "Abstract. We present a novel definition of the reinforcement <b>learning</b> state, actions and reward function that allows a <b>deep</b> <b>Q-network</b> (<b>DQN</b>) to learn to control an optimization hyperparameter ...", "dateLastCrawled": "2022-01-17T10:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Recurrent <b>Reinforcement</b> <b>Learning</b>: A Hybrid Approach | DeepAI", "url": "https://deepai.org/publication/recurrent-reinforcement-learning-a-hybrid-approach", "isFamilyFriendly": true, "displayUrl": "https://<b>deep</b>ai.org/publication/recurrent-<b>reinforcement</b>-<b>learning</b>-a-hybrid-approach", "snippet": "Most prominent is the recent use of a <b>deep</b> <b>Q-network</b> (<b>DQN</b>) in Q-<b>learning</b> to solve a large number of Atari games (Mnih et al., 2015), although neural networks have been used in some of the classic RL applications like TD-Gammon (Tesauro, 1995). For partially observable environments, <b>deep</b> <b>learning</b> may also be used to represent and track hidden states, without much domain knowledge. For example, Deng et al. apply a <b>deep</b> network to track belief states in a spoken dialogue <b>system</b>. Examples in RL ...", "dateLastCrawled": "2022-01-30T04:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Deep</b> Reinforcement <b>Learning</b> for Crowdsourced Urban Delivery - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0191261521001636", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0191261521001636", "snippet": "We propose a new <b>deep</b> reinforcement <b>learning</b> (DRL)-based approach to tackling this assignment problem. A <b>deep</b> <b>Q network</b> (<b>DQN</b>) algorithm is trained which entails two salient features of experience replay and target network that enhance the efficiency, convergence, and stability of DRL training. More importantly, this paper makes three methodological contributions: 1) presenting a comprehensive and novel characterization of crowdshipping <b>system</b> states that encompasses spatial-temporal and ...", "dateLastCrawled": "2022-01-19T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is the difference between computing Q value of Q-<b>learning</b> and <b>deep</b> ...", "url": "https://www.quora.com/What-is-the-difference-between-computing-Q-value-of-Q-learning-and-deep-Q-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-computing-Q-value-of-Q-<b>learning</b>...", "snippet": "Answer: I will assume that by Q-<b>learning</b> you\u2019re using a table to store the Q values, so as you said the Q values is updated by: Q_new = (1-alpha) * Q(s,a)_old + alpha * (reward + gamma*max(Q(s+1,ai))) That\u2019s because you can directly modify the value of the Q value. In <b>Deep</b> Q-<b>learning</b> you have ...", "dateLastCrawled": "2021-12-31T18:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What&#39;s the difference between <b>reinforcement learning</b>, <b>deep</b> <b>learning</b> ...", "url": "https://stackoverflow.com/questions/50542818/whats-the-difference-between-reinforcement-learning-deep-learning-and-deep-re", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/50542818", "snippet": "<b>Deep</b> <b>learning</b> (DL) is considered crucial part of modern <b>machine</b> <b>learning</b> (classical <b>machine</b> <b>learning</b> usually mean SVM, liner regression etc.). DL <b>uses</b> <b>deep</b> multilayered neural networks (NN) with backpropagation for <b>learning</b>. By using well designed <b>deep</b> NN networks complex input-output relations can be learned. Because of this property of approximating very complex functions DL have been extremely popular in recent years (2010-ish), especially in natural language tasks and <b>computer</b> vision ...", "dateLastCrawled": "2022-01-26T01:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Deep</b> reinforcement <b>learning</b> for mobile 5g and beyond : fundamentals ...", "url": "https://dr.ntu.edu.sg/bitstream/10356/143868/2/Deep%20reinforcement%20learning%20for%20mobile%205G%20and%20beyond%20fundamentals%20applications%20and%20challenges.pdf", "isFamilyFriendly": true, "displayUrl": "https://dr.ntu.edu.sg/bitstream/10356/143868/2/<b>Deep</b> reinforcement <b>learning</b> for mobile...", "snippet": "by the success of <b>machine</b> <b>learning</b> in solving complicated control and decision-making problems, in this article, we focus on <b>deep</b> reinforcement <b>learning</b> based approaches, which allow network entities to learn and build knowledge about the networks to make optimal decisions locally and independently. We \ufb01rst present an overview and fundamental concepts of <b>deep</b> reinforcement <b>learning</b>. Next, we review some related works that capitalize <b>deep</b> reinforcement <b>learning</b> to address different issues ...", "dateLastCrawled": "2022-01-24T19:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep Q-Learning</b> | An <b>Introduction To Deep</b> Reinforcement <b>Learning</b>", "url": "https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2019/04/intro", "snippet": "The scope of <b>Deep</b> RL is IMMENSE. This is a great time to enter into this field and make a career out of it. In this article, I aim to help you take your first steps into the world of <b>deep</b> reinforcement <b>learning</b>. We\u2019ll use one of the most popular algorithms in RL, <b>deep Q-learning</b>, to understand how <b>deep</b> RL works.", "dateLastCrawled": "2022-02-03T02:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Advanced DQNs: Playing <b>Pac-man</b> with <b>Deep</b> Reinforcement <b>Learning</b> | by ...", "url": "https://towardsdatascience.com/advanced-dqns-playing-pac-man-with-deep-reinforcement-learning-3ffbd99e0814", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/advanced-<b>dqn</b>s-playing-<b>pac-man</b>-with-<b>deep</b>-reinforcement...", "snippet": "In 2013, DeepMind published the first version of its <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>), a <b>computer</b> program capabl e of human-level performance on a number of classic Atari 2600 games. Just like a human, the algorithm played based on its vision of the screen. Starting from scratch, it discovered gameplay strategies that let it meet (and in many cases, exceed) human benchmarks. In the years since, researchers have made a number of improvements that super-charge performance and solve games faster than ever ...", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Episodic Memory <b>and Deep Q-Networks - GeeksforGeeks</b>", "url": "https://www.geeksforgeeks.org/episodic-memory-and-deep-q-networks/", "isFamilyFriendly": true, "displayUrl": "https://www.geeksforgeeks.org/episodic-memory-and-<b>deep</b>-q-networks", "snippet": "<b>Deep</b> Q-Networks (<b>DQN</b>): A well-established technique to perform the above task is Q-<b>learning</b>, where we decide on a function called Q-function which is important for the success of the algorithm. <b>DQN</b> <b>uses</b> the neural networks as Q-function to approximate the action values Q(s, a, \\theta) where the parameter of network and (s,a) represents the state-action pair .", "dateLastCrawled": "2022-01-16T05:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Implementing the <b>Deep</b> <b>Q-Network</b> | Request PDF", "url": "https://www.researchgate.net/publication/321210388_Implementing_the_Deep_Q-Network", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/321210388_Implementing_the_<b>Deep</b>_<b>Q-Network</b>", "snippet": "This problem <b>can</b> be addressed by <b>deep</b> <b>Q-Network</b> (<b>DQN</b>) [12, 17] which is a networked Q-<b>learning</b> algorithm and a DRL technique that combines reinforcement <b>learning</b> with a class of artificial neural ...", "dateLastCrawled": "2022-01-28T01:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Deep</b> Recurrent Q-<b>Learning</b> vs <b>Deep</b> Q-<b>Learning</b> on a simple Partially ...", "url": "https://deepai.org/publication/deep-recurrent-q-learning-vs-deep-q-learning-on-a-simple-partially-observable-markov-decision-process-with-minecraft", "isFamilyFriendly": true, "displayUrl": "https://<b>deep</b>ai.org/publication/<b>deep</b>-recurrent-q-<b>learning</b>-vs-<b>deep</b>-q-<b>learning</b>-on-a...", "snippet": "03/11/19 - <b>Deep</b> Q-<b>Learning</b> has been successfully applied to a wide variety of tasks in the past several years. However, the architecture of t...", "dateLastCrawled": "2021-12-07T10:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Introduction to Deep Reinforcement Learning</b> \u2013 KejiTech", "url": "https://davideliu.com/2020/01/13/introduction-to-deep-reinforcement-learning/", "isFamilyFriendly": true, "displayUrl": "https://davideliu.com/2020/01/13/<b>introduction-to-deep-reinforcement-learning</b>", "snippet": "Thus, in <b>deep</b> reinforcement <b>learning</b>, we train a <b>deep</b> neural network, also known as <b>deep</b> <b>Q-network</b> (<b>DQN</b>) to learn an estimate of the Q-value Q(s,a,\u03b8) where \u03b8 are the parameters of the network. Its architecture is composed of a first convolutional network which takes as input a state S t and learns to detect increasingly abstract features from it.", "dateLastCrawled": "2022-01-30T00:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Intelligent fault diagnosis for rotating</b> machinery using <b>deep</b> <b>Q-network</b> ...", "url": "https://www.researchgate.net/publication/336186043_Intelligent_fault_diagnosis_for_rotating_machinery_using_deep_Q-network_based_health_state_classification_A_deep_reinforcement_learning_approach", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/336186043_Intelligent_fault_diagnosis_for...", "snippet": "<b>Q-network based health state classification: a deep reinforcement learning</b> approach Y u Ding 1, 2 , Liang Ma 1, 2 , Jian Ma 1, 2 , Laifa T ao 1, 2 , Y ujie Cheng 3 , Chen Lu 1, 2 *", "dateLastCrawled": "2022-02-01T17:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Last <b>5 Years In Deep Learning</b> \u2013 Adit Deshpande \u2013 Engineering at ...", "url": "https://adeshpande3.github.io/The-Last-5-Years-in-Deep-Learning", "isFamilyFriendly": true, "displayUrl": "https://adeshpande3.github.io/The-Last-<b>5-Years-in-Deep-Learning</b>", "snippet": "Atari with <b>DQN</b> (2013) and subsequent Nature Paper (2015) \u2013 First successful use of <b>deep</b> <b>learning</b> in RL. Introduced <b>DQN</b> (<b>Deep</b> <b>Q-Network</b>), which is an end to end RL agent <b>that uses</b> a large neural net to process game states and choose appropriate actions.", "dateLastCrawled": "2022-01-29T15:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What is the difference between computing Q value of Q-<b>learning</b> and <b>deep</b> ...", "url": "https://www.quora.com/What-is-the-difference-between-computing-Q-value-of-Q-learning-and-deep-Q-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-the-difference-between-computing-Q-value-of-Q-<b>learning</b>...", "snippet": "Answer: I will assume that by Q-<b>learning</b> you\u2019re using a table to store the Q values, so as you said the Q values is updated by: Q_new = (1-alpha) * Q(s,a)_old + alpha * (reward + gamma*max(Q(s+1,ai))) That\u2019s because you <b>can</b> directly modify the value of the Q value. In <b>Deep</b> Q-<b>learning</b> you have ...", "dateLastCrawled": "2021-12-31T18:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How <b>can</b> I <b>use RNN in DQN? - Quora</b>", "url": "https://www.quora.com/How-can-I-use-RNN-in-DQN", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/How-<b>can</b>-I-use-RNN-in-<b>DQN</b>", "snippet": "Answer: The mechanism is called <b>Deep</b> Recurrent <b>Q-Network</b>. Let\u2019s say you have programmed a robot to solve a maze. It\u2019s at point A and it needs to go to point B. But the robot doesn\u2019t know it\u2019s position in the maze, it only <b>can</b> measure its distance from point B. We call these measurements \u201cObserva...", "dateLastCrawled": "2022-01-19T00:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Deep</b> <b>Q-Network</b> based resource allocation for UAV-assisted Ultra-Dense ...", "url": "https://www.sciencedirect.com/science/article/pii/S138912862100284X", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S138912862100284X", "snippet": "Finally, by using <b>deep</b> reinforcement <b>learning</b> (DRL) technique, we propose a <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) based resource allocation scheme to maximize the <b>system</b> energy efficiency. Simulation results exhibit that the proposed <b>DQN</b>-based resource allocation scheme <b>can</b> significantly improve the <b>system</b> EE <b>compared</b> with the legacy Q-<b>Learning</b>, random and maximum resource allocation algorithms.", "dateLastCrawled": "2022-01-20T16:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A <b>pair of interrelated neural networks in</b> <b>Deep</b> <b>Q-Network</b> | by Rafael ...", "url": "https://towardsdatascience.com/a-pair-of-interrelated-neural-networks-in-dqn-f0f58e09b3c4", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-<b>pair-of-interrelated-neural-networks-in</b>-<b>dqn</b>-f0f58e09b3c4", "snippet": "The success of neural networks in <b>Computer</b> Vision has sparked interest in trying them out in RL. ... the lookup tables were replaced by neural networks and a Q-<b>Learning</b> became a <b>Deep</b> Q-<b>Learning</b>, or, equivalently, <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>). In fact, it was a breakthrough in RL agent training. The <b>DQN</b> is the algorithm that combines Q-<b>learning</b> with neural networks. The <b>DQN</b> components. Pair of Q-Networks (local and target). Experience replay \u2014 a biologically inspired mechanism. \u03b5-greedy mechanism ...", "dateLastCrawled": "2022-01-29T13:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "A <b>Computer</b> Vision-Based Attention Generator Using <b>DQN</b>", "url": "https://openaccess.thecvf.com/content/ICCV2021W/AVVision/papers/Chipka_A_Computer_Vision-Based_Attention_Generator_Using_DQN_ICCVW_2021_paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://openaccess.thecvf.com/content/ICCV2021W/AVVision/papers/Chipka_A_<b>Computer</b>...", "snippet": "This work presents an end-to-end <b>computer</b> vision-based <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) technique that intelligently selects a priority region of an image to place greater atten- tion to achieve better perception performance. This method is evaluated on the Berkeley <b>Deep</b> Drive (BDD) dataset. Re-sults demonstrate that a substantial improvement in percep-tion performance <b>can</b> be attained \u2013 <b>compared</b> to a baseline method \u2013 at a minimal cost in terms of time and processing. 1. Introduction As AD/ADAS ...", "dateLastCrawled": "2021-12-04T20:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "[2008.04109] <b>Deep</b> <b>Q-Network</b> Based <b>Multi-agent</b> Reinforcement <b>Learning</b> ...", "url": "https://arxiv.org/abs/2008.04109", "isFamilyFriendly": true, "displayUrl": "https://arxiv.org/abs/2008.04109", "snippet": "<b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) based <b>multi-agent</b> systems (MAS) for reinforcement <b>learning</b> (RL) use various schemes where in the agents have to learn and communicate. The <b>learning</b> is however specific to each agent and communication may be satisfactorily designed for the agents. As more complex <b>Deep</b> QNetworks come to the fore, the overall complexity of the <b>multi-agent</b> <b>system</b> increases leading to issues like difficulty in training, need for higher resources and more training time, difficulty in fine ...", "dateLastCrawled": "2021-12-25T01:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "ROBUST FINANCIAL TRADING <b>SYSTEM</b> WITH <b>DEEP</b> <b>Q NETWORK</b> (<b>DQN</b>)", "url": "https://repository.nida.ac.th/bitstream/handle/662723737/4077/b203303e.pdf?sequence=4", "isFamilyFriendly": true, "displayUrl": "https://repository.nida.ac.th/bitstream/handle/662723737/4077/b203303e.pdf?sequence=4", "snippet": "ROBUST FINANCIAL TRADING <b>SYSTEM</b> WITH <b>DEEP</b> <b>Q NETWORK</b> (<b>DQN</b>) Sutta Sornmayura A Dissertation Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy (Management) International College, National Institute of Development Administration 2017 . ROBUST FINANCIAL TRADING <b>SYSTEM</b> WITH <b>DEEP</b> <b>Q NETWORK</b> (<b>DQN</b>) Sutta Sornmayura International College, Major Advisor (Associate Professor Vesarach Aumeboonsuke, Ph.D.) The Examining Committee Approved This Dissertation ...", "dateLastCrawled": "2022-01-23T05:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Intelligent Traffic Signal Phase Distribution <b>System</b> Using <b>Deep</b> <b>Q-Network</b>", "url": "https://www.mdpi.com/2076-3417/12/1/425/htm", "isFamilyFriendly": true, "displayUrl": "https://www.mdpi.com/2076-3417/12/1/425/htm", "snippet": "In this paper, we propose a traffic signal <b>system</b> using a <b>deep</b> <b>Q-network</b> (<b>DQN</b>), which is a type of reinforcement <b>learning</b> method. The proposed model recognizes traffic conditions at intersections and determines the phase order, that is, the order in which the green traffic light turns on. The purpose of the proposed model is to maximize the throughput of the intersection and distribute the signals fairly. Throughput refers to the number of vehicles passing through an intersection over time ...", "dateLastCrawled": "2022-01-26T17:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "In a <b>deep</b> <b>Q-network</b>, what are the advantages/disadvantages of ...", "url": "https://www.quora.com/In-a-deep-Q-network-what-are-the-advantages-disadvantages-of-enumerating-all-possible-action-states-even-if-actions-are-independent", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/In-a-<b>deep</b>-<b>Q-network</b>-what-are-the-advantages-disadvantages-of...", "snippet": "Answer (1 of 3): Q <b>learning</b> requires the creation of a two-dimensional array. The first dimension is the number of possible states, while the second dimension is the number of possible actions. Each state-action pair maintains a Q value, which is the expected discounted long-term reward for selec...", "dateLastCrawled": "2022-01-14T00:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Collecting Bananas with a <b>Deep</b> <b>Q-Network</b> | by David Rose | Medium", "url": "https://david010.medium.com/collecting-bananas-with-a-deep-q-network-26c7a45d4c27", "isFamilyFriendly": true, "displayUrl": "https://david010.medium.com/collecting-bananas-with-a-<b>deep</b>-<b>q-network</b>-26c7a45d4c27", "snippet": "Reinforcement <b>Learning</b> \u2192 Q-<b>Learning</b> \u2192 <b>Deep</b> Q-<b>Learning</b>. Under the umbrella of <b>machine</b> <b>learning</b>, we typically describe 3 foundational perspectives: Unsupervised <b>Learning</b>; Supervised <b>Learning</b> ; Reinforcement <b>Learning</b>; Each of these relate to differing method s of finding patterns in data, but the one we focus on here is reinforcement <b>learning</b> in which we are able to build up an optimal policy of actions using a simulation of positive and/or negative rewards. The specific model used is ...", "dateLastCrawled": "2022-01-29T05:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Using <b>Deep</b> Q-<b>Learning to Control Optimization Hyperparameters</b>", "url": "https://www.researchgate.net/publication/301846248_Using_Deep_Q-Learning_to_Control_Optimization_Hyperparameters", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/301846248_Using_<b>Deep</b>_Q-<b>Learning</b>_to_Control...", "snippet": "In this paper, we show that by feeding the weights of a <b>deep</b> neural network (DNN) during training into a <b>deep</b> <b>Q-network</b> (<b>DQN</b>) as its states, this <b>DQN</b> <b>can</b> learn policies to accelerate the training ...", "dateLastCrawled": "2022-01-17T10:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Balancing a <b>CartPole System with Reinforcement Learning -- A Tutorial</b>", "url": "https://www.researchgate.net/publication/342094706_Balancing_a_CartPole_System_with_Reinforcement_Learning_--_A_Tutorial", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/342094706_Balancing_a_CartPole_<b>System</b>_with...", "snippet": "In this paper, the implementation of two Reinforcement learnings namely, Q <b>Learning</b> and <b>Deep</b> <b>Q Network</b>(<b>DQN</b>) on a Self Balancing Robot Gazebo model has been discussed. The goal of the experiments ...", "dateLastCrawled": "2022-01-20T23:25:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>DQN</b> Algorithm: A father-son tale. The <b>Deep</b> <b>Q-Network</b> (<b>DQN</b> ...", "url": "https://medium.com/analytics-vidhya/dqn-algorithm-a-father-son-tale-b4bf6ff1ae2f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/analytics-vidhya/<b>dqn</b>-algorithm-a-father-son-tale-b4bf6ff1ae2f", "snippet": "The <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) Reinforcement <b>learning</b> algorithm has a surprisingly simple and real life <b>analogy</b> with which it can be explained. It helps understand the sequence of operations involved by ...", "dateLastCrawled": "2022-01-13T23:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Deep Q-Learning with Keras and Gym</b> \u00b7 Keon&#39;s Blog", "url": "https://keon.github.io/deep-q-learning/", "isFamilyFriendly": true, "displayUrl": "https://keon.github.io/<b>deep</b>-q-<b>learning</b>", "snippet": "If we use the <b>analogy</b> of the bicycle, we can define reward as the distance from the original starting point. ## <b>Deep</b> Reinforcement <b>Learning</b> Google\u2019s DeepMind published its famous paper Playing Atari with <b>Deep</b> Reinforcement <b>Learning</b>, in which they introduced a new algorithm called <b>Deep</b> <b>Q Network</b> (<b>DQN</b> for short) in 2013. It demonstrated how an ...", "dateLastCrawled": "2022-02-01T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Graying the Black Box: Understanding DQNs</b> | the morning paper", "url": "https://blog.acolyer.org/2016/03/02/graying-the-black-box-understanding-dqns/", "isFamilyFriendly": true, "displayUrl": "https://blog.acolyer.org/2016/03/02/<b>graying-the-black-box-understanding-dqns</b>", "snippet": "<b>Deep</b> Reinforcement <b>Learning</b> (DRL) applies <b>Deep</b> Neural Networks to reinforcement <b>learning</b>. The <b>Deep</b> Mind team used a DRL algorithm called <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) to learn how to play the Atari games. In \u2018Graying the Black Box,\u2019 Zahavy et al. look at three of those games \u2013 Breakout, Pacman, and Seaquest \u2013 and develop a new visualization and interaction approach that helps to shed insight on what it is that <b>DQN</b> is actually <b>learning</b>.", "dateLastCrawled": "2022-01-20T19:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Using <b>Keras and Deep Q-Network to Play FlappyBird</b> | Ben Lau", "url": "https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html", "isFamilyFriendly": true, "displayUrl": "https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html", "snippet": "What is <b>Deep</b> <b>Q-Network</b>? <b>Deep</b> <b>Q-Network</b> is a <b>learning</b> algorithm developed by Google DeepMind to play Atari games. They demonstrated how a computer learned to play Atari 2600 video games by observing just the screen pixels and receiving a reward when the game score increased. The result was remarkable because it demonstrates the algorithm is generic enough to play various games. The following post is a must-read for those who are interested in <b>deep</b> reinforcement <b>learning</b>. Demystifying <b>Deep</b> ...", "dateLastCrawled": "2022-01-30T05:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Reinforcement Learning for On-Demand Logistics</b> - <b>DoorDash Engineering Blog</b>", "url": "https://doordash.engineering/2018/09/10/reinforcement-learning-for-on-demand-logistics/", "isFamilyFriendly": true, "displayUrl": "https://doordash.engineering/2018/09/10/<b>reinforcement-learning-for-on-demand-logistics</b>", "snippet": "This approach is known as <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) and is very useful when feature dimensionality is high and data volume is also high. Reinforcement learned assignment . Now we will discuss how we applied reinforcement <b>learning</b> to the DoorDash assignment problem. To formulate the assignment problem in a way that\u2019s suitable for reinforcement <b>learning</b>, we made the following definitions. State: The outstanding deliveries and working Dashers, since they represent the current status of the world ...", "dateLastCrawled": "2022-01-18T18:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Guide to Reinforcement <b>Learning with Python and TensorFlow</b>", "url": "https://rubikscode.net/2021/07/13/deep-q-learning-with-python-and-tensorflow-2-0/", "isFamilyFriendly": true, "displayUrl": "https://rubikscode.net/2021/07/13/<b>deep</b>-q-<b>learning-with-python-and-tensorflow</b>-2-0", "snippet": "In the previous two articles we started exploring the interesting universe of reinforcement <b>learning</b>.First we went through the basics of third paradigm within <b>machine</b> <b>learning</b> \u2013 reinforcement <b>learning</b>.Just to freshen up our memory, we saw that approach of this type of <b>learning</b> is unlike the previously explored supervised and unsupervised <b>learning</b>. In reinforcement <b>learning</b>, self-<b>learning</b> agent learns how to interact with the environment and solve a problem within it. In this article, we ...", "dateLastCrawled": "2022-02-03T13:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Solving Combinatorial Problems with Machine Learning Methods</b> | Request PDF", "url": "https://www.researchgate.net/publication/333525406_Solving_Combinatorial_Problems_with_Machine_Learning_Methods", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/333525406_Solving_Combinatorial_Problems_with...", "snippet": "Next we discuss <b>Deep</b> <b>Q-Network</b> (<b>DQN</b>) and its extensions, asynchronous methods, policy optimization, reward, and planning. After that, we talk about attention and memory, unsupervised <b>learning</b>, and ...", "dateLastCrawled": "2022-01-23T14:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Deep</b> Reinforcement <b>Learning</b> for Crowdsourced Urban Delivery - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0191261521001636", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0191261521001636", "snippet": "We propose a new <b>deep</b> reinforcement <b>learning</b> (DRL)-based approach to tackling this assignment problem. A <b>deep</b> <b>Q network</b> (<b>DQN</b>) algorithm is trained which entails two salient features of experience replay and target network that enhance the efficiency, convergence, and stability of DRL training. More importantly, this paper makes three methodological contributions: 1) presenting a comprehensive and novel characterization of crowdshipping system states that encompasses spatial-temporal and ...", "dateLastCrawled": "2022-01-19T19:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Reinforcement Learning for Formula 1</b> Race Strategy | by Ashref Maiza ...", "url": "https://towardsdatascience.com/reinforcement-learning-for-formula-1-race-strategy-7f29c966472a", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>reinforcement-learning-for-formula-1</b>-race-strategy-7f29...", "snippet": "Reinforcement <b>Learning</b> (RL) is an advanced <b>machine</b> <b>learning</b> (ML) technique which takes a very different approach to training models than other <b>machine</b> <b>learning</b> methods. Its super power is that it learns very complex behaviors without requiring any labeled training data, and can make short term decisions while optimizing for a longer term goal. RL in the context of Formula 1 racing. In RL, an agent learns the optimal behavior to perform a certain task by interacting directly with the ...", "dateLastCrawled": "2022-02-02T11:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Applications of <b>Reinforcement Learning</b> in Real World | by garychl ...", "url": "https://towardsdatascience.com/applications-of-reinforcement-learning-in-real-world-1a94955bcd12", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/applications-of-<b>reinforcement-learning</b>-in-real-world-1a...", "snippet": "RL, known as a semi-supervised <b>learning</b> model in <b>machine</b> <b>learning</b>, is a technique to allow an agent to take actions and interact with an environment so as to maximize the total rewards. RL is usually modeled as a Markov Decision Process (MDP). Source: <b>Reinforcement Learning</b>:An Introduction. Imagine a baby is given a TV remote control at your home (environment). In simple terms, the baby (agent) will first observe and construct his/her own representation of the environment (state). Then the ...", "dateLastCrawled": "2022-02-02T20:37:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(deep q-network (dqn))  is like +(a computer system that uses machine learning)", "+(deep q-network (dqn)) is similar to +(a computer system that uses machine learning)", "+(deep q-network (dqn)) can be thought of as +(a computer system that uses machine learning)", "+(deep q-network (dqn)) can be compared to +(a computer system that uses machine learning)", "machine learning +(deep q-network (dqn) AND analogy)", "machine learning +(\"deep q-network (dqn) is like\")", "machine learning +(\"deep q-network (dqn) is similar\")", "machine learning +(\"just as deep q-network (dqn)\")", "machine learning +(\"deep q-network (dqn) can be thought of as\")", "machine learning +(\"deep q-network (dqn) can be compared to\")"]}