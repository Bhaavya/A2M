{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introductory note on Deep Learning - Analytics Vidhya", "url": "https://www.analyticsvidhya.com/blog/2022/01/introductory-note-on-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2022/01/introductory-note-on-deep-learning", "snippet": "10) <b>Gradient</b> Descent \u2013 <b>Gradient</b> descent is an optimization algorithm for minimizing the cost. To think of it intuitively, while climbing <b>down</b> <b>a hill</b> you should take small steps and <b>walk</b> <b>down</b> instead of just jumping <b>down</b> at once. Therefore, what we do is, if we start from a point x, we move <b>down</b> a little i.e. delta h, and update our position to x-delta h and we keep doing the same till we reach the bottom. Consider bottom to be the minimum cost point.", "dateLastCrawled": "2022-01-31T18:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 1, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Gradient descent</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Gradient_descent", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Gradient_descent</b>", "snippet": "A <b>person</b> is stuck in the mountains and is <b>trying</b> to get <b>down</b> (i.e., <b>trying</b> to find the global minimum). There is heavy fog such that visibility is extremely low. Therefore, the path <b>down</b> the mountain is not visible, so they must use local information to find the minimum. They can use the method of <b>gradient descent</b>, which involves looking at the steepness of the <b>hill</b> at their current position, then proceeding in the direction with the steepest descent (i.e., downhill). If they were <b>trying</b> to ...", "dateLastCrawled": "2022-02-03T03:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "25 Must Know <b>Concepts for Beginners in Deep Learning</b> &amp; Neural Network", "url": "https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners-in-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners...", "snippet": "10) <b>Gradient</b> Descent \u2013 <b>Gradient</b> descent is an optimization algorithm for minimizing the cost. To think of it intuitively, while climbing <b>down</b> <b>a hill</b> you should take small steps and <b>walk</b> <b>down</b> instead of just jumping <b>down</b> at once. Therefore, what we do is, if we start from a point x, we move <b>down</b> a little i.e. delta h, and update our position to x-delta h and we keep doing the same till we reach the bottom. Consider bottom to be the minimum cost point.", "dateLastCrawled": "2022-02-03T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "A <b>non computer science graduate approach to understanding deep</b> learning ...", "url": "https://medium.com/dataly-ai/a-non-computer-science-graduate-approach-to-understanding-deep-learning-techniques-and-77d75dfd924f", "isFamilyFriendly": true, "displayUrl": "https://medium.com/dataly-ai/a-<b>non-computer-science-graduate-approach-to-understanding</b>...", "snippet": "The problems of RNN are vanishing and <b>exploding</b> <b>gradient</b>. Two of this variants are Gated RNNs and Long Short-Term Memory RNNs also known as LSTMs. Both of this variants uses a form of memory to ...", "dateLastCrawled": "2021-07-30T04:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Adaptive Computation and Machine Learning series- Deep learning</b> ...", "url": "https://www.academia.edu/38223830/Adaptive_Computation_and_Machine_Learning_series_Deep_learning_The_MIT_Press_2016_pdf", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/38223830/<b>Adaptive_Computation_and_Machine_Learning_series</b>...", "snippet": "<b>Adaptive Computation and Machine Learning series- Deep learning</b>-The MIT Press (2016).pdf", "dateLastCrawled": "2022-02-02T06:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Lightning Protection: The Truth About Dissipators</b> - Practical Sailor", "url": "https://www.practical-sailor.com/blog/lightning-protection-the-truth-about-dissipators", "isFamilyFriendly": true, "displayUrl": "https://www.practical-sailor.com/blog/<b>lightning-protection-the-truth-about-dissipators</b>", "snippet": "Simply put, the imbalance can occur due to the movement of the air, which <b>like</b> the movement of a <b>person</b> across a carpet, can cause electrical charges to be moved from one place to another. Imbalance in electrical charge causes a potential <b>gradient</b> to develop. This <b>gradient</b> can be measured and is usually expressed in volts per meter. The normal electric (E) field averages about 150 volts per meter. The field can exceed 1,000 volts per meter on a dry day. At this intensity, the potential ...", "dateLastCrawled": "2022-01-30T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "\u201cStep-free\u201d doesn\u2019t mean <b>DDA-compliant</b> \u2013 Daniel Bowen", "url": "https://www.danielbowen.com/2017/11/06/dda-compliant-stations/", "isFamilyFriendly": true, "displayUrl": "https://www.danielbowen.com/2017/11/06/<b>dda-compliant</b>-stations", "snippet": "And my mum \u2013 my formerly fit, active, healthy mum who used <b>to walk</b> everywhere, for miles \u2013 now uses a walking stick, and cannot <b>walk</b> <b>down</b> steep ramps or manage a step higher than about 12cm. I was confronted with that reality some years ago when I was planning a journey for the two of us: \u201c\u2026 So, Mum, you\u2019ll get off the bus at Essendon. I\u2019ll meet you there, and we\u2019ll catch the train\u2026\u201d, and she paused and then said quietly, \u201cI can\u2019t use Essendon any more. I can change ...", "dateLastCrawled": "2021-12-31T23:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "If the weather is calm, could a <b>person</b> take a 15 minutes stroll on Mars ...", "url": "https://www.quora.com/If-the-weather-is-calm-could-a-person-take-a-15-minutes-stroll-on-Mars-without-a-space-suit-and-wearing-just-a-basic-oxygen-mask-and-light-gear", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/If-the-weather-is-calm-could-a-<b>person</b>-take-a-15-minutes-stroll...", "snippet": "Answer (1 of 6): Yes, Mars has an atmosphere, and yes, it has weather too\u2014note the gigantic dust storm currently \u201craging\u201d and endangering the Mars Opportunity rover. But Mars\u2019 atmosphere is super thin, less than 1% the atmospheric pressure on Earth. Because of this, a dust storm\u2014even one with 20...", "dateLastCrawled": "2022-01-13T20:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 8, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Nihachu (SMP</b>) | Dream Team Wiki | Fandom", "url": "https://dreamteam.fandom.com/wiki/Nihachu/SMP", "isFamilyFriendly": true, "displayUrl": "https://dreamteam.fandom.com/wiki/<b>Nihachu/SMP</b>", "snippet": "Nihachu, more commonly referred to as Niki, is the nineteenth member of the Dream SMP, joining on August 6, 2020.She is a member of the Syndicate and a former loyal member of L&#39;Manberg.. She was a citizen of L&#39;Manberg during the presidency of Wilbur Soot, but during the Manberg Rebellion, she spoke out strongly against the Jschlatt Administration, leading to her banishment and subsequent joining of Pogtopia at the culmination of the Manberg Festival.She fought alongside the Pogtopians during ...", "dateLastCrawled": "2022-02-03T05:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What would happen if someone was sucked out of a hull breach at high ...", "url": "https://www.reddit.com/r/DaystromInstitute/comments/2fp7t2/what_would_happen_if_someone_was_sucked_out_of_a/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/DaystromInstitute/comments/2fp7t2/what_would_happen_if...", "snippet": "If the warp drive is warping space around a subspace bubble that surrounds the ship, then once a <b>person</b> left the confines of the ship and drifted to the edge of the subspace bubble, they&#39;d begin to get warped just as the surrounding space, so I&#39;d assume they&#39;d be ripped apart much <b>like</b> a <b>person</b> caught in the event horizon of a black hole. 3.", "dateLastCrawled": "2021-06-22T02:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introductory note on Deep Learning - Analytics Vidhya", "url": "https://www.analyticsvidhya.com/blog/2022/01/introductory-note-on-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2022/01/introductory-note-on-deep-learning", "snippet": "10) <b>Gradient</b> Descent \u2013 <b>Gradient</b> descent is an optimization algorithm for minimizing the cost. To think of it intuitively, while climbing <b>down</b> <b>a hill</b> you should take small steps and <b>walk</b> <b>down</b> instead of just jumping <b>down</b> at once. Therefore, what we do is, if we start from a point x, we move <b>down</b> a little i.e. delta h, and update our position to x-delta h and we keep doing the same till we reach the bottom. Consider bottom to be the minimum cost point.", "dateLastCrawled": "2022-01-31T18:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "25 Must Know <b>Concepts for Beginners in Deep Learning</b> &amp; Neural Network", "url": "https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners-in-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners...", "snippet": "10) <b>Gradient</b> Descent \u2013 <b>Gradient</b> descent is an optimization algorithm for minimizing the cost. To think of it intuitively, while climbing <b>down</b> <b>a hill</b> you should take small steps and <b>walk</b> <b>down</b> instead of just jumping <b>down</b> at once. Therefore, what we do is, if we start from a point x, we move <b>down</b> a little i.e. delta h, and update our position to x-delta h and we keep doing the same till we reach the bottom. Consider bottom to be the minimum cost point.", "dateLastCrawled": "2022-02-03T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 2, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Gradient descent</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Gradient_descent", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Gradient_descent</b>", "snippet": "<b>Gradient descent</b> is based on the observation that if the multi-variable function is defined and differentiable in a neighborhood of a point , then () decreases fastest if one goes from in the direction of the negative <b>gradient</b> of at , ().It follows that, if + = for a small enough step size or learning rate +, then (+).In other words, the term () is subtracted from because we want to move against the <b>gradient</b>, toward the local minimum. With this observation in mind, one starts with a guess ...", "dateLastCrawled": "2022-02-03T03:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Tricuspid Valve Regurgitation</b>: What You NEED to Know", "url": "https://myheart.net/articles/tricuspid-valve-regurgitation/", "isFamilyFriendly": true, "displayUrl": "https://myheart.net/articles/<b>tricuspid-valve-regurgitation</b>", "snippet": "Primary tricuspid regurgitation is where there is a direct <b>problem</b> with the valve leaflets or associated chord strings. This only accounts for around 20% of severe tricuspid regurgitation. The majority of tricuspid regurgitation is secondary and due to left sided heart disease. In the case of primary tricuspid regurgitation, the primary operation will be on the tricuspid valve, unlike secondary tricuspid regurgitation where operations will typically be done on the left sided heart valve (the ...", "dateLastCrawled": "2022-02-02T07:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Deep Learning A Practitioners Approach</b> | Alamelu ... - Academia.edu", "url": "https://www.academia.edu/37119738/Deep_Learning_A_Practitioners_Approach", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/37119738/<b>Deep_Learning_A_Practitioners_Approach</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-30T22:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) Deep <b>Learning for NLP and Speech Recognition</b> | William Jacome ...", "url": "https://www.academia.edu/43190210/Deep_Learning_for_NLP_and_Speech_Recognition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43190210/Deep_<b>Learning_for_NLP_and_Speech_Recognition</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-02T18:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Yield Thought", "url": "https://yieldthought.com/", "isFamilyFriendly": true, "displayUrl": "https://yieldthought.com", "snippet": "It could be any of: * Hyperparameters need to be more carefully tuned (algorithms can be rather sensitive even within <b>similar</b> domains) * Initialization is incorrect and weights are dropping to zero (vanishing <b>gradient</b> <b>problem</b>) or are becoming unstable (<b>exploding</b> <b>gradient</b> <b>problem</b>) - these at least you can check by producing images of the weights and staring hard at them, like astrologers seeking meaning in the stars. * The input is not preprocessed, normalized or augmented enough. Or it\u2019s", "dateLastCrawled": "2022-01-29T12:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "\u201cStep-free\u201d doesn\u2019t mean <b>DDA-compliant</b> \u2013 Daniel Bowen", "url": "https://www.danielbowen.com/2017/11/06/dda-compliant-stations/", "isFamilyFriendly": true, "displayUrl": "https://www.danielbowen.com/2017/11/06/<b>dda-compliant</b>-stations", "snippet": "(For <b>similar</b> reasons, Sydney never had very many level crossings. Sure, ... my formerly fit, active, healthy mum who used <b>to walk</b> everywhere, for miles \u2013 now uses a walking stick, and cannot <b>walk</b> <b>down</b> steep ramps or manage a step higher than about 12cm. I was confronted with that reality some years ago when I was planning a journey for the two of us: \u201c\u2026 So, Mum, you\u2019ll get off the bus at Essendon. I\u2019ll meet you there, and we\u2019ll catch the train\u2026\u201d, and she paused and then said ...", "dateLastCrawled": "2021-12-31T23:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "GRE Flashcards - <b>Quizlet</b>", "url": "https://quizlet.com/gb/523138019/gre-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/gb/523138019/gre-flash-cards", "snippet": "A logistical <b>problem</b> occurs when your plans didn&#39;t account for something: &quot;You forgot to get a permit for this parade, and now the marching band and floats are causing a traffic jam \u2014 what a logistical nightmare!&quot; Logistical things can relate to strategy or management, though this adjective originally meant &quot;pertaining to logic,&quot; from the Greek logistikos, &quot;endowed with reason.&quot; adj - of or relating to logistics But they all declined, citing conflicts of interest and other logistical ...", "dateLastCrawled": "2022-02-02T13:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What would happen if someone was sucked out of a hull breach at high ...", "url": "https://www.reddit.com/r/DaystromInstitute/comments/2fp7t2/what_would_happen_if_someone_was_sucked_out_of_a/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/DaystromInstitute/comments/2fp7t2/what_would_happen_if...", "snippet": "For some people, they request solo access (e.g. senior officers maybe) kinda <b>similar</b> to how senior officers have solo rooms but junior ranks share a room. They can also be requested if you&#39;re working on something. You still might have times where there&#39;s no one else in there (odd hours etc) which would explain those episodes where the program ends and no one is there (or that is also a simulation to let you feel happy the program is shut off and show you where <b>to walk</b> to get to the exit).", "dateLastCrawled": "2021-06-22T02:37:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 0, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Gradient descent</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Gradient_descent", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Gradient_descent</b>", "snippet": "A <b>person</b> is stuck in the mountains and is <b>trying</b> to get <b>down</b> (i.e., <b>trying</b> to find the global minimum). There is heavy fog such that visibility is extremely low. Therefore, the path <b>down</b> the mountain is not visible, so they must use local information to find the minimum. They <b>can</b> use the method of <b>gradient descent</b>, which involves looking at the steepness of the <b>hill</b> at their current position, then proceeding in the direction with the steepest descent (i.e., downhill). If they were <b>trying</b> to ...", "dateLastCrawled": "2022-02-03T03:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Yield <b>Thought</b>", "url": "https://yieldthought.com/", "isFamilyFriendly": true, "displayUrl": "https://yield<b>thought</b>.com", "snippet": "It could be any of: * Hyperparameters need to be more carefully tuned (algorithms <b>can</b> be rather sensitive even within similar domains) * Initialization is incorrect and weights are dropping to zero (vanishing <b>gradient</b> <b>problem</b>) or are becoming unstable (<b>exploding</b> <b>gradient</b> <b>problem</b>) - these at least you <b>can</b> check by producing images of the weights and staring hard at them, like astrologers seeking meaning in the stars. * The input is not preprocessed, normalized or augmented enough. Or it\u2019s", "dateLastCrawled": "2022-01-29T12:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Lightning Protection: The Truth About Dissipators</b> - Practical Sailor", "url": "https://www.practical-sailor.com/blog/lightning-protection-the-truth-about-dissipators", "isFamilyFriendly": true, "displayUrl": "https://www.practical-sailor.com/blog/<b>lightning-protection-the-truth-about-dissipators</b>", "snippet": "Simply put, the imbalance <b>can</b> occur due to the movement of the air, which like the movement of a <b>person</b> across a carpet, <b>can</b> cause electrical charges to be moved from one place to another. Imbalance in electrical charge causes a potential <b>gradient</b> to develop. This <b>gradient</b> <b>can</b> be measured and is usually expressed in volts per meter. The normal electric (E) field averages about 150 volts per meter. The field <b>can</b> exceed 1,000 volts per meter on a dry day. At this intensity, the potential ...", "dateLastCrawled": "2022-01-30T09:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Deep Learning A Practitioners Approach</b> | Alamelu ... - Academia.edu", "url": "https://www.academia.edu/37119738/Deep_Learning_A_Practitioners_Approach", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/37119738/<b>Deep_Learning_A_Practitioners_Approach</b>", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-30T22:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) Cambridge-international-as-and-a-level-physics-coursebook-second ...", "url": "https://www.academia.edu/19977963/Cambridge_international_as_and_a_level_physics_coursebook_second_edition_part_one_web_1_", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/19977963", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-03T03:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "\u201cStep-free\u201d doesn\u2019t mean <b>DDA-compliant</b> \u2013 Daniel Bowen", "url": "https://www.danielbowen.com/2017/11/06/dda-compliant-stations/", "isFamilyFriendly": true, "displayUrl": "https://www.danielbowen.com/2017/11/06/<b>dda-compliant</b>-stations", "snippet": "And my mum \u2013 my formerly fit, active, healthy mum who used <b>to walk</b> everywhere, for miles \u2013 now uses a walking stick, and cannot <b>walk</b> <b>down</b> steep ramps or manage a step higher than about 12cm. I was confronted with that reality some years ago when I was planning a journey for the two of us: \u201c\u2026 So, Mum, you\u2019ll get off the bus at Essendon. I\u2019ll meet you there, and we\u2019ll catch the train\u2026\u201d, and she paused and then said quietly, \u201cI <b>can</b>\u2019t use Essendon any more. I <b>can</b> change ...", "dateLastCrawled": "2021-12-31T23:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>4 Training Myths for Cyclists 50</b> and Older - Chris Carmichael", "url": "https://trainright.com/4-training-myths-for-cyclists-50-and-older/", "isFamilyFriendly": true, "displayUrl": "https://trainright.com/<b>4-training-myths-for-cyclists-50</b>-and-older", "snippet": "I <b>can</b> easily ride 100 miles at a good average and i does lots of climbing, over 400,000. ft. with <b>gradient</b> up to 20%. I ride 3 to 4 times per week. I take daily naps when i feel like and i sleep at least 8 hrs. each night. Watch my diet, lot of fruits and try to stay well hydrated. I have never use a HRM or a power meter. I feel my body and i know when i am in the red on a really steep climb so i sometimes back off and in a couple minutes i am good to go. My resting HR is 48 BPM. When i ride ...", "dateLastCrawled": "2022-02-02T12:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "If the weather is calm, could a <b>person</b> take a 15 minutes stroll on Mars ...", "url": "https://www.quora.com/If-the-weather-is-calm-could-a-person-take-a-15-minutes-stroll-on-Mars-without-a-space-suit-and-wearing-just-a-basic-oxygen-mask-and-light-gear", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/If-the-weather-is-calm-could-a-<b>person</b>-take-a-15-minutes-stroll...", "snippet": "Answer (1 of 6): Yes, Mars has an atmosphere, and yes, it has weather too\u2014note the gigantic dust storm currently \u201craging\u201d and endangering the Mars Opportunity rover. But Mars\u2019 atmosphere is super thin, less than 1% the atmospheric pressure on Earth. Because of this, a dust storm\u2014even one with 20...", "dateLastCrawled": "2022-01-13T20:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>University_physics_with_modern_physics</b>_(13th)_ ... - ID:5cf6d5108f1d4", "url": "https://baixardoc.com/documents/universityphysicswithmodernphysics13th--5cf6d5108f1d4", "isFamilyFriendly": true, "displayUrl": "https://baixardoc.com/documents/<b>universityphysicswithmodernphysics</b>13th--5cf6d5108f1d4", "snippet": "<b>University_physics_with_modern_physics</b>_(13th)_ ... - ID:5cf6d5108f1d4. Mathematics Review Tutorials Each Example is explained and solved by an instructor MasteringPhysics offers an extensive ...", "dateLastCrawled": "2022-02-02T09:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 9, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Nihachu (SMP</b>) | Dream Team Wiki | Fandom", "url": "https://dreamteam.fandom.com/wiki/Nihachu/SMP", "isFamilyFriendly": true, "displayUrl": "https://dreamteam.fandom.com/wiki/<b>Nihachu/SMP</b>", "snippet": "Nihachu, more commonly referred to as Niki, is the nineteenth member of the Dream SMP, joining on August 6, 2020.She is a member of the Syndicate and a former loyal member of L&#39;Manberg.. She was a citizen of L&#39;Manberg during the presidency of Wilbur Soot, but during the Manberg Rebellion, she spoke out strongly against the Jschlatt Administration, leading to her banishment and subsequent joining of Pogtopia at the culmination of the Manberg Festival.She fought alongside the Pogtopians during ...", "dateLastCrawled": "2022-02-03T05:02:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Introductory note on Deep Learning - Analytics Vidhya", "url": "https://www.analyticsvidhya.com/blog/2022/01/introductory-note-on-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2022/01/introductory-note-on-deep-learning", "snippet": "10) <b>Gradient</b> Descent \u2013 <b>Gradient</b> descent is an optimization algorithm for minimizing the cost. To think of it intuitively, while climbing <b>down</b> <b>a hill</b> you should take small steps and <b>walk</b> <b>down</b> instead of just jumping <b>down</b> at once. Therefore, what we do is, if we start from a point x, we move <b>down</b> a little i.e. delta h, and update our position to x-delta h and we keep doing the same till we reach the bottom. Consider bottom to be the minimum cost point.", "dateLastCrawled": "2022-01-31T18:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "contractualRules": [{"_type": "ContractualRules/LicenseAttribution", "targetPropertyName": "snippet", "targetPropertyIndex": 1, "mustBeCloseToContent": true, "license": {"name": "CC-BY-SA", "url": "http://creativecommons.org/licenses/by-sa/3.0/"}, "licenseNotice": "Text under CC-BY-SA license"}], "name": "<b>Gradient descent</b> - <b>Wikipedia</b>", "url": "https://en.wikipedia.org/wiki/Gradient_descent", "isFamilyFriendly": true, "displayUrl": "https://<b>en.wikipedia.org</b>/wiki/<b>Gradient_descent</b>", "snippet": "A <b>person</b> is stuck in the mountains and is <b>trying</b> to get <b>down</b> (i.e., <b>trying</b> to find the global minimum). There is heavy fog such that visibility is extremely low. Therefore, the path <b>down</b> the mountain is not visible, so they must use local information to find the minimum. They <b>can</b> use the method of <b>gradient descent</b>, which involves looking at the steepness of the <b>hill</b> at their current position, then proceeding in the direction with the steepest descent (i.e., downhill). If they were <b>trying</b> to ...", "dateLastCrawled": "2022-02-03T03:05:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "25 Must Know <b>Concepts for Beginners in Deep Learning</b> &amp; Neural Network", "url": "https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners-in-deep-learning/", "isFamilyFriendly": true, "displayUrl": "https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners...", "snippet": "10) <b>Gradient</b> Descent \u2013 <b>Gradient</b> descent is an optimization algorithm for minimizing the cost. To think of it intuitively, while climbing <b>down</b> <b>a hill</b> you should take small steps and <b>walk</b> <b>down</b> instead of just jumping <b>down</b> at once. Therefore, what we do is, if we start from a point x, we move <b>down</b> a little i.e. delta h, and update our position to x-delta h and we keep doing the same till we reach the bottom. Consider bottom to be the minimum cost point.", "dateLastCrawled": "2022-02-03T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Deep Learning and Neural Networks with Python</b> | Frank Kane | Skillshare", "url": "https://www.skillshare.com/classes/Deep-Learning-and-Neural-Networks-with-Python/45606211", "isFamilyFriendly": true, "displayUrl": "https://www.skillshare.com/classes/<b>Deep-Learning-and-Neural-Networks-with-Python</b>/45606211", "snippet": "I&#39;ve also included my own solution to the <b>problem</b>. Soumyadipto Ray 3 likes. Deep learning. Cale Van der Westhuizen 2 likes. 1 comment. Class Ratings. Most Liked. Expectations Met? Exceeded! 0%; Yes. 0%; Somewhat. 0%; Not really. 0%; Load More Reviews. Reviews Archive. In October 2018, we updated our review system to improve the way we collect feedback. Below are the reviews written before that update. Load More Reviews. Get Started for Free. Why Join Skillshare? Take award-winning Skillshare ...", "dateLastCrawled": "2022-02-02T14:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "(PDF) <b>Adaptive Computation and Machine Learning series- Deep learning</b> ...", "url": "https://www.academia.edu/38223830/Adaptive_Computation_and_Machine_Learning_series_Deep_learning_The_MIT_Press_2016_pdf", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/38223830/<b>Adaptive_Computation_and_Machine_Learning_series</b>...", "snippet": "<b>Adaptive Computation and Machine Learning series- Deep learning</b>-The MIT Press (2016).pdf", "dateLastCrawled": "2022-02-02T06:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>GitHub</b> - <b>eltiffster/authorFunction</b>: Imitating Grant Allen&#39;s style with ...", "url": "https://github.com/eltiffster/authorFunction", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/eltiffster/authorFunction", "snippet": "In practice, the <b>gradient</b> is not quite so smooth and <b>can</b> fluctuate even as the overall trend slopes downward. I recommend copying and pasting the information printed at every checkpoint into a blank Excel document so you <b>can</b> keep track of (training and validation) loss values and whether they are increasing or decreasing over time. This documentation <b>can</b> be useful not only for deciding which checkpoint to sample but also to judge (by looking at the relationship between training and ...", "dateLastCrawled": "2021-08-13T12:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Master&#39;s theses</b> \u2013 Seminar for Statistics | ETH Zurich", "url": "https://math.ethz.ch/sfs/research/master-theses.html", "isFamilyFriendly": true, "displayUrl": "https://math.ethz.ch/sfs/research/master-theses.html", "snippet": "This <b>problem</b> <b>can</b> be formulated as an optimization <b>problem</b> where the latent con- founder structure corresponds to a low-rank constraint, which is non-convex and difficult to deal with. We study and implement al- gorithms to approach this optimization <b>problem</b> and make it more computationally feasible. One of the proposed algorithms is based on nuclear norm regularization and one is based on projected gra- dient descent.", "dateLastCrawled": "2022-02-03T02:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Hazardous Materials Incident</b> Response Operations", "url": "https://nepis.epa.gov/Exe/ZyPURL.cgi?Dockey=94006S59.txt", "isFamilyFriendly": true, "displayUrl": "https://nepis.epa.gov/Exe/ZyPURL.cgi?Dockey=94006S59.txt", "snippet": "Not only <b>can</b> they tip over, but they <b>can</b> be so corroded that they cannot support a <b>person</b>&#39;s weight. If it is necessary <b>to walk</b> over drums, place a piece of plywood over several drums and stand on this. This distributes the walker&#39;s weight over several drums. In some cases, a drum grappler <b>can</b> be used to move drums to a more accessible location. Falls are more serious when they occur from heights. Extra precautions must be taken if guardrails or railings are absent. The precautions generally ...", "dateLastCrawled": "2022-01-31T21:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "One <b>Small Step For A Space Elevator</b> | <b>Hackaday</b>", "url": "https://hackaday.com/2018/09/14/one-small-step-for-a-space-elevator/", "isFamilyFriendly": true, "displayUrl": "https://<b>hackaday.com</b>/2018/09/14/one-<b>small-step-for-a-space-elevator</b>", "snippet": "Finally, once you <b>can</b> bring crap from the moon or asteroids to the elevator terminus, you don\u2019t even need a way to use that crap as rocket propellant \u2014 just send it <b>down</b> the elevator to earth ...", "dateLastCrawled": "2022-01-14T13:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Amazon.com. Spend less. Smile more.", "url": "https://www.amazon.com/", "isFamilyFriendly": true, "displayUrl": "https://www.amazon.com", "snippet": "Free shipping on millions of items. Get the best of Shopping and Entertainment with Prime. Enjoy low prices and great deals on the largest selection of everyday essentials and other products, including fashion, home, beauty, electronics, Alexa Devices, sporting goods, toys, automotive, pets, baby, books, video games, musical instruments, office supplies, and more.", "dateLastCrawled": "2022-02-02T22:30:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Exploding</b> Gradients and the <b>Problem</b> with Overshooting \u2013 Populus Press", "url": "https://populuspress.blog/2021/12/24/exploding-gradients-and-the-problem-with-overshooting/", "isFamilyFriendly": true, "displayUrl": "https://populuspress.blog/2021/12/24/<b>exploding</b>-<b>gradients</b>-and-the-<b>problem</b>-with-overshooting", "snippet": "Similar to the vanishing <b>gradient</b>, an <b>exploding</b> <b>gradient</b> can occur when individual layer gradients turn out to be large. When the model multiples these individual gradients together during backpropagation, this can result in a huge <b>gradient</b> since multiplying many large numbers together will cause the product to skyrocket. The thing is, we want our model to make smaller adjustments as time passes. If the model is <b>learning</b> and getting closer and closer to making predictions in line with the ...", "dateLastCrawled": "2022-01-24T21:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Lecture 15: <b>Exploding</b> and Vanishing Gradients", "url": "https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L15%20Exploding%20and%20Vanishing%20Gradients.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L15 <b>Exploding</b> and...", "snippet": "1.1 <b>Learning</b> Goals Understand why gradients explode or vanish, both { in terms of the mechanics of computing the gradients { the functional relationship between the hidden units at di erent time steps Be able to analyze simple examples of iterated functions, including identifying xed points and qualitatively determining the long-term behavior from a given initialization. Know about various methods for dealing with the <b>problem</b>, and why they help: { <b>Gradient</b> clipping { Reversing the input ...", "dateLastCrawled": "2022-01-30T11:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Exploding And Vanishing Gradient Problem: Math Behind</b> The Truth | by ...", "url": "https://becominghuman.ai/exploding-and-vanishing-gradient-problem-math-behind-the-truth-2d17f9bf6a57", "isFamilyFriendly": true, "displayUrl": "https://becominghuman.ai/<b>exploding-and-vanishing-gradient-problem-math-behind</b>-the...", "snippet": "But what if the <b>gradient</b> becomes negligible? When the <b>gradient</b> becomes negligible, subtracting it from original matrix doesn\u2019t makes any sense and hence the model stops <b>learning</b>. This <b>problem</b> is called as Vanishing <b>Gradient</b> <b>Problem</b>. We\u2019ll first visualise the <b>problem</b> practically in our mind. We\u2019ll train a Deep <b>Learning</b> Model with MNIST(you ...", "dateLastCrawled": "2022-01-17T22:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Vanishing gradient</b> and <b>exploding</b> <b>gradient</b> in Neural networks | by Arun ...", "url": "https://medium.com/tech-break/vanishing-gradient-and-exploding-gradient-in-neural-networks-15950664447e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/tech-break/<b>vanishing-gradient</b>-and-<b>exploding</b>-<b>gradient</b>-in-neural...", "snippet": "<b>Vanishing gradient</b> <b>problem</b> is a common <b>problem</b> that we face while training deep neural networks.Gradients of neural networks are found during back propagation. Generally, adding more hidden layers\u2026", "dateLastCrawled": "2022-01-25T21:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "CPSC 540: <b>Machine</b> <b>Learning</b>", "url": "https://www.cs.ubc.ca/~schmidtm/Courses/440-W21/L36.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~schmidtm/Courses/440-W21/L36.pdf", "snippet": "\u2022 ^<b>Exploding</b>/vanishing <b>gradient</b> _, initialization is important, slow progress, etc. \u2022<b>Exploding</b>/vanishing <b>gradient</b> <b>problem</b> is now worse: \u2013Parameters are tied across time: \u2022<b>Gradient</b> gets magnified or shrunk exponentially at each step. \u2013Common solutions: \u2022 ^<b>Gradient</b> clipping: limit <b>gradient</b> norm to some maximum value. \u2022Long Short Term Memory (LSTM): make it easier for information to persist. Variations on Recurrent Neural Networks \u2022Bi-directional RNNs: feedforward from past and ...", "dateLastCrawled": "2021-09-01T20:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Gradient Descent</b>. It is a slippery slope, but promise it\u2026 | by Hamza ...", "url": "https://towardsdatascience.com/gradient-descent-3a7db7520711", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>gradient-descent</b>-3a7db7520711", "snippet": "tl;dr <b>Gradient Descent</b> is an optimization technique that is used to improve deep <b>learning</b> and neural network-based models by minimizing the cost function.. In our previous post, we talked about activation functions (link here) and where it is used in <b>machine</b> <b>learning</b> models.However, we also heavily used the term \u2018<b>Gradient Descent</b>\u2019 which is a key element in deep <b>learning</b> models, which are going to talk about in this post.", "dateLastCrawled": "2022-01-30T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine Learning: Text Generation, A Summary</b> \u2013 Alan&#39;s Blog", "url": "https://achungweb.wordpress.com/2017/04/14/machine-learning-text-generation-a-summary/", "isFamilyFriendly": true, "displayUrl": "https://achungweb.wordpress.com/2017/04/14/<b>machine-learning-text-generation-a-summary</b>", "snippet": "The Vanishing (and <b>Exploding</b>!) <b>Gradient</b> <b>Problem</b>. Previously, we stated that the output from the (n-1)th unit is multiplied by some hidden weight matrix H before it gets transferred to the next unit. As a program runs, therefore, a previous piece of information will be multiplied by hundreds of thousands of such matrices as it gets transferred along the RNN. As we know, repeated multiplication has the potential to grow staggering large, and our previous data will become so inflated to the ...", "dateLastCrawled": "2022-01-20T17:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The <b>Vanishing Gradient</b> <b>Problem</b>. The <b>Problem</b>, Its Causes, Its\u2026 | by Chi ...", "url": "https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/the-<b>vanishing-gradient</b>-<b>problem</b>-69bf08b15484", "snippet": "For shallow network with only a few layers that use these activations, this isn\u2019t a big <b>problem</b>. However, when more layers are used, it can cause the <b>gradient</b> to be too small for training to work effectively. Gradients of neural networks are found using backpropagation. Simply put, backpropagation finds the derivatives of the network by ...", "dateLastCrawled": "2022-02-02T06:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>machine</b> <b>learning</b> - Can the vanishing <b>gradient</b> <b>problem</b> be solved by ...", "url": "https://datascience.stackexchange.com/questions/51545/can-the-vanishing-gradient-problem-be-solved-by-multiplying-the-input-of-tanh-wi", "isFamilyFriendly": true, "displayUrl": "https://datascience.stackexchange.com/questions/51545/can-the-vanishing-<b>gradient</b>...", "snippet": "To my understanding, the vanishing <b>gradient</b> <b>problem</b> occurs when training neural networks when the <b>gradient</b> of each activation function is less than 1 such that when corrections are back-propagated through many layers, the product of these gradients becomes very small.", "dateLastCrawled": "2022-01-10T06:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Alan&#39;s Blog \u2013 Math, <b>Machine</b> <b>Learning</b>, and other Life Thoughts", "url": "https://achungweb.wordpress.com/", "isFamilyFriendly": true, "displayUrl": "https://achungweb.wordpress.com", "snippet": "The Vanishing (and <b>Exploding</b>!) <b>Gradient</b> <b>Problem</b>. Previously, we stated that the output from the (n-1)th unit is multiplied by some hidden weight matrix H before it gets transferred to the next unit. As a program runs, therefore, a previous piece of information will be multiplied by hundreds of thousands of such matrices as it gets transferred ...", "dateLastCrawled": "2022-01-19T07:52:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(exploding gradient problem)  is like +(person trying to walk down a hill)", "+(exploding gradient problem) is similar to +(person trying to walk down a hill)", "+(exploding gradient problem) can be thought of as +(person trying to walk down a hill)", "+(exploding gradient problem) can be compared to +(person trying to walk down a hill)", "machine learning +(exploding gradient problem AND analogy)", "machine learning +(\"exploding gradient problem is like\")", "machine learning +(\"exploding gradient problem is similar\")", "machine learning +(\"just as exploding gradient problem\")", "machine learning +(\"exploding gradient problem can be thought of as\")", "machine learning +(\"exploding gradient problem can be compared to\")"]}