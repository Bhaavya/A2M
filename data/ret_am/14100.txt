{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Review on Fairness in <b>Machine</b> <b>Learning</b> | ACM Computing Surveys", "url": "https://dl.acm.org/doi/10.1145/3494672", "isFamilyFriendly": true, "displayUrl": "https://dl.acm.org/doi/10.1145/3494672", "snippet": "Biases caused by \u201c<b>proxy</b>\u201d <b>attributes</b> for <b>sensitive</b> <b>attributes</b>. <b>Sensitive</b> <b>attributes</b> differentiate privileged and unprivileged groups, such as race, gender, and age, and are typically not legitimate for use in decision making. <b>Proxy</b> <b>attributes</b> are non-<b>sensitive</b> <b>attributes</b> that can be exploited to derive <b>sensitive</b> <b>attributes</b>. In the case that the dataset contains <b>proxy</b> <b>attributes</b>, the ML <b>algorithm</b> can implicitly make decisions based on the <b>sensitive</b> <b>attributes</b> under the cover of using ...", "dateLastCrawled": "2022-02-07T09:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Algorithmic Bias - University of Pittsburgh", "url": "http://philsci-archive.pitt.edu/17169/1/Algorithmic%20Bias.pdf", "isFamilyFriendly": true, "displayUrl": "philsci-archive.pitt.edu/17169/1/<b>Algorithm</b>ic Bias.pdf", "snippet": "One reason biases resist revision is that they rely on <b>proxy</b> <b>attributes</b>, seemingly innocuous <b>attributes</b> that correlate with socially-<b>sensitive</b> <b>attributes</b>, serving as proxies for the socially-<b>sensitive</b> <b>attributes</b> themselves. I argue that in both human and algo-rithmic domains, this problem presents a common dilemma for mitigation: attempts to discourage reliance on <b>proxy</b> <b>attributes</b> risk a tradeo with judgement accuracy. This problem, I contend, admits of no purely algorithmic solution. 1 ...", "dateLastCrawled": "2022-01-29T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "YouTube Monetization and Censorship by <b>Proxy</b>: A <b>Machine</b> <b>Learning</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1877050921024467", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050921024467", "snippet": "<b>Machine</b> <b>Learning</b> Our work aims to understand if a set of YouTube features (i.e., <b>attributes</b>) can predict whether a change in the values of the attribute will lead to (demonetization) censorship of the video. Anthony Zappin et al. / Procedia Computer Science 198 (2022) 23\u00e2\u20ac\u201c32 29 Author name / Procedia Computer Science 00 (2018) 000\u00e2\u20ac\u201c000 7 More simply, to find if the set of <b>attributes</b> can act as a <b>proxy</b> to the YouTube Blackbox censorship <b>algorithm</b> that heavily relies on ...", "dateLastCrawled": "2022-01-26T16:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "Which of the following is a widely used and effective <b>machine</b> <b>learning</b> <b>algorithm</b> based on the idea of bagging? A. Decision Tree B. Regression C. Classification D. Random Forest Answer : D Explanation: The Radom Forest <b>algorithm</b> builds an ensemble of Decision Trees, mostly trained with the bagging method. 12. To find the minimum or the maximum of a function, we set the gradient to zero because: A. The value of the gradient at extrema of a function is always zero B. Depends on the type of ...", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "How Did My <b>Machine</b> <b>Learning</b> Model Become Unfair? | by Divya Gopinath ...", "url": "https://towardsdatascience.com/how-did-my-machine-learning-model-become-unfair-c6508a795989", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-did-my-<b>machine</b>-<b>learning</b>-model-become-unfair-c6508a...", "snippet": "In this way, models that are \u201cblind\u201d to demographic data <b>like</b> gender and race can still encode this information through other features that are statistically correlated with protected <b>attributes</b> \u2014 this phenomenon is known as <b>proxy</b> bias. It can be hard to disentangle <b>proxy</b> bias because input features into a model are usually correlated with each other, but practitioners who carefully consider data provenance and seek out less biased alternative data to train their model can mitigate its ...", "dateLastCrawled": "2022-01-09T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Non-Discriminatory <b>Machine</b> <b>Learning</b> through Convex Fairness Criteria", "url": "https://lia.epfl.ch/wp-content/uploads/publications/Goel_Naman_AAAI.pdf", "isFamilyFriendly": true, "displayUrl": "https://lia.epfl.ch/wp-content/uploads/publications/Goel_Naman_AAAI.pdf", "snippet": "non-<b>sensitive</b> <b>attributes</b> are often correlated with the <b>sensi-tive</b> <b>attributes</b> (because of historical bias) and algorithms can learn this bias even without access to <b>sensitive</b> <b>attributes</b>. The two broad ideas in advanced approaches (Kamishima et al. 2012), (Zafar et al. 2017b), (Zafar et al. 2017c) are : i) using a regularizer term that penalizes discrimination; and ii) enforcing non-discrimination constraints on the <b>learning</b> objective. A general problem in these approaches is that they are non ...", "dateLastCrawled": "2022-01-10T07:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Measuring fairness with AlgoInsight - Deloitte Netherlands", "url": "https://www2.deloitte.com/nl/nl/pages/risk/articles/measuring-fairness-with-algoinsight.html", "isFamilyFriendly": true, "displayUrl": "https://www2.deloitte.com/nl/nl/pages/risk/articles/measuring-fairness-with-algo...", "snippet": "<b>Sensitive</b> <b>attributes</b> and <b>proxy</b> variables. How can companies ensure that their use of AI models is considered fair? First, they should check whether their use of AI-powered algorithms complies with anti-discrimination laws, says Ignatov. \u201cVarious anti-discrimination laws prohibit discrimination based on age, gender, religion, citizenship, disability, pregnancy, colour or national origin,\u201d he says. \u201cAnd customers expect companies to adhere to the highest ethical standards, which ...", "dateLastCrawled": "2022-02-03T09:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "How to <b>Choose a Pre-Processing Technique to Mitigate AI</b> Bias | by ...", "url": "https://towardsdatascience.com/how-to-choose-a-pre-processing-technique-to-mitigate-ai-bias-11ed9fc0f881", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-<b>choose-a-pre-processing-technique-to-mitigate-ai</b>...", "snippet": "When <b>proxy</b> features are included in the data, models built on feature lists that exclude <b>sensitive</b> <b>attributes</b> can still indirectly infer the association of individual records to different groups within those <b>sensitive</b> <b>attributes</b>. For example, if Zip Code or Sports are part of the features, models can infer race or gender from the records. This inference enables models to learn discriminatory behaviors from the data and encode it in the predictions. To mitigate such scenarios, the ...", "dateLastCrawled": "2022-02-03T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Obfuscation of sensitive data for machine learning</b> - <b>Stack Overflow</b>", "url": "https://stackoverflow.com/questions/31378669/obfuscation-of-sensitive-data-for-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://<b>stackoverflow.com</b>/questions/31378669", "snippet": "The original dataset contains <b>sensitive</b> information from transactions, <b>like</b> Credit card no, Customer email, client ip, origin country, etc. I have to obfuscate this <b>sensitive</b> information, before they leave my origin data-source and store them for my analysis algorithms. Some of the fields in data can be categorical and would not be difficult to obfuscate. Problem lies with the non-categorical data fields, how best should I obfuscate them to leave underlying statistical characteristics of my ...", "dateLastCrawled": "2022-01-19T00:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Can Bias Be Eliminated from Algorithms? | Yale Insights", "url": "https://insights.som.yale.edu/insights/can-bias-be-eliminated-from-algorithms", "isFamilyFriendly": true, "displayUrl": "https://insights.som.yale.edu/insights/can-bias-be-eliminated-from-<b>algorithms</b>", "snippet": "The prediction process carried out by <b>machine</b>-<b>learning</b> algorithms takes place in two stages. First, the <b>algorithm</b> is given training data so it can \u201clearn\u201d how <b>attributes</b> are linked to certain outcomes. For example, software that predicts recidivism might be trained on data containing criminals\u2019 demographic details and history. Second, the <b>algorithm</b> is given information about new cases and predicts, based on similarities to previous cases, what will happen.", "dateLastCrawled": "2022-01-28T02:18:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Algorithmic Bias - University of Pittsburgh", "url": "http://philsci-archive.pitt.edu/17169/1/Algorithmic%20Bias.pdf", "isFamilyFriendly": true, "displayUrl": "philsci-archive.pitt.edu/17169/1/<b>Algorithm</b>ic Bias.pdf", "snippet": "innocuous <b>attributes</b> that correlate with socially-<b>sensitive</b> <b>attributes</b>, serving as proxies for the socially-<b>sensitive</b> <b>attributes</b> themselves. I argue that in both human and algo- rithmic domains, this problem presents a common dilemma for mitigation: attempts to discourage reliance on <b>proxy</b> <b>attributes</b> risk a tradeo with judgement accuracy. This problem, I contend, admits of no purely algorithmic solution. 1 Introduction On March 23rd, 2016, Microsoft Corporation released Tay, an arti cial ...", "dateLastCrawled": "2022-01-29T11:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Algorithmic bias: on the implicit biases of social technology</b> ...", "url": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s11229-020-02696-y", "snippet": "Here, I discuss a problem that emerges from this fact: the <b>Proxy</b> Problem. <b>Machine</b> <b>learning</b> programmers have long struggled with eliminating algorithmic biases that are based on so-called \u2018<b>proxy</b> <b>attributes</b>\u2019: seemingly innocuous <b>attributes</b> that correlate with socially <b>sensitive</b> <b>attributes</b>, serving as proxies for the socially-<b>sensitive</b> <b>attributes</b> themselves. Footnote 23 Often, engineers attempt to protect disadvantaged social groups by preventing classification algorithms from performing ...", "dateLastCrawled": "2022-01-25T14:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "How to <b>Choose a Pre-Processing Technique to Mitigate AI</b> Bias | by ...", "url": "https://towardsdatascience.com/how-to-choose-a-pre-processing-technique-to-mitigate-ai-bias-11ed9fc0f881", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-to-<b>choose-a-pre-processing-technique-to-mitigate-ai</b>...", "snippet": "When <b>proxy</b> features are included in the data, models built on feature lists that exclude <b>sensitive</b> <b>attributes</b> can still indirectly infer the association of individual records to different groups within those <b>sensitive</b> <b>attributes</b>. For example, if Zip Code or Sports are part of the features, models can infer race or gender from the records. This inference enables models to learn discriminatory behaviors from the data and encode it in the predictions. To mitigate such scenarios, the ...", "dateLastCrawled": "2022-02-03T15:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "An SSH predictive model using <b>machine</b> <b>learning</b> with web <b>proxy</b> session ...", "url": "https://link.springer.com/article/10.1007/s10207-021-00555-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10207-021-00555-6", "snippet": "We set the labels for supervised <b>learning</b> by identifying the service <b>attributes</b> of web <b>proxy</b> logs. First, we classified SSH communications based on the destination port. TCP port 22, commonly used for SSH communications, and TCP port 2022, used for SSH communications within the environment from which the logs were collected, were labeled as SSH. Next, Web, Mobile APP, and Dev APP communications, which account for a high proportion of all communications, were classified based on their cs_user ...", "dateLastCrawled": "2022-02-03T16:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Non-Discriminatory <b>Machine</b> <b>Learning</b> through Convex Fairness Criteria", "url": "https://lia.epfl.ch/wp-content/uploads/publications/Goel_Naman_AAAI.pdf", "isFamilyFriendly": true, "displayUrl": "https://lia.epfl.ch/wp-content/uploads/publications/Goel_Naman_AAAI.pdf", "snippet": "non-<b>sensitive</b> <b>attributes</b> are often correlated with the <b>sensi-tive</b> <b>attributes</b> (because of historical bias) and algorithms can learn this bias even without access to <b>sensitive</b> <b>attributes</b>. The two broad ideas in advanced approaches (Kamishima et al. 2012), (Zafar et al. 2017b), (Zafar et al. 2017c) are : i) using a regularizer term that penalizes discrimination; and ii) enforcing non-discrimination constraints on the <b>learning</b> objective. A general problem in these approaches is that they are non ...", "dateLastCrawled": "2022-01-10T07:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "ELIMINATINGLATENTDISCRIMINATION:TRAINTHENMASK By December2018 COWLES ...", "url": "https://cowles.yale.edu/sites/default/files/files/pub/d21/d2157.pdf", "isFamilyFriendly": true, "displayUrl": "https://cowles.yale.edu/sites/default/files/files/pub/d21/d2157.pdf", "snippet": "<b>attributes</b> (e.g., race, gender, etc). Clearly, training a <b>machine</b> <b>learning</b> <b>algorithm</b> with the standard aim of loss function minimization (i.e., high accuracy, low prediction error, etc) may result in predictive behaviors that are unfair towards certain groups or individuals (Hardt et al., 2016; Liu et al., 2018; Zhang and Bareinboim, 2018). In many real-world applications, we are not allowed to use some <b>sensitive</b> features. For example, EU anti-discrimination law prohibits the use of ...", "dateLastCrawled": "2021-11-10T20:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "A Tutorial on <b>Fairness</b> in <b>Machine</b> <b>Learning</b> | by Ziyuan Zhong | Towards ...", "url": "https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/a-tutorial-on-<b>fairness</b>-in-<b>machine</b>-<b>learning</b>-3ff8ba1040cb", "snippet": "<b>Machine</b> <b>Learning</b>, the most widely used AI techniques, relies heavily on data. It is a common misconception that AI is absolutely objective. AI is objective only in the sense of <b>learning</b> what human teaches. The data provided by human can be highly-biased. It has been found in 2016 that COMPAS, the <b>algorithm</b> used for recidivism prediction produces much higher false positive rate for black people than white people(see Fig2, Larson et al. ProPublica, 2016). Fig2: The bias in COMPAS. (from Larson ...", "dateLastCrawled": "2022-02-01T18:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b> <b>learning</b> for <b>occupant-behavior-sensitive cooling energy</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1364032121000113", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1364032121000113", "snippet": "First, this research offers a <b>machine</b>-<b>learning</b> approach for predicting building energy consumption in an occupant-behavior-<b>sensitive</b> manner. The proposed approach uses a set of <b>proxy</b> variables to represent and account for the behavior, in a simplified manner, in the energy simulations. The proposed approach could help better understand the impact of occupant behavior on building energy consumption, as well as identify opportunities for behavioral energy-saving measures and efficient building ...", "dateLastCrawled": "2022-01-05T08:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fairer <b>machine</b> <b>learning</b> in the real world: Mitigating discrimination ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2053951717743530", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2053951717743530", "snippet": "It is not our aim here to analyse the extent to which privacy and data protection law and best practice is substantively in conflict with the collection and processing of <b>sensitive</b> <b>attributes</b> for the purposes of fairness-aware <b>machine</b> <b>learning</b>. 3 It may be that collection and processing for such purposes is legitimate; however, it may still not be desirable. It would require data subjects to share <b>sensitive</b> <b>attributes</b> along with non-<b>sensitive</b> ones every time their data was to be used to ...", "dateLastCrawled": "2022-01-31T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) Study and Analysis of <b>Decision Tree Based Classification Algorithms</b>", "url": "https://www.researchgate.net/publication/330138092_Study_and_Analysis_of_Decision_Tree_Based_Classification_Algorithms", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/330138092_Study_and_Analysis_of_Decision_Tree...", "snippet": "Decision tree is one of the earliest and prominent supervised <b>machine</b> <b>learning</b> algorithms used for classification.It is a tree based <b>algorithm</b> where the data is continuously split according to a ...", "dateLastCrawled": "2022-01-29T15:35:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Understanding unfair bias and product consequences in tech: Learning</b> by ...", "url": "https://medium.com/wellcome-data/understanding-unfair-bias-and-product-consequences-in-tech-learning-by-doing-1ce10b2c2535", "isFamilyFriendly": true, "displayUrl": "https://medium.com/wellcome-data/<b>understanding-unfair-bias-and-product-consequences</b>-in...", "snippet": "It <b>can</b> even be caused by <b>attributes</b> in the data that, by <b>proxy</b>, link to <b>sensitive</b> characteristics such as race and gender. For example, someone\u2019s home address may have a correlation to their ...", "dateLastCrawled": "2022-01-24T22:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Explaining Bias in Your Data</b> - Blog - Dataiku", "url": "https://blog.dataiku.com/explaining-bias-in-your-data", "isFamilyFriendly": true, "displayUrl": "https://blog.dataiku.com/<b>explaining-bias-in-your-data</b>", "snippet": "However, even if protected <b>sensitive</b> <b>attributes</b> (gender, race, etc.) are removed, <b>machine</b> <b>learning</b> models <b>can</b> still perform poorer on minority classes than on the overall population. These differences in performance might be explained when remaining features act as proxies of the protected attribute.", "dateLastCrawled": "2022-02-02T02:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "Which of the following is a widely used and effective <b>machine</b> <b>learning</b> <b>algorithm</b> based on the idea of bagging? A. Decision Tree B. Regression C. Classification D. Random Forest Answer : D Explanation: The Radom Forest <b>algorithm</b> builds an ensemble of Decision Trees, mostly trained with the bagging method. 12. To find the minimum or the maximum of a function, we set the gradient to zero because: A. The value of the gradient at extrema of a function is always zero B. Depends on the type of ...", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Algorithmic bias detection and mitigation: Best practices and policies ...", "url": "https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.brookings.edu</b>/research/<b>algorithm</b>ic-bias-detection-and-mitigation-best-", "snippet": "While it is intuitively appealing to think that an <b>algorithm</b> <b>can</b> be blind to <b>sensitive</b> <b>attributes</b>, this is not always the case. 24 Critics have pointed out that an <b>algorithm</b> may classify ...", "dateLastCrawled": "2022-02-03T04:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Can</b> Machines Find the Bilingual Advantage? <b>Machine</b> <b>Learning</b> Algorithms ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8019743/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8019743", "snippet": "Two non-language criterion were also modelled as a means to measure the validity of the <b>machine</b> <b>learning</b> <b>algorithm</b> and to act as a benchmark for the bilingualism models. The criterion were a) age, split by young (18-59) and older (60-90), and b) education, split by those who have achieved a higher education degree and those who have not. Cognitive Profile \u2013 Predictors. The cognitive profile was represented by 19 dependent variables derived from the 10 tasks the participants completed. As ...", "dateLastCrawled": "2021-12-03T05:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "InfoGram and admissible <b>machine</b> <b>learning</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10994-021-06121-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-021-06121-4", "snippet": "We have entered a new era of <b>machine</b> <b>learning</b> (ML), where the most accurate <b>algorithm</b> with superior predictive power may not even be deployable, unless it is admissible under the regulatory constraints. This has led to great interest in developing fair, transparent and trustworthy ML methods. The purpose of this article is to introduce a new information-theoretic <b>learning</b> framework (admissible <b>machine</b> <b>learning</b>) and algorithmic risk-management tools (InfoGram, L-features, ALFA-testing) that ...", "dateLastCrawled": "2022-01-31T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Fair, Transparent, and Accountable Algorithmic Decision-making ...", "url": "https://link.springer.com/article/10.1007/s13347-017-0279-x", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s13347-017-0279-x", "snippet": "A simple way to try to maximize fairness\u2014understood as the lack of bias and discrimination\u2014in <b>machine</b> <b>learning</b> is precluding the use of <b>sensitive</b> <b>attributes</b> (Calders &amp; Verwer 2010; Kamiran et al. 2010; Schermer 2011; Barocas &amp; Selbst 2016). For example, if we want a race-blind or a gender-blind decision-making process, we may exclude these <b>attributes</b> (i.e., race, gender, etc.) from the process. However, this solution has several technical problems. First, the excluded <b>attributes</b> <b>can</b> ...", "dateLastCrawled": "2022-01-28T19:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Implementation of <b>machine</b> <b>learning</b> algorithms to create diabetic ...", "url": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-0990-x", "isFamilyFriendly": true, "displayUrl": "https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-0990-x", "snippet": "<b>Machine</b> <b>learning</b> is a branch of Artificial Intelligence that is concerned with the design and development of algorithms, and it enables today\u2019s computers to have the property of <b>learning</b>. <b>Machine</b> <b>learning</b> is gradually growing and becoming a critical approach in many domains such as health, education, and business. In this paper, we applied <b>machine</b> <b>learning</b> to the diabetes dataset with the aim of recognizing patterns and combinations of factors that characterizes or explain re-admission ...", "dateLastCrawled": "2022-01-29T04:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fairer <b>machine</b> <b>learning</b> in the real world: Mitigating discrimination ...", "url": "https://journals.sagepub.com/doi/full/10.1177/2053951717743530", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/full/10.1177/2053951717743530", "snippet": "Many of the fairness issues in <b>machine</b> <b>learning</b> are primarily <b>thought</b> to arise from data. Some think, falling for what could be called the \u2018neutrality fallacy\u2019, that <b>machine</b> <b>learning</b> will provide a more even and objective treatment of individuals (Sandvig, 2015).As Latour indicates, we are often more than happy to declare value-laden issues as matters of fact, and let machines settle them for us (1999).", "dateLastCrawled": "2022-01-31T03:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Solving the transcription start site identification problem with ADAPT ...", "url": "https://www.nature.com/articles/s41598-020-57811-3", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41598-020-57811-3", "snippet": "Georgakilas, G.K., Perdikopanis, N. &amp; Hatzigeorgiou, A. Solving the transcription start site identification problem with ADAPT-CAGE: a <b>Machine</b> <b>Learning</b> <b>algorithm</b> for the analysis of CAGE data.", "dateLastCrawled": "2022-01-25T02:53:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "YouTube Monetization and Censorship by <b>Proxy</b>: A <b>Machine</b> <b>Learning</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1877050921024467", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1877050921024467", "snippet": "<b>Machine</b> <b>Learning</b> Our work aims to understand if a set of YouTube features (i.e., <b>attributes</b>) <b>can</b> predict whether a change in the values of the attribute will lead to (demonetization) censorship of the video. Anthony Zappin et al. / Procedia Computer Science 198 (2022) 23\u00e2\u20ac\u201c32 29 Author name / Procedia Computer Science 00 (2018) 000\u00e2\u20ac\u201c000 7 More simply, to find if the set of <b>attributes</b> <b>can</b> act as a <b>proxy</b> to the YouTube Blackbox censorship <b>algorithm</b> that heavily relies on ...", "dateLastCrawled": "2022-01-26T16:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Can</b> Bias Be Eliminated from Algorithms? | Yale Insights", "url": "https://insights.som.yale.edu/insights/can-bias-be-eliminated-from-algorithms", "isFamilyFriendly": true, "displayUrl": "https://insights.som.yale.edu/insights/<b>can</b>-bias-be-eliminated-from-<b>algorithms</b>", "snippet": "The prediction process carried out by <b>machine</b>-<b>learning</b> algorithms takes place in two stages. First, the <b>algorithm</b> is given training data so it <b>can</b> \u201clearn\u201d how <b>attributes</b> are linked to certain outcomes. For example, software that predicts recidivism might be trained on data containing criminals\u2019 demographic details and history. Second, the <b>algorithm</b> is given information about new cases and predicts, based on similarities to previous cases, what will happen. Since removing <b>sensitive</b> ...", "dateLastCrawled": "2022-01-28T02:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "An SSH predictive model using <b>machine</b> <b>learning</b> with web <b>proxy</b> session ...", "url": "https://link.springer.com/article/10.1007/s10207-021-00555-6", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10207-021-00555-6", "snippet": "An adversary <b>can</b> use SSH communication as a route for information leakage or hacking. Many studies have focused on TCP header analysis to detect encrypted communication. However, SSH detection using TCP header analysis is limited when changing TCP port information or modifying components of the SSH protocol. Various <b>machine</b>-<b>learning</b> (ML) techniques have been introduced to enhance network traffic classification by analyzing TCP headers. Most ML-based traffic classification research has ...", "dateLastCrawled": "2022-02-03T16:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "InfoGram and admissible <b>machine</b> <b>learning</b> | SpringerLink", "url": "https://link.springer.com/article/10.1007/s10994-021-06121-4", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s10994-021-06121-4", "snippet": "We have entered a new era of <b>machine</b> <b>learning</b> (ML), where the most accurate <b>algorithm</b> with superior predictive power may not even be deployable, unless it is admissible under the regulatory constraints. This has led to great interest in developing fair, transparent and trustworthy ML methods. The purpose of this article is to introduce a new information-theoretic <b>learning</b> framework (admissible <b>machine</b> <b>learning</b>) and algorithmic risk-management tools (InfoGram, L-features, ALFA-testing) that ...", "dateLastCrawled": "2022-01-31T17:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Hybrid rule-based botnet detection approach using <b>machine</b> <b>learning</b> for ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8372004/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8372004", "snippet": "EFFORT has five specific modules that use a controlled <b>machine</b> <b>learning</b> <b>algorithm</b> to report malicious domain names regardless of network topology or communication protocol and performs well with encrypted protocols. However, the EFFORT framework only worked with botnets that rely on the DNS administration to recognise C&amp;C servers\u2019 addresses. Host-based IDS is typically an inadaptable approach. Consequently, the observing agents must be deployed on all devices in the network to be effective ...", "dateLastCrawled": "2022-01-25T04:01:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Bias, <b>Fairness</b> and Explainability \u2014 steps towards building Responsible ...", "url": "https://medium.com/walmartglobaltech/bias-fairness-and-explainability-steps-towards-building-responsible-ai-dc735b06279", "isFamilyFriendly": true, "displayUrl": "https://medium.com/walmartglobaltech/bias-<b>fairness</b>-and-explainability-steps-towards...", "snippet": "Outcome <b>proxy</b> bias: It occurs when ... \u201cIn <b>machine</b> <b>learning</b>, a given <b>algorithm</b> is said to be fair, or to have <b>fairness</b>, if its results are independent of given variables, especially those ...", "dateLastCrawled": "2022-01-23T22:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "How Did My <b>Machine</b> <b>Learning</b> Model Become Unfair? | by Divya Gopinath ...", "url": "https://towardsdatascience.com/how-did-my-machine-learning-model-become-unfair-c6508a795989", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/how-did-my-<b>machine</b>-<b>learning</b>-model-become-unfair-c6508a...", "snippet": "This often occurs if a <b>machine</b> <b>learning</b> model is trained on data generated from complex pipelines. As an example, we <b>can</b> use Yelp\u2019s restaurant review system: Yelp allows restaurants to pay to promote their establishments on the Yelp platform, but this naturally affects how many people see advertisements for a given restaurant and thus who chooses to eat there. In this way, Yelp reviews may be unfairly biased towards larger restaurants in higher-income neighborhoods because of a conflation ...", "dateLastCrawled": "2022-01-09T11:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b> <b>learning</b> for <b>occupant-behavior-sensitive cooling energy</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S1364032121000113", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S1364032121000113", "snippet": "Four <b>machine</b>-<b>learning</b> algorithms were tested and <b>compared</b>. \u2022 The <b>machine</b>-<b>learning</b> models learn from 5760 different energy-use cases. \u2022 The most accurate prediction model achieved CV of 2.97%. \u2022 The proposed approach could help better understand the impact of occupant behavior. Abstract. Building energy consumption prediction plays a key role in energy-efficiency decision making. With the advancement in data analytics, a number of <b>machine</b> <b>learning</b>-based building energy consumption ...", "dateLastCrawled": "2022-01-05T08:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Does <b>Learning</b> Stable Features Provide Privacy Bene\ufb01ts for <b>Machine</b> ...", "url": "https://ppml-workshop.github.io/ppml20/pdfs/Mahajan_et_al.pdf", "isFamilyFriendly": true, "displayUrl": "https://ppml-workshop.github.io/ppml20/pdfs/Mahajan_et_al.pdf", "snippet": "<b>Machine</b> <b>learning</b> (ML) models have been shown to be sus-ceptible to membership inference attacks, where an attacker <b>can</b> detect whether a data point belongs to a model\u2019s training set or not [47]. These attacks have been connected to over\ufb01t-ting [57], and the risk increases when the data points come from a different distribution than the train distribution since it is generally harder for a ML model to generalize to data from a new distribution <b>compared</b> to the train distribution. Having ...", "dateLastCrawled": "2022-02-01T22:43:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "A <b>machine</b> <b>learning</b>\u2013based approach to regional\u2010scale mapping of ...", "url": "https://onlinelibrary.wiley.com/doi/10.1002/nsg.12166", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/10.1002/nsg.12166", "snippet": "Our best-performing <b>machine</b> <b>learning</b> <b>algorithm</b> compensated for the limited resolution of AEM data by using the information contained in spatial <b>attributes</b>, but using more physics-guided modelling would likely improve results. This could be achieved by using additional data sets, by using higher-resolution resistivity models, or by accounting for lateral variations in resistivities. More investigations are needed to understand how to optimally use predictions to guide the sequencing of follow ...", "dateLastCrawled": "2021-10-24T10:00:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "The choice of <b>sensitive</b> <b>attributes</b> will generally have profound consequences as it decides which groups of the population we highlight, and what conclusions we draw from our investigation. The taxonomy induced by discretization can on its own be a source of harm if it is too coarse, too granular, misleading, or inaccurate. Even the act of introducing a <b>sensitive</b> attribute on its own can be problematic. We will revisit this important discussion in the next chapter. No fairness through ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Machine</b> <b>learning</b> and applications in microbiology", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8498514/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8498514", "snippet": "<b>Machine</b> <b>learning</b> has two main <b>learning</b> modes: supervised (also known as predictive) to make future predictions from training data, and unsupervised (descriptive), which is exploratory in nature without training data, defined target or output (Mitchell 1997). Training data are the initial information used to teach supervised ML algorithms in the process of developing a model, from which the model creates and refines its rules required for prediction. Typically, training data comprises a set ...", "dateLastCrawled": "2021-12-06T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "[<b>MCQ&#39;s] Machine Learning - Last Moment Tuitions</b>", "url": "https://lastmomenttuitions.com/mcqs-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://lastmomenttuitions.com/<b>mcqs-machine-learning</b>", "snippet": "A. <b>Machine</b> <b>Learning</b> (ML) is that field of computer science. B. ML is a type of artificial intelligence that extract patterns out of raw data by using an algorithm or method. C. The main focus of ML is to allow computer systems learn from experience without being explicitly programmed or human intervention. D.", "dateLastCrawled": "2022-02-03T02:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Using Copies to Remove <b>Sensitive</b> Data: A Case Study on Fair Superhero ...", "url": "https://www.bbvaaifactory.com/publications/IBPRIA_2019.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.bbvaaifactory.com/publications/IBPRIA_2019.pdf", "snippet": "sitive data <b>attributes</b> is a crucial task when applying <b>machine</b> <b>learning</b> models to real-world problems. Particularly in company production envi-ronments, where the decision output by models may have a direct impact on individuals and predictive performance should be maintained over time. In this article, build upon [17], we propose copies as a technique to mitigate the bias of trained algorithms in circumstances where the original data is not accessible and/or the models cannot be re-trained ...", "dateLastCrawled": "2022-01-26T23:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "A Survey on Bias and <b>Fairness in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/a-survey-on-bias-and-fairness-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/a-survey-on-bias-and-<b>fairness-in-machine-learning</b>", "snippet": "Some of the existing work tries to treat <b>sensitive</b> <b>attributes</b> as noise to disregard their effect on the decision-making, while some causal methods try to use causal graphs, and disregard some paths in the causal graph that result in <b>sensitive</b> <b>attributes</b> affecting the outcome of the decision. Different bias-mitigating methods and techniques are discussed below for different domains\u2014each targeting a different problem in different areas of <b>machine</b> <b>learning</b> in detail. This can expand the ...", "dateLastCrawled": "2022-01-22T23:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Machine</b> <b>Learning</b> \u2014 Academic Research \u2014 <b>ellpha</b>", "url": "https://www.ellpha.com/academic-research/category/Machine+Learning", "isFamilyFriendly": true, "displayUrl": "https://www.<b>ellpha</b>.com/academic-research/category/<b>Machine</b>+<b>Learning</b>", "snippet": "For legal, institutional or commercial reasons, organisations might not hold the data on <b>sensitive</b> <b>attributes</b> such as gender, ethnicity, sexuality or disability needed to diagnose and mitigate emergent indirect discrimination-by-<b>proxy</b>, such as redlining. Such organisations might also lack the knowledge and capacity to identify and manage fairness issues that are emergent properties of complex sociotechnical systems. This paper presents and discusses three potential approaches to deal with ...", "dateLastCrawled": "2021-12-23T12:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The language of <b>proteins: NLP, machine learning &amp; protein sequences</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S2001037021000945", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S2001037021000945", "snippet": "By this <b>analogy</b>, common protein motifs and domains, which are the basic functional building ... suitable for small datasets, noisy data, or when the underlying signal follows simple rules (e.g. an exact motif). Deep <b>learning</b> is also <b>sensitive</b> to the lengths of the texts or sequences involved \u2013 a dataset containing protein sequence lengths ranging from 10 to 10,000 AAs can be challenging to process. The high memory and computation requirements of large, deep models (such as BERT) make ...", "dateLastCrawled": "2022-02-03T02:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Shortcut <b>learning</b> in deep neural networks | Nature <b>Machine</b> Intelligence", "url": "https://www.nature.com/articles/s42256-020-00257-z", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42256-020-00257-z", "snippet": "Deep <b>learning</b> has triggered the current rise of artificial intelligence and is the workhorse of today\u2019s <b>machine</b> intelligence. Numerous success stories have rapidly spread all over science ...", "dateLastCrawled": "2022-02-03T07:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Deep <b>Learning</b>: <b>Feedforward</b> Neural Network | by Tushar Gupta | Towards ...", "url": "https://towardsdatascience.com/deep-learning-feedforward-neural-network-26a6705dbdc7", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/deep-<b>learning</b>-<b>feedforward</b>-neural-network-26a6705dbdc7", "snippet": "Designing and training a neural network is not much di\ufb00erent from training any other <b>machine</b> <b>learning</b> model with gradient descent. The largest di\ufb00erence between the linear models we have seen so far and neural networks is that the nonlinearity of a neural network causes most interesting loss functions to become non-convex. This means that neural networks are usually trained by using iterative, gradient-based optimizers that merely drive the cost function to a very low value, rather than ...", "dateLastCrawled": "2022-01-30T17:57:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Bias in Bios: A <b>Case Study of Semantic Representation Bias in</b> a High ...", "url": "https://deepai.org/publication/bias-in-bios-a-case-study-of-semantic-representation-bias-in-a-high-stakes-setting", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/bias-in-bios-a-<b>case-study-of-semantic-representation</b>...", "snippet": "We note that the practice of \u201cscrubbing\u201d explicit gender indicators and other <b>sensitive</b> <b>attributes</b> is not unique to <b>machine</b> <b>learning</b>, and is often used as a way to mitigate the effects of implicit and explicit bias on decisions made by humans. For example, gender diversity in orchestras was significantly improved by the introduction of \u201cblind\u201d auditions, where candidates play behind a curtain (Goldin and Rouse, 2000). To quantify gender bias, we compute the true positive rate (TPR ...", "dateLastCrawled": "2022-01-16T16:25:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(proxy (sensitive attributes))  is like +(machine learning algorithm)", "+(proxy (sensitive attributes)) is similar to +(machine learning algorithm)", "+(proxy (sensitive attributes)) can be thought of as +(machine learning algorithm)", "+(proxy (sensitive attributes)) can be compared to +(machine learning algorithm)", "machine learning +(proxy (sensitive attributes) AND analogy)", "machine learning +(\"proxy (sensitive attributes) is like\")", "machine learning +(\"proxy (sensitive attributes) is similar\")", "machine learning +(\"just as proxy (sensitive attributes)\")", "machine learning +(\"proxy (sensitive attributes) can be thought of as\")", "machine learning +(\"proxy (sensitive attributes) can be compared to\")"]}