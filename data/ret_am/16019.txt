{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Minimax</b> Theorem in <b>Game</b> Theory. In <b>Game</b> Theory, there are many\u2026 | by ...", "url": "https://medium.com/intellectually-yours/minimax-theorem-in-game-theory-7a2c7fd70c7e", "isFamilyFriendly": true, "displayUrl": "https://medium.com/intellectually-yours/<b>minimax</b>-theorem-in-<b>game</b>-theory-7a2c7fd70c7e", "snippet": "Let us take the example of a simple Stag-and-Rabbit hunt <b>game</b>.There are 2 wolves in the wild, hunting for meat. They both have 2 options, to collaborate and hunt a bigger animal, <b>like</b> a stag, or ...", "dateLastCrawled": "2021-12-03T05:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "A Gentle Introduction to <b>Generative Adversarial Network Loss Functions</b>", "url": "https://machinelearningmastery.com/generative-adversarial-network-loss-functions/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>generative-adversarial-network-loss-functions</b>", "snippet": "This framing of the <b>loss</b> for the GAN was found to be useful in the analysis of the model as a <b>minimax</b> <b>game</b>, but in practice, it was found that, in practice, this <b>loss</b> function for the generator saturates. This means that if it cannot learn as quickly as the discriminator, the discriminator wins, the <b>game</b> ends, and the model cannot be trained effectively. In practice, [the <b>loss</b> function] may not provide sufficient gradient for G to learn well. Early in learning, when G is poor, D can reject ...", "dateLastCrawled": "2022-02-03T09:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Game</b>-Playing &amp; Adversarial Search", "url": "https://www.ics.uci.edu/~rickl/courses/cs-171/0-ihler-2016-fq/Lectures/Lathrop/cs-171-07a-Games-MiniMax.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ics.uci.edu/.../0-ihler-2016-fq/Lectures/Lathrop/cs-171-07a-<b>Games</b>-<b>MiniMax</b>.pdf", "snippet": "\u2022 <b>Minimax</b> optimal <b>game</b> search (5.2) ... \u2013 Winner gets reward, loser gets <b>penalty</b>. \u2013 \u201cZero sum\u201d means the sum of the reward and the <b>penalty</b> is a constant. \u2022 Formal definition as a search problem: \u2013 Initial state: Setup specified by the rules, e.g., initial board set- up of chess.- \u2013 Player(s): Defines which player has the move in a state. \u2013 Actions(s): Returns the set of legal moves in a state. \u2013 Result(s,a): Transition model defines the result of a move. \u2013 Terminal-Test ...", "dateLastCrawled": "2022-01-26T11:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Games and Adversarial Search A <b>Minimax</b> Cutting Off", "url": "https://slidetodoc.com/games-and-adversarial-search-a-minimax-cutting-off-7/", "isFamilyFriendly": true, "displayUrl": "https://slidetodoc.com/<b>games</b>-and-adversarial-search-a-<b>minimax</b>-cutting-off-7", "snippet": "Games as search \u2022 Two players, \u201cMAX\u201d and \u201cMIN\u201d \u2022 MAX moves first, and they take turns until <b>game</b> is over \u2013 Winner gets reward, loser gets <b>penalty</b> \u2013 \u201cZero sum\u201d: sum of reward and <b>penalty</b> is constant \u2022 Formal definition as a search problem: \u2013 \u2013 \u2013 Initial state: set-up defined by rules, e. g. , initial board for chess Player(s): which player has the move in state s Actions(s): set of legal moves in a state Result(s, a): transition model defines result of a move ...", "dateLastCrawled": "2021-12-29T10:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "26.1 Introduction 26.2 Two-player zero-sum", "url": "https://www.cs.jhu.edu/~mdinitz/classes/IntroAlgorithms/Fall2021/Lectures/Lecture26/lecture26.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.jhu.edu/~mdinitz/classes/IntroAlgorithms/Fall2021/Lectures/Lecture26/...", "snippet": "In this <b>game</b> the <b>minimax</b> strategy for the shooter is (2=3;1=3), which guarantees expected gain of at least 2=3 no matter what the goalie does. The <b>minimax</b> strategy for the goalie is also (2=3;1=3), which guarantees expected <b>loss</b> of at most 2=3 no matter what the shooter does. Theorem 26.2.1 (<b>Minimax</b> Theorem (von Neumann)) Every 2-player zero-sum <b>game</b> has a unique value V such that the <b>minimax</b> strategy for the row player guarantees expected gain of at least V, and the <b>minimax</b> strategy for the ...", "dateLastCrawled": "2021-12-31T16:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "TTIC 31250 An Introduction to the Theory of Machine Learning Learning ...", "url": "https://home.ttic.edu/~avrim/MLT18/GameTheory.pdf", "isFamilyFriendly": true, "displayUrl": "https://home.ttic.edu/~avrim/MLT18/<b>Game</b>Theory.pdf", "snippet": "<b>Minimax</b> optimal for goalie is also (2/3,1/3). Guarantees expected <b>loss</b> at most 2/3. <b>Minimax</b> Theorem (von Neumann 1928) \u2022 Every 2-player zero-sum <b>game</b> has a unique value V. \u2022 <b>Minimax</b> optimal strategy for R guarantees R\u2019s expected gain at least V. \u2022 <b>Minimax</b> optimal strategy for C guarantees C\u2019s expected <b>loss</b> at most V.", "dateLastCrawled": "2021-09-02T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Game-Playing &amp; Adversarial Search</b>", "url": "https://www.ics.uci.edu/~rickl/courses/cs-171/2014-wq-cs171/2014-wq-cs171-lecture-slides/2014wq171-07-Games.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ics.uci.edu/.../2014-wq-cs171-lecture-slides/2014wq171-07-<b>Games</b>.pdf", "snippet": "\u2022 <b>Minimax</b> optimal <b>game</b> search (5.2) ... \u2013 Winner gets reward, loser gets <b>penalty</b>. \u2013 \u201cZero sum\u201d means the sum of the reward and the <b>penalty</b> is a constant. \u2022 Formal definition as a search problem: \u2013 Initial state: Set-up specified by the rules, e.g., initial board configuration of chess. \u2013 Player(s): Defines which player has the move in a state. \u2013 Actions(s): Returns the set of legal moves in a state. \u2013 Result(s,a): Transition model defines the result of a move. \u2013 (2. nd ...", "dateLastCrawled": "2021-12-21T05:34:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Algorithms and Networking for Computer Games: <b>Game</b> Trees", "url": "http://staff.cs.utu.fi/staff/jouni.smed/AN4CG/Slides/04_GameTrees.pdf", "isFamilyFriendly": true, "displayUrl": "staff.cs.utu.fi/staff/jouni.smed/AN4CG/Slides/04_<b>Game</b>Trees.pdf", "snippet": "<b>Minimax</b> assumption: players are rational and try to win given a <b>game</b> tree, we know the outcome in the leaves assign the leaves to win, draw, or <b>loss</b> (or a numeric value <b>like</b> +1, 0, \u20131) according to MAX\u2019s point of view at nodes one ply above the leaves, we choose the best outcome among the children (which are leaves)", "dateLastCrawled": "2021-08-27T14:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Is <b>Game</b> Theory Real?", "url": "https://www.cs.ubc.ca/~kevinlb/teaching/cs532l%20-%202011-12/projects/2,3.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~kevinlb/teaching/cs532l - 2011-12/projects/2,3.pdf", "snippet": "Indeed, most sport games are highly dynamic in nature (<b>like</b> soccer) - everyone moves around in almost chaotic way, and the action space for each player is vast (and contin-uous). But researchers still found a nice way to tie it to the classic theory - they model a very speci\ufb01c part of a <b>game</b>, which is relatively easy to analyze. For soccer, they modeled <b>penalty</b> kick. For tennis, they modeled the serve. Note, that even for these very speci\ufb01c parts of the <b>game</b> still a lot of ...", "dateLastCrawled": "2021-09-03T08:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "How to Code the GAN <b>Training Algorithm and Loss Functions</b>", "url": "https://machinelearningmastery.com/how-to-code-the-generative-adversarial-network-training-algorithm-and-loss-functions/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/how-to-code-the-generative-adversarial-network...", "snippet": "The Generative Adversarial Network, or GAN for short, is an architecture for training a generative model. The architecture is comprised of two models. The generator that we are interested in, and a discriminator model that is used to assist in the training of the generator. Initially, both of the generator and discriminator models were implemented as Multilayer Perceptrons (MLP), although more", "dateLastCrawled": "2022-02-02T17:50:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "A Gentle Introduction to <b>Generative Adversarial Network Loss Functions</b>", "url": "https://machinelearningmastery.com/generative-adversarial-network-loss-functions/", "isFamilyFriendly": true, "displayUrl": "https://machinelearningmastery.com/<b>generative-adversarial-network-loss-functions</b>", "snippet": "This framing of the <b>loss</b> for the GAN was found to be useful in the analysis of the model as a <b>minimax</b> <b>game</b>, but in practice, it was found that, in practice, this <b>loss</b> function for the generator saturates. This means that if it cannot learn as quickly as the discriminator, the discriminator wins, the <b>game</b> ends, and the model cannot be trained effectively. In practice, [the <b>loss</b> function] may not provide sufficient gradient for G to learn well. Early in learning, when G is poor, D can reject ...", "dateLastCrawled": "2022-02-03T09:08:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Minimax</b> Optimal Algorithms for Unconstrained Linear Optimization", "url": "https://proceedings.neurips.cc/paper/5148-minimax-optimal-algorithms-for-unconstrained-linear-optimization.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/5148-<b>minimax</b>-optimal-algorithms-for-unconstrained...", "snippet": "from a suitable <b>penalty</b> on comparator points x, so L(G)=minx Gx+ (x). and Hazan and Kale [2009] consider regret with respect to the best constant-rebalanced portfolio. Our algorithm in Section 3.2 applies to <b>similar</b> problems, but does not require a \u201cno junk bonds\u201d assumption, and is in fact <b>minimax</b> optimal for a natural benchmark.", "dateLastCrawled": "2022-01-18T12:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Minimax</b> Theory Based Scheme to Detect Selfish Node and Reduce Latency ...", "url": "https://www.atlantis-press.com/article/6282.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.atlantis-press.com/article/6282.pdf", "snippet": "<b>Minimax</b> Theory . <b>Minimax</b>. 1. 1 is a decision rule used in decision theory, statistics, philosophy and <b>game</b> theory for mini mizing the possible <b>loss</b> for a worst case scenario. Alternatively, it can be thought of as maximizing the minimum gain (maximin). Originally formulated for two-player zero-sum <b>game</b> 1 2, covering", "dateLastCrawled": "2022-01-31T12:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "26.1 Introduction 26.2 Two-player zero-sum", "url": "https://www.cs.jhu.edu/~mdinitz/classes/IntroAlgorithms/Fall2021/Lectures/Lecture26/lecture26.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.jhu.edu/~mdinitz/classes/IntroAlgorithms/Fall2021/Lectures/Lecture26/...", "snippet": "The <b>minimax</b> strategy for the goalie is also (2=3;1=3), which guarantees expected <b>loss</b> of at most 2=3 no matter what the shooter does. Theorem 26.2.1 (<b>Minimax</b> Theorem (von Neumann)) Every 2-player zero-sum <b>game</b> has a unique value V such that the <b>minimax</b> strategy for the row player guarantees expected gain of at", "dateLastCrawled": "2021-12-31T16:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Assessing Policy, <b>Loss</b> and Planning Combinations in Reinforcement ...", "url": "https://deepai.org/publication/assessing-policy-loss-and-planning-combinations-in-reinforcement-learning-using-a-new-modular-architecture", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/assessing-policy-<b>loss</b>-and-planning-combinations-in...", "snippet": "Each specific <b>loss</b> algorithm is dependent on the particular characteristics of the problem, so it does not need to work for every node and <b>game</b> class. It is the responsibility of the user to instantiate a policy (and, as a consequence, a planning class) that returns compatible data classes for the <b>loss</b> algorithm intended to be used. For example, if we want to update a policy function using the number of times a node has been visited during search (like AlphaZero), we should use a planning ...", "dateLastCrawled": "2022-02-03T16:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Machine vs <b>Machine: Minimax-Optimal Defense Against Adversarial</b> ...", "url": "https://deepai.org/publication/machine-vs-machine-minimax-optimal-defense-against-adversarial-examples", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/machine-vs-<b>machine-minimax-optimal-defense-against</b>...", "snippet": "<b>Similar</b> to what we propose, others have recently considered training neural networks to generate adversarial examples ... We then describe more general form of the <b>game</b>, and algorithms for finding <b>minimax</b> solutions using sensitivity-penalized optimization. 3.1 A motivating observation. Suppose g is a classifier g: X \u2192 Y and l (g (x), y) is a <b>loss</b> function. The untargeted FGSM attack generates a perturbed example . z (x) given the clean sample x as follows: z (x) = x + \u03b7 s i g n (\u2207 x l ...", "dateLastCrawled": "2022-01-19T01:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Minimax</b> Estimation of Conditional Moment Models", "url": "https://papers.nips.cc/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Paper.pdf", "snippet": "with a second moment <b>penalty</b> on the test function and the test function space is suf\ufb01ciently rich, the estimation rate scales with the critical radius of the hypothesis and test function spaces, a quantity which typically gives tight fast rates. Our main result follows from a novel localized Rademacher analysis of statistical learning problems de\ufb01ned via <b>minimax</b> objectives. We provide applications of our main results for several hypothesis spaces used in practice such as: reproducing ...", "dateLastCrawled": "2022-01-22T08:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Is <b>Game</b> Theory Real?", "url": "https://www.cs.ubc.ca/~kevinlb/teaching/cs532l%20-%202011-12/projects/2,3.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.ubc.ca/~kevinlb/teaching/cs532l - 2011-12/projects/2,3.pdf", "snippet": "behavior <b>similar</b> to the <b>minimax</b> strategy. O\u2019Neill pointed out \ufb02aws in previous experi-ments that invalidated them as tests of mixed strategy equilibrium, like dependence on quantitative assumptions about agents utility for money, games without real opponent and so on. Consequently, he improved experimental design and the understanding of empirical validity of mixed strategy play. In O\u2019Neill\u2019s experiment, the subjects played a matching-card <b>game</b> with four cards only. Each player would ...", "dateLastCrawled": "2021-09-03T08:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Self-Supervised GANs using auxiliary rotation loss</b> | by Vandit Jain ...", "url": "https://towardsdatascience.com/self-supervised-gans-using-auxiliary-rotation-loss-60d8a929b556", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>self-supervised-gans-using-auxiliary-rotation-loss</b>-60d8...", "snippet": "GANs which is short for Generative Adversarial Networks a re a system of Neural networks in which two neural networks (Generator or Discriminator) work together and to play a <b>game</b> of <b>minimax</b> in order to learn their tasks of generating an image and trying to detect if the image is real or fake respectively. In other words, the goal of the discriminator is to tell the difference between the data generated by the generator and the real-world data we are trying to model. This method of combining ...", "dateLastCrawled": "2022-01-22T18:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Self-<b>supervised GAN: Analysis and Improvement with Multi-class Minimax</b> <b>Game</b>", "url": "https://proceedings.neurips.cc/paper/2019/file/d04cb95ba2bea9fd2f0daa8945d70f11-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/2019/file/d04cb95ba2bea9fd2f0daa8945d70f11-Paper.pdf", "snippet": "multi-class <b>minimax</b> <b>game</b>. Our proposed new SS tasks of discriminator and generator compete with each other to reach the equilibrium point. Through this competition, our proposed SS tasks are able to support the GAN task better. Speci\ufb01cally, our analysis shows that our proposed SS tasks enhance matching between P d and P g by leveraging the transformed samples used in the SS classi\ufb01cation (rotated images when [10] is applied). In addition, our design couples GAN task and SS task. To ...", "dateLastCrawled": "2022-01-24T19:31:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Penalty</b> \u2013 A <b>Game</b> of Choices | Goalden Times", "url": "http://www.goaldentimes.org/penalty-a-game-of-choices/", "isFamilyFriendly": true, "displayUrl": "www.goaldentimes.org/<b>penalty</b>-a-<b>game</b>-of-choices", "snippet": "The percentage of kicks where the choices don\u2019t coincide are more or less equally divided between LR (21.6%) and RL (21.7%). Let\u2019s now take a look at the tests of the implications of the <b>Minimax</b> theorem in the <b>penalty</b> kick <b>game</b>. The Revelation. Table 1: Pearson and Runs Tests for 20 key <b>penalty</b> takers and goalkeepers 2", "dateLastCrawled": "2021-12-13T14:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Minimax</b> Theory Based Scheme to Detect Selfish Node and Reduce Latency ...", "url": "https://www.atlantis-press.com/article/6282.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.atlantis-press.com/article/6282.pdf", "snippet": "<b>Minimax</b> Theory . <b>Minimax</b>. 1. 1 is a decision rule used in decision theory, statistics, philosophy and <b>game</b> theory for mini mizing the possible <b>loss</b> for a worst case scenario. Alternatively, it <b>can</b> <b>be thought</b> of as maximizing the minimum gain (maximin). Originally formulated for two-player zero-sum <b>game</b> 1 2, covering", "dateLastCrawled": "2022-01-31T12:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Minimax</b> Optimal Algorithms for Unconstrained Linear Optimization", "url": "https://proceedings.neurips.cc/paper/5148-minimax-optimal-algorithms-for-unconstrained-linear-optimization.pdf", "isFamilyFriendly": true, "displayUrl": "https://proceedings.neurips.cc/paper/5148-<b>minimax</b>-optimal-algorithms-for-unconstrained...", "snippet": "thorough analysis of the <b>minimax</b> behavior of the <b>game</b>, providing characteriza-tions for the value of the <b>game</b>, as well as both the player\u2019s and the adversary\u2019s optimal strategy. We show how these objects <b>can</b> be computed ef\ufb01ciently under certain circumstances, and by selecting an appropriate benchmark, we construct a novel hedging strategy for an unconstrained betting <b>game</b>. 1 Introduction <b>Minimax</b> analysis has recently been shown to be a powerful tool for the construction of online ...", "dateLastCrawled": "2022-01-18T12:02:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Minimax</b> Estimation of Conditional Moment Models", "url": "https://papers.nips.cc/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Paper.pdf", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Paper.pdf", "snippet": "with a second moment <b>penalty</b> on the test function and the test function space is suf\ufb01ciently rich, the estimation rate scales with the critical radius of the hypothesis and test function spaces, a quantity which typically gives tight fast rates. Our main result follows from a novel localized Rademacher analysis of statistical learning problems de\ufb01ned via <b>minimax</b> objectives. We provide applications of our main results for several hypothesis spaces used in practice such as: reproducing ...", "dateLastCrawled": "2022-01-22T08:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "TTIC 31250 <b>Game</b> theory An Introduction to the Theory Learning and <b>Game</b> ...", "url": "https://home.ttic.edu/~avrim/MLT20/05-13-GameTheory.pdf", "isFamilyFriendly": true, "displayUrl": "https://home.ttic.edu/~avrim/MLT20/05-13-<b>Game</b>Theory.pdf", "snippet": "<b>Minimax</b> optimal for shooter is (2/3,1/3). Guarantees expected gain at least 2/3. <b>Minimax</b> optimal for goalie is also (2/3,1/3). Guarantees expected <b>loss</b> at most 2/3. <b>Minimax</b> Theorem (von Neumann 1928) \u2022 Every 2-player zero-sum <b>game</b> has a unique value V. \u2022 <b>Minimax</b> optimal strategy for R guarantees R\u2019s expected gain at least V.", "dateLastCrawled": "2021-11-02T16:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Review for NeurIPS paper: <b>Minimax</b> Estimation of Conditional Moment Models", "url": "https://papers.nips.cc/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Review.html", "isFamilyFriendly": true, "displayUrl": "https://papers.nips.cc/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Review.html", "snippet": "The abstract makes some claims that are not explicitly mentioned later in the paper, e.g. that the estimation problem <b>can</b> <b>be thought</b> of as a zero-sum <b>game</b> between a modeler and an adversary. The article repeatedly refers to Theorem 6, but there is no Theorem 6 in the paper (just the supplementary material). The expression of instrumental variable models as a conditional moment restriction in equation (1), although used in econometrics is very different than the usual expression as ...", "dateLastCrawled": "2021-12-05T21:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "TTIC 31250 An Introduction to the Theory of Machine Learning Learning ...", "url": "https://home.ttic.edu/~avrim/MLT18/GameTheory.pdf", "isFamilyFriendly": true, "displayUrl": "https://home.ttic.edu/~avrim/MLT18/<b>Game</b>Theory.pdf", "snippet": "<b>Minimax</b> optimal for shooter is (2/3,1/3). Guarantees expected gain at least 2/3. <b>Minimax</b> optimal for goalie is also (2/3,1/3). Guarantees expected <b>loss</b> at most 2/3. <b>Minimax</b> Theorem (von Neumann 1928) \u2022 Every 2-player zero-sum <b>game</b> has a unique value V. \u2022 <b>Minimax</b> optimal strategy for R guarantees R\u2019s expected gain at least V.", "dateLastCrawled": "2021-09-02T04:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>OPTIMALITY, INSENSITIVITY, AND GAME THEORY</b> - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/B9781483198224500091", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/B9781483198224500091", "snippet": "One <b>can</b> then often find probability laws \u03be 0 (u) and \u03b7 0 (v) for which the <b>minimax</b> <b>penalty</b> S \u00af 0 = \u222c S (x, r; u, v) d \u03be 0 (u) d \u03b7 0 (v) = min \u03be max \u03b7 S \u00af (\u03be, \u03b7) is defined and which <b>can</b> be calculated as well by exchanging the operations of max and min, viz., S \u00af 0 = max \u03b7 min \u03be S (\u03be, \u03b7).", "dateLastCrawled": "2021-12-15T06:25:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Examples of Zero-Sum Games - Advanced Problem Solving Using Maple ...", "url": "https://ebrary.net/134831/mathematics/examples_ero_games", "isFamilyFriendly": true, "displayUrl": "https://ebrary.net/134831/mathematics/examples_ero_<b>games</b>", "snippet": "A <b>penalty</b> kick in soccer is a <b>game</b> between a kicker and the opposing goalie. The kicker has two alternative strategies: he might kick left or kick right. The goalie will also have two strategies: the goalie <b>can</b> dive left or right to block the kick. We will start with a very simple payoff matrix with a 1 for the player that is successful and a \u20141 for the player that is unsuccessful, assuming a correct dive blocks the kick. The payoff matrix is in Table 7.10. TABLE 7.10: <b>Penalty</b> Kick Payoffs ...", "dateLastCrawled": "2022-02-01T07:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Can</b> you <b>explain the Social Dilemma Game Theory? - Quora</b>", "url": "https://www.quora.com/Can-you-explain-the-Social-Dilemma-Game-Theory", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>Can</b>-you-<b>explain-the-Social-Dilemma-Game-Theory</b>", "snippet": "Answer (1 of 7): A Social dilemma is a collective action situation in which there is a conflict between the individual and collective interests. It is a situation in which individuals could do better if they either changed their strategies or changed the rules of the <b>game</b>. This feature introduce...", "dateLastCrawled": "2022-01-12T22:59:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Minimax</b> Theory Based Scheme to Detect Selfish Node and Reduce Latency ...", "url": "https://www.atlantis-press.com/article/6282.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.atlantis-press.com/article/6282.pdf", "snippet": "<b>Minimax</b> Theory . <b>Minimax</b>. 1. 1 is a decision rule used in decision theory, statistics, philosophy and <b>game</b> theory for mini mizing the possible <b>loss</b> for a worst case scenario. Alternatively, it <b>can</b> be thought of as maximizing the minimum gain (maximin). Originally formulated for two-player zero-sum <b>game</b> 1 2, covering", "dateLastCrawled": "2022-01-31T12:42:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Penalty</b> \u2013 A <b>Game</b> of Choices | Goalden Times", "url": "https://www.goaldentimes.org/penalty-a-game-of-choices/", "isFamilyFriendly": true, "displayUrl": "https://www.goaldentimes.org/<b>penalty</b>-a-<b>game</b>-of-choices", "snippet": "The player then plays out the strategy that will result in the minimization of his maximum <b>loss</b>. 3. Although empirical verification of strategic models of behaviour is often very difficult, the phenomenon of the <b>penalty</b> kick is a good candidate to test the implications of <b>Minimax</b> theorem in a real-life setting. The pay-off in a <b>penalty</b> kick is always constant-sum; the pay-off of the shot taker is exactly the negative of the pay-off of the goalkeeper. This is a case of pure conflict with no ...", "dateLastCrawled": "2021-11-29T07:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "X-model: Improving Data Efficiency in Deep Learning with A <b>Minimax</b> ...", "url": "https://deepai.org/publication/x-model-improving-data-efficiency-in-deep-learning-with-a-minimax-model", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/x-model-improving-data-efficiency-in-deep-learning-with...", "snippet": "<b>Compared</b> to the manually designed strategy of adding a dropout layer, this novel approach directly optimizes a <b>minimax</b> <b>loss</b> function in the hypothesis space. By maximizing the inconsistency between task-specific heads, more diverse learners are generated to further enhance the invariance to model stochasticity and thus fully explore the intrinsic structure of unlabeled data. In short, our contributions <b>can</b> be summarized as follows: We propose the \u03c7-model that jointly encourages the ...", "dateLastCrawled": "2022-01-05T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Lecture : Lower Bounds and <b>Game</b> Theory I", "url": "https://web.eecs.umich.edu/~jabernet/eecs598course/fall2013/web/notes/lec6_092313.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.eecs.umich.edu/~jabernet/eecs598course/fall2013/web/notes/lec6_092313.pdf", "snippet": "6.1 Lower Bounds and <b>Minimax</b> Regret In the context of prediction with expert advice, the concept of <b>minimax</b> regret is introduced and lower bounds on this quantity are obtained using a randomization argument. 6.1.1 <b>Minimax</b> Regret Here we introduce the concept of <b>minimax</b> regret. Consider the problem of prediction with expert advice where a <b>loss</b> function land the number of experts Nhave been \ufb01xed. By an algorithm we are referring to a rule or prescription that at each time tmakes a prediction ...", "dateLastCrawled": "2021-06-22T09:04:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Stanford University", "url": "https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/reports/6906148.pdf", "isFamilyFriendly": true, "displayUrl": "https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/reports/6906148.pdf", "snippet": "instabilities caused by a difficult <b>minimax</b> optimization problem <b>in a game</b> theoretic situ- ation, where the generator and discriminator aim to find a Nash Equilibrium. Formally, the <b>game</b> between the generator G and the discriminator D is the <b>minimax</b> objective: (1) where Pr is the data distribution and Pg is the model distribution implicitly defined by = G(z),z \u2014 p(z) (the input z to the generator is sampled from some simple noise distribution p, such as the uniform distribution or a ...", "dateLastCrawled": "2022-01-29T02:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>A smoothing trust-region Newton-CG</b> method for <b>minimax</b> problem | Request PDF", "url": "https://www.researchgate.net/publication/220559663_A_smoothing_trust-region_Newton-CG_method_for_minimax_problem", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/220559663_<b>A_smoothing_trust-region_Newton-CG</b>...", "snippet": "The maximin problem is quite relative to the <b>minimax</b> problem in <b>Game</b> Theory. So far, there are many studies on the solution methods for the <b>minimax</b> problem (Zhou and Tits 1998; Feng et al. 2008 ...", "dateLastCrawled": "2021-09-30T08:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Adversarial Data Mining: A <b>Game</b> Theoretic Approach", "url": "https://www.stat.purdue.edu/~xbw/research/MP-SAS-106-Kantarcioglu-Xi-05-01.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.stat.purdue.edu/~xbw/research/MP-SAS-106-Kantarcioglu-Xi-05-01.pdf", "snippet": "adversary is the follower in the <b>game</b>. <b>Compared</b> with [2], in [8], we let the data miner be the follower. Furthermore our formulation <b>can</b> be generalized, and the data miner <b>can</b> have the option to take an action that does not optimize its utility but instead punishes the adversary at its own expense. Improved models in which Nash strategies are played have also been proposed [1, 10]. Other <b>game</b> theoretic models play zero-sum <b>minimax</b> strategies. Globerson and Roweis [7] consider a problem where ...", "dateLastCrawled": "2021-11-14T19:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Self-Supervised GANs using auxiliary rotation loss</b> | by Vandit Jain ...", "url": "https://towardsdatascience.com/self-supervised-gans-using-auxiliary-rotation-loss-60d8a929b556", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/<b>self-supervised-gans-using-auxiliary-rotation-loss</b>-60d8...", "snippet": "GANs which is short for Generative Adversarial Networks a re a system of Neural networks in which two neural networks (Generator or Discriminator) work together and to play a <b>game</b> of <b>minimax</b> in order to learn their tasks of generating an image and trying to detect if the image is real or fake respectively. In other words, the goal of the discriminator is to tell the difference between the data generated by the generator and the real-world data we are trying to model. This method of combining ...", "dateLastCrawled": "2022-01-22T18:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Two-Stage <b>Minimax</b> Regret-Based Offering and Generation Scheduling ...", "url": "https://bura.brunel.ac.uk/bitstream/2438/23821/3/FullText.pdf", "isFamilyFriendly": true, "displayUrl": "https://bura.brunel.ac.uk/bitstream/2438/23821/3/FullText.pdf", "snippet": "issues, high transmission <b>loss</b>, high penetration of renewable generations and low reliability. Transforming from centralized generation and long-distance supply strategy to distributed generations (DGs) and local supply strategy is a promising way to address the aforementioned challenges. VPP as a cloud-based aggregation of DGs has recently attracted intensive attention. Its main objective is to maximize the pro\ufb01t via optimally bidding in the electricity market and scheduling its DGs ...", "dateLastCrawled": "2021-12-29T08:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>minimax</b>/pacman.py at master \u00b7 JakobGM/<b>minimax</b> \u00b7 GitHub", "url": "https://github.com/JakobGM/minimax/blob/master/pacman.py", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/JakobGM/<b>minimax</b>/blob/master/pacman.py", "snippet": "A GameState specifies the full <b>game</b> state, including the food, capsules, agent configurations and score changes. GameStates are used by the <b>Game</b> object to capture the actual state of the <b>game</b> and: <b>can</b> be used by agents to reason about the <b>game</b>. Much of the information in a GameState is stored in a GameStateData object. We", "dateLastCrawled": "2021-08-25T19:53:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Understanding the 3 most common <b>loss</b> functions for <b>Machine</b> <b>Learning</b> ...", "url": "https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-the-3-most-common-<b>loss</b>-functions-for...", "snippet": "A <b>loss function</b> in <b>Machine</b> <b>Learning</b> is a measure of how accurately your ML model is able to predict the expected outcome i.e the ground truth. The <b>loss function</b> will take two items as input: the output value of our model and the ground truth expected value. The output of the <b>loss function</b> is called the <b>loss</b> which is a measure of how well our model did at predicting the outcome. A high value for the <b>loss</b> means our model performed very poorly. A low value for the <b>loss</b> means our model performed ...", "dateLastCrawled": "2022-02-02T13:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "In between Real <b>or Fake: Generative Adversarial Networks (GANs</b>) | by ...", "url": "https://medium.datadriveninvestor.com/in-between-real-or-fake-generative-adversarial-networks-gans-f46f64577fb5", "isFamilyFriendly": true, "displayUrl": "https://medium.datadriveninvestor.com/in-between-real-or-fake-generative-adversarial...", "snippet": "<b>Minimax</b> <b>Loss</b>. In the paper that introduced GANs, the generator tries to minimize the following function while the discriminator tries to maximize it: Ex[log(D(x))]+Ez[log(1\u2212D(G(z)))] In this function: D(x) is the discriminator\u2019s estimate of the probability that real data instance x is real. Ex is the expected value over all real data instances. G(z) is the generator\u2019s output when given noise z. D(G(z)) is the discriminator\u2019s estimate of the probability that a fake instance is real ...", "dateLastCrawled": "2022-01-12T22:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine</b> <b>Learning</b> Concepts for Revision | by Raunak Sarada | Medium", "url": "https://raunaksarada-cse21.medium.com/machine-learning-concepts-for-revision-491384952d27", "isFamilyFriendly": true, "displayUrl": "https://raunaksarada-cse21.medium.com/<b>machine</b>-<b>learning</b>-concepts-for-revision-491384952d27", "snippet": "ML Concepts. A.I \u2014 Intelligence showed by machines which is common for humans <b>Machine</b> <b>Learning</b>- Recognize the pattern in data and automatically learn and improve through experience without explicitly being programmed Deep <b>Learning</b>- branch of <b>machine</b> <b>learning</b>.We have to deal with lots of data so in that case problems can\u2019t be solved with simple ML algorithms.", "dateLastCrawled": "2022-01-25T20:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Generative Adversarial Networks (GANs) - TJ <b>Machine</b> <b>Learning</b>", "url": "https://tjmachinelearning.com/lectures/1920/guest/Generative_Adversarial_Networks.pdf", "isFamilyFriendly": true, "displayUrl": "https://tj<b>machinelearning</b>.com/lectures/1920/guest/Generative_Adversarial_Networks.pdf", "snippet": "Figure 1: <b>Minimax</b> objective function Density Models follow a stochastic approach. To simplify, Explicit Density models pick a random variable and then compare that random variable\u2019s value in the data provided (e.g. plotting the degree that some images are green) and then tries to learn a function to estimate this nature. Implicit models, aim to generate samples to mimic the given &quot;real&quot; data (training data). 3 Concept Generative Adversarial Networks are currently the state-of-the-art ...", "dateLastCrawled": "2021-08-25T21:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Intro to Generative Adversarial Networks (GANs) - PyImageSearch", "url": "https://www.pyimagesearch.com/2021/09/13/intro-to-generative-adversarial-networks-gans/", "isFamilyFriendly": true, "displayUrl": "https://www.pyimagesearch.com/2021/09/13/intro-to-generative-adversarial-networks-gans", "snippet": "The <b>Minimax</b> game: G vs. D. Most deep <b>learning</b> models (for example, image classification) are based on optimization: finding the low value of the cost function. GANs are different because the two networks: the generator and discriminator, each has its own cost with opposite objectives: The generator tries to fool the discriminator into thinking the fake images as real; The discriminator tries to classify real and fake images correctly; The <b>minimax</b> game math function below illustrates this ...", "dateLastCrawled": "2022-02-03T12:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Synthetic data in <b>machine</b> <b>learning</b> for medicine and healthcare | Nature ...", "url": "https://www.nature.com/articles/s41551-021-00751-8", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s41551-021-00751-8", "snippet": "GANs consist of two neural networks \u2014 a generator and a discriminator \u2014 that compete in a <b>minimax</b> game (that is, a game of minimizing the maximum possible <b>loss</b>) to fool each other. For ...", "dateLastCrawled": "2022-02-03T05:33:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Understanding Generative Adversarial Networks (GANs) | by Joseph Rocca ...", "url": "https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/understanding-generative-adversarial-networks-<b>gan</b>s-cd6e...", "snippet": "This way to twist the <b>loss</b> function to go from a direct comparison to an indirect one is really something that can be very inspiring for further works in the deep <b>learning</b> area. To conclude, let\u2019s say that we don\u2019t know if the idea of GANs is really \u201cthe most interesting idea in the last 10 years in <b>Machine</b> <b>Learning</b>\u201d\u2026 but it\u2019s pretty obvious that it is, at least, one of the most interesting!", "dateLastCrawled": "2022-02-03T05:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Machine</b> <b>Learning</b> \u2013 KejiTech", "url": "https://davideliu.com/category/machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://davideliu.com/category/<b>machine</b>-<b>learning</b>", "snippet": "Challenges of <b>machine</b> <b>learning</b> <b>Machine</b> <b>learning</b> is a complex field that borrows elements from different areas such as computer science, algebra and statistics. Hence, it is not immediate, even for experts in the field, to build strong <b>machine</b> <b>learning</b> models to solve predefined task. Furthermore, those models should also be optimized with a time-consuming and repetitive hyper-parameters search in order to find the best set \u2026", "dateLastCrawled": "2022-01-09T10:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Understanding <b>Gradient Descent with Python</b>", "url": "https://rubikscode.net/2021/06/28/ml-optimization-pt-1-gradient-descent-with-python/", "isFamilyFriendly": true, "displayUrl": "https://rubikscode.net/2021/06/28/ml-optimization-pt-1-<b>gradient-descent-with-python</b>", "snippet": "In general, every <b>machine</b> <b>learning</b> algorithm is composed of three integral parts: A <b>loss</b> function.; Optimization criteria based on the <b>loss</b> function, like a cost function.; Optimization technique \u2013 this process leverages training data to find a solution for optimization criteria (cost function).; As you were able to see in previous articles, some algorithms were created intuitively and didn\u2019t have optimization criteria in mind.", "dateLastCrawled": "2022-02-02T07:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Machine Learning Gist</b> \u00b7 GitHub", "url": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "isFamilyFriendly": true, "displayUrl": "https://gist.github.com/sgoyal1012/b30d70d12b6efad88bb285e8e709b161", "snippet": "Orthogonalization - Adjust one knob to adjust one parameter, to solve one problem - The TV knob <b>analogy</b> and the car <b>analogy</b>. Chain of assumptions in <b>Machine</b> <b>Learning</b> and different knobs to say improve performance on train/dev set. Andrew Ng does not recommend Early stopping, as it is a knob that affects multiple thing at once. Setting up your goal", "dateLastCrawled": "2022-01-29T03:42:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Using Latent Codes for Class Imbalance Problem in Unsupervised ...", "url": "https://www.researchgate.net/publication/335926235_Using_Latent_Codes_for_Class_Imbalance_Problem_in_Unsupervised_Domain_Adaptation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/335926235_Using_Latent_Codes_for_Class...", "snippet": "PDF | We address the problem of severe class imbalance in unsupervised domain adaptation, when the class spaces in source and target domains diverge... | Find, read and cite all the research you ...", "dateLastCrawled": "2021-11-14T06:28:00.0000000Z", "language": "en", "isNavigational": false}], [], [], []], "all_bing_queries": ["+(minimax loss)  is like +(penalty in a game)", "+(minimax loss) is similar to +(penalty in a game)", "+(minimax loss) can be thought of as +(penalty in a game)", "+(minimax loss) can be compared to +(penalty in a game)", "machine learning +(minimax loss AND analogy)", "machine learning +(\"minimax loss is like\")", "machine learning +(\"minimax loss is similar\")", "machine learning +(\"just as minimax loss\")", "machine learning +(\"minimax loss can be thought of as\")", "machine learning +(\"minimax loss can be compared to\")"]}