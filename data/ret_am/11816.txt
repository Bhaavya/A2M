{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "On Consequentialism and <b>Fairness</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7861221/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7861221", "snippet": "All other information about <b>each</b> <b>individual</b> is represented by a feature vector, X. ... 5.1.2. <b>Individual</b> <b>Fairness</b> . A more general application of the <b>same</b> idea argues that models must make similar predictions for similar individuals (in terms of their representations, X) (Dwork et al., 2012). This proposal was originally framed as being in the Rawlsian tradition, suggesting it should be a matter of public deliberation to determine who counts as similar. However, as has been noted, the ...", "dateLastCrawled": "2022-01-28T22:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "The Four Values Framework: <b>Fairness</b>, Respect, Care and <b>Honesty</b> ...", "url": "https://link.springer.com/chapter/10.1007/978-3-030-15745-6_3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-15745-6_3", "snippet": "Other national or professional codes have incorporated values prominently into <b>individual</b> articles. For instance, at the national level in the UK, ... when moral values <b>like</b> <b>fairness</b> or respect are important, people will react when they witness instances of unfairness or disrespect; they will feel motivated to respond in some <b>way</b>. Schwartz\u2019s research investigated motivational values in general (combining our second and third meanings of \u201cvalue\u201d), and not just moral values. As noted ...", "dateLastCrawled": "2022-02-02T09:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": ": Exploring <b>fairness</b> and bias", "url": "https://fisher.wharton.upenn.edu/wp-content/uploads/2019/06/Thesisi_Sosnick.pdf", "isFamilyFriendly": true, "displayUrl": "https://fisher.wharton.upenn.edu/wp-content/uploads/2019/06/Thesisi_Sosnick.pdf", "snippet": "<b>Individual</b> <b>Fairness</b> _____ 10 7. Word Embedding _____ 11 8. Metrics for Bias in Word Embedding _____ 12 ... those <b>same</b> attributes to near accuracy from a combination of other <b>data</b> points. For example, Jernigan and Mistree developed an algorithm with a type of &quot;gay-dar&quot; which could detect a <b>person&#39;s</b> sexual orientation based on that <b>person&#39;s</b> network of Facebook friends alone (Jernigan and Mistree, 2009). Algorithm architects must be careful to ensure that their algorithms are not doing this ...", "dateLastCrawled": "2022-02-03T00:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Fairness</b>, Individuality, and Free Riding | The Philosophical Quarterly ...", "url": "https://academic.oup.com/pq/advance-article/doi/10.1093/pq/pqab075/6500929", "isFamilyFriendly": true, "displayUrl": "https://academic.oup.com/pq/advance-article/doi/10.1093/pq/pqab075/6500929", "snippet": "This paper exposes this tension between <b>fairness</b> and individuality, and proposes a <b>way</b> to resolve it. The resolution depends on an alternative approach to understanding <b>fairness</b>\u2014one that appeals to the relational goods <b>fairness</b> is meant to maintain. In particular, norms of <b>fairness</b> protect against the interactions within a relationship becoming disrespectful. Many instances of free riding are indeed disrespectful and hence unfair. But this is not always so: one can choose to live a ...", "dateLastCrawled": "2022-02-03T02:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Equality implies sameness. Equity implies fairness</b>. What is the ...", "url": "https://www.researchgate.net/post/Equality-implies-sameness-Equity-implies-fairness-What-is-the-difference-between-Equality-Equity-Please-give-your-opinion", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/<b>Equality-implies-sameness-Equity-implies-fairness</b>...", "snippet": "<b>Like</b> equity, equality aims to promote <b>fairness</b> and justice, but it can only work if everyone starts from the <b>same</b> place and needs the <b>same</b> things. Let\u2019s think for a moment about runners ...", "dateLastCrawled": "2022-01-31T08:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) On the Apparent Conflict Between <b>Individual</b> and Group <b>Fairness</b>", "url": "https://www.researchgate.net/publication/337967636_On_the_Apparent_Conflict_Between_Individual_and_Group_Fairness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/337967636_On_the_Apparent_Conflict_Between...", "snippet": "posed in the fair machine learning literature. The conclusion is. that the apparent con\ufb02ict between <b>individual</b> and group <b>fairness</b>. is more of an artefact of the blunt application of <b>fairness</b> ...", "dateLastCrawled": "2021-11-01T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Belonging at Work Isn&#39;t about Special Treatment. It&#39;s About <b>Fairness</b> ...", "url": "https://www.inc.com/emma-brudner/belonging-at-work-isnt-about-special-treatment-its-about-fairness.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.inc.com</b>/emma-brudner/belonging-at-work-isnt-about-special-treatment-its...", "snippet": "The fact that <b>fairness</b> impacts feelings of belonging -- and associated improvements in performance -- would indicate that company leaders can focus on <b>fairness</b> as a <b>way</b> of boosting belonging. On ...", "dateLastCrawled": "2022-01-08T03:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "3. Harm, Discrimination, and Measurement \u2014 <b>Fairness</b> &amp; Algorithmic ...", "url": "https://afraenkel.github.io/fairness-book/content/03-harms.html", "isFamilyFriendly": true, "displayUrl": "https://afraenkel.github.io/<b>fairness</b>-book/content/03-harms.html", "snippet": "3.2. Bias\u00b6. Bias is a term often associated with discrimination; it is milder in the severity of intent. Those that are biased against an <b>individual</b> exhibit some systematic leaning that causes the person treat this <b>individual</b> differently (in a negative <b>way</b>).. Bias also has a statistical meaning: a statistical estimator is biased if it systematically differs from the population parameter it estimates.. The two meanings are (loosely) connected, if one assumes that a <b>person\u2019s</b> decisions (i.e ...", "dateLastCrawled": "2022-02-03T01:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Confidentiality and Privacy of Personal <b>Data</b> - Health <b>Data</b> in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK236546/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK236546", "snippet": "Without preemptive federal legislation that requires <b>data</b> recipients to protect the <b>data</b> they obtain <b>in the same</b> <b>way</b> that the HDOs are required to protect those <b>data</b>, no protection can be assured. First, HDOs would have to police the uses made of <b>data</b> by all recipients, and they would have to police redisclosures. As a practical matter, these steps are impossible. Second, no mechanism such as a notarized affidavit would suffice, because such an instrument is merely a sworn statement and has ...", "dateLastCrawled": "2022-02-03T02:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Individual</b> <b>Differences in Person Perception</b> \u2013 Principles of Social ...", "url": "https://opentextbc.ca/socialpsychology/chapter/individual-and-cultural-differences-in-person-perception/", "isFamilyFriendly": true, "displayUrl": "https://opentextbc.ca/socialpsychology/chapter/<b>individual</b>-and-cultural-", "snippet": "Because we <b>each</b> use our own expectations in judgment, people may form different impressions of the <b>same</b> person performing the <b>same</b> behavior. <b>Individual</b> differences in the cognitive accessibility of a given personal characteristic may lead to more overlap in the descriptions provided by the <b>same</b> perceiver about different people than there is in those provided by different perceivers about the <b>same</b> target person.", "dateLastCrawled": "2022-01-29T22:16:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "On Consequentialism and <b>Fairness</b>", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7861221/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC7861221", "snippet": "All other information about <b>each</b> <b>individual</b> is represented by a feature vector, X. ... 5.1.2. <b>Individual</b> <b>Fairness</b> . A more general application of the <b>same</b> idea argues that models must make <b>similar</b> predictions for <b>similar</b> individuals (in terms of their representations, X) (Dwork et al., 2012). This proposal was originally framed as being in the Rawlsian tradition, suggesting it should be a matter of public deliberation to determine who counts as <b>similar</b>. However, as has been noted, the ...", "dateLastCrawled": "2022-01-28T22:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "On the Apparent Conflict Between <b>Individual</b> and Group <b>Fairness</b> | DeepAI", "url": "https://deepai.org/publication/on-the-apparent-conflict-between-individual-and-group-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../on-the-apparent-conflict-between-<b>individual</b>-and-group-<b>fairness</b>", "snippet": "Although they do not address the relationship between different worldviews and the <b>individual</b> / group <b>fairness</b> distinction, focusing on assumed worldviews in this <b>way</b> can help illustrate why apparent conflicts between <b>individual</b> and group <b>fairness</b> are misguided. The important difference is between worldviews, not whether we render our assumptions about them at the <b>individual</b> or group level. The reason for <b>treating</b> people differently on the basis of group membership is the assumption that it ...", "dateLastCrawled": "2022-01-15T05:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Equality implies sameness. Equity implies fairness</b>. What is the ...", "url": "https://www.researchgate.net/post/Equality-implies-sameness-Equity-implies-fairness-What-is-the-difference-between-Equality-Equity-Please-give-your-opinion", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/post/<b>Equality-implies-sameness-Equity-implies-fairness</b>...", "snippet": "---Justness and <b>fairness</b> in the manner of <b>treating</b> individuals are called equity. Equality is what we call, the state where everyone is at the <b>same</b> level. ---Equity is a process while equality is ...", "dateLastCrawled": "2022-01-31T08:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) On the Apparent Conflict Between <b>Individual</b> and Group <b>Fairness</b>", "url": "https://www.researchgate.net/publication/337967636_On_the_Apparent_Conflict_Between_Individual_and_Group_Fairness", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/337967636_On_the_Apparent_Conflict_Between...", "snippet": "posed in the fair machine learning literature. The conclusion is. that the apparent con\ufb02ict between <b>individual</b> and group <b>fairness</b>. is more of an artefact of the blunt application of <b>fairness</b> ...", "dateLastCrawled": "2021-11-01T06:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "3. Fair <b>Data</b> \u2013 Practical <b>Fairness</b> \u2013 Dev Tutorials", "url": "https://goois.net/3-fair-data-practical-fairness.html", "isFamilyFriendly": true, "displayUrl": "https://goois.net/3-fair-<b>data</b>-practical-<b>fairness</b>.html", "snippet": "Duplicate <b>data</b> points find their <b>way</b> into the <b>same</b> <b>data</b> set surprisingly often. Perhaps someone\u2019s name was misspelled in one round of inputs so that a person becomes more than one person, thereby having greater weight than they ought to in subsequent analyses. Worse is when this happens because of problems with a <b>data</b> pipeline, and particularly if such problems introduce bias into estimates or projects obtained from subsequently applied methods. For example, imagine a mobile app designed ...", "dateLastCrawled": "2021-12-07T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Sex / Gender Discrimination - Workplace <b>Fairness</b>", "url": "https://www.workplacefairness.org/sexual-gender-discrimination", "isFamilyFriendly": true, "displayUrl": "https://www.workplace<b>fairness</b>.org/sexual-gender-discrimination", "snippet": "Sex or gender discrimination in employment involves <b>treating</b> someone unfavorably because of the <b>person\u2019s</b> sex, whether they are applying for a job or are a current employee. Although women have made clear they have the ability to perform with the <b>same</b> skill and success in every endeavor engaged in by men, the issue of sex discrimination still holds many back. Sex discrimination, although predominantly an issue for women, can sometimes be directed towards men as well. Below, we answer many ...", "dateLastCrawled": "2022-01-30T14:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The <b>Equity Theory</b> of Motivation - How to Keep your team Motivated", "url": "https://expertprogrammanagement.com/2017/06/equity-theory/", "isFamilyFriendly": true, "displayUrl": "https://expertprogrammanagement.com/2017/06/<b>equity-theory</b>", "snippet": "As an example of <b>equity theory</b>, if an employee learns that a peer doing exactly the <b>same</b> job as them is earning more money, then they may choose to do less work, thus creating <b>fairness</b> in their eyes. Extrapolating from this, Adam\u2019s <b>Equity Theory</b> tells us that the higher an <b>individual</b>\u2019s perception of equity (<b>fairness</b>), then the more motivated they will be.", "dateLastCrawled": "2022-02-02T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "3. Harm, Discrimination, and Measurement \u2014 <b>Fairness</b> &amp; Algorithmic ...", "url": "https://afraenkel.github.io/fairness-book/content/03-harms.html", "isFamilyFriendly": true, "displayUrl": "https://afraenkel.github.io/<b>fairness</b>-book/content/03-harms.html", "snippet": "3.2. Bias\u00b6. Bias is a term often associated with discrimination; it is milder in the severity of intent. Those that are biased against an <b>individual</b> exhibit some systematic leaning that causes the person treat this <b>individual</b> differently (in a negative <b>way</b>).. Bias also has a statistical meaning: a statistical estimator is biased if it systematically differs from the population parameter it estimates.. The two meanings are (loosely) connected, if one assumes that a <b>person\u2019s</b> decisions (i.e ...", "dateLastCrawled": "2022-02-03T01:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Equity vs. Equality: What\u2019s the Difference? | Online Public Health", "url": "https://onlinepublichealth.gwu.edu/resources/equity-vs-equality/", "isFamilyFriendly": true, "displayUrl": "https://onlinepublichealth.gwu.edu/resources/equity-vs-equality", "snippet": "While the terms equity and equality may sound <b>similar</b>, the implementation of one versus the other can lead to dramatically different outcomes for marginalized people. Equality means <b>each</b> <b>individual</b> or group of people is given the <b>same</b> resources or opportunities. Equity recognizes that <b>each</b> person has different circumstances and allocates the exact resources and opportunities needed to reach an equal outcome. In the illustration below, two individuals have unequal access to a system \u2014 in ...", "dateLastCrawled": "2022-02-03T06:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Confidentiality and Privacy of Personal <b>Data</b> - Health <b>Data</b> in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK236546/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK236546", "snippet": "Without preemptive federal legislation that requires <b>data</b> recipients to protect the <b>data</b> they obtain <b>in the same</b> <b>way</b> that the HDOs are required to protect those <b>data</b>, no protection can be assured. First, HDOs would have to police the uses made of <b>data</b> by all recipients, and they would have to police redisclosures. As a practical matter, these steps are impossible. Second, no mechanism such as a notarized affidavit would suffice, because such an instrument is merely a sworn statement and has ...", "dateLastCrawled": "2022-02-03T02:09:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "[<b>Parent\u2019s Guide] Treating Kids with Fairness</b> - Noor Kids", "url": "https://blog.noorkids.com/parents-guide-treating-kids-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blog.noorkids.com/<b>parents-guide-treating-kids</b>-<b>fairness</b>", "snippet": "Most people would agree that <b>fairness</b> doesn\u2019t mean <b>treating</b> everyone the <b>same</b>. A child\u2019s circumstances sometimes demand some form of special treatment. For example, it would be ridiculous to say that a baby and a 14-year-old should have the <b>same</b> bedtime or eat the <b>same</b> food. A child who excels in his or her studies should be praised for doing so. A child who has a disability should be shown the extra care, affection, and support that is appropriate and required.", "dateLastCrawled": "2022-01-29T14:56:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "<b>Adams&#39; Equity Theory of Motivation</b>: A Simple Summary - The World of ...", "url": "https://worldofwork.io/2019/02/adams-equity-theory-of-motivation/", "isFamilyFriendly": true, "displayUrl": "https://worldofwork.io/2019/02/<b>adams-equity-theory-of-motivation</b>", "snippet": "Inputs <b>can</b> <b>be thought</b> of as the things that an <b>individual</b> does to help an organization achieve a goal. These the the things that the <b>individual</b> contributes to the organization. Often the first thing that springs to mind is the time that an <b>individual</b> spends working. However, there is actually a lot more to it than just this. There are many different types of factors that <b>can</b> <b>be thought</b> of as inputs. These include: time, education, prior experience, effort, loyalty, hard work, adaptability ...", "dateLastCrawled": "2022-02-03T06:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "The Four Values Framework: <b>Fairness</b>, Respect, Care and <b>Honesty</b> ...", "url": "https://link.springer.com/chapter/10.1007/978-3-030-15745-6_3", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/chapter/10.1007/978-3-030-15745-6_3", "snippet": "The values of one <b>individual</b> <b>can</b> be very different from those of another person. For instance, a regular income is worth a lot to a person who values routine and security; it <b>can</b> contribute to their wellbeing and happiness. Others, who value personal freedom more than routine and security, might be just as happy with occasional income, as long as they are not bound to a nine-to-five job. If most humans around the world value a particular thing, it <b>can</b> be described as a universal value ...", "dateLastCrawled": "2022-02-02T09:14:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "On the Apparent Conflict Between <b>Individual</b> and Group <b>Fairness</b> | DeepAI", "url": "https://deepai.org/publication/on-the-apparent-conflict-between-individual-and-group-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../on-the-apparent-conflict-between-<b>individual</b>-and-group-<b>fairness</b>", "snippet": "Although they do not address the relationship between different worldviews and the <b>individual</b> / group <b>fairness</b> distinction, focusing on assumed worldviews in this <b>way</b> <b>can</b> help illustrate why apparent conflicts between <b>individual</b> and group <b>fairness</b> are misguided. The important difference is between worldviews, not whether we render our assumptions about them at the <b>individual</b> or group level. The reason for <b>treating</b> people differently on the basis of group membership is the assumption that it ...", "dateLastCrawled": "2022-01-15T05:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "3. Fair <b>Data</b> \u2013 Practical <b>Fairness</b> \u2013 Dev Tutorials", "url": "https://goois.net/3-fair-data-practical-fairness.html", "isFamilyFriendly": true, "displayUrl": "https://goois.net/3-fair-<b>data</b>-practical-<b>fairness</b>.html", "snippet": "In addition to adjusting the relative weights of <b>data</b> points, pre-processing <b>can</b> relate to different representations of the input <b>data</b>, such as reducing the dimensionality of the <b>data</b> in a <b>way</b> that removes information about a protected category or finding a transformation of the <b>data</b>, including its labels, that preserves as much of the original information as possible while reducing unfairness. Pre-processing methods may be particularly attractive when contemplating the release of a <b>data</b> set ...", "dateLastCrawled": "2021-12-07T07:00:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "(PDF) <b>Fairness</b> in <b>Data</b> Science", "url": "https://www.researchgate.net/publication/352021231_Fairness_in_Data_Science", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/352021231_<b>Fairness</b>_in_<b>Data</b>_Science", "snippet": "immigrants will be treated the <b>same</b> <b>way</b> independent. of their country of origin. On top of the base legisla-tion, every state <b>can</b> hav e some additional legislation. as well [11]. However ...", "dateLastCrawled": "2021-11-30T04:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Confidentiality and Privacy of Personal <b>Data</b> - Health <b>Data</b> in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK236546/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK236546", "snippet": "Without preemptive federal legislation that requires <b>data</b> recipients to protect the <b>data</b> they obtain <b>in the same</b> <b>way</b> that the HDOs are required to protect those <b>data</b>, no protection <b>can</b> be assured. First, HDOs would have to police the uses made of <b>data</b> by all recipients, and they would have to police redisclosures. As a practical matter, these steps are impossible. Second, no mechanism such as a notarized affidavit would suffice, because such an instrument is merely a sworn statement and has ...", "dateLastCrawled": "2022-02-03T02:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "The Impact of Biases and <b>How to Prevent Their Interference in the</b> ...", "url": "https://www.insightintodiversity.com/the-impact-of-biases-and-how-to-prevent-their-interference-in-the-workplace/", "isFamilyFriendly": true, "displayUrl": "https://www.insightintodiversity.com/the-impact-of-biases-and-how-to-prevent-their...", "snippet": "<b>Thought</b> awareness <b>can</b> help you eliminate negative thinking and replace it with positive imagery. Preventing Bias in the Workplace Biased tendencies <b>can</b> also affect our professional lives. They <b>can</b> influence actions and decisions such as whom we hire or promote, how we interact with <b>persons</b> of a particular group, what advice we consider, and how we conduct performance evaluations. Biases <b>can</b> also cause us to make discriminatory decisions regarding a protected class, which <b>can</b> result in ...", "dateLastCrawled": "2022-02-02T09:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Fair - College of Policing APP", "url": "https://www.app.college.police.uk/app-content/stop-and-search/fair/", "isFamilyFriendly": true, "displayUrl": "https://www.app.college.police.uk/app-content/<b>stop-and-search</b>/fair", "snippet": "The only <b>way</b> to be certain of <b>treating</b> everyone fairly, irrespective of personal factors, is to apply an objective test as the trigger for exercising <b>stop and search</b> powers. Unless exercising a specific \u2018no suspicion\u2019 <b>stop and search</b> power \u2013 the circumstances of which are strictly limited \u2013 the officer must have reasonable grounds for suspicion before they <b>stop and search</b> someone. This means that: the officer must genuinely suspect that they will find the item searched for and; it ...", "dateLastCrawled": "2022-02-01T10:03:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Mirror Mirror", "url": "https://shiraamitchell.github.io/fairness/", "isFamilyFriendly": true, "displayUrl": "https://shiraamitchell.github.io/<b>fairness</b>", "snippet": "For <b>each</b> type of <b>data</b> we <b>can</b> attempt to interpret the two kinds of <b>fairness</b> we saw in our chart, namely $\\textrm{Decision} \\perp \\textrm{Group} ~\\vert~ \\textrm{<b>Data</b>}$ and $\\textrm{<b>Data</b>} \\perp \\textrm{Group} ~\\vert~ \\textrm{Decision}$. This gives seven conditional independence statements all of which seem to be intensely politicized in a <b>way</b> we cannot resolve here. Consider some examples:", "dateLastCrawled": "2022-01-06T19:19:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "On the Apparent Conflict Between <b>Individual</b> and Group <b>Fairness</b> | DeepAI", "url": "https://deepai.org/publication/on-the-apparent-conflict-between-individual-and-group-fairness", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/.../on-the-apparent-conflict-between-<b>individual</b>-and-group-<b>fairness</b>", "snippet": "Although they do not address the relationship between different worldviews and the <b>individual</b> / group <b>fairness</b> distinction, focusing on assumed worldviews in this <b>way</b> <b>can</b> help illustrate why apparent conflicts between <b>individual</b> and group <b>fairness</b> are misguided. The important difference is between worldviews, not whether we render our assumptions about them at the <b>individual</b> or group level. The reason for <b>treating</b> people differently on the basis of group membership is the assumption that it ...", "dateLastCrawled": "2022-01-15T05:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "5. <b>Equity Theory</b> - PSYCH 484: Work Attitudes and Job Motivation ...", "url": "https://wikispaces.psu.edu/display/PSYCH484/5.+Equity+Theory", "isFamilyFriendly": true, "displayUrl": "https://wikispaces.psu.edu/display/PSYCH484/5.+<b>Equity+Theory</b>", "snippet": "<b>Equity Theory</b> <b>can</b> be broken down into four basic propositions (Huseman, Hatfield, &amp; Miles, 1987). 1. Individuals develop their perception of <b>fairness</b> by calculating a ratio of their inputs and outcomes and then comparing this to the ratio of others (Huseman, et. al., 1987). For example, an <b>individual</b> may not perceive he is being treated fairly when he works 40 hours per week (input) and receives $500 in pay (output) while his co-worker (comparable other) works 30 hours per week (input) and ...", "dateLastCrawled": "2022-01-30T06:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Fairness</b> and <b>Affirmative Action</b> in the 21st Century | Office of the ...", "url": "https://chancellor.berkeley.edu/chancellors/berdahl/speeches/fairness-and-affirmative-action", "isFamilyFriendly": true, "displayUrl": "https://chancellor.berkeley.edu/chancellors/berdahl/speeches/<b>fairness</b>-and-affirmative...", "snippet": "<b>Individual</b> achievement, <b>individual</b> initiative, is to be encouraged; the greatest public good, it is believed, will accrue from the collective achievements of the individuals who comprise a meritocratic society. <b>Individual</b> merit should therefore be the sole criterion upon which university admission should be based. <b>Affirmative action</b>, as a product of a &quot;failed&quot; program of the Great Society, is a major barrier to the achievement of meritocratic principles because it provides access to major ...", "dateLastCrawled": "2022-02-02T10:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Adams&#39; Equity Theory of Motivation</b>: A Simple Summary - The World of ...", "url": "https://worldofwork.io/2019/02/adams-equity-theory-of-motivation/", "isFamilyFriendly": true, "displayUrl": "https://worldofwork.io/2019/02/<b>adams-equity-theory-of-motivation</b>", "snippet": "Both of these methods of responding to distress have the <b>same</b> effect for the <b>individual</b> involved. They may, though, have different impacts on others within the peer group. Individuals who feel over compensated . It might seem strange that individuals who perceive that they are overcompensated for their contributions feel distress, but they do. Individuals in this situation often feel a sense of shame or guilt for their circumstances and seek to reintroduce a sense of <b>fairness</b>. The ways that ...", "dateLastCrawled": "2022-02-03T06:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Belonging at Work Isn&#39;t about Special Treatment. It&#39;s About <b>Fairness</b> ...", "url": "https://www.inc.com/emma-brudner/belonging-at-work-isnt-about-special-treatment-its-about-fairness.html", "isFamilyFriendly": true, "displayUrl": "https://<b>www.inc.com</b>/emma-brudner/belonging-at-work-isnt-about-special-treatment-its...", "snippet": "Belonging is a feeling, and at the end of the day no one <b>can</b> (or arguably should) try to make someone feel a certain <b>way</b>. However, if leaders focus on <b>treating</b> everyone fairly, it&#39;s more likely ...", "dateLastCrawled": "2022-01-08T03:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "The <b>Equity Theory</b> of Motivation - How to Keep your team Motivated", "url": "https://expertprogrammanagement.com/2017/06/equity-theory/", "isFamilyFriendly": true, "displayUrl": "https://expertprogrammanagement.com/2017/06/<b>equity-theory</b>", "snippet": "<b>Each</b> person will respond to perceived inequality in their own <b>individual</b> and unique <b>way</b>. <b>Equity Theory</b> Examples. You <b>can</b> identify <b>Equity Theory</b> in the workplace by listening to the phrases that people use in conversation. Most commonly an <b>individual</b> will compare the role that they do to someone who is getting paid more than they are. Equity ...", "dateLastCrawled": "2022-02-02T19:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Confidentiality and Privacy of Personal <b>Data</b> - Health <b>Data</b> in the ...", "url": "https://www.ncbi.nlm.nih.gov/books/NBK236546/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/books/NBK236546", "snippet": "Without preemptive federal legislation that requires <b>data</b> recipients to protect the <b>data</b> they obtain <b>in the same</b> <b>way</b> that the HDOs are required to protect those <b>data</b>, no protection <b>can</b> be assured. First, HDOs would have to police the uses made of <b>data</b> by all recipients, and they would have to police redisclosures. As a practical matter, these steps are impossible. Second, no mechanism such as a notarized affidavit would suffice, because such an instrument is merely a sworn statement and has ...", "dateLastCrawled": "2022-02-03T02:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Individual</b> <b>Differences in Person Perception</b> \u2013 Principles of Social ...", "url": "https://opentextbc.ca/socialpsychology/chapter/individual-and-cultural-differences-in-person-perception/", "isFamilyFriendly": true, "displayUrl": "https://opentextbc.ca/socialpsychology/chapter/<b>individual</b>-and-cultural-", "snippet": "Because we <b>each</b> use our own expectations in judgment, people may form different impressions of the <b>same</b> person performing the <b>same</b> behavior. <b>Individual</b> differences in the cognitive accessibility of a given personal characteristic may lead to more overlap in the descriptions provided by the <b>same</b> perceiver about different people than there is in those provided by different perceivers about the <b>same</b> target person.", "dateLastCrawled": "2022-01-29T22:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Algorithmic <b>Fairness</b>: Tackling Bias in City Algorithms | <b>Data</b>-Smart ...", "url": "https://datasmart.ash.harvard.edu/news/article/algorithmic-fairness-tackling-bias-city-algorithms", "isFamilyFriendly": true, "displayUrl": "https://<b>data</b>smart.ash.harvard.edu/news/article/algorithmic-<b>fairness</b>-tackling-bias-city...", "snippet": "The researchers also created their own algorithm and found that it only takes two <b>data</b> points to achieve the 65 percent accuracy achieved by COMPAS: the <b>person&#39;s</b> age and the number of prior convictions. While of course this is only one test of one algorithmic tool, the research undermines the common assumption that <b>data</b>-driven predictions inevitably improve the accuracy and impartiality of government decisions.", "dateLastCrawled": "2022-02-03T10:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Mirror Mirror", "url": "https://shiraamitchell.github.io/fairness/", "isFamilyFriendly": true, "displayUrl": "https://shiraamitchell.github.io/<b>fairness</b>", "snippet": "For <b>each</b> type of <b>data</b> we <b>can</b> attempt to interpret the two kinds of <b>fairness</b> we saw in our chart, namely $\\textrm{Decision} \\perp \\textrm{Group} ~\\vert~ \\textrm{<b>Data</b>}$ and $\\textrm{<b>Data</b>} \\perp \\textrm{Group} ~\\vert~ \\textrm{Decision}$. This gives seven conditional independence statements all of which seem to be intensely politicized in a <b>way</b> we cannot resolve here. Consider some examples:", "dateLastCrawled": "2022-01-06T19:19:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Towards Analogy-Based Explanations in Machine Learning</b> | DeepAI", "url": "https://deepai.org/publication/towards-analogy-based-explanations-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/<b>towards-analogy-based-explanations-in-machine-learning</b>", "snippet": "More specifically, we take the view that an <b>analogy</b>-based approach is a viable alternative to existing approaches in the realm of explainable AI and interpretable <b>machine</b> <b>learning</b>, and that <b>analogy</b>-based explanations of the predictions produced by a <b>machine</b> <b>learning</b> algorithm can complement similarity-based explanations in a meaningful way. To corroborate these claims, we outline the basic idea of an <b>analogy</b>-based explanation and illustrate its potential usefulness by means of some examples.", "dateLastCrawled": "2022-01-10T12:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Practical <b>Individual</b> <b>Fairness</b> Algorithms \u2013 Toronto <b>Machine</b> <b>Learning</b>", "url": "https://www.torontomachinelearning.com/events/practical-individual-fairness-algorithms/", "isFamilyFriendly": true, "displayUrl": "https://www.toronto<b>machinelearning</b>.com/events/practical-<b>individual</b>-<b>fairness</b>-algorithms", "snippet": "<b>Individual</b> <b>Fairness</b> (IF) is a very intuitive and desirable notion of <b>fairness</b>: we want ML models to treat similar individuals similarly, that is, to be fair for every person. For example, two resumes of individuals that only differ in their name and gender pronouns should be treated similarly by the model. Despite the intuition, training ML/AI models that abide by this rule in theory and in practice poses several challenges. In this talk, I will introduce a notion of Distributional ...", "dateLastCrawled": "2021-12-31T05:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Finding the <b>fairness</b> in ethical <b>machine</b> <b>learning</b> - Taylor Fry", "url": "https://taylorfry.nz/articles/finding-the-fairness-in-ethical-machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://taylorfry.nz/articles/finding-the-<b>fairness</b>-in-ethical-<b>machine</b>-<b>learning</b>", "snippet": "Likewise, <b>machine</b> <b>learning</b> infrastructure is also missing, specifically, regulating the use of <b>machine</b> <b>learning</b> to ensure it\u2019s used in an ethical and beneficial way, rather than used by a small number for their advantage at the significant disadvantage of the majority. It\u2019s important we all continue to have this conversation together, and take action at <b>individual</b>, organisational, governmental and global levels to bring about a future where AI is used to help not hinder.", "dateLastCrawled": "2022-01-07T11:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Residual Unfairness in Fair <b>Machine</b> <b>Learning</b> from Prejudiced Data", "url": "http://proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "isFamilyFriendly": true, "displayUrl": "proceedings.mlr.press/v80/kallus18a/kallus18a.pdf", "snippet": "Recent work on <b>fairness</b> in <b>machine</b> <b>learning</b> proposes and analyzes competing criteria for assessing the <b>fairness</b> of <b>ma-chine</b> <b>learning</b> algorithms, where some adjustments attempt to equalize accuracy metrics across groups (Corbett-Davies etal.,2017;Kleinbergetal.,2017;Hardtetal.,2016). Other work studies how historical prejudices may be re\ufb02ected in training data such that algorithmic systems might replicate historical biases (Angwin et al., 2016; Lum &amp; Isaac, 2016; Kilbertus et al., 2017). We ...", "dateLastCrawled": "2022-01-31T07:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "RStudio AI Blog: Starting to think about AI <b>Fairness</b>", "url": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/", "isFamilyFriendly": true, "displayUrl": "https://blogs.rstudio.com/ai/posts/2021-07-15-ai-<b>fairness</b>", "snippet": "Papers on <b>fairness</b> in <b>machine</b> <b>learning</b>, as is common in fields like computer science, abound with formulae. Even the papers referenced here, though selected not for their theorems and proofs but for the ideas they harbor, are no exception. But to start thinking about <b>fairness</b> as it might apply to an ML process at hand, common language \u2013 and common sense \u2013 will do just fine. If, after analyzing your use case, you judge that the more technical results are relevant to the process in ...", "dateLastCrawled": "2022-01-31T09:59:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "How to <b>Create Unbiased ML Models | Deepchecks</b>", "url": "https://deepchecks.com/how-to-create-unbiased-ml-models/", "isFamilyFriendly": true, "displayUrl": "https://deepchecks.com/how-to-create-unbiased-ml-models", "snippet": "\u201cIn <b>machine</b> <b>learning</b>, a given algorithm is said to be fair, or to have <b>fairness</b>, if its results are independent of given variables, especially those considered sensitive, such as the traits of individuals which should not correlate with the outcome (i.e. gender, ethnicity, sexual orientation, disability, etc.).\u201d \u201c<b>Fairness</b>\u201d, Wikipedia", "dateLastCrawled": "2022-01-13T06:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Machine</b> <b>Learning</b> and Theological Traditions of <b>Analogy</b> - Davison - 2021 ...", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/moth.12682", "snippet": "12 <b>Machine</b> <b>Learning</b>, <b>Analogy</b>, and God. The texts considered in this article come from theological sources. They have offered ways to think analogically about features of the world, in this case the similarities we are beginning to see between capacities in <b>machine</b> <b>learning</b> and those in human beings and other animals. Much of the mediaeval ...", "dateLastCrawled": "2021-04-16T10:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Fairness</b> Through Awareness", "url": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.cs.toronto.edu/~zemel/documents/fairAwareItcs2012.pdf", "snippet": "this <b>individual</b>-based <b>fairness</b>, we assume a distance metric that de\ufb01nes the similarity between the individuals. This is the source of \u201cawareness\u201d in the title of this paper. We formalize this guiding principle as a Lipschitz condition on the classi\ufb01er. In our approach a classi\ufb01er is a randomized mapping from individuals to outcomes, or equivalently, a mapping from individuals to distributions over outcomes. The Lipschitz condition requires that any two individuals x;ythat are at ...", "dateLastCrawled": "2022-01-29T03:48:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "An evaluation of scanpath-comparison and <b>machine</b>-<b>learning</b> ...", "url": "https://link.springer.com/article/10.3758/s13428-016-0788-z", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.3758/s13428-016-0788-z", "snippet": "The bottom line is that scanpath-comparison algorithms and the <b>machine</b>-<b>learning</b> techniques that accompany them are powerful tools to study the dynamics of <b>analogy</b> making. In building models of <b>analogy</b> making, we want to know what the models predict and how they make those predictions. Although the tools presented in this article are more involved with prediction than with explanation, the two are hardly unrelated, especially when we know the bases of the predictions. Our overarching goal has ...", "dateLastCrawled": "2021-11-05T03:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The UX of AI Part I: Ants in Your Pants or Ants in Your Brain? | by zac ...", "url": "https://medium.com/@ZacTaschdjian/the-ux-of-ai-part-i-ants-in-your-pants-or-ants-in-your-brain-3cfef7990e7a", "isFamilyFriendly": true, "displayUrl": "https://medium.com/@ZacTaschdjian/the-ux-of-ai-part-i-ants-in-your-pants-or-ants-in...", "snippet": "The UX of AI Part II: Inscrutability in Deep Reinforcement <b>Learning</b> Neural Networks. Paper 1 is \u201cTransparency and Explanation in Deep Reinforcement <b>Learning</b> Neural Networks\u201d(Iyar, et. al. 2018 ...", "dateLastCrawled": "2022-01-22T22:46:00.0000000Z", "language": "en", "isNavigational": false}], [], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Making Fair ML Software using Trustworthy Explanation", "url": "https://www.researchgate.net/profile/Kewen-Peng-4/publication/342733939_Making_Fair_ML_Software_using_Trustworthy_Explanation/links/5fe0ddcea6fdccdcb8ef5a11/Making-Fair-ML-Software-using-Trustworthy-Explanation.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/profile/Kewen-Peng-4/publication/342733939_Making_Fair_ML...", "snippet": "<b>Machine</b> <b>learning</b> software is being used in many applications (fi-nance, hiring, admissions, criminal justice) having huge social im-pact. But sometimes the behavior of this software is biased and ...", "dateLastCrawled": "2021-09-29T17:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Making Fair <b>ML Software using Trustworthy Explanation</b> | DeepAI", "url": "https://deepai.org/publication/making-fair-ml-software-using-trustworthy-explanation", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/making-fair-<b>ml-software-using-trustworthy-explanation</b>", "snippet": "<b>Machine</b> <b>learning</b> software is being used in many applications (finance, hiring, admissions, criminal justice) having a huge social impact. But sometimes the behavior of this software is biased and it shows discrimination based on some sensitive attributes such as sex, race, etc. Prior works concentrated on finding and mitigating bias in ML models.", "dateLastCrawled": "2022-01-24T00:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "(PDF) Making fair ML software using trustworthy explanation", "url": "https://www.researchgate.net/publication/348827111_Making_fair_ML_software_using_trustworthy_explanation", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/348827111_Making_fair_ML_software_using...", "snippet": "PDF | On Dec 21, 2020, Joymallya Chakraborty and others published Making fair ML software using trustworthy explanation | Find, read and cite all the research you need on ResearchGate", "dateLastCrawled": "2021-11-13T01:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Service-Oriented Computing: 18th International Conference, ICSOC 2020 ...", "url": "https://dokumen.pub/service-oriented-computing-18th-international-conference-icsoc-2020-dubai-united-arab-emirates-december-1417-2020-proceedings-1st-ed-9783030653095-9783030653101.html", "isFamilyFriendly": true, "displayUrl": "https://<b>dokumen.pub</b>/service-oriented-computing-18th-international-conference-icsoc...", "snippet": "In a Fog environment, a Kubernetes Node is a worker <b>machine</b>, and it may be a virtual <b>machine</b> or a physical <b>machine</b> that corresponds to a node, a.k.a., Fog node. A set of Kubernetes Nodes makes up a Kubernetes cluster. A Kubernetes cluster corresponds to a set of fog nodes. Each microservice can be containerized and, therefore, it belongs to a single Docker container. A Kubernetes Pod is a group of containers with shared network and storage, that are always coscheduled and co-located. Finally ...", "dateLastCrawled": "2021-12-24T17:49:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Counterfactual Fairness: Unidentification, Bound and Algorithm ...", "url": "https://www.researchgate.net/publication/334843895_Counterfactual_Fairness_Unidentification_Bound_and_Algorithm", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/334843895_Counterfactual_Fairness_Un...", "snippet": "Fairness in <b>machine</b> <b>learning</b> has been a research subject with rapid growth recently. Many different definitions of fairness have been designed to fit different settings, e.g., equality of ...", "dateLastCrawled": "2021-12-23T12:05:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Putting <b>Fairness Principles into Practice: Challenges, Metrics</b>, and ...", "url": "https://deepai.org/publication/putting-fairness-principles-into-practice-challenges-metrics-and-improvements", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/putting-<b>fairness-principles-into-practice-challenges</b>...", "snippet": "By almost every measure, there has been an explosion in attention and research on <b>machine</b> <b>learning</b> fairness: there is a quickly growing amount of research on how to define, measure, and address <b>machine</b> <b>learning</b> fairness, and products are evaluated with these concerns in mind. Despite this significant attention, there has been much less published work detailing how fairness concerns are measured and addressed by product teams in industry. In this paper, we hope to shed light on the challenges ...", "dateLastCrawled": "2022-01-23T04:12:00.0000000Z", "language": "en", "isNavigational": false}], []], "all_bing_queries": ["+(individual fairness)  is like +(treating each person\u2019s data in the same way)", "+(individual fairness) is similar to +(treating each person\u2019s data in the same way)", "+(individual fairness) can be thought of as +(treating each person\u2019s data in the same way)", "+(individual fairness) can be compared to +(treating each person\u2019s data in the same way)", "machine learning +(individual fairness AND analogy)", "machine learning +(\"individual fairness is like\")", "machine learning +(\"individual fairness is similar\")", "machine learning +(\"just as individual fairness\")", "machine learning +(\"individual fairness can be thought of as\")", "machine learning +(\"individual fairness can be compared to\")"]}