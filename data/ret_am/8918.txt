{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Biases in <b>machine</b> <b>learning</b> models and big data analytics: The ...", "url": "https://www.cambridge.org/core/journals/international-review-of-the-red-cross/article/biases-in-machine-learning-models-and-big-data-analytics-the-international-criminal-and-humanitarian-law-implications/86BEAC9ADD165C90B2931AB2B665FFDF", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/international-review-of-the-red-cross/article/...", "snippet": "Common biases in <b>machine</b> <b>learning</b> and big data analytics. Data sets often contain biases which have the potential to unfairly disadvantage <b>certain</b> groups or to over-focus on <b>certain</b> activities to the detriment of others, and ML models or big data analytics trained on such data sets can inherit these biases.", "dateLastCrawled": "2021-12-21T11:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Biases <b>Make People Vulnerable to Misinformation</b> Spread by Social Media ...", "url": "https://www.scientificamerican.com/article/biases-make-people-vulnerable-to-misinformation-spread-by-social-media/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.scientificamerican.com</b>/article/<b>bias</b>es-make-people-vulnerable-to...", "snippet": "<b>Bias</b> in the <b>machine</b>. The third group of biases arises directly from the algorithms used to determine what people see online. Both social media platforms and search engines employ them. These ...", "dateLastCrawled": "2022-01-30T01:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "GitHub - ikasu93/Data-Science-<b>Bias</b>-Guideline: A simple <b>bias</b> guideline ...", "url": "https://github.com/ikasu93/Data-Science-Bias-Guideline", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ikasu93/Data-Science-<b>Bias</b>-Guideline", "snippet": "During the data processing, the <b>algorithm</b> can itself be <b>biased</b>, called <b>Algorithm</b> Processing <b>Bias</b>. The most obvious instance of algorithmic processing <b>bias</b> is the use of a statistically <b>biased</b> estimator in the <b>algorithm</b> for better future predictions. So, this <b>bias</b> mostly occurs due to deliberate choice. 4: Algorithmic <b>Bias</b> can also occur when the specific model is employed outside of its context, commonly known as Transfer Context <b>Bias</b>. For instance, using an autonomous system worldwide that ...", "dateLastCrawled": "2021-11-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Misinformation and biases infect <b>social media</b>, both intentionally and ...", "url": "https://theconversation.com/misinformation-and-biases-infect-social-media-both-intentionally-and-accidentally-97148", "isFamilyFriendly": true, "displayUrl": "https://theconversation.com/misinformation-and-<b>bias</b>es-infect-<b>social-media</b>-both...", "snippet": "<b>Bias</b> in the <b>machine</b>. The third group of biases arises directly from the algorithms used to determine what people see online. Both <b>social media</b> platforms and search engines employ them. These ...", "dateLastCrawled": "2022-01-30T06:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Max Min</b> - Bo Waggoner", "url": "https://www.bowaggoner.com/blahg/2019/02-23-fairness-in-ml/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.bowaggoner.com/blahg/2019/02-23-fairness-in-ml/index.html", "snippet": "Fairness in <b>Machine</b> <b>Learning</b>: A <b>Biased</b> Primer. Posted: 2019-02-23. This post will summarize some of the motivation for and definitions of fairness in ML. This is a huge and evolving topic -- here we&#39;ll focus a bit on discrimination in algorithmic decisionmaking. We&#39;ll spend relatively less time on motivations and real-world examples, <b>more</b> at the highest and lowest-level meanings of fair <b>machine</b> <b>learning</b>. Note - throughout the post, I&#39;ll try to use a variety of fairness examples such as ...", "dateLastCrawled": "2021-12-29T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Implicit Racial/Ethnic <b>Bias</b> Among Health Care Professionals and Its ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4638275/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4638275", "snippet": "<b>Certain</b> health care disciplines may be <b>more</b> prone to implicit <b>bias</b>. It is possible that <b>certain</b> types of training address problematic attitudes throughout the education period so that practicing professionals demonstrate lower levels of <b>bias</b>. Within medicine, examinations of the curriculum and comparisons by specialty may prove useful. Interventions for <b>bias</b> may look different according to the needs and realities of particular specialties. For instance, because of time pressure, critical ...", "dateLastCrawled": "2022-02-02T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What is a true error in <b>machine</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-a-true-error-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-a-true-error-in-<b>machine</b>-<b>learning</b>", "snippet": "Answer: In <b>machine</b> <b>learning</b> we always use some data to produce a model capable of generalize predictions. There is a probability distribution behind your data, what we call True probability distribution. But your data is always a restricted, <b>biased</b> and noisy sample of reality. We dot not have acc...", "dateLastCrawled": "2022-01-12T07:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Productive Conflict <b>in Group</b> Decision Making: Genuine and Contrived ...", "url": "https://www.researchgate.net/publication/222034795_Productive_Conflict_in_Group_Decision_Making_Genuine_and_Contrived_Dissent_as_Strategies_to_Counteract_Biased_Information_Seeking", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/222034795_Productive_Conflict_<b>in_Group</b>...", "snippet": "Information biases <b>like</b> attentional biases, availability, <b>biased</b> information search, shared information <b>bias</b> or information neglect (Herbert &amp; Estes, 1977;Schulz-Hardt et al., 2002) can be reduced ...", "dateLastCrawled": "2022-01-11T02:10:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "What are the various techniques of <b>machine</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-are-the-various-techniques-of-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-the-various-techniques-of-<b>machine</b>-<b>learning</b>", "snippet": "Answer (1 of 6): 1. Linear Regression To understand the working functionality of this <b>algorithm</b>, imagine how you would arrange random logs of wood in increasing order of their weight. There is a catch, however \u2013 you cannot actually weigh each log. You have to guess its weight just by looking at ...", "dateLastCrawled": "2022-01-31T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Chapter 1 Psychology quiz ANSWERS</b> - <b>Learning</b> tools &amp; flashcards, for free", "url": "https://quizlet.com/363855798/chapter-1-psychology-quiz-answers-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/363855798/<b>chapter-1-psychology-quiz-answers</b>-flash-cards", "snippet": "<b>Learn</b> vocabulary, terms, and <b>more</b> with flashcards, games, and other study tools. Search. Browse. Create. Log in Sign up. Log in Sign up. Upgrade to remove ads. Only $2.99/month . <b>Chapter 1 Psychology quiz ANSWERS</b>. STUDY. Flashcards. <b>Learn</b>. Write. Spell. Test. PLAY. Match. Gravity. Created by. makenzie_zimmerman. Terms in this set (1124) Critical thinking is _____. A. applying a set of skills to find information about a controversial topic B. applying a set of skills to understand and ...", "dateLastCrawled": "2020-12-13T16:47:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Biases in <b>machine</b> <b>learning</b> models and big data analytics: The ...", "url": "https://www.cambridge.org/core/journals/international-review-of-the-red-cross/article/biases-in-machine-learning-models-and-big-data-analytics-the-international-criminal-and-humanitarian-law-implications/86BEAC9ADD165C90B2931AB2B665FFDF", "isFamilyFriendly": true, "displayUrl": "https://www.cambridge.org/core/journals/international-review-of-the-red-cross/article/...", "snippet": "Common biases in <b>machine</b> <b>learning</b> and big data analytics. Data sets often contain biases which have the potential to unfairly disadvantage <b>certain</b> groups or to over-focus on <b>certain</b> activities to the detriment of others, and ML models or big data analytics trained on such data sets can inherit these biases.", "dateLastCrawled": "2021-12-21T11:19:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "GitHub - ikasu93/Data-Science-<b>Bias</b>-Guideline: A simple <b>bias</b> guideline ...", "url": "https://github.com/ikasu93/Data-Science-Bias-Guideline", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ikasu93/Data-Science-<b>Bias</b>-Guideline", "snippet": "During the data processing, the <b>algorithm</b> can itself be <b>biased</b>, called <b>Algorithm</b> Processing <b>Bias</b>. The most obvious instance of algorithmic processing <b>bias</b> is the use of a statistically <b>biased</b> estimator in the <b>algorithm</b> for better future predictions. So, this <b>bias</b> mostly occurs due to deliberate choice. 4: Algorithmic <b>Bias</b> can also occur when the specific model is employed outside of its context, commonly known as Transfer Context <b>Bias</b>. For instance, using an autonomous system worldwide that ...", "dateLastCrawled": "2021-11-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Max Min</b> - Bo Waggoner", "url": "https://www.bowaggoner.com/blahg/2019/02-23-fairness-in-ml/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.bowaggoner.com/blahg/2019/02-23-fairness-in-ml/index.html", "snippet": "Fairness in <b>Machine</b> <b>Learning</b>: A <b>Biased</b> Primer. Posted: 2019-02-23. This post will summarize some of the motivation for and definitions of fairness in ML. This is a huge and evolving topic -- here we&#39;ll focus a bit on discrimination in algorithmic decisionmaking. We&#39;ll spend relatively less time on motivations and real-world examples, <b>more</b> at the highest and lowest-level meanings of fair <b>machine</b> <b>learning</b>. Note - throughout the post, I&#39;ll try to use a variety of fairness examples such as ...", "dateLastCrawled": "2021-12-29T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Machine Learning</b> | <b>AI Strategy &amp; Policy</b>", "url": "https://aistrategyblog.com/category/machine-learning/", "isFamilyFriendly": true, "displayUrl": "https://aistrategyblog.com/category/<b>machine-learning</b>", "snippet": "While there are 42 (i.e., many, but 42 is the answer to many <b>things</b> unknown and known) definitions out there defining fairness (or <b>bias</b>), I will define it as \u201ca systematic and significant difference in outcome of a given policy between distinct and statistically meaningful groups\u201d (note that in case of <b>in-group</b> systematic <b>bias</b> it often means that there actually are distinct sub-groups within that main group). So, yes this is a challenge.", "dateLastCrawled": "2022-01-16T11:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "What are <b>some problem statements for machine learning or</b> data ... - Quora", "url": "https://www.quora.com/What-are-some-problem-statements-for-machine-learning-or-data-analytics", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>some-problem-statements-for-machine-learning-or</b>-data...", "snippet": "Answer (1 of 2): This is pretty open ended question and frankly there\u2019s absolutely no limit to the problem statements that can be phrased for different domain, technology, and requirement. Now, when you say \u2018Problem statement\u2019, please understand, you\u2019re talking about the \u2018Business Problem Statem...", "dateLastCrawled": "2022-01-21T20:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "<b>Chapter 1 Psychology quiz ANSWERS</b> - <b>Learning</b> tools &amp; flashcards, for free", "url": "https://quizlet.com/363855798/chapter-1-psychology-quiz-answers-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/363855798/<b>chapter-1-psychology-quiz-answers</b>-flash-cards", "snippet": "<b>Learn</b> vocabulary, terms, and <b>more</b> with flashcards, games, and other study tools. Search. Browse. Create. Log in Sign up. Log in Sign up. Upgrade to remove ads. Only $2.99/month . <b>Chapter 1 Psychology quiz ANSWERS</b>. STUDY. Flashcards. <b>Learn</b>. Write. Spell. Test. PLAY. Match. Gravity. Created by. makenzie_zimmerman. Terms in this set (1124) Critical thinking is _____. A. applying a set of skills to find information about a controversial topic B. applying a set of skills to understand and ...", "dateLastCrawled": "2020-12-13T16:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Introduction to MAchine Learning &amp; Knowledge Extraction (MAKE</b>)", "url": "https://www.researchgate.net/publication/318118437_Introduction_to_MAchine_Learning_Knowledge_Extraction_MAKE", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/318118437_Introduction_<b>to_MAchine</b>_<b>Learning</b>...", "snippet": "Abstract and Figures. The grand goal of <b>Machine</b> <b>Learning</b> is to develop software which can <b>learn</b> from previous experience\u2014<b>similar</b> to how we humans do. Ultimately, to reach a level of usable ...", "dateLastCrawled": "2022-01-22T07:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Precondition for <b>machine</b> <b>learning</b> techniques? - Quora", "url": "https://www.quora.com/Precondition-for-machine-learning-techniques", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/Precondition-for-<b>machine</b>-<b>learning</b>-techniques", "snippet": "Answer: This is a great question. As with all great questions, the answer is a bit complicated. Let&#39;s take the first question - what if you have independent variables that aren&#39;t correlated with any dependent variable? Another way to state this problem is that you have many potential causes for ...", "dateLastCrawled": "2022-01-31T16:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) Miroslav Kubat <b>An Introduction to Machine Learning Second Edition</b> ...", "url": "https://www.academia.edu/43873294/Miroslav_Kubat_An_Introduction_to_Machine_Learning_Second_Edition", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/43873294/Miroslav_Kubat_<b>An_Introduction_to_Machine_Learning</b>...", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-02-03T05:26:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "CH 7-9 Flashcards | Quizlet", "url": "https://quizlet.com/515124972/ch-7-9-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/515124972/ch-7-9-flash-cards", "snippet": "Children <b>learn</b> to read faster by the use of phonics than by the whole-word method. Children <b>learn</b> to read faster by the whole-word method than by the use of phonics. People who describe an event in words remember it better than those who don&#39;t. You <b>more</b> <b>easily</b> recognize a letter when it is part of a word than when it is alone.", "dateLastCrawled": "2022-01-24T01:46:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "GitHub - ikasu93/Data-Science-<b>Bias</b>-Guideline: A simple <b>bias</b> guideline ...", "url": "https://github.com/ikasu93/Data-Science-Bias-Guideline", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ikasu93/Data-Science-<b>Bias</b>-Guideline", "snippet": "During the data processing, the <b>algorithm</b> <b>can</b> itself be <b>biased</b>, called <b>Algorithm</b> Processing <b>Bias</b>. The most obvious instance of algorithmic processing <b>bias</b> is the use of a statistically <b>biased</b> estimator in the <b>algorithm</b> for better future predictions. So, this <b>bias</b> mostly occurs due to deliberate choice. 4: Algorithmic <b>Bias</b> <b>can</b> also occur when the specific model is employed outside of its context, commonly known as Transfer Context <b>Bias</b>. For instance, using an autonomous system worldwide that ...", "dateLastCrawled": "2021-11-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Implicit Racial/Ethnic <b>Bias</b> Among Health Care Professionals and Its ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4638275/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4638275", "snippet": "<b>Certain</b> health care disciplines may be <b>more</b> prone to implicit <b>bias</b>. It is possible that <b>certain</b> types of training address problematic attitudes throughout the education period so that practicing professionals demonstrate lower levels of <b>bias</b>. Within medicine, examinations of the curriculum and comparisons by specialty may prove useful. Interventions for <b>bias</b> may look different according to the needs and realities of particular specialties. For instance, because of time pressure, critical ...", "dateLastCrawled": "2022-02-02T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Max Min</b> - Bo Waggoner", "url": "https://www.bowaggoner.com/blahg/2019/02-23-fairness-in-ml/index.html", "isFamilyFriendly": true, "displayUrl": "https://www.bowaggoner.com/blahg/2019/02-23-fairness-in-ml/index.html", "snippet": "Fairness in <b>Machine</b> <b>Learning</b>: A <b>Biased</b> Primer. Posted: 2019-02-23. This post will summarize some of the motivation for and definitions of fairness in ML. This is a huge and evolving topic -- here we&#39;ll focus a bit on discrimination in algorithmic decisionmaking. We&#39;ll spend relatively less time on motivations and real-world examples, <b>more</b> at the highest and lowest-level meanings of fair <b>machine</b> <b>learning</b>. Note - throughout the post, I&#39;ll try to use a variety of fairness examples such as ...", "dateLastCrawled": "2021-12-29T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Chapter 17. Analyzing Community Problems and Solutions | Section 2 ...", "url": "https://ctb.ku.edu/en/table-of-contents/analyze/analyze-community-problems-and-solutions/think-critically/main", "isFamilyFriendly": true, "displayUrl": "https://ctb.ku.edu/en/table-of-contents/analyze/analyze-community-problems-and...", "snippet": "A <b>bias</b> is not necessarily bad: it is simply a preferred way of looking at <b>things</b>. You <b>can</b> be racially <b>biased</b>, but you <b>can</b> also be <b>biased</b> toward looking at all humans as one family. You <b>can</b> be <b>biased</b> toward a liberal or conservative political point of view, or toward or against tolerance. Regardless of whether most of us would consider a particular <b>bias</b> good or bad, not seeing it <b>can</b> limit how we resolve a problem or issue. It&#39;s oriented toward the problem, issue, or situation that you&#39;re ...", "dateLastCrawled": "2022-02-03T02:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Socio-cognitive biases in folk AI ethics and risk discourse | SpringerLink", "url": "https://link.springer.com/article/10.1007/s43681-021-00060-5", "isFamilyFriendly": true, "displayUrl": "https://link.springer.com/article/10.1007/s43681-021-00060-5", "snippet": "A <b>machine</b> <b>learning</b> <b>algorithm</b> <b>can</b> be trained to perform some task well, but it is practically impossible for a human to follow the actual decision process behind its performance. There is ongoing ethical discussion on this problem, especially concerning the transparency of algorithmic decisions affecting human lives , but we are not going to address it here. Of interest in this context is the psychological side to the black box problem. We have the tendency to view the decisions made by a ...", "dateLastCrawled": "2021-12-29T15:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "What are <b>some problem statements for machine learning or</b> data ... - Quora", "url": "https://www.quora.com/What-are-some-problem-statements-for-machine-learning-or-data-analytics", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-<b>some-problem-statements-for-machine-learning-or</b>-data...", "snippet": "Answer (1 of 2): This is pretty open ended question and frankly there\u2019s absolutely no limit to the problem statements that <b>can</b> be phrased for different domain, technology, and requirement. Now, when you say \u2018Problem statement\u2019, please understand, you\u2019re talking about the \u2018Business Problem Statem...", "dateLastCrawled": "2022-01-21T20:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) <b>Boltzmann machines: Constraint satisfaction networks that</b> <b>learn</b> ...", "url": "https://www.academia.edu/631729/Boltzmann_machines_Constraint_satisfaction_networks_that_learn", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/631729/<b>Boltzmann_machines_Constraint_satisfaction_networks</b>...", "snippet": "The Boltzmann <b>Machine</b> <b>learning</b> <b>algorithm</b> <b>can</b> also be formulated as an input-output model. The visible units are divided into an input set I and an output set O, and an environment specifies a set of conditional probabilities of the form P{Op\\Ia). During the &quot;training&quot; phase the environment clamps both the input and output units, and pijs are estimated. During the &quot;testing&quot; phase the input units are clamped and the output units and hidden units free-run, and p&#39;-s are estimated. The ...", "dateLastCrawled": "2022-01-03T11:38:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Frontiers | <b>Illusions of causality</b>: how they <b>bias</b> our everyday thinking ...", "url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00888/full", "isFamilyFriendly": true, "displayUrl": "https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00888", "snippet": "Examples of intuitive assessment of causality (sometimes correct, sometimes <b>biased</b>) <b>can</b> be found <b>easily</b> in everyday life. A company could initiate a new training program, attract <b>more</b> clients, and assume that the new program was effective. Upon carrying a good-luck charm and playing a fantastic game, one cannot avoid feeling that the charm had a critical role in victory. This tendency to detect causal relationships is so strong that people infer them even when they are rationally convinced ...", "dateLastCrawled": "2022-01-29T18:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Chapter 1 Psychology quiz ANSWERS</b> - <b>Learning</b> tools &amp; flashcards, for free", "url": "https://quizlet.com/363855798/chapter-1-psychology-quiz-answers-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/363855798/<b>chapter-1-psychology-quiz-answers</b>-flash-cards", "snippet": "Char heard from her friends that marijuana use <b>can</b> cure glaucoma so it should be legal in all 50 states. Char knows that she is <b>biased</b> in favor of marijuana legalization, so she decides to exercise some skepticism about this claim. She researches where her friends got their information, how reliable it is, and what other sources say about ...", "dateLastCrawled": "2020-12-13T16:47:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "(PDF) <b>Understanding perception of algorithmic decisions: Fairness</b> ...", "url": "https://www.researchgate.net/publication/323651524_Understanding_perception_of_algorithmic_decisions_Fairness_trust_and_emotion_in_response_to_algorithmic_management", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323651524_Understanding_perception_of...", "snippet": "\u2018\u2018I think the <b>algorithm</b> is <b>more</b> than capable of. assessing the applicability of people [for] the job. I.e., it ought to be able to <b>easily</b> assess GPA, and the. number and duration of previous ...", "dateLastCrawled": "2022-01-27T13:17:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Biases in <b>machine</b> <b>learning</b> models and big data analytics: The ...", "url": "http://international-review.icrc.org/articles/biases-machine-learning-big-data-analytics-ihl-implications-913", "isFamilyFriendly": true, "displayUrl": "international-review.icrc.org/articles/<b>bias</b>es-<b>machine</b>-<b>learning</b>-big-data-analytics-ihl...", "snippet": "Non-response <b>bias</b> or participation <b>bias</b> is a form of selection <b>bias</b> that occurs when users from <b>certain</b> groups opt out from participating in the process, such that the data set ends up being unrepresentative due to participation gaps in the data collection process.41 This <b>bias</b> <b>can</b> be prevalent where marginalized or traditionally under-represented groups distrust the process and are consequently less likely to participate in it.42 This also happens to be a common issue in internal armed ...", "dateLastCrawled": "2022-02-01T10:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Implicit Racial/Ethnic <b>Bias</b> Among Health Care Professionals and Its ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4638275/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC4638275", "snippet": "<b>Certain</b> health care disciplines may be <b>more</b> prone to implicit <b>bias</b>. It is possible that <b>certain</b> types of training address problematic attitudes throughout the education period so that practicing professionals demonstrate lower levels of <b>bias</b>. Within medicine, examinations of the curriculum and comparisons by specialty may prove useful. Interventions for <b>bias</b> may look different according to the needs and realities of particular specialties. For instance, because of time pressure, critical ...", "dateLastCrawled": "2022-02-02T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "GitHub - ikasu93/Data-Science-<b>Bias</b>-Guideline: A simple <b>bias</b> guideline ...", "url": "https://github.com/ikasu93/Data-Science-Bias-Guideline", "isFamilyFriendly": true, "displayUrl": "https://<b>github.com</b>/ikasu93/Data-Science-<b>Bias</b>-Guideline", "snippet": "During the data processing, the <b>algorithm</b> <b>can</b> itself be <b>biased</b>, called <b>Algorithm</b> Processing <b>Bias</b>. The most obvious instance of algorithmic processing <b>bias</b> is the use of a statistically <b>biased</b> estimator in the <b>algorithm</b> for better future predictions. So, this <b>bias</b> mostly occurs due to deliberate choice. 4: Algorithmic <b>Bias</b> <b>can</b> also occur when the specific model is employed outside of its context, commonly known as Transfer Context <b>Bias</b>. For instance, using an autonomous system worldwide that ...", "dateLastCrawled": "2021-11-23T03:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "(PDF) <b>Introduction to MAchine Learning &amp; Knowledge Extraction (MAKE</b>)", "url": "https://www.researchgate.net/publication/318118437_Introduction_to_MAchine_Learning_Knowledge_Extraction_MAKE", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/318118437_Introduction_<b>to_MAchine</b>_<b>Learning</b>...", "snippet": "The grand goal of <b>Machine</b> <b>Learning</b> is to develop software which <b>can</b> <b>learn</b> from previous experience\u2014similar to how we humans do. Ultimately, to reach a level of usable intelligence, we need (1 ...", "dateLastCrawled": "2022-01-22T07:30:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "AI Safety Needs Social Scientists - Distill", "url": "https://distill.pub/2019/safety-needs-social-scientists/", "isFamilyFriendly": true, "displayUrl": "https://distill.pub/2019/safety-needs-social-scientists", "snippet": "A judge with an ethical <b>bias</b> who is happy to accept statements reinforcing that <b>bias</b> could result in even <b>more</b> <b>biased</b> debates. A judge with too much confirmation <b>bias</b> might happily accept misleading sources of evidence, and be unwilling to accept arguments showing why that evidence is wrong. In this case, an optimal debate agent might be quite malicious, taking advantage of biases and weakness in the judge to win with convincing but wrong arguments.", "dateLastCrawled": "2022-01-31T07:12:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Chapter 17. Analyzing Community Problems and Solutions | Section 2 ...", "url": "https://ctb.ku.edu/en/table-of-contents/analyze/analyze-community-problems-and-solutions/think-critically/main", "isFamilyFriendly": true, "displayUrl": "https://ctb.ku.edu/en/table-of-contents/analyze/analyze-community-problems-and...", "snippet": "A <b>bias</b> is not necessarily bad: it is simply a preferred way of looking at <b>things</b>. You <b>can</b> be racially <b>biased</b>, but you <b>can</b> also be <b>biased</b> toward looking at all humans as one family. You <b>can</b> be <b>biased</b> toward a liberal or conservative political point of view, or toward or against tolerance. Regardless of whether most of us would consider a particular <b>bias</b> good or bad, not seeing it <b>can</b> limit how we resolve a problem or issue. It&#39;s oriented toward the problem, issue, or situation that you&#39;re ...", "dateLastCrawled": "2022-02-03T02:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "What are the various techniques of <b>machine</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-are-the-various-techniques-of-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-are-the-various-techniques-of-<b>machine</b>-<b>learning</b>", "snippet": "Answer (1 of 6): 1. Linear Regression To understand the working functionality of this <b>algorithm</b>, imagine how you would arrange random logs of wood in increasing order of their weight. There is a catch, however \u2013 you cannot actually weigh each log. You have to guess its weight just by looking at ...", "dateLastCrawled": "2022-01-31T21:37:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "What is a true error in <b>machine</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-a-true-error-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-is-a-true-error-in-<b>machine</b>-<b>learning</b>", "snippet": "Answer: In <b>machine</b> <b>learning</b> we always use some data to produce a model capable of generalize predictions. There is a probability distribution behind your data, what we call True probability distribution. But your data is always a restricted, <b>biased</b> and noisy sample of reality. We dot not have acc...", "dateLastCrawled": "2022-01-12T07:46:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "(PDF) <b>Understanding perception of algorithmic decisions: Fairness</b> ...", "url": "https://www.researchgate.net/publication/323651524_Understanding_perception_of_algorithmic_decisions_Fairness_trust_and_emotion_in_response_to_algorithmic_management", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/323651524_Understanding_perception_of...", "snippet": "\u2018\u2018I think the <b>algorithm</b> is <b>more</b> than capable of. assessing the applicability of people [for] the job. I.e., it ought to be able to <b>easily</b> assess GPA, and the. number and duration of previous ...", "dateLastCrawled": "2022-01-27T13:17:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Chapter 1 Psychology quiz ANSWERS</b> - <b>Learning</b> tools &amp; flashcards, for free", "url": "https://quizlet.com/363855798/chapter-1-psychology-quiz-answers-flash-cards/", "isFamilyFriendly": true, "displayUrl": "https://<b>quizlet.com</b>/363855798/<b>chapter-1-psychology-quiz-answers</b>-flash-cards", "snippet": "<b>Learn</b> vocabulary, terms, and <b>more</b> with flashcards, games, and other study tools. Search. Browse. Create. Log in Sign up. Log in Sign up. Upgrade to remove ads. Only $2.99/month . <b>Chapter 1 Psychology quiz ANSWERS</b>. STUDY. Flashcards. <b>Learn</b>. Write. Spell. Test. PLAY. Match. Gravity. Created by. makenzie_zimmerman. Terms in this set (1124) Critical thinking is _____. A. applying a set of skills to find information about a controversial topic B. applying a set of skills to understand and ...", "dateLastCrawled": "2020-12-13T16:47:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "<b>Machine</b> <b>Learning Techniques for Group Technology Applications</b> ...", "url": "https://www.sciencedirect.com/science/article/pii/S0007850607627450", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0007850607627450", "snippet": "Based on the relative roles of teacher and learner, <b>learning</b> can be classified as 1131: <b>learning</b> by rote, <b>learning</b> by instruction, <b>learning</b> by <b>analogy</b>, <b>learning</b> from examples, <b>learning</b> from observation and discovery. The laat two kinds require inductive <b>learning</b> which is the process of acquiring new knowledge by making inductive inferences from facts provided by a teacher or environment. For a typical inductive <b>learning</b> problem, the givens are (1) a set of observational statements that ...", "dateLastCrawled": "2022-01-19T03:18:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Multi-Dimensional Gender <b>Bias</b> Classification | DeepAI", "url": "https://deepai.org/publication/multi-dimensional-gender-bias-classification", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/multi-dimensional-gender-<b>bias</b>-classification", "snippet": "Multi-Dimensional Gender <b>Bias</b> Classification. 05/01/2020 \u2219 by Emily Dinan, et al. \u2219 0 \u2219 share. <b>Machine</b> <b>learning</b> models are trained to find patterns in data. NLP models can inadvertently learn socially undesirable patterns when training on gender biased text. In this work, we propose a general framework that decomposes gender <b>bias</b> in text ...", "dateLastCrawled": "2021-12-15T17:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Bow-tie signaling in c-di-GMP: <b>Machine</b> <b>learning</b> in a simple biochemical ...", "url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005677", "isFamilyFriendly": true, "displayUrl": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005677", "snippet": "The <b>analogy</b> between c-di-GMP signaling and a <b>machine</b> <b>learning</b> classifier explains that weak selection favors generalist bacteria; generalists integrate environmental stimuli and decide between biofilm and swarming according to the environmental fluctuations experienced in their evolutionary history. Evolution in strong selection, on the other hand, favors specialists. This is similar to how small data sets tend to produce biased classifiers.", "dateLastCrawled": "2019-11-12T12:53:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Classification - Fairness and <b>machine</b> <b>learning</b>", "url": "https://fairmlbook.org/classification.html", "isFamilyFriendly": true, "displayUrl": "https://fairmlbook.org/classification.html", "snippet": "Simply put, the goal of classification is to determine a plausible value for an unknown variable Y given an observed variable X.For example, we might try to predict whether a loan applicant will pay back her loan by looking at various characteristics such as credit history, income, and net worth. Classification also applies in situations where the variable Y does not refer to an event that lies in the future. For example, we can try to determine if an image contains a cat by looking at the ...", "dateLastCrawled": "2022-02-03T07:41:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Recommendation System Series Part 7: The 3 Variants of Boltzmann ...", "url": "https://towardsdatascience.com/recsys-series-part-7-the-3-variants-of-boltzmann-machines-for-collaborative-filtering-4c002af258f9", "isFamilyFriendly": true, "displayUrl": "https://towardsdatascience.com/recsys-series-part-7-the-3-variants-of-boltzmann...", "snippet": "The <b>learning</b> algorithm is intuitive: They subtracted the sleep phase correlation from the wake <b>learning</b> phase and then adjusted the weights accordingly. With a big enough dataset, this algorithm can effectively learn arbitrary mappings between input and output. The Boltzmann <b>machine</b> <b>analogy</b> turns out to be a good insight into what\u2019s happing in the human brain during sleep. In cognitive science, there\u2019s a concept called replay, where the hippocampus plays back our memories and experiences ...", "dateLastCrawled": "2022-01-31T08:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Comparing diversity between groups - drive5", "url": "https://www.drive5.com/usearch/manual/diversity_metrics_compare_groups.html", "isFamilyFriendly": true, "displayUrl": "https://www.drive5.com/usearch/manual/diversity_metrics_compare_groups.html", "snippet": "<b>Machine</b> <b>learning</b> Chimeras Read quality Paired reads OTU errors and biases. Publications. Comparing diversity between sample groups. See also alpha_div_sig command Which alpha and beta diversity metrics are recommended? Interpreting alpha and beta diversity Alpha diversity Beta diversity Abundance <b>bias</b> Cross-talk. Diversity metrics can be compared between groups by amplicon sequencing It is not possible to measure alpha diversity of a single sample. However, diversity metrics can nevertheless ...", "dateLastCrawled": "2022-02-01T14:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "The human factor: Working with machines to make big decisions", "url": "https://images.forbes.com/forbesinsights/StudyPDFs/PwC-The_Human_Factor-REPORT.pdf", "isFamilyFriendly": true, "displayUrl": "https://images.forbes.com/forbesinsights/StudyPDFs/PwC-The_Human_Factor-REPORT.pdf", "snippet": "role of <b>machine</b> <b>learning</b> in the business world. \u201cArtificial intelligence can help people make faster, better, and cheaper decisions. For that to happen, first and foremost, you need an openness of mind to collaborate with the <b>machine</b>, as opposed to treating the technology as either a servant or an overlord.\u201d This balance of mind and machines is just taking hold as companies experiment. Executives say their internal cultures could be more data-driven, with a greater emphasis on data ...", "dateLastCrawled": "2022-01-29T18:49:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "15 Examples of Implicit <b>Bias</b> in the Workplace \u2014 viaMaven: The #1 ...", "url": "https://www.viamaven.com/blog/examples-of-implicit-bias-at-work", "isFamilyFriendly": true, "displayUrl": "https://www.viamaven.com/blog/examples-of-implicit-<b>bias</b>-at-work", "snippet": "There can be an implicit <b>bias</b> to encourage marginalized groups to behave a certain way. For example, managers may overpraise women or black men for being on \u201cgood behavior.\u201d. Example 3: Assertive women. Women may be afraid to be assertive because it will be viewed as being \u201cdifficult.\u201d. Example 4: Black men and tempers.", "dateLastCrawled": "2022-02-03T02:32:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Understanding Unconscious Bias - A Deeper</b> Dive | Webfor", "url": "https://webfor.com/blog/understanding-unconscious-bias-a-deeper-dive/", "isFamilyFriendly": true, "displayUrl": "https://webfor.com/blog/<b>understanding-unconscious-bias-a-deeper</b>-dive", "snippet": "There\u2019s the \u201c<b>in\u201d group</b> and \u201cout\u201d group. So what happens with a team <b>bias</b>, I often call it as if I\u2019m in a game and I\u2019m watching the Blazers play. If the other team does a foul against my team in basketball, I\u2019m going to be screaming and yelling like, \u201cHey call the foul,\u201d right? But on the other side of the floor, when our team fouls their team and possibly gets away with it, I\u2019m probably not going to be yelling and screaming that out because I have this association, this ...", "dateLastCrawled": "2021-12-31T07:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "What does the word &#39;fit&#39; mean in <b>machine</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-does-the-word-fit-mean-in-machine-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/What-does-the-word-fit-mean-in-<b>machine</b>-<b>learning</b>", "snippet": "Answer (1 of 3): \u201cFit\u201d is a term that belongs to the process of back propagation, where the desired outcome is pre-set and the AI is rewarded based on how close it comes to that outcome. What you want the AI to learn is called \u201cfit\u201d. For example, if an AI is trying to learn to play guitar, \u201cfit\u201d ...", "dateLastCrawled": "2022-01-26T08:00:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(in-group bias)  is like +(machine learning algorithm biased to learn certain things more easily)", "+(in-group bias) is similar to +(machine learning algorithm biased to learn certain things more easily)", "+(in-group bias) can be thought of as +(machine learning algorithm biased to learn certain things more easily)", "+(in-group bias) can be compared to +(machine learning algorithm biased to learn certain things more easily)", "machine learning +(in-group bias AND analogy)", "machine learning +(\"in-group bias is like\")", "machine learning +(\"in-group bias is similar\")", "machine learning +(\"just as in-group bias\")", "machine learning +(\"in-group bias can be thought of as\")", "machine learning +(\"in-group bias can be compared to\")"]}