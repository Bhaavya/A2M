{"src_spec_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "SibNet: Food instance counting and segmentation - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0031320321006464", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320321006464", "snippet": "PQ first performs <b>one</b>-to-<b>one</b> matching between ground-truth and segmented instances, and then measures the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) of two matched instances. A match is qualified as true positive TP) if the <b>IoU</b> between two instances is <b>more</b> <b>than</b> 0.5. Otherwise, the ground-truth instance is regarded as a false negative (FN), and a segmented instance is treated as false positive (FP). Specifically, denoting p and g as the segmented and ground-truth instances respectively, PQ of an image is ...", "dateLastCrawled": "2021-12-25T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Functional Task Tree Generation from a Knowledge Graph to Solve Unseen ...", "url": "https://deepai.org/publication/functional-task-tree-generation-from-a-knowledge-graph-to-solve-unseen-problems", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/functional-task-tree-generation-from-a-knowledge-graph...", "snippet": "This was our first effort to evaluate the quality of a task tree, as it is impossible to judge a recipe by only relying on automated testing such as <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>). This is because there can be many ways to prepare a meal. Furthermore, despite having the same <b>ingredients</b>, <b>one</b> recipe can differ from another recipe in terms of cooking steps while both are valid or correct. Hence, we chose to evaluate the FOON-generated task trees by manually checking the task plan for each ...", "dateLastCrawled": "2022-01-13T15:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Cut &amp; recombine: reuse of robot action - SAGE Journals", "url": "https://journals.sagepub.com/doi/pdf/10.1177/0278364919865594", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/pdf/10.1177/0278364919865594", "snippet": "symbolic level, we <b>used</b> the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) measure S box = volume(B scene \\B ADT) volume(B scene [B ADT) where B scene and B ADT are the axis-aligned bounding boxes of the corresponding objects in the scene and in the ADT. The axes are defined as follows: we describe the horizontal (table) plane as (X,Y) and the vertical ...", "dateLastCrawled": "2020-08-19T11:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Abstracts - 2020 - Basic &amp;amp; Clinical ... - <b>Wiley Online Library</b>", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/bcpt.13494", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/bcpt.13494", "snippet": "Segmentation results measured by <b>IoU</b> (<b>Intersection</b> <b>over</b> <b>Union</b>) and Dice metrics. In Kvasir-\u00adSeg test dataset our proposed method achieved Dice = 0.856, <b>IoU</b> = 0.824 and UNet++: Dice = 0.821, <b>IoU</b> = 0.802, U-\u00ad Net: Dice = 0.798, <b>IoU</b> = 0.783, respectively. Conclusions: Our proposed \u201cA-\u00adDenseUNet\u201d method presented <b>more</b> accurate segmentation results compared to other methods. The improved performance by our proposed structure is attributed to its densely connected structure and atrous ...", "dateLastCrawled": "2022-01-16T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Iou</b> <b>One</b> Galaxy Lyrics", "url": "https://groups.google.com/g/kqzg4s8v6/c/as0JzB7l3CI", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/kqzg4s8v6/c/as0JzB7l3CI", "snippet": "What does <b>IOU</b> <b>One</b> Galaxy mean? EPFO has issued revised instructions to adjust field offices to facilitate PF members to rectify their domain of multitude in EPFO records. Dieser Podcast bleibt wie gewohnt absolutes Mittelma\u00df, and <b>like</b> pie spice mix according to package directions. No records found by yours request. The cord of ataris kills working class men. Every year thousands of companies developing creative marketing campaigns to get a page of the billions of dollars being spent. Day ...", "dateLastCrawled": "2022-01-15T06:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Tracking in Unstructured Crowded Scenes | Request PDF", "url": "https://www.researchgate.net/publication/224136004_Tracking_in_Unstructured_Crowded_Scenes", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/224136004_Tracking_in_Unstructured_Crowded_Scenes", "snippet": "In the predeep learning era, trackers often <b>used</b> Kalman filters [4,10], <b>Intersection</b>-<b>over</b>-<b>Union</b> (<b>IoU</b>) [4,5] or flow fields [34, 20] for association. These methods are simple and fast but they fail ...", "dateLastCrawled": "2022-02-02T10:16:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "<b>Data Science</b> Blog - 365 <b>DATA SCIENCE</b>", "url": "https://365datascience.weebly.com/the-best-data-science-blog-2020/archives/08-2020", "isFamilyFriendly": true, "displayUrl": "https://365<b>datascience</b>.weebly.com/the-best-<b>data-science</b>-blog-2020/archives/08-2020", "snippet": "<b>IoU</b>_Score (<b>Intersection</b> <b>over</b> <b>Union</b>): so we have talked about loss, but what about Evaluation Metrics, should we use Accuracy ??? so Answer is No, for Image Segmenation or Object Localization task <b>IoU</b>_score is being <b>Used</b> extensively , Basically Accuracy function will also take those region/pixels which is not part of that object in specific image , specially for medical image segmentation task in which targeted mask contains very less amount of pixel , so in that case accuracy will always be ...", "dateLastCrawled": "2022-01-02T05:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Copy of report.docx - A dissertation on PERSONALIZED RECIPE ...", "url": "https://www.coursehero.com/file/103943514/Copy-of-reportdocx/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/103943514/Copy-of-reportdocx", "snippet": "Screenshot shows the YOLO detects at three scales at 82, 94 and 106 11 layers 2.10 1 X 1 Kernel\u2019s Shape 12 2.11 Convolution layer 13 2.12 Bounding box coordinates prediction 14 2.13 <b>Intersection</b> <b>over</b> <b>union</b> 15 2.14 Different bounding boxes <b>IOU</b> 15 2.15 Non max suppression 18 3.1 Block Diagram of Proposed work 24 3.2 Flow chart of the extraction of number from the number plate for a non 25 helmeted motorcyclist 3.3 Image shows detection of helmet 26 3.4 Image shows detection of License Plate ...", "dateLastCrawled": "2022-01-25T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Grab, Pay <b>and Eat: Semantic Food Detection</b> for Smart ... - arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1711.05128/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1711.05128", "snippet": "To date, most food recognition algorithms and datasets focus on classifying images that include only <b>one</b> <b>dish</b> [martinel2016, liu2016, hassannejad2016]. However, in some cases, there may be <b>more</b> <b>than</b> <b>one</b> <b>dish</b> in the image and, in some cases, the <b>dish</b> can contain several kinds of food.", "dateLastCrawled": "2022-01-29T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>The Origins and Development of the English Language</b> (Textbook) - Term Paper", "url": "https://www.termpaperwarehouse.com/essay-on/The-Origins-And-Development-Of-The/468400", "isFamilyFriendly": true, "displayUrl": "https://www.termpaperwarehouse.com/essay-on/<b>The-Origins-And-Development-Of-The</b>/468400", "snippet": "Some morphemes, <b>like</b> apple, have <b>more</b> <b>than</b> <b>one</b> syllable; others, <b>like</b> -s, are less <b>than</b> a syllable. A morpheme is a form (a sequence of sounds) with a recognizable meaning. Knowing a word\u2019s early history, or etymology, may be useful in dividing it into morphemes, but the decisive factor is the form-meaning link. A morpheme may, however, have <b>more</b> <b>than</b> <b>one</b> pronunciation or spelling. For example, the regular noun plural ending has two spellings (-s and -es) and three pronunciations (an s ...", "dateLastCrawled": "2022-01-25T23:39:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "(PDF) Deep Learning based Food Instance Segmentation using Synthetic Data", "url": "https://www.researchgate.net/publication/353284786_Deep_Learning_based_Food_Instance_Segmentation_using_Synthetic_Data", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/353284786_Deep_Learning_based_Food_Instance...", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>), also known as the Jacquard . Index, is a simple and highly effectiv e rating metric that. calculates the overlapping area between the predicted and. ground truth ...", "dateLastCrawled": "2021-11-30T05:40:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "SibNet: Food instance counting and segmentation - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0031320321006464", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320321006464", "snippet": "PQ first performs <b>one</b>-to-<b>one</b> matching between ground-truth and segmented instances, and then measures the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) of two matched instances. A match is qualified as true positive TP) if the <b>IoU</b> between two instances is <b>more</b> <b>than</b> 0.5. Otherwise, the ground-truth instance is regarded as a false negative (FN), and a segmented instance is treated as false positive (FP). Specifically, denoting p and g as the segmented and ground-truth instances respectively, PQ of an image is ...", "dateLastCrawled": "2021-12-25T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Enhanced Mask R-CNN <b>for Chinese Food Image Detection</b>", "url": "https://www.hindawi.com/journals/mpe/2020/6253827/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/mpe/2020/6253827", "snippet": "In RPNs training, the anchors with the largest <b>intersection</b>-<b>over</b>-<b>Union</b> (<b>IoU</b>) overlapping with the ground truth box are <b>used</b> as positive labels, and the anchors with <b>IoU</b> ratio below 0.3 are <b>used</b> as negative labels. The calculation of <b>IoU</b> is shown in where Detection Result indicates the predicted box, and the Ground Truth indicates the ground truth box. RPNs will fine-tune the region proposals based on the obtained regression information and delete those region proposals that coincide with the ...", "dateLastCrawled": "2022-01-30T18:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Abstracts - 2020 - Basic &amp;amp; Clinical ... - <b>Wiley Online Library</b>", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/bcpt.13494", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/bcpt.13494", "snippet": "Segmentation results measured by <b>IoU</b> (<b>Intersection</b> <b>over</b> <b>Union</b>) and Dice metrics. In Kvasir-\u00adSeg test dataset our proposed method achieved Dice = 0.856, <b>IoU</b> = 0.824 and UNet++: Dice = 0.821, <b>IoU</b> = 0.802, U-\u00ad Net: Dice = 0.798, <b>IoU</b> = 0.783, respectively. Conclusions: Our proposed \u201cA-\u00adDenseUNet\u201d method presented <b>more</b> accurate segmentation results compared to other methods. The improved performance by our proposed structure is attributed to its densely connected structure and atrous ...", "dateLastCrawled": "2022-01-16T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Data Science</b> Blog - 365 <b>DATA SCIENCE</b>", "url": "https://365datascience.weebly.com/the-best-data-science-blog-2020/archives/08-2020", "isFamilyFriendly": true, "displayUrl": "https://365<b>datascience</b>.weebly.com/the-best-<b>data-science</b>-blog-2020/archives/08-2020", "snippet": "<b>IoU</b>_Score (<b>Intersection</b> <b>over</b> <b>Union</b>): so we have talked about loss, but what about Evaluation Metrics, should we use Accuracy ??? so Answer is No, for Image Segmenation or Object Localization task <b>IoU</b>_score is being <b>Used</b> extensively , Basically Accuracy function will also take those region/pixels which is not part of that object in specific image , specially for medical image segmentation task in which targeted mask contains very less amount of pixel , so in that case accuracy will always be ...", "dateLastCrawled": "2022-01-02T05:09:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Copy of report.docx - A dissertation on PERSONALIZED RECIPE ...", "url": "https://www.coursehero.com/file/103943514/Copy-of-reportdocx/", "isFamilyFriendly": true, "displayUrl": "https://www.coursehero.com/file/103943514/Copy-of-reportdocx", "snippet": "Screenshot shows the YOLO detects at three scales at 82, 94 and 106 11 layers 2.10 1 X 1 Kernel\u2019s Shape 12 2.11 Convolution layer 13 2.12 Bounding box coordinates prediction 14 2.13 <b>Intersection</b> <b>over</b> <b>union</b> 15 2.14 Different bounding boxes <b>IOU</b> 15 2.15 Non max suppression 18 3.1 Block Diagram of Proposed work 24 3.2 Flow chart of the extraction of number from the number plate for a non 25 helmeted motorcyclist 3.3 Image shows detection of helmet 26 3.4 Image shows detection of License Plate ...", "dateLastCrawled": "2022-01-25T22:13:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) An <b>Image Processing Approach for Calorie Intake</b> ... - ResearchGate", "url": "https://www.researchgate.net/publication/241633012_An_Image_Processing_Approach_for_Calorie_Intake_Measurement", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/241633012_An_Image_Processing_Approach_for...", "snippet": "The recognition accuracy for the combination of Ville Cafe and the Food-256 Datasets was 99.86%, and the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) was 97.17%. The food weight estimation experiment included ...", "dateLastCrawled": "2022-01-11T01:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Graph-based food ingredient detection</b> - UBC Library Open Collections", "url": "https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0387154", "isFamilyFriendly": true, "displayUrl": "https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0387154", "snippet": "Normally objects in an image are explicit, but <b>ingredients</b> in food photos are most often invisible (integrated) and hence need to be inferred in a much <b>more</b> contextual manner. To this end, we explore an end-to-end neural framework with the core property of learning the relationships between ingredient pairs. We incorporate a Transformer module followed by a Gated Graph Attention Network (GGAT) to determine the ingredient list for the input <b>dish</b> image. This framework encodes <b>ingredients</b> in a ...", "dateLastCrawled": "2021-04-19T02:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "<b>Iou</b> <b>One</b> Galaxy Lyrics - groups.google.com", "url": "https://groups.google.com/g/kqzg4s8v6/c/as0JzB7l3CI", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/kqzg4s8v6/c/as0JzB7l3CI", "snippet": "Watch all seasons and episodes of Blue Exorcist including the Kyoto Saga and feedback the <b>intersection</b> of Assiah, and saw man asks the phone to host another out of his exes. Mom all our long! All lyrics speak for educational purposes and personal use only. You looked so today, <b>more</b> organized inbox. Choose from huge variety of jewelry in them beautiful silver tone. Would rub a free coupons. Once flat the lineup changed, places to halve and where to eat there a day movie in Greenwich ...", "dateLastCrawled": "2022-01-15T06:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Cut &amp; recombine: reuse of robot action - SAGE Journals", "url": "https://journals.sagepub.com/doi/pdf/10.1177/0278364919865594", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/pdf/10.1177/0278364919865594", "snippet": "et al., 2011). We use simpler language <b>than</b> is <b>used</b> in these studies, <b>more</b> related to the way <b>one</b> would give an instruc-tion to a child or a \u2018\u2018newbie\u2019\u2019 in a workshop. This makes our approach quite intuitive and also accessible to new and non-expert users. It also leads to <b>more</b> robust language pro-", "dateLastCrawled": "2020-08-19T11:24:00.0000000Z", "language": "en", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "Enhancing Food Intake Tracking in Long-Term Care with Automated Food ...", "url": "https://deepai.org/publication/enhancing-food-intake-tracking-in-long-term-care-with-automated-food-imaging-and-nutrient-intake-tracking-afini-t-technology", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/enhancing-food-intake-tracking-in-long-term-care-with...", "snippet": "Segmentation accuracy was good with an average an <b>intersection</b> <b>over</b> <b>union</b> (<b>IOU</b>) of 0.879 across RTF and MTF datasets ... AFINI-T could also be <b>used</b> as a tool for developing <b>more</b> nutrient-dense recipes in which certain <b>ingredients</b> could be replaced with others. For example, replacing half of the ground beef in a chili recipe with lentils to decrease saturated fat and cholesterol while increasing fibre. Data on which foods are consumed <b>can</b> inform how to design recipes to be smarter, <b>more</b> ...", "dateLastCrawled": "2022-01-26T14:54:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Yolo <b>Iou</b> Loss Recipes - yakcook.com", "url": "https://yakcook.com/yolo-iou-loss/", "isFamilyFriendly": true, "displayUrl": "https://yakcook.com/yolo-<b>iou</b>-loss", "snippet": "2018-05-03 \u00b7 <b>IOU</b> to the rescue! What <b>IOU</b> (<b>Intersection</b> <b>Over</b> <b>Union</b>) does is, it gets you a score of area of overlap <b>over</b> area of <b>union</b>. <b>IOU</b> = Area of Overlap / Area of <b>Union</b>. While it&#39;s rarely perfect or 1. Its somewhat closer, the lesser the value of <b>IOU</b>, the worse YOLO is predicting the bounding box with reference to ground truth.", "dateLastCrawled": "2022-02-03T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Abstracts - 2020 - Basic &amp;amp; Clinical ... - <b>Wiley Online Library</b>", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/bcpt.13494", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/bcpt.13494", "snippet": "Segmentation results measured by <b>IoU</b> (<b>Intersection</b> <b>over</b> <b>Union</b>) and Dice metrics. In Kvasir-\u00adSeg test dataset our proposed method achieved Dice = 0.856, <b>IoU</b> = 0.824 and UNet++: Dice = 0.821, <b>IoU</b> = 0.802, U-\u00ad Net: Dice = 0.798, <b>IoU</b> = 0.783, respectively. Conclusions: Our proposed \u201cA-\u00adDenseUNet\u201d method presented <b>more</b> accurate segmentation results compared to other methods. The improved performance by our proposed structure is attributed to its densely connected structure and atrous ...", "dateLastCrawled": "2022-01-16T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>Dish</b> <b>Detection and Segmentation for Dietary Assessment on</b> Smartphones ...", "url": "https://www.researchgate.net/publication/283662115_Dish_Detection_and_Segmentation_for_Dietary_Assessment_on_Smartphones", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/283662115_<b>Dish</b>_Detection_and_Segmentation_for...", "snippet": "The recognition accuracy for the combination of Ville Cafe and the Food-256 Datasets was 99.86%, and the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) was 97.17%. The food weight estimation experiment included ...", "dateLastCrawled": "2021-12-03T12:11:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "<b>Iou</b> <b>One</b> Galaxy Lyrics - groups.google.com", "url": "https://groups.google.com/g/kqzg4s8v6/c/as0JzB7l3CI", "isFamilyFriendly": true, "displayUrl": "https://groups.google.com/g/kqzg4s8v6/c/as0JzB7l3CI", "snippet": "KFC <b>can</b> tune into the popularity of justify own biscuits while connecting with another popular item, off <b>more</b> online. Make a reservation and punch your mom how amazing she is. If you bloom like your name to be removed or adapted, use their catering it as inspiration for dry your entertaining ideas. So I gave it crawl away. Donald Faison on the TV Land comedy, for proof of duration work, den ich je gemacht habe.", "dateLastCrawled": "2022-01-15T06:28:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Learning Video Models from Text: Zero-Shot Anticipation for Procedural ...", "url": "https://deepai.org/publication/learning-video-models-from-text-zero-shot-anticipation-for-procedural-actions", "isFamilyFriendly": true, "displayUrl": "https://deepai.org/publication/learning-video-models-from-text-zero-shot-anticipation...", "snippet": "Recipe1M is a large-scale dataset with, as the name suggests, approximately <b>one</b> million recipes with a recipe name, list of <b>ingredients</b>, a sequence of instructions, and images of the final <b>dish</b> for each recipe. YoucookII is a collection of cooking videos from YouTube with around 2000 videos of 89 dishes. Videos are captured from a third-person viewpoint. Each <b>dish</b> has an average of 22 videos, each with an average of 8 steps. The videos are annotated with the temporal boundaries of each step ...", "dateLastCrawled": "2021-11-26T02:15:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) The <b>Origins and Development of the English Language (Textbook</b> ...", "url": "https://www.academia.edu/36656706/The_Origins_and_Development_of_the_English_Language_Textbook_", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/36656706/The_<b>Origins_and_Development_of_the_English_Language</b>...", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-21T15:35:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "(PDF) [<b>Amy Wilkinson The Creator 39 s</b> Code The Six Essen - Academia.edu", "url": "https://www.academia.edu/36958114/_Amy_Wilkinson_The_Creator_39_s_Code_The_Six_Essen", "isFamilyFriendly": true, "displayUrl": "https://www.academia.edu/36958114/_<b>Amy_Wilkinson_The_Creator_39_s</b>_Code_The_Six_Essen", "snippet": "Academia.edu is a platform for academics to share research papers.", "dateLastCrawled": "2022-01-09T01:36:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "The Pulse Classic - Wang Shu-he.pdf [x25ddzevj9wp]", "url": "https://vbook.pub/documents/the-pulse-classic-wang-shu-hepdf-x25ddzevj9wp", "isFamilyFriendly": true, "displayUrl": "https://vbook.pub/documents/the-pulse-classic-wang-shu-hepdf-x25ddzevj9wp", "snippet": "The translator believes that the most plausible <b>one</b> has to do with the fact that, in Chinese culture, the left is believed to be superior to or <b>more</b> respectable <b>than</b> the right. Therefore, the viscera that the left pulse reflects are offices, while the viscera reflected by the right pulse are mansions. This point is made clear by the following comparison: Heart (fire)-lung (metal); liver (wood) -spleen (earth); kidney (water)- life gate (ministerial fire). The pairs are arranged in order of ...", "dateLastCrawled": "2022-02-02T17:20:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "Vocabulary | <b>KBI El Rahma Education Centre Sukabumi</b>", "url": "https://forstudyforsmart.wordpress.com/category/vocabulary/", "isFamilyFriendly": true, "displayUrl": "https://forstudyforsmart.wordpress.com/category/vocabulary", "snippet": "3. People <b>can</b> afford to buy <b>more</b> and live <b>more</b> comfortably <b>than</b> they could twenty years ago. There has been a _____ in the standard of living. 4. Because our company is bigger now <b>than</b> it was two years ago, we need to recruit <b>more</b> employees. Because of company _____ <b>over</b> the last two years, we need <b>more</b> workers. 5. American travelers abroad ...", "dateLastCrawled": "2022-01-18T18:26:00.0000000Z", "language": "id", "isNavigational": false}], [{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "SibNet: Food instance counting and segmentation - ScienceDirect", "url": "https://www.sciencedirect.com/science/article/pii/S0031320321006464", "isFamilyFriendly": true, "displayUrl": "https://www.sciencedirect.com/science/article/pii/S0031320321006464", "snippet": "PQ first performs <b>one</b>-to-<b>one</b> matching between ground-truth and segmented instances, and then measures the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) of two matched instances. A match is qualified as true positive TP) if the <b>IoU</b> between two instances is <b>more</b> <b>than</b> 0.5. Otherwise, the ground-truth instance is regarded as a false negative (FN), and a segmented instance is treated as false positive (FP). Specifically, denoting p and g as the segmented and ground-truth instances respectively, PQ of an image is ...", "dateLastCrawled": "2021-12-25T02:21:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Food Image Segmentation for Dietary Assessment | Request PDF", "url": "https://www.researchgate.net/publication/309127489_Food_Image_Segmentation_for_Dietary_Assessment", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/309127489_Food_Image_Segmentation_for_Dietary...", "snippet": "Three kinds of metrics are utilised here to evaluate the semantic food segmentation performance, including: 1) the <b>Intersection</b> of <b>Union</b> (<b>IoU</b>) and mIoU, where <b>IoU</b> is evaluated for each hyper food ...", "dateLastCrawled": "2022-01-27T03:58:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "Enhanced Mask R-CNN <b>for Chinese Food Image Detection</b>", "url": "https://www.hindawi.com/journals/mpe/2020/6253827/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/mpe/2020/6253827", "snippet": "In RPNs training, the anchors with the largest <b>intersection</b>-<b>over</b>-<b>Union</b> (<b>IoU</b>) overlapping with the ground truth box are <b>used</b> as positive labels, and the anchors with <b>IoU</b> ratio below 0.3 are <b>used</b> as negative labels. The calculation of <b>IoU</b> is shown in where Detection Result indicates the predicted box, and the Ground Truth indicates the ground truth box. RPNs will fine-tune the region proposals based on the obtained regression information and delete those region proposals that coincide with the ...", "dateLastCrawled": "2022-01-30T18:39:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "Grab, Pay <b>and Eat: Semantic Food Detection</b> for Smart ... - arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/1711.05128/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/1711.05128", "snippet": "However, in some cases, there may be <b>more</b> <b>than</b> <b>one</b> <b>dish</b> in the image and, in some cases, the <b>dish</b> <b>can</b> contain several kinds of food. ... <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>). Also known as Jaccard index, it is defined as: <b>I o U</b> (c) = \u2211 i t i = = c \u2227 p i = = c \u2211 i t i = = c \u2228 p i = = c (2) where c is a class, i represents all the pixels of the dataset, t i are the target labels, and p i are the predicted labels. Note that this metric is calculated for each single class c, and then the mean ...", "dateLastCrawled": "2022-01-29T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Yolo <b>Iou</b> Loss Recipes - yakcook.com", "url": "https://yakcook.com/yolo-iou-loss/", "isFamilyFriendly": true, "displayUrl": "https://yakcook.com/yolo-<b>iou</b>-loss", "snippet": "2018-05-03 \u00b7 <b>IOU</b> to the rescue! What <b>IOU</b> (<b>Intersection</b> <b>Over</b> <b>Union</b>) does is, it gets you a score of area of overlap <b>over</b> area of <b>union</b>. <b>IOU</b> = Area of Overlap / Area of <b>Union</b>. While it&#39;s rarely perfect or 1. Its somewhat closer, the lesser the value of <b>IOU</b>, the worse YOLO is predicting the bounding box with reference to ground truth.", "dateLastCrawled": "2022-02-03T07:45:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Abstracts - 2020 - Basic &amp;amp; Clinical ... - <b>Wiley Online Library</b>", "url": "https://onlinelibrary.wiley.com/doi/full/10.1111/bcpt.13494", "isFamilyFriendly": true, "displayUrl": "https://onlinelibrary.wiley.com/doi/full/10.1111/bcpt.13494", "snippet": "Segmentation results measured by <b>IoU</b> (<b>Intersection</b> <b>over</b> <b>Union</b>) and Dice metrics. In Kvasir-\u00adSeg test dataset our proposed method achieved Dice = 0.856, <b>IoU</b> = 0.824 and UNet++: Dice = 0.821, <b>IoU</b> = 0.802, U-\u00ad Net: Dice = 0.798, <b>IoU</b> = 0.783, respectively. Conclusions: Our proposed \u201cA-\u00adDenseUNet\u201d method presented <b>more</b> accurate segmentation results <b>compared</b> to other methods. The improved performance by our proposed structure is attributed to its densely connected structure and atrous ...", "dateLastCrawled": "2022-01-16T03:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "(PDF) An <b>Image Processing Approach for Calorie Intake</b> ... - ResearchGate", "url": "https://www.researchgate.net/publication/241633012_An_Image_Processing_Approach_for_Calorie_Intake_Measurement", "isFamilyFriendly": true, "displayUrl": "https://www.researchgate.net/publication/241633012_An_Image_Processing_Approach_for...", "snippet": "The recognition accuracy for the combination of Ville Cafe and the Food-256 Datasets was 99.86%, and the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) was 97.17%. The food weight estimation experiment included ...", "dateLastCrawled": "2022-01-11T01:44:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "<b>Graph-based food ingredient detection</b> - UBC Library Open Collections", "url": "https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0387154", "isFamilyFriendly": true, "displayUrl": "https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0387154", "snippet": "Normally objects in an image are explicit, but <b>ingredients</b> in food photos are most often invisible (integrated) and hence need to be inferred in a much <b>more</b> contextual manner. To this end, we explore an end-to-end neural framework with the core property of learning the relationships between ingredient pairs. We incorporate a Transformer module followed by a Gated Graph Attention Network (GGAT) to determine the ingredient list for the input <b>dish</b> image. This framework encodes <b>ingredients</b> in a ...", "dateLastCrawled": "2021-04-19T02:55:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Cut &amp; recombine: reuse of robot action - SAGE Journals", "url": "https://journals.sagepub.com/doi/pdf/10.1177/0278364919865594", "isFamilyFriendly": true, "displayUrl": "https://journals.sagepub.com/doi/pdf/10.1177/0278364919865594", "snippet": "et al., 2011). We use simpler language <b>than</b> is <b>used</b> in these studies, <b>more</b> related to the way <b>one</b> would give an instruc-tion to a child or a \u2018\u2018newbie\u2019\u2019 in a workshop. This makes our approach quite intuitive and also accessible to new and non-expert users. It also leads to <b>more</b> robust language pro-", "dateLastCrawled": "2020-08-19T11:24:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "The Pulse Classic - Wang Shu-he.pdf [x25ddzevj9wp]", "url": "https://vbook.pub/documents/the-pulse-classic-wang-shu-hepdf-x25ddzevj9wp", "isFamilyFriendly": true, "displayUrl": "https://vbook.pub/documents/the-pulse-classic-wang-shu-hepdf-x25ddzevj9wp", "snippet": "The translator believes that the most plausible <b>one</b> has to do with the fact that, in Chinese culture, the left is believed to be superior to or <b>more</b> respectable <b>than</b> the right. Therefore, the viscera that the left pulse reflects are offices, while the viscera reflected by the right pulse are mansions. This point is made clear by the following comparison: Heart (fire)-lung (metal); liver (wood) -spleen (earth); kidney (water)- life gate (ministerial fire). The pairs are arranged in order of ...", "dateLastCrawled": "2022-02-02T17:20:00.0000000Z", "language": "en", "isNavigational": false}]], "gen_res": [[{"id": "https://api.bing.microsoft.com/api/v7/#WebPages.0", "name": "13.4. <b>Anchor</b> Boxes \u2014 Dive into Deep <b>Learning</b> 0.17.2 documentation", "url": "https://d2l.ai/chapter_computer-vision/anchor.html", "isFamilyFriendly": true, "displayUrl": "https://d2l.ai/chapter_computer-vision/<b>anchor</b>.html", "snippet": "<b>Intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>), also known as Jaccard index, measures the similarity of two bounding boxes. It is the ratio of their <b>intersection</b> area to their <b>union</b> area. In a training set, we need two types of labels for each <b>anchor</b> box. One is the class of the object relevant to the <b>anchor</b> box and the other is the offset of the ground-truth ...", "dateLastCrawled": "2022-01-31T12:07:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.1", "name": "Deep Hybrid Convolutional Neural Network for Segmentation of Melanoma ...", "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8592765/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.ncbi.nlm.nih.gov</b>/pmc/articles/PMC8592765", "snippet": "<b>Machine</b> <b>learning</b> algorithms have been widely used in cancer research [2 ... <b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) is a task outputting a prediction range. In order for <b>IoU</b> to be used to detect objects of any size and shape, it is necessary to mark the range of the detected object in the training set image and measure the correlation between the ground-truth and the prediction. <b>IoU</b> = TP TP + FP + FN. (6) 3. Experiment. 3.1. Dataset. 3.1.1. International Skin Imaging Collaboration 2018 Dataset . The ...", "dateLastCrawled": "2021-11-20T10:31:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.2", "name": "<b>Machine Learning</b> Glossary | <b>Google Developers</b>", "url": "https://developers.google.com/machine-learning/glossary/", "isFamilyFriendly": true, "displayUrl": "https://<b>developers.google.com</b>/<b>machine-learning</b>/glossary", "snippet": "The <b>intersection</b> of two sets divided by their <b>union</b>. In <b>machine-learning</b> image-detection tasks, <b>IoU</b> is used to measure the accuracy of the model\u2019s predicted bounding box with respect to the ground-truth bounding box. In this case, the <b>IoU</b> for the two boxes is the ratio between the overlapping area and the total area, and its value ranges from ...", "dateLastCrawled": "2022-02-03T02:22:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.3", "name": "<b>What is intersection over union in deep</b> <b>learning</b>? - Quora", "url": "https://www.quora.com/What-is-intersection-over-union-in-deep-learning", "isFamilyFriendly": true, "displayUrl": "https://www.quora.com/<b>What-is-intersection-over-union-in-deep</b>-<b>learning</b>", "snippet": "Answer (1 of 2): Generally <b>Intersection</b> <b>over</b> <b>union</b>(<b>IOU</b>) is a measure of overlap between two bounding box . In computer vision it is used for correctly detecting an object.To know object detection first you have to know about object localization . Object localization refers to figuring out where i...", "dateLastCrawled": "2022-01-19T07:29:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.4", "name": "Crack identification for bridge condition monitoring using deep ...", "url": "https://www.jvejournals.com/article/22032", "isFamilyFriendly": true, "displayUrl": "https://www.jvejournals.com/article/22032", "snippet": "By that <b>analogy</b>, several different CNN models are obtained and the accuracy of patch classification could be improved by using all models together. Finally, 80 test images are processed by the feedback-update CNN models and FCN model with a sliding window technique to generate crack identification results. <b>Intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) is calculated as an index to quantificationally evaluate the accuracy of the proposed method. Orthotropic steel bridge decks and steel box girders are key ...", "dateLastCrawled": "2021-12-22T03:52:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.5", "name": "Visual Chunking: A List Prediction Framework for Region-Based Object ...", "url": "https://www.ri.cmu.edu/pub_files/2015/5/VC_icra.pdf", "isFamilyFriendly": true, "displayUrl": "https://www.ri.cmu.edu/pub_files/2015/5/VC_icra.pdf", "snippet": "as a natural extension of the <b>intersection</b> <b>over</b> <b>union</b> metric (<b>IoU</b>) (described in Section III-A), and develop an algorithm that targets this criterion. This approach uses recent work Fig. 1: Visual Chunking run on test data. The rst prediction is shown in red, the second in green, the third in blue, and the fourth in yellow.", "dateLastCrawled": "2021-07-17T04:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.6", "name": "Deep Hybrid Convolutional Neural Network for Segmentation of Melanoma ...", "url": "https://www.hindawi.com/journals/cin/2021/9409508/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.hindawi.com</b>/journals/cin/2021/9409508", "snippet": "<b>Intersection</b> <b>over</b> <b>Union</b> (<b>IoU</b>) is a task outputting a prediction range. In order for <b>IoU</b> to be used to detect objects of any size and shape, it is necessary to mark the range of the detected object in the training set image and measure the correlation between the ground-truth and the prediction. 3. Experiment 3.1. Dataset 3.1.1. International ...", "dateLastCrawled": "2021-12-28T07:50:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.7", "name": "Unraveling the deep <b>learning</b> gearbox in optical coherence tomography ...", "url": "https://www.nature.com/articles/s42003-021-01697-y", "isFamilyFriendly": true, "displayUrl": "https://www.nature.com/articles/s42003-021-01697-y", "snippet": "In that previous study, the <b>intersection</b> <b>over</b> <b>union</b> (<b>IOU</b>) scores was applied. In the proposed analysis in cynomolgus monkeys, that score was changed to the Hamming distance metric to additionally ...", "dateLastCrawled": "2022-01-31T21:51:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.8", "name": "Unsupervised part representation by Flow Capsules \u2013 arXiv Vanity", "url": "https://www.arxiv-vanity.com/papers/2011.13920/", "isFamilyFriendly": true, "displayUrl": "https://www.arxiv-vanity.com/papers/2011.13920", "snippet": "Tab. 3 compares the <b>intersection</b> <b>over</b> <b>union</b> (<b>IoU</b>) of our masks against PSD and R-NEM (van2018relational). Although PSD receives the ground truth optical flow during training, FlowCapsules consistently have better or equal IoUs during testing on both the Geo and Exercise datasets. One other significant difference between PSD and FlowCapsules lies in how they generate the masks. FlowCapsules generate the", "dateLastCrawled": "2022-01-06T16:23:00.0000000Z", "language": "en", "isNavigational": false}, {"id": "https://api.bing.microsoft.com/api/v7/#WebPages.9", "name": "<b>Calculating IOU of masks using tensorflow</b> : learnmachinelearning", "url": "https://www.reddit.com/r/learnmachinelearning/comments/ns8c8q/calculating_iou_of_masks_using_tensorflow/", "isFamilyFriendly": true, "displayUrl": "https://<b>www.reddit.com</b>/r/learn<b>machinelearning</b>/comments/ns8c8q/calculating_<b>iou</b>_of_masks...", "snippet": "<b>Calculating IOU of masks using tensorflow</b>. Hello! I&#39;m trying to speed up a process from my computer vision pipeline where I calculate <b>IOU</b> of two binary masks by using tensorflow 1.15. I&#39;ll post a snippet of code showing how I&#39;m doing it with numpy and how I&#39;m trying to do it with tensorflow, so far tensorflow is waaaay slower and was hoping someone could point out why that is happening. ...", "dateLastCrawled": "2021-12-28T03:28:00.0000000Z", "language": "en", "isNavigational": false}], [], [], [], [], []], "all_bing_queries": ["+(intersection over union (iou))  is like +(ingredients used in more than one dish)", "+(intersection over union (iou)) is similar to +(ingredients used in more than one dish)", "+(intersection over union (iou)) can be thought of as +(ingredients used in more than one dish)", "+(intersection over union (iou)) can be compared to +(ingredients used in more than one dish)", "machine learning +(intersection over union (iou) AND analogy)", "machine learning +(\"intersection over union (iou) is like\")", "machine learning +(\"intersection over union (iou) is similar\")", "machine learning +(\"just as intersection over union (iou)\")", "machine learning +(\"intersection over union (iou) can be thought of as\")", "machine learning +(\"intersection over union (iou) can be compared to\")"]}